{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "1d4cf661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import torch.optim as optim \n",
    "from torch.optim import AdamW \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "21fc117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Данные.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "a3c142df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>lu</th>\n",
       "      <th>P0</th>\n",
       "      <th>I</th>\n",
       "      <th>gamma</th>\n",
       "      <th>sgamma</th>\n",
       "      <th>r</th>\n",
       "      <th>Psat</th>\n",
       "      <th>Lsat</th>\n",
       "      <th>loptim</th>\n",
       "      <th>lres</th>\n",
       "      <th>loptim/lres</th>\n",
       "      <th>Psat/Pall</th>\n",
       "      <th>Lsat/lu</th>\n",
       "      <th>f</th>\n",
       "      <th>rho</th>\n",
       "      <th>P0/Pall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>12800000.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.430000e+08</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2.261250e-08</td>\n",
       "      <td>2.257770e-08</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>1.180000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.800000e+07</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1.585280e-07</td>\n",
       "      <td>1.580440e-07</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>3.130000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.130000e+09</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2.061380e-08</td>\n",
       "      <td>2.057220e-08</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>2.070000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.100000e+09</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.648760e-08</td>\n",
       "      <td>1.645770e-08</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.00136</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>1.850000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.180000e+09</td>\n",
       "      <td>19.4</td>\n",
       "      <td>2.356200e-08</td>\n",
       "      <td>2.351110e-08</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>2.210000e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k    lu          P0      I   gamma  sgamma       r          Psat  Lsat  \\\n",
       "0  3.89  3.69  12800000.0   80.0  2650.0     0.0  0.0001  1.430000e+08  18.5   \n",
       "1  3.89  3.69     12800.0   80.0  1000.0     0.0  0.0001  9.800000e+07  16.7   \n",
       "2  3.98  3.69    150000.0  500.0  2830.0     0.0  0.0001  1.130000e+09  20.3   \n",
       "3  3.98  3.69   1500000.0  500.0  3160.0     0.0  0.0001  1.100000e+09  18.3   \n",
       "4  3.98  3.69    150000.0  500.0  2650.0     0.0  0.0001  1.180000e+09  19.4   \n",
       "\n",
       "         loptim          lres  loptim/lres  Psat/Pall  Lsat/lu      f  \\\n",
       "0  2.261250e-08  2.257770e-08     0.001542    0.00132     5.01  0.736   \n",
       "1  1.585280e-07  1.580440e-07     0.003065    0.00240     4.52  0.736   \n",
       "2  2.061380e-08  2.057220e-08     0.002024    0.00156     5.49  0.735   \n",
       "3  1.648760e-08  1.645770e-08     0.001814    0.00136     4.96  0.735   \n",
       "4  2.356200e-08  2.351110e-08     0.002164    0.00175     5.25  0.735   \n",
       "\n",
       "        rho       P0/Pall  \n",
       "0  0.000965  1.180000e-04  \n",
       "1  0.002550  3.130000e-07  \n",
       "2  0.001690  2.070000e-07  \n",
       "3  0.001510  1.850000e-06  \n",
       "4  0.001800  2.210000e-07  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "140b811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "52e1ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "243cc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Psat/Pall']<0.008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "2f6103f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log'] = np.log(df[['Psat/Pall']])\n",
    "df['log0'] = np.log(df['P0']/df['I']/df['gamma']/511000)\n",
    "df['optim'] = df['loptim/lres']/df['Psat/Pall']\n",
    "df['Lsat/lu'] = np.log(df['Lsat/lu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "ee8f0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['optim']<2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "294bf40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.931013431013431"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)/l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "611d767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['optim'] = df['loptim/lres']/df['rho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "cf41df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['optim'] = (df['optim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "f418fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(columns=['P0', 'optim', 'P0/Pall', 'Psat', 'Lsat', 'loptim','lres', 'loptim/lres', 'Psat/Pall', 'Lsat/lu', 'f', 'rho', 'log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "3642dca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>lu</th>\n",
       "      <th>I</th>\n",
       "      <th>gamma</th>\n",
       "      <th>sgamma</th>\n",
       "      <th>r</th>\n",
       "      <th>log0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-9.043511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-14.976706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-15.388374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-13.196085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>-15.322657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>3.76</td>\n",
       "      <td>3.77</td>\n",
       "      <td>700.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-16.464401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>2.50</td>\n",
       "      <td>2.84</td>\n",
       "      <td>800.0</td>\n",
       "      <td>4470.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-13.771266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>3.74</td>\n",
       "      <td>3.55</td>\n",
       "      <td>800.0</td>\n",
       "      <td>9490.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-14.109963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>3.54</td>\n",
       "      <td>3.55</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1730.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-17.811909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>2.95</td>\n",
       "      <td>3.55</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>-15.450491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1525 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         k    lu      I    gamma  sgamma         r       log0\n",
       "0     3.89  3.69   80.0   2650.0  0.0000  0.000100  -9.043511\n",
       "1     3.89  3.69   80.0   1000.0  0.0000  0.000100 -14.976706\n",
       "2     3.98  3.69  500.0   2830.0  0.0000  0.000100 -15.388374\n",
       "3     3.98  3.69  500.0   3160.0  0.0000  0.000100 -13.196085\n",
       "4     3.98  3.69  500.0   2650.0  0.0000  0.000100 -15.322657\n",
       "...    ...   ...    ...      ...     ...       ...        ...\n",
       "1632  3.76  3.77  700.0  10000.0  0.0001  0.000086 -16.464401\n",
       "1633  2.50  2.84  800.0   4470.0  0.0001  0.000086 -13.771266\n",
       "1634  3.74  3.55  800.0   9490.0  0.0001  0.000086 -14.109963\n",
       "1635  3.54  3.55   80.0   1730.0  0.0001  0.000086 -17.811909\n",
       "1636  2.95  3.55  500.0   2650.0  0.0001  0.000086 -15.450491\n",
       "\n",
       "[1525 rows x 7 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "17404835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(columns=[ 'k', 'lu', 'I', 'gamma', 'sgamma', 'r', 'log0', 'P0', 'P0/Pall', 'loptim','lres', 'loptim/lres', 'Psat/Pall', 'Lsat', 'f', 'rho', 'Psat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "01cfb8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lsat/lu</th>\n",
       "      <th>log</th>\n",
       "      <th>optim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.611436</td>\n",
       "      <td>-6.630124</td>\n",
       "      <td>1.598041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.508512</td>\n",
       "      <td>-6.032287</td>\n",
       "      <td>1.201894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.702928</td>\n",
       "      <td>-6.463069</td>\n",
       "      <td>1.197420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.601406</td>\n",
       "      <td>-6.600271</td>\n",
       "      <td>1.201364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.658228</td>\n",
       "      <td>-6.348139</td>\n",
       "      <td>1.202222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>2.815409</td>\n",
       "      <td>-7.675626</td>\n",
       "      <td>1.195740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>2.100469</td>\n",
       "      <td>-7.303765</td>\n",
       "      <td>0.802487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>2.468100</td>\n",
       "      <td>-7.726466</td>\n",
       "      <td>0.794438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>2.142416</td>\n",
       "      <td>-6.469500</td>\n",
       "      <td>1.200967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>1.752672</td>\n",
       "      <td>-6.502290</td>\n",
       "      <td>1.195663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1525 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lsat/lu       log     optim\n",
       "0     1.611436 -6.630124  1.598041\n",
       "1     1.508512 -6.032287  1.201894\n",
       "2     1.702928 -6.463069  1.197420\n",
       "3     1.601406 -6.600271  1.201364\n",
       "4     1.658228 -6.348139  1.202222\n",
       "...        ...       ...       ...\n",
       "1632  2.815409 -7.675626  1.195740\n",
       "1633  2.100469 -7.303765  0.802487\n",
       "1634  2.468100 -7.726466  0.794438\n",
       "1635  2.142416 -6.469500  1.200967\n",
       "1636  1.752672 -6.502290  1.195663\n",
       "\n",
       "[1525 rows x 3 columns]"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "2a77acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "515fa4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler2.fit(y_train)\n",
    "\n",
    "y_train = scaler2.transform(y_train)\n",
    "y_test = scaler2.transform(y_test)\n",
    "y_val = scaler2.transform(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "dcc3a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = torch.Tensor(X_train) \n",
    "y_train = torch.Tensor(y_train)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(y_val)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "train_set = TensorDataset(X_train, y_train) \n",
    "validate_set = TensorDataset(X_val, y_val) \n",
    "test_set = TensorDataset(X_test, y_test) \n",
    "\n",
    "\n",
    "# Create Dataloader to read the data within batch sizes and put into memory. \n",
    "train_loader = DataLoader(train_set, batch_size = 64, shuffle = True) \n",
    "validate_loader = DataLoader(validate_set, batch_size = 20) \n",
    "test_loader = DataLoader(test_set, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "541c3e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.46153846, 0.7658863 , 1.        , 0.94883835, 0.        ,\n",
       "        0.04347826, 0.54561245],\n",
       "       [0.22408026, 0.8929766 , 0.08176101, 0.07457566, 0.5       ,\n",
       "        0.05797102, 0.6521354 ],\n",
       "       [0.89966553, 0.24749164, 0.8742138 , 0.1703784 , 0.1       ,\n",
       "        0.08695652, 0.45691556],\n",
       "       [0.6354515 , 0.9230769 , 0.00251572, 0.24260664, 0.        ,\n",
       "        0.05797102, 0.17896353],\n",
       "       [0.66220737, 0.5819398 , 0.00377358, 0.02692508, 0.1       ,\n",
       "        0.20289855, 0.45028192],\n",
       "       [0.09030101, 0.93645483, 0.00251572, 0.19746399, 0.        ,\n",
       "        0.13043478, 0.47188294],\n",
       "       [0.23076923, 0.4949833 , 0.06918239, 0.01097468, 1.        ,\n",
       "        0.42028984, 0.8454146 ],\n",
       "       [0.8394649 , 0.72240806, 0.05660377, 0.19746399, 0.        ,\n",
       "        0.10144927, 0.5766411 ],\n",
       "       [0.60535115, 0.7424749 , 0.8742138 , 0.63083345, 0.        ,\n",
       "        0.2753623 , 0.32059497],\n",
       "       [0.81270903, 0.16722408, 0.00251572, 0.09714699, 0.        ,\n",
       "        0.13043478, 0.35115942],\n",
       "       [0.6187291 , 0.6588629 , 0.06918239, 0.13827695, 1.        ,\n",
       "        0.10144927, 0.4166992 ],\n",
       "       [0.7658863 , 0.16053511, 0.00377358, 0.2807271 , 0.        ,\n",
       "        0.08695652, 0.46736518],\n",
       "       [0.04013378, 0.72240806, 0.08176101, 0.08079531, 0.1       ,\n",
       "        0.2753623 , 0.36917174],\n",
       "       [0.7591973 , 0.24414715, 1.        , 1.        , 0.        ,\n",
       "        0.10144927, 0.48929328],\n",
       "       [0.48494983, 0.29431438, 0.08176101, 0.26267004, 0.2       ,\n",
       "        0.20289855, 0.30865285],\n",
       "       [0.02006689, 0.07023411, 0.7484277 , 0.01418482, 0.        ,\n",
       "        0.42028984, 0.4728682 ],\n",
       "       [0.4949833 , 0.8160535 , 0.        , 0.31383172, 0.        ,\n",
       "        0.01449275, 0.7172627 ],\n",
       "       [0.21070234, 0.08026756, 0.        , 0.06023033, 0.        ,\n",
       "        0.07246377, 0.53349316],\n",
       "       [0.6020067 , 0.11371238, 0.7484277 , 0.09714699, 0.5       ,\n",
       "        0.5652174 , 0.378019  ],\n",
       "       [0.5585284 , 0.17391305, 0.05660377, 0.08651339, 0.5       ,\n",
       "        0.08695652, 0.59388167],\n",
       "       [0.5451505 , 0.66555184, 0.8742138 , 0.24260664, 0.        ,\n",
       "        0.71014494, 0.5170478 ],\n",
       "       [0.9832776 , 0.6555184 , 0.06918239, 0.13827695, 1.        ,\n",
       "        0.20289855, 0.57862514],\n",
       "       [0.5250836 , 0.6020067 , 0.7484277 , 0.8364833 , 0.1       ,\n",
       "        0.10144927, 0.5077774 ],\n",
       "       [0.8026756 , 0.        , 0.06918239, 0.02521969, 0.        ,\n",
       "        0.71014494, 0.5771088 ],\n",
       "       [0.05685619, 0.7424749 , 0.7484277 , 0.445247  , 0.        ,\n",
       "        0.2753623 , 0.29872918],\n",
       "       [0.5852843 , 0.13377926, 0.09433962, 0.13827695, 0.5       ,\n",
       "        0.11594203, 0.5552041 ],\n",
       "       [0.9397993 , 0.7993311 , 0.09433962, 0.297781  , 0.5       ,\n",
       "        0.11594203, 0.55930483],\n",
       "       [0.77257526, 0.819398  , 0.6226415 , 0.94883835, 0.        ,\n",
       "        0.2753623 , 0.47030142],\n",
       "       [0.6956522 , 0.44147158, 0.00251572, 0.08651339, 0.1       ,\n",
       "        0.71014494, 0.4713665 ],\n",
       "       [0.22073579, 0.71571904, 0.05660377, 0.2807271 , 0.1       ,\n",
       "        0.1594203 , 0.31269568],\n",
       "       [0.9665552 , 0.80936456, 0.7484277 , 0.24260664, 0.        ,\n",
       "        0.71014494, 0.717741  ],\n",
       "       [0.9632107 , 0.19063546, 0.06918239, 0.54656714, 0.        ,\n",
       "        0.05797102, 0.3192574 ],\n",
       "       [0.93311036, 0.93645483, 0.06918239, 0.31383172, 0.5       ,\n",
       "        0.05797102, 0.5836474 ],\n",
       "       [0.6688963 , 0.24414715, 0.05660377, 0.31383172, 0.        ,\n",
       "        0.10144927, 0.32484627],\n",
       "       [0.02006689, 0.67558527, 0.8742138 , 0.1703784 , 0.1       ,\n",
       "        0.20289855, 0.38220283],\n",
       "       [0.8528428 , 0.9632107 , 0.00377358, 0.04167168, 0.        ,\n",
       "        0.71014494, 0.38451543],\n",
       "       [0.9799331 , 0.2173913 , 0.8742138 , 0.77428675, 0.        ,\n",
       "        0.13043478, 0.6785493 ],\n",
       "       [0.30769232, 0.8929766 , 0.08176101, 0.02692508, 0.2       ,\n",
       "        0.71014494, 0.7915142 ],\n",
       "       [0.458194  , 0.19063546, 0.06918239, 0.02853015, 0.        ,\n",
       "        0.5652174 , 0.7621797 ],\n",
       "       [0.36120403, 0.13377926, 0.00251572, 0.01097468, 1.        ,\n",
       "        0.20289855, 0.629462  ],\n",
       "       [0.96989965, 0.8896321 , 0.09433962, 0.07457566, 0.        ,\n",
       "        0.71014494, 0.5806126 ],\n",
       "       [0.7826087 , 0.32107022, 0.8742138 , 0.31383172, 0.        ,\n",
       "        0.42028984, 0.51436085],\n",
       "       [0.2374582 , 0.9431438 , 0.09433962, 0.22154006, 0.1       ,\n",
       "        0.1594203 , 0.3541638 ],\n",
       "       [0.77257526, 0.09030101, 0.6226415 , 0.09714699, 1.        ,\n",
       "        0.2753623 , 0.76979375],\n",
       "       [0.8896321 , 0.5986622 , 0.00251572, 0.22154006, 0.        ,\n",
       "        0.04347826, 0.72613657],\n",
       "       [0.5852843 , 0.01672241, 0.00377358, 0.09203082, 0.1       ,\n",
       "        0.10144927, 0.34035182],\n",
       "       [0.9230769 , 0.9264214 , 0.08176101, 1.        , 0.1       ,\n",
       "        0.11014493, 0.29256824],\n",
       "       [0.7792642 , 0.9665552 , 0.        , 0.1703784 , 0.        ,\n",
       "        0.10144927, 0.35909453],\n",
       "       [0.13712375, 0.55518395, 0.06918239, 0.24260664, 0.        ,\n",
       "        0.13043478, 0.85349673],\n",
       "       [0.32441473, 0.69899666, 0.00377358, 0.31383172, 0.        ,\n",
       "        0.01449275, 0.7121049 ],\n",
       "       [0.13712375, 0.5719063 , 0.        , 0.19746399, 0.1       ,\n",
       "        0.07246377, 0.4775066 ],\n",
       "       [0.34448162, 0.909699  , 0.        , 0.1703784 , 0.        ,\n",
       "        0.08695652, 0.5156973 ],\n",
       "       [0.82608694, 0.01003344, 0.05660377, 0.7060712 , 0.1       ,\n",
       "        0.        , 0.3505347 ],\n",
       "       [0.28093645, 0.5652174 , 0.06918239, 0.26267004, 0.        ,\n",
       "        0.10144927, 0.34048897],\n",
       "       [0.17391305, 0.3645485 , 0.08176101, 0.01420539, 0.2       ,\n",
       "        0.5652174 , 0.62690854],\n",
       "       [0.458194  , 0.2006689 , 0.05660377, 0.31383172, 0.1       ,\n",
       "        0.01449275, 0.3797767 ],\n",
       "       [0.2742475 , 0.70234114, 0.7484277 , 0.06023033, 1.        ,\n",
       "        0.71014494, 0.777892  ],\n",
       "       [0.10367893, 0.91973245, 0.09433962, 0.94883835, 0.1       ,\n",
       "        0.        , 0.7111664 ],\n",
       "       [0.27759197, 0.8929766 , 0.00251572, 0.0677541 , 0.2       ,\n",
       "        0.71014494, 0.30887273],\n",
       "       [0.15384616, 0.01003344, 0.09433962, 0.02853015, 1.        ,\n",
       "        0.71014494, 0.7117387 ],\n",
       "       [0.458194  , 0.05685619, 0.        , 0.06023033, 0.        ,\n",
       "        0.10144927, 0.7124694 ],\n",
       "       [0.28093645, 0.5652174 , 0.06918239, 0.445247  , 0.        ,\n",
       "        0.10144927, 0.47769156],\n",
       "       [0.8762542 , 0.9230769 , 0.6226415 , 0.31383172, 1.        ,\n",
       "        0.71014494, 0.33952078],\n",
       "       [0.93645483, 0.16722408, 0.08176101, 0.19746399, 0.1       ,\n",
       "        0.2753623 , 0.3265205 ]], dtype=float32)"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_array = next(iter(train_loader))[0].numpy()\n",
    "train_dataset_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "db94f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters \n",
    "input_size = list(X_train.shape)[1]   \n",
    "output_size = list(y_train.shape)[1]  \n",
    "\n",
    "\n",
    "\n",
    "# Define neural network \n",
    "class Network(nn.Module): \n",
    "    def __init__(self, input_size, output_size, init_form=\"normal\"): \n",
    "        super().__init__() \n",
    "        self.conv_stack = nn.Sequential(\n",
    "        nn.Linear(input_size, 300), \n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(300, 100),\n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(100, 100),\n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.2))\n",
    "        \n",
    "        self.conv_stack1 = nn.Sequential(\n",
    "        nn.Linear(100, 50), \n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(50, 30),\n",
    "        nn.Tanh(), \n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(30, 1))\n",
    "                \n",
    "        self.conv_stack2 = nn.Sequential(\n",
    "        nn.Linear(100, 50), \n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(50, 30),\n",
    "        nn.Tanh(), \n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(30, 1))\n",
    "        \n",
    "        self.conv_stack3 = nn.Sequential(\n",
    "        nn.Linear(100, 50), \n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(50, 30),\n",
    "        nn.Tanh(), \n",
    "        nn.Dropout(p=0.2),\n",
    "        nn.Linear(30, 1))\n",
    "            \n",
    "        \n",
    "        self.init_form = init_form\n",
    "        if self.init_form is not None:\n",
    "            self.init()\n",
    "\n",
    "    def forward(self, x): \n",
    "        s = self.conv_stack(x)\n",
    "        out1 = self.conv_stack1(s)\n",
    "        out2 = self.conv_stack2(s)\n",
    "        out3 = self.conv_stack3(s)\n",
    "        return out1, out2, out3\n",
    "    \n",
    "    \n",
    "        # xavier weight initialization\n",
    "    def init(self):\n",
    "        sigmoid_gain = torch.nn.init.calculate_gain(\"tanh\")\n",
    "        for child in self.conv_stack.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                if self.init_form == \"normal\":\n",
    "                    torch.nn.init.xavier_normal_(child.weight,\n",
    "                                                 gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                elif self.init_form == \"uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(child.weight,\n",
    "                                                  gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                else:\n",
    "                    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "a50d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_epoch(model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                train_loader):\n",
    "    loss_history = []\n",
    "    for batch in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        x_train, y_train = batch # parse data\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "        y_pred = torch.cat(model(x_train),1) # get predictions\n",
    "        loss = criterion(y_pred, y_train) # compute loss\n",
    "        loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "8a6c7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,\n",
    "             criterion,\n",
    "             val_loader):\n",
    "    cumloss = 0\n",
    "    loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_train, y_train = batch # parse data\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "            y_pred = torch.cat(model(x_train),1)# get predictions\n",
    "            loss = criterion(y_pred, y_train) # compute loss\n",
    "            loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
    "            cumloss += loss\n",
    "    return cumloss / len(val_loader), loss_history # mean loss and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "f3fed850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, optimizer, model_name=None, n_epochs=5):\n",
    "  \n",
    "    criterion = nn.MSELoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history['model_name'] = model_name\n",
    "    train_history['loss_on_train'] = []\n",
    "    train_history['loss_on_test'] = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        loss_on_train = train_epoch(model,\n",
    "                                    optimizer,\n",
    "                                    criterion,\n",
    "                                    train_loader)\n",
    "        _, loss_on_test = validate(model,\n",
    "                                   criterion,\n",
    "                                   validate_loader)\n",
    "        train_history['loss_on_train'].append(np.mean(loss_on_train))\n",
    "        train_history['loss_on_test'].append(np.mean(loss_on_test))\n",
    "        scheduler.step()\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "a2e8bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(scalars, weight):  \n",
    "    last = scalars[0]  \n",
    "    smoothed = []\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  \n",
    "        smoothed.append(smoothed_val)                        \n",
    "        last = smoothed_val                                 \n",
    "\n",
    "    return smoothed\n",
    "\n",
    "\n",
    "def plot_history(history, n_epochs=5, smooth_val=0.9):\n",
    "    fig, ax =  plt.subplots(3, 1, figsize=(12, 14))\n",
    "    for stage_idx, (stage_lbl, stage_title) in enumerate(\n",
    "        zip(['loss_on_train', 'loss_on_test'],\n",
    "            ['train loss', 'test loss'])):\n",
    "        # plot history on each learning step\n",
    "        epoch_len = len(history[stage_lbl])//n_epochs\n",
    "        full_stage_len = len(history[stage_lbl])\n",
    "        ax[stage_idx].plot(exponential_smoothing(history[stage_lbl], smooth_val),\n",
    "                           label='smoothed',\n",
    "                           color='m')\n",
    "        ax[stage_idx].plot(history[stage_lbl],\n",
    "                           label='raw',\n",
    "                           alpha=0.2,\n",
    "                           color='c')\n",
    "        ax[stage_idx].set_title(stage_title)\n",
    "        ax[stage_idx].set_xlabel('epochs')\n",
    "        ax[stage_idx].set_ylabel('loss')\n",
    "        epochs_ticks_positions = np.arange(stop=full_stage_len+1,\n",
    "                                           step=epoch_len)\n",
    "        ax[stage_idx].set_xticks(epochs_ticks_positions)\n",
    "        ax[stage_idx].set_xticklabels(np.arange(n_epochs+1))\n",
    "        ax[stage_idx].legend()\n",
    "\n",
    "        # plot mean train and test loss combined\n",
    "        mean_loss_on_epoch = [np.mean(history[stage_lbl][i:i+epoch_len]) \\\n",
    "                              for i in range(0, full_stage_len, epoch_len)]\n",
    "        std_loss_on_epoch = [np.std(history[stage_lbl][i:i+epoch_len]) \\\n",
    "                              for i in range(0, full_stage_len, epoch_len)]\n",
    "\n",
    "        ax[2].set_title('\\nAverage loss per epoch')\n",
    "        ax[2].errorbar(np.arange(n_epochs) + stage_idx / 30.,\n",
    "                       mean_loss_on_epoch,\n",
    "                       yerr=std_loss_on_epoch,\n",
    "                       capsize=5,\n",
    "                       fmt=\"X--\",\n",
    "                       label=stage_title)\n",
    "        ax[2].set_xticks(np.arange(5))\n",
    "        ax[2].set_xticklabels(np.arange(5))\n",
    "        ax[2].set_xlabel('epochs')\n",
    "        ax[2].set_ylabel('loss')\n",
    "        ax[2].legend()\n",
    "\n",
    "    fig.suptitle(history['model_name'], fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "f030e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:49<00:00,  9.12it/s]\n"
     ]
    }
   ],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "model = Network(input_size,output_size).to(device) \n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "lambda1 = lambda epoch: 0.99 ** epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1, last_epoch = -1)\n",
    "\n",
    "n_epochs = 1000\n",
    "history = train_model(model, optimizer, model_name='model', n_epochs=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "6971052a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x1008 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history, n_epochs=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "fc83567c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x20683657580>"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,n_epochs+1), (history['loss_on_train']), label='train')\n",
    "plt.plot(range(1,n_epochs+1), (history['loss_on_test']), label='test')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "6986b941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv_stack): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=300, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=300, out_features=100, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (7): Tanh()\n",
       "    (8): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (conv_stack1): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       "  (conv_stack2): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       "  (conv_stack3): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Dropout(p=0.2, inplace=False)\n",
       "    (6): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "c7685f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc for Lsat= 0.07781869022927423 \n",
      "acc for Psat= 0.11027953170231342 \n",
      "acc for optim= 0.16012041378721406\n"
     ]
    }
   ],
   "source": [
    "def relative_root_mean_squared_error(true, pred):\n",
    "    num = np.sum(np.square(true - pred))\n",
    "    den = np.sum(np.square(true))\n",
    "    squared_error = num/den\n",
    "    rrmse_loss = np.sqrt(squared_error)\n",
    "    return rrmse_loss\n",
    "\n",
    "\n",
    "def test(model, val_loader):\n",
    "    cumloss1 = 0\n",
    "    cumloss2 = 0\n",
    "    cumloss3 = 0\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    l3 = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_train, y_train = batch # parse data\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "            y_pred = torch.cat(model(x_train),1) # get predictions\n",
    "            y_pred = scaler2.inverse_transform(y_pred.cpu().detach().numpy())\n",
    "            y_train = scaler2.inverse_transform(y_train.cpu().detach().numpy())\n",
    "            loss1 = relative_root_mean_squared_error(np.exp(y_pred[0][0]), \n",
    "                                                    np.exp(y_train[0][0])) # compute loss\n",
    "            loss2 = relative_root_mean_squared_error(np.exp(y_pred[0][1]), \n",
    "                                                    np.exp(y_train[0][1]))\n",
    "            loss3 = relative_root_mean_squared_error((y_pred[0][2]), \n",
    "                                                    (y_train[0][2]))\n",
    "            cumloss1 += loss1\n",
    "            cumloss2 += loss2\n",
    "            cumloss3 += loss3\n",
    "            l1.append(loss1)\n",
    "            l2.append(loss2)\n",
    "            l3.append(loss3)\n",
    "    return cumloss1 / len(val_loader), cumloss2 / len(val_loader), cumloss3 / len(val_loader), l1, l2, l3\n",
    "\n",
    "\n",
    "l = test(model, test_loader)\n",
    "print('acc for Lsat=', l[0],'\\n' 'acc for Psat=', l[1], '\\n' 'acc for optim=', l[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "39faae6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Lsat error')"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEICAYAAABYoZ8gAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAATbUlEQVR4nO3dfbCmdX3f8fdnHwiOaMTugWyWXdcAk2htXDNHQsC0PpEBakValdAUaGq6ZBIyoTGJtJ1pybSdcaYSTDMVWZURE6sYHwohJJGAxCgEPTQrBcGgDoaHze5BpYCxyO5++8d9bTnunsO5djnXfZ89v/dr5pr7vn739fA9v9n53NdeD787VYUkqR2rJl2AJGm8DH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfK0qS+5O8fgm39y+TfG6ptictBwa/NEZJ1szTtvogt3FQy0v7M/jVhCTrklyf5NEk30ryF0lWdZ9dkuRrSR5P8uUkZ3ftLwHeC/xUkieSPLrAtn8wyQeS7EjyUJL/vC+cu/8xfD7J5Um+BVya5INJrkhyQ5LvAK9J8pIkt3T13Z3kjXO2f8Dyw/aWVroDjj6kFertwIPAVDd/MrBvvJKvAT8N/C3wFuD3k5xQVfck+UXgF6rqVc+w7auBncAJwHOB64EHgCu7z38S+ChwDLAWuAL458CZwBu6df4KuAr4GeBVwLVJpqvqK9025i5/xCH2gQR4xK92PAWsB15UVU9V1V9UN1BVVf1BVT1cVXur6hrgPuCkPhtNcixwBnBxVX2nqnYBlwM/O2exh6vqd6tqd1V9t2u7tqo+X1V7gS3AUcA7q+p7VXUzoy+Pc+ds4/8vX1X/95B7QcLgVzv+K/BV4NNJvp7kkn0fJDk/yfbuNMujwMuAdT23+yJGR/E75qx/JaOj+30emGe9uW0/DDzQfQns8w1gwyLbkA6Jp3rUhKp6nNHpnrcn+fvAZ5J8kdGXwfuA1wG3VdWeJNuB7Ft1kU0/ADwJrKuq3QvtfpG2h4GNSVbNCf9NwF8vsg3pkHjEr5VobZIj50xrkrwhyQlJAjwG7Omm5zIK1VmAJD/P6Ih/n53AcUnmPa9eVTuATwOXJXl+klVJjk/yjw6i3tuB7wC/mWRtklcD/4TRdQFpyRn8WoluAL47Z7oUOBH4M+AJ4DbgPVV1S1V9Gbisa9sJ/APg83O2dTNwN/C3SR5ZYH/nM7rg+mXg28DHGV1P6KWqvge8kdG1gkeA9wDnV9W9fbchHYz4QyyS1BaP+CWpMQa/JDXG4Jekxhj8ktSYw+I+/nXr1tXmzZsnXYYkHVbuuOOOR6pqav/2wyL4N2/ezMzMzKTLkKTDSpJvzNc++KmeJKuT/FWS67v5Fya5Mcl93evRQ9cgSXraOM7x/ypwz5z5S4CbqupE4KZuXpI0JoMGf5LjgH8MvH9O81mMhrGle33TkDVIkr7f0Ef87wZ+E5g76uCx3fgm+8Y5OWae9UiyNclMkpnZ2dmBy5SkdgwW/EneAOyqqjsOZf2q2lZV01U1PTV1wEVpSdIhGvKunlOBNyY5EzgSeH6S3wd2JllfVTuSrAd2DViDJGk/gx3xV9W/rarjqmozo18jurmq/gVwHXBBt9gFwLVD1SBJOtAkntx9J3BakvuA07p5SdKYjOUBrqq6Bbile/9NRr92JEmagBU/Vs+GjZtIsmTTho2bJv0nSdKzclgM2fBsPPzgA5xz5a1Ltr1rLjxlybYlSZOw4o/4JUnfz+CXpMYY/JLUGIP/YK1as6QXi71gLGncVvzF3SW3d/eSXiwGLxhLGi+P+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYMFvxJjkzyhSRfSnJ3kt/q2i9N8lCS7d105lA1SJIONOQgbU8Cr62qJ5KsBT6X5I+7zy6vqncNuG9J0gIGC/6qKuCJbnZtN9VQ+5Mk9TPoOf4kq5NsB3YBN1bV7d1HFyW5M8lVSY5eYN2tSWaSzMzOzg5ZpiQ1ZdDgr6o9VbUFOA44KcnLgCuA44EtwA7gsgXW3VZV01U1PTU1NWSZktSUsdzVU1WPArcAp1fVzu4LYS/wPuCkcdQgSRoZ8q6eqSQv6N4/B3g9cG+S9XMWOxu4a6gaJEkHGvKunvXA1UlWM/qC+VhVXZ/k95JsYXSh937gwgFrkCTtZ8i7eu4EXjFP+3lD7VOStDif3JWkxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgl6TGDPmbu0cm+UKSLyW5O8lvde0vTHJjkvu616OHqkGSdKAhj/ifBF5bVS8HtgCnJzkZuAS4qapOBG7q5iVJYzJY8NfIE93s2m4q4Czg6q79auBNQ9UgSTrQoOf4k6xOsh3YBdxYVbcDx1bVDoDu9Zgha5Akfb9Bg7+q9lTVFuA44KQkL+u7bpKtSWaSzMzOzg5WoyS1Zix39VTVo8AtwOnAziTrAbrXXQuss62qpqtqempqahxlSlIThryrZyrJC7r3zwFeD9wLXAdc0C12AXDtUDVIkg60ZsBtrweuTrKa0RfMx6rq+iS3AR9L8jbgb4C3DFiDJGk/gwV/Vd0JvGKe9m8Crxtqv5KkZ+aTu5LUGINfkhpj8EtSYwx+SWqMwS9JjTH4l4NVa0iyZNOGjZsm/RdJWsaGvI9ffe3dzTlX3rpkm7vmwlOWbFuSVh6P+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYM+WPrG5N8Jsk9Se5O8qtd+6VJHkqyvZvOHKoGSdKBhhykbTfw9qr6X0meB9yR5Mbus8ur6l0D7luStIAhf2x9B7Cje/94knuADUPtT5LUz1jO8SfZDLwCuL1ruijJnUmuSnL0AutsTTKTZGZ2dnYcZUpSEwYP/iRHAZ8ALq6qx4ArgOOBLYz+R3DZfOtV1baqmq6q6ampqaHLlKRmDBr8SdYyCv0PV9UnAapqZ1Xtqaq9wPuAk4asQZL0/Ya8qyfAB4B7quq357Svn7PY2cBdQ9UgSTrQkHf1nAqcB/zvJNu7tn8HnJtkC1DA/cCFA9YgSdrPkHf1fA7IPB/dMNQ+JUmL88ldSWqMwS9JjTH4JakxBr8kNcbgl6TGGPyS1JhewZ/k1D5tkqTlr+8R/+/2bJMkLXPP+ABXkp8CTgGmkvzanI+eD6wesjBJ0jAWe3L3COCobrnnzWl/DHjzUEVJkobzjMFfVX8O/HmSD1bVN8ZUkyRpQH3H6vmBJNuAzXPXqarXDlGUJGk4fYP/D4D3Au8H9gxXjiRpaH2Df3dVXTFoJZKkseh7O+cfJvmlJOuTvHDfNGhlkqRB9D3iv6B7/Y05bQX8yNKWI0kaWq/gr6oXD12IJGk8egV/kvPna6+qDz3DOhuBDwE/BOwFtlXV73SniK5hdIfQ/cBbq+rbB1e2JOlQ9T3H/8o5008DlwJvXGSd3cDbq+olwMnALyd5KXAJcFNVnQjc1M1Lksak76meX5k7n+QHgd9bZJ0dwI7u/eNJ7gE2AGcBr+4Wuxq4BXjHwRQtSTp0hzos898BJ/ZdOMlm4BXA7cCx3ZfCvi+HYw6xBknSIeh7jv8PGd3FA6PB2V4CfKznukcBnwAurqrHkvQqLMlWYCvApk2beq0jSVpc39s53zXn/W7gG1X14GIrJVnLKPQ/XFWf7Jp3JllfVTuSrAd2zbduVW0DtgFMT0/XfMtIkg5er1M93WBt9zIaofNo4HuLrZPRof0HgHuq6rfnfHQdTz8XcAFw7cEULEl6dvr+AtdbgS8AbwHeCtyeZLFhmU8FzgNem2R7N50JvBM4Lcl9wGndvCRpTPqe6vn3wCurahdAkingz4CPL7RCVX0OWOiE/usOpkhJ0tLpe1fPqn2h3/nmQawrSVpG+h7x/0mSPwU+0s2fA9wwTEmSpCEt9pu7JzC67/43kvxT4FWMTt/cBnx4DPVJkpbYYqdr3g08DlBVn6yqX6uqf8PoaP/dw5YmSRrCYsG/uaru3L+xqmYYDbImSTrMLBb8Rz7DZ89ZykIkSeOxWPB/Mcm/3r8xyduAO4YpSZI0pMXu6rkY+FSSn+PpoJ8GjgDOHrAuSdJAnjH4q2oncEqS1wAv65r/qKpuHrwySdIg+o7H/xngMwPXIkkaA5++laTGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDVmsOBPclWSXUnumtN2aZKH9vsNXknSGA15xP9B4PR52i+vqi3d5K94SdKYDRb8VfVZ4FtDbV+SdGgmcY7/oiR3dqeCjl5ooSRbk8wkmZmdnR1nfZK0oo07+K8Ajge2ADuAyxZasKq2VdV0VU1PTU2NqTxJWvnGGvxVtbOq9lTVXuB9wEnj3L8kaczBn2T9nNmzgbsWWlaSNIxe4/EfiiQfAV4NrEvyIPAfgVcn2QIUcD9w4VD7lyTNb7Dgr6pz52n+wFD7kyT145O7ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSYwx+SWqMwS9JjTH4JakxBr8kNcbgX4lWrSHJkk0bNm6a9F8kaQkN9kMsmqC9uznnyluXbHPXXHjKkm1L0uR5xC9JjRks+JNclWRXkrvmtL0wyY1J7utejx5q/5Kk+Q15xP9B4PT92i4BbqqqE4GbunlJ0hgNFvxV9VngW/s1nwVc3b2/GnjTUPuXJM1v3Of4j62qHQDd6zELLZhka5KZJDOzs7NjK1DzWOK7hJKw5ogjvfNImpBle1dPVW0DtgFMT0/XhMtp2xLfJQSjO4W880iajHEf8e9Msh6ge9015v1LUvPGHfzXARd07y8Arh3z/iWpeUPezvkR4DbgR5M8mORtwDuB05LcB5zWzUuSxmiwc/xVde4CH71uqH1Kkhbnk7uS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/JDXG4Jekxhj8ktQYg1+SGmPwS1JjDH5JaozBL0mNMfglqTEGvyQ1xuCXpMYY/JLUmMF+geuZJLkfeBzYA+yuqulJ1CFJLZpI8HdeU1WPTHD/ktQkT/VIUmMmFfwFfDrJHUm2zrdAkq1JZpLMzM7Ojrk8SVq5JhX8p1bVTwBnAL+c5B/uv0BVbauq6aqanpqaGn+FkrRCTST4q+rh7nUX8CngpEnUIUktGnvwJ3lukuftew/8DHDXuOuQpFZN4q6eY4FPJdm3//9RVX8ygTokqUljD/6q+jrw8nHvV5I0Msn7+KWls2oN3f8il8TqtT/AnqeeXLLt/fBxG3nogb9Zsu1Jz4bBr5Vh727OufLWJdvcNReesuTbk5YLH+CSpMYY/JLUGINfkhpj8EuHqQ0bN5FkyaY1Rxy5pNvbsHHTpLtIC/DirnSYevjBB7ygrUPiEb8kNcbgl6TGGPyS1BiDX5IaY/BLUmMMfklqjMEvSY0x+CWpMQa/NA7dsNFLOenZW+5PPw/1BLRP7krjsMTDRoNPxi6F5f70875tLjWP+CWpMRMJ/iSnJ/lKkq8muWQSNUhSq8Ye/ElWA/8dOAN4KXBukpeOuw5JatUkjvhPAr5aVV+vqu8BHwXOmkAdktSkVNV4d5i8GTi9qn6hmz8P+Mmqumi/5bYCW7vZHwW+coi7XAc8cojrtsI+6sd+Wpx91M+4+ulFVTW1f+Mk7uqZ7z60A759qmobsO1Z7yyZqarpZ7udlcw+6sd+Wpx91M+k+2kSp3oeBDbOmT8OeHgCdUhSkyYR/F8ETkzy4iRHAD8LXDeBOiSpSWM/1VNVu5NcBPwpsBq4qqruHnCXz/p0UQPso37sp8XZR/1MtJ/GfnFXkjRZPrkrSY0x+CWpMSsm+BcbBiIj/637/M4kPzGJOiepRx/9WJLbkjyZ5NcnUeNy0KOffq77N3RnkluTvHwSdU5Sjz46q+uf7UlmkrxqEnVOWt/haZK8Msme7jmn4VXVYT8xukj8NeBHgCOALwEv3W+ZM4E/ZvQcwcnA7ZOuexn20THAK4H/Avz6pGtexv10CnB09/4M/y3N20dH8fQ1xB8H7p103cuxn+YsdzNwA/DmcdS2Uo74+wwDcRbwoRr5S+AFSdaPu9AJWrSPqmpXVX0ReGoSBS4Tffrp1qr6djf7l4yeRWlJnz56orpUA57LPA9pNqDv8DS/AnwC2DWuwlZK8G8AHpgz/2DXdrDLrGSt//19HWw/vY3R/yRb0quPkpyd5F7gj4B/NabalpNF+ynJBuBs4L1jrGvFBH+fYSB6DRWxgrX+9/fVu5+SvIZR8L9j0IqWn77Drnyqqn4MeBPwn4Yuahnq00/vBt5RVXuGL+dpK+UXuPoMA9H6UBGt//199eqnJD8OvB84o6q+OabalouD+rdUVZ9NcnySdVXV0gBuffppGvho91Oa64Azk+yuqv85ZGEr5Yi/zzAQ1wHnd3f3nAz8n6raMe5CJ8ihMvpZtJ+SbAI+CZxXVX89gRonrU8fnZAuzbo76I4AWvuCXLSfqurFVbW5qjYDHwd+aejQhxVyxF8LDAOR5Be7z9/L6Ir5mcBXgb8Dfn5S9U5Cnz5K8kPADPB8YG+SixndhfDYpOoet57/lv4D8PeA93TZtrsaGpGyZx/9M0YHWk8B3wXOmXOxtwk9+2kiHLJBkhqzUk71SJJ6MvglqTEGvyQ1xuCXpMYY/JLUGINfkhpj8EtSY/4fij2I+hn83nMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(l[3])\n",
    "plt.title(\"Lsat error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "fe589d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Power error')"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(l[4])\n",
    "plt.title(\"Power error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4214a0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113    0.000015\n",
       "26     0.000713\n",
       "0      0.001088\n",
       "65     0.001454\n",
       "58     0.001975\n",
       "         ...   \n",
       "106    0.494023\n",
       "39     0.512600\n",
       "107    0.545573\n",
       "61     0.618078\n",
       "95     0.655617\n",
       "Length: 153, dtype: float32"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(l[4]).sort_values()\n",
    "#scaler.inverse_transform(np.array([X_test[103].cpu().detach().numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "c55302e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'optim error')"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(l[5])\n",
    "plt.title(\"optim error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "6404a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import jv\n",
    "\n",
    "X = pd.DataFrame({'k':[3.5], 'lu':[3], 'I':[3000], 'gamma':[26600], 'sgamma':[0.0001], \n",
    "                  'r':[0.000022], 'log0':[100000]})\n",
    "\n",
    "ksi = X['k']**2/(1+X['k']**2/2)/4\n",
    "f = jv(0,ksi)-jv(1,ksi)\n",
    "\n",
    "rho = 1/2/(X['gamma'])*(X['I']/X['r']**2/np.pi/4/np.pi/17000*(X['lu']/100*X['k']*f)**2)**(1/3)\n",
    "X['log0'] = np.log(X['log0']/X['I']/X['gamma']/511000)\n",
    "\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "id": "f47cf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.Tensor(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "fba5bf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.4556587, -7.6786027,  1.0989047]], dtype=float32)"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (torch.cat(model(input1.to(device)),1)).cpu().detach().numpy()\n",
    "a= scaler2.inverse_transform(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "64901883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lsat= 34.962318420410156 Psat= 18864661245.30416 loptim= 1.511669250596506e-10\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame({'k':[3.5], 'lu':[3], 'I':[3000], 'gamma':[26600], 'sgamma':[0.0001], \n",
    "                  'r':[0.000022], 'log0':[100000]})\n",
    "\n",
    "\n",
    "\n",
    "ksi = X['k']**2/(1+X['k']**2/2)/4\n",
    "f = jv(0,ksi)-jv(1,ksi)\n",
    "\n",
    "rho = 1/2/(X['gamma'])*(X['I']/X['r']**2/np.pi/4/np.pi/17000*(X['lu']/100*X['k']*f)**2)**(1/3)\n",
    "X['log0'] = np.log(X['log0']/X['I']/X['gamma']/511000)\n",
    "\n",
    "print('Lsat=', np.exp(a[0][0])*X['lu'][0], 'Psat=', (np.exp(a[0][1])*X['gamma']*511000*X['I'])[0], \n",
    "'loptim=',(((a[0][2])*rho+1)*X['lu']/100/2/X['gamma']/X['gamma']*(1+X['k']*X['k']/2))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "9992987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "57c36cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, SubsetRandomSampler, ConcatDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "id": "0a148458",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "set_random_seed(42)\n",
    "\n",
    "num_epochs=1000\n",
    "batch_size=64\n",
    "k=5\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "a1a8b1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.13187500834465027\n",
      "Loss on test= 0.046548157930374146\n",
      "acc for Lsat= 0.7227935112096736 \n",
      "acc for Psat= 0.6890176486285007 \n",
      "acc for optim= 0.3229730052911661\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.040267255157232285\n",
      "Loss on test= 0.034442465752363205\n",
      "acc for Lsat= 0.6166507102312428 \n",
      "acc for Psat= 0.6286606590981122 \n",
      "acc for optim= 0.22289350462207175\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.03059488907456398\n",
      "Loss on test= 0.028143486008048058\n",
      "acc for Lsat= 0.5199311554965327 \n",
      "acc for Psat= 0.5490122498990204 \n",
      "acc for optim= 0.21572184532443747\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.027531728148460388\n",
      "Loss on test= 0.029264463111758232\n",
      "acc for Lsat= 0.4616388707253777 \n",
      "acc for Psat= 0.5682731403679144 \n",
      "acc for optim= 0.22366897258678542\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.024757105857133865\n",
      "Loss on test= 0.03739073872566223\n",
      "acc for Lsat= 0.45145285546199465 \n",
      "acc for Psat= 1.0895400254375522 \n",
      "acc for optim= 0.2634396503119325\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.030805399641394615\n",
      "Loss on test= 0.032490067183971405\n",
      "acc for Lsat= 0.4423140205931468 \n",
      "acc for Psat= 0.8124653837872577 \n",
      "acc for optim= 0.2817545502622169\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.024298660457134247\n",
      "Loss on test= 0.02592330612242222\n",
      "acc for Lsat= 0.47433234616106407 \n",
      "acc for Psat= 0.5937254084587158 \n",
      "acc for optim= 0.2808301485322996\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.0222943015396595\n",
      "Loss on test= 0.02329332008957863\n",
      "acc for Lsat= 0.45003109919899675 \n",
      "acc for Psat= 0.5641708035079274 \n",
      "acc for optim= 0.20995013144012295\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.023256700485944748\n",
      "Loss on test= 0.022955643013119698\n",
      "acc for Lsat= 0.6336013929404798 \n",
      "acc for Psat= 0.483704303699683 \n",
      "acc for optim= 0.21787932089102438\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.024288032203912735\n",
      "Loss on test= 0.030651673674583435\n",
      "acc for Lsat= 0.42896293469658886 \n",
      "acc for Psat= 1.0257957881385247 \n",
      "acc for optim= 0.21585491992243122\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.02532055415213108\n",
      "Loss on test= 0.021182360127568245\n",
      "acc for Lsat= 0.45029254478744046 \n",
      "acc for Psat= 0.49543520621535536 \n",
      "acc for optim= 0.2102862420989502\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.02090401202440262\n",
      "Loss on test= 0.02434912882745266\n",
      "acc for Lsat= 0.7068601417416309 \n",
      "acc for Psat= 0.44192648587431604 \n",
      "acc for optim= 0.19870495707642089\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.020309139043092728\n",
      "Loss on test= 0.022714251652359962\n",
      "acc for Lsat= 0.5894150629296105 \n",
      "acc for Psat= 0.4614040158440924 \n",
      "acc for optim= 0.20661320341636472\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.019946230575442314\n",
      "Loss on test= 0.019964762032032013\n",
      "acc for Lsat= 0.4341145845372459 \n",
      "acc for Psat= 0.4932377831857713 \n",
      "acc for optim= 0.20357450882018713\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.017934810370206833\n",
      "Loss on test= 0.022095302119851112\n",
      "acc for Lsat= 0.3437167668585345 \n",
      "acc for Psat= 0.6835591723638602 \n",
      "acc for optim= 0.2091980902436113\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.017330292612314224\n",
      "Loss on test= 0.017837533727288246\n",
      "acc for Lsat= 0.4008748638939845 \n",
      "acc for Psat= 0.47051366734085603 \n",
      "acc for optim= 0.21850712116083443\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.017840538173913956\n",
      "Loss on test= 0.01658228598535061\n",
      "acc for Lsat= 0.3823248669657795 \n",
      "acc for Psat= 0.4320524272239828 \n",
      "acc for optim= 0.1990043573203634\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.01626959815621376\n",
      "Loss on test= 0.017361409962177277\n",
      "acc for Lsat= 0.33100080190829506 \n",
      "acc for Psat= 0.4730779582451357 \n",
      "acc for optim= 0.21644080529680293\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.01579379104077816\n",
      "Loss on test= 0.01900215819478035\n",
      "acc for Lsat= 0.33308678697794675 \n",
      "acc for Psat= 0.50724037568062 \n",
      "acc for optim= 0.20865524483417144\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.017951086163520813\n",
      "Loss on test= 0.02854212187230587\n",
      "acc for Lsat= 0.3439239209017823 \n",
      "acc for Psat= 1.067742817551203 \n",
      "acc for optim= 0.22167969065490292\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.02114931493997574\n",
      "Loss on test= 0.01776435412466526\n",
      "acc for Lsat= 0.35123767724153815 \n",
      "acc for Psat= 0.49898073191098014 \n",
      "acc for optim= 0.20478777192889897\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.016505613923072815\n",
      "Loss on test= 0.019235633313655853\n",
      "acc for Lsat= 0.4505749946868536 \n",
      "acc for Psat= 0.39463189346830313 \n",
      "acc for optim= 0.19322135148390548\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.017125315964221954\n",
      "Loss on test= 0.015623703598976135\n",
      "acc for Lsat= 0.28731252837155136 \n",
      "acc for Psat= 0.37649172416460686 \n",
      "acc for optim= 0.19817763312283682\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.01610044203698635\n",
      "Loss on test= 0.017531195655465126\n",
      "acc for Lsat= 0.3239541242700681 \n",
      "acc for Psat= 0.5210972478796946 \n",
      "acc for optim= 0.2040652541351146\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.015362681820988655\n",
      "Loss on test= 0.014156641438603401\n",
      "acc for Lsat= 0.32160616248796436 \n",
      "acc for Psat= 0.385350065997045 \n",
      "acc for optim= 0.20116065573634304\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.014342007227241993\n",
      "Loss on test= 0.01615319401025772\n",
      "acc for Lsat= 0.3866376597632761 \n",
      "acc for Psat= 0.3589735521453998 \n",
      "acc for optim= 0.2034014486622821\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.016346251592040062\n",
      "Loss on test= 0.018020451068878174\n",
      "acc for Lsat= 0.49011806255763735 \n",
      "acc for Psat= 0.3667871247173562 \n",
      "acc for optim= 0.19663565152736961\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.014847186394035816\n",
      "Loss on test= 0.014224019832909107\n",
      "acc for Lsat= 0.3321422617554237 \n",
      "acc for Psat= 0.3566923092504902 \n",
      "acc for optim= 0.21181985588561072\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.013465622439980507\n",
      "Loss on test= 0.016101287677884102\n",
      "acc for Lsat= 0.4538770788024775 \n",
      "acc for Psat= 0.31916396761862714 \n",
      "acc for optim= 0.19543823650198394\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.013979583978652954\n",
      "Loss on test= 0.014155065640807152\n",
      "acc for Lsat= 0.2891784405801445 \n",
      "acc for Psat= 0.3918482494338217 \n",
      "acc for optim= 0.19329420173708656\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.01298839133232832\n",
      "Loss on test= 0.013305953703820705\n",
      "acc for Lsat= 0.27398132764749594 \n",
      "acc for Psat= 0.3625863262894945 \n",
      "acc for optim= 0.19463480577697276\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.01325989980250597\n",
      "Loss on test= 0.014375408180058002\n",
      "acc for Lsat= 0.29732617349592877 \n",
      "acc for Psat= 0.34330796600151503 \n",
      "acc for optim= 0.23343189288938387\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.013783390633761883\n",
      "Loss on test= 0.020345158874988556\n",
      "acc for Lsat= 0.592473307735531 \n",
      "acc for Psat= 0.3508885461768349 \n",
      "acc for optim= 0.20220722490406334\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.0163545161485672\n",
      "Loss on test= 0.013872803188860416\n",
      "acc for Lsat= 0.28612082846778575 \n",
      "acc for Psat= 0.3397608439884622 \n",
      "acc for optim= 0.20098545151480213\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.012447181157767773\n",
      "Loss on test= 0.013606543652713299\n",
      "acc for Lsat= 0.323824165394858 \n",
      "acc for Psat= 0.3614332380633969 \n",
      "acc for optim= 0.19462843219612222\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.012966942973434925\n",
      "Loss on test= 0.014569984748959541\n",
      "acc for Lsat= 0.2846156929787554 \n",
      "acc for Psat= 0.44684206334016185 \n",
      "acc for optim= 0.19821558647453175\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.011683931574225426\n",
      "Loss on test= 0.017337875440716743\n",
      "acc for Lsat= 0.40247454953792156 \n",
      "acc for Psat= 0.3298179738254088 \n",
      "acc for optim= 0.2039055096741277\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.01282338798046112\n",
      "Loss on test= 0.01331418752670288\n",
      "acc for Lsat= 0.25934357038077893 \n",
      "acc for Psat= 0.3070832062924861 \n",
      "acc for optim= 0.2013894157438371\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.01198827289044857\n",
      "Loss on test= 0.013688137754797935\n",
      "acc for Lsat= 0.3121878207027607 \n",
      "acc for Psat= 0.4315016799392637 \n",
      "acc for optim= 0.19219331759119743\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.011503012850880623\n",
      "Loss on test= 0.01309843361377716\n",
      "acc for Lsat= 0.35193639066467275 \n",
      "acc for Psat= 0.32646888078449937 \n",
      "acc for optim= 0.19832438054956403\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.011462774127721786\n",
      "Loss on test= 0.012939631007611752\n",
      "acc for Lsat= 0.264453045579559 \n",
      "acc for Psat= 0.30114186495756273 \n",
      "acc for optim= 0.192487352779784\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.01168641448020935\n",
      "Loss on test= 0.016557922586798668\n",
      "acc for Lsat= 0.3486520118960828 \n",
      "acc for Psat= 0.3482540887635445 \n",
      "acc for optim= 0.19786401798397105\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.015978440642356873\n",
      "Loss on test= 0.015050015412271023\n",
      "acc for Lsat= 0.33725103792757344 \n",
      "acc for Psat= 0.42353117537959556 \n",
      "acc for optim= 0.195427065190466\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.013099901378154755\n",
      "Loss on test= 0.01488993875682354\n",
      "acc for Lsat= 0.33575314494903336 \n",
      "acc for Psat= 0.32834876664536317 \n",
      "acc for optim= 0.19403827388391098\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.013614580035209656\n",
      "Loss on test= 0.01396302692592144\n",
      "acc for Lsat= 0.3741486658698585 \n",
      "acc for Psat= 0.32798043445714553 \n",
      "acc for optim= 0.19319484501716405\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.011902792379260063\n",
      "Loss on test= 0.01176685281097889\n",
      "acc for Lsat= 0.2614481658586988 \n",
      "acc for Psat= 0.32678610402327335 \n",
      "acc for optim= 0.1926616748333069\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.011504684574902058\n",
      "Loss on test= 0.012220430187880993\n",
      "acc for Lsat= 0.27392411703533937 \n",
      "acc for Psat= 0.3499468625085877 \n",
      "acc for optim= 0.1986728317972624\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.011354489251971245\n",
      "Loss on test= 0.011634200811386108\n",
      "acc for Lsat= 0.23065046192104852 \n",
      "acc for Psat= 0.33173431836781436 \n",
      "acc for optim= 0.18511430616624133\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.010470399633049965\n",
      "Loss on test= 0.0113599868491292\n",
      "acc for Lsat= 0.251540206068913 \n",
      "acc for Psat= 0.29148737056539625 \n",
      "acc for optim= 0.20382596042320195\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.010986216366291046\n",
      "Loss on test= 0.012718280777335167\n",
      "acc for Lsat= 0.3369987265119085 \n",
      "acc for Psat= 0.28697601312973736 \n",
      "acc for optim= 0.1918720473483831\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.011052044108510017\n",
      "Loss on test= 0.011634615249931812\n",
      "acc for Lsat= 0.3012431064270414 \n",
      "acc for Psat= 0.3356371539759881 \n",
      "acc for optim= 0.1905043292905158\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.010756129398941994\n",
      "Loss on test= 0.010950865224003792\n",
      "acc for Lsat= 0.2350865026424471 \n",
      "acc for Psat= 0.3059911832106529 \n",
      "acc for optim= 0.19699645372351907\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.010270306840538979\n",
      "Loss on test= 0.011109861545264721\n",
      "acc for Lsat= 0.2347008160208581 \n",
      "acc for Psat= 0.3163667551940307 \n",
      "acc for optim= 0.18966249992277046\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.013069498352706432\n",
      "Loss on test= 0.011991147883236408\n",
      "acc for Lsat= 0.27303086320762754 \n",
      "acc for Psat= 0.29388962010748026 \n",
      "acc for optim= 0.20705593048869708\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.010712572373449802\n",
      "Loss on test= 0.012378284707665443\n",
      "acc for Lsat= 0.2690872362689363 \n",
      "acc for Psat= 0.2704493721886004 \n",
      "acc for optim= 0.21893840731335346\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.009962429292500019\n",
      "Loss on test= 0.010894232429564\n",
      "acc for Lsat= 0.2530903722403846 \n",
      "acc for Psat= 0.322291402895954 \n",
      "acc for optim= 0.1866971938042581\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.009920611046254635\n",
      "Loss on test= 0.012947086244821548\n",
      "acc for Lsat= 0.25813598112626857 \n",
      "acc for Psat= 0.4377591961513838 \n",
      "acc for optim= 0.1970878661077729\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.01401702780276537\n",
      "Loss on test= 0.013263382017612457\n",
      "acc for Lsat= 0.2583435876429993 \n",
      "acc for Psat= 0.3190500411746993 \n",
      "acc for optim= 0.1920497559409371\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.011190015822649002\n",
      "Loss on test= 0.011170607060194016\n",
      "acc for Lsat= 0.2567774334915455 \n",
      "acc for Psat= 0.29946720878876076 \n",
      "acc for optim= 0.19299442227853492\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.010264983400702477\n",
      "Loss on test= 0.011644137091934681\n",
      "acc for Lsat= 0.26269373005011776 \n",
      "acc for Psat= 0.2739300109293373 \n",
      "acc for optim= 0.20714223021565037\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.009103752672672272\n",
      "Loss on test= 0.011463158763945103\n",
      "acc for Lsat= 0.26896347060559134 \n",
      "acc for Psat= 0.2775458000783549 \n",
      "acc for optim= 0.18433194367146333\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.009445506148040295\n",
      "Loss on test= 0.010932203382253647\n",
      "acc for Lsat= 0.22253686946961784 \n",
      "acc for Psat= 0.27561885870962843 \n",
      "acc for optim= 0.21008675794258377\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.009103314951062202\n",
      "Loss on test= 0.012178588658571243\n",
      "acc for Lsat= 0.2952189872972667 \n",
      "acc for Psat= 0.28238350870736617 \n",
      "acc for optim= 0.18856203181134273\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.010025182738900185\n",
      "Loss on test= 0.011041006073355675\n",
      "acc for Lsat= 0.24081515536078665 \n",
      "acc for Psat= 0.3383059124885028 \n",
      "acc for optim= 0.19582371082821037\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.009360005147755146\n",
      "Loss on test= 0.009775815531611443\n",
      "acc for Lsat= 0.23093926535325782 \n",
      "acc for Psat= 0.2926453598931462 \n",
      "acc for optim= 0.18963488493249553\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.008881228975951672\n",
      "Loss on test= 0.009957603178918362\n",
      "acc for Lsat= 0.21976681796940745 \n",
      "acc for Psat= 0.33864877711615116 \n",
      "acc for optim= 0.20679371283469783\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.009503276087343693\n",
      "Loss on test= 0.011223827488720417\n",
      "acc for Lsat= 0.21518467023709148 \n",
      "acc for Psat= 0.33797615413996773 \n",
      "acc for optim= 0.209490935862843\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.009839585050940514\n",
      "Loss on test= 0.013818568550050259\n",
      "acc for Lsat= 0.3362015467889027 \n",
      "acc for Psat= 0.2875155697002259 \n",
      "acc for optim= 0.1949028917158893\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.01515939086675644\n",
      "Loss on test= 0.011960769072175026\n",
      "acc for Lsat= 0.27333391302610655 \n",
      "acc for Psat= 0.31898281145650037 \n",
      "acc for optim= 0.18879582503711287\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.011774217709898949\n",
      "Loss on test= 0.01212800107896328\n",
      "acc for Lsat= 0.23801197694064896 \n",
      "acc for Psat= 0.35589388966022184 \n",
      "acc for optim= 0.1942261491091082\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.011095119640231133\n",
      "Loss on test= 0.012982492335140705\n",
      "acc for Lsat= 0.30606576179423306 \n",
      "acc for Psat= 0.27915852849341194 \n",
      "acc for optim= 0.2019994053121305\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.010461443103849888\n",
      "Loss on test= 0.012143041007220745\n",
      "acc for Lsat= 0.2977344988612458 \n",
      "acc for Psat= 0.27100556843531687 \n",
      "acc for optim= 0.19235554742693642\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.00892989058047533\n",
      "Loss on test= 0.01014839205890894\n",
      "acc for Lsat= 0.22151372857071214 \n",
      "acc for Psat= 0.2678683474591216 \n",
      "acc for optim= 0.19611855948794266\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.008215532638132572\n",
      "Loss on test= 0.009537353180348873\n",
      "acc for Lsat= 0.22545144673413978 \n",
      "acc for Psat= 0.24465311605208476 \n",
      "acc for optim= 0.18758354170789912\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.008496814407408237\n",
      "Loss on test= 0.010286865755915642\n",
      "acc for Lsat= 0.24788073462502816 \n",
      "acc for Psat= 0.2915251765476509 \n",
      "acc for optim= 0.20011284303485002\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.009107695892453194\n",
      "Loss on test= 0.009936917573213577\n",
      "acc for Lsat= 0.2441358307483377 \n",
      "acc for Psat= 0.25980889491076564 \n",
      "acc for optim= 0.18826013495028865\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.009103372693061829\n",
      "Loss on test= 0.009756477549672127\n",
      "acc for Lsat= 0.21181259866618765 \n",
      "acc for Psat= 0.2917054933552059 \n",
      "acc for optim= 0.1874509553330546\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.00852905586361885\n",
      "Loss on test= 0.010464799590408802\n",
      "acc for Lsat= 0.2710105269080501 \n",
      "acc for Psat= 0.26211436823808176 \n",
      "acc for optim= 0.18678750131359384\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.009166515432298183\n",
      "Loss on test= 0.010646442882716656\n",
      "acc for Lsat= 0.2574422157627195 \n",
      "acc for Psat= 0.2545641698954688 \n",
      "acc for optim= 0.1854633215102978\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.008749439381062984\n",
      "Loss on test= 0.010688492096960545\n",
      "acc for Lsat= 0.2310424759726376 \n",
      "acc for Psat= 0.2663053491743488 \n",
      "acc for optim= 0.19467672075404496\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.008513011038303375\n",
      "Loss on test= 0.00991043820977211\n",
      "acc for Lsat= 0.23305866131253664 \n",
      "acc for Psat= 0.25309332222410585 \n",
      "acc for optim= 0.1906355965214583\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.009449336677789688\n",
      "Loss on test= 0.009515617042779922\n",
      "acc for Lsat= 0.2077382295044162 \n",
      "acc for Psat= 0.24658633514124229 \n",
      "acc for optim= 0.19733685996291822\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.008544783107936382\n",
      "Loss on test= 0.01001879945397377\n",
      "acc for Lsat= 0.21308942628264824 \n",
      "acc for Psat= 0.24527779305640027 \n",
      "acc for optim= 0.1948324911533015\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.008573604747653008\n",
      "Loss on test= 0.0093734385445714\n",
      "acc for Lsat= 0.20806488514931293 \n",
      "acc for Psat= 0.26102984027639337 \n",
      "acc for optim= 0.18995428045745938\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.008072372525930405\n",
      "Loss on test= 0.009632449597120285\n",
      "acc for Lsat= 0.23298129968232567 \n",
      "acc for Psat= 0.2570007159343165 \n",
      "acc for optim= 0.20035748203078926\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.008395690470933914\n",
      "Loss on test= 0.009710433892905712\n",
      "acc for Lsat= 0.1909930645255849 \n",
      "acc for Psat= 0.2501458233432295 \n",
      "acc for optim= 0.1848338677773069\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.00846611987799406\n",
      "Loss on test= 0.008905557915568352\n",
      "acc for Lsat= 0.21212841600168222 \n",
      "acc for Psat= 0.222928166456261 \n",
      "acc for optim= 0.1821109890395806\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.008259056136012077\n",
      "Loss on test= 0.008724251762032509\n",
      "acc for Lsat= 0.21941203696645614 \n",
      "acc for Psat= 0.24263816150344267 \n",
      "acc for optim= 0.1894707044998764\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.008601346053183079\n",
      "Loss on test= 0.011459187604486942\n",
      "acc for Lsat= 0.27725032511526015 \n",
      "acc for Psat= 0.2501403787490133 \n",
      "acc for optim= 0.18397461324892023\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.008761290460824966\n",
      "Loss on test= 0.01049820240586996\n",
      "acc for Lsat= 0.2047543106970881 \n",
      "acc for Psat= 0.29015487010920415 \n",
      "acc for optim= 0.18832983282188595\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.00871074665337801\n",
      "Loss on test= 0.010412877425551414\n",
      "acc for Lsat= 0.22858308333079103 \n",
      "acc for Psat= 0.23935215579036653 \n",
      "acc for optim= 0.1843722377335042\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.00878365058451891\n",
      "Loss on test= 0.009121552109718323\n",
      "acc for Lsat= 0.19981750964690917 \n",
      "acc for Psat= 0.26039501465961995 \n",
      "acc for optim= 0.18965602264306355\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.0086308429017663\n",
      "Loss on test= 0.00936846062541008\n",
      "acc for Lsat= 0.2224286266304858 \n",
      "acc for Psat= 0.2415583972254726 \n",
      "acc for optim= 0.19518610207157852\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.008158675394952297\n",
      "Loss on test= 0.009490236639976501\n",
      "acc for Lsat= 0.22061851641248992 \n",
      "acc for Psat= 0.24281080528015112 \n",
      "acc for optim= 0.2024988716118969\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.008214370347559452\n",
      "Loss on test= 0.009091508574783802\n",
      "acc for Lsat= 0.18358666591048545 \n",
      "acc for Psat= 0.23869326144311823 \n",
      "acc for optim= 0.18660021322496906\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.00801358837634325\n",
      "Loss on test= 0.009271731600165367\n",
      "acc for Lsat= 0.19251470685951777 \n",
      "acc for Psat= 0.25694496262528493 \n",
      "acc for optim= 0.1907300375539382\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.007941806688904762\n",
      "Loss on test= 0.008731980808079243\n",
      "acc for Lsat= 0.1945117549693067 \n",
      "acc for Psat= 0.2501320889360867 \n",
      "acc for optim= 0.18662610392717904\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.0078103081323206425\n",
      "Loss on test= 0.009207810275256634\n",
      "acc for Lsat= 0.20391827192401787 \n",
      "acc for Psat= 0.24188230486517986 \n",
      "acc for optim= 0.18987797327381636\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.007938218303024769\n",
      "Loss on test= 0.009147501550614834\n",
      "acc for Lsat= 0.21338089931008147 \n",
      "acc for Psat= 0.25060692619585784 \n",
      "acc for optim= 0.19222658468395104\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.007863001897931099\n",
      "Loss on test= 0.009866808541119099\n",
      "acc for Lsat= 0.22014290357770047 \n",
      "acc for Psat= 0.24420572666214688 \n",
      "acc for optim= 0.1829382326810804\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.00786080863326788\n",
      "Loss on test= 0.009025300852954388\n",
      "acc for Lsat= 0.21089146916075135 \n",
      "acc for Psat= 0.23189617203411142 \n",
      "acc for optim= 0.18953085215313772\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.007898552343249321\n",
      "Loss on test= 0.009406153112649918\n",
      "acc for Lsat= 0.1780122589403916 \n",
      "acc for Psat= 0.2361236269074324 \n",
      "acc for optim= 0.19351811283649725\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.0076691387221217155\n",
      "Loss on test= 0.009136423468589783\n",
      "acc for Lsat= 0.19426389730146124 \n",
      "acc for Psat= 0.25051385644121005 \n",
      "acc for optim= 0.20202073473445156\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.007666378282010555\n",
      "Loss on test= 0.009273158386349678\n",
      "acc for Lsat= 0.1909877940958946 \n",
      "acc for Psat= 0.2570619540481798 \n",
      "acc for optim= 0.19225804739036276\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.008030029013752937\n",
      "Loss on test= 0.00884863082319498\n",
      "acc for Lsat= 0.18299033791971867 \n",
      "acc for Psat= 0.2538845219477614 \n",
      "acc for optim= 0.1875833810483617\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.007647056132555008\n",
      "Loss on test= 0.008732267655432224\n",
      "acc for Lsat= 0.18737231976542046 \n",
      "acc for Psat= 0.23524289132853526 \n",
      "acc for optim= 0.18412984759760562\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.007921896874904633\n",
      "Loss on test= 0.009511767886579037\n",
      "acc for Lsat= 0.17982389012286745 \n",
      "acc for Psat= 0.28518272880436163 \n",
      "acc for optim= 0.189570668673326\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.007728931959718466\n",
      "Loss on test= 0.008871331810951233\n",
      "acc for Lsat= 0.19549672601202533 \n",
      "acc for Psat= 0.25097427609248746 \n",
      "acc for optim= 0.18822154744268685\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.008297589607536793\n",
      "Loss on test= 0.009132472798228264\n",
      "acc for Lsat= 0.21271182758061857 \n",
      "acc for Psat= 0.22235455758330272 \n",
      "acc for optim= 0.1825049716689539\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.007513833232223988\n",
      "Loss on test= 0.008571111597120762\n",
      "acc for Lsat= 0.17874468422311618 \n",
      "acc for Psat= 0.2471948743909945 \n",
      "acc for optim= 0.191998069113088\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.007556455675512552\n",
      "Loss on test= 0.009133136831223965\n",
      "acc for Lsat= 0.1682897496679378 \n",
      "acc for Psat= 0.22625805621615566 \n",
      "acc for optim= 0.18469552209612258\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.008584217168390751\n",
      "Loss on test= 0.013200207613408566\n",
      "acc for Lsat= 0.3529702690544492 \n",
      "acc for Psat= 0.2680218008373574 \n",
      "acc for optim= 0.18372199805062187\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.009847376495599747\n",
      "Loss on test= 0.010805206373333931\n",
      "acc for Lsat= 0.21483308868597215 \n",
      "acc for Psat= 0.3046639672980537 \n",
      "acc for optim= 0.19541653336138373\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.008624138310551643\n",
      "Loss on test= 0.009474435821175575\n",
      "acc for Lsat= 0.21588492180831204 \n",
      "acc for Psat= 0.21118454870788883 \n",
      "acc for optim= 0.19247485133332629\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.007639308925718069\n",
      "Loss on test= 0.009109338745474815\n",
      "acc for Lsat= 0.19887830549660215 \n",
      "acc for Psat= 0.2479676209143258 \n",
      "acc for optim= 0.1894357405108644\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.007838730700314045\n",
      "Loss on test= 0.009690181352198124\n",
      "acc for Lsat= 0.19231606645578306 \n",
      "acc for Psat= 0.2536193851803307 \n",
      "acc for optim= 0.18990363985086317\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.007709145545959473\n",
      "Loss on test= 0.009146380238234997\n",
      "acc for Lsat= 0.18878793969109167 \n",
      "acc for Psat= 0.21461229939166396 \n",
      "acc for optim= 0.19256084687219643\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.0075303963385522366\n",
      "Loss on test= 0.00913190096616745\n",
      "acc for Lsat= 0.1905795249297879 \n",
      "acc for Psat= 0.25105108169220447 \n",
      "acc for optim= 0.20001257608843143\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.008067658171057701\n",
      "Loss on test= 0.009772932156920433\n",
      "acc for Lsat= 0.23465504110411486 \n",
      "acc for Psat= 0.2309276497067853 \n",
      "acc for optim= 0.17755509140136935\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.008009331300854683\n",
      "Loss on test= 0.00897220429033041\n",
      "acc for Lsat= 0.2079677494238016 \n",
      "acc for Psat= 0.22812433835332754 \n",
      "acc for optim= 0.18567751179636288\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.007541037164628506\n",
      "Loss on test= 0.008407429791986942\n",
      "acc for Lsat= 0.18711588607908258 \n",
      "acc for Psat= 0.22964530680519452 \n",
      "acc for optim= 0.1878707282163573\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.007266172207891941\n",
      "Loss on test= 0.008414899930357933\n",
      "acc for Lsat= 0.1784537955132393 \n",
      "acc for Psat= 0.2516546103946834 \n",
      "acc for optim= 0.20384883752253027\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.007251574192196131\n",
      "Loss on test= 0.008634677156805992\n",
      "acc for Lsat= 0.20108741441327452 \n",
      "acc for Psat= 0.22327603925550052 \n",
      "acc for optim= 0.18062500499921744\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.007496270351111889\n",
      "Loss on test= 0.008519720286130905\n",
      "acc for Lsat= 0.1785240062562077 \n",
      "acc for Psat= 0.2612528259709447 \n",
      "acc for optim= 0.17685454796348912\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.007259891368448734\n",
      "Loss on test= 0.008795495145022869\n",
      "acc for Lsat= 0.18620105139666893 \n",
      "acc for Psat= 0.25050361442120106 \n",
      "acc for optim= 0.18712621131858437\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.007397182285785675\n",
      "Loss on test= 0.008503515273332596\n",
      "acc for Lsat= 0.18153763365460424 \n",
      "acc for Psat= 0.25355317833295216 \n",
      "acc for optim= 0.18527611230431337\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.007792280055582523\n",
      "Loss on test= 0.009233107790350914\n",
      "acc for Lsat= 0.1893420782797115 \n",
      "acc for Psat= 0.22681654987906366 \n",
      "acc for optim= 0.19422061555087566\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.008195126429200172\n",
      "Loss on test= 0.009493247605860233\n",
      "acc for Lsat= 0.19837382007352092 \n",
      "acc for Psat= 0.30063992133115985 \n",
      "acc for optim= 0.18388526050578766\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.01216651126742363\n",
      "Loss on test= 0.012075802311301231\n",
      "acc for Lsat= 0.2473478045177142 \n",
      "acc for Psat= 0.34301054085581945 \n",
      "acc for optim= 0.20408295052026812\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.010539960116147995\n",
      "Loss on test= 0.010800711810588837\n",
      "acc for Lsat= 0.23855808279782412 \n",
      "acc for Psat= 0.2947334586065854 \n",
      "acc for optim= 0.19711086177763332\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.009082388132810593\n",
      "Loss on test= 0.00997846107929945\n",
      "acc for Lsat= 0.21389376929213033 \n",
      "acc for Psat= 0.28627637301793046 \n",
      "acc for optim= 0.18728508882026082\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.00868227705359459\n",
      "Loss on test= 0.009820924140512943\n",
      "acc for Lsat= 0.19926934897819473 \n",
      "acc for Psat= 0.26564814227587374 \n",
      "acc for optim= 0.18423456077041203\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.009395618923008442\n",
      "Loss on test= 0.009149261750280857\n",
      "acc for Lsat= 0.1894289882681867 \n",
      "acc for Psat= 0.2657938193514577 \n",
      "acc for optim= 0.18338958037498057\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.00786654744297266\n",
      "Loss on test= 0.008895829319953918\n",
      "acc for Lsat= 0.19940005650803003 \n",
      "acc for Psat= 0.25098466842786454 \n",
      "acc for optim= 0.18506925263571875\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.008159177377820015\n",
      "Loss on test= 0.009088782593607903\n",
      "acc for Lsat= 0.1853828858015448 \n",
      "acc for Psat= 0.23588638035771362 \n",
      "acc for optim= 0.19374152985306028\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.008336271159350872\n",
      "Loss on test= 0.009025730192661285\n",
      "acc for Lsat= 0.18704783930405058 \n",
      "acc for Psat= 0.26412709539500445 \n",
      "acc for optim= 0.19772525553927436\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.008076369762420654\n",
      "Loss on test= 0.008994294330477715\n",
      "acc for Lsat= 0.1824096153245964 \n",
      "acc for Psat= 0.25365509279377635 \n",
      "acc for optim= 0.1865071254537978\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.007614761590957642\n",
      "Loss on test= 0.008785119280219078\n",
      "acc for Lsat= 0.1971301066091849 \n",
      "acc for Psat= 0.22582246224107516 \n",
      "acc for optim= 0.18115299995988607\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.007750288583338261\n",
      "Loss on test= 0.008782840333878994\n",
      "acc for Lsat= 0.18729727222378076 \n",
      "acc for Psat= 0.224287230046237 \n",
      "acc for optim= 0.19740322361543744\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.00810533482581377\n",
      "Loss on test= 0.008923586457967758\n",
      "acc for Lsat= 0.19353005233713136 \n",
      "acc for Psat= 0.3049493051469937 \n",
      "acc for optim= 0.1945219677979829\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.007784930523484945\n",
      "Loss on test= 0.009135980159044266\n",
      "acc for Lsat= 0.19312926241421888 \n",
      "acc for Psat= 0.21873872231102365 \n",
      "acc for optim= 0.18201301796819833\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.006952081806957722\n",
      "Loss on test= 0.00880433339625597\n",
      "acc for Lsat= 0.19737559276626762 \n",
      "acc for Psat= 0.23470699090212888 \n",
      "acc for optim= 0.19054328055563766\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.0070783840492367744\n",
      "Loss on test= 0.00892183929681778\n",
      "acc for Lsat= 0.19103869836411028 \n",
      "acc for Psat= 0.2203996112482378 \n",
      "acc for optim= 0.19568622805193434\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.007555872201919556\n",
      "Loss on test= 0.008320153690874577\n",
      "acc for Lsat= 0.1939560063870349 \n",
      "acc for Psat= 0.23364710295837673 \n",
      "acc for optim= 0.18711787696744575\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.0073094977997243404\n",
      "Loss on test= 0.008702683262526989\n",
      "acc for Lsat= 0.19162828226413456 \n",
      "acc for Psat= 0.24207106364555045 \n",
      "acc for optim= 0.17911799867641273\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.00713525852188468\n",
      "Loss on test= 0.008603201247751713\n",
      "acc for Lsat= 0.18378112047670225 \n",
      "acc for Psat= 0.24839835154411735 \n",
      "acc for optim= 0.19851668290154564\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.007627583108842373\n",
      "Loss on test= 0.010432600043714046\n",
      "acc for Lsat= 0.25746574939770595 \n",
      "acc for Psat= 0.25859133634710546 \n",
      "acc for optim= 0.18290927946209046\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.0103298369795084\n",
      "Loss on test= 0.009920967742800713\n",
      "acc for Lsat= 0.21065255185764772 \n",
      "acc for Psat= 0.2868039317303108 \n",
      "acc for optim= 0.17983145002584874\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.008442949503660202\n",
      "Loss on test= 0.009160717017948627\n",
      "acc for Lsat= 0.20179732206600076 \n",
      "acc for Psat= 0.24715649312129245 \n",
      "acc for optim= 0.18466725261733088\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.007557205855846405\n",
      "Loss on test= 0.008467013947665691\n",
      "acc for Lsat= 0.18804617271583038 \n",
      "acc for Psat= 0.22878234934149555 \n",
      "acc for optim= 0.18390798546759352\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.008048596791923046\n",
      "Loss on test= 0.008844244293868542\n",
      "acc for Lsat= 0.18822622249841872 \n",
      "acc for Psat= 0.22737777382898772 \n",
      "acc for optim= 0.17864400641458322\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.00731549272313714\n",
      "Loss on test= 0.008589153178036213\n",
      "acc for Lsat= 0.18999571134298124 \n",
      "acc for Psat= 0.22672564281879726 \n",
      "acc for optim= 0.1956382168243166\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.007027746178209782\n",
      "Loss on test= 0.008678300306200981\n",
      "acc for Lsat= 0.1793610746142088 \n",
      "acc for Psat= 0.23823906887504206 \n",
      "acc for optim= 0.18079193002737812\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.0071223946288228035\n",
      "Loss on test= 0.00802554003894329\n",
      "acc for Lsat= 0.19723317303549742 \n",
      "acc for Psat= 0.22167460843367257 \n",
      "acc for optim= 0.1968069665815269\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.006791413761675358\n",
      "Loss on test= 0.008383272215723991\n",
      "acc for Lsat= 0.18840507919915386 \n",
      "acc for Psat= 0.23878546609489829 \n",
      "acc for optim= 0.17961345059094858\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.007294304668903351\n",
      "Loss on test= 0.008567841723561287\n",
      "acc for Lsat= 0.2004727031276027 \n",
      "acc for Psat= 0.2156076109767739 \n",
      "acc for optim= 0.18452588928210717\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.007181578315794468\n",
      "Loss on test= 0.00850767083466053\n",
      "acc for Lsat= 0.1735053984181131 \n",
      "acc for Psat= 0.23919539115177926 \n",
      "acc for optim= 0.17926543439570508\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.006607352290302515\n",
      "Loss on test= 0.007926106452941895\n",
      "acc for Lsat= 0.1781062338318004 \n",
      "acc for Psat= 0.21970020319415318 \n",
      "acc for optim= 0.18226027101179065\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.006923099514096975\n",
      "Loss on test= 0.008083358407020569\n",
      "acc for Lsat= 0.17689247146844253 \n",
      "acc for Psat= 0.2329054992944651 \n",
      "acc for optim= 0.18501322406032084\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.0065993377938866615\n",
      "Loss on test= 0.008329692296683788\n",
      "acc for Lsat= 0.17694447041516856 \n",
      "acc for Psat= 0.2057324160405694 \n",
      "acc for optim= 0.1842948079833925\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.007063268218189478\n",
      "Loss on test= 0.008097589015960693\n",
      "acc for Lsat= 0.17713870178387103 \n",
      "acc for Psat= 0.2151952579466733 \n",
      "acc for optim= 0.19093726949354053\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.007422833237797022\n",
      "Loss on test= 0.008823874406516552\n",
      "acc for Lsat= 0.17487052386830806 \n",
      "acc for Psat= 0.2536273890358136 \n",
      "acc for optim= 0.1905923173873548\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.00814775936305523\n",
      "Loss on test= 0.008500384166836739\n",
      "acc for Lsat= 0.16983225654956663 \n",
      "acc for Psat= 0.2237430530188025 \n",
      "acc for optim= 0.18439265784204434\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.0070529505610466\n",
      "Loss on test= 0.007986937649548054\n",
      "acc for Lsat= 0.19902155873099472 \n",
      "acc for Psat= 0.21598545464030544 \n",
      "acc for optim= 0.18615696484749739\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.007447620388120413\n",
      "Loss on test= 0.008555038832128048\n",
      "acc for Lsat= 0.1909581650502705 \n",
      "acc for Psat= 0.24586676266550117 \n",
      "acc for optim= 0.1916170936340245\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.007341337855905294\n",
      "Loss on test= 0.008356205187737942\n",
      "acc for Lsat= 0.20680417832345932 \n",
      "acc for Psat= 0.2478516115616152 \n",
      "acc for optim= 0.1817870451305367\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.007163046393543482\n",
      "Loss on test= 0.00872244406491518\n",
      "acc for Lsat= 0.1847248420951369 \n",
      "acc for Psat= 0.20986207599800139 \n",
      "acc for optim= 0.18319456524169836\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.007032337132841349\n",
      "Loss on test= 0.007922094315290451\n",
      "acc for Lsat= 0.17584697352760456 \n",
      "acc for Psat= 0.21455526804712746 \n",
      "acc for optim= 0.18822696668002373\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.006848047021776438\n",
      "Loss on test= 0.008245989680290222\n",
      "acc for Lsat= 0.17130846657110838 \n",
      "acc for Psat= 0.20367071441547432 \n",
      "acc for optim= 0.1854834486539552\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.006633071694523096\n",
      "Loss on test= 0.008282922208309174\n",
      "acc for Lsat= 0.19324076226454412 \n",
      "acc for Psat= 0.21383930674532703 \n",
      "acc for optim= 0.179485580125503\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.0071343714371323586\n",
      "Loss on test= 0.008115459233522415\n",
      "acc for Lsat= 0.17325217966066642 \n",
      "acc for Psat= 0.2240027446353228 \n",
      "acc for optim= 0.18355536855047294\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.006921195425093174\n",
      "Loss on test= 0.00837894156575203\n",
      "acc for Lsat= 0.20811746355153804 \n",
      "acc for Psat= 0.22692250120835225 \n",
      "acc for optim= 0.19644441939165175\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.00719019491225481\n",
      "Loss on test= 0.008449899964034557\n",
      "acc for Lsat= 0.16164941024073384 \n",
      "acc for Psat= 0.2083769380427958 \n",
      "acc for optim= 0.18153979307933726\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.00690634548664093\n",
      "Loss on test= 0.007564626168459654\n",
      "acc for Lsat= 0.18337766618838106 \n",
      "acc for Psat= 0.2087613726126366 \n",
      "acc for optim= 0.18044123133934545\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.00659932941198349\n",
      "Loss on test= 0.0077448999509215355\n",
      "acc for Lsat= 0.17995516243178425 \n",
      "acc for Psat= 0.21196500364192197 \n",
      "acc for optim= 0.1844554918849188\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.0064928410574793816\n",
      "Loss on test= 0.007664194330573082\n",
      "acc for Lsat= 0.1677262119416407 \n",
      "acc for Psat= 0.22748038053112277 \n",
      "acc for optim= 0.18370538493847383\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.006522008683532476\n",
      "Loss on test= 0.008284587413072586\n",
      "acc for Lsat= 0.16508002309675532 \n",
      "acc for Psat= 0.23180975509219665 \n",
      "acc for optim= 0.1843662050224413\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.007006867788732052\n",
      "Loss on test= 0.008004536852240562\n",
      "acc for Lsat= 0.1595815054511224 \n",
      "acc for Psat= 0.21178432169244396 \n",
      "acc for optim= 0.17191786911399637\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.006561773829162121\n",
      "Loss on test= 0.008619758300483227\n",
      "acc for Lsat= 0.1751527799732342 \n",
      "acc for Psat= 0.22554860385516506 \n",
      "acc for optim= 0.181484571616089\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.006901653949171305\n",
      "Loss on test= 0.008388899266719818\n",
      "acc for Lsat= 0.19461651112403355 \n",
      "acc for Psat= 0.2045326016148644 \n",
      "acc for optim= 0.17794123131354325\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.007297097239643335\n",
      "Loss on test= 0.008091013878583908\n",
      "acc for Lsat= 0.17342898395202566 \n",
      "acc for Psat= 0.23148659163185198 \n",
      "acc for optim= 0.1855328689060235\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.006755555979907513\n",
      "Loss on test= 0.007881902158260345\n",
      "acc for Lsat= 0.17304441323079223 \n",
      "acc for Psat= 0.22210199450167492 \n",
      "acc for optim= 0.18795390972432482\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.006329725030809641\n",
      "Loss on test= 0.00798304844647646\n",
      "acc for Lsat= 0.1888871351020319 \n",
      "acc for Psat= 0.1941049356352286 \n",
      "acc for optim= 0.18106348343750797\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.006561387330293655\n",
      "Loss on test= 0.007741119246929884\n",
      "acc for Lsat= 0.1710362270795053 \n",
      "acc for Psat= 0.22203557437675103 \n",
      "acc for optim= 0.1814301692260683\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.006471236702054739\n",
      "Loss on test= 0.00757082412019372\n",
      "acc for Lsat= 0.16923377522091823 \n",
      "acc for Psat= 0.21113748487970624 \n",
      "acc for optim= 0.17389053605042673\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.007093013264238834\n",
      "Loss on test= 0.007844092324376106\n",
      "acc for Lsat= 0.18289926592623204 \n",
      "acc for Psat= 0.20347362507027802 \n",
      "acc for optim= 0.18018740995359592\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.0063628265634179115\n",
      "Loss on test= 0.007928160950541496\n",
      "acc for Lsat= 0.1819555586162424 \n",
      "acc for Psat= 0.21892412631690394 \n",
      "acc for optim= 0.1861377438194439\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.006646968424320221\n",
      "Loss on test= 0.008181000128388405\n",
      "acc for Lsat= 0.17872491880209324 \n",
      "acc for Psat= 0.21197491397730028 \n",
      "acc for optim= 0.1828816192280921\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.006667089648544788\n",
      "Loss on test= 0.007798915728926659\n",
      "acc for Lsat= 0.16564369969409662 \n",
      "acc for Psat= 0.2230319669849495 \n",
      "acc for optim= 0.18048411669041656\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.00650955643504858\n",
      "Loss on test= 0.007956231012940407\n",
      "acc for Lsat= 0.17088854510348325 \n",
      "acc for Psat= 0.22175381504930555 \n",
      "acc for optim= 0.18948506547517877\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.007286875508725643\n",
      "Loss on test= 0.007695785257965326\n",
      "acc for Lsat= 0.1689810964301778 \n",
      "acc for Psat= 0.2169612899403561 \n",
      "acc for optim= 0.1877795318886113\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.006763621233403683\n",
      "Loss on test= 0.00753120519220829\n",
      "acc for Lsat= 0.16938595034327114 \n",
      "acc for Psat= 0.20167285781821281 \n",
      "acc for optim= 0.1853564490928681\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.006605411879718304\n",
      "Loss on test= 0.007703434210270643\n",
      "acc for Lsat= 0.19120161611296724 \n",
      "acc for Psat= 0.21458816665881236 \n",
      "acc for optim= 0.181905819669072\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.006520827300846577\n",
      "Loss on test= 0.008040666580200195\n",
      "acc for Lsat= 0.18045004009055432 \n",
      "acc for Psat= 0.22784398605943978 \n",
      "acc for optim= 0.17958867893951228\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.006567701697349548\n",
      "Loss on test= 0.00818851962685585\n",
      "acc for Lsat= 0.17279420932964804 \n",
      "acc for Psat= 0.21366146857751014 \n",
      "acc for optim= 0.1871007559463623\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.006496927235275507\n",
      "Loss on test= 0.007796334568411112\n",
      "acc for Lsat= 0.15089394087601668 \n",
      "acc for Psat= 0.215370309578835 \n",
      "acc for optim= 0.17092283120699472\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.006555899977684021\n",
      "Loss on test= 0.007908974774181843\n",
      "acc for Lsat= 0.1701308665926889 \n",
      "acc for Psat= 0.21427295771904564 \n",
      "acc for optim= 0.18292644978100128\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.00652022659778595\n",
      "Loss on test= 0.008136458694934845\n",
      "acc for Lsat= 0.16112556073119955 \n",
      "acc for Psat= 0.20794057166585547 \n",
      "acc for optim= 0.1729560014656287\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.006334385368973017\n",
      "Loss on test= 0.00785523746162653\n",
      "acc for Lsat= 0.16184479621979483 \n",
      "acc for Psat= 0.19349144724375172 \n",
      "acc for optim= 0.18318074588457764\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.006481287535279989\n",
      "Loss on test= 0.007597143296152353\n",
      "acc for Lsat= 0.15679371831175246 \n",
      "acc for Psat= 0.2399544503493998 \n",
      "acc for optim= 0.1798376234624245\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.006466759834438562\n",
      "Loss on test= 0.007611608598381281\n",
      "acc for Lsat= 0.166903980745224 \n",
      "acc for Psat= 0.19094959517757668 \n",
      "acc for optim= 0.17750524239610788\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.0062538073398172855\n",
      "Loss on test= 0.007608663756400347\n",
      "acc for Lsat= 0.16877310202136392 \n",
      "acc for Psat= 0.2063754966742069 \n",
      "acc for optim= 0.17822763093224284\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.006432744674384594\n",
      "Loss on test= 0.00778817106038332\n",
      "acc for Lsat= 0.15612079423010639 \n",
      "acc for Psat= 0.19258106629618016 \n",
      "acc for optim= 0.17498405458105987\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.006400656886398792\n",
      "Loss on test= 0.007773513440042734\n",
      "acc for Lsat= 0.1654117631947347 \n",
      "acc for Psat= 0.22111484897628306 \n",
      "acc for optim= 0.17518971358362936\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.006375239696353674\n",
      "Loss on test= 0.007628914434462786\n",
      "acc for Lsat= 0.16819140978589783 \n",
      "acc for Psat= 0.2068358277646752 \n",
      "acc for optim= 0.18149883869575473\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.006577789783477783\n",
      "Loss on test= 0.007846280001103878\n",
      "acc for Lsat= 0.18116933526833862 \n",
      "acc for Psat= 0.19949445632147053 \n",
      "acc for optim= 0.17674514116131562\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.006807637866586447\n",
      "Loss on test= 0.008227246813476086\n",
      "acc for Lsat= 0.18265639746126996 \n",
      "acc for Psat= 0.19759018132415387 \n",
      "acc for optim= 0.1886559923897024\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.006957653909921646\n",
      "Loss on test= 0.008617352694272995\n",
      "acc for Lsat= 0.18466162313172807 \n",
      "acc for Psat= 0.2044777810893243 \n",
      "acc for optim= 0.17893622483271862\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.006597475614398718\n",
      "Loss on test= 0.008154277689754963\n",
      "acc for Lsat= 0.17532759761346167 \n",
      "acc for Psat= 0.1991897995630947 \n",
      "acc for optim= 0.18729521972108173\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.006687256041914225\n",
      "Loss on test= 0.007678636349737644\n",
      "acc for Lsat= 0.1613119955908423 \n",
      "acc for Psat= 0.21246245923482138 \n",
      "acc for optim= 0.1789805558051143\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.006801626179367304\n",
      "Loss on test= 0.007643633987754583\n",
      "acc for Lsat= 0.16389579400954554 \n",
      "acc for Psat= 0.2009583016564081 \n",
      "acc for optim= 0.1831216393607348\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.006286422722041607\n",
      "Loss on test= 0.007748033385723829\n",
      "acc for Lsat= 0.18046768353030573 \n",
      "acc for Psat= 0.21129770154996058 \n",
      "acc for optim= 0.17744595041099795\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.006504390388727188\n",
      "Loss on test= 0.008227336220443249\n",
      "acc for Lsat= 0.17656259593333415 \n",
      "acc for Psat= 0.22189676820464646 \n",
      "acc for optim= 0.1710923246339365\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.006755794398486614\n",
      "Loss on test= 0.007925731129944324\n",
      "acc for Lsat= 0.17648109581214605 \n",
      "acc for Psat= 0.2070380481070463 \n",
      "acc for optim= 0.18696676317113833\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.0068495310842990875\n",
      "Loss on test= 0.007926278747618198\n",
      "acc for Lsat= 0.19493297313685437 \n",
      "acc for Psat= 0.2046756840088269 \n",
      "acc for optim= 0.19135064890028022\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.0066514997743070126\n",
      "Loss on test= 0.007231485564261675\n",
      "acc for Lsat= 0.16817798022253316 \n",
      "acc for Psat= 0.21329040112828868 \n",
      "acc for optim= 0.1734065093054268\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.006686938460916281\n",
      "Loss on test= 0.007912407629191875\n",
      "acc for Lsat= 0.15997002460615953 \n",
      "acc for Psat= 0.23376115455958213 \n",
      "acc for optim= 0.17589321955141504\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.006494047585874796\n",
      "Loss on test= 0.007892413064837456\n",
      "acc for Lsat= 0.1659322973210021 \n",
      "acc for Psat= 0.2022992702922402 \n",
      "acc for optim= 0.1834171621292894\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.006367667578160763\n",
      "Loss on test= 0.00737988343462348\n",
      "acc for Lsat= 0.17267586692433412 \n",
      "acc for Psat= 0.2054151255389309 \n",
      "acc for optim= 0.16971044161998225\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.006089767441153526\n",
      "Loss on test= 0.007633070927113295\n",
      "acc for Lsat= 0.17613638585173816 \n",
      "acc for Psat= 0.20245565345699776 \n",
      "acc for optim= 0.17043709436080373\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.006241579540073872\n",
      "Loss on test= 0.00746686477214098\n",
      "acc for Lsat= 0.18060930422364094 \n",
      "acc for Psat= 0.20343676862367963 \n",
      "acc for optim= 0.17688208210747688\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.006176487542688847\n",
      "Loss on test= 0.008175997994840145\n",
      "acc for Lsat= 0.19809693318074112 \n",
      "acc for Psat= 0.21091866564717943 \n",
      "acc for optim= 0.18059620706659846\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.00628818292170763\n",
      "Loss on test= 0.007421746850013733\n",
      "acc for Lsat= 0.17901233125470395 \n",
      "acc for Psat= 0.20123826208377454 \n",
      "acc for optim= 0.1756766602832091\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.0061571476981043816\n",
      "Loss on test= 0.007623148616403341\n",
      "acc for Lsat= 0.1593479760954935 \n",
      "acc for Psat= 0.1963767899327232 \n",
      "acc for optim= 0.1792912357527816\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.006899890955537558\n",
      "Loss on test= 0.007901635952293873\n",
      "acc for Lsat= 0.16585123706074645 \n",
      "acc for Psat= 0.24338599426755833 \n",
      "acc for optim= 0.1861096281204258\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.0066789062693715096\n",
      "Loss on test= 0.007793843746185303\n",
      "acc for Lsat= 0.1569770171667724 \n",
      "acc for Psat= 0.23103390576233934 \n",
      "acc for optim= 0.18369053409579897\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.0065086716786026955\n",
      "Loss on test= 0.007764602079987526\n",
      "acc for Lsat= 0.16313617341602069 \n",
      "acc for Psat= 0.18671175850732785 \n",
      "acc for optim= 0.18504741570087374\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.006460980977863073\n",
      "Loss on test= 0.007127775810658932\n",
      "acc for Lsat= 0.155174119142075 \n",
      "acc for Psat= 0.18757151315412407 \n",
      "acc for optim= 0.1813835791149463\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.006504769437015057\n",
      "Loss on test= 0.0073680877685546875\n",
      "acc for Lsat= 0.14808057725465795 \n",
      "acc for Psat= 0.20186081183196397 \n",
      "acc for optim= 0.18001848324774536\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.006112636998295784\n",
      "Loss on test= 0.007316456642001867\n",
      "acc for Lsat= 0.16607184344255552 \n",
      "acc for Psat= 0.1846934761558125 \n",
      "acc for optim= 0.18057268392542744\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.006074503064155579\n",
      "Loss on test= 0.007931274361908436\n",
      "acc for Lsat= 0.15646119369041236 \n",
      "acc for Psat= 0.19274414702018983 \n",
      "acc for optim= 0.17733379962193765\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.006355280987918377\n",
      "Loss on test= 0.007666366640478373\n",
      "acc for Lsat= 0.1634748257865765 \n",
      "acc for Psat= 0.19838608700713356 \n",
      "acc for optim= 0.18247802093430407\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.006170644424855709\n",
      "Loss on test= 0.007678335998207331\n",
      "acc for Lsat= 0.15196045654631204 \n",
      "acc for Psat= 0.2082525173074291 \n",
      "acc for optim= 0.1779937279420918\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.0061376746743917465\n",
      "Loss on test= 0.0075433808378875256\n",
      "acc for Lsat= 0.16125525482357708 \n",
      "acc for Psat= 0.19831799192766308 \n",
      "acc for optim= 0.1767767259169782\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.00608229823410511\n",
      "Loss on test= 0.0076261255890131\n",
      "acc for Lsat= 0.1758284669377093 \n",
      "acc for Psat= 0.20596786877387308 \n",
      "acc for optim= 0.1761872653040241\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.006707561668008566\n",
      "Loss on test= 0.007021217606961727\n",
      "acc for Lsat= 0.1713090954085914 \n",
      "acc for Psat= 0.21252505983820213 \n",
      "acc for optim= 0.1746400307417374\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.006293634884059429\n",
      "Loss on test= 0.007344152312725782\n",
      "acc for Lsat= 0.16073310329847432 \n",
      "acc for Psat= 0.1984302272298755 \n",
      "acc for optim= 0.18256104986820768\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.0067254588939249516\n",
      "Loss on test= 0.007531269919127226\n",
      "acc for Lsat= 0.19860765391304233 \n",
      "acc for Psat= 0.2157253928535969 \n",
      "acc for optim= 0.18212912401964398\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.0066399117931723595\n",
      "Loss on test= 0.007757165934890509\n",
      "acc for Lsat= 0.18721134823271776 \n",
      "acc for Psat= 0.2030384507219185 \n",
      "acc for optim= 0.17828863912136064\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.006494609173387289\n",
      "Loss on test= 0.008548812940716743\n",
      "acc for Lsat= 0.15963848099631608 \n",
      "acc for Psat= 0.17614491658731837 \n",
      "acc for optim= 0.17797501348693795\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.0067077865824103355\n",
      "Loss on test= 0.007491435389965773\n",
      "acc for Lsat= 0.1656804056177832 \n",
      "acc for Psat= 0.20894266179510865 \n",
      "acc for optim= 0.17051647932528227\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.006436598487198353\n",
      "Loss on test= 0.009262978099286556\n",
      "acc for Lsat= 0.1975151816493694 \n",
      "acc for Psat= 0.2214019514742445 \n",
      "acc for optim= 0.18046018455972415\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.006510944105684757\n",
      "Loss on test= 0.00796044897288084\n",
      "acc for Lsat= 0.17559879292985883 \n",
      "acc for Psat= 0.20138212049066959 \n",
      "acc for optim= 0.17068717703891184\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.006427928805351257\n",
      "Loss on test= 0.007438322063535452\n",
      "acc for Lsat= 0.16985924785620854 \n",
      "acc for Psat= 0.20574893530775015 \n",
      "acc for optim= 0.17688019870466468\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.00634406041353941\n",
      "Loss on test= 0.007576765026897192\n",
      "acc for Lsat= 0.16203871454096963 \n",
      "acc for Psat= 0.21842642292250558 \n",
      "acc for optim= 0.18411369061586066\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.006439561955630779\n",
      "Loss on test= 0.007482094690203667\n",
      "acc for Lsat= 0.15816856423721146 \n",
      "acc for Psat= 0.21481155313018968 \n",
      "acc for optim= 0.17701969061840753\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.006223507225513458\n",
      "Loss on test= 0.0074959504418075085\n",
      "acc for Lsat= 0.1766020029792791 \n",
      "acc for Psat= 0.2165121094903863 \n",
      "acc for optim= 0.18105303661632505\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.006112388335168362\n",
      "Loss on test= 0.0072059426456689835\n",
      "acc for Lsat= 0.1577169909203028 \n",
      "acc for Psat= 0.1754526667018253 \n",
      "acc for optim= 0.181156277370288\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.005984744057059288\n",
      "Loss on test= 0.007069919258356094\n",
      "acc for Lsat= 0.15903978368847585 \n",
      "acc for Psat= 0.21312316369721437 \n",
      "acc for optim= 0.17873366574516336\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.0058556487783789635\n",
      "Loss on test= 0.007684057112783194\n",
      "acc for Lsat= 0.15805058185579865 \n",
      "acc for Psat= 0.20497002143099843 \n",
      "acc for optim= 0.1765845278762739\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.0059170108288526535\n",
      "Loss on test= 0.007917247712612152\n",
      "acc for Lsat= 0.17123049537011434 \n",
      "acc for Psat= 0.20346245749927028 \n",
      "acc for optim= 0.17727051342209632\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.005887147039175034\n",
      "Loss on test= 0.0072412132285535336\n",
      "acc for Lsat= 0.15164978057274892 \n",
      "acc for Psat= 0.20486635868213346 \n",
      "acc for optim= 0.18432989670040056\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.005919101648032665\n",
      "Loss on test= 0.007529836613684893\n",
      "acc for Lsat= 0.16749430532208415 \n",
      "acc for Psat= 0.2093276914615627 \n",
      "acc for optim= 0.17523106251744033\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.005942397750914097\n",
      "Loss on test= 0.007259509526193142\n",
      "acc for Lsat= 0.16030447037077555 \n",
      "acc for Psat= 0.20429651841757912 \n",
      "acc for optim= 0.1737228892921073\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.006288664881139994\n",
      "Loss on test= 0.007947170175611973\n",
      "acc for Lsat= 0.16506938387288667 \n",
      "acc for Psat= 0.211946816544538 \n",
      "acc for optim= 0.18390361708188124\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.005837442819029093\n",
      "Loss on test= 0.007154466118663549\n",
      "acc for Lsat= 0.16325663944065083 \n",
      "acc for Psat= 0.19392532175788504 \n",
      "acc for optim= 0.17542442590376117\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.006091109476983547\n",
      "Loss on test= 0.0077216350473463535\n",
      "acc for Lsat= 0.16239261998199536 \n",
      "acc for Psat= 0.19422153565234918 \n",
      "acc for optim= 0.18611631392268463\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.0059122443199157715\n",
      "Loss on test= 0.007771610748022795\n",
      "acc for Lsat= 0.16124236909405434 \n",
      "acc for Psat= 0.21061820528263867 \n",
      "acc for optim= 0.17561516338791394\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.005923367105424404\n",
      "Loss on test= 0.007543372921645641\n",
      "acc for Lsat= 0.1566476240223579 \n",
      "acc for Psat= 0.18469827187230398 \n",
      "acc for optim= 0.17744506556277362\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.005968978628516197\n",
      "Loss on test= 0.0076623642817139626\n",
      "acc for Lsat= 0.17909558777636314 \n",
      "acc for Psat= 0.2053202899031677 \n",
      "acc for optim= 0.17922757823874488\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.005968679673969746\n",
      "Loss on test= 0.007346787955611944\n",
      "acc for Lsat= 0.16329902127875612 \n",
      "acc for Psat= 0.1754765465145656 \n",
      "acc for optim= 0.18138045032401798\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.006621792912483215\n",
      "Loss on test= 0.007085523568093777\n",
      "acc for Lsat= 0.17069103662878823 \n",
      "acc for Psat= 0.1808068134487973 \n",
      "acc for optim= 0.17928414072375745\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.005834163166582584\n",
      "Loss on test= 0.007920926436781883\n",
      "acc for Lsat= 0.16216968878078825 \n",
      "acc for Psat= 0.18827713579435634 \n",
      "acc for optim= 0.17177346230438742\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.005735930986702442\n",
      "Loss on test= 0.007747146766632795\n",
      "acc for Lsat= 0.15748847793748594 \n",
      "acc for Psat= 0.1995334326770046 \n",
      "acc for optim= 0.17797959626520618\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.005633994471281767\n",
      "Loss on test= 0.006952519528567791\n",
      "acc for Lsat= 0.15251344498752648 \n",
      "acc for Psat= 0.20195263133328942 \n",
      "acc for optim= 0.16399681055064305\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.005891577340662479\n",
      "Loss on test= 0.007543462794274092\n",
      "acc for Lsat= 0.16586695942508517 \n",
      "acc for Psat= 0.21068059353913623 \n",
      "acc for optim= 0.18258368712926254\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.005927567835897207\n",
      "Loss on test= 0.0075795711018145084\n",
      "acc for Lsat= 0.16329458618964085 \n",
      "acc for Psat= 0.20538291322137991 \n",
      "acc for optim= 0.18163287284417598\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.0058881621807813644\n",
      "Loss on test= 0.007516767363995314\n",
      "acc for Lsat= 0.17403313551369107 \n",
      "acc for Psat= 0.18325416267292238 \n",
      "acc for optim= 0.178670011289814\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.006265641655772924\n",
      "Loss on test= 0.007411366794258356\n",
      "acc for Lsat= 0.15923057410667543 \n",
      "acc for Psat= 0.21232725120088483 \n",
      "acc for optim= 0.18602152502690977\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.006167776882648468\n",
      "Loss on test= 0.0073788524605333805\n",
      "acc for Lsat= 0.15980821181752825 \n",
      "acc for Psat= 0.19328353318049893 \n",
      "acc for optim= 0.18632297187005398\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.006019125692546368\n",
      "Loss on test= 0.007211474701762199\n",
      "acc for Lsat= 0.16666698769368538 \n",
      "acc for Psat= 0.19612877093079942 \n",
      "acc for optim= 0.17727383778146164\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.006040013860911131\n",
      "Loss on test= 0.00735880434513092\n",
      "acc for Lsat= 0.16220693696850502 \n",
      "acc for Psat= 0.2112651680426321 \n",
      "acc for optim= 0.18343479666538293\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.006025935057550669\n",
      "Loss on test= 0.007395366206765175\n",
      "acc for Lsat= 0.1576958898788883 \n",
      "acc for Psat= 0.2030032755081832 \n",
      "acc for optim= 0.18747101012754758\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.006124749314039946\n",
      "Loss on test= 0.007603149861097336\n",
      "acc for Lsat= 0.16468393466164374 \n",
      "acc for Psat= 0.18410619662761626 \n",
      "acc for optim= 0.17511734065473783\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.0068252841010689735\n",
      "Loss on test= 0.007949448190629482\n",
      "acc for Lsat= 0.16266000773834033 \n",
      "acc for Psat= 0.20814693628688205 \n",
      "acc for optim= 0.18281324725513648\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.006453239358961582\n",
      "Loss on test= 0.006972014904022217\n",
      "acc for Lsat= 0.16298261029592365 \n",
      "acc for Psat= 0.22151281074420395 \n",
      "acc for optim= 0.1804094492751708\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.00611951993778348\n",
      "Loss on test= 0.007384303491562605\n",
      "acc for Lsat= 0.15811553705568004 \n",
      "acc for Psat= 0.20199346778089883 \n",
      "acc for optim= 0.17902438453948277\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.005926147103309631\n",
      "Loss on test= 0.007585514336824417\n",
      "acc for Lsat= 0.1582633326452256 \n",
      "acc for Psat= 0.19574006451766168 \n",
      "acc for optim= 0.18064264064579802\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.006154266186058521\n",
      "Loss on test= 0.007227559108287096\n",
      "acc for Lsat= 0.17500102718026564 \n",
      "acc for Psat= 0.18821668533138838 \n",
      "acc for optim= 0.17258080680917598\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.0058658542111516\n",
      "Loss on test= 0.00758923077955842\n",
      "acc for Lsat= 0.1617278056933457 \n",
      "acc for Psat= 0.20448297003520743 \n",
      "acc for optim= 0.17922677955891722\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.006265147123485804\n",
      "Loss on test= 0.007809640374034643\n",
      "acc for Lsat= 0.1629859358034112 \n",
      "acc for Psat= 0.1988752816240761 \n",
      "acc for optim= 0.17502638491091974\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.006025564391165972\n",
      "Loss on test= 0.0074902684427797794\n",
      "acc for Lsat= 0.17922089406323513 \n",
      "acc for Psat= 0.22544566231062177 \n",
      "acc for optim= 0.17624146325363907\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.006057193037122488\n",
      "Loss on test= 0.00733343418687582\n",
      "acc for Lsat= 0.16422017765323035 \n",
      "acc for Psat= 0.19997832392166812 \n",
      "acc for optim= 0.1756846416245413\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.006113787181675434\n",
      "Loss on test= 0.007465032860636711\n",
      "acc for Lsat= 0.1832526418311735 \n",
      "acc for Psat= 0.1960619580915024 \n",
      "acc for optim= 0.174126638559678\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.005849398672580719\n",
      "Loss on test= 0.007413145620375872\n",
      "acc for Lsat= 0.16689693756464996 \n",
      "acc for Psat= 0.18949536727703192 \n",
      "acc for optim= 0.16863900585172575\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.00607468094676733\n",
      "Loss on test= 0.007537975441664457\n",
      "acc for Lsat= 0.16801406153034967 \n",
      "acc for Psat= 0.18643398976609965 \n",
      "acc for optim= 0.18344638254321716\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.005925992503762245\n",
      "Loss on test= 0.00723035866394639\n",
      "acc for Lsat= 0.16480508622411374 \n",
      "acc for Psat= 0.206545009985986 \n",
      "acc for optim= 0.17422923921668504\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.005725487135350704\n",
      "Loss on test= 0.007597927935421467\n",
      "acc for Lsat= 0.1665755802455366 \n",
      "acc for Psat= 0.20780663831449556 \n",
      "acc for optim= 0.17506165901097837\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.005739652086049318\n",
      "Loss on test= 0.007718089502304792\n",
      "acc for Lsat= 0.16946282266738413 \n",
      "acc for Psat= 0.2003256018353687 \n",
      "acc for optim= 0.17635901722919622\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.006079852115362883\n",
      "Loss on test= 0.007658740505576134\n",
      "acc for Lsat= 0.1722881282851974 \n",
      "acc for Psat= 0.19810368530509506 \n",
      "acc for optim= 0.1763361571471161\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.005650696810334921\n",
      "Loss on test= 0.007277342490851879\n",
      "acc for Lsat= 0.1479235537266206 \n",
      "acc for Psat= 0.19867172587479726 \n",
      "acc for optim= 0.17879889193678\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.006032449193298817\n",
      "Loss on test= 0.007316550239920616\n",
      "acc for Lsat= 0.15494314298438305 \n",
      "acc for Psat= 0.18746547073709824 \n",
      "acc for optim= 0.17732246772416668\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.005753326695412397\n",
      "Loss on test= 0.007474168203771114\n",
      "acc for Lsat= 0.16042610861391562 \n",
      "acc for Psat= 0.19071628728912013 \n",
      "acc for optim= 0.1791315756436651\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.005804847925901413\n",
      "Loss on test= 0.007276198826730251\n",
      "acc for Lsat= 0.16721727753327167 \n",
      "acc for Psat= 0.18970331314328073 \n",
      "acc for optim= 0.17366126734409368\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.005708739161491394\n",
      "Loss on test= 0.007509342394769192\n",
      "acc for Lsat= 0.16718760257664128 \n",
      "acc for Psat= 0.18299587676645118 \n",
      "acc for optim= 0.17372112026377046\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.005945802666246891\n",
      "Loss on test= 0.008024653419852257\n",
      "acc for Lsat= 0.17923348633148783 \n",
      "acc for Psat= 0.18294380962527568 \n",
      "acc for optim= 0.17720085346940562\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.006099800579249859\n",
      "Loss on test= 0.007226626388728619\n",
      "acc for Lsat= 0.16641091175614017 \n",
      "acc for Psat= 0.19463908148979098 \n",
      "acc for optim= 0.18048389515902497\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.0060906196013092995\n",
      "Loss on test= 0.007815396413207054\n",
      "acc for Lsat= 0.1450318454698942 \n",
      "acc for Psat= 0.2033315025090591 \n",
      "acc for optim= 0.17639427968552795\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.006048659328371286\n",
      "Loss on test= 0.007506502792239189\n",
      "acc for Lsat= 0.16780540629632043 \n",
      "acc for Psat= 0.20356049061214673 \n",
      "acc for optim= 0.17187415869514358\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.006092014256864786\n",
      "Loss on test= 0.007257265970110893\n",
      "acc for Lsat= 0.16086620792372489 \n",
      "acc for Psat= 0.18240222060769573 \n",
      "acc for optim= 0.17631689497903294\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.005806622561067343\n",
      "Loss on test= 0.0068997289054095745\n",
      "acc for Lsat= 0.16549199722873306 \n",
      "acc for Psat= 0.19609109379625955 \n",
      "acc for optim= 0.1698486407877368\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.005963379517197609\n",
      "Loss on test= 0.00721508264541626\n",
      "acc for Lsat= 0.1586782995392912 \n",
      "acc for Psat= 0.18385026826462175 \n",
      "acc for optim= 0.18490222064524386\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.0058313580229878426\n",
      "Loss on test= 0.007249750662595034\n",
      "acc for Lsat= 0.15493246899139074 \n",
      "acc for Psat= 0.19593047282131787 \n",
      "acc for optim= 0.17751028817347403\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.005594815127551556\n",
      "Loss on test= 0.00746356463059783\n",
      "acc for Lsat= 0.1584130393619817 \n",
      "acc for Psat= 0.19590011749828815 \n",
      "acc for optim= 0.17719392939375286\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.005904139950871468\n",
      "Loss on test= 0.007338089402765036\n",
      "acc for Lsat= 0.16394020354386693 \n",
      "acc for Psat= 0.19335003627156916 \n",
      "acc for optim= 0.18192897649972364\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.0057709477841854095\n",
      "Loss on test= 0.007489235606044531\n",
      "acc for Lsat= 0.15675139363213886 \n",
      "acc for Psat= 0.19088481291785042 \n",
      "acc for optim= 0.18499892105646126\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.005754292476922274\n",
      "Loss on test= 0.007085631135851145\n",
      "acc for Lsat= 0.16364173582338987 \n",
      "acc for Psat= 0.19985760313527445 \n",
      "acc for optim= 0.1765703789363081\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.00556291313841939\n",
      "Loss on test= 0.007113774307072163\n",
      "acc for Lsat= 0.16101104671528685 \n",
      "acc for Psat= 0.21244236742047073 \n",
      "acc for optim= 0.18025963182585433\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.005781043786555529\n",
      "Loss on test= 0.007666254881769419\n",
      "acc for Lsat= 0.15521926100339098 \n",
      "acc for Psat= 0.17461261421625243 \n",
      "acc for optim= 0.17635041051296152\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.005731872282922268\n",
      "Loss on test= 0.007110014092177153\n",
      "acc for Lsat= 0.16230253442615217 \n",
      "acc for Psat= 0.1996373893451671 \n",
      "acc for optim= 0.1797608816593057\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.005747892428189516\n",
      "Loss on test= 0.007494767662137747\n",
      "acc for Lsat= 0.1538944207751154 \n",
      "acc for Psat= 0.19792054366362358 \n",
      "acc for optim= 0.1743157778967737\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.005639052949845791\n",
      "Loss on test= 0.007082353811711073\n",
      "acc for Lsat= 0.16183946692388596 \n",
      "acc for Psat= 0.19312508403911394 \n",
      "acc for optim= 0.17560652300892454\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.005793588235974312\n",
      "Loss on test= 0.00695886230096221\n",
      "acc for Lsat= 0.165629832080344 \n",
      "acc for Psat= 0.20169549790386598 \n",
      "acc for optim= 0.1817986527771773\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.005661533679813147\n",
      "Loss on test= 0.006955285090953112\n",
      "acc for Lsat= 0.16084718604602652 \n",
      "acc for Psat= 0.2077893017110969 \n",
      "acc for optim= 0.18089173549669796\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.005779359955340624\n",
      "Loss on test= 0.00710114324465394\n",
      "acc for Lsat= 0.1564419536670044 \n",
      "acc for Psat= 0.20102518129049893 \n",
      "acc for optim= 0.18174017349174093\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.005722873844206333\n",
      "Loss on test= 0.007075021974742413\n",
      "acc for Lsat= 0.16107706186403598 \n",
      "acc for Psat= 0.19457773479755175 \n",
      "acc for optim= 0.18163090696917145\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.005625182297080755\n",
      "Loss on test= 0.007391714490950108\n",
      "acc for Lsat= 0.15732339550760102 \n",
      "acc for Psat= 0.17824482581097267 \n",
      "acc for optim= 0.17667370851258518\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.005894666537642479\n",
      "Loss on test= 0.00732436403632164\n",
      "acc for Lsat= 0.165116230964653 \n",
      "acc for Psat= 0.21312528063237074 \n",
      "acc for optim= 0.17542388854609406\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.005841796286404133\n",
      "Loss on test= 0.007321016862988472\n",
      "acc for Lsat= 0.164537249269254 \n",
      "acc for Psat= 0.20526269581436074 \n",
      "acc for optim= 0.1693627864566582\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.005534985102713108\n",
      "Loss on test= 0.007368434686213732\n",
      "acc for Lsat= 0.16133354445160786 \n",
      "acc for Psat= 0.19071862087487224 \n",
      "acc for optim= 0.186923696839472\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.005936162546277046\n",
      "Loss on test= 0.007249678019434214\n",
      "acc for Lsat= 0.16817917244005032 \n",
      "acc for Psat= 0.20278428217861802 \n",
      "acc for optim= 0.17503144604298973\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.006004751659929752\n",
      "Loss on test= 0.0072468603029847145\n",
      "acc for Lsat= 0.16153050368999086 \n",
      "acc for Psat= 0.19628821286367115 \n",
      "acc for optim= 0.187506320123889\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.006067453883588314\n",
      "Loss on test= 0.007276799064129591\n",
      "acc for Lsat= 0.15667350028133875 \n",
      "acc for Psat= 0.19675950053315916 \n",
      "acc for optim= 0.17235524363617305\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.005573382135480642\n",
      "Loss on test= 0.00736544094979763\n",
      "acc for Lsat= 0.16219776082670861 \n",
      "acc for Psat= 0.18385811425854268 \n",
      "acc for optim= 0.1805519005209284\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.005801432300359011\n",
      "Loss on test= 0.007288167718797922\n",
      "acc for Lsat= 0.17305826727889162 \n",
      "acc for Psat= 0.20334511303404187 \n",
      "acc for optim= 0.1766040145240144\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.005716055631637573\n",
      "Loss on test= 0.006973165087401867\n",
      "acc for Lsat= 0.1521980566564245 \n",
      "acc for Psat= 0.19286964669543105 \n",
      "acc for optim= 0.17420267645588344\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.005924222059547901\n",
      "Loss on test= 0.007268950808793306\n",
      "acc for Lsat= 0.1531922687257289 \n",
      "acc for Psat= 0.18994610849309895 \n",
      "acc for optim= 0.1782820988625868\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.006183834746479988\n",
      "Loss on test= 0.007098611444234848\n",
      "acc for Lsat= 0.1649599698251953 \n",
      "acc for Psat= 0.21115962591434478 \n",
      "acc for optim= 0.18018496490768768\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.005695119965821505\n",
      "Loss on test= 0.007259789388626814\n",
      "acc for Lsat= 0.14586283492991228 \n",
      "acc for Psat= 0.20261867727595764 \n",
      "acc for optim= 0.18105515727284746\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.0056279865093529224\n",
      "Loss on test= 0.00722150644287467\n",
      "acc for Lsat= 0.15035839252723535 \n",
      "acc for Psat= 0.1996692088688342 \n",
      "acc for optim= 0.17640879661423062\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.006504411343485117\n",
      "Loss on test= 0.007647598162293434\n",
      "acc for Lsat= 0.16817544793588926 \n",
      "acc for Psat= 0.19384955514516283 \n",
      "acc for optim= 0.18244492591980876\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.005969027057290077\n",
      "Loss on test= 0.0075277783907949924\n",
      "acc for Lsat= 0.1601793246962069 \n",
      "acc for Psat= 0.1859846769167935 \n",
      "acc for optim= 0.17988710538484157\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.0058823926374316216\n",
      "Loss on test= 0.007307456806302071\n",
      "acc for Lsat= 0.1457449380438164 \n",
      "acc for Psat= 0.2040376029563228 \n",
      "acc for optim= 0.17884834844821332\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.005674666725099087\n",
      "Loss on test= 0.007651173509657383\n",
      "acc for Lsat= 0.1687193210721474 \n",
      "acc for Psat= 0.19415592475234006 \n",
      "acc for optim= 0.17448343444829348\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.005516628734767437\n",
      "Loss on test= 0.007865493185818195\n",
      "acc for Lsat= 0.14676338986295168 \n",
      "acc for Psat= 0.2111464017838026 \n",
      "acc for optim= 0.17914716656907598\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.005694440566003323\n",
      "Loss on test= 0.007470997050404549\n",
      "acc for Lsat= 0.15877520706748866 \n",
      "acc for Psat= 0.18259025320456532 \n",
      "acc for optim= 0.17921694720328069\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.005601240787655115\n",
      "Loss on test= 0.007301559671759605\n",
      "acc for Lsat= 0.14792868540236787 \n",
      "acc for Psat= 0.1859863858736255 \n",
      "acc for optim= 0.17610228766923863\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.005612689070403576\n",
      "Loss on test= 0.007045583333820105\n",
      "acc for Lsat= 0.17507535638077734 \n",
      "acc for Psat= 0.195769054310007 \n",
      "acc for optim= 0.18157857651688677\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.005631673149764538\n",
      "Loss on test= 0.007276954594999552\n",
      "acc for Lsat= 0.15400630329271825 \n",
      "acc for Psat= 0.194690171333381 \n",
      "acc for optim= 0.17675112821419386\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.005548134446144104\n",
      "Loss on test= 0.007145934738218784\n",
      "acc for Lsat= 0.15286580244640197 \n",
      "acc for Psat= 0.20359211529807386 \n",
      "acc for optim= 0.17481277327312797\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.005438574589788914\n",
      "Loss on test= 0.0075784120708703995\n",
      "acc for Lsat= 0.1504339349716724 \n",
      "acc for Psat= 0.18056027546065065 \n",
      "acc for optim= 0.17339120011654546\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.005671016406267881\n",
      "Loss on test= 0.007509021088480949\n",
      "acc for Lsat= 0.1617165333802285 \n",
      "acc for Psat= 0.20306327125309492 \n",
      "acc for optim= 0.1774060038284811\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.005755597725510597\n",
      "Loss on test= 0.007014777977019548\n",
      "acc for Lsat= 0.15658991152695456 \n",
      "acc for Psat= 0.189552503652092 \n",
      "acc for optim= 0.1761107923873542\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.005697396583855152\n",
      "Loss on test= 0.007410457357764244\n",
      "acc for Lsat= 0.14893776446592338 \n",
      "acc for Psat= 0.17921550278093848 \n",
      "acc for optim= 0.17849471187724764\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.005622489377856255\n",
      "Loss on test= 0.007051081862300634\n",
      "acc for Lsat= 0.1423427780317219 \n",
      "acc for Psat= 0.1891664353837679 \n",
      "acc for optim= 0.17614431160456334\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.005755132529884577\n",
      "Loss on test= 0.007282223552465439\n",
      "acc for Lsat= 0.1472974976074317 \n",
      "acc for Psat= 0.19434791373825616 \n",
      "acc for optim= 0.17387276868408424\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.005567255429923534\n",
      "Loss on test= 0.007168952841311693\n",
      "acc for Lsat= 0.14360897699307165 \n",
      "acc for Psat= 0.19737365979426463 \n",
      "acc for optim= 0.1796931693109027\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.005582558922469616\n",
      "Loss on test= 0.007152363657951355\n",
      "acc for Lsat= 0.14889954118455043 \n",
      "acc for Psat= 0.17704856286939905 \n",
      "acc for optim= 0.17871444459134317\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.005532470531761646\n",
      "Loss on test= 0.006952866446226835\n",
      "acc for Lsat= 0.1559693640883302 \n",
      "acc for Psat= 0.21163934048758554 \n",
      "acc for optim= 0.17917995228518954\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.005605698563158512\n",
      "Loss on test= 0.007394143380224705\n",
      "acc for Lsat= 0.15979669426308304 \n",
      "acc for Psat= 0.18934196640859496 \n",
      "acc for optim= 0.17188729893790222\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.005593043752014637\n",
      "Loss on test= 0.007543839979916811\n",
      "acc for Lsat= 0.1588256132025577 \n",
      "acc for Psat= 0.2135691864576313 \n",
      "acc for optim= 0.18269550467490173\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.00589189026504755\n",
      "Loss on test= 0.007424445822834969\n",
      "acc for Lsat= 0.16879211886037812 \n",
      "acc for Psat= 0.19305217046444267 \n",
      "acc for optim= 0.1757353534505962\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.005722433794289827\n",
      "Loss on test= 0.007211086340248585\n",
      "acc for Lsat= 0.152377548942497 \n",
      "acc for Psat= 0.18405271030573145 \n",
      "acc for optim= 0.17533766384614388\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.005464508198201656\n",
      "Loss on test= 0.0070334747433662415\n",
      "acc for Lsat= 0.1625316509465519 \n",
      "acc for Psat= 0.1883672984652832 \n",
      "acc for optim= 0.16957674928405037\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.005331253167241812\n",
      "Loss on test= 0.007448398042470217\n",
      "acc for Lsat= 0.16025267699738147 \n",
      "acc for Psat= 0.19702527363112837 \n",
      "acc for optim= 0.18478844543598347\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.005537997465580702\n",
      "Loss on test= 0.007155062165111303\n",
      "acc for Lsat= 0.1533332154697254 \n",
      "acc for Psat= 0.1859214799984389 \n",
      "acc for optim= 0.1791312543552805\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.005678131245076656\n",
      "Loss on test= 0.007454346865415573\n",
      "acc for Lsat= 0.1543528217548451 \n",
      "acc for Psat= 0.18819272538807366 \n",
      "acc for optim= 0.17902478749680592\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.005586712155491114\n",
      "Loss on test= 0.0074292621575295925\n",
      "acc for Lsat= 0.16093291542912666 \n",
      "acc for Psat= 0.1780149057431177 \n",
      "acc for optim= 0.18046118580845003\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.005564084276556969\n",
      "Loss on test= 0.007164730224758387\n",
      "acc for Lsat= 0.16220745343961143 \n",
      "acc for Psat= 0.21132807339900403 \n",
      "acc for optim= 0.17934171944955882\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.005933649837970734\n",
      "Loss on test= 0.007476179860532284\n",
      "acc for Lsat= 0.15277657647832815 \n",
      "acc for Psat= 0.19497955157994062 \n",
      "acc for optim= 0.17467594535985093\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.0056003485806286335\n",
      "Loss on test= 0.007081055082380772\n",
      "acc for Lsat= 0.15869290334416827 \n",
      "acc for Psat= 0.1871359791906291 \n",
      "acc for optim= 0.18439995000618614\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.00579510722309351\n",
      "Loss on test= 0.007553641684353352\n",
      "acc for Lsat= 0.1559550950159407 \n",
      "acc for Psat= 0.18620620564382034 \n",
      "acc for optim= 0.18345034221734957\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.0059328144416213036\n",
      "Loss on test= 0.007382410112768412\n",
      "acc for Lsat= 0.16420372419224358 \n",
      "acc for Psat= 0.1816234673197824 \n",
      "acc for optim= 0.18157383480450887\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.005945530720055103\n",
      "Loss on test= 0.007425590418279171\n",
      "acc for Lsat= 0.17095424489828578 \n",
      "acc for Psat= 0.20035655823055287 \n",
      "acc for optim= 0.1774763357795519\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.005536720156669617\n",
      "Loss on test= 0.007082701660692692\n",
      "acc for Lsat= 0.15562431460750273 \n",
      "acc for Psat= 0.17901129402338573 \n",
      "acc for optim= 0.1813410371329185\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.005656364839524031\n",
      "Loss on test= 0.007336055394262075\n",
      "acc for Lsat= 0.14720157121105854 \n",
      "acc for Psat= 0.1918588572858306 \n",
      "acc for optim= 0.18278380461816282\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.005378070753067732\n",
      "Loss on test= 0.007171588018536568\n",
      "acc for Lsat= 0.1529866080108761 \n",
      "acc for Psat= 0.1790035283751929 \n",
      "acc for optim= 0.17689821016249538\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.005884964019060135\n",
      "Loss on test= 0.006974680814892054\n",
      "acc for Lsat= 0.15460878098001857 \n",
      "acc for Psat= 0.18729141354102824 \n",
      "acc for optim= 0.1772547836591524\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.005618410650640726\n",
      "Loss on test= 0.007112876046448946\n",
      "acc for Lsat= 0.16687671019023925 \n",
      "acc for Psat= 0.18987946612836762 \n",
      "acc for optim= 0.18075813699254126\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.005639842711389065\n",
      "Loss on test= 0.006991911679506302\n",
      "acc for Lsat= 0.147573876396188 \n",
      "acc for Psat= 0.19227472013039096 \n",
      "acc for optim= 0.1793456580358191\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.00555149232968688\n",
      "Loss on test= 0.00700785918161273\n",
      "acc for Lsat= 0.16205865399784133 \n",
      "acc for Psat= 0.1765824811931005 \n",
      "acc for optim= 0.18611592504646263\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.005479888059198856\n",
      "Loss on test= 0.007079135626554489\n",
      "acc for Lsat= 0.15908785055498365 \n",
      "acc for Psat= 0.19649291139279232 \n",
      "acc for optim= 0.18408521479396456\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.005565721541643143\n",
      "Loss on test= 0.007302859798073769\n",
      "acc for Lsat= 0.15934141471210989 \n",
      "acc for Psat= 0.17561639004280089 \n",
      "acc for optim= 0.1785322243718003\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.00557011878117919\n",
      "Loss on test= 0.0070414370857179165\n",
      "acc for Lsat= 0.1625952913303722 \n",
      "acc for Psat= 0.1964238728091243 \n",
      "acc for optim= 0.17583109260374274\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.005605827085673809\n",
      "Loss on test= 0.007108239457011223\n",
      "acc for Lsat= 0.1577133404518493 \n",
      "acc for Psat= 0.2020806300881334 \n",
      "acc for optim= 0.17802787241067922\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.005777503829449415\n",
      "Loss on test= 0.007111788727343082\n",
      "acc for Lsat= 0.1561520136775426 \n",
      "acc for Psat= 0.1910409567460535 \n",
      "acc for optim= 0.18254430582708694\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.005556982010602951\n",
      "Loss on test= 0.0073332651518285275\n",
      "acc for Lsat= 0.15582711538299918 \n",
      "acc for Psat= 0.18734934443501053 \n",
      "acc for optim= 0.18266085495649395\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.005632112734019756\n",
      "Loss on test= 0.0069661266170442104\n",
      "acc for Lsat= 0.15853227312279652 \n",
      "acc for Psat= 0.1933622248883008 \n",
      "acc for optim= 0.17415440843102692\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.006019541062414646\n",
      "Loss on test= 0.007254021242260933\n",
      "acc for Lsat= 0.16608507029944078 \n",
      "acc for Psat= 0.18744793771966514 \n",
      "acc for optim= 0.17162577321325415\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.00558754988014698\n",
      "Loss on test= 0.00721929594874382\n",
      "acc for Lsat= 0.1588248051634272 \n",
      "acc for Psat= 0.19691057769261056 \n",
      "acc for optim= 0.17998210193558795\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.005475388839840889\n",
      "Loss on test= 0.0067509752698242664\n",
      "acc for Lsat= 0.15536818703747218 \n",
      "acc for Psat= 0.1810471197991006 \n",
      "acc for optim= 0.17786180259942336\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.005689469166100025\n",
      "Loss on test= 0.00697383563965559\n",
      "acc for Lsat= 0.1575725493429121 \n",
      "acc for Psat= 0.19605683175098823 \n",
      "acc for optim= 0.1751953236571681\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.005656885448843241\n",
      "Loss on test= 0.007776229176670313\n",
      "acc for Lsat= 0.16540572339619727 \n",
      "acc for Psat= 0.17286366730371155 \n",
      "acc for optim= 0.17794758643340472\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.00575160700827837\n",
      "Loss on test= 0.0070559862069785595\n",
      "acc for Lsat= 0.15352582544153728 \n",
      "acc for Psat= 0.19704041121294721 \n",
      "acc for optim= 0.1802570810611169\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.0057677822187542915\n",
      "Loss on test= 0.007021594326943159\n",
      "acc for Lsat= 0.15037435146776737 \n",
      "acc for Psat= 0.18903998465026295 \n",
      "acc for optim= 0.18117947203095727\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.005290278699249029\n",
      "Loss on test= 0.007218500133603811\n",
      "acc for Lsat= 0.16870634517838537 \n",
      "acc for Psat= 0.186252391704007 \n",
      "acc for optim= 0.18098174451838903\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.005669404752552509\n",
      "Loss on test= 0.007247644942253828\n",
      "acc for Lsat= 0.1527810830920152 \n",
      "acc for Psat= 0.19311445352991616 \n",
      "acc for optim= 0.1685878092054751\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.005592533387243748\n",
      "Loss on test= 0.007334818597882986\n",
      "acc for Lsat= 0.15875439567884553 \n",
      "acc for Psat= 0.194575777286511 \n",
      "acc for optim= 0.18423376411790174\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.005532440263777971\n",
      "Loss on test= 0.006682456936687231\n",
      "acc for Lsat= 0.16107078386150056 \n",
      "acc for Psat= 0.18986020260318717 \n",
      "acc for optim= 0.17412331223575642\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.005918276961892843\n",
      "Loss on test= 0.007278833072632551\n",
      "acc for Lsat= 0.15372607499975857 \n",
      "acc for Psat= 0.19765304715685608 \n",
      "acc for optim= 0.1787452723079487\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.005842879414558411\n",
      "Loss on test= 0.007028879132121801\n",
      "acc for Lsat= 0.1487665188405281 \n",
      "acc for Psat= 0.17621441037226163 \n",
      "acc for optim= 0.17971112488470323\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.00539419986307621\n",
      "Loss on test= 0.007370833307504654\n",
      "acc for Lsat= 0.15626972851221313 \n",
      "acc for Psat= 0.18291438041630842 \n",
      "acc for optim= 0.17472266334230194\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.005484747234731913\n",
      "Loss on test= 0.0070507340133190155\n",
      "acc for Lsat= 0.16402223292646595 \n",
      "acc for Psat= 0.19139029314587863 \n",
      "acc for optim= 0.1758756542277759\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.005474473349750042\n",
      "Loss on test= 0.007144616916775703\n",
      "acc for Lsat= 0.1529130742759215 \n",
      "acc for Psat= 0.17777567535493768 \n",
      "acc for optim= 0.1758346671986653\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.005330693908035755\n",
      "Loss on test= 0.00762949138879776\n",
      "acc for Lsat= 0.15519971962369067 \n",
      "acc for Psat= 0.18263985255406787 \n",
      "acc for optim= 0.16960662045586686\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.005833194591104984\n",
      "Loss on test= 0.007233478128910065\n",
      "acc for Lsat= 0.16583188485552663 \n",
      "acc for Psat= 0.18942658920512587 \n",
      "acc for optim= 0.17722710503616415\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.005771622993052006\n",
      "Loss on test= 0.006987033877521753\n",
      "acc for Lsat= 0.14836511849082212 \n",
      "acc for Psat= 0.1906387364157842 \n",
      "acc for optim= 0.1719726966817331\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.005333899520337582\n",
      "Loss on test= 0.006765965837985277\n",
      "acc for Lsat= 0.1677721290712695 \n",
      "acc for Psat= 0.19396737409759404 \n",
      "acc for optim= 0.1781955280226701\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.005773799028247595\n",
      "Loss on test= 0.007466023787856102\n",
      "acc for Lsat= 0.1652238425338778 \n",
      "acc for Psat= 0.20028018379740448 \n",
      "acc for optim= 0.17665237308533283\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.005446760915219784\n",
      "Loss on test= 0.007145111449062824\n",
      "acc for Lsat= 0.168373457878183 \n",
      "acc for Psat= 0.1988510354009808 \n",
      "acc for optim= 0.18157675733702014\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.005381996743381023\n",
      "Loss on test= 0.006820552051067352\n",
      "acc for Lsat= 0.15470601359847932 \n",
      "acc for Psat= 0.1931992257891803 \n",
      "acc for optim= 0.18530726247117854\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.00554351881146431\n",
      "Loss on test= 0.007375992368906736\n",
      "acc for Lsat= 0.15239358731931013 \n",
      "acc for Psat= 0.1834970045336675 \n",
      "acc for optim= 0.17231694582513854\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.005497756414115429\n",
      "Loss on test= 0.007356069982051849\n",
      "acc for Lsat= 0.15711702015787674 \n",
      "acc for Psat= 0.19561957906546132 \n",
      "acc for optim= 0.16762880959021326\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.00574322696775198\n",
      "Loss on test= 0.006889957468956709\n",
      "acc for Lsat= 0.15477290373857583 \n",
      "acc for Psat= 0.17799923935195155 \n",
      "acc for optim= 0.18288631863590543\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.005596930626779795\n",
      "Loss on test= 0.007247637026011944\n",
      "acc for Lsat= 0.158068267963674 \n",
      "acc for Psat= 0.1991323353879184 \n",
      "acc for optim= 0.17464562504114317\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.0055058738216757774\n",
      "Loss on test= 0.007056681904941797\n",
      "acc for Lsat= 0.16977066700637805 \n",
      "acc for Psat= 0.19960927869432765 \n",
      "acc for optim= 0.18272573411937987\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.005405340809375048\n",
      "Loss on test= 0.006918920669704676\n",
      "acc for Lsat= 0.15836402179642778 \n",
      "acc for Psat= 0.18786597809922256 \n",
      "acc for optim= 0.17505790586316133\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.005536581389605999\n",
      "Loss on test= 0.007108761928975582\n",
      "acc for Lsat= 0.15616502109686003 \n",
      "acc for Psat= 0.19705837283476224 \n",
      "acc for optim= 0.17451835774529292\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.005616039969027042\n",
      "Loss on test= 0.0066527570597827435\n",
      "acc for Lsat= 0.15762521578132588 \n",
      "acc for Psat= 0.17591979874252173 \n",
      "acc for optim= 0.1744439497061425\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.005486384965479374\n",
      "Loss on test= 0.006580767221748829\n",
      "acc for Lsat= 0.1443749797614444 \n",
      "acc for Psat= 0.19689637772380145 \n",
      "acc for optim= 0.1800887393310941\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.00556448008865118\n",
      "Loss on test= 0.007290045730769634\n",
      "acc for Lsat= 0.17043517417098838 \n",
      "acc for Psat= 0.1904956808647706 \n",
      "acc for optim= 0.17961914786676778\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.006139672826975584\n",
      "Loss on test= 0.006847699172794819\n",
      "acc for Lsat= 0.15634642737334573 \n",
      "acc for Psat= 0.19783101576785023 \n",
      "acc for optim= 0.17935530286724582\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.005836498457938433\n",
      "Loss on test= 0.007075960282236338\n",
      "acc for Lsat= 0.15850100557980143 \n",
      "acc for Psat= 0.2004247266310649 \n",
      "acc for optim= 0.1795670717342024\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.005728927440941334\n",
      "Loss on test= 0.007207855582237244\n",
      "acc for Lsat= 0.15602386724747733 \n",
      "acc for Psat= 0.1816835650801086 \n",
      "acc for optim= 0.17402946539137315\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.005408154334872961\n",
      "Loss on test= 0.007273610681295395\n",
      "acc for Lsat= 0.17394784108781425 \n",
      "acc for Psat= 0.19152195292914317 \n",
      "acc for optim= 0.17758465146521377\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.005446870811283588\n",
      "Loss on test= 0.006979193538427353\n",
      "acc for Lsat= 0.1603704966597076 \n",
      "acc for Psat= 0.19316214327853112 \n",
      "acc for optim= 0.18015101183908153\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.005425668321549892\n",
      "Loss on test= 0.007346101570874453\n",
      "acc for Lsat= 0.14989173701099792 \n",
      "acc for Psat= 0.18935831289530397 \n",
      "acc for optim= 0.17519038098064618\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.005745531525462866\n",
      "Loss on test= 0.007218723651021719\n",
      "acc for Lsat= 0.16332200740876257 \n",
      "acc for Psat= 0.2043296755527215 \n",
      "acc for optim= 0.17681492741761698\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.005786489695310593\n",
      "Loss on test= 0.006887147668749094\n",
      "acc for Lsat= 0.1637655533641218 \n",
      "acc for Psat= 0.17375278285557602 \n",
      "acc for optim= 0.1768231925016391\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.005247543100267649\n",
      "Loss on test= 0.007012689486145973\n",
      "acc for Lsat= 0.15014660484558276 \n",
      "acc for Psat= 0.18716382767707415 \n",
      "acc for optim= 0.18047810513426008\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.005418241955339909\n",
      "Loss on test= 0.0069400169886648655\n",
      "acc for Lsat= 0.1547274622547089 \n",
      "acc for Psat= 0.17267669123410415 \n",
      "acc for optim= 0.18072039975716014\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.005308200605213642\n",
      "Loss on test= 0.007416184060275555\n",
      "acc for Lsat= 0.15966417860567997 \n",
      "acc for Psat= 0.18889862938772015 \n",
      "acc for optim= 0.17381258955476786\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.005302904173731804\n",
      "Loss on test= 0.007282787933945656\n",
      "acc for Lsat= 0.1639794996446743 \n",
      "acc for Psat= 0.19158157080242058 \n",
      "acc for optim= 0.17588911100460566\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.0053547220304608345\n",
      "Loss on test= 0.00710931234061718\n",
      "acc for Lsat= 0.14805757489120283 \n",
      "acc for Psat= 0.18850199305051632 \n",
      "acc for optim= 0.1768974769558017\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.005549500230699778\n",
      "Loss on test= 0.007060715463012457\n",
      "acc for Lsat= 0.15690344825165622 \n",
      "acc for Psat= 0.1916810327690461 \n",
      "acc for optim= 0.18369373396510397\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.005300584249198437\n",
      "Loss on test= 0.00739668682217598\n",
      "acc for Lsat= 0.17266731794272763 \n",
      "acc for Psat= 0.18437474766296724 \n",
      "acc for optim= 0.17731263182282478\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.005399846471846104\n",
      "Loss on test= 0.00673958845436573\n",
      "acc for Lsat= 0.15011604028719583 \n",
      "acc for Psat= 0.17367567139616633 \n",
      "acc for optim= 0.17416816161006507\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.005432404577732086\n",
      "Loss on test= 0.006775699555873871\n",
      "acc for Lsat= 0.15988436118903815 \n",
      "acc for Psat= 0.18192469729912147 \n",
      "acc for optim= 0.17618623734585423\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.005267237313091755\n",
      "Loss on test= 0.006666223984211683\n",
      "acc for Lsat= 0.16075560883599807 \n",
      "acc for Psat= 0.1846459691637944 \n",
      "acc for optim= 0.17392221013452386\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.005592770408838987\n",
      "Loss on test= 0.007087530102580786\n",
      "acc for Lsat= 0.14935612063654546 \n",
      "acc for Psat= 0.1890064974687612 \n",
      "acc for optim= 0.17504133487861703\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.005205259658396244\n",
      "Loss on test= 0.0069844103418290615\n",
      "acc for Lsat= 0.14858229850632612 \n",
      "acc for Psat= 0.18818245603412878 \n",
      "acc for optim= 0.17428320511244239\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.005334923509508371\n",
      "Loss on test= 0.00691990926861763\n",
      "acc for Lsat= 0.14631701594535415 \n",
      "acc for Psat= 0.1809767299064542 \n",
      "acc for optim= 0.17876882291147028\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.005617120303213596\n",
      "Loss on test= 0.007453293073922396\n",
      "acc for Lsat= 0.15889809398614174 \n",
      "acc for Psat= 0.18685640780648877 \n",
      "acc for optim= 0.17532142465917458\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.005358460359275341\n",
      "Loss on test= 0.007204574998468161\n",
      "acc for Lsat= 0.1458534062897298 \n",
      "acc for Psat= 0.1788925289527559 \n",
      "acc for optim= 0.17636361139832202\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.005474607460200787\n",
      "Loss on test= 0.006897410377860069\n",
      "acc for Lsat= 0.1528992330418808 \n",
      "acc for Psat= 0.18657919260869796 \n",
      "acc for optim= 0.1834262220711413\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.005419358145445585\n",
      "Loss on test= 0.007293259724974632\n",
      "acc for Lsat= 0.16459780111605946 \n",
      "acc for Psat= 0.19370860435206017 \n",
      "acc for optim= 0.16832283348022564\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.005285336636006832\n",
      "Loss on test= 0.007252995856106281\n",
      "acc for Lsat= 0.15682811817826062 \n",
      "acc for Psat= 0.18990350813380738 \n",
      "acc for optim= 0.173529790601403\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.005300640128552914\n",
      "Loss on test= 0.007103468291461468\n",
      "acc for Lsat= 0.14257033306706438 \n",
      "acc for Psat= 0.19676829952227531 \n",
      "acc for optim= 0.18240909725482496\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.005317266099154949\n",
      "Loss on test= 0.007141913753002882\n",
      "acc for Lsat= 0.15367020745341833 \n",
      "acc for Psat= 0.18553141935188877 \n",
      "acc for optim= 0.17690018384281325\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.00591373723000288\n",
      "Loss on test= 0.007450035773217678\n",
      "acc for Lsat= 0.1517622949532615 \n",
      "acc for Psat= 0.17899854387687214 \n",
      "acc for optim= 0.18216630015713087\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.005480484571307898\n",
      "Loss on test= 0.006851903162896633\n",
      "acc for Lsat= 0.14468526715216165 \n",
      "acc for Psat= 0.1977714725151719 \n",
      "acc for optim= 0.17731949428750535\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.0061891162768006325\n",
      "Loss on test= 0.007335349451750517\n",
      "acc for Lsat= 0.13827183983435656 \n",
      "acc for Psat= 0.18742756029270344 \n",
      "acc for optim= 0.1785336457572679\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.005378963425755501\n",
      "Loss on test= 0.007168355397880077\n",
      "acc for Lsat= 0.15444311706080163 \n",
      "acc for Psat= 0.19190609446520626 \n",
      "acc for optim= 0.17999555064006478\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.005371483974158764\n",
      "Loss on test= 0.007246843073517084\n",
      "acc for Lsat= 0.15037518262435667 \n",
      "acc for Psat= 0.18859052794069597 \n",
      "acc for optim= 0.174516642583891\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.0058478498831391335\n",
      "Loss on test= 0.007212014868855476\n",
      "acc for Lsat= 0.1672715803654101 \n",
      "acc for Psat= 0.17779626873861923 \n",
      "acc for optim= 0.17382463313272742\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.005453334655612707\n",
      "Loss on test= 0.007262657396495342\n",
      "acc for Lsat= 0.1570251430449702 \n",
      "acc for Psat= 0.1914843831417441 \n",
      "acc for optim= 0.1724951703516484\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.005667544901371002\n",
      "Loss on test= 0.0074950032867491245\n",
      "acc for Lsat= 0.14660605309439487 \n",
      "acc for Psat= 0.18695115756041172 \n",
      "acc for optim= 0.1752487181222112\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.005363610573112965\n",
      "Loss on test= 0.007246736437082291\n",
      "acc for Lsat= 0.1605680972151649 \n",
      "acc for Psat= 0.18964569895910782 \n",
      "acc for optim= 0.17356316660889654\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.005442268680781126\n",
      "Loss on test= 0.007561238016933203\n",
      "acc for Lsat= 0.15405575674710428 \n",
      "acc for Psat= 0.18344018558597527 \n",
      "acc for optim= 0.17938254165299022\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.005415816325694323\n",
      "Loss on test= 0.007431922946125269\n",
      "acc for Lsat= 0.15595866185422133 \n",
      "acc for Psat= 0.1848953204898385 \n",
      "acc for optim= 0.1784871982662465\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.005335019435733557\n",
      "Loss on test= 0.007165675982832909\n",
      "acc for Lsat= 0.1598231876482729 \n",
      "acc for Psat= 0.20135935098085492 \n",
      "acc for optim= 0.1805486534996966\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.005710816942155361\n",
      "Loss on test= 0.007008912041783333\n",
      "acc for Lsat= 0.14699426596305815 \n",
      "acc for Psat= 0.1875990716786292 \n",
      "acc for optim= 0.17767759361991384\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.005683640018105507\n",
      "Loss on test= 0.007195031736046076\n",
      "acc for Lsat= 0.1512845292487029 \n",
      "acc for Psat= 0.18426871496103855 \n",
      "acc for optim= 0.1741514007847176\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.005668566562235355\n",
      "Loss on test= 0.0071671102195978165\n",
      "acc for Lsat= 0.16927121200364514 \n",
      "acc for Psat= 0.1838684728472173 \n",
      "acc for optim= 0.1713433510669675\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.0053815683349967\n",
      "Loss on test= 0.007113446481525898\n",
      "acc for Lsat= 0.15762530290712526 \n",
      "acc for Psat= 0.18001704132718752 \n",
      "acc for optim= 0.1818856507326003\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.005405298434197903\n",
      "Loss on test= 0.006630241870880127\n",
      "acc for Lsat= 0.1569387975667 \n",
      "acc for Psat= 0.18949849722438422 \n",
      "acc for optim= 0.18033351834050426\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.005333926063030958\n",
      "Loss on test= 0.007043206132948399\n",
      "acc for Lsat= 0.14559581739528366 \n",
      "acc for Psat= 0.1731375946914758 \n",
      "acc for optim= 0.18034209922666006\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.005687358323484659\n",
      "Loss on test= 0.007353679277002811\n",
      "acc for Lsat= 0.14991251619789867 \n",
      "acc for Psat= 0.17709475372541986 \n",
      "acc for optim= 0.17945294621587563\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.005563194397836924\n",
      "Loss on test= 0.007395593449473381\n",
      "acc for Lsat= 0.15589201357062968 \n",
      "acc for Psat= 0.17911477915935034 \n",
      "acc for optim= 0.174523932139435\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.005268387030810118\n",
      "Loss on test= 0.006989475805312395\n",
      "acc for Lsat= 0.15215594665048124 \n",
      "acc for Psat= 0.1829493402784927 \n",
      "acc for optim= 0.17808817002700916\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.005597696639597416\n",
      "Loss on test= 0.007075798232108355\n",
      "acc for Lsat= 0.14995431964968897 \n",
      "acc for Psat= 0.17835058693728242 \n",
      "acc for optim= 0.17698255622507547\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.005300885532051325\n",
      "Loss on test= 0.006816449575126171\n",
      "acc for Lsat= 0.15425281744320557 \n",
      "acc for Psat= 0.17480248352703562 \n",
      "acc for optim= 0.17240402901766547\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.0054493797942996025\n",
      "Loss on test= 0.006966844201087952\n",
      "acc for Lsat= 0.16854294232962572 \n",
      "acc for Psat= 0.19428639284403781 \n",
      "acc for optim= 0.17813933945306745\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.005295848473906517\n",
      "Loss on test= 0.007222691550850868\n",
      "acc for Lsat= 0.1547466905138715 \n",
      "acc for Psat= 0.1887904420502667 \n",
      "acc for optim= 0.17740227831456024\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.0054323505610227585\n",
      "Loss on test= 0.007330469321459532\n",
      "acc for Lsat= 0.1566774642274364 \n",
      "acc for Psat= 0.18096721060851972 \n",
      "acc for optim= 0.179148193066329\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.005269236396998167\n",
      "Loss on test= 0.006989561952650547\n",
      "acc for Lsat= 0.15418090901364281 \n",
      "acc for Psat= 0.1920852088812189 \n",
      "acc for optim= 0.1897773013503642\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.005398160312324762\n",
      "Loss on test= 0.00708352867513895\n",
      "acc for Lsat= 0.154233347035975 \n",
      "acc for Psat= 0.1969001050626279 \n",
      "acc for optim= 0.17939563789061408\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.005392092280089855\n",
      "Loss on test= 0.007127080112695694\n",
      "acc for Lsat= 0.16031230963102436 \n",
      "acc for Psat= 0.17186376934539008 \n",
      "acc for optim= 0.18046208482319642\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.005481854546815157\n",
      "Loss on test= 0.006906215567141771\n",
      "acc for Lsat= 0.15576389288858006 \n",
      "acc for Psat= 0.19584057757527887 \n",
      "acc for optim= 0.1794466432806135\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.005399782210588455\n",
      "Loss on test= 0.007178172003477812\n",
      "acc for Lsat= 0.15679272520126866 \n",
      "acc for Psat= 0.19258893011137843 \n",
      "acc for optim= 0.1775473899053425\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.00551400613039732\n",
      "Loss on test= 0.007116341032087803\n",
      "acc for Lsat= 0.1587627219968021 \n",
      "acc for Psat= 0.17565846961281706 \n",
      "acc for optim= 0.17687809923950001\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.006493750028312206\n",
      "Loss on test= 0.006692965980619192\n",
      "acc for Lsat= 0.15659376664285654 \n",
      "acc for Psat= 0.18840961356028976 \n",
      "acc for optim= 0.17368752581189523\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.005936170928180218\n",
      "Loss on test= 0.006942518521100283\n",
      "acc for Lsat= 0.1497048281682808 \n",
      "acc for Psat= 0.1893127492468682 \n",
      "acc for optim= 0.17625063724728057\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.006623976863920689\n",
      "Loss on test= 0.007258175872266293\n",
      "acc for Lsat= 0.15411749640904313 \n",
      "acc for Psat= 0.17575291082163755 \n",
      "acc for optim= 0.1815657807384297\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.005509686656296253\n",
      "Loss on test= 0.007288005668669939\n",
      "acc for Lsat= 0.15180298082347288 \n",
      "acc for Psat= 0.1942395354698166 \n",
      "acc for optim= 0.1857102786689867\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.005537727382034063\n",
      "Loss on test= 0.006830101367086172\n",
      "acc for Lsat= 0.15046368715755037 \n",
      "acc for Psat= 0.2102291604916214 \n",
      "acc for optim= 0.17285004622135006\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.005393092520534992\n",
      "Loss on test= 0.006783693563193083\n",
      "acc for Lsat= 0.15714778467768528 \n",
      "acc for Psat= 0.18544050026455985 \n",
      "acc for optim= 0.17365826480896937\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.005592675413936377\n",
      "Loss on test= 0.0071623739786446095\n",
      "acc for Lsat= 0.15213421885626482 \n",
      "acc for Psat= 0.18959777146486229 \n",
      "acc for optim= 0.18040288763242912\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.005447475705295801\n",
      "Loss on test= 0.00689710071310401\n",
      "acc for Lsat= 0.14620279791406127 \n",
      "acc for Psat= 0.19294373461180825 \n",
      "acc for optim= 0.17354108758908163\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.005308191291987896\n",
      "Loss on test= 0.007082040421664715\n",
      "acc for Lsat= 0.1547564261778044 \n",
      "acc for Psat= 0.21370969788232422 \n",
      "acc for optim= 0.17462453903462433\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.005459919106215239\n",
      "Loss on test= 0.007062600925564766\n",
      "acc for Lsat= 0.1557409235051085 \n",
      "acc for Psat= 0.1813440281006538 \n",
      "acc for optim= 0.17599350274674075\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.005266740918159485\n",
      "Loss on test= 0.007381490897387266\n",
      "acc for Lsat= 0.16423731216961387 \n",
      "acc for Psat= 0.19426849025881804 \n",
      "acc for optim= 0.17216932070193447\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.005200553685426712\n",
      "Loss on test= 0.007210645359009504\n",
      "acc for Lsat= 0.1458912527930747 \n",
      "acc for Psat= 0.19612645130627407 \n",
      "acc for optim= 0.1818416840488427\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.005324493162333965\n",
      "Loss on test= 0.006814983207732439\n",
      "acc for Lsat= 0.16246950288921533 \n",
      "acc for Psat= 0.18166291761502135 \n",
      "acc for optim= 0.17923250369738108\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.005713062360882759\n",
      "Loss on test= 0.006954430136829615\n",
      "acc for Lsat= 0.16341422044091905 \n",
      "acc for Psat= 0.1878929356631697 \n",
      "acc for optim= 0.17908092079413138\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.00532067334279418\n",
      "Loss on test= 0.006979484111070633\n",
      "acc for Lsat= 0.15913365707526625 \n",
      "acc for Psat= 0.18002050386295182 \n",
      "acc for optim= 0.17537389630283617\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.005593470297753811\n",
      "Loss on test= 0.007162717171013355\n",
      "acc for Lsat= 0.1537982773799144 \n",
      "acc for Psat= 0.1799314119059165 \n",
      "acc for optim= 0.17974907697389425\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.005466056987643242\n",
      "Loss on test= 0.00749081140384078\n",
      "acc for Lsat= 0.14530076191776822 \n",
      "acc for Psat= 0.19036150210953057 \n",
      "acc for optim= 0.17652300150429717\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.005318158306181431\n",
      "Loss on test= 0.006745125167071819\n",
      "acc for Lsat= 0.15548453046737495 \n",
      "acc for Psat= 0.20337728742036784 \n",
      "acc for optim= 0.179937883952373\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.006400597747415304\n",
      "Loss on test= 0.007230602204799652\n",
      "acc for Lsat= 0.15755977492896864 \n",
      "acc for Psat= 0.20668098642657792 \n",
      "acc for optim= 0.17464703329734801\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.005501777399331331\n",
      "Loss on test= 0.007211857941001654\n",
      "acc for Lsat= 0.1555885486291401 \n",
      "acc for Psat= 0.18407056796241392 \n",
      "acc for optim= 0.17884072755371816\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.005825151689350605\n",
      "Loss on test= 0.0070373318158090115\n",
      "acc for Lsat= 0.14969586416445368 \n",
      "acc for Psat= 0.18009113335798754 \n",
      "acc for optim= 0.1739057966446901\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.005933734588325024\n",
      "Loss on test= 0.007257841527462006\n",
      "acc for Lsat= 0.1600637184035178 \n",
      "acc for Psat= 0.19142606988220978 \n",
      "acc for optim= 0.17730565225709322\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.005502886138856411\n",
      "Loss on test= 0.00689083943143487\n",
      "acc for Lsat= 0.15041055074648657 \n",
      "acc for Psat= 0.20935652815702477 \n",
      "acc for optim= 0.17794599401455402\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.00545861292630434\n",
      "Loss on test= 0.006963834632188082\n",
      "acc for Lsat= 0.15067493185786468 \n",
      "acc for Psat= 0.1731066498729843 \n",
      "acc for optim= 0.18356905819461242\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.005302581004798412\n",
      "Loss on test= 0.007033038418740034\n",
      "acc for Lsat= 0.15807903132317436 \n",
      "acc for Psat= 0.20003560935626008 \n",
      "acc for optim= 0.18096037924911856\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.0053400881588459015\n",
      "Loss on test= 0.0071804639883339405\n",
      "acc for Lsat= 0.14634453066716308 \n",
      "acc for Psat= 0.1821501912262871 \n",
      "acc for optim= 0.1775400887850336\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.005602264776825905\n",
      "Loss on test= 0.006976188626140356\n",
      "acc for Lsat= 0.15122063713411601 \n",
      "acc for Psat= 0.19021646332218298 \n",
      "acc for optim= 0.17662973858964282\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.0051311529241502285\n",
      "Loss on test= 0.007023931946605444\n",
      "acc for Lsat= 0.15482268383016534 \n",
      "acc for Psat= 0.18031560160051727 \n",
      "acc for optim= 0.17465163019789215\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.005323310382664204\n",
      "Loss on test= 0.007036547642201185\n",
      "acc for Lsat= 0.15162165982030393 \n",
      "acc for Psat= 0.18639271115067368 \n",
      "acc for optim= 0.1834671872279957\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.005562651436775923\n",
      "Loss on test= 0.006471363361924887\n",
      "acc for Lsat= 0.16575178941158333 \n",
      "acc for Psat= 0.18079095931158815 \n",
      "acc for optim= 0.17137496612688025\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.005500719882547855\n",
      "Loss on test= 0.006942218169569969\n",
      "acc for Lsat= 0.1616046277172558 \n",
      "acc for Psat= 0.18466838801157523 \n",
      "acc for optim= 0.17736398689334326\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.005154692102223635\n",
      "Loss on test= 0.00717199919745326\n",
      "acc for Lsat= 0.14588213229349617 \n",
      "acc for Psat= 0.17402578984934944 \n",
      "acc for optim= 0.17284982832698303\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.005635146517306566\n",
      "Loss on test= 0.006928089074790478\n",
      "acc for Lsat= 0.15695037321286795 \n",
      "acc for Psat= 0.20401136452975285 \n",
      "acc for optim= 0.17585912349385296\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.005203901790082455\n",
      "Loss on test= 0.007074481341987848\n",
      "acc for Lsat= 0.149949224712184 \n",
      "acc for Psat= 0.17133871063160172 \n",
      "acc for optim= 0.1754398548157817\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.0055679576471447945\n",
      "Loss on test= 0.007099969312548637\n",
      "acc for Lsat= 0.15847771708103522 \n",
      "acc for Psat= 0.18109475750853996 \n",
      "acc for optim= 0.1708124022472833\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.005494006909430027\n",
      "Loss on test= 0.006984113249927759\n",
      "acc for Lsat= 0.16124219729929598 \n",
      "acc for Psat= 0.19955884313332986 \n",
      "acc for optim= 0.16776067848741\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.005378182046115398\n",
      "Loss on test= 0.006878448650240898\n",
      "acc for Lsat= 0.15207414065438063 \n",
      "acc for Psat= 0.1830508445561329 \n",
      "acc for optim= 0.17484236952636895\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.005393308587372303\n",
      "Loss on test= 0.006994897965341806\n",
      "acc for Lsat= 0.16410933770392028 \n",
      "acc for Psat= 0.1867951850063305 \n",
      "acc for optim= 0.16913716737012766\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.005424214992672205\n",
      "Loss on test= 0.007205570582300425\n",
      "acc for Lsat= 0.16344215466972958 \n",
      "acc for Psat= 0.18781573273256788 \n",
      "acc for optim= 0.17980521674569483\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.0056621721014380455\n",
      "Loss on test= 0.007006140425801277\n",
      "acc for Lsat= 0.15502987292721165 \n",
      "acc for Psat= 0.19240603302242845 \n",
      "acc for optim= 0.1807737248512672\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.005635097622871399\n",
      "Loss on test= 0.006894226651638746\n",
      "acc for Lsat= 0.1568450563363483 \n",
      "acc for Psat= 0.18390979593062437 \n",
      "acc for optim= 0.1682126317715719\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.005353243090212345\n",
      "Loss on test= 0.006879324093461037\n",
      "acc for Lsat= 0.15576519644475678 \n",
      "acc for Psat= 0.18577935726622302 \n",
      "acc for optim= 0.17385761644834363\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.005656707100570202\n",
      "Loss on test= 0.006899225525557995\n",
      "acc for Lsat= 0.14443675987918664 \n",
      "acc for Psat= 0.18512722931093284 \n",
      "acc for optim= 0.1752094234788378\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.005660699680447578\n",
      "Loss on test= 0.0069307126104831696\n",
      "acc for Lsat= 0.1522619606257172 \n",
      "acc for Psat= 0.19977377611517785 \n",
      "acc for optim= 0.17880702208914626\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.005550979170948267\n",
      "Loss on test= 0.007129419129341841\n",
      "acc for Lsat= 0.15119918060076773 \n",
      "acc for Psat= 0.18609989866515103 \n",
      "acc for optim= 0.17407562202529706\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.005424119997769594\n",
      "Loss on test= 0.007120329421013594\n",
      "acc for Lsat= 0.14867234962961834 \n",
      "acc for Psat= 0.18753566124751309 \n",
      "acc for optim= 0.17631744943944677\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.005222347564995289\n",
      "Loss on test= 0.007379197981208563\n",
      "acc for Lsat= 0.15322986211242215 \n",
      "acc for Psat= 0.19664827613007338 \n",
      "acc for optim= 0.18010241463589557\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.00537690008059144\n",
      "Loss on test= 0.007034860551357269\n",
      "acc for Lsat= 0.15254541982812655 \n",
      "acc for Psat= 0.1916549918050954 \n",
      "acc for optim= 0.1757175514762687\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.0056335218250751495\n",
      "Loss on test= 0.00719384616240859\n",
      "acc for Lsat= 0.16320469090486037 \n",
      "acc for Psat= 0.18231084098186956 \n",
      "acc for optim= 0.16902138344546566\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.005464389454573393\n",
      "Loss on test= 0.007118099834769964\n",
      "acc for Lsat= 0.15584397507549003 \n",
      "acc for Psat= 0.19138439507571958 \n",
      "acc for optim= 0.17449278726918074\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.005615157075226307\n",
      "Loss on test= 0.0069913058541715145\n",
      "acc for Lsat= 0.15103580543168316 \n",
      "acc for Psat= 0.1902076049413929 \n",
      "acc for optim= 0.18265600195230886\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.005346998106688261\n",
      "Loss on test= 0.007167453411966562\n",
      "acc for Lsat= 0.1502173819208945 \n",
      "acc for Psat= 0.1777063447356102 \n",
      "acc for optim= 0.17794079091991527\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.005550713278353214\n",
      "Loss on test= 0.007314024493098259\n",
      "acc for Lsat= 0.14854481566666825 \n",
      "acc for Psat= 0.1861043535409587 \n",
      "acc for optim= 0.17054671381359737\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.005410024896264076\n",
      "Loss on test= 0.006735122296959162\n",
      "acc for Lsat= 0.15255127367940463 \n",
      "acc for Psat= 0.19556062959714746 \n",
      "acc for optim= 0.17687252236789733\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.005509261507540941\n",
      "Loss on test= 0.007086439523845911\n",
      "acc for Lsat= 0.14940629102896563 \n",
      "acc for Psat= 0.16873783581111518 \n",
      "acc for optim= 0.17541259295768943\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.005415937397629023\n",
      "Loss on test= 0.00677329208701849\n",
      "acc for Lsat= 0.15847963771427845 \n",
      "acc for Psat= 0.1808856316766755 \n",
      "acc for optim= 0.17251816014377552\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.005649106577038765\n",
      "Loss on test= 0.007160733919590712\n",
      "acc for Lsat= 0.14870101679779674 \n",
      "acc for Psat= 0.18441073847047176 \n",
      "acc for optim= 0.1773449044401727\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.005715384613722563\n",
      "Loss on test= 0.007418491877615452\n",
      "acc for Lsat= 0.1703301732168823 \n",
      "acc for Psat= 0.18461184227060465 \n",
      "acc for optim= 0.17809446653070646\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.005565444938838482\n",
      "Loss on test= 0.007003673352301121\n",
      "acc for Lsat= 0.14757792244924875 \n",
      "acc for Psat= 0.19030069720961887 \n",
      "acc for optim= 0.17162062747358175\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.005717399064451456\n",
      "Loss on test= 0.007027500309050083\n",
      "acc for Lsat= 0.15034424978085092 \n",
      "acc for Psat= 0.18033229233048184 \n",
      "acc for optim= 0.17367337873648303\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.005189927294850349\n",
      "Loss on test= 0.007411961443722248\n",
      "acc for Lsat= 0.15665573235849284 \n",
      "acc for Psat= 0.19594778098303398 \n",
      "acc for optim= 0.18284919965157254\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.005454089026898146\n",
      "Loss on test= 0.0066206250339746475\n",
      "acc for Lsat= 0.16082235834309372 \n",
      "acc for Psat= 0.18916741753164984 \n",
      "acc for optim= 0.18253987958181467\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.005406009033322334\n",
      "Loss on test= 0.006695257965475321\n",
      "acc for Lsat= 0.1594021136248408 \n",
      "acc for Psat= 0.1969494037667946 \n",
      "acc for optim= 0.17941487465711256\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.0053349630907177925\n",
      "Loss on test= 0.00715210847556591\n",
      "acc for Lsat= 0.1554374224349826 \n",
      "acc for Psat= 0.18326449086832372 \n",
      "acc for optim= 0.16649641864546613\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.00549213495105505\n",
      "Loss on test= 0.006933445110917091\n",
      "acc for Lsat= 0.1580503096510122 \n",
      "acc for Psat= 0.18122977623286596 \n",
      "acc for optim= 0.17646509585482237\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.005663798190653324\n",
      "Loss on test= 0.006814535241574049\n",
      "acc for Lsat= 0.14894295723170814 \n",
      "acc for Psat= 0.18361885922800628 \n",
      "acc for optim= 0.17604348441250967\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.0055470941588282585\n",
      "Loss on test= 0.006738482974469662\n",
      "acc for Lsat= 0.1418931108849795 \n",
      "acc for Psat= 0.1844406367637423 \n",
      "acc for optim= 0.1726490178765714\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.005338309332728386\n",
      "Loss on test= 0.007025412283837795\n",
      "acc for Lsat= 0.1555887767604276 \n",
      "acc for Psat= 0.18434137094526867 \n",
      "acc for optim= 0.17293885476695428\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.005422969814389944\n",
      "Loss on test= 0.0072827087715268135\n",
      "acc for Lsat= 0.1521196222044413 \n",
      "acc for Psat= 0.18799908394452 \n",
      "acc for optim= 0.17312116266503075\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.005462405737489462\n",
      "Loss on test= 0.007023376878350973\n",
      "acc for Lsat= 0.1425167355265822 \n",
      "acc for Psat= 0.18036182201868228 \n",
      "acc for optim= 0.18055192902626957\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.005278855562210083\n",
      "Loss on test= 0.00741494121029973\n",
      "acc for Lsat= 0.15616824837958776 \n",
      "acc for Psat= 0.19517792229746758 \n",
      "acc for optim= 0.17039919911586054\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.005588254425674677\n",
      "Loss on test= 0.007235817611217499\n",
      "acc for Lsat= 0.16675706738911447 \n",
      "acc for Psat= 0.18489984227229886 \n",
      "acc for optim= 0.17658046661784538\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.005421011708676815\n",
      "Loss on test= 0.006814356427639723\n",
      "acc for Lsat= 0.1618223161085463 \n",
      "acc for Psat= 0.1910645638890259 \n",
      "acc for optim= 0.17871505838544985\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.005386529490351677\n",
      "Loss on test= 0.0068211983889341354\n",
      "acc for Lsat= 0.15416551355060693 \n",
      "acc for Psat= 0.17512582996154022 \n",
      "acc for optim= 0.17575800412040601\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.005435519851744175\n",
      "Loss on test= 0.007097367662936449\n",
      "acc for Lsat= 0.15506058729284244 \n",
      "acc for Psat= 0.17516334685706916 \n",
      "acc for optim= 0.17871574098072548\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.005546869244426489\n",
      "Loss on test= 0.006944209802895784\n",
      "acc for Lsat= 0.15721183699559513 \n",
      "acc for Psat= 0.1908822966239522 \n",
      "acc for optim= 0.17844451283501675\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.005567311309278011\n",
      "Loss on test= 0.0071926116943359375\n",
      "acc for Lsat= 0.1638286506966115 \n",
      "acc for Psat= 0.19319696436105602 \n",
      "acc for optim= 0.17308641874429875\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.005371874198317528\n",
      "Loss on test= 0.007432148326188326\n",
      "acc for Lsat= 0.16249394976804948 \n",
      "acc for Psat= 0.19321399421333793 \n",
      "acc for optim= 0.17679817556827251\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.0053163799457252026\n",
      "Loss on test= 0.007226797752082348\n",
      "acc for Lsat= 0.1579724999228645 \n",
      "acc for Psat= 0.18644279002261607 \n",
      "acc for optim= 0.17813452662261714\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.005456945858895779\n",
      "Loss on test= 0.007000683341175318\n",
      "acc for Lsat= 0.14461764942885177 \n",
      "acc for Psat= 0.18627794175513746 \n",
      "acc for optim= 0.17757962177169784\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.005228763911873102\n",
      "Loss on test= 0.007072530221194029\n",
      "acc for Lsat= 0.1544879640513992 \n",
      "acc for Psat= 0.19357565906243285 \n",
      "acc for optim= 0.1691116824123978\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.005227147601544857\n",
      "Loss on test= 0.007194281555712223\n",
      "acc for Lsat= 0.16305405729045694 \n",
      "acc for Psat= 0.17939742155731886 \n",
      "acc for optim= 0.17790043963440008\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.005501427687704563\n",
      "Loss on test= 0.007143345661461353\n",
      "acc for Lsat= 0.15970880708907212 \n",
      "acc for Psat= 0.1902729597105239 \n",
      "acc for optim= 0.17014382688574814\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.005188738461583853\n",
      "Loss on test= 0.007075665984302759\n",
      "acc for Lsat= 0.1595924564058984 \n",
      "acc for Psat= 0.1801683506394019 \n",
      "acc for optim= 0.17463172623089926\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.0054159765131771564\n",
      "Loss on test= 0.006912281271070242\n",
      "acc for Lsat= 0.1582983955183662 \n",
      "acc for Psat= 0.18178588530529657 \n",
      "acc for optim= 0.18088264865609893\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.005328391678631306\n",
      "Loss on test= 0.007212041411548853\n",
      "acc for Lsat= 0.15860635602930714 \n",
      "acc for Psat= 0.187463434267938 \n",
      "acc for optim= 0.16864357548994852\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.005299616605043411\n",
      "Loss on test= 0.006932639982551336\n",
      "acc for Lsat= 0.16367224777865483 \n",
      "acc for Psat= 0.17660243990525726 \n",
      "acc for optim= 0.1727105068714648\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.005275171250104904\n",
      "Loss on test= 0.007137162610888481\n",
      "acc for Lsat= 0.16773721749940124 \n",
      "acc for Psat= 0.19884204541745246 \n",
      "acc for optim= 0.1797790301631617\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.005556102842092514\n",
      "Loss on test= 0.007368187885731459\n",
      "acc for Lsat= 0.16915826926171992 \n",
      "acc for Psat= 0.18848659830152623 \n",
      "acc for optim= 0.17670169890405932\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.005399208515882492\n",
      "Loss on test= 0.006850877311080694\n",
      "acc for Lsat= 0.14972459700673754 \n",
      "acc for Psat= 0.18525460464378904 \n",
      "acc for optim= 0.18048988647766595\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.005383237265050411\n",
      "Loss on test= 0.006898209452629089\n",
      "acc for Lsat= 0.157982630395716 \n",
      "acc for Psat= 0.17501260902137175 \n",
      "acc for optim= 0.17162502650610462\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.005263640079647303\n",
      "Loss on test= 0.007199728395789862\n",
      "acc for Lsat= 0.16094485758069033 \n",
      "acc for Psat= 0.19152393412020546 \n",
      "acc for optim= 0.17855433293095346\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.005647953599691391\n",
      "Loss on test= 0.007079609204083681\n",
      "acc for Lsat= 0.15028339248326164 \n",
      "acc for Psat= 0.17584211085541326 \n",
      "acc for optim= 0.17589101967226226\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.005467416252940893\n",
      "Loss on test= 0.006616209167987108\n",
      "acc for Lsat= 0.16284205036115695 \n",
      "acc for Psat= 0.18762585007028318 \n",
      "acc for optim= 0.18414550376941496\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.005548857152462006\n",
      "Loss on test= 0.007407491561025381\n",
      "acc for Lsat= 0.1636708063973021 \n",
      "acc for Psat= 0.19489864328123255 \n",
      "acc for optim= 0.17110040471827054\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.005460485816001892\n",
      "Loss on test= 0.007164622191339731\n",
      "acc for Lsat= 0.16032760703943852 \n",
      "acc for Psat= 0.192669806546211 \n",
      "acc for optim= 0.1741620394618338\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.0054280636832118034\n",
      "Loss on test= 0.007072379346936941\n",
      "acc for Lsat= 0.16418096941254545 \n",
      "acc for Psat= 0.19224779499469508 \n",
      "acc for optim= 0.17195600296545308\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.005221308209002018\n",
      "Loss on test= 0.007118217181414366\n",
      "acc for Lsat= 0.15978060277879283 \n",
      "acc for Psat= 0.1892168135897516 \n",
      "acc for optim= 0.17827576283312052\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.005367911420762539\n",
      "Loss on test= 0.006878329906612635\n",
      "acc for Lsat= 0.164598080218907 \n",
      "acc for Psat= 0.19637018325619332 \n",
      "acc for optim= 0.17542386892887182\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.005147687159478664\n",
      "Loss on test= 0.007106971926987171\n",
      "acc for Lsat= 0.1508113906150073 \n",
      "acc for Psat= 0.17657645886055895 \n",
      "acc for optim= 0.17996336391775822\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.005393083207309246\n",
      "Loss on test= 0.0070958323776721954\n",
      "acc for Lsat= 0.13524297742792368 \n",
      "acc for Psat= 0.1851880630372344 \n",
      "acc for optim= 0.1733961550688722\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.005301374942064285\n",
      "Loss on test= 0.006996752228587866\n",
      "acc for Lsat= 0.15079586906205925 \n",
      "acc for Psat= 0.18724455783891752 \n",
      "acc for optim= 0.17533094409002054\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.005758975632488728\n",
      "Loss on test= 0.006489763967692852\n",
      "acc for Lsat= 0.14702450317668453 \n",
      "acc for Psat= 0.18145650391758908 \n",
      "acc for optim= 0.18234131876913617\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.005456577055156231\n",
      "Loss on test= 0.007063953205943108\n",
      "acc for Lsat= 0.15399328566415876 \n",
      "acc for Psat= 0.18772797785531425 \n",
      "acc for optim= 0.1760577479323714\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.0054393792524933815\n",
      "Loss on test= 0.0070050801150500774\n",
      "acc for Lsat= 0.16779384350243834 \n",
      "acc for Psat= 0.18997511202164116 \n",
      "acc for optim= 0.17739301596111695\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.005456528626382351\n",
      "Loss on test= 0.006813264451920986\n",
      "acc for Lsat= 0.1544060557645547 \n",
      "acc for Psat= 0.20379937703990317 \n",
      "acc for optim= 0.1788729497010163\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.0053471652790904045\n",
      "Loss on test= 0.007063689175993204\n",
      "acc for Lsat= 0.14806173948082524 \n",
      "acc for Psat= 0.1788371594792583 \n",
      "acc for optim= 0.1774197207400709\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.005342144053429365\n",
      "Loss on test= 0.007291126996278763\n",
      "acc for Lsat= 0.16005967337472105 \n",
      "acc for Psat= 0.19118419261191225 \n",
      "acc for optim= 0.17013884409441477\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.005109050311148167\n",
      "Loss on test= 0.007001656573265791\n",
      "acc for Lsat= 0.14966137557238968 \n",
      "acc for Psat= 0.19133480981022852 \n",
      "acc for optim= 0.17490426899522227\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.005133374594151974\n",
      "Loss on test= 0.007190787233412266\n",
      "acc for Lsat= 0.15358276961044004 \n",
      "acc for Psat= 0.1944279544751091 \n",
      "acc for optim= 0.1770100296389113\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.005477478262037039\n",
      "Loss on test= 0.006757116876542568\n",
      "acc for Lsat= 0.14497398823126578 \n",
      "acc for Psat= 0.1765013663869229 \n",
      "acc for optim= 0.17138780313543975\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.005259089637547731\n",
      "Loss on test= 0.006937960162758827\n",
      "acc for Lsat= 0.1486118879928788 \n",
      "acc for Psat= 0.1805319938771465 \n",
      "acc for optim= 0.17517484810707143\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.005517395678907633\n",
      "Loss on test= 0.007233514916151762\n",
      "acc for Lsat= 0.15887256330604374 \n",
      "acc for Psat= 0.18456079928752142 \n",
      "acc for optim= 0.17466313307303324\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.005567329004406929\n",
      "Loss on test= 0.0066546485759317875\n",
      "acc for Lsat= 0.14943141790625036 \n",
      "acc for Psat= 0.17836879581495924 \n",
      "acc for optim= 0.17590307120394083\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.005588036961853504\n",
      "Loss on test= 0.007110028062015772\n",
      "acc for Lsat= 0.1629585283403819 \n",
      "acc for Psat= 0.18330168292373916 \n",
      "acc for optim= 0.1770749514788312\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.00527262594550848\n",
      "Loss on test= 0.006897699553519487\n",
      "acc for Lsat= 0.14633102313234647 \n",
      "acc for Psat= 0.18660813989251332 \n",
      "acc for optim= 0.1742479527993204\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.0055897654965519905\n",
      "Loss on test= 0.007171852048486471\n",
      "acc for Lsat= 0.13874188933834494 \n",
      "acc for Psat= 0.17075669234694882 \n",
      "acc for optim= 0.18203429641391983\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.0054215919226408005\n",
      "Loss on test= 0.0071699172258377075\n",
      "acc for Lsat= 0.15247605109823958 \n",
      "acc for Psat= 0.1942357450621546 \n",
      "acc for optim= 0.1860364307225758\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.005573471076786518\n",
      "Loss on test= 0.006893964018672705\n",
      "acc for Lsat= 0.15734476553902152 \n",
      "acc for Psat= 0.1853796335710136 \n",
      "acc for optim= 0.1690324523738112\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.0052358172833919525\n",
      "Loss on test= 0.0071434881538152695\n",
      "acc for Lsat= 0.15411436840410908 \n",
      "acc for Psat= 0.1908117170743339 \n",
      "acc for optim= 0.1697302846335825\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.005345487967133522\n",
      "Loss on test= 0.007240635342895985\n",
      "acc for Lsat= 0.15449519288052468 \n",
      "acc for Psat= 0.18237549445026965 \n",
      "acc for optim= 0.17712376012436312\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.005592962261289358\n",
      "Loss on test= 0.007133773062378168\n",
      "acc for Lsat= 0.1559560021375054 \n",
      "acc for Psat= 0.1688336465423774 \n",
      "acc for optim= 0.17949594664139307\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.0056611718609929085\n",
      "Loss on test= 0.007066483609378338\n",
      "acc for Lsat= 0.14730585888972828 \n",
      "acc for Psat= 0.19280217667415617 \n",
      "acc for optim= 0.18053810049082653\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.005515250377357006\n",
      "Loss on test= 0.00711315032094717\n",
      "acc for Lsat= 0.15036153305955535 \n",
      "acc for Psat= 0.18387845653981413 \n",
      "acc for optim= 0.179307414899813\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.005177325569093227\n",
      "Loss on test= 0.007287253625690937\n",
      "acc for Lsat= 0.16342947175840802 \n",
      "acc for Psat= 0.18065178779871813 \n",
      "acc for optim= 0.1703679421626997\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.005255626514554024\n",
      "Loss on test= 0.007007453590631485\n",
      "acc for Lsat= 0.1598957072857569 \n",
      "acc for Psat= 0.18093445873628447 \n",
      "acc for optim= 0.1720772992373925\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.005553887225687504\n",
      "Loss on test= 0.007074881345033646\n",
      "acc for Lsat= 0.14477134918675713 \n",
      "acc for Psat= 0.18219848759376947 \n",
      "acc for optim= 0.1753376262136506\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.00540641974657774\n",
      "Loss on test= 0.007068910636007786\n",
      "acc for Lsat= 0.15721602266698267 \n",
      "acc for Psat= 0.19186859486441388 \n",
      "acc for optim= 0.17511341566130229\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.005200275219976902\n",
      "Loss on test= 0.007004148326814175\n",
      "acc for Lsat= 0.1587040837150884 \n",
      "acc for Psat= 0.175999855669597 \n",
      "acc for optim= 0.1767789259133097\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.005239645019173622\n",
      "Loss on test= 0.006987161934375763\n",
      "acc for Lsat= 0.15178799010988814 \n",
      "acc for Psat= 0.1951743243343758 \n",
      "acc for optim= 0.17707895930669437\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.005383657291531563\n",
      "Loss on test= 0.007029555272310972\n",
      "acc for Lsat= 0.16470062836764196 \n",
      "acc for Psat= 0.19088936507135065 \n",
      "acc for optim= 0.17623310527806246\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.0054176137782633305\n",
      "Loss on test= 0.007198784034699202\n",
      "acc for Lsat= 0.15250000137574285 \n",
      "acc for Psat= 0.19432436515328802 \n",
      "acc for optim= 0.18320643455152721\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.00540597690269351\n",
      "Loss on test= 0.006842930801212788\n",
      "acc for Lsat= 0.14969551920116753 \n",
      "acc for Psat= 0.17371173907914886 \n",
      "acc for optim= 0.17745857540495144\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.005327676422894001\n",
      "Loss on test= 0.006681703496724367\n",
      "acc for Lsat= 0.1564374271936745 \n",
      "acc for Psat= 0.18776249917850021 \n",
      "acc for optim= 0.17970341723374106\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.005650501232594252\n",
      "Loss on test= 0.006814229767769575\n",
      "acc for Lsat= 0.15588270546105065 \n",
      "acc for Psat= 0.1861570098132017 \n",
      "acc for optim= 0.17678637948177267\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.0052870577201247215\n",
      "Loss on test= 0.00682641938328743\n",
      "acc for Lsat= 0.15297557712673565 \n",
      "acc for Psat= 0.18482997974869414 \n",
      "acc for optim= 0.17507580732535494\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.005019195377826691\n",
      "Loss on test= 0.007080145180225372\n",
      "acc for Lsat= 0.14430213013557014 \n",
      "acc for Psat= 0.1922730221430252 \n",
      "acc for optim= 0.17606840433207432\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.005188831128180027\n",
      "Loss on test= 0.007582447025924921\n",
      "acc for Lsat= 0.16509235696471106 \n",
      "acc for Psat= 0.19173596244931343 \n",
      "acc for optim= 0.1769438378276212\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.005359681788831949\n",
      "Loss on test= 0.006540520116686821\n",
      "acc for Lsat= 0.1528709617768773 \n",
      "acc for Psat= 0.17777459411328414 \n",
      "acc for optim= 0.1717036560731253\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.005525434855371714\n",
      "Loss on test= 0.007273735012859106\n",
      "acc for Lsat= 0.15438186826630967 \n",
      "acc for Psat= 0.18864386265245303 \n",
      "acc for optim= 0.17268765450590748\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.005416675936430693\n",
      "Loss on test= 0.0072029284201562405\n",
      "acc for Lsat= 0.16247736704917473 \n",
      "acc for Psat= 0.18130828619659803 \n",
      "acc for optim= 0.17789232246844922\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.00608816696330905\n",
      "Loss on test= 0.006842935457825661\n",
      "acc for Lsat= 0.14348099313000767 \n",
      "acc for Psat= 0.19151627376621216 \n",
      "acc for optim= 0.1798841150219411\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.005394162144511938\n",
      "Loss on test= 0.007095059379935265\n",
      "acc for Lsat= 0.16060041007643078 \n",
      "acc for Psat= 0.19089472321812523 \n",
      "acc for optim= 0.17933992685589817\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.005369907710701227\n",
      "Loss on test= 0.006983769591897726\n",
      "acc for Lsat= 0.15456040983592145 \n",
      "acc for Psat= 0.18373169815167784 \n",
      "acc for optim= 0.1717728444795672\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.005456394050270319\n",
      "Loss on test= 0.00671938294544816\n",
      "acc for Lsat= 0.15579746871820238 \n",
      "acc for Psat= 0.19175420940031115 \n",
      "acc for optim= 0.17981146300501633\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.005488136317580938\n",
      "Loss on test= 0.007144774775952101\n",
      "acc for Lsat= 0.150164963946235 \n",
      "acc for Psat= 0.18707021660959638 \n",
      "acc for optim= 0.18052376592293246\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.005223421845585108\n",
      "Loss on test= 0.007029376458376646\n",
      "acc for Lsat= 0.16127927313934723 \n",
      "acc for Psat= 0.19264616685858393 \n",
      "acc for optim= 0.18063851499521616\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.0053909760899841785\n",
      "Loss on test= 0.007378668058663607\n",
      "acc for Lsat= 0.15160808899291012 \n",
      "acc for Psat= 0.18465968754694065 \n",
      "acc for optim= 0.17546882587408677\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.005433006677776575\n",
      "Loss on test= 0.006847037002444267\n",
      "acc for Lsat= 0.16213158583154016 \n",
      "acc for Psat= 0.1994362996433352 \n",
      "acc for optim= 0.17459323017230088\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.005311795976012945\n",
      "Loss on test= 0.007001243531703949\n",
      "acc for Lsat= 0.16149355349489716 \n",
      "acc for Psat= 0.17996142376004337 \n",
      "acc for optim= 0.1765818398822286\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.005661352537572384\n",
      "Loss on test= 0.00706867640838027\n",
      "acc for Lsat= 0.15074158080464198 \n",
      "acc for Psat= 0.18913818984125458 \n",
      "acc for optim= 0.17695050158196313\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.0053863925859332085\n",
      "Loss on test= 0.007106626406311989\n",
      "acc for Lsat= 0.15430724862848455 \n",
      "acc for Psat= 0.18868194330353902 \n",
      "acc for optim= 0.18364846506356414\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.005641691852360964\n",
      "Loss on test= 0.00709616718813777\n",
      "acc for Lsat= 0.15473280467835973 \n",
      "acc for Psat= 0.19157230944952883 \n",
      "acc for optim= 0.1751361922669171\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.005319277290254831\n",
      "Loss on test= 0.006999280769377947\n",
      "acc for Lsat= 0.15700409273324978 \n",
      "acc for Psat= 0.18024018638968645 \n",
      "acc for optim= 0.17380076156018806\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.005360190290957689\n",
      "Loss on test= 0.007080553565174341\n",
      "acc for Lsat= 0.1532102097749527 \n",
      "acc for Psat= 0.19444166972668323 \n",
      "acc for optim= 0.17682643988910207\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.005690940655767918\n",
      "Loss on test= 0.006738288328051567\n",
      "acc for Lsat= 0.14871063428896586 \n",
      "acc for Psat= 0.18040754886699045 \n",
      "acc for optim= 0.1788310986580938\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.005530779715627432\n",
      "Loss on test= 0.007064557634294033\n",
      "acc for Lsat= 0.15561006352377935 \n",
      "acc for Psat= 0.18343724536052983 \n",
      "acc for optim= 0.1707602919754954\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.005385188385844231\n",
      "Loss on test= 0.006773392204195261\n",
      "acc for Lsat= 0.16008947331794218 \n",
      "acc for Psat= 0.18930017097040125 \n",
      "acc for optim= 0.17322850116238964\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.00539716612547636\n",
      "Loss on test= 0.006976595148444176\n",
      "acc for Lsat= 0.15611358016636795 \n",
      "acc for Psat= 0.1724985987752424 \n",
      "acc for optim= 0.1812061722817846\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.005230339244008064\n",
      "Loss on test= 0.007157864980399609\n",
      "acc for Lsat= 0.1555184333088529 \n",
      "acc for Psat= 0.2010995196453372 \n",
      "acc for optim= 0.1688474166685499\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.005768794100731611\n",
      "Loss on test= 0.006566522177308798\n",
      "acc for Lsat= 0.16094975657947172 \n",
      "acc for Psat= 0.18397836724437439 \n",
      "acc for optim= 0.17686663458284113\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.0057000950910151005\n",
      "Loss on test= 0.0066736782900989056\n",
      "acc for Lsat= 0.1613951668524962 \n",
      "acc for Psat= 0.19835712460755203 \n",
      "acc for optim= 0.1754431456781649\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.005461050663143396\n",
      "Loss on test= 0.006837107706815004\n",
      "acc for Lsat= 0.15963846792316172 \n",
      "acc for Psat= 0.19512372470582973 \n",
      "acc for optim= 0.18032355196506822\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.005553198512643576\n",
      "Loss on test= 0.007188810966908932\n",
      "acc for Lsat= 0.14907084338741042 \n",
      "acc for Psat= 0.19399679413248525 \n",
      "acc for optim= 0.1857220494633991\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.005681817885488272\n",
      "Loss on test= 0.006920834071934223\n",
      "acc for Lsat= 0.14895988353981338 \n",
      "acc for Psat= 0.20387859827510585 \n",
      "acc for optim= 0.1774237056266608\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.005666585173457861\n",
      "Loss on test= 0.006776968948543072\n",
      "acc for Lsat= 0.1556620979106214 \n",
      "acc for Psat= 0.1796367652870745 \n",
      "acc for optim= 0.1736912054097524\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.0054939850233495235\n",
      "Loss on test= 0.007410590536892414\n",
      "acc for Lsat= 0.14729000654331117 \n",
      "acc for Psat= 0.19165330098189995 \n",
      "acc for optim= 0.174895551651441\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.005517729092389345\n",
      "Loss on test= 0.006799893453717232\n",
      "acc for Lsat= 0.15967709613671968 \n",
      "acc for Psat= 0.19416448770636754 \n",
      "acc for optim= 0.17791613701004086\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.0059407358057796955\n",
      "Loss on test= 0.006991363130509853\n",
      "acc for Lsat= 0.14852359082309347 \n",
      "acc for Psat= 0.1783867395454092 \n",
      "acc for optim= 0.17496451685113495\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.0052979132160544395\n",
      "Loss on test= 0.006988656707108021\n",
      "acc for Lsat= 0.15629893458232696 \n",
      "acc for Psat= 0.18389295328362676 \n",
      "acc for optim= 0.17426977435548668\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.005440301727503538\n",
      "Loss on test= 0.00673698028549552\n",
      "acc for Lsat= 0.15228051217225166 \n",
      "acc for Psat= 0.1736928174695855 \n",
      "acc for optim= 0.1747564468525644\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.005366120487451553\n",
      "Loss on test= 0.006790013983845711\n",
      "acc for Lsat= 0.15634365047425505 \n",
      "acc for Psat= 0.1904205651923281 \n",
      "acc for optim= 0.18178995271808787\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.005459038075059652\n",
      "Loss on test= 0.007212290074676275\n",
      "acc for Lsat= 0.13851137614587597 \n",
      "acc for Psat= 0.18129696392332068 \n",
      "acc for optim= 0.17860323673564574\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.005533183924853802\n",
      "Loss on test= 0.006933585740625858\n",
      "acc for Lsat= 0.15419075683591368 \n",
      "acc for Psat= 0.19280808656256967 \n",
      "acc for optim= 0.17139261226602984\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.005249298643320799\n",
      "Loss on test= 0.00695724505931139\n",
      "acc for Lsat= 0.1497578346800273 \n",
      "acc for Psat= 0.1741583433391557 \n",
      "acc for optim= 0.17606326990446447\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.0053074900060892105\n",
      "Loss on test= 0.007004607934504747\n",
      "acc for Lsat= 0.16433864679821142 \n",
      "acc for Psat= 0.2015009741552678 \n",
      "acc for optim= 0.17907753614372418\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.005548693705350161\n",
      "Loss on test= 0.007290160283446312\n",
      "acc for Lsat= 0.15377086351785932 \n",
      "acc for Psat= 0.18620994953766892 \n",
      "acc for optim= 0.18024371432380934\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.005425735842436552\n",
      "Loss on test= 0.006953313481062651\n",
      "acc for Lsat= 0.15154345896283258 \n",
      "acc for Psat= 0.19328232424669578 \n",
      "acc for optim= 0.16888865150576152\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.005420179106295109\n",
      "Loss on test= 0.007187678944319487\n",
      "acc for Lsat= 0.1540439784847444 \n",
      "acc for Psat= 0.20686092812789328 \n",
      "acc for optim= 0.17130282115091983\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.005425109528005123\n",
      "Loss on test= 0.007472182158380747\n",
      "acc for Lsat= 0.15614843057605943 \n",
      "acc for Psat= 0.17525979634775155 \n",
      "acc for optim= 0.1780175638240075\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.005283644888550043\n",
      "Loss on test= 0.007107086014002562\n",
      "acc for Lsat= 0.15321906592403958 \n",
      "acc for Psat= 0.17560879375602378 \n",
      "acc for optim= 0.18523286425329163\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.005349775310605764\n",
      "Loss on test= 0.007251930423080921\n",
      "acc for Lsat= 0.15007686588176541 \n",
      "acc for Psat= 0.18390216512575014 \n",
      "acc for optim= 0.17594276549348029\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.005476007238030434\n",
      "Loss on test= 0.006682966370135546\n",
      "acc for Lsat= 0.14102130824848857 \n",
      "acc for Psat= 0.18148842858099073 \n",
      "acc for optim= 0.17973910657666073\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.00544359814375639\n",
      "Loss on test= 0.007083993870764971\n",
      "acc for Lsat= 0.15640203309551715 \n",
      "acc for Psat= 0.19992291094023415 \n",
      "acc for optim= 0.18535388715061374\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.005481447093188763\n",
      "Loss on test= 0.007234688848257065\n",
      "acc for Lsat= 0.15423149740567707 \n",
      "acc for Psat= 0.19441471487039425 \n",
      "acc for optim= 0.1784701175474348\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.0054432000033557415\n",
      "Loss on test= 0.007049374282360077\n",
      "acc for Lsat= 0.1462390812100522 \n",
      "acc for Psat= 0.1764280394337056 \n",
      "acc for optim= 0.18021970978655594\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.005437023006379604\n",
      "Loss on test= 0.0069832527078688145\n",
      "acc for Lsat= 0.15014303548152502 \n",
      "acc for Psat= 0.17619971372301643 \n",
      "acc for optim= 0.17788268504206275\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.006195428781211376\n",
      "Loss on test= 0.007199481129646301\n",
      "acc for Lsat= 0.16555560189256346 \n",
      "acc for Psat= 0.18774274443772423 \n",
      "acc for optim= 0.17927873831425534\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.0053778826259076595\n",
      "Loss on test= 0.006954385433346033\n",
      "acc for Lsat= 0.15224711303522842 \n",
      "acc for Psat= 0.17756596039327008 \n",
      "acc for optim= 0.16950766038012188\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.005617199465632439\n",
      "Loss on test= 0.006998593918979168\n",
      "acc for Lsat= 0.16008004126275915 \n",
      "acc for Psat= 0.18820668384881278 \n",
      "acc for optim= 0.1834647558873794\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.005236201453953981\n",
      "Loss on test= 0.0068626184947788715\n",
      "acc for Lsat= 0.1518997667206558 \n",
      "acc for Psat= 0.17535826594885592 \n",
      "acc for optim= 0.17781966120027556\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.005439030472189188\n",
      "Loss on test= 0.0073556979186832905\n",
      "acc for Lsat= 0.14897968126103076 \n",
      "acc for Psat= 0.16949200781055565 \n",
      "acc for optim= 0.17394198841648176\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.005373263265937567\n",
      "Loss on test= 0.007172101642936468\n",
      "acc for Lsat= 0.1487814311449584 \n",
      "acc for Psat= 0.19164259163204764 \n",
      "acc for optim= 0.16970346040248901\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.005344023462384939\n",
      "Loss on test= 0.006990485824644566\n",
      "acc for Lsat= 0.15774498480242358 \n",
      "acc for Psat= 0.19599311657891166 \n",
      "acc for optim= 0.18658433880916506\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.005263012833893299\n",
      "Loss on test= 0.00713845482096076\n",
      "acc for Lsat= 0.16212909050003366 \n",
      "acc for Psat= 0.18840317371660142 \n",
      "acc for optim= 0.1738502941141096\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.0053058527410030365\n",
      "Loss on test= 0.006897163577377796\n",
      "acc for Lsat= 0.16388092426751114 \n",
      "acc for Psat= 0.19078913380727783 \n",
      "acc for optim= 0.1826149501322509\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.005714213941246271\n",
      "Loss on test= 0.006802515126764774\n",
      "acc for Lsat= 0.14627159097209022 \n",
      "acc for Psat= 0.20720887330840684 \n",
      "acc for optim= 0.17625034618626548\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.0051637208089232445\n",
      "Loss on test= 0.0067526064813137054\n",
      "acc for Lsat= 0.15175913257474752 \n",
      "acc for Psat= 0.20266462451526437 \n",
      "acc for optim= 0.1790090546008108\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.005346001125872135\n",
      "Loss on test= 0.006935818586498499\n",
      "acc for Lsat= 0.14970697672833921 \n",
      "acc for Psat= 0.17236889657778207 \n",
      "acc for optim= 0.1707500147820998\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.005259853787720203\n",
      "Loss on test= 0.006659397389739752\n",
      "acc for Lsat= 0.15196710306937333 \n",
      "acc for Psat= 0.18225327508894298 \n",
      "acc for optim= 0.18039474878956366\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.005425922106951475\n",
      "Loss on test= 0.0069121625274419785\n",
      "acc for Lsat= 0.14608253666484103 \n",
      "acc for Psat= 0.19239809369309577 \n",
      "acc for optim= 0.18145483067415685\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.005394744221121073\n",
      "Loss on test= 0.007119486574083567\n",
      "acc for Lsat= 0.15127540726794816 \n",
      "acc for Psat= 0.18091856599518205 \n",
      "acc for optim= 0.17992547027013822\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.005348102655261755\n",
      "Loss on test= 0.007335462141782045\n",
      "acc for Lsat= 0.16758397037056505 \n",
      "acc for Psat= 0.17499729739712003 \n",
      "acc for optim= 0.1829376787361145\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.005415735300630331\n",
      "Loss on test= 0.006763050332665443\n",
      "acc for Lsat= 0.15667777191141438 \n",
      "acc for Psat= 0.19246194882730602 \n",
      "acc for optim= 0.18245143022342417\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.005548687186092138\n",
      "Loss on test= 0.006643034052103758\n",
      "acc for Lsat= 0.1524103170993631 \n",
      "acc for Psat= 0.18909656899426797 \n",
      "acc for optim= 0.17982824433262873\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.005619093310087919\n",
      "Loss on test= 0.006992393173277378\n",
      "acc for Lsat= 0.14478158244042996 \n",
      "acc for Psat= 0.17314600641705616 \n",
      "acc for optim= 0.17297797959591796\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.006502850912511349\n",
      "Loss on test= 0.006812358275055885\n",
      "acc for Lsat= 0.15158967592076686 \n",
      "acc for Psat= 0.1838405928892259 \n",
      "acc for optim= 0.18129792367171382\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.005479720886796713\n",
      "Loss on test= 0.007369605824351311\n",
      "acc for Lsat= 0.14398176812182265 \n",
      "acc for Psat= 0.20664119906036457 \n",
      "acc for optim= 0.16817992322118744\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.005280388053506613\n",
      "Loss on test= 0.007022025994956493\n",
      "acc for Lsat= 0.15611890637750936 \n",
      "acc for Psat= 0.18841483571497938 \n",
      "acc for optim= 0.1778962268184901\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.005355720408260822\n",
      "Loss on test= 0.00699994433671236\n",
      "acc for Lsat= 0.153746454847488 \n",
      "acc for Psat= 0.18130454311803837 \n",
      "acc for optim= 0.18197365088221812\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.005434689112007618\n",
      "Loss on test= 0.007199942599982023\n",
      "acc for Lsat= 0.16332686163225502 \n",
      "acc for Psat= 0.18767087515930217 \n",
      "acc for optim= 0.1827576596770802\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.0061685917899012566\n",
      "Loss on test= 0.006720216013491154\n",
      "acc for Lsat= 0.15247652698379796 \n",
      "acc for Psat= 0.20208045095396152 \n",
      "acc for optim= 0.18445924353560617\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.00572248687967658\n",
      "Loss on test= 0.006716603878885508\n",
      "acc for Lsat= 0.1477001440654066 \n",
      "acc for Psat= 0.17992282151320918 \n",
      "acc for optim= 0.1726847022600075\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.005259318742901087\n",
      "Loss on test= 0.007245962042361498\n",
      "acc for Lsat= 0.15564171491270945 \n",
      "acc for Psat= 0.18260380963195635 \n",
      "acc for optim= 0.17828221638862532\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.00542848277837038\n",
      "Loss on test= 0.007296674884855747\n",
      "acc for Lsat= 0.14833190696367413 \n",
      "acc for Psat= 0.1811762511985926 \n",
      "acc for optim= 0.17942327147189405\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.005337021313607693\n",
      "Loss on test= 0.007267153821885586\n",
      "acc for Lsat= 0.14164991836086466 \n",
      "acc for Psat= 0.18693071183611135 \n",
      "acc for optim= 0.17819604984165902\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.0054007889702916145\n",
      "Loss on test= 0.006905247922986746\n",
      "acc for Lsat= 0.15222804729586284 \n",
      "acc for Psat= 0.184423118368837 \n",
      "acc for optim= 0.17570936998970746\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.005341884680092335\n",
      "Loss on test= 0.006919329985976219\n",
      "acc for Lsat= 0.14537631399618448 \n",
      "acc for Psat= 0.1780905420520181 \n",
      "acc for optim= 0.1713572119161311\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.005405276082456112\n",
      "Loss on test= 0.006896348670125008\n",
      "acc for Lsat= 0.15700143196307062 \n",
      "acc for Psat= 0.19801859460316873 \n",
      "acc for optim= 0.174463509497248\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.005287808366119862\n",
      "Loss on test= 0.007100395858287811\n",
      "acc for Lsat= 0.15319611477678963 \n",
      "acc for Psat= 0.18565643900379417 \n",
      "acc for optim= 0.1779435949151969\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.0052569168619811535\n",
      "Loss on test= 0.007235489320009947\n",
      "acc for Lsat= 0.14991061044959486 \n",
      "acc for Psat= 0.19396388342749082 \n",
      "acc for optim= 0.17842753355183302\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.005677101667970419\n",
      "Loss on test= 0.00676071597263217\n",
      "acc for Lsat= 0.14849397743027276 \n",
      "acc for Psat= 0.19351620675583722 \n",
      "acc for optim= 0.1778533065937303\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.005331801250576973\n",
      "Loss on test= 0.00701436772942543\n",
      "acc for Lsat= 0.14066620755988804 \n",
      "acc for Psat= 0.17776744514436568 \n",
      "acc for optim= 0.17824364528571066\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.005690006073564291\n",
      "Loss on test= 0.007420812733471394\n",
      "acc for Lsat= 0.16857533869536337 \n",
      "acc for Psat= 0.1791972007617721 \n",
      "acc for optim= 0.17891262602824412\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.0055658165365457535\n",
      "Loss on test= 0.006618148647248745\n",
      "acc for Lsat= 0.15777828034841776 \n",
      "acc for Psat= 0.18702010825776388 \n",
      "acc for optim= 0.17497124588498694\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.005318735726177692\n",
      "Loss on test= 0.007176815066486597\n",
      "acc for Lsat= 0.15402764222302215 \n",
      "acc for Psat= 0.19098673029535557 \n",
      "acc for optim= 0.17734976764004684\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.005525761283934116\n",
      "Loss on test= 0.007821762003004551\n",
      "acc for Lsat= 0.15608512429314375 \n",
      "acc for Psat= 0.18035635194344232 \n",
      "acc for optim= 0.18569530563726716\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.005507330410182476\n",
      "Loss on test= 0.007229186594486237\n",
      "acc for Lsat= 0.14223010437195685 \n",
      "acc for Psat= 0.1728402709092212 \n",
      "acc for optim= 0.1780380763071513\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.0053930459544062614\n",
      "Loss on test= 0.006700898986309767\n",
      "acc for Lsat= 0.14835861392746694 \n",
      "acc for Psat= 0.16966273845087537 \n",
      "acc for optim= 0.17422392704947776\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.005627109203487635\n",
      "Loss on test= 0.006962188519537449\n",
      "acc for Lsat= 0.1572022290594998 \n",
      "acc for Psat= 0.19736275376263457 \n",
      "acc for optim= 0.17790341599611564\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.005202812142670155\n",
      "Loss on test= 0.007374733220785856\n",
      "acc for Lsat= 0.16318811211719741 \n",
      "acc for Psat= 0.17832672481146472 \n",
      "acc for optim= 0.17940829176943346\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.005364655051380396\n",
      "Loss on test= 0.0069765569642186165\n",
      "acc for Lsat= 0.15346493927426025 \n",
      "acc for Psat= 0.18449555743661267 \n",
      "acc for optim= 0.1807538371054135\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.005214125849306583\n",
      "Loss on test= 0.006603916175663471\n",
      "acc for Lsat= 0.16201065342919138 \n",
      "acc for Psat= 0.19021521531156127 \n",
      "acc for optim= 0.17315114618080563\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.005509600974619389\n",
      "Loss on test= 0.006872215308248997\n",
      "acc for Lsat= 0.14863401174804838 \n",
      "acc for Psat= 0.18955623238732977 \n",
      "acc for optim= 0.17862343310042605\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.005327826365828514\n",
      "Loss on test= 0.006957259029150009\n",
      "acc for Lsat= 0.15489769279536958 \n",
      "acc for Psat= 0.17750964795170565 \n",
      "acc for optim= 0.18234642914221547\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.005430411081761122\n",
      "Loss on test= 0.006767835933715105\n",
      "acc for Lsat= 0.1558756064899365 \n",
      "acc for Psat= 0.1883463849048283 \n",
      "acc for optim= 0.17674600343223754\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.0053257024846971035\n",
      "Loss on test= 0.0068192677572369576\n",
      "acc for Lsat= 0.14995191166459843 \n",
      "acc for Psat= 0.1864306727092194 \n",
      "acc for optim= 0.1752932907063056\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.005177433602511883\n",
      "Loss on test= 0.007188023999333382\n",
      "acc for Lsat= 0.15242906202806436 \n",
      "acc for Psat= 0.18408623358776763 \n",
      "acc for optim= 0.17415305584760718\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.005578579846769571\n",
      "Loss on test= 0.006873313803225756\n",
      "acc for Lsat= 0.15383107067946036 \n",
      "acc for Psat= 0.19618905345416918 \n",
      "acc for optim= 0.17686815880426038\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.005312568042427301\n",
      "Loss on test= 0.00667019747197628\n",
      "acc for Lsat= 0.15538589262735616 \n",
      "acc for Psat= 0.20564349632305629 \n",
      "acc for optim= 0.17940098231249932\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.005589063744992018\n",
      "Loss on test= 0.006871040444821119\n",
      "acc for Lsat= 0.15160238817639526 \n",
      "acc for Psat= 0.19041738999954075 \n",
      "acc for optim= 0.17382943848812127\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.005215433891862631\n",
      "Loss on test= 0.006919765379279852\n",
      "acc for Lsat= 0.15689655850206302 \n",
      "acc for Psat= 0.18750161169608293 \n",
      "acc for optim= 0.18442482172018185\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.005276948679238558\n",
      "Loss on test= 0.007166307419538498\n",
      "acc for Lsat= 0.15436340268958001 \n",
      "acc for Psat= 0.1785905950412643 \n",
      "acc for optim= 0.1825779165416101\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.005287452135235071\n",
      "Loss on test= 0.006742110010236502\n",
      "acc for Lsat= 0.1443249376712092 \n",
      "acc for Psat= 0.19327814164953153 \n",
      "acc for optim= 0.1770344184772646\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.005499933380633593\n",
      "Loss on test= 0.007209884934127331\n",
      "acc for Lsat= 0.1553541280693741 \n",
      "acc for Psat= 0.18291042417070263 \n",
      "acc for optim= 0.17385073640411453\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.00560226384550333\n",
      "Loss on test= 0.007206250913441181\n",
      "acc for Lsat= 0.15453735080239417 \n",
      "acc for Psat= 0.18062069462326005 \n",
      "acc for optim= 0.17957141467095275\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.00536756357178092\n",
      "Loss on test= 0.007570488844066858\n",
      "acc for Lsat= 0.14636865299458418 \n",
      "acc for Psat= 0.17357225735351198 \n",
      "acc for optim= 0.18125655548150849\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.005278480239212513\n",
      "Loss on test= 0.0068659596145153046\n",
      "acc for Lsat= 0.15453493755890943 \n",
      "acc for Psat= 0.19726273185620274 \n",
      "acc for optim= 0.1760258803583756\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.005293825175613165\n",
      "Loss on test= 0.0068642678670585155\n",
      "acc for Lsat= 0.1566247568494396 \n",
      "acc for Psat= 0.1845107835528563 \n",
      "acc for optim= 0.17576107268534663\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.005512815900146961\n",
      "Loss on test= 0.007140866480767727\n",
      "acc for Lsat= 0.149889585924894 \n",
      "acc for Psat= 0.1789803736911008 \n",
      "acc for optim= 0.17715064420318993\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.005354970693588257\n",
      "Loss on test= 0.006914414931088686\n",
      "acc for Lsat= 0.1662439759595503 \n",
      "acc for Psat= 0.1876270013137102 \n",
      "acc for optim= 0.17549701105678248\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.005218931008130312\n",
      "Loss on test= 0.007320650853216648\n",
      "acc for Lsat= 0.15135315064857066 \n",
      "acc for Psat= 0.18286635410326885 \n",
      "acc for optim= 0.1707330081645031\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.005630184896290302\n",
      "Loss on test= 0.00709151616320014\n",
      "acc for Lsat= 0.1506665271561837 \n",
      "acc for Psat= 0.19158838508559056 \n",
      "acc for optim= 0.17614432475694214\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.005960414651781321\n",
      "Loss on test= 0.007170762401074171\n",
      "acc for Lsat= 0.15651005043831395 \n",
      "acc for Psat= 0.1806139202920155 \n",
      "acc for optim= 0.17674310535600898\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.005463696084916592\n",
      "Loss on test= 0.00717961834743619\n",
      "acc for Lsat= 0.15954484526179138 \n",
      "acc for Psat= 0.18490537835850923 \n",
      "acc for optim= 0.17947547197013666\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.005216165445744991\n",
      "Loss on test= 0.007174648344516754\n",
      "acc for Lsat= 0.15459216981057505 \n",
      "acc for Psat= 0.187133945859816 \n",
      "acc for optim= 0.1770152015520401\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.005520837847143412\n",
      "Loss on test= 0.007086426950991154\n",
      "acc for Lsat= 0.15225282244109473 \n",
      "acc for Psat= 0.1870329679152642 \n",
      "acc for optim= 0.1799420830240229\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.005426125600934029\n",
      "Loss on test= 0.006865322589874268\n",
      "acc for Lsat= 0.16485056909350831 \n",
      "acc for Psat= 0.19331584447234074 \n",
      "acc for optim= 0.17876848644027335\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.005206356290727854\n",
      "Loss on test= 0.0074774459935724735\n",
      "acc for Lsat= 0.16363745858075981 \n",
      "acc for Psat= 0.17745487505529978 \n",
      "acc for optim= 0.17711791151382608\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.005462177097797394\n",
      "Loss on test= 0.0072702644392848015\n",
      "acc for Lsat= 0.1617040267836333 \n",
      "acc for Psat= 0.1944519378893928 \n",
      "acc for optim= 0.1792938356081665\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.00540516572073102\n",
      "Loss on test= 0.006616480648517609\n",
      "acc for Lsat= 0.14835599284393897 \n",
      "acc for Psat= 0.1774404777839902 \n",
      "acc for optim= 0.17815807410401338\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.005434255115687847\n",
      "Loss on test= 0.0072761401534080505\n",
      "acc for Lsat= 0.15579840064079303 \n",
      "acc for Psat= 0.19105945312624156 \n",
      "acc for optim= 0.18653727218310243\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.0056181191466748714\n",
      "Loss on test= 0.007114756852388382\n",
      "acc for Lsat= 0.13528714316122264 \n",
      "acc for Psat= 0.1895143574896673 \n",
      "acc for optim= 0.17586960070842847\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.00525143276900053\n",
      "Loss on test= 0.0070541477762162685\n",
      "acc for Lsat= 0.1613546757172549 \n",
      "acc for Psat= 0.191140765663557 \n",
      "acc for optim= 0.1766739149962468\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.0056938668712973595\n",
      "Loss on test= 0.007048599887639284\n",
      "acc for Lsat= 0.15411502857755519 \n",
      "acc for Psat= 0.19620747562177235 \n",
      "acc for optim= 0.17873885986914279\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.005295624025166035\n",
      "Loss on test= 0.006773835513740778\n",
      "acc for Lsat= 0.14322192341286774 \n",
      "acc for Psat= 0.1965983066280357 \n",
      "acc for optim= 0.1798378067808684\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.005230186972767115\n",
      "Loss on test= 0.006646096706390381\n",
      "acc for Lsat= 0.1598344055737262 \n",
      "acc for Psat= 0.1809077406892759 \n",
      "acc for optim= 0.1785872936848032\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.0054161641746759415\n",
      "Loss on test= 0.007131719030439854\n",
      "acc for Lsat= 0.15166467566703462 \n",
      "acc for Psat= 0.1945769750276489 \n",
      "acc for optim= 0.1738378816060951\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.005472983233630657\n",
      "Loss on test= 0.006802528630942106\n",
      "acc for Lsat= 0.15726631406621175 \n",
      "acc for Psat= 0.18750441494859663 \n",
      "acc for optim= 0.18228886499504757\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.005381743423640728\n",
      "Loss on test= 0.006820503622293472\n",
      "acc for Lsat= 0.15999065904141418 \n",
      "acc for Psat= 0.20088925986258757 \n",
      "acc for optim= 0.17443111784580606\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.005290005821734667\n",
      "Loss on test= 0.007021892815828323\n",
      "acc for Lsat= 0.14609224619878242 \n",
      "acc for Psat= 0.19045486514586343 \n",
      "acc for optim= 0.17934792197969518\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.005464897491037846\n",
      "Loss on test= 0.007383690681308508\n",
      "acc for Lsat= 0.15123697730825192 \n",
      "acc for Psat= 0.1761674693611939 \n",
      "acc for optim= 0.17140542983433393\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.005394733976572752\n",
      "Loss on test= 0.007117496337741613\n",
      "acc for Lsat= 0.15895793168790273 \n",
      "acc for Psat= 0.18645004212506092 \n",
      "acc for optim= 0.17650498464114564\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.005538369528949261\n",
      "Loss on test= 0.007113961037248373\n",
      "acc for Lsat= 0.15236380037271463 \n",
      "acc for Psat= 0.19067580383041965 \n",
      "acc for optim= 0.17687745799852506\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.005792009644210339\n",
      "Loss on test= 0.006862923968583345\n",
      "acc for Lsat= 0.1623647894576711 \n",
      "acc for Psat= 0.18520310707084955 \n",
      "acc for optim= 0.17986563975678482\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.005539339035749435\n",
      "Loss on test= 0.006780414842069149\n",
      "acc for Lsat= 0.15219010716498846 \n",
      "acc for Psat= 0.19702032754029775 \n",
      "acc for optim= 0.17533720316266121\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.005409743171185255\n",
      "Loss on test= 0.007084042765200138\n",
      "acc for Lsat= 0.1484136634249599 \n",
      "acc for Psat= 0.18887873664345653 \n",
      "acc for optim= 0.17382266282821532\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.005309307016432285\n",
      "Loss on test= 0.006874290760606527\n",
      "acc for Lsat= 0.15626597603321168 \n",
      "acc for Psat= 0.18494511527464294 \n",
      "acc for optim= 0.17252703289669313\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005346106830984354\n",
      "Loss on test= 0.007001393940299749\n",
      "acc for Lsat= 0.14948146985276015 \n",
      "acc for Psat= 0.1770492584204118 \n",
      "acc for optim= 0.1710088956020925\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.005247373133897781\n",
      "Loss on test= 0.007109584286808968\n",
      "acc for Lsat= 0.1511710977218053 \n",
      "acc for Psat= 0.17386396563761977 \n",
      "acc for optim= 0.17588963386293532\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.005393194500356913\n",
      "Loss on test= 0.007137153297662735\n",
      "acc for Lsat= 0.15736010210649645 \n",
      "acc for Psat= 0.18505150567831807 \n",
      "acc for optim= 0.17759845263675833\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.005192284006625414\n",
      "Loss on test= 0.0067751118913292885\n",
      "acc for Lsat= 0.1595867724558644 \n",
      "acc for Psat= 0.19336679607217552 \n",
      "acc for optim= 0.17537051887594002\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.0053013646975159645\n",
      "Loss on test= 0.006716045085340738\n",
      "acc for Lsat= 0.1527082589855723 \n",
      "acc for Psat= 0.17813344348592255 \n",
      "acc for optim= 0.17862791697185518\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.005456994287669659\n",
      "Loss on test= 0.007048039231449366\n",
      "acc for Lsat= 0.15408547260019867 \n",
      "acc for Psat= 0.18362821455086872 \n",
      "acc for optim= 0.17761383846961104\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.0057911621406674385\n",
      "Loss on test= 0.007077193818986416\n",
      "acc for Lsat= 0.1592318930392169 \n",
      "acc for Psat= 0.19557721367779524 \n",
      "acc for optim= 0.1794190130390219\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.0052322931587696075\n",
      "Loss on test= 0.007114476058632135\n",
      "acc for Lsat= 0.15457493739782788 \n",
      "acc for Psat= 0.18732087089351881 \n",
      "acc for optim= 0.18659163659031036\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.0054426779970526695\n",
      "Loss on test= 0.006737655960023403\n",
      "acc for Lsat= 0.15610451234245032 \n",
      "acc for Psat= 0.1961384314936815 \n",
      "acc for optim= 0.1797595987684231\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.006360222585499287\n",
      "Loss on test= 0.006834575906395912\n",
      "acc for Lsat= 0.15793086824915753 \n",
      "acc for Psat= 0.19172540109310696 \n",
      "acc for optim= 0.17518719116542641\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.0050780209712684155\n",
      "Loss on test= 0.006802654359489679\n",
      "acc for Lsat= 0.15624143381862612 \n",
      "acc for Psat= 0.17997826414152246 \n",
      "acc for optim= 0.17236070464097764\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.005289787892252207\n",
      "Loss on test= 0.007029586471617222\n",
      "acc for Lsat= 0.14714155823114466 \n",
      "acc for Psat= 0.19349750290914883 \n",
      "acc for optim= 0.17314523233245813\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.00572813767939806\n",
      "Loss on test= 0.006854266859591007\n",
      "acc for Lsat= 0.14409617921289775 \n",
      "acc for Psat= 0.18335422317604305 \n",
      "acc for optim= 0.1765436530452924\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.005333784501999617\n",
      "Loss on test= 0.007074276451021433\n",
      "acc for Lsat= 0.15283675696624474 \n",
      "acc for Psat= 0.17631673276220203 \n",
      "acc for optim= 0.18173934418524876\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.0054549528285861015\n",
      "Loss on test= 0.00759316748008132\n",
      "acc for Lsat= 0.14903488578961888 \n",
      "acc for Psat= 0.1888820868826874 \n",
      "acc for optim= 0.17612715679322002\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.005588778760284185\n",
      "Loss on test= 0.00676076440140605\n",
      "acc for Lsat= 0.15732178785246567 \n",
      "acc for Psat= 0.19984620265418387 \n",
      "acc for optim= 0.16941890650549063\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.0053772758692502975\n",
      "Loss on test= 0.007105016615241766\n",
      "acc for Lsat= 0.14975505726584654 \n",
      "acc for Psat= 0.19722550188488952 \n",
      "acc for optim= 0.17408511218515638\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005848350934684277\n",
      "Loss on test= 0.007154369261115789\n",
      "acc for Lsat= 0.15257029081427598 \n",
      "acc for Psat= 0.19651041686321136 \n",
      "acc for optim= 0.17744147721143652\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.005312774330377579\n",
      "Loss on test= 0.00709899514913559\n",
      "acc for Lsat= 0.15445436693348188 \n",
      "acc for Psat= 0.18994483293194445 \n",
      "acc for optim= 0.17530473862807114\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.005329900421202183\n",
      "Loss on test= 0.007604511454701424\n",
      "acc for Lsat= 0.1453561262087324 \n",
      "acc for Psat= 0.18008463037678338 \n",
      "acc for optim= 0.1765047099207028\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.005576496012508869\n",
      "Loss on test= 0.00701133394613862\n",
      "acc for Lsat= 0.15774076806942428 \n",
      "acc for Psat= 0.17194611427839845 \n",
      "acc for optim= 0.17664075985543246\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.005454332567751408\n",
      "Loss on test= 0.00702998461201787\n",
      "acc for Lsat= 0.1433380300366152 \n",
      "acc for Psat= 0.19547482207474742 \n",
      "acc for optim= 0.1756881938754871\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.005393213126808405\n",
      "Loss on test= 0.007290206849575043\n",
      "acc for Lsat= 0.16099290377994785 \n",
      "acc for Psat= 0.1927291149948151 \n",
      "acc for optim= 0.17593032877365525\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.005257705692201853\n",
      "Loss on test= 0.007411525119096041\n",
      "acc for Lsat= 0.15496691552765637 \n",
      "acc for Psat= 0.17845011067282807 \n",
      "acc for optim= 0.17434879295718422\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.005373192019760609\n",
      "Loss on test= 0.007035433780401945\n",
      "acc for Lsat= 0.14884063867760486 \n",
      "acc for Psat= 0.19908868305915423 \n",
      "acc for optim= 0.17816252394566945\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.005447062198072672\n",
      "Loss on test= 0.007254542782902718\n",
      "acc for Lsat= 0.16485756735158053 \n",
      "acc for Psat= 0.1872197990840087 \n",
      "acc for optim= 0.18685132397422718\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.005548479501157999\n",
      "Loss on test= 0.007354253903031349\n",
      "acc for Lsat= 0.1511319981429432 \n",
      "acc for Psat= 0.183905231004932 \n",
      "acc for optim= 0.17147126279840033\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.005555334500968456\n",
      "Loss on test= 0.007292371708899736\n",
      "acc for Lsat= 0.14443925315605813 \n",
      "acc for Psat= 0.20538745266652558 \n",
      "acc for optim= 0.1799501534483632\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.005450159776955843\n",
      "Loss on test= 0.007088883314281702\n",
      "acc for Lsat= 0.16382987332973079 \n",
      "acc for Psat= 0.19213998120155978 \n",
      "acc for optim= 0.17959939528831098\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.0055969394743442535\n",
      "Loss on test= 0.006973701063543558\n",
      "acc for Lsat= 0.14041620655050674 \n",
      "acc for Psat= 0.18443159487930538 \n",
      "acc for optim= 0.17421833053799002\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.005353202577680349\n",
      "Loss on test= 0.00723603181540966\n",
      "acc for Lsat= 0.157704081832332 \n",
      "acc for Psat= 0.1820740695935903 \n",
      "acc for optim= 0.17602921265738514\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.005699503235518932\n",
      "Loss on test= 0.006794400978833437\n",
      "acc for Lsat= 0.16032452489169252 \n",
      "acc for Psat= 0.19111855318227097 \n",
      "acc for optim= 0.17650907233950958\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.005467484705150127\n",
      "Loss on test= 0.006821639370173216\n",
      "acc for Lsat= 0.15131762865472767 \n",
      "acc for Psat= 0.19360429680215377 \n",
      "acc for optim= 0.1803835887944261\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.005271729547530413\n",
      "Loss on test= 0.006941352970898151\n",
      "acc for Lsat= 0.14610273495228718 \n",
      "acc for Psat= 0.19012128751511212 \n",
      "acc for optim= 0.17572259276401114\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.005221644416451454\n",
      "Loss on test= 0.006081415340304375\n",
      "acc for Lsat= 0.1605713180552588 \n",
      "acc for Psat= 0.1838323676305991 \n",
      "acc for optim= 0.1784361607899897\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.00547025678679347\n",
      "Loss on test= 0.007052487228065729\n",
      "acc for Lsat= 0.143776273078163 \n",
      "acc for Psat= 0.19271062314472176 \n",
      "acc for optim= 0.18014592490518955\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.0054490999318659306\n",
      "Loss on test= 0.006940760184079409\n",
      "acc for Lsat= 0.15345209442352453 \n",
      "acc for Psat= 0.1823208904655299 \n",
      "acc for optim= 0.1825263665050085\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.0055154794827103615\n",
      "Loss on test= 0.00717700133100152\n",
      "acc for Lsat= 0.14647193140685213 \n",
      "acc for Psat= 0.17385980259306485 \n",
      "acc for optim= 0.17584381269716612\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.005631540901958942\n",
      "Loss on test= 0.0070994822308421135\n",
      "acc for Lsat= 0.14796907529781178 \n",
      "acc for Psat= 0.18106961197880111 \n",
      "acc for optim= 0.17130659412157045\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.005430222488939762\n",
      "Loss on test= 0.006800932809710503\n",
      "acc for Lsat= 0.14996716554360617 \n",
      "acc for Psat= 0.1903087183035391 \n",
      "acc for optim= 0.1817108581626032\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.005658543668687344\n",
      "Loss on test= 0.007018544245511293\n",
      "acc for Lsat= 0.15269658211446901 \n",
      "acc for Psat= 0.18569804564897033 \n",
      "acc for optim= 0.18012082570234358\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005228952504694462\n",
      "Loss on test= 0.0071708508767187595\n",
      "acc for Lsat= 0.1569890837249972 \n",
      "acc for Psat= 0.19055898793186749 \n",
      "acc for optim= 0.17621998425199054\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.0053677367977797985\n",
      "Loss on test= 0.0072847106494009495\n",
      "acc for Lsat= 0.1388434351185245 \n",
      "acc for Psat= 0.1711141224537373 \n",
      "acc for optim= 0.17453388916271295\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.005336964502930641\n",
      "Loss on test= 0.00671007577329874\n",
      "acc for Lsat= 0.15329231553039224 \n",
      "acc for Psat= 0.19315702909676236 \n",
      "acc for optim= 0.17498230946357132\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.005474039353430271\n",
      "Loss on test= 0.007156724575906992\n",
      "acc for Lsat= 0.1493789171112022 \n",
      "acc for Psat= 0.17029525781537933 \n",
      "acc for optim= 0.18118561220195023\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.005296994466334581\n",
      "Loss on test= 0.0069851079024374485\n",
      "acc for Lsat= 0.15339085571544214 \n",
      "acc for Psat= 0.17304607870679378 \n",
      "acc for optim= 0.17475794482724283\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.005521445535123348\n",
      "Loss on test= 0.007222683634608984\n",
      "acc for Lsat= 0.15738964069092676 \n",
      "acc for Psat= 0.20257358208268147 \n",
      "acc for optim= 0.17642566802230145\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.005506782326847315\n",
      "Loss on test= 0.0067238761112093925\n",
      "acc for Lsat= 0.13837835597075698 \n",
      "acc for Psat= 0.18920986845909968 \n",
      "acc for optim= 0.1744927074068088\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.005559886340051889\n",
      "Loss on test= 0.007143454626202583\n",
      "acc for Lsat= 0.1424672815467796 \n",
      "acc for Psat= 0.183026447053617 \n",
      "acc for optim= 0.1841360218847766\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.005288326181471348\n",
      "Loss on test= 0.007084897253662348\n",
      "acc for Lsat= 0.15509866898207636 \n",
      "acc for Psat= 0.18067674997270292 \n",
      "acc for optim= 0.17593983510694253\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.005437212996184826\n",
      "Loss on test= 0.006696305703371763\n",
      "acc for Lsat= 0.14449246634485163 \n",
      "acc for Psat= 0.18294665669415483 \n",
      "acc for optim= 0.1758051760048132\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.005418728571385145\n",
      "Loss on test= 0.007103607524186373\n",
      "acc for Lsat= 0.15036494163281025 \n",
      "acc for Psat= 0.1895167538785513 \n",
      "acc for optim= 0.176860958485116\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.005542431958019733\n",
      "Loss on test= 0.00688297301530838\n",
      "acc for Lsat= 0.16029108084860394 \n",
      "acc for Psat= 0.1866916571209421 \n",
      "acc for optim= 0.18106436789809674\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.005250715650618076\n",
      "Loss on test= 0.007053261157125235\n",
      "acc for Lsat= 0.16192409699729293 \n",
      "acc for Psat= 0.1882400937981476 \n",
      "acc for optim= 0.17409249007211403\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.005597412586212158\n",
      "Loss on test= 0.007479685824364424\n",
      "acc for Lsat= 0.15357796634608484 \n",
      "acc for Psat= 0.18733458330885308 \n",
      "acc for optim= 0.17639957499636919\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.005208703223615885\n",
      "Loss on test= 0.007263782434165478\n",
      "acc for Lsat= 0.15676151361377513 \n",
      "acc for Psat= 0.1881305758757364 \n",
      "acc for optim= 0.16981860515318017\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.005343966651707888\n",
      "Loss on test= 0.007071051746606827\n",
      "acc for Lsat= 0.15281485788863855 \n",
      "acc for Psat= 0.18068231564328047 \n",
      "acc for optim= 0.17900029818637614\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.005603174213320017\n",
      "Loss on test= 0.007243015803396702\n",
      "acc for Lsat= 0.14002861396235902 \n",
      "acc for Psat= 0.18752631756217508 \n",
      "acc for optim= 0.17183578287568096\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.0058631496503949165\n",
      "Loss on test= 0.006934225559234619\n",
      "acc for Lsat= 0.15215538677601545 \n",
      "acc for Psat= 0.18643560414507862 \n",
      "acc for optim= 0.18166155118044833\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.005642702337354422\n",
      "Loss on test= 0.007189139258116484\n",
      "acc for Lsat= 0.15541999147227797 \n",
      "acc for Psat= 0.1942045387192727 \n",
      "acc for optim= 0.1714131616663806\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.0052307406440377235\n",
      "Loss on test= 0.006859140936285257\n",
      "acc for Lsat= 0.14836852815170146 \n",
      "acc for Psat= 0.19258308155943074 \n",
      "acc for optim= 0.1728484650663497\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.0055028898641467094\n",
      "Loss on test= 0.007235642522573471\n",
      "acc for Lsat= 0.16213996216757834 \n",
      "acc for Psat= 0.18625916871413986 \n",
      "acc for optim= 0.17707708524715704\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.00550747150555253\n",
      "Loss on test= 0.006860538385808468\n",
      "acc for Lsat= 0.15650127673021624 \n",
      "acc for Psat= 0.18737484088289688 \n",
      "acc for optim= 0.17590484615481175\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.005524079315364361\n",
      "Loss on test= 0.007208072114735842\n",
      "acc for Lsat= 0.16139074840552373 \n",
      "acc for Psat= 0.18239283880722693 \n",
      "acc for optim= 0.17478620284609114\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.005091829691082239\n",
      "Loss on test= 0.006759535055607557\n",
      "acc for Lsat= 0.15226010732251585 \n",
      "acc for Psat= 0.19536895366332144 \n",
      "acc for optim= 0.17535843041899127\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.0051262592896819115\n",
      "Loss on test= 0.006963173393160105\n",
      "acc for Lsat= 0.1663860554816024 \n",
      "acc for Psat= 0.19759768346309295 \n",
      "acc for optim= 0.17385920930890458\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.0056115915067493916\n",
      "Loss on test= 0.007081903982907534\n",
      "acc for Lsat= 0.17178788248339352 \n",
      "acc for Psat= 0.18087515547856323 \n",
      "acc for optim= 0.18197085475940333\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.005214124917984009\n",
      "Loss on test= 0.006977126467972994\n",
      "acc for Lsat= 0.14746058843381032 \n",
      "acc for Psat= 0.19967948169844438 \n",
      "acc for optim= 0.17140130684405688\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.00548148388043046\n",
      "Loss on test= 0.006774347275495529\n",
      "acc for Lsat= 0.15635008765499062 \n",
      "acc for Psat= 0.19975801779636654 \n",
      "acc for optim= 0.18103218793594203\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.005790496710687876\n",
      "Loss on test= 0.006939257960766554\n",
      "acc for Lsat= 0.1644280288093647 \n",
      "acc for Psat= 0.18225957323361922 \n",
      "acc for optim= 0.17756561082468147\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.0051574185490608215\n",
      "Loss on test= 0.007719952147454023\n",
      "acc for Lsat= 0.1620924553561948 \n",
      "acc for Psat= 0.1904812424523817 \n",
      "acc for optim= 0.17241963095629978\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.005372519604861736\n",
      "Loss on test= 0.00673917168751359\n",
      "acc for Lsat= 0.14709655107018066 \n",
      "acc for Psat= 0.18427690382985795 \n",
      "acc for optim= 0.17738988282980558\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005533701274544001\n",
      "Loss on test= 0.007141160778701305\n",
      "acc for Lsat= 0.13889581833080555 \n",
      "acc for Psat= 0.19114763500802523 \n",
      "acc for optim= 0.1769431900737576\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.005196710117161274\n",
      "Loss on test= 0.0070540085434913635\n",
      "acc for Lsat= 0.1599769724704722 \n",
      "acc for Psat= 0.18398602876629008 \n",
      "acc for optim= 0.17552638854507022\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005436672829091549\n",
      "Loss on test= 0.007420068606734276\n",
      "acc for Lsat= 0.15088209579088038 \n",
      "acc for Psat= 0.18550033434141489 \n",
      "acc for optim= 0.1780575616183103\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.005265726242214441\n",
      "Loss on test= 0.0072284238412976265\n",
      "acc for Lsat= 0.16130789614732943 \n",
      "acc for Psat= 0.1866482770933052 \n",
      "acc for optim= 0.1744976167685398\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.006029239855706692\n",
      "Loss on test= 0.007444239221513271\n",
      "acc for Lsat= 0.15799562367782394 \n",
      "acc for Psat= 0.1852474250754372 \n",
      "acc for optim= 0.17369498757566287\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.00563005218282342\n",
      "Loss on test= 0.007066149730235338\n",
      "acc for Lsat= 0.14780553024036516 \n",
      "acc for Psat= 0.20518296833081384 \n",
      "acc for optim= 0.17761451879484755\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.005339065566658974\n",
      "Loss on test= 0.007243557367473841\n",
      "acc for Lsat= 0.14878368280721335 \n",
      "acc for Psat= 0.18946631506446093 \n",
      "acc for optim= 0.1786585925711838\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.005160497967153788\n",
      "Loss on test= 0.007167020346969366\n",
      "acc for Lsat= 0.14481437649009138 \n",
      "acc for Psat= 0.1874653943890675 \n",
      "acc for optim= 0.176221095777611\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.00599235575646162\n",
      "Loss on test= 0.006880189757794142\n",
      "acc for Lsat= 0.15999263403097502 \n",
      "acc for Psat= 0.17555319092572347 \n",
      "acc for optim= 0.18245287980678201\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005470679607242346\n",
      "Loss on test= 0.007145814597606659\n",
      "acc for Lsat= 0.15048536156771988 \n",
      "acc for Psat= 0.19000194148889543 \n",
      "acc for optim= 0.17925505475627762\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.005262210965156555\n",
      "Loss on test= 0.007021639961749315\n",
      "acc for Lsat= 0.14295615914934237 \n",
      "acc for Psat= 0.18711020879272838 \n",
      "acc for optim= 0.1712553009944758\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.005501606035977602\n",
      "Loss on test= 0.0067571052350103855\n",
      "acc for Lsat= 0.15478608555420012 \n",
      "acc for Psat= 0.17355995377540956 \n",
      "acc for optim= 0.17456170439044563\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.005198678933084011\n",
      "Loss on test= 0.006825614254921675\n",
      "acc for Lsat= 0.16165961079045627 \n",
      "acc for Psat= 0.2056711911582617 \n",
      "acc for optim= 0.1757760623019555\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.005426471121609211\n",
      "Loss on test= 0.007169337943196297\n",
      "acc for Lsat= 0.16226025975140415 \n",
      "acc for Psat= 0.185113397388448 \n",
      "acc for optim= 0.17724617044202845\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.005130053497850895\n",
      "Loss on test= 0.006692016962915659\n",
      "acc for Lsat= 0.15481779345103203 \n",
      "acc for Psat= 0.18356595552090096 \n",
      "acc for optim= 0.17708899979670456\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.005151746328920126\n",
      "Loss on test= 0.007139780558645725\n",
      "acc for Lsat= 0.16506002788426216 \n",
      "acc for Psat= 0.20293007961046866 \n",
      "acc for optim= 0.17466215035576588\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.005170356947928667\n",
      "Loss on test= 0.007117815315723419\n",
      "acc for Lsat= 0.1412057422231272 \n",
      "acc for Psat= 0.1830035658827105 \n",
      "acc for optim= 0.17766644066733073\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.005395827814936638\n",
      "Loss on test= 0.007220832630991936\n",
      "acc for Lsat= 0.14258722144782116 \n",
      "acc for Psat= 0.19100798441127675 \n",
      "acc for optim= 0.18222196232603832\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005444756243377924\n",
      "Loss on test= 0.007167974952608347\n",
      "acc for Lsat= 0.15453338003335673 \n",
      "acc for Psat= 0.1880324444605694 \n",
      "acc for optim= 0.17864099257266852\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.005365724675357342\n",
      "Loss on test= 0.006755768787115812\n",
      "acc for Lsat= 0.15753143262786132 \n",
      "acc for Psat= 0.19710240857429362 \n",
      "acc for optim= 0.1791649475784354\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.0052412948571145535\n",
      "Loss on test= 0.007100230548530817\n",
      "acc for Lsat= 0.16388067847077703 \n",
      "acc for Psat= 0.1787567983648633 \n",
      "acc for optim= 0.17874682955138507\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.005466471426188946\n",
      "Loss on test= 0.007146972697228193\n",
      "acc for Lsat= 0.1511646904973084 \n",
      "acc for Psat= 0.19008027938896882 \n",
      "acc for optim= 0.1806614617289895\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.005402703769505024\n",
      "Loss on test= 0.006876251194626093\n",
      "acc for Lsat= 0.14392089595756738 \n",
      "acc for Psat= 0.1816571359102782 \n",
      "acc for optim= 0.17366606598456588\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.0055847675539553165\n",
      "Loss on test= 0.0070139761082828045\n",
      "acc for Lsat= 0.16022493739032231 \n",
      "acc for Psat= 0.19151055517178944 \n",
      "acc for optim= 0.17947137856552545\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.005701822228729725\n",
      "Loss on test= 0.007042185869067907\n",
      "acc for Lsat= 0.154078161083429 \n",
      "acc for Psat= 0.1710953932526506 \n",
      "acc for optim= 0.17306490266871197\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.005184059962630272\n",
      "Loss on test= 0.00688353693112731\n",
      "acc for Lsat= 0.14903201211222875 \n",
      "acc for Psat= 0.19667416537241614 \n",
      "acc for optim= 0.17567429990568734\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.005387593526393175\n",
      "Loss on test= 0.006465676706284285\n",
      "acc for Lsat= 0.15419948264588143 \n",
      "acc for Psat= 0.19061617336873363 \n",
      "acc for optim= 0.1858713798214206\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.00520495418459177\n",
      "Loss on test= 0.006679100450128317\n",
      "acc for Lsat= 0.15270324160495666 \n",
      "acc for Psat= 0.18762249745367493 \n",
      "acc for optim= 0.1745600348881438\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.005668953526765108\n",
      "Loss on test= 0.007304383907467127\n",
      "acc for Lsat= 0.14984717622330626 \n",
      "acc for Psat= 0.19510709004186583 \n",
      "acc for optim= 0.1807242759532051\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.00529836630448699\n",
      "Loss on test= 0.007132569327950478\n",
      "acc for Lsat= 0.14552442388471643 \n",
      "acc for Psat= 0.18465007450851445 \n",
      "acc for optim= 0.18368774580761607\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.005116411484777927\n",
      "Loss on test= 0.0072216917760670185\n",
      "acc for Lsat= 0.14863515485771817 \n",
      "acc for Psat= 0.18433382870719126 \n",
      "acc for optim= 0.17612370811078362\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.005436144769191742\n",
      "Loss on test= 0.007018523756414652\n",
      "acc for Lsat= 0.1500941458162012 \n",
      "acc for Psat= 0.17470022058896872 \n",
      "acc for optim= 0.17601454643318887\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.005333590321242809\n",
      "Loss on test= 0.006674014497548342\n",
      "acc for Lsat= 0.15510782389787073 \n",
      "acc for Psat= 0.1752551973064537 \n",
      "acc for optim= 0.18439984036319446\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.0053622485138475895\n",
      "Loss on test= 0.007417638320475817\n",
      "acc for Lsat= 0.14449870492270614 \n",
      "acc for Psat= 0.18760889721728982 \n",
      "acc for optim= 0.17959420361248854\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.005240274127572775\n",
      "Loss on test= 0.007138081826269627\n",
      "acc for Lsat= 0.14934803143479541 \n",
      "acc for Psat= 0.1921069870760176 \n",
      "acc for optim= 0.1834436278707218\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.005430347286164761\n",
      "Loss on test= 0.006951515097171068\n",
      "acc for Lsat= 0.1559745466661044 \n",
      "acc for Psat= 0.1940283386740971 \n",
      "acc for optim= 0.1743846858929858\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.005140581633895636\n",
      "Loss on test= 0.007108489982783794\n",
      "acc for Lsat= 0.14940822543175586 \n",
      "acc for Psat= 0.18249579683503472 \n",
      "acc for optim= 0.1761577858685012\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005621481686830521\n",
      "Loss on test= 0.006989894900470972\n",
      "acc for Lsat= 0.16132015269631367 \n",
      "acc for Psat= 0.19217022204061696 \n",
      "acc for optim= 0.17724093921639056\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.005235821940004826\n",
      "Loss on test= 0.0069065154530107975\n",
      "acc for Lsat= 0.15804401542151683 \n",
      "acc for Psat= 0.1922156838093766 \n",
      "acc for optim= 0.1825503278411085\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.005399380810558796\n",
      "Loss on test= 0.0067558554001152515\n",
      "acc for Lsat= 0.1480152411447441 \n",
      "acc for Psat= 0.19514552249313621 \n",
      "acc for optim= 0.17440723197064248\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.005548399873077869\n",
      "Loss on test= 0.0065245479345321655\n",
      "acc for Lsat= 0.1545261015667061 \n",
      "acc for Psat= 0.17344432600323478 \n",
      "acc for optim= 0.18373189960094932\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.005469123832881451\n",
      "Loss on test= 0.007195163052529097\n",
      "acc for Lsat= 0.15022651196360115 \n",
      "acc for Psat= 0.19781028541696227 \n",
      "acc for optim= 0.1776774407616343\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.005415764171630144\n",
      "Loss on test= 0.007122938521206379\n",
      "acc for Lsat= 0.15705030114603702 \n",
      "acc for Psat= 0.20962294205435414 \n",
      "acc for optim= 0.17411337198744925\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.005518126301467419\n",
      "Loss on test= 0.007156393025070429\n",
      "acc for Lsat= 0.1669562683730829 \n",
      "acc for Psat= 0.19278607089072466 \n",
      "acc for optim= 0.17505344728878164\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.005239925347268581\n",
      "Loss on test= 0.0067479913122951984\n",
      "acc for Lsat= 0.16301439268613277 \n",
      "acc for Psat= 0.18470763971029064 \n",
      "acc for optim= 0.1760660394386877\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.005366885103285313\n",
      "Loss on test= 0.007167657371610403\n",
      "acc for Lsat= 0.1505322856622458 \n",
      "acc for Psat= 0.1884106531777404 \n",
      "acc for optim= 0.17761721267655003\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.005330491345375776\n",
      "Loss on test= 0.006870460696518421\n",
      "acc for Lsat= 0.14510380693341102 \n",
      "acc for Psat= 0.18413302043040633 \n",
      "acc for optim= 0.1774106239243487\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.0052721272222697735\n",
      "Loss on test= 0.007110103033483028\n",
      "acc for Lsat= 0.16271476431513113 \n",
      "acc for Psat= 0.18059229698780252 \n",
      "acc for optim= 0.17769352021363763\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.00529820378869772\n",
      "Loss on test= 0.007253388874232769\n",
      "acc for Lsat= 0.16179854716441489 \n",
      "acc for Psat= 0.18307969351604458 \n",
      "acc for optim= 0.17224753850886834\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.005255940370261669\n",
      "Loss on test= 0.006699974648654461\n",
      "acc for Lsat= 0.1714632646631083 \n",
      "acc for Psat= 0.18551248085940805 \n",
      "acc for optim= 0.1742624406091159\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005902689881622791\n",
      "Loss on test= 0.006906148977577686\n",
      "acc for Lsat= 0.1522746791624174 \n",
      "acc for Psat= 0.18105245865843275 \n",
      "acc for optim= 0.17521905081220673\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.0054829418659210205\n",
      "Loss on test= 0.006913281977176666\n",
      "acc for Lsat= 0.15967497748750278 \n",
      "acc for Psat= 0.19563683898371384 \n",
      "acc for optim= 0.17597429864337577\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.005266067571938038\n",
      "Loss on test= 0.00696197897195816\n",
      "acc for Lsat= 0.1568637650643216 \n",
      "acc for Psat= 0.18658914716372058 \n",
      "acc for optim= 0.17553384114938528\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.005061612464487553\n",
      "Loss on test= 0.0068596345372498035\n",
      "acc for Lsat= 0.15707031674559044 \n",
      "acc for Psat= 0.18563283882180198 \n",
      "acc for optim= 0.17228830795628725\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.0054056523367762566\n",
      "Loss on test= 0.006560514215379953\n",
      "acc for Lsat= 0.15831132168293793 \n",
      "acc for Psat= 0.18510500261518095 \n",
      "acc for optim= 0.17960236156607412\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.005852984730154276\n",
      "Loss on test= 0.007232210133224726\n",
      "acc for Lsat= 0.1518122901021671 \n",
      "acc for Psat= 0.17079943375142873 \n",
      "acc for optim= 0.1780699537681477\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.005203730892390013\n",
      "Loss on test= 0.007200038060545921\n",
      "acc for Lsat= 0.16157699833074432 \n",
      "acc for Psat= 0.1888063348474775 \n",
      "acc for optim= 0.16880477376234027\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.005588487256318331\n",
      "Loss on test= 0.006828582379966974\n",
      "acc for Lsat= 0.1639991430638236 \n",
      "acc for Psat= 0.17975117762813528 \n",
      "acc for optim= 0.17586585177551406\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.00613983953371644\n",
      "Loss on test= 0.006967771798372269\n",
      "acc for Lsat= 0.16361561068801256 \n",
      "acc for Psat= 0.19151556496622926 \n",
      "acc for optim= 0.1730341809340867\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.0056208474561572075\n",
      "Loss on test= 0.006968651432543993\n",
      "acc for Lsat= 0.1550146693522187 \n",
      "acc for Psat= 0.1836764579444177 \n",
      "acc for optim= 0.17636025568701638\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.00540219247341156\n",
      "Loss on test= 0.007188495248556137\n",
      "acc for Lsat= 0.150289808550361 \n",
      "acc for Psat= 0.18208823073121003 \n",
      "acc for optim= 0.17282606181077903\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.0055075702257454395\n",
      "Loss on test= 0.00715227983891964\n",
      "acc for Lsat= 0.15011769260877894 \n",
      "acc for Psat= 0.1859141393247839 \n",
      "acc for optim= 0.16640751769777662\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.005254202522337437\n",
      "Loss on test= 0.007305055391043425\n",
      "acc for Lsat= 0.14853015997638871 \n",
      "acc for Psat= 0.1911743511713003 \n",
      "acc for optim= 0.17845492760314927\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.005265729036182165\n",
      "Loss on test= 0.007093604654073715\n",
      "acc for Lsat= 0.15726469367748264 \n",
      "acc for Psat= 0.1836507405440674 \n",
      "acc for optim= 0.1797708977012872\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005512786563485861\n",
      "Loss on test= 0.006939117331057787\n",
      "acc for Lsat= 0.1473299806710947 \n",
      "acc for Psat= 0.19211713801906014 \n",
      "acc for optim= 0.17930057487454357\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.0053536188788712025\n",
      "Loss on test= 0.006910302210599184\n",
      "acc for Lsat= 0.15807579103551928 \n",
      "acc for Psat= 0.18744089059268323 \n",
      "acc for optim= 0.17720034512782806\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.0053690518252551556\n",
      "Loss on test= 0.006670612376183271\n",
      "acc for Lsat= 0.15599119970068043 \n",
      "acc for Psat= 0.19223471105539575 \n",
      "acc for optim= 0.1721763287571671\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005358472932130098\n",
      "Loss on test= 0.007332193665206432\n",
      "acc for Lsat= 0.15596579849074946 \n",
      "acc for Psat= 0.17921002594597607 \n",
      "acc for optim= 0.17927761707012638\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005435789003968239\n",
      "Loss on test= 0.0067456369288265705\n",
      "acc for Lsat= 0.16100438764074543 \n",
      "acc for Psat= 0.18430679020038654 \n",
      "acc for optim= 0.1783014983251752\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.005287755746394396\n",
      "Loss on test= 0.007184589747339487\n",
      "acc for Lsat= 0.1564132414283956 \n",
      "acc for Psat= 0.18126446904889384 \n",
      "acc for optim= 0.18197821234224065\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.0053836689330637455\n",
      "Loss on test= 0.007309097331017256\n",
      "acc for Lsat= 0.1583092319532789 \n",
      "acc for Psat= 0.19482131943366202 \n",
      "acc for optim= 0.18017015400586925\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.00552224600687623\n",
      "Loss on test= 0.006912525277584791\n",
      "acc for Lsat= 0.15333248581451012 \n",
      "acc for Psat= 0.19531026622127803 \n",
      "acc for optim= 0.1773621780836008\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.0053771911188960075\n",
      "Loss on test= 0.007251557428389788\n",
      "acc for Lsat= 0.1522098698202887 \n",
      "acc for Psat= 0.1887124604534083 \n",
      "acc for optim= 0.18029920855454995\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.005332173779606819\n",
      "Loss on test= 0.006959857419133186\n",
      "acc for Lsat= 0.1444709152160031 \n",
      "acc for Psat= 0.167487763026901 \n",
      "acc for optim= 0.17416505584207967\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005103708244860172\n",
      "Loss on test= 0.0074178483337163925\n",
      "acc for Lsat= 0.152040300280434 \n",
      "acc for Psat= 0.19898130609577552 \n",
      "acc for optim= 0.1811204760694174\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.0056093111634254456\n",
      "Loss on test= 0.007564167957752943\n",
      "acc for Lsat= 0.15525734475498912 \n",
      "acc for Psat= 0.18343507004634585 \n",
      "acc for optim= 0.1810529427021884\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.005291018635034561\n",
      "Loss on test= 0.007201395463198423\n",
      "acc for Lsat= 0.1499656390097206 \n",
      "acc for Psat= 0.17573243577976055 \n",
      "acc for optim= 0.17732153496815686\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.005154012702405453\n",
      "Loss on test= 0.006666879169642925\n",
      "acc for Lsat= 0.16031807704416454 \n",
      "acc for Psat= 0.1787474475846794 \n",
      "acc for optim= 0.17375136227652307\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.005669596139341593\n",
      "Loss on test= 0.006749164313077927\n",
      "acc for Lsat= 0.16903524174055345 \n",
      "acc for Psat= 0.1860023544948609 \n",
      "acc for optim= 0.1777781721715029\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.00544424494728446\n",
      "Loss on test= 0.006838145200163126\n",
      "acc for Lsat= 0.1549468580079952 \n",
      "acc for Psat= 0.18631939447683388 \n",
      "acc for optim= 0.17506522114372422\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.005572858266532421\n",
      "Loss on test= 0.007159906905144453\n",
      "acc for Lsat= 0.1553243781405608 \n",
      "acc for Psat= 0.1873777454444131 \n",
      "acc for optim= 0.1794851702214295\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.005234026350080967\n",
      "Loss on test= 0.00727100670337677\n",
      "acc for Lsat= 0.1520169483811917 \n",
      "acc for Psat= 0.1815914888768915 \n",
      "acc for optim= 0.17667688323522643\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.005634866654872894\n",
      "Loss on test= 0.007030715234577656\n",
      "acc for Lsat= 0.14684633407818123 \n",
      "acc for Psat= 0.1835492337968479 \n",
      "acc for optim= 0.1738600911190886\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.005586731713265181\n",
      "Loss on test= 0.0071767354384064674\n",
      "acc for Lsat= 0.1541388319224142 \n",
      "acc for Psat= 0.1911522700871173 \n",
      "acc for optim= 0.17698845754722972\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.0055779023095965385\n",
      "Loss on test= 0.0069487439468503\n",
      "acc for Lsat= 0.1619331177350775 \n",
      "acc for Psat= 0.17731097402452103 \n",
      "acc for optim= 0.1816330193462982\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.0053362296894192696\n",
      "Loss on test= 0.007155793718993664\n",
      "acc for Lsat= 0.143703661239935 \n",
      "acc for Psat= 0.19178847909755203 \n",
      "acc for optim= 0.17164048503733195\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.005357285030186176\n",
      "Loss on test= 0.006861676461994648\n",
      "acc for Lsat= 0.15552661112394206 \n",
      "acc for Psat= 0.18640850438263085 \n",
      "acc for optim= 0.17484766272818442\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.005392255261540413\n",
      "Loss on test= 0.0070391325280070305\n",
      "acc for Lsat= 0.14947937241350834 \n",
      "acc for Psat= 0.20218255187071799 \n",
      "acc for optim= 0.17376266807560106\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.0053349086083471775\n",
      "Loss on test= 0.0070641376078128815\n",
      "acc for Lsat= 0.14494717727151898 \n",
      "acc for Psat= 0.18244739057282444 \n",
      "acc for optim= 0.17509319470149512\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.005875692702829838\n",
      "Loss on test= 0.006868439260870218\n",
      "acc for Lsat= 0.15079375034137094 \n",
      "acc for Psat= 0.19211725151431355 \n",
      "acc for optim= 0.17347957117981125\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005199943669140339\n",
      "Loss on test= 0.0067985160276293755\n",
      "acc for Lsat= 0.145656904268277 \n",
      "acc for Psat= 0.19929308415482155 \n",
      "acc for optim= 0.18123091544934977\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.005288103595376015\n",
      "Loss on test= 0.0067481775768101215\n",
      "acc for Lsat= 0.1560400186700567 \n",
      "acc for Psat= 0.19741185951298562 \n",
      "acc for optim= 0.17365957700731385\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.005667052697390318\n",
      "Loss on test= 0.006907341070473194\n",
      "acc for Lsat= 0.15993545908770967 \n",
      "acc for Psat= 0.18744310386805485 \n",
      "acc for optim= 0.17353594827954275\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.005591623019427061\n",
      "Loss on test= 0.007199664134532213\n",
      "acc for Lsat= 0.14665113626483095 \n",
      "acc for Psat= 0.18502437620756282 \n",
      "acc for optim= 0.1730730750502591\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.00576381990686059\n",
      "Loss on test= 0.007165520917624235\n",
      "acc for Lsat= 0.15448595129915316 \n",
      "acc for Psat= 0.18636236764857025 \n",
      "acc for optim= 0.18175929611067854\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.0059148878790438175\n",
      "Loss on test= 0.006890847347676754\n",
      "acc for Lsat= 0.15797118307301225 \n",
      "acc for Psat= 0.178949698636148 \n",
      "acc for optim= 0.181308865141635\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.005387821700423956\n",
      "Loss on test= 0.0069617824628949165\n",
      "acc for Lsat= 0.14205248402030834 \n",
      "acc for Psat= 0.1833531553847009 \n",
      "acc for optim= 0.18129015679586416\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.005356667097657919\n",
      "Loss on test= 0.007120032329112291\n",
      "acc for Lsat= 0.14997091986941266 \n",
      "acc for Psat= 0.1820218810258189 \n",
      "acc for optim= 0.1782526249111798\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.005355976987630129\n",
      "Loss on test= 0.006965838838368654\n",
      "acc for Lsat= 0.1484024365730994 \n",
      "acc for Psat= 0.19506115628087695 \n",
      "acc for optim= 0.17528917073524083\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.005201227497309446\n",
      "Loss on test= 0.006847395561635494\n",
      "acc for Lsat= 0.1443931294984917 \n",
      "acc for Psat= 0.1811232615197383 \n",
      "acc for optim= 0.17951162859652436\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.005543186329305172\n",
      "Loss on test= 0.007396961562335491\n",
      "acc for Lsat= 0.1521126182108629 \n",
      "acc for Psat= 0.1810410598571103 \n",
      "acc for optim= 0.17651967542569466\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.005515037104487419\n",
      "Loss on test= 0.007408317178487778\n",
      "acc for Lsat= 0.1576721790849735 \n",
      "acc for Psat= 0.2053280285753302 \n",
      "acc for optim= 0.17902568338126837\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.005187258590012789\n",
      "Loss on test= 0.0070868320763111115\n",
      "acc for Lsat= 0.16198978892100027 \n",
      "acc for Psat= 0.20162337664285768 \n",
      "acc for optim= 0.17928235993117522\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.005396298132836819\n",
      "Loss on test= 0.007109541911631823\n",
      "acc for Lsat= 0.13867198736454575 \n",
      "acc for Psat= 0.18864060203224176 \n",
      "acc for optim= 0.1796557419776886\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.005360063165426254\n",
      "Loss on test= 0.00756554352119565\n",
      "acc for Lsat= 0.16978753917816203 \n",
      "acc for Psat= 0.18727643547687473 \n",
      "acc for optim= 0.17467071690313235\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.0053254892118275166\n",
      "Loss on test= 0.0069552017375826836\n",
      "acc for Lsat= 0.14913383587536075 \n",
      "acc for Psat= 0.18901572293853847 \n",
      "acc for optim= 0.1811735420955391\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.005681293550878763\n",
      "Loss on test= 0.007202864624559879\n",
      "acc for Lsat= 0.15694905126211614 \n",
      "acc for Psat= 0.19643892395485682 \n",
      "acc for optim= 0.1777290989420225\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.005958082154393196\n",
      "Loss on test= 0.007232175674289465\n",
      "acc for Lsat= 0.16005644712348854 \n",
      "acc for Psat= 0.18572394297707284 \n",
      "acc for optim= 0.1762891274968498\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.005426743067800999\n",
      "Loss on test= 0.007082121446728706\n",
      "acc for Lsat= 0.14513718974905387 \n",
      "acc for Psat= 0.1787369941124601 \n",
      "acc for optim= 0.1747020115073938\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.005672958679497242\n",
      "Loss on test= 0.007694486528635025\n",
      "acc for Lsat= 0.15021199414231737 \n",
      "acc for Psat= 0.1807183474005409 \n",
      "acc for optim= 0.1806554883541005\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.005346375051885843\n",
      "Loss on test= 0.00743064796552062\n",
      "acc for Lsat= 0.15215852398026475 \n",
      "acc for Psat= 0.19154215750998252 \n",
      "acc for optim= 0.1842471772220871\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.005950264632701874\n",
      "Loss on test= 0.006946491077542305\n",
      "acc for Lsat= 0.15796840284477737 \n",
      "acc for Psat= 0.19082201830871007 \n",
      "acc for optim= 0.1788576690726303\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005274166353046894\n",
      "Loss on test= 0.006905377376824617\n",
      "acc for Lsat= 0.14394026330894538 \n",
      "acc for Psat= 0.18361514019321834 \n",
      "acc for optim= 0.1804120682317336\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.005292546469718218\n",
      "Loss on test= 0.006849166937172413\n",
      "acc for Lsat= 0.15852594862646255 \n",
      "acc for Psat= 0.18425071374226942 \n",
      "acc for optim= 0.17490260974297941\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.005326735321432352\n",
      "Loss on test= 0.006971321534365416\n",
      "acc for Lsat= 0.14721238199949693 \n",
      "acc for Psat= 0.1786281614167402 \n",
      "acc for optim= 0.171374009254858\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.005440274253487587\n",
      "Loss on test= 0.0070583452470600605\n",
      "acc for Lsat= 0.14811599253386748 \n",
      "acc for Psat= 0.16820289894411738 \n",
      "acc for optim= 0.18446868740090885\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.005360428709536791\n",
      "Loss on test= 0.007104954216629267\n",
      "acc for Lsat= 0.15187139691895668 \n",
      "acc for Psat= 0.1864235074725002 \n",
      "acc for optim= 0.17573264061213761\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.005455106496810913\n",
      "Loss on test= 0.006826967466622591\n",
      "acc for Lsat= 0.15503618023816312 \n",
      "acc for Psat= 0.20221677130034774 \n",
      "acc for optim= 0.17201087485498975\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.005371707491576672\n",
      "Loss on test= 0.007024563383311033\n",
      "acc for Lsat= 0.15766402883341843 \n",
      "acc for Psat= 0.18088963900265267 \n",
      "acc for optim= 0.1787117358575743\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.005214829929172993\n",
      "Loss on test= 0.0073386067524552345\n",
      "acc for Lsat= 0.16780396489785282 \n",
      "acc for Psat= 0.18457099973533272 \n",
      "acc for optim= 0.17543346733789983\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.0052688284777104855\n",
      "Loss on test= 0.006900036241859198\n",
      "acc for Lsat= 0.16394986199276124 \n",
      "acc for Psat= 0.18612302636010114 \n",
      "acc for optim= 0.18321970451647535\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.005342836957424879\n",
      "Loss on test= 0.006771272048354149\n",
      "acc for Lsat= 0.15917768760080464 \n",
      "acc for Psat= 0.17537515591830016 \n",
      "acc for optim= 0.17939980143650633\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.00568611454218626\n",
      "Loss on test= 0.0072066206485033035\n",
      "acc for Lsat= 0.14426735775930746 \n",
      "acc for Psat= 0.18118007778691997 \n",
      "acc for optim= 0.17543991461842795\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.005477484315633774\n",
      "Loss on test= 0.0073704500682652\n",
      "acc for Lsat= 0.15386633505934055 \n",
      "acc for Psat= 0.18401862895078042 \n",
      "acc for optim= 0.1747775140974182\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.005930999293923378\n",
      "Loss on test= 0.007111141923815012\n",
      "acc for Lsat= 0.14801489025454936 \n",
      "acc for Psat= 0.19170451687558718 \n",
      "acc for optim= 0.1826947320017918\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005304874386638403\n",
      "Loss on test= 0.007397518027573824\n",
      "acc for Lsat= 0.15790449076916138 \n",
      "acc for Psat= 0.17662192343869704 \n",
      "acc for optim= 0.17784717043126516\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005429343786090612\n",
      "Loss on test= 0.007219228427857161\n",
      "acc for Lsat= 0.14836296384990003 \n",
      "acc for Psat= 0.18534487348255516 \n",
      "acc for optim= 0.1760886397073427\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.006560120731592178\n",
      "Loss on test= 0.007186963222920895\n",
      "acc for Lsat= 0.1584891786883761 \n",
      "acc for Psat= 0.1889477484441576 \n",
      "acc for optim= 0.1774352695586801\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.005193178541958332\n",
      "Loss on test= 0.007064132951200008\n",
      "acc for Lsat= 0.14081787664021486 \n",
      "acc for Psat= 0.17399387291301477 \n",
      "acc for optim= 0.18011121993872994\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.005456947721540928\n",
      "Loss on test= 0.006944128777831793\n",
      "acc for Lsat= 0.15640135089271381 \n",
      "acc for Psat= 0.19441091599893284 \n",
      "acc for optim= 0.18244502109200617\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.005411171354353428\n",
      "Loss on test= 0.007458016276359558\n",
      "acc for Lsat= 0.1447535311302612 \n",
      "acc for Psat= 0.1691042041097821 \n",
      "acc for optim= 0.17701466253798334\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.005361601710319519\n",
      "Loss on test= 0.006617034785449505\n",
      "acc for Lsat= 0.15908172051116945 \n",
      "acc for Psat= 0.19057864583761538 \n",
      "acc for optim= 0.18259872831175195\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.005153801292181015\n",
      "Loss on test= 0.007017028518021107\n",
      "acc for Lsat= 0.1550163466689467 \n",
      "acc for Psat= 0.18627396200222468 \n",
      "acc for optim= 0.1794461641779368\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.005616630427539349\n",
      "Loss on test= 0.007069866172969341\n",
      "acc for Lsat= 0.15038796865136064 \n",
      "acc for Psat= 0.19582695555148005 \n",
      "acc for optim= 0.18231082108925234\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.005392438266426325\n",
      "Loss on test= 0.007083442527800798\n",
      "acc for Lsat= 0.14007193439059937 \n",
      "acc for Psat= 0.1783503607237286 \n",
      "acc for optim= 0.1773198265296056\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005391375161707401\n",
      "Loss on test= 0.0071609122678637505\n",
      "acc for Lsat= 0.14728257053400023 \n",
      "acc for Psat= 0.19422951168676486 \n",
      "acc for optim= 0.17803171144981608\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.005390905775129795\n",
      "Loss on test= 0.007051508408039808\n",
      "acc for Lsat= 0.15263741847545625 \n",
      "acc for Psat= 0.19753602611351392 \n",
      "acc for optim= 0.18129662343751274\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.005529297981411219\n",
      "Loss on test= 0.0072107394225895405\n",
      "acc for Lsat= 0.15374692386688024 \n",
      "acc for Psat= 0.19108847632286613 \n",
      "acc for optim= 0.17844225480549822\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.005618218798190355\n",
      "Loss on test= 0.0068253399804234505\n",
      "acc for Lsat= 0.15206923073197745 \n",
      "acc for Psat= 0.19774897701718147 \n",
      "acc for optim= 0.1704094494367591\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.005350446794182062\n",
      "Loss on test= 0.007194650359451771\n",
      "acc for Lsat= 0.1561159040470661 \n",
      "acc for Psat= 0.19018372245940196 \n",
      "acc for optim= 0.1764046646803465\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.005264260806143284\n",
      "Loss on test= 0.006686708424240351\n",
      "acc for Lsat= 0.1513579214480324 \n",
      "acc for Psat= 0.18203369728976584 \n",
      "acc for optim= 0.18058411753125733\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.0055618747137486935\n",
      "Loss on test= 0.0067211962305009365\n",
      "acc for Lsat= 0.14451637862452504 \n",
      "acc for Psat= 0.1889547660137664 \n",
      "acc for optim= 0.18077247951038516\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.005866736173629761\n",
      "Loss on test= 0.0069183302111923695\n",
      "acc for Lsat= 0.1567168849608174 \n",
      "acc for Psat= 0.1890848385778897 \n",
      "acc for optim= 0.18224500382193135\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.005287119187414646\n",
      "Loss on test= 0.0067256600596010685\n",
      "acc for Lsat= 0.14619780390744755 \n",
      "acc for Psat= 0.18481734054588683 \n",
      "acc for optim= 0.180477258450157\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.005375731270760298\n",
      "Loss on test= 0.007616906892508268\n",
      "acc for Lsat= 0.15074389971035043 \n",
      "acc for Psat= 0.2005730527872983 \n",
      "acc for optim= 0.17498659160585509\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.005087105557322502\n",
      "Loss on test= 0.006747085601091385\n",
      "acc for Lsat= 0.14669928736641208 \n",
      "acc for Psat= 0.19141014423288144 \n",
      "acc for optim= 0.17461962803289843\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.005342417396605015\n",
      "Loss on test= 0.007000993471592665\n",
      "acc for Lsat= 0.1503293271764319 \n",
      "acc for Psat= 0.18518535702901542 \n",
      "acc for optim= 0.18142221151186977\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.005352962762117386\n",
      "Loss on test= 0.006859327666461468\n",
      "acc for Lsat= 0.1579268542576398 \n",
      "acc for Psat= 0.18627331922533083 \n",
      "acc for optim= 0.17474869830933681\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.005410932935774326\n",
      "Loss on test= 0.007317342329770327\n",
      "acc for Lsat= 0.1572130755864997 \n",
      "acc for Psat= 0.18817298350203018 \n",
      "acc for optim= 0.1744452156015809\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.005112106911838055\n",
      "Loss on test= 0.007096079643815756\n",
      "acc for Lsat= 0.14553332263298455 \n",
      "acc for Psat= 0.18678422855827806 \n",
      "acc for optim= 0.18565357131702198\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.005540909711271524\n",
      "Loss on test= 0.007303750142455101\n",
      "acc for Lsat= 0.14932114824580628 \n",
      "acc for Psat= 0.18628809329858967 \n",
      "acc for optim= 0.17865705772982451\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.005330575630068779\n",
      "Loss on test= 0.00713514257222414\n",
      "acc for Lsat= 0.15964355151136558 \n",
      "acc for Psat= 0.19948163911142983 \n",
      "acc for optim= 0.17728309959314428\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.005390773992985487\n",
      "Loss on test= 0.006935497280210257\n",
      "acc for Lsat= 0.1603055811503837 \n",
      "acc for Psat= 0.1904999370930693 \n",
      "acc for optim= 0.17946636412940636\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.005514177493751049\n",
      "Loss on test= 0.006997063290327787\n",
      "acc for Lsat= 0.15483022507515803 \n",
      "acc for Psat= 0.1734857041869679 \n",
      "acc for optim= 0.18162199483581315\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.0056517100892961025\n",
      "Loss on test= 0.006787867750972509\n",
      "acc for Lsat= 0.14532876160400385 \n",
      "acc for Psat= 0.19666443475384693 \n",
      "acc for optim= 0.1783986345399171\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.00554839288815856\n",
      "Loss on test= 0.006968380883336067\n",
      "acc for Lsat= 0.1568176579060029 \n",
      "acc for Psat= 0.20347184433075066 \n",
      "acc for optim= 0.1770036573903244\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.005333960521966219\n",
      "Loss on test= 0.0067380680702626705\n",
      "acc for Lsat= 0.14989579053071794 \n",
      "acc for Psat= 0.19997390645783258 \n",
      "acc for optim= 0.17643106660851446\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.00518641946837306\n",
      "Loss on test= 0.007095902692526579\n",
      "acc for Lsat= 0.14737600614622112 \n",
      "acc for Psat= 0.18874210072602585 \n",
      "acc for optim= 0.18176105361466188\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.005202078260481358\n",
      "Loss on test= 0.006701094098389149\n",
      "acc for Lsat= 0.1467505472593895 \n",
      "acc for Psat= 0.20075629126432268 \n",
      "acc for optim= 0.17438070737493422\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.005494465585798025\n",
      "Loss on test= 0.007206315640360117\n",
      "acc for Lsat= 0.15181875388308802 \n",
      "acc for Psat= 0.17770180075227085 \n",
      "acc for optim= 0.18063519875457906\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005368451122194529\n",
      "Loss on test= 0.0072748130187392235\n",
      "acc for Lsat= 0.1677131829419761 \n",
      "acc for Psat= 0.1844834727830574 \n",
      "acc for optim= 0.18169303776879536\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.005199403502047062\n",
      "Loss on test= 0.006957551464438438\n",
      "acc for Lsat= 0.16314659680833385 \n",
      "acc for Psat= 0.1918886318165412 \n",
      "acc for optim= 0.17524998217313473\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.005171795841306448\n",
      "Loss on test= 0.00728222168982029\n",
      "acc for Lsat= 0.14763542133083826 \n",
      "acc for Psat= 0.18304507963537797 \n",
      "acc for optim= 0.17520294602289768\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.005474695935845375\n",
      "Loss on test= 0.0074924626387655735\n",
      "acc for Lsat= 0.15294466939648985 \n",
      "acc for Psat= 0.18398757135728375 \n",
      "acc for optim= 0.18084285571831507\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.005260468926280737\n",
      "Loss on test= 0.006738959811627865\n",
      "acc for Lsat= 0.15198643060561393 \n",
      "acc for Psat= 0.1753862841731342 \n",
      "acc for optim= 0.17383817980537328\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.005300784949213266\n",
      "Loss on test= 0.006552318576723337\n",
      "acc for Lsat= 0.14545387012471797 \n",
      "acc for Psat= 0.18643722413794794 \n",
      "acc for optim= 0.1827064547850464\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.005808091256767511\n",
      "Loss on test= 0.007237116806209087\n",
      "acc for Lsat= 0.14987413710761877 \n",
      "acc for Psat= 0.18651253141512422 \n",
      "acc for optim= 0.18424389707840613\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.005226253531873226\n",
      "Loss on test= 0.007329205982387066\n",
      "acc for Lsat= 0.15151746814562864 \n",
      "acc for Psat= 0.19302533544670622 \n",
      "acc for optim= 0.17809042681512408\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.005688800010830164\n",
      "Loss on test= 0.007259049918502569\n",
      "acc for Lsat= 0.14919565448987862 \n",
      "acc for Psat= 0.18935868668247807 \n",
      "acc for optim= 0.17455491722660657\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.0052627092227339745\n",
      "Loss on test= 0.0073666018433868885\n",
      "acc for Lsat= 0.14635797034773487 \n",
      "acc for Psat= 0.179235871636011 \n",
      "acc for optim= 0.18034372136347973\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.005442832596600056\n",
      "Loss on test= 0.007481012027710676\n",
      "acc for Lsat= 0.15512550979772521 \n",
      "acc for Psat= 0.1917870806713329 \n",
      "acc for optim= 0.17488207862305466\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.005417479667812586\n",
      "Loss on test= 0.00707396911457181\n",
      "acc for Lsat= 0.15799219108331705 \n",
      "acc for Psat= 0.18005073375410216 \n",
      "acc for optim= 0.1693068911619179\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.005229452159255743\n",
      "Loss on test= 0.006724937818944454\n",
      "acc for Lsat= 0.1518741655423016 \n",
      "acc for Psat= 0.17992253064933675 \n",
      "acc for optim= 0.18273524083769652\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.0054200319573283195\n",
      "Loss on test= 0.007117064204066992\n",
      "acc for Lsat= 0.1588255489871028 \n",
      "acc for Psat= 0.18364039067833562 \n",
      "acc for optim= 0.18521998387524766\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005323017481714487\n",
      "Loss on test= 0.007109032478183508\n",
      "acc for Lsat= 0.15515581100700102 \n",
      "acc for Psat= 0.18418686456785568 \n",
      "acc for optim= 0.18413866693917358\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.005602368153631687\n",
      "Loss on test= 0.007001964375376701\n",
      "acc for Lsat= 0.1496818731685902 \n",
      "acc for Psat= 0.19483401249997798 \n",
      "acc for optim= 0.17703326977517447\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.0052960338070988655\n",
      "Loss on test= 0.007350266445428133\n",
      "acc for Lsat= 0.16703424287528623 \n",
      "acc for Psat= 0.17680606755874592 \n",
      "acc for optim= 0.17897228540444257\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.005144803784787655\n",
      "Loss on test= 0.006710754241794348\n",
      "acc for Lsat= 0.1596946000628704 \n",
      "acc for Psat= 0.19380981116708307 \n",
      "acc for optim= 0.1782591269130162\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.0053345332853496075\n",
      "Loss on test= 0.007079059723764658\n",
      "acc for Lsat= 0.15750912146310733 \n",
      "acc for Psat= 0.18656989899301735 \n",
      "acc for optim= 0.1765244996615067\n",
      "Fold 2\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.10565482079982758\n",
      "Loss on test= 0.04509725049138069\n",
      "acc for Lsat= 0.7403599408730009 \n",
      "acc for Psat= 0.7718585751362939 \n",
      "acc for optim= 0.2747263052779418\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.04041862115263939\n",
      "Loss on test= 0.04631975665688515\n",
      "acc for Lsat= 1.3759705012599313 \n",
      "acc for Psat= 0.5468959169813478 \n",
      "acc for optim= 0.2392067502189779\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.03289774805307388\n",
      "Loss on test= 0.02338245138525963\n",
      "acc for Lsat= 0.4494424880389697 \n",
      "acc for Psat= 0.5193905329642833 \n",
      "acc for optim= 0.21887011368774245\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.024940859526395798\n",
      "Loss on test= 0.023922985419631004\n",
      "acc for Lsat= 0.6045998199048956 \n",
      "acc for Psat= 0.4833065271850859 \n",
      "acc for optim= 0.23064107837147826\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.02264096774160862\n",
      "Loss on test= 0.022219369187951088\n",
      "acc for Lsat= 0.4573022832544368 \n",
      "acc for Psat= 0.5212146837649806 \n",
      "acc for optim= 0.2414002011209482\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.025049567222595215\n",
      "Loss on test= 0.022159304469823837\n",
      "acc for Lsat= 0.39102075438618233 \n",
      "acc for Psat= 0.5490682575458539 \n",
      "acc for optim= 0.216358293502207\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.021675702184438705\n",
      "Loss on test= 0.024019120261073112\n",
      "acc for Lsat= 0.6393588925589669 \n",
      "acc for Psat= 0.44623882851113 \n",
      "acc for optim= 0.2055395404854026\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.021475909277796745\n",
      "Loss on test= 0.018913429230451584\n",
      "acc for Lsat= 0.3381231131322193 \n",
      "acc for Psat= 0.5413257601167091 \n",
      "acc for optim= 0.2208238991780863\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.021189723163843155\n",
      "Loss on test= 0.018301058560609818\n",
      "acc for Lsat= 0.35025315324959083 \n",
      "acc for Psat= 0.44259433439230456 \n",
      "acc for optim= 0.22563601135673214\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.019995374605059624\n",
      "Loss on test= 0.01800893247127533\n",
      "acc for Lsat= 0.3188676886581129 \n",
      "acc for Psat= 0.458789244053225 \n",
      "acc for optim= 0.20119173348142735\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.018389934673905373\n",
      "Loss on test= 0.01823500730097294\n",
      "acc for Lsat= 0.33799375766109613 \n",
      "acc for Psat= 0.40312111532386224 \n",
      "acc for optim= 0.20406004214472306\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.01809251680970192\n",
      "Loss on test= 0.02607857435941696\n",
      "acc for Lsat= 0.3770290392588396 \n",
      "acc for Psat= 0.8304030527742426 \n",
      "acc for optim= 0.20602553158723672\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.023904524743556976\n",
      "Loss on test= 0.02073746733367443\n",
      "acc for Lsat= 0.4249181346727352 \n",
      "acc for Psat= 0.6283915397157648 \n",
      "acc for optim= 0.20621833200948161\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.018435733392834663\n",
      "Loss on test= 0.016448015347123146\n",
      "acc for Lsat= 0.3456623523677394 \n",
      "acc for Psat= 0.42545089514155066 \n",
      "acc for optim= 0.20392407448733318\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.015650594606995583\n",
      "Loss on test= 0.016457563266158104\n",
      "acc for Lsat= 0.33380775657848866 \n",
      "acc for Psat= 0.39226421474967704 \n",
      "acc for optim= 0.20924990085549042\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.015701565891504288\n",
      "Loss on test= 0.016452590003609657\n",
      "acc for Lsat= 0.35525147039748606 \n",
      "acc for Psat= 0.36110268118562266 \n",
      "acc for optim= 0.20288177505195176\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.014783723279833794\n",
      "Loss on test= 0.018196919932961464\n",
      "acc for Lsat= 0.47019783188169056 \n",
      "acc for Psat= 0.3723096088991027 \n",
      "acc for optim= 0.20595557512839507\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.015731845051050186\n",
      "Loss on test= 0.014596623368561268\n",
      "acc for Lsat= 0.3607018402102022 \n",
      "acc for Psat= 0.3895238537654342 \n",
      "acc for optim= 0.20440081804303728\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.014383782632648945\n",
      "Loss on test= 0.01514189038425684\n",
      "acc for Lsat= 0.345531767513603 \n",
      "acc for Psat= 0.38681833555227235 \n",
      "acc for optim= 0.20395775947597672\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.013899611309170723\n",
      "Loss on test= 0.022705519571900368\n",
      "acc for Lsat= 0.6476082160900019 \n",
      "acc for Psat= 0.3485467457503546 \n",
      "acc for optim= 0.20241090709374088\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.014543374069035053\n",
      "Loss on test= 0.013087278231978416\n",
      "acc for Lsat= 0.28773515544465333 \n",
      "acc for Psat= 0.3582517531780587 \n",
      "acc for optim= 0.20132320264085257\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.013239571824669838\n",
      "Loss on test= 0.01544171292334795\n",
      "acc for Lsat= 0.3023752555663346 \n",
      "acc for Psat= 0.3561777250096965 \n",
      "acc for optim= 0.2013538634498054\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.012848041951656342\n",
      "Loss on test= 0.014374678023159504\n",
      "acc for Lsat= 0.3040831941210466 \n",
      "acc for Psat= 0.44935829971313906 \n",
      "acc for optim= 0.1997153829995039\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.016425736248493195\n",
      "Loss on test= 0.014895480126142502\n",
      "acc for Lsat= 0.29029288341713017 \n",
      "acc for Psat= 0.44077267172692924 \n",
      "acc for optim= 0.22177356676137472\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.014278660528361797\n",
      "Loss on test= 0.015051888301968575\n",
      "acc for Lsat= 0.3083360116440253 \n",
      "acc for Psat= 0.3428353184376095 \n",
      "acc for optim= 0.20201346762192085\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.012820695526897907\n",
      "Loss on test= 0.013659300282597542\n",
      "acc for Lsat= 0.29247546879046016 \n",
      "acc for Psat= 0.3404718200905157 \n",
      "acc for optim= 0.20238711246185304\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.012159149162471294\n",
      "Loss on test= 0.01320137083530426\n",
      "acc for Lsat= 0.26005056701050916 \n",
      "acc for Psat= 0.3456297718200329 \n",
      "acc for optim= 0.20805535124057567\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.012275181710720062\n",
      "Loss on test= 0.013355647213757038\n",
      "acc for Lsat= 0.25832570838526303 \n",
      "acc for Psat= 0.37982092214229163 \n",
      "acc for optim= 0.20269624370839218\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.01220239419490099\n",
      "Loss on test= 0.013027231208980083\n",
      "acc for Lsat= 0.266707737853304 \n",
      "acc for Psat= 0.3454037968954835 \n",
      "acc for optim= 0.21923760655679603\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.01269434206187725\n",
      "Loss on test= 0.014829554595053196\n",
      "acc for Lsat= 0.28681831748423275 \n",
      "acc for Psat= 0.298697775712315 \n",
      "acc for optim= 0.2060802641571843\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.012948478572070599\n",
      "Loss on test= 0.012691710144281387\n",
      "acc for Lsat= 0.28554555112496016 \n",
      "acc for Psat= 0.2997372701397685 \n",
      "acc for optim= 0.20156856114044785\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.012211041525006294\n",
      "Loss on test= 0.01344939973205328\n",
      "acc for Lsat= 0.25456520576472774 \n",
      "acc for Psat= 0.4064632732359135 \n",
      "acc for optim= 0.20135365506905115\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.012955516576766968\n",
      "Loss on test= 0.012357804924249649\n",
      "acc for Lsat= 0.25092543079880386 \n",
      "acc for Psat= 0.32753642826707513 \n",
      "acc for optim= 0.19782119947485627\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.011378494091331959\n",
      "Loss on test= 0.012878156267106533\n",
      "acc for Lsat= 0.2575075948150012 \n",
      "acc for Psat= 0.3354983213517937 \n",
      "acc for optim= 0.19814315972635982\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.011437458917498589\n",
      "Loss on test= 0.012882081791758537\n",
      "acc for Lsat= 0.2914766810106812 \n",
      "acc for Psat= 0.31897834606228215 \n",
      "acc for optim= 0.1947563944483695\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.011944386176764965\n",
      "Loss on test= 0.01442566979676485\n",
      "acc for Lsat= 0.3445691738094463 \n",
      "acc for Psat= 0.3216079437204438 \n",
      "acc for optim= 0.19560668838590184\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.011890807189047337\n",
      "Loss on test= 0.014766880311071873\n",
      "acc for Lsat= 0.3207030229201754 \n",
      "acc for Psat= 0.3055222657308761 \n",
      "acc for optim= 0.19589476421719693\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.012213105335831642\n",
      "Loss on test= 0.012991886585950851\n",
      "acc for Lsat= 0.28648828751957195 \n",
      "acc for Psat= 0.3077094463104779 \n",
      "acc for optim= 0.198915075561505\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.011600950732827187\n",
      "Loss on test= 0.012711964547634125\n",
      "acc for Lsat= 0.30766261429067887 \n",
      "acc for Psat= 0.2827361692124825 \n",
      "acc for optim= 0.19591193974636434\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.010253015905618668\n",
      "Loss on test= 0.012868897058069706\n",
      "acc for Lsat= 0.27544839884723216 \n",
      "acc for Psat= 0.28255915768314765 \n",
      "acc for optim= 0.1955796411825863\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.010407454334199429\n",
      "Loss on test= 0.010804899968206882\n",
      "acc for Lsat= 0.21280478720599022 \n",
      "acc for Psat= 0.292457445066188 \n",
      "acc for optim= 0.19686944565934236\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.010373586788773537\n",
      "Loss on test= 0.011388693004846573\n",
      "acc for Lsat= 0.2354740340734038 \n",
      "acc for Psat= 0.28487191283846364 \n",
      "acc for optim= 0.188508562508543\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.01046600379049778\n",
      "Loss on test= 0.011081717908382416\n",
      "acc for Lsat= 0.21912683068213318 \n",
      "acc for Psat= 0.2953381288815748 \n",
      "acc for optim= 0.1953101183899457\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.010849256068468094\n",
      "Loss on test= 0.01323439460247755\n",
      "acc for Lsat= 0.3349601709955662 \n",
      "acc for Psat= 0.27923299194328854 \n",
      "acc for optim= 0.19723889290395225\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.01005961000919342\n",
      "Loss on test= 0.010892446152865887\n",
      "acc for Lsat= 0.2710630131099129 \n",
      "acc for Psat= 0.2679896394355742 \n",
      "acc for optim= 0.192400354654032\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.01003221608698368\n",
      "Loss on test= 0.012332776561379433\n",
      "acc for Lsat= 0.22809319617703833 \n",
      "acc for Psat= 0.3591423559882373 \n",
      "acc for optim= 0.2028436828202608\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.01093670167028904\n",
      "Loss on test= 0.01101774349808693\n",
      "acc for Lsat= 0.20021414957269282 \n",
      "acc for Psat= 0.30482517191186 \n",
      "acc for optim= 0.1944998245564152\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.01032162643969059\n",
      "Loss on test= 0.010990331880748272\n",
      "acc for Lsat= 0.2394011169193946 \n",
      "acc for Psat= 0.31803643208791 \n",
      "acc for optim= 0.20001857979032286\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.010919427499175072\n",
      "Loss on test= 0.011761780828237534\n",
      "acc for Lsat= 0.2620794805686646 \n",
      "acc for Psat= 0.29916889117725315 \n",
      "acc for optim= 0.20498934306173783\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.011481894180178642\n",
      "Loss on test= 0.010912696830928326\n",
      "acc for Lsat= 0.2178792664998776 \n",
      "acc for Psat= 0.2826217299711807 \n",
      "acc for optim= 0.1948299577375244\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.011215006932616234\n",
      "Loss on test= 0.012452187947928905\n",
      "acc for Lsat= 0.25145273595651396 \n",
      "acc for Psat= 0.3181328335607073 \n",
      "acc for optim= 0.19826423408784216\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.010467784479260445\n",
      "Loss on test= 0.011563065461814404\n",
      "acc for Lsat= 0.23765313725949067 \n",
      "acc for Psat= 0.2769256272609918 \n",
      "acc for optim= 0.19524563509344933\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.010112019255757332\n",
      "Loss on test= 0.011246946640312672\n",
      "acc for Lsat= 0.19776074509155464 \n",
      "acc for Psat= 0.26242096226024975 \n",
      "acc for optim= 0.19603673121014029\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.009778916835784912\n",
      "Loss on test= 0.01066378504037857\n",
      "acc for Lsat= 0.2229983610223185 \n",
      "acc for Psat= 0.29252361905833585 \n",
      "acc for optim= 0.19818051248253513\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.009354451671242714\n",
      "Loss on test= 0.011247506365180016\n",
      "acc for Lsat= 0.21979535263943958 \n",
      "acc for Psat= 0.31185472724524127 \n",
      "acc for optim= 0.19194986420057591\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.010622442699968815\n",
      "Loss on test= 0.012391282245516777\n",
      "acc for Lsat= 0.2917911357893303 \n",
      "acc for Psat= 0.2659654270582756 \n",
      "acc for optim= 0.19648549479592714\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.00943128764629364\n",
      "Loss on test= 0.01035289466381073\n",
      "acc for Lsat= 0.2154132745242067 \n",
      "acc for Psat= 0.25303105461815767 \n",
      "acc for optim= 0.20120631442631912\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.009622275829315186\n",
      "Loss on test= 0.010396153666079044\n",
      "acc for Lsat= 0.23838306008819032 \n",
      "acc for Psat= 0.25121492871014617 \n",
      "acc for optim= 0.19507878718241195\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.010228738188743591\n",
      "Loss on test= 0.011103043332695961\n",
      "acc for Lsat= 0.2613526196810646 \n",
      "acc for Psat= 0.26721725090040416 \n",
      "acc for optim= 0.1930923881929093\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.011306166648864746\n",
      "Loss on test= 0.012232414446771145\n",
      "acc for Lsat= 0.2983489761222536 \n",
      "acc for Psat= 0.28864267689488887 \n",
      "acc for optim= 0.1977926142292372\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.01030522771179676\n",
      "Loss on test= 0.011130131781101227\n",
      "acc for Lsat= 0.21909178164017054 \n",
      "acc for Psat= 0.2954701324558405 \n",
      "acc for optim= 0.20281852294996736\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.010328457690775394\n",
      "Loss on test= 0.015418721362948418\n",
      "acc for Lsat= 0.3177967850832635 \n",
      "acc for Psat= 0.2852058797387681 \n",
      "acc for optim= 0.20385144785701176\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.011957760900259018\n",
      "Loss on test= 0.012275313027203083\n",
      "acc for Lsat= 0.31269411183683754 \n",
      "acc for Psat= 0.32051781608005525 \n",
      "acc for optim= 0.18532612113946223\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.010433230549097061\n",
      "Loss on test= 0.010926702991127968\n",
      "acc for Lsat= 0.22768318096666498 \n",
      "acc for Psat= 0.29587005016462664 \n",
      "acc for optim= 0.19709959174544536\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.010639247484505177\n",
      "Loss on test= 0.010878960601985455\n",
      "acc for Lsat= 0.22659324215587656 \n",
      "acc for Psat= 0.2558876370579829 \n",
      "acc for optim= 0.19466487648438846\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.009535731747746468\n",
      "Loss on test= 0.011108762584626675\n",
      "acc for Lsat= 0.2413981327273669 \n",
      "acc for Psat= 0.25540360291831987 \n",
      "acc for optim= 0.1958743778605121\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.009508994407951832\n",
      "Loss on test= 0.012422170490026474\n",
      "acc for Lsat= 0.30174098017474743 \n",
      "acc for Psat= 0.26534500982646725 \n",
      "acc for optim= 0.19322518356369625\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.010000649839639664\n",
      "Loss on test= 0.009961633011698723\n",
      "acc for Lsat= 0.21049520163567828 \n",
      "acc for Psat= 0.27523350964288884 \n",
      "acc for optim= 0.19939325762066712\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.010107197798788548\n",
      "Loss on test= 0.010309532284736633\n",
      "acc for Lsat= 0.20643030259761574 \n",
      "acc for Psat= 0.28627355325066284 \n",
      "acc for optim= 0.1904293838254802\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.009498881176114082\n",
      "Loss on test= 0.010661188513040543\n",
      "acc for Lsat= 0.21750724025187082 \n",
      "acc for Psat= 0.2623843648180854 \n",
      "acc for optim= 0.19182513185975247\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.009190085344016552\n",
      "Loss on test= 0.010342697612941265\n",
      "acc for Lsat= 0.19498626880508038 \n",
      "acc for Psat= 0.2671005763968483 \n",
      "acc for optim= 0.1907716258228604\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.009121780283749104\n",
      "Loss on test= 0.009823246859014034\n",
      "acc for Lsat= 0.2339858831047676 \n",
      "acc for Psat= 0.2705919987186179 \n",
      "acc for optim= 0.19283444504940608\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.008925815112888813\n",
      "Loss on test= 0.01077178306877613\n",
      "acc for Lsat= 0.20327240629446097 \n",
      "acc for Psat= 0.2862235337755353 \n",
      "acc for optim= 0.1930558766163962\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.008595628663897514\n",
      "Loss on test= 0.010089521296322346\n",
      "acc for Lsat= 0.19044448087501462 \n",
      "acc for Psat= 0.2695844057976978 \n",
      "acc for optim= 0.187163951105942\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.009733501821756363\n",
      "Loss on test= 0.011393756605684757\n",
      "acc for Lsat= 0.22460927507633985 \n",
      "acc for Psat= 0.3011715138334873 \n",
      "acc for optim= 0.203007299884711\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.010208068415522575\n",
      "Loss on test= 0.011075659655034542\n",
      "acc for Lsat= 0.25841778777978675 \n",
      "acc for Psat= 0.249317139435987 \n",
      "acc for optim= 0.19271692905124643\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.009546363726258278\n",
      "Loss on test= 0.012704768218100071\n",
      "acc for Lsat= 0.30761551559429434 \n",
      "acc for Psat= 0.2694349306292038 \n",
      "acc for optim= 0.19324827301416156\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.009542291983962059\n",
      "Loss on test= 0.011002667248249054\n",
      "acc for Lsat= 0.20130169252315383 \n",
      "acc for Psat= 0.23016406582844 \n",
      "acc for optim= 0.19289110221816075\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.008919895626604557\n",
      "Loss on test= 0.009663070552051067\n",
      "acc for Lsat= 0.18447636099070402 \n",
      "acc for Psat= 0.24476747188839268 \n",
      "acc for optim= 0.1868575596601748\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.00925794243812561\n",
      "Loss on test= 0.011235236190259457\n",
      "acc for Lsat= 0.24464290025357738 \n",
      "acc for Psat= 0.24213328913730173 \n",
      "acc for optim= 0.19102524475759414\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.008207515813410282\n",
      "Loss on test= 0.010599477216601372\n",
      "acc for Lsat= 0.19948422308919617 \n",
      "acc for Psat= 0.23628928418751696 \n",
      "acc for optim= 0.20251618773565766\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.008719922974705696\n",
      "Loss on test= 0.010641073808073997\n",
      "acc for Lsat= 0.20498971788771594 \n",
      "acc for Psat= 0.24493037814075952 \n",
      "acc for optim= 0.18129859672838794\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.009436046704649925\n",
      "Loss on test= 0.010553160682320595\n",
      "acc for Lsat= 0.24518901287887215 \n",
      "acc for Psat= 0.26062001322365563 \n",
      "acc for optim= 0.19053935627529367\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.009051723405718803\n",
      "Loss on test= 0.01017112098634243\n",
      "acc for Lsat= 0.23651451651793218 \n",
      "acc for Psat= 0.24683617052171747 \n",
      "acc for optim= 0.1948187687783502\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.008099649101495743\n",
      "Loss on test= 0.00992931704968214\n",
      "acc for Lsat= 0.19145590806624196 \n",
      "acc for Psat= 0.24947757727855846 \n",
      "acc for optim= 0.18675855817750373\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.008387336507439613\n",
      "Loss on test= 0.009951074607670307\n",
      "acc for Lsat= 0.2225088432362517 \n",
      "acc for Psat= 0.24398292727066112 \n",
      "acc for optim= 0.1887823596235067\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.008345937356352806\n",
      "Loss on test= 0.009782525710761547\n",
      "acc for Lsat= 0.22015410536579544 \n",
      "acc for Psat= 0.22598419092437175 \n",
      "acc for optim= 0.18588541395252295\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.00823244545608759\n",
      "Loss on test= 0.009677315130829811\n",
      "acc for Lsat= 0.19793857936117584 \n",
      "acc for Psat= 0.22434533122272352 \n",
      "acc for optim= 0.18657333861605158\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.008501490578055382\n",
      "Loss on test= 0.01101373415440321\n",
      "acc for Lsat= 0.2521964668654589 \n",
      "acc for Psat= 0.26540625151224123 \n",
      "acc for optim= 0.18816645538289345\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.008701504208147526\n",
      "Loss on test= 0.009416853077709675\n",
      "acc for Lsat= 0.19350893177019554 \n",
      "acc for Psat= 0.23049112335028754 \n",
      "acc for optim= 0.18895083691296932\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.00794036965817213\n",
      "Loss on test= 0.009232500568032265\n",
      "acc for Lsat= 0.22002560696221093 \n",
      "acc for Psat= 0.24206738223581284 \n",
      "acc for optim= 0.1929935183768737\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.00881827063858509\n",
      "Loss on test= 0.01040489599108696\n",
      "acc for Lsat= 0.2067693917447182 \n",
      "acc for Psat= 0.24739211191820196 \n",
      "acc for optim= 0.19400226848875554\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.008689932525157928\n",
      "Loss on test= 0.010591993108391762\n",
      "acc for Lsat= 0.19575821538169516 \n",
      "acc for Psat= 0.27841224984292584 \n",
      "acc for optim= 0.19212423170855666\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.009401040151715279\n",
      "Loss on test= 0.009907607920467854\n",
      "acc for Lsat= 0.22590758802138314 \n",
      "acc for Psat= 0.24964955442386572 \n",
      "acc for optim= 0.1882776336408541\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.008626680821180344\n",
      "Loss on test= 0.009151244536042213\n",
      "acc for Lsat= 0.1958295947964662 \n",
      "acc for Psat= 0.23852422756188718 \n",
      "acc for optim= 0.1878492438563119\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.008723175153136253\n",
      "Loss on test= 0.01060718297958374\n",
      "acc for Lsat= 0.1946907953534764 \n",
      "acc for Psat= 0.2213130306645743 \n",
      "acc for optim= 0.21280575817313474\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.008938530460000038\n",
      "Loss on test= 0.009967883117496967\n",
      "acc for Lsat= 0.20193904948314187 \n",
      "acc for Psat= 0.23828670364045004 \n",
      "acc for optim= 0.2062652763775092\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.009690133854746819\n",
      "Loss on test= 0.010142531245946884\n",
      "acc for Lsat= 0.20469495825064904 \n",
      "acc for Psat= 0.26342680797335827 \n",
      "acc for optim= 0.18712238686590563\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.009044752456247807\n",
      "Loss on test= 0.010415716096758842\n",
      "acc for Lsat= 0.24779543034717075 \n",
      "acc for Psat= 0.2235354348303384 \n",
      "acc for optim= 0.19286355161858096\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.008315456099808216\n",
      "Loss on test= 0.008976155892014503\n",
      "acc for Lsat= 0.23087846946780433 \n",
      "acc for Psat= 0.2346824921148478 \n",
      "acc for optim= 0.18403861392690174\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.008930398151278496\n",
      "Loss on test= 0.009572810493409634\n",
      "acc for Lsat= 0.1827048949964085 \n",
      "acc for Psat= 0.2802554519961542 \n",
      "acc for optim= 0.19035831103025036\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.008761766366660595\n",
      "Loss on test= 0.010346023365855217\n",
      "acc for Lsat= 0.23041275927079383 \n",
      "acc for Psat= 0.24476144275299777 \n",
      "acc for optim= 0.18968813099791526\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.00835045613348484\n",
      "Loss on test= 0.009808537550270557\n",
      "acc for Lsat= 0.190225517618676 \n",
      "acc for Psat= 0.23822880291139523 \n",
      "acc for optim= 0.201530698656303\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.007900132797658443\n",
      "Loss on test= 0.009874315932393074\n",
      "acc for Lsat= 0.20218675252127455 \n",
      "acc for Psat= 0.21486122753532205 \n",
      "acc for optim= 0.1858970141427622\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.008237406611442566\n",
      "Loss on test= 0.010724188759922981\n",
      "acc for Lsat= 0.2147012110288087 \n",
      "acc for Psat= 0.21164224686551472 \n",
      "acc for optim= 0.2043013784156532\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.008100753650069237\n",
      "Loss on test= 0.00879964791238308\n",
      "acc for Lsat= 0.1859031280682071 \n",
      "acc for Psat= 0.23483563959388612 \n",
      "acc for optim= 0.18604230737541688\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.0078071849420666695\n",
      "Loss on test= 0.009953703731298447\n",
      "acc for Lsat= 0.20282859924234084 \n",
      "acc for Psat= 0.20317903999010192 \n",
      "acc for optim= 0.19018429263464373\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.007738247513771057\n",
      "Loss on test= 0.008989080786705017\n",
      "acc for Lsat= 0.18391795248961168 \n",
      "acc for Psat= 0.22786002470844532 \n",
      "acc for optim= 0.1879680204640341\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.007531182374805212\n",
      "Loss on test= 0.00912010669708252\n",
      "acc for Lsat= 0.2124798034844523 \n",
      "acc for Psat= 0.22136530484698835 \n",
      "acc for optim= 0.1845009823629373\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.007528445217758417\n",
      "Loss on test= 0.00848066434264183\n",
      "acc for Lsat= 0.16732606880717957 \n",
      "acc for Psat= 0.21139688026427184 \n",
      "acc for optim= 0.18907058304815064\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.0076165637001395226\n",
      "Loss on test= 0.009238707832992077\n",
      "acc for Lsat= 0.223698331056865 \n",
      "acc for Psat= 0.20951681334375533 \n",
      "acc for optim= 0.19047241965461462\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.007957958616316319\n",
      "Loss on test= 0.008757696487009525\n",
      "acc for Lsat= 0.19646497672160354 \n",
      "acc for Psat= 0.22647103977152985 \n",
      "acc for optim= 0.1896361171341402\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.007573707960546017\n",
      "Loss on test= 0.008640432730317116\n",
      "acc for Lsat= 0.18587229653169995 \n",
      "acc for Psat= 0.218058700169929 \n",
      "acc for optim= 0.18485185754710626\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.00765127781778574\n",
      "Loss on test= 0.008880255743861198\n",
      "acc for Lsat= 0.16905078556365716 \n",
      "acc for Psat= 0.2113104862405262 \n",
      "acc for optim= 0.1834691289204486\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.00822718720883131\n",
      "Loss on test= 0.00936044193804264\n",
      "acc for Lsat= 0.19103546090038553 \n",
      "acc for Psat= 0.23205795241367133 \n",
      "acc for optim= 0.19180589695193911\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.008000556379556656\n",
      "Loss on test= 0.009334941394627094\n",
      "acc for Lsat= 0.21276859719998997 \n",
      "acc for Psat= 0.22852585775191803 \n",
      "acc for optim= 0.18658713389600276\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.00792708806693554\n",
      "Loss on test= 0.008659303188323975\n",
      "acc for Lsat= 0.17531008028451994 \n",
      "acc for Psat= 0.2218742911040699 \n",
      "acc for optim= 0.17578033262908604\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.00785148050636053\n",
      "Loss on test= 0.009030954912304878\n",
      "acc for Lsat= 0.18028493655891326 \n",
      "acc for Psat= 0.20020402691491163 \n",
      "acc for optim= 0.1789721168466504\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.00785030983388424\n",
      "Loss on test= 0.008736160583794117\n",
      "acc for Lsat= 0.16587248182088352 \n",
      "acc for Psat= 0.22933300691399128 \n",
      "acc for optim= 0.19177178443699586\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.007537889294326305\n",
      "Loss on test= 0.008961006999015808\n",
      "acc for Lsat= 0.1816312493863525 \n",
      "acc for Psat= 0.22115204930496327 \n",
      "acc for optim= 0.18504647476904926\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.007851255126297474\n",
      "Loss on test= 0.009014627896249294\n",
      "acc for Lsat= 0.16812593467518322 \n",
      "acc for Psat= 0.22533132702009143 \n",
      "acc for optim= 0.187346894700262\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.007713580969721079\n",
      "Loss on test= 0.009072721004486084\n",
      "acc for Lsat= 0.20751943468635323 \n",
      "acc for Psat= 0.22028853507938156 \n",
      "acc for optim= 0.17882819450842063\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.007532875053584576\n",
      "Loss on test= 0.00893255416303873\n",
      "acc for Lsat= 0.17842685358971452 \n",
      "acc for Psat= 0.21568717090074224 \n",
      "acc for optim= 0.18507266951239187\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.007206353358924389\n",
      "Loss on test= 0.008266479708254337\n",
      "acc for Lsat= 0.19729812879565736 \n",
      "acc for Psat= 0.21251971366572897 \n",
      "acc for optim= 0.177656590020223\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.008318123407661915\n",
      "Loss on test= 0.008549093268811703\n",
      "acc for Lsat= 0.18457684253688833 \n",
      "acc for Psat= 0.2143558658877021 \n",
      "acc for optim= 0.19580131340957987\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.008097441866993904\n",
      "Loss on test= 0.00949353538453579\n",
      "acc for Lsat= 0.19790094974832456 \n",
      "acc for Psat= 0.2201624825186016 \n",
      "acc for optim= 0.18852089736309474\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.007408858742564917\n",
      "Loss on test= 0.009082228876650333\n",
      "acc for Lsat= 0.17639367584908214 \n",
      "acc for Psat= 0.20266706347217417 \n",
      "acc for optim= 0.18396297326143526\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.007394065149128437\n",
      "Loss on test= 0.008425814099609852\n",
      "acc for Lsat= 0.16480400837618156 \n",
      "acc for Psat= 0.20588625725396895 \n",
      "acc for optim= 0.18690169291746359\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.007052113302052021\n",
      "Loss on test= 0.00914238952100277\n",
      "acc for Lsat= 0.17918277400708948 \n",
      "acc for Psat= 0.2136563902652105 \n",
      "acc for optim= 0.18768270118314712\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.007023656275123358\n",
      "Loss on test= 0.008418223820626736\n",
      "acc for Lsat= 0.18930310250057641 \n",
      "acc for Psat= 0.1882623376376301 \n",
      "acc for optim= 0.19524158110924889\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.007529863156378269\n",
      "Loss on test= 0.008809860795736313\n",
      "acc for Lsat= 0.17024884437254753 \n",
      "acc for Psat= 0.2064396765438046 \n",
      "acc for optim= 0.18150144241383817\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.0073196860030293465\n",
      "Loss on test= 0.008913620375096798\n",
      "acc for Lsat= 0.17582188397722287 \n",
      "acc for Psat= 0.240497657820319 \n",
      "acc for optim= 0.19050562875698412\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.007137308828532696\n",
      "Loss on test= 0.00797947309911251\n",
      "acc for Lsat= 0.1700349063831992 \n",
      "acc for Psat= 0.1990177635584393 \n",
      "acc for optim= 0.17995926003223744\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.007003292441368103\n",
      "Loss on test= 0.008826691657304764\n",
      "acc for Lsat= 0.18067279941817224 \n",
      "acc for Psat= 0.24402105501117818 \n",
      "acc for optim= 0.1769094129772399\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.007036986295133829\n",
      "Loss on test= 0.008383112959563732\n",
      "acc for Lsat= 0.18193824455627722 \n",
      "acc for Psat= 0.21386095308813222 \n",
      "acc for optim= 0.18452930594144537\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.0072380900382995605\n",
      "Loss on test= 0.008638342842459679\n",
      "acc for Lsat= 0.17924183567744473 \n",
      "acc for Psat= 0.21330890462058213 \n",
      "acc for optim= 0.17800446260080208\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.007440335117280483\n",
      "Loss on test= 0.008571661077439785\n",
      "acc for Lsat= 0.17446113540933214 \n",
      "acc for Psat= 0.2191825260499828 \n",
      "acc for optim= 0.17566272687876872\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.007755563594400883\n",
      "Loss on test= 0.008926212787628174\n",
      "acc for Lsat= 0.20084839803701052 \n",
      "acc for Psat= 0.22742030203951233 \n",
      "acc for optim= 0.18257867217261428\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.00717919459566474\n",
      "Loss on test= 0.009311030618846416\n",
      "acc for Lsat= 0.19477361306976565 \n",
      "acc for Psat= 0.2337272427296724 \n",
      "acc for optim= 0.18835116064053822\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.006663291249424219\n",
      "Loss on test= 0.008640125393867493\n",
      "acc for Lsat= 0.21532397923597943 \n",
      "acc for Psat= 0.20795046851195426 \n",
      "acc for optim= 0.18455515503700867\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.006978069897741079\n",
      "Loss on test= 0.008316542953252792\n",
      "acc for Lsat= 0.17355691508626658 \n",
      "acc for Psat= 0.20554442801207426 \n",
      "acc for optim= 0.17866965484486694\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.007231642957776785\n",
      "Loss on test= 0.008171448484063148\n",
      "acc for Lsat= 0.19344737799757075 \n",
      "acc for Psat= 0.2054940471956201 \n",
      "acc for optim= 0.1815250286954831\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.007205460220575333\n",
      "Loss on test= 0.008310205303132534\n",
      "acc for Lsat= 0.16878521250161657 \n",
      "acc for Psat= 0.21573502495503205 \n",
      "acc for optim= 0.17874521761889317\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.006741791032254696\n",
      "Loss on test= 0.008846255950629711\n",
      "acc for Lsat= 0.18042647034754275 \n",
      "acc for Psat= 0.2114418597159083 \n",
      "acc for optim= 0.18494298119655214\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.007489593233913183\n",
      "Loss on test= 0.008767018094658852\n",
      "acc for Lsat= 0.17357890436150988 \n",
      "acc for Psat= 0.20161689764984167 \n",
      "acc for optim= 0.1858157560389611\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.0068066478706896305\n",
      "Loss on test= 0.008513112552464008\n",
      "acc for Lsat= 0.17322605520479198 \n",
      "acc for Psat= 0.20970361400720067 \n",
      "acc for optim= 0.17642291112789563\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.006942971143871546\n",
      "Loss on test= 0.008860073983669281\n",
      "acc for Lsat= 0.2009816250714214 \n",
      "acc for Psat= 0.22509453554479567 \n",
      "acc for optim= 0.17804118619008433\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.006641055457293987\n",
      "Loss on test= 0.008319956250488758\n",
      "acc for Lsat= 0.17946671182060706 \n",
      "acc for Psat= 0.20691159480197935 \n",
      "acc for optim= 0.18355380958890863\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.006923051085323095\n",
      "Loss on test= 0.009037405252456665\n",
      "acc for Lsat= 0.17160875980272797 \n",
      "acc for Psat= 0.20367099863995194 \n",
      "acc for optim= 0.1879860859947302\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.007061619311571121\n",
      "Loss on test= 0.008713028393685818\n",
      "acc for Lsat= 0.16680530130263937 \n",
      "acc for Psat= 0.1988688806986024 \n",
      "acc for optim= 0.1800711145414589\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.006703123450279236\n",
      "Loss on test= 0.008529359474778175\n",
      "acc for Lsat= 0.16106647661692447 \n",
      "acc for Psat= 0.2302326646527408 \n",
      "acc for optim= 0.1821457124076646\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.00699987867847085\n",
      "Loss on test= 0.00884469598531723\n",
      "acc for Lsat= 0.19122151533164633 \n",
      "acc for Psat= 0.20398383855754815 \n",
      "acc for optim= 0.17920741240997784\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.00690542533993721\n",
      "Loss on test= 0.008722566068172455\n",
      "acc for Lsat= 0.1696381620314644 \n",
      "acc for Psat= 0.20427396942052195 \n",
      "acc for optim= 0.18971018190271427\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.0072738551534712315\n",
      "Loss on test= 0.007976469583809376\n",
      "acc for Lsat= 0.1767910862081497 \n",
      "acc for Psat= 0.2063936628126463 \n",
      "acc for optim= 0.17512763384443356\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.007075200323015451\n",
      "Loss on test= 0.008629384450614452\n",
      "acc for Lsat= 0.16904519305976687 \n",
      "acc for Psat= 0.21858427436587202 \n",
      "acc for optim= 0.17978980879959666\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.007480690721422434\n",
      "Loss on test= 0.009096188470721245\n",
      "acc for Lsat= 0.1776967179047356 \n",
      "acc for Psat= 0.1968512201196391 \n",
      "acc for optim= 0.18361081586173567\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.006801971700042486\n",
      "Loss on test= 0.00845252349972725\n",
      "acc for Lsat= 0.19349632064628675 \n",
      "acc for Psat= 0.22191504680672774 \n",
      "acc for optim= 0.17945353578944065\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.006810366176068783\n",
      "Loss on test= 0.00853575486689806\n",
      "acc for Lsat= 0.20115430444043864 \n",
      "acc for Psat= 0.2026741260990928 \n",
      "acc for optim= 0.17916019924412496\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.0069772289134562016\n",
      "Loss on test= 0.008247877471148968\n",
      "acc for Lsat= 0.16213056256643452 \n",
      "acc for Psat= 0.20386821616471545 \n",
      "acc for optim= 0.18567855017274984\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.007347462233155966\n",
      "Loss on test= 0.008362801745533943\n",
      "acc for Lsat= 0.1910834146864172 \n",
      "acc for Psat= 0.20376622145613807 \n",
      "acc for optim= 0.18204251128691631\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.006960405968129635\n",
      "Loss on test= 0.009348860010504723\n",
      "acc for Lsat= 0.17641837408539046 \n",
      "acc for Psat= 0.2022627280399081 \n",
      "acc for optim= 0.18593899662476165\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.006697432138025761\n",
      "Loss on test= 0.008661938831210136\n",
      "acc for Lsat= 0.1746349374833326 \n",
      "acc for Psat= 0.2287261418612735 \n",
      "acc for optim= 0.18811563746889168\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.007359839044511318\n",
      "Loss on test= 0.008330225944519043\n",
      "acc for Lsat= 0.17266802482810786 \n",
      "acc for Psat= 0.22218286697600098 \n",
      "acc for optim= 0.18260402772613785\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.0066751837730407715\n",
      "Loss on test= 0.00882973987609148\n",
      "acc for Lsat= 0.18983326497080746 \n",
      "acc for Psat= 0.2221464482017747 \n",
      "acc for optim= 0.1878301924330251\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.006684968713670969\n",
      "Loss on test= 0.008003635331988335\n",
      "acc for Lsat= 0.18038382267037437 \n",
      "acc for Psat= 0.1937051086585881 \n",
      "acc for optim= 0.18174746226372396\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.006565083749592304\n",
      "Loss on test= 0.008201250806450844\n",
      "acc for Lsat= 0.15788049368191603 \n",
      "acc for Psat= 0.1938831100730821 \n",
      "acc for optim= 0.18348121736217748\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.0065983617678284645\n",
      "Loss on test= 0.008612983860075474\n",
      "acc for Lsat= 0.16551855405693355 \n",
      "acc for Psat= 0.21083231836129895 \n",
      "acc for optim= 0.1784633437864345\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.0066758692264556885\n",
      "Loss on test= 0.007706745527684689\n",
      "acc for Lsat= 0.16847875592037348 \n",
      "acc for Psat= 0.20212630324474093 \n",
      "acc for optim= 0.18635024194568434\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.006426770240068436\n",
      "Loss on test= 0.008003787137567997\n",
      "acc for Lsat= 0.15948029675103007 \n",
      "acc for Psat= 0.21287109130978218 \n",
      "acc for optim= 0.18010501054422853\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.0064540887251496315\n",
      "Loss on test= 0.008684087544679642\n",
      "acc for Lsat= 0.175134208146101 \n",
      "acc for Psat= 0.19827563251040925 \n",
      "acc for optim= 0.17657887868828437\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.006507874932140112\n",
      "Loss on test= 0.007922861725091934\n",
      "acc for Lsat= 0.1696384266400557 \n",
      "acc for Psat= 0.19801076939522735 \n",
      "acc for optim= 0.18145306012326026\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.006630724761635065\n",
      "Loss on test= 0.008457809686660767\n",
      "acc for Lsat= 0.17497053230186108 \n",
      "acc for Psat= 0.19452707021741472 \n",
      "acc for optim= 0.17793936942728833\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.0065682739950716496\n",
      "Loss on test= 0.009221077896654606\n",
      "acc for Lsat= 0.18443197685057205 \n",
      "acc for Psat= 0.21205272992431629 \n",
      "acc for optim= 0.1793224777522512\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.006562258116900921\n",
      "Loss on test= 0.008331291377544403\n",
      "acc for Lsat= 0.15405096381188935 \n",
      "acc for Psat= 0.21466181357811037 \n",
      "acc for optim= 0.18073077584219882\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.006532664410769939\n",
      "Loss on test= 0.008538165129721165\n",
      "acc for Lsat= 0.17940961037329245 \n",
      "acc for Psat= 0.20265117659783144 \n",
      "acc for optim= 0.184769726523244\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.006626327987760305\n",
      "Loss on test= 0.00812914315611124\n",
      "acc for Lsat= 0.16742730485389895 \n",
      "acc for Psat= 0.2234590732354621 \n",
      "acc for optim= 0.18362827380908248\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.007054551504552364\n",
      "Loss on test= 0.008297123946249485\n",
      "acc for Lsat= 0.17158832783948202 \n",
      "acc for Psat= 0.2082669696927101 \n",
      "acc for optim= 0.18375159964312754\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.006873052567243576\n",
      "Loss on test= 0.007970210164785385\n",
      "acc for Lsat= 0.17841801858300985 \n",
      "acc for Psat= 0.19101047441439672 \n",
      "acc for optim= 0.1875119167138497\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.006614905782043934\n",
      "Loss on test= 0.008086884394288063\n",
      "acc for Lsat= 0.18834293691000564 \n",
      "acc for Psat= 0.19175125593166858 \n",
      "acc for optim= 0.184924334468946\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.006652705371379852\n",
      "Loss on test= 0.007916326634585857\n",
      "acc for Lsat= 0.17402030835481605 \n",
      "acc for Psat= 0.21442850432797625 \n",
      "acc for optim= 0.18571156307398418\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.006389113608747721\n",
      "Loss on test= 0.008128616027534008\n",
      "acc for Lsat= 0.17551232443507675 \n",
      "acc for Psat= 0.20097199277630262 \n",
      "acc for optim= 0.1776680788492114\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.006533819250762463\n",
      "Loss on test= 0.00806738343089819\n",
      "acc for Lsat= 0.1678869630416214 \n",
      "acc for Psat= 0.20308319892825893 \n",
      "acc for optim= 0.17848932867770495\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.006417463067919016\n",
      "Loss on test= 0.008150390349328518\n",
      "acc for Lsat= 0.18085539174193638 \n",
      "acc for Psat= 0.19455569532459419 \n",
      "acc for optim= 0.18101052605550827\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.006445811130106449\n",
      "Loss on test= 0.008032421581447124\n",
      "acc for Lsat= 0.16096493790601762 \n",
      "acc for Psat= 0.20142905032163802 \n",
      "acc for optim= 0.17857622266747059\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.006170802284032106\n",
      "Loss on test= 0.008123599924147129\n",
      "acc for Lsat= 0.1568621363635862 \n",
      "acc for Psat= 0.20514583516184653 \n",
      "acc for optim= 0.18156592631998822\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.006775097455829382\n",
      "Loss on test= 0.008248517289757729\n",
      "acc for Lsat= 0.1784627994338764 \n",
      "acc for Psat= 0.21042034960500744 \n",
      "acc for optim= 0.17814770060950189\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.006231331266462803\n",
      "Loss on test= 0.007890265434980392\n",
      "acc for Lsat= 0.17260217856955484 \n",
      "acc for Psat= 0.19828303394148308 \n",
      "acc for optim= 0.186466948431344\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.006294610910117626\n",
      "Loss on test= 0.008547897450625896\n",
      "acc for Lsat= 0.18006628271016736 \n",
      "acc for Psat= 0.20786605337252992 \n",
      "acc for optim= 0.1815940834113686\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.006564769893884659\n",
      "Loss on test= 0.00843757577240467\n",
      "acc for Lsat= 0.16691846768209542 \n",
      "acc for Psat= 0.209481671586877 \n",
      "acc for optim= 0.1767976668330299\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.006483499892055988\n",
      "Loss on test= 0.008140922524034977\n",
      "acc for Lsat= 0.16536288803021545 \n",
      "acc for Psat= 0.22310307899902224 \n",
      "acc for optim= 0.18184819457896023\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.006503411568701267\n",
      "Loss on test= 0.007770194206386805\n",
      "acc for Lsat= 0.16646273038044693 \n",
      "acc for Psat= 0.20171160303728014 \n",
      "acc for optim= 0.1828773792066848\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.0068711331114172935\n",
      "Loss on test= 0.008055102080106735\n",
      "acc for Lsat= 0.16631097555309382 \n",
      "acc for Psat= 0.2071259147215627 \n",
      "acc for optim= 0.18613411295566457\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.006685609929263592\n",
      "Loss on test= 0.008496795780956745\n",
      "acc for Lsat= 0.17025226302383864 \n",
      "acc for Psat= 0.21668622063045376 \n",
      "acc for optim= 0.18734800397240953\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.006411279551684856\n",
      "Loss on test= 0.008134869858622551\n",
      "acc for Lsat= 0.16414505733171342 \n",
      "acc for Psat= 0.19722281168930644 \n",
      "acc for optim= 0.18223972285288523\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.006475237663835287\n",
      "Loss on test= 0.007858735509216785\n",
      "acc for Lsat= 0.15658939272073694 \n",
      "acc for Psat= 0.20551928623205387 \n",
      "acc for optim= 0.18750591681705744\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.006561306770890951\n",
      "Loss on test= 0.008152328431606293\n",
      "acc for Lsat= 0.15739655928642368 \n",
      "acc for Psat= 0.21441373150761345 \n",
      "acc for optim= 0.1798418660315143\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.006672913674265146\n",
      "Loss on test= 0.00827990472316742\n",
      "acc for Lsat= 0.1671615051422421 \n",
      "acc for Psat= 0.2223520775592779 \n",
      "acc for optim= 0.17748283598510944\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.006526575889438391\n",
      "Loss on test= 0.008579680696129799\n",
      "acc for Lsat= 0.1796967672160254 \n",
      "acc for Psat= 0.21635239423356653 \n",
      "acc for optim= 0.17920158683497947\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.0060902489349246025\n",
      "Loss on test= 0.008367137052118778\n",
      "acc for Lsat= 0.17039087838171238 \n",
      "acc for Psat= 0.20404587275650138 \n",
      "acc for optim= 0.17412504750078728\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.00644537340849638\n",
      "Loss on test= 0.008141763508319855\n",
      "acc for Lsat= 0.16430080460337254 \n",
      "acc for Psat= 0.19405347495201447 \n",
      "acc for optim= 0.17602605752164563\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.006073429249227047\n",
      "Loss on test= 0.008587982505559921\n",
      "acc for Lsat= 0.16768360287981626 \n",
      "acc for Psat= 0.22420599658546023 \n",
      "acc for optim= 0.18649425101752745\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.006378048565238714\n",
      "Loss on test= 0.007971957325935364\n",
      "acc for Lsat= 0.164570943344018 \n",
      "acc for Psat= 0.198973205713956 \n",
      "acc for optim= 0.17941081138875442\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.006118965335190296\n",
      "Loss on test= 0.008068877272307873\n",
      "acc for Lsat= 0.1579785448388334 \n",
      "acc for Psat= 0.1887527240881757 \n",
      "acc for optim= 0.1843352890952269\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.006207966711372137\n",
      "Loss on test= 0.007815325632691383\n",
      "acc for Lsat= 0.1556850752663478 \n",
      "acc for Psat= 0.1999439917977844 \n",
      "acc for optim= 0.1785939259164673\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.00647431006655097\n",
      "Loss on test= 0.008165791630744934\n",
      "acc for Lsat= 0.17545911758607557 \n",
      "acc for Psat= 0.19589286263112254 \n",
      "acc for optim= 0.17324920291344437\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.005955701228231192\n",
      "Loss on test= 0.007636519148945808\n",
      "acc for Lsat= 0.1692296097321306 \n",
      "acc for Psat= 0.20512063275291736 \n",
      "acc for optim= 0.17692702144504138\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.006579688750207424\n",
      "Loss on test= 0.008906886912882328\n",
      "acc for Lsat= 0.1899510881920788 \n",
      "acc for Psat= 0.18493775673283142 \n",
      "acc for optim= 0.18398044120413481\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.006281000562012196\n",
      "Loss on test= 0.00820942036807537\n",
      "acc for Lsat= 0.15860100450093445 \n",
      "acc for Psat= 0.1918053886174705 \n",
      "acc for optim= 0.181379763275904\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.006488417740911245\n",
      "Loss on test= 0.008239520713686943\n",
      "acc for Lsat= 0.1810960541110005 \n",
      "acc for Psat= 0.2119519195992683 \n",
      "acc for optim= 0.1801055582683938\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.006250257603824139\n",
      "Loss on test= 0.008386727422475815\n",
      "acc for Lsat= 0.16064711940752965 \n",
      "acc for Psat= 0.20041137510545282 \n",
      "acc for optim= 0.17058967453213866\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.006129165645688772\n",
      "Loss on test= 0.008125877007842064\n",
      "acc for Lsat= 0.16403676036794929 \n",
      "acc for Psat= 0.19985729357803558 \n",
      "acc for optim= 0.17399716452432062\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.006152299232780933\n",
      "Loss on test= 0.008126477710902691\n",
      "acc for Lsat= 0.15419701679121153 \n",
      "acc for Psat= 0.18253636992704428 \n",
      "acc for optim= 0.18559633325976244\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.005893008317798376\n",
      "Loss on test= 0.007903612218797207\n",
      "acc for Lsat= 0.16337852886559243 \n",
      "acc for Psat= 0.19365264927304243 \n",
      "acc for optim= 0.1803601697381189\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.006362223066389561\n",
      "Loss on test= 0.008086379617452621\n",
      "acc for Lsat= 0.16048472378026984 \n",
      "acc for Psat= 0.20701448169525438 \n",
      "acc for optim= 0.1793684128106984\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.006345398724079132\n",
      "Loss on test= 0.008242946118116379\n",
      "acc for Lsat= 0.18542226560616132 \n",
      "acc for Psat= 0.22137673480882783 \n",
      "acc for optim= 0.18441868940421732\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.00607129093259573\n",
      "Loss on test= 0.00881727784872055\n",
      "acc for Lsat= 0.1739670981914492 \n",
      "acc for Psat= 0.19945760948858302 \n",
      "acc for optim= 0.18233897298017182\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.006146931555122137\n",
      "Loss on test= 0.007929845713078976\n",
      "acc for Lsat= 0.16202538917031994 \n",
      "acc for Psat= 0.19044758433239442 \n",
      "acc for optim= 0.18400545772594462\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.006300545297563076\n",
      "Loss on test= 0.008499963209033012\n",
      "acc for Lsat= 0.16282558021112728 \n",
      "acc for Psat= 0.1954945091581827 \n",
      "acc for optim= 0.1778420328314332\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.005899438168853521\n",
      "Loss on test= 0.008038876578211784\n",
      "acc for Lsat= 0.1730256206359806 \n",
      "acc for Psat= 0.1921437404381844 \n",
      "acc for optim= 0.17521734232126857\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.006229201797395945\n",
      "Loss on test= 0.008166694082319736\n",
      "acc for Lsat= 0.174083628410046 \n",
      "acc for Psat= 0.20486236879579173 \n",
      "acc for optim= 0.17808604250933027\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.00622590584680438\n",
      "Loss on test= 0.008713909424841404\n",
      "acc for Lsat= 0.17728552279543497 \n",
      "acc for Psat= 0.1901708618856081 \n",
      "acc for optim= 0.1750963185352777\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.006149631924927235\n",
      "Loss on test= 0.008082214742898941\n",
      "acc for Lsat= 0.17621642905888607 \n",
      "acc for Psat= 0.19953177898175647 \n",
      "acc for optim= 0.18059160141613081\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.005987910553812981\n",
      "Loss on test= 0.007841108366847038\n",
      "acc for Lsat= 0.16293226050548867 \n",
      "acc for Psat= 0.2155335909847292 \n",
      "acc for optim= 0.17998526220755712\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.005923010408878326\n",
      "Loss on test= 0.007850964553654194\n",
      "acc for Lsat= 0.17159580898234528 \n",
      "acc for Psat= 0.20357087118967176 \n",
      "acc for optim= 0.18003666126598666\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.00643785297870636\n",
      "Loss on test= 0.008209215477108955\n",
      "acc for Lsat= 0.1618861516714325 \n",
      "acc for Psat= 0.1870446018605554 \n",
      "acc for optim= 0.18836772232182844\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.00599359767511487\n",
      "Loss on test= 0.008377725258469582\n",
      "acc for Lsat= 0.18502814267651316 \n",
      "acc for Psat= 0.19717030743686634 \n",
      "acc for optim= 0.17977790178790246\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.005933777894824743\n",
      "Loss on test= 0.008587503805756569\n",
      "acc for Lsat= 0.16982284587164806 \n",
      "acc for Psat= 0.19869202143039372 \n",
      "acc for optim= 0.17671208817814285\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.0057457974180579185\n",
      "Loss on test= 0.007824958302080631\n",
      "acc for Lsat= 0.15668547780817893 \n",
      "acc for Psat= 0.18293947682746486 \n",
      "acc for optim= 0.18081479005837148\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.005917923524975777\n",
      "Loss on test= 0.008213529363274574\n",
      "acc for Lsat= 0.17347903731679848 \n",
      "acc for Psat= 0.19329303703957892 \n",
      "acc for optim= 0.16891138950261653\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.005849099718034267\n",
      "Loss on test= 0.007926330901682377\n",
      "acc for Lsat= 0.1769420051418596 \n",
      "acc for Psat= 0.1828700243274025 \n",
      "acc for optim= 0.17651737933925002\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.006043541245162487\n",
      "Loss on test= 0.00842052511870861\n",
      "acc for Lsat= 0.1656954777594961 \n",
      "acc for Psat= 0.19001356689793775 \n",
      "acc for optim= 0.17209192666102996\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.0061201960779726505\n",
      "Loss on test= 0.008734599687159061\n",
      "acc for Lsat= 0.1750455927317504 \n",
      "acc for Psat= 0.19933864111075994 \n",
      "acc for optim= 0.18344477736065498\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.006177257746458054\n",
      "Loss on test= 0.008265616372227669\n",
      "acc for Lsat= 0.15194093587591942 \n",
      "acc for Psat= 0.19239562512299077 \n",
      "acc for optim= 0.17700743620077788\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.006678213365375996\n",
      "Loss on test= 0.007660506293177605\n",
      "acc for Lsat= 0.1772483672114608 \n",
      "acc for Psat= 0.2041254518465826 \n",
      "acc for optim= 0.18173759648515309\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.006183589808642864\n",
      "Loss on test= 0.008533291518688202\n",
      "acc for Lsat= 0.16411113827050375 \n",
      "acc for Psat= 0.22166584331955433 \n",
      "acc for optim= 0.1778939960845059\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.006198656279593706\n",
      "Loss on test= 0.007759620901197195\n",
      "acc for Lsat= 0.17320930095681478 \n",
      "acc for Psat= 0.19308633811339607 \n",
      "acc for optim= 0.1786342679596884\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.00613326346501708\n",
      "Loss on test= 0.007847780361771584\n",
      "acc for Lsat= 0.16590780674672656 \n",
      "acc for Psat= 0.21249775443107774 \n",
      "acc for optim= 0.18321140794046262\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.006460587494075298\n",
      "Loss on test= 0.008088399656116962\n",
      "acc for Lsat= 0.16071918398942456 \n",
      "acc for Psat= 0.18842028267853358 \n",
      "acc for optim= 0.18330881581775324\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.006082361564040184\n",
      "Loss on test= 0.008264964446425438\n",
      "acc for Lsat= 0.15940195701844115 \n",
      "acc for Psat= 0.21486156994293704 \n",
      "acc for optim= 0.1767647559004411\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.006662347819656134\n",
      "Loss on test= 0.008366458117961884\n",
      "acc for Lsat= 0.16224862103136714 \n",
      "acc for Psat= 0.20198897352083356 \n",
      "acc for optim= 0.18399549598927747\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.006112114991992712\n",
      "Loss on test= 0.0082849794998765\n",
      "acc for Lsat= 0.1783966894249134 \n",
      "acc for Psat= 0.20313541841403138 \n",
      "acc for optim= 0.1877409316377989\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.006005891598761082\n",
      "Loss on test= 0.008183296769857407\n",
      "acc for Lsat= 0.1633871345649107 \n",
      "acc for Psat= 0.1998833072509189 \n",
      "acc for optim= 0.18038302383578353\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.006124638020992279\n",
      "Loss on test= 0.008575525134801865\n",
      "acc for Lsat= 0.15821844855815814 \n",
      "acc for Psat= 0.18653196175048342 \n",
      "acc for optim= 0.18386306639180564\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.00572302658110857\n",
      "Loss on test= 0.008022531867027283\n",
      "acc for Lsat= 0.18022845633667664 \n",
      "acc for Psat= 0.19691449449222045 \n",
      "acc for optim= 0.17921645522144333\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.005968592595309019\n",
      "Loss on test= 0.008060690015554428\n",
      "acc for Lsat= 0.17881756865373644 \n",
      "acc for Psat= 0.20041216377619286 \n",
      "acc for optim= 0.17611739734129514\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.005707126576453447\n",
      "Loss on test= 0.007546928245574236\n",
      "acc for Lsat= 0.16085207930500772 \n",
      "acc for Psat= 0.18886247441701837 \n",
      "acc for optim= 0.17905200095801924\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.005829315632581711\n",
      "Loss on test= 0.007852284237742424\n",
      "acc for Lsat= 0.15420968904289736 \n",
      "acc for Psat= 0.1947839492263528 \n",
      "acc for optim= 0.17508899441139666\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.006183289457112551\n",
      "Loss on test= 0.007947046309709549\n",
      "acc for Lsat= 0.15709306697540565 \n",
      "acc for Psat= 0.1995908294756683 \n",
      "acc for optim= 0.18236011490263962\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.005973841529339552\n",
      "Loss on test= 0.008210732601583004\n",
      "acc for Lsat= 0.16355781952132945 \n",
      "acc for Psat= 0.20491153075451368 \n",
      "acc for optim= 0.17794647265099692\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.00613812729716301\n",
      "Loss on test= 0.008106148801743984\n",
      "acc for Lsat= 0.14795591733027172 \n",
      "acc for Psat= 0.18937277902494049 \n",
      "acc for optim= 0.1790154070301424\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.00592526700347662\n",
      "Loss on test= 0.008294947445392609\n",
      "acc for Lsat= 0.16409857123250476 \n",
      "acc for Psat= 0.18084294165701217 \n",
      "acc for optim= 0.17572641536978945\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.005912020802497864\n",
      "Loss on test= 0.0079873688519001\n",
      "acc for Lsat= 0.16021492019654482 \n",
      "acc for Psat= 0.19142790732477777 \n",
      "acc for optim= 0.1722333103894508\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.006684719584882259\n",
      "Loss on test= 0.008107408881187439\n",
      "acc for Lsat= 0.1705346084783831 \n",
      "acc for Psat= 0.180993980475793 \n",
      "acc for optim= 0.19057302079048985\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.005874862428754568\n",
      "Loss on test= 0.008343937806785107\n",
      "acc for Lsat= 0.16649865219426785 \n",
      "acc for Psat= 0.19962532776178885 \n",
      "acc for optim= 0.18617834595325938\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.005853727459907532\n",
      "Loss on test= 0.0076653603464365005\n",
      "acc for Lsat= 0.15088238400639967 \n",
      "acc for Psat= 0.18877558730338456 \n",
      "acc for optim= 0.17332927833547906\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.005746403709053993\n",
      "Loss on test= 0.008360637351870537\n",
      "acc for Lsat= 0.15422094951886645 \n",
      "acc for Psat= 0.19161248923766955 \n",
      "acc for optim= 0.1762599173582113\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.005719953216612339\n",
      "Loss on test= 0.00779885845258832\n",
      "acc for Lsat= 0.17083863317432096 \n",
      "acc for Psat= 0.18541060612941557 \n",
      "acc for optim= 0.18018302967558142\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.005973345600068569\n",
      "Loss on test= 0.007822893559932709\n",
      "acc for Lsat= 0.16737683997985708 \n",
      "acc for Psat= 0.19079146679475537 \n",
      "acc for optim= 0.1765222212578338\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.005859216209501028\n",
      "Loss on test= 0.00830902624875307\n",
      "acc for Lsat= 0.16068613230838577 \n",
      "acc for Psat= 0.18569940583490324 \n",
      "acc for optim= 0.18287816616614944\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.006991384085267782\n",
      "Loss on test= 0.007813706994056702\n",
      "acc for Lsat= 0.165886585093027 \n",
      "acc for Psat= 0.18989562504766433 \n",
      "acc for optim= 0.1781781240041963\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.00620597368106246\n",
      "Loss on test= 0.00785747542977333\n",
      "acc for Lsat= 0.16397908506838635 \n",
      "acc for Psat= 0.19798291931386855 \n",
      "acc for optim= 0.18527157482859052\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.0059995390474796295\n",
      "Loss on test= 0.008475411683321\n",
      "acc for Lsat= 0.17080750806053402 \n",
      "acc for Psat= 0.180335195974798 \n",
      "acc for optim= 0.17641840836245062\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.005964871495962143\n",
      "Loss on test= 0.008274375461041927\n",
      "acc for Lsat= 0.15851010442005287 \n",
      "acc for Psat= 0.197585951408837 \n",
      "acc for optim= 0.1787838530458594\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.005972502753138542\n",
      "Loss on test= 0.007753313519060612\n",
      "acc for Lsat= 0.1555532382251542 \n",
      "acc for Psat= 0.18849305279923176 \n",
      "acc for optim= 0.1816459688772142\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.0057422928512096405\n",
      "Loss on test= 0.008357738144695759\n",
      "acc for Lsat= 0.16734383405457234 \n",
      "acc for Psat= 0.18126971489314722 \n",
      "acc for optim= 0.18591616447732523\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.00571438018232584\n",
      "Loss on test= 0.007923959754407406\n",
      "acc for Lsat= 0.14926585192280653 \n",
      "acc for Psat= 0.1828848292451871 \n",
      "acc for optim= 0.17493677543953098\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.005925372708588839\n",
      "Loss on test= 0.0078046307899057865\n",
      "acc for Lsat= 0.16511993226137195 \n",
      "acc for Psat= 0.1788688741967876 \n",
      "acc for optim= 0.17724743994300207\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.005910483188927174\n",
      "Loss on test= 0.0078144995495677\n",
      "acc for Lsat= 0.15429761359753416 \n",
      "acc for Psat= 0.18303955172123693 \n",
      "acc for optim= 0.17650425546596468\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.005807401612401009\n",
      "Loss on test= 0.00814430695027113\n",
      "acc for Lsat= 0.14664710848477716 \n",
      "acc for Psat= 0.1950420246750582 \n",
      "acc for optim= 0.18164360372924063\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.00584801658987999\n",
      "Loss on test= 0.007910443469882011\n",
      "acc for Lsat= 0.15763701587807116 \n",
      "acc for Psat= 0.18026271219354326 \n",
      "acc for optim= 0.17589761170417406\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.005861334037035704\n",
      "Loss on test= 0.007663703989237547\n",
      "acc for Lsat= 0.1532857017737592 \n",
      "acc for Psat= 0.1957543468495953 \n",
      "acc for optim= 0.17572208435034195\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.005613221321254969\n",
      "Loss on test= 0.0076976860873401165\n",
      "acc for Lsat= 0.15313311974817628 \n",
      "acc for Psat= 0.1916916283385706 \n",
      "acc for optim= 0.18304694311580713\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.006225033197551966\n",
      "Loss on test= 0.007817146368324757\n",
      "acc for Lsat= 0.1517097670613544 \n",
      "acc for Psat= 0.19666375143178663 \n",
      "acc for optim= 0.1796214767620082\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.0060554672963917255\n",
      "Loss on test= 0.007991058751940727\n",
      "acc for Lsat= 0.1487463133573746 \n",
      "acc for Psat= 0.1946921007728708 \n",
      "acc for optim= 0.18675266763087567\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.005808084271848202\n",
      "Loss on test= 0.008105171844363213\n",
      "acc for Lsat= 0.15702833559852644 \n",
      "acc for Psat= 0.18577287557580677 \n",
      "acc for optim= 0.18531305651359006\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.0057161590084433556\n",
      "Loss on test= 0.008284499868750572\n",
      "acc for Lsat= 0.15782454418415418 \n",
      "acc for Psat= 0.18660024190378818 \n",
      "acc for optim= 0.18378969949229285\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.005732591729611158\n",
      "Loss on test= 0.007817531004548073\n",
      "acc for Lsat= 0.16876695675099818 \n",
      "acc for Psat= 0.19463895846036125 \n",
      "acc for optim= 0.1747773151121438\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.005893033929169178\n",
      "Loss on test= 0.007950586266815662\n",
      "acc for Lsat= 0.16398730689552843 \n",
      "acc for Psat= 0.20518830420900724 \n",
      "acc for optim= 0.18182807665386955\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.0056680114939808846\n",
      "Loss on test= 0.007982567884027958\n",
      "acc for Lsat= 0.15162588053050863 \n",
      "acc for Psat= 0.197208096094231 \n",
      "acc for optim= 0.17859153573164624\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.00590507360175252\n",
      "Loss on test= 0.007567412685602903\n",
      "acc for Lsat= 0.1520889115831376 \n",
      "acc for Psat= 0.2015619074494471 \n",
      "acc for optim= 0.1801512007349644\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.005687791388481855\n",
      "Loss on test= 0.008171053603291512\n",
      "acc for Lsat= 0.1654178721085954 \n",
      "acc for Psat= 0.1957110643247524 \n",
      "acc for optim= 0.17405750396266412\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.005613697227090597\n",
      "Loss on test= 0.007817665114998817\n",
      "acc for Lsat= 0.16680278384840483 \n",
      "acc for Psat= 0.20051037566965355 \n",
      "acc for optim= 0.1793407024288947\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.005633541848510504\n",
      "Loss on test= 0.008019736967980862\n",
      "acc for Lsat= 0.16507167010701673 \n",
      "acc for Psat= 0.19657312494780885 \n",
      "acc for optim= 0.17645513738847154\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.006106062792241573\n",
      "Loss on test= 0.008122364059090614\n",
      "acc for Lsat= 0.15886568546898236 \n",
      "acc for Psat= 0.18777635506426793 \n",
      "acc for optim= 0.18928160376447925\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.005815854296088219\n",
      "Loss on test= 0.007899473421275616\n",
      "acc for Lsat= 0.17268140979576857 \n",
      "acc for Psat= 0.20444146870505675 \n",
      "acc for optim= 0.18573816728427028\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.005998201668262482\n",
      "Loss on test= 0.00818798691034317\n",
      "acc for Lsat= 0.16470951591217586 \n",
      "acc for Psat= 0.18680543775334343 \n",
      "acc for optim= 0.17519366697629637\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.0057649328373372555\n",
      "Loss on test= 0.008115374483168125\n",
      "acc for Lsat= 0.17208768035207406 \n",
      "acc for Psat= 0.19300666856560397 \n",
      "acc for optim= 0.18453590316506155\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.005691081285476685\n",
      "Loss on test= 0.007742160931229591\n",
      "acc for Lsat= 0.166120441501901 \n",
      "acc for Psat= 0.18792830095562005 \n",
      "acc for optim= 0.17220196461335557\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.005813304800540209\n",
      "Loss on test= 0.007832860574126244\n",
      "acc for Lsat= 0.1512190709978134 \n",
      "acc for Psat= 0.17784846953863515 \n",
      "acc for optim= 0.1780694188576833\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.005730459000915289\n",
      "Loss on test= 0.008013193495571613\n",
      "acc for Lsat= 0.16006871919609514 \n",
      "acc for Psat= 0.19647861683099974 \n",
      "acc for optim= 0.18612695010107003\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.005775378085672855\n",
      "Loss on test= 0.007588803768157959\n",
      "acc for Lsat= 0.16086156335249008 \n",
      "acc for Psat= 0.1915379066176743 \n",
      "acc for optim= 0.1809690689419961\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.005668590776622295\n",
      "Loss on test= 0.00789650622755289\n",
      "acc for Lsat= 0.16567154717727062 \n",
      "acc for Psat= 0.18809923677033455 \n",
      "acc for optim= 0.17767659829658472\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.005903164856135845\n",
      "Loss on test= 0.007844794541597366\n",
      "acc for Lsat= 0.15858899663778817 \n",
      "acc for Psat= 0.19973030829359395 \n",
      "acc for optim= 0.17965679432591805\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.005689213518053293\n",
      "Loss on test= 0.007799508050084114\n",
      "acc for Lsat= 0.16152224963812156 \n",
      "acc for Psat= 0.2011587336602178 \n",
      "acc for optim= 0.17884990903167206\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.005629912484437227\n",
      "Loss on test= 0.007615875918418169\n",
      "acc for Lsat= 0.15327359744076632 \n",
      "acc for Psat= 0.1913378826261414 \n",
      "acc for optim= 0.17642969963833552\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.005623895209282637\n",
      "Loss on test= 0.008071325719356537\n",
      "acc for Lsat= 0.15707187953325882 \n",
      "acc for Psat= 0.19606626879607067 \n",
      "acc for optim= 0.17644518484746977\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.005627742502838373\n",
      "Loss on test= 0.008145674131810665\n",
      "acc for Lsat= 0.16317154258932368 \n",
      "acc for Psat= 0.19598382781641405 \n",
      "acc for optim= 0.18275688587679323\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.005608452949672937\n",
      "Loss on test= 0.007987819612026215\n",
      "acc for Lsat= 0.16254230962758962 \n",
      "acc for Psat= 0.2020779988765619 \n",
      "acc for optim= 0.18207598218282103\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.005596718285232782\n",
      "Loss on test= 0.007872995920479298\n",
      "acc for Lsat= 0.16068696739346736 \n",
      "acc for Psat= 0.20895927315224802 \n",
      "acc for optim= 0.1831215129796889\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.005884059704840183\n",
      "Loss on test= 0.0076608299277722836\n",
      "acc for Lsat= 0.15570155262114999 \n",
      "acc for Psat= 0.18423956619484014 \n",
      "acc for optim= 0.18086899450873253\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.005707631818950176\n",
      "Loss on test= 0.007664729841053486\n",
      "acc for Lsat= 0.15031679282451552 \n",
      "acc for Psat= 0.19832548448390358 \n",
      "acc for optim= 0.174223944929249\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.005890387110412121\n",
      "Loss on test= 0.00835000816732645\n",
      "acc for Lsat= 0.15711745707285743 \n",
      "acc for Psat= 0.18956545311194217 \n",
      "acc for optim= 0.1740083506350253\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.00563033577054739\n",
      "Loss on test= 0.007792677730321884\n",
      "acc for Lsat= 0.16017054229226635 \n",
      "acc for Psat= 0.20539650751190017 \n",
      "acc for optim= 0.18365963217221462\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.005854791961610317\n",
      "Loss on test= 0.007568804081529379\n",
      "acc for Lsat= 0.16429846232382916 \n",
      "acc for Psat= 0.1827278123442828 \n",
      "acc for optim= 0.1823832221901508\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.005815367214381695\n",
      "Loss on test= 0.00763749610632658\n",
      "acc for Lsat= 0.16154686789997838 \n",
      "acc for Psat= 0.189849369211235 \n",
      "acc for optim= 0.18362335678109837\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.005572867579758167\n",
      "Loss on test= 0.007984725758433342\n",
      "acc for Lsat= 0.16627085944255968 \n",
      "acc for Psat= 0.1994037869348206 \n",
      "acc for optim= 0.1769709506387952\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.00580188911408186\n",
      "Loss on test= 0.008077731356024742\n",
      "acc for Lsat= 0.15815097129552222 \n",
      "acc for Psat= 0.18520562922654552 \n",
      "acc for optim= 0.17498547419038274\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.006219010800123215\n",
      "Loss on test= 0.00865531712770462\n",
      "acc for Lsat= 0.15657929011761806 \n",
      "acc for Psat= 0.19247221913924403 \n",
      "acc for optim= 0.17809835754222328\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.006057891063392162\n",
      "Loss on test= 0.007850523106753826\n",
      "acc for Lsat= 0.15403808759617024 \n",
      "acc for Psat= 0.179569030203284 \n",
      "acc for optim= 0.17867598292445497\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.005789184011518955\n",
      "Loss on test= 0.007856123149394989\n",
      "acc for Lsat= 0.15667828864963787 \n",
      "acc for Psat= 0.19057143212326605 \n",
      "acc for optim= 0.19155460218984832\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.005477603059262037\n",
      "Loss on test= 0.008108126930892467\n",
      "acc for Lsat= 0.17570587145698974 \n",
      "acc for Psat= 0.1937078702463921 \n",
      "acc for optim= 0.16872013631574026\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.005993732251226902\n",
      "Loss on test= 0.00800261553376913\n",
      "acc for Lsat= 0.16654382564077824 \n",
      "acc for Psat= 0.2041430968588951 \n",
      "acc for optim= 0.18395992263771793\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.0058455877006053925\n",
      "Loss on test= 0.00807592086493969\n",
      "acc for Lsat= 0.16507040576619997 \n",
      "acc for Psat= 0.1844387595446353 \n",
      "acc for optim= 0.18584174959983327\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.005464321002364159\n",
      "Loss on test= 0.007938027381896973\n",
      "acc for Lsat= 0.1496550284400506 \n",
      "acc for Psat= 0.19078259214865745 \n",
      "acc for optim= 0.1755991283006447\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.005708959884941578\n",
      "Loss on test= 0.007876476272940636\n",
      "acc for Lsat= 0.16272109935144116 \n",
      "acc for Psat= 0.20969077648497644 \n",
      "acc for optim= 0.17846181387287854\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.005932661239057779\n",
      "Loss on test= 0.007599294185638428\n",
      "acc for Lsat= 0.15892653465996207 \n",
      "acc for Psat= 0.1970464325736832 \n",
      "acc for optim= 0.1775911563838981\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.005665684584528208\n",
      "Loss on test= 0.007781330496072769\n",
      "acc for Lsat= 0.1623088046173626 \n",
      "acc for Psat= 0.19148050319922508 \n",
      "acc for optim= 0.175909442364784\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.005625855177640915\n",
      "Loss on test= 0.007728059310466051\n",
      "acc for Lsat= 0.1548700132103805 \n",
      "acc for Psat= 0.19565707683338035 \n",
      "acc for optim= 0.18066101990283284\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.005598409101366997\n",
      "Loss on test= 0.008000745438039303\n",
      "acc for Lsat= 0.16520675608838647 \n",
      "acc for Psat= 0.1852930472200912 \n",
      "acc for optim= 0.18691598461172973\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.005249667447060347\n",
      "Loss on test= 0.007858067750930786\n",
      "acc for Lsat= 0.15943622363215507 \n",
      "acc for Psat= 0.19075969740266432 \n",
      "acc for optim= 0.17511371736098777\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.00562282744795084\n",
      "Loss on test= 0.007933716289699078\n",
      "acc for Lsat= 0.16166218496805637 \n",
      "acc for Psat= 0.19873369946068184 \n",
      "acc for optim= 0.17961598452389121\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.00571735855191946\n",
      "Loss on test= 0.0077889286912977695\n",
      "acc for Lsat= 0.1594428326201732 \n",
      "acc for Psat= 0.1783755122218281 \n",
      "acc for optim= 0.1834102744873056\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.005448211915791035\n",
      "Loss on test= 0.008091072551906109\n",
      "acc for Lsat= 0.16162326903608207 \n",
      "acc for Psat= 0.1801524612922832 \n",
      "acc for optim= 0.18094505116812976\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.00574825843796134\n",
      "Loss on test= 0.007880892604589462\n",
      "acc for Lsat= 0.17337177518266636 \n",
      "acc for Psat= 0.20328471071247134 \n",
      "acc for optim= 0.17410145525011372\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.005713184829801321\n",
      "Loss on test= 0.007970885373651981\n",
      "acc for Lsat= 0.1516548178395348 \n",
      "acc for Psat= 0.18179279507565327 \n",
      "acc for optim= 0.176949214075046\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.005338927265256643\n",
      "Loss on test= 0.00808640755712986\n",
      "acc for Lsat= 0.16498516168078928 \n",
      "acc for Psat= 0.20030132988009786 \n",
      "acc for optim= 0.18807137437225854\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.005528750363737345\n",
      "Loss on test= 0.007565871812403202\n",
      "acc for Lsat= 0.15401649246834764 \n",
      "acc for Psat= 0.18581053223957109 \n",
      "acc for optim= 0.17924349205625686\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.005375039763748646\n",
      "Loss on test= 0.00781860388815403\n",
      "acc for Lsat= 0.1585467503387023 \n",
      "acc for Psat= 0.19079416664622603 \n",
      "acc for optim= 0.170102533931676\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.00575959263369441\n",
      "Loss on test= 0.007652264088392258\n",
      "acc for Lsat= 0.1577132153175909 \n",
      "acc for Psat= 0.1796711057439813 \n",
      "acc for optim= 0.18171001683737412\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.005600278731435537\n",
      "Loss on test= 0.007274024188518524\n",
      "acc for Lsat= 0.1656310526406026 \n",
      "acc for Psat= 0.17551319896945822 \n",
      "acc for optim= 0.1768259001719731\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.005614059511572123\n",
      "Loss on test= 0.007870717905461788\n",
      "acc for Lsat= 0.16735473194515135 \n",
      "acc for Psat= 0.20070318142097676 \n",
      "acc for optim= 0.18143446401660246\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.005322045646607876\n",
      "Loss on test= 0.007913259789347649\n",
      "acc for Lsat= 0.14925667296056866 \n",
      "acc for Psat= 0.1917864312425439 \n",
      "acc for optim= 0.18285328635800874\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.00532009731978178\n",
      "Loss on test= 0.007815958000719547\n",
      "acc for Lsat= 0.15114210045927007 \n",
      "acc for Psat= 0.19081806758510284 \n",
      "acc for optim= 0.18472965976918024\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.005497168283909559\n",
      "Loss on test= 0.008341328240931034\n",
      "acc for Lsat= 0.1631258964988968 \n",
      "acc for Psat= 0.19961251155964718 \n",
      "acc for optim= 0.17501423293493257\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.005454579368233681\n",
      "Loss on test= 0.007771290373057127\n",
      "acc for Lsat= 0.16245996576627014 \n",
      "acc for Psat= 0.17954146217547173 \n",
      "acc for optim= 0.18042510842587647\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.005533132702112198\n",
      "Loss on test= 0.008133064955472946\n",
      "acc for Lsat= 0.17344341301750468 \n",
      "acc for Psat= 0.1777135055980714 \n",
      "acc for optim= 0.1734226495077162\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.005952194333076477\n",
      "Loss on test= 0.007782205007970333\n",
      "acc for Lsat= 0.1542193328744167 \n",
      "acc for Psat= 0.17433263145036018 \n",
      "acc for optim= 0.18110133897223066\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.005349720362573862\n",
      "Loss on test= 0.007838288322091103\n",
      "acc for Lsat= 0.15478608826152432 \n",
      "acc for Psat= 0.19070698851242388 \n",
      "acc for optim= 0.17932169893909183\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.005520062055438757\n",
      "Loss on test= 0.00783078745007515\n",
      "acc for Lsat= 0.16070419578797748 \n",
      "acc for Psat= 0.19539745490755656 \n",
      "acc for optim= 0.1719239750043031\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.005608945153653622\n",
      "Loss on test= 0.007895177230238914\n",
      "acc for Lsat= 0.16529098517608784 \n",
      "acc for Psat= 0.18849851848027044 \n",
      "acc for optim= 0.18109185808742817\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.005332259926944971\n",
      "Loss on test= 0.007659834809601307\n",
      "acc for Lsat= 0.15743482623065128 \n",
      "acc for Psat= 0.20256273023713547 \n",
      "acc for optim= 0.1763355466390227\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.005761727225035429\n",
      "Loss on test= 0.007718641310930252\n",
      "acc for Lsat= 0.1540981924289181 \n",
      "acc for Psat= 0.20301381776712407 \n",
      "acc for optim= 0.17987385357684288\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.005577931646257639\n",
      "Loss on test= 0.007609915919601917\n",
      "acc for Lsat= 0.15064806887368504 \n",
      "acc for Psat= 0.17749712830876976 \n",
      "acc for optim= 0.18219113060173991\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.0053622485138475895\n",
      "Loss on test= 0.007572215516120195\n",
      "acc for Lsat= 0.158831398974585 \n",
      "acc for Psat= 0.18965916892620505 \n",
      "acc for optim= 0.18112545611041495\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.00537157105281949\n",
      "Loss on test= 0.007786367554217577\n",
      "acc for Lsat= 0.16698268911100878 \n",
      "acc for Psat= 0.19611059147597398 \n",
      "acc for optim= 0.1787916940739989\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.005622723139822483\n",
      "Loss on test= 0.007796343881636858\n",
      "acc for Lsat= 0.1608116498018508 \n",
      "acc for Psat= 0.19619434970630462 \n",
      "acc for optim= 0.1801947502998805\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.005614520516246557\n",
      "Loss on test= 0.007601444609463215\n",
      "acc for Lsat= 0.1574027562116394 \n",
      "acc for Psat= 0.1801515140526806 \n",
      "acc for optim= 0.18165876743971507\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.00565800815820694\n",
      "Loss on test= 0.007620017975568771\n",
      "acc for Lsat= 0.15832331594762958 \n",
      "acc for Psat= 0.19441373345602425 \n",
      "acc for optim= 0.1760187159800047\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.005531651433557272\n",
      "Loss on test= 0.007678232155740261\n",
      "acc for Lsat= 0.15544327624060106 \n",
      "acc for Psat= 0.19169010848492063 \n",
      "acc for optim= 0.1789306031084633\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.005520475562661886\n",
      "Loss on test= 0.008174126036465168\n",
      "acc for Lsat= 0.15712077241118036 \n",
      "acc for Psat= 0.18117078887527716 \n",
      "acc for optim= 0.18265771369812878\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.005732142366468906\n",
      "Loss on test= 0.00809345580637455\n",
      "acc for Lsat= 0.15295468665254836 \n",
      "acc for Psat= 0.18163153355875336 \n",
      "acc for optim= 0.18019793017409655\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.0054671200923621655\n",
      "Loss on test= 0.007490290328860283\n",
      "acc for Lsat= 0.16399544168332378 \n",
      "acc for Psat= 0.20090353402889288 \n",
      "acc for optim= 0.1821795996813844\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.005479134619235992\n",
      "Loss on test= 0.007735746446996927\n",
      "acc for Lsat= 0.15564116907561748 \n",
      "acc for Psat= 0.18524410194239282 \n",
      "acc for optim= 0.1766420712362456\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.0053776646964251995\n",
      "Loss on test= 0.007500173058360815\n",
      "acc for Lsat= 0.15502003934158043 \n",
      "acc for Psat= 0.17919856157214914 \n",
      "acc for optim= 0.18331853966610354\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.005617677234113216\n",
      "Loss on test= 0.007686908822506666\n",
      "acc for Lsat= 0.15587913972606166 \n",
      "acc for Psat= 0.18644862866494805 \n",
      "acc for optim= 0.17874710483416403\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.0054930029436945915\n",
      "Loss on test= 0.0083510996773839\n",
      "acc for Lsat= 0.14968331241445829 \n",
      "acc for Psat= 0.18958579169655004 \n",
      "acc for optim= 0.18069809250625185\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.005346321500837803\n",
      "Loss on test= 0.00764036551117897\n",
      "acc for Lsat= 0.1677111555916662 \n",
      "acc for Psat= 0.19647220725682182 \n",
      "acc for optim= 0.18051666539547903\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.00525649031624198\n",
      "Loss on test= 0.007394520100206137\n",
      "acc for Lsat= 0.1494610320541962 \n",
      "acc for Psat= 0.19285768703366707 \n",
      "acc for optim= 0.17116472591373108\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.005634418688714504\n",
      "Loss on test= 0.007960072718560696\n",
      "acc for Lsat= 0.14600125160127914 \n",
      "acc for Psat= 0.17355594761692536 \n",
      "acc for optim= 0.17994850648597616\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.00538795767351985\n",
      "Loss on test= 0.007528974208980799\n",
      "acc for Lsat= 0.15098861670908786 \n",
      "acc for Psat= 0.20103122932487166 \n",
      "acc for optim= 0.17852286162774736\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.005273566581308842\n",
      "Loss on test= 0.007899475283920765\n",
      "acc for Lsat= 0.1523197490313533 \n",
      "acc for Psat= 0.18808245067561014 \n",
      "acc for optim= 0.18840823324786307\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.005703787785023451\n",
      "Loss on test= 0.007602209225296974\n",
      "acc for Lsat= 0.15425126079821075 \n",
      "acc for Psat= 0.1815128429143949 \n",
      "acc for optim= 0.18867075265510214\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.005466940812766552\n",
      "Loss on test= 0.00754015427082777\n",
      "acc for Lsat= 0.1640747201564096 \n",
      "acc for Psat= 0.1905709767252442 \n",
      "acc for optim= 0.1737395814652402\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.005651493091136217\n",
      "Loss on test= 0.008054619655013084\n",
      "acc for Lsat= 0.1568470333009857 \n",
      "acc for Psat= 0.18835796969134044 \n",
      "acc for optim= 0.17778205056865623\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.0053058648481965065\n",
      "Loss on test= 0.007600370794534683\n",
      "acc for Lsat= 0.156343374352093 \n",
      "acc for Psat= 0.17967269027912913 \n",
      "acc for optim= 0.17871047976387658\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.005387881305068731\n",
      "Loss on test= 0.007581409066915512\n",
      "acc for Lsat= 0.149941321285098 \n",
      "acc for Psat= 0.17905452755455417 \n",
      "acc for optim= 0.18319766911998636\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.005599752068519592\n",
      "Loss on test= 0.007853640243411064\n",
      "acc for Lsat= 0.15106476399642949 \n",
      "acc for Psat= 0.18647204003283432 \n",
      "acc for optim= 0.17658885565651275\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.005303190089762211\n",
      "Loss on test= 0.00749027356505394\n",
      "acc for Lsat= 0.16222974914488703 \n",
      "acc for Psat= 0.1796462996229224 \n",
      "acc for optim= 0.17567256749989313\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.0055070980452001095\n",
      "Loss on test= 0.007686772849410772\n",
      "acc for Lsat= 0.15820198569496421 \n",
      "acc for Psat= 0.19582734772340074 \n",
      "acc for optim= 0.17362192486008232\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.005352911539375782\n",
      "Loss on test= 0.007916625589132309\n",
      "acc for Lsat= 0.1518922022459876 \n",
      "acc for Psat= 0.19251021493501105 \n",
      "acc for optim= 0.18248703051587475\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.005454702768474817\n",
      "Loss on test= 0.007476472761482\n",
      "acc for Lsat= 0.15714044509232272 \n",
      "acc for Psat= 0.19221950094673598 \n",
      "acc for optim= 0.18357234211050769\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.005568442400544882\n",
      "Loss on test= 0.007858969271183014\n",
      "acc for Lsat= 0.15860264310498767 \n",
      "acc for Psat= 0.18823195494545364 \n",
      "acc for optim= 0.17982412863018937\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.005551322363317013\n",
      "Loss on test= 0.00759111950173974\n",
      "acc for Lsat= 0.15678185345480966 \n",
      "acc for Psat= 0.17905444735851994 \n",
      "acc for optim= 0.18040903293084903\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.005330768413841724\n",
      "Loss on test= 0.00811762735247612\n",
      "acc for Lsat= 0.14925417036245592 \n",
      "acc for Psat= 0.16122600770804488 \n",
      "acc for optim= 0.1752396084808126\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.005516677629202604\n",
      "Loss on test= 0.008229442872107029\n",
      "acc for Lsat= 0.1529216784368399 \n",
      "acc for Psat= 0.18555721280729917 \n",
      "acc for optim= 0.17520410846804316\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.005121148191392422\n",
      "Loss on test= 0.0077161337248981\n",
      "acc for Lsat= 0.15430218868766774 \n",
      "acc for Psat= 0.19230560322051685 \n",
      "acc for optim= 0.17706647606587542\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.005421600304543972\n",
      "Loss on test= 0.007313532754778862\n",
      "acc for Lsat= 0.1564971943794784 \n",
      "acc for Psat= 0.1897074740296077 \n",
      "acc for optim= 0.17890543171708456\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.005271932575851679\n",
      "Loss on test= 0.007984667085111141\n",
      "acc for Lsat= 0.15825996520493912 \n",
      "acc for Psat= 0.18093124637685595 \n",
      "acc for optim= 0.18143608462586464\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.005219312384724617\n",
      "Loss on test= 0.0077764056622982025\n",
      "acc for Lsat= 0.14848627604135756 \n",
      "acc for Psat= 0.18042524663710463 \n",
      "acc for optim= 0.1792833259771244\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.005641832482069731\n",
      "Loss on test= 0.007397618610411882\n",
      "acc for Lsat= 0.15647249605705138 \n",
      "acc for Psat= 0.189285315300546 \n",
      "acc for optim= 0.18543789967642638\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.005352338310331106\n",
      "Loss on test= 0.007920137606561184\n",
      "acc for Lsat= 0.16026435031662467 \n",
      "acc for Psat= 0.20036780637112583 \n",
      "acc for optim= 0.18362738316736496\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.00533004105091095\n",
      "Loss on test= 0.008079005405306816\n",
      "acc for Lsat= 0.1633286118089435 \n",
      "acc for Psat= 0.18703317946237208 \n",
      "acc for optim= 0.18147775909575237\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.005708097480237484\n",
      "Loss on test= 0.007404880132526159\n",
      "acc for Lsat= 0.16098240745963804 \n",
      "acc for Psat= 0.21825658208003543 \n",
      "acc for optim= 0.18693012827854666\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.00579111510887742\n",
      "Loss on test= 0.008141517639160156\n",
      "acc for Lsat= 0.14768187180829434 \n",
      "acc for Psat= 0.20528761312541108 \n",
      "acc for optim= 0.1776724646884908\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.0053909821435809135\n",
      "Loss on test= 0.007837186567485332\n",
      "acc for Lsat= 0.14684018762209683 \n",
      "acc for Psat= 0.17650225827752872 \n",
      "acc for optim= 0.1704156678205749\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.005421313922852278\n",
      "Loss on test= 0.007441801484674215\n",
      "acc for Lsat= 0.16755693162501348 \n",
      "acc for Psat= 0.18689813680334216 \n",
      "acc for optim= 0.18463530234084083\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.005338975228369236\n",
      "Loss on test= 0.00794315431267023\n",
      "acc for Lsat= 0.1499229826695347 \n",
      "acc for Psat= 0.18568780662102594 \n",
      "acc for optim= 0.18189443858055546\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.005401461385190487\n",
      "Loss on test= 0.007781516760587692\n",
      "acc for Lsat= 0.15599618834905235 \n",
      "acc for Psat= 0.18561997213744422 \n",
      "acc for optim= 0.17657645410422967\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.005543203558772802\n",
      "Loss on test= 0.007868289016187191\n",
      "acc for Lsat= 0.15300946543336708 \n",
      "acc for Psat= 0.18269778727973643 \n",
      "acc for optim= 0.17284809267186543\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.005215649958699942\n",
      "Loss on test= 0.007779540494084358\n",
      "acc for Lsat= 0.15383159902383817 \n",
      "acc for Psat= 0.18585738023269738 \n",
      "acc for optim= 0.1822623752447353\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.005311747081577778\n",
      "Loss on test= 0.00793205015361309\n",
      "acc for Lsat= 0.15956769414150898 \n",
      "acc for Psat= 0.18618733473236626 \n",
      "acc for optim= 0.1793017092414704\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.005729328840970993\n",
      "Loss on test= 0.0077954987064003944\n",
      "acc for Lsat= 0.14409899716752153 \n",
      "acc for Psat= 0.17136364865169734 \n",
      "acc for optim= 0.17613775959251768\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.0052107395604252815\n",
      "Loss on test= 0.008014513179659843\n",
      "acc for Lsat= 0.15912090641747947 \n",
      "acc for Psat= 0.1715991286735516 \n",
      "acc for optim= 0.17894751513601076\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.005422166548669338\n",
      "Loss on test= 0.007885725237429142\n",
      "acc for Lsat= 0.15823360557923644 \n",
      "acc for Psat= 0.19207808699031345 \n",
      "acc for optim= 0.18009929560414958\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.005567322019487619\n",
      "Loss on test= 0.007813992910087109\n",
      "acc for Lsat= 0.15826579633313917 \n",
      "acc for Psat= 0.19806682239498916 \n",
      "acc for optim= 0.17466639757469357\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.005348095204681158\n",
      "Loss on test= 0.007308316417038441\n",
      "acc for Lsat= 0.16087300061094612 \n",
      "acc for Psat= 0.1920922296469054 \n",
      "acc for optim= 0.17756068056323338\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.005443849600851536\n",
      "Loss on test= 0.007701088208705187\n",
      "acc for Lsat= 0.1619372284824227 \n",
      "acc for Psat= 0.19562476077269703 \n",
      "acc for optim= 0.1759671934594049\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.00556194968521595\n",
      "Loss on test= 0.007574667688459158\n",
      "acc for Lsat= 0.15048102173838787 \n",
      "acc for Psat= 0.19224795729797867 \n",
      "acc for optim= 0.17688889097618932\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.005643879063427448\n",
      "Loss on test= 0.007247079163789749\n",
      "acc for Lsat= 0.1550872541922068 \n",
      "acc for Psat= 0.19103993615665144 \n",
      "acc for optim= 0.17794121491043355\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.0053112138994038105\n",
      "Loss on test= 0.007953268475830555\n",
      "acc for Lsat= 0.16756954749084277 \n",
      "acc for Psat= 0.18056907498231922 \n",
      "acc for optim= 0.17743568986761155\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.005489762406796217\n",
      "Loss on test= 0.008181730285286903\n",
      "acc for Lsat= 0.14755788043190984 \n",
      "acc for Psat= 0.17201762612542656 \n",
      "acc for optim= 0.18747888278200855\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.005149200093001127\n",
      "Loss on test= 0.007738830056041479\n",
      "acc for Lsat= 0.1491930198135259 \n",
      "acc for Psat= 0.17761028117317035 \n",
      "acc for optim= 0.17952555590605013\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.005304574966430664\n",
      "Loss on test= 0.007864514365792274\n",
      "acc for Lsat= 0.15230807760028076 \n",
      "acc for Psat= 0.19077309662415112 \n",
      "acc for optim= 0.17795410115103863\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.005269929300993681\n",
      "Loss on test= 0.007968243211507797\n",
      "acc for Lsat= 0.1452097190990586 \n",
      "acc for Psat= 0.18450689710458154 \n",
      "acc for optim= 0.17778089184178753\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.005228972062468529\n",
      "Loss on test= 0.007595862727612257\n",
      "acc for Lsat= 0.1581711093923764 \n",
      "acc for Psat= 0.18803003658607342 \n",
      "acc for optim= 0.18256886925807864\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.005320271477103233\n",
      "Loss on test= 0.0075077167712152\n",
      "acc for Lsat= 0.1452553762142073 \n",
      "acc for Psat= 0.19100001276495532 \n",
      "acc for optim= 0.17819463293092921\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.005238763522356749\n",
      "Loss on test= 0.0077841319143772125\n",
      "acc for Lsat= 0.1501525882085724 \n",
      "acc for Psat= 0.17949247093390308 \n",
      "acc for optim= 0.18072401641192465\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.0054557607509195805\n",
      "Loss on test= 0.008195222355425358\n",
      "acc for Lsat= 0.1570622754198562 \n",
      "acc for Psat= 0.19672985169406768 \n",
      "acc for optim= 0.1794955721628837\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.005448896903544664\n",
      "Loss on test= 0.007906167767941952\n",
      "acc for Lsat= 0.15761725750096242 \n",
      "acc for Psat= 0.18296115495728282 \n",
      "acc for optim= 0.18051393965448131\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.005348579026758671\n",
      "Loss on test= 0.007837750017642975\n",
      "acc for Lsat= 0.1535298598697409 \n",
      "acc for Psat= 0.17717168206505507 \n",
      "acc for optim= 0.17887695025002306\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.005417635664343834\n",
      "Loss on test= 0.007650273852050304\n",
      "acc for Lsat= 0.15723667981109743 \n",
      "acc for Psat= 0.2002165397835254 \n",
      "acc for optim= 0.17967753458155516\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.005784234497696161\n",
      "Loss on test= 0.007251047529280186\n",
      "acc for Lsat= 0.1696099565213653 \n",
      "acc for Psat= 0.19881020300281158 \n",
      "acc for optim= 0.17963151285409562\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.005457189865410328\n",
      "Loss on test= 0.007679843809455633\n",
      "acc for Lsat= 0.14479429417549342 \n",
      "acc for Psat= 0.17155177642240144 \n",
      "acc for optim= 0.18183636634618228\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.0052597252652049065\n",
      "Loss on test= 0.007706492207944393\n",
      "acc for Lsat= 0.15856607091731437 \n",
      "acc for Psat= 0.1938046417046638 \n",
      "acc for optim= 0.17973779774820584\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.00533207505941391\n",
      "Loss on test= 0.008122928440570831\n",
      "acc for Lsat= 0.14704699685475522 \n",
      "acc for Psat= 0.19487583720891977 \n",
      "acc for optim= 0.16936629843367568\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.005524909123778343\n",
      "Loss on test= 0.007569416891783476\n",
      "acc for Lsat= 0.16138702762412427 \n",
      "acc for Psat= 0.17838916545123107 \n",
      "acc for optim= 0.17825475463120755\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.005180631298571825\n",
      "Loss on test= 0.007661763112992048\n",
      "acc for Lsat= 0.15689526161438497 \n",
      "acc for Psat= 0.1862211016907555 \n",
      "acc for optim= 0.1846053489970373\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.0057904161512851715\n",
      "Loss on test= 0.007476447150111198\n",
      "acc for Lsat= 0.16388422594606306 \n",
      "acc for Psat= 0.18900175457209592 \n",
      "acc for optim= 0.1872161678206958\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.00591477332636714\n",
      "Loss on test= 0.007594881113618612\n",
      "acc for Lsat= 0.14204489546827972 \n",
      "acc for Psat= 0.1743416736696343 \n",
      "acc for optim= 0.1867060766250733\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.0055476282723248005\n",
      "Loss on test= 0.007779065985232592\n",
      "acc for Lsat= 0.1468868683176268 \n",
      "acc for Psat= 0.18574879354688523 \n",
      "acc for optim= 0.17948741628735929\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.005591472145169973\n",
      "Loss on test= 0.008286225609481335\n",
      "acc for Lsat= 0.15463361856680302 \n",
      "acc for Psat= 0.18423138169226327 \n",
      "acc for optim= 0.17994529336813042\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.005412315018475056\n",
      "Loss on test= 0.007663088385015726\n",
      "acc for Lsat= 0.15066503931493422 \n",
      "acc for Psat= 0.18230351060523928 \n",
      "acc for optim= 0.17791085876018709\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.0052789910696446896\n",
      "Loss on test= 0.007681299466639757\n",
      "acc for Lsat= 0.14737604916378183 \n",
      "acc for Psat= 0.1800972932770268 \n",
      "acc for optim= 0.17899016883962818\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.0053648329339921474\n",
      "Loss on test= 0.007898174226284027\n",
      "acc for Lsat= 0.15961971024316582 \n",
      "acc for Psat= 0.19624213497020823 \n",
      "acc for optim= 0.18014432314699125\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.005220431834459305\n",
      "Loss on test= 0.007897494360804558\n",
      "acc for Lsat= 0.16858040622519482 \n",
      "acc for Psat= 0.17749037908177373 \n",
      "acc for optim= 0.16868030842909873\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.005635113455355167\n",
      "Loss on test= 0.007620425429195166\n",
      "acc for Lsat= 0.1394155794374843 \n",
      "acc for Psat= 0.18019591075693617 \n",
      "acc for optim= 0.1777230841416835\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.0053582265973091125\n",
      "Loss on test= 0.007733648177236319\n",
      "acc for Lsat= 0.16612919810701346 \n",
      "acc for Psat= 0.18077201045645003 \n",
      "acc for optim= 0.1791169142106273\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.005492841359227896\n",
      "Loss on test= 0.00788647960871458\n",
      "acc for Lsat= 0.16093288547756365 \n",
      "acc for Psat= 0.17705668609161845 \n",
      "acc for optim= 0.18656499517077701\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.0051359133794903755\n",
      "Loss on test= 0.007661547977477312\n",
      "acc for Lsat= 0.1644532223216823 \n",
      "acc for Psat= 0.18867427091854702 \n",
      "acc for optim= 0.16929064128418134\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.00524542573839426\n",
      "Loss on test= 0.007744767237454653\n",
      "acc for Lsat= 0.14335781068571646 \n",
      "acc for Psat= 0.17026671213326883 \n",
      "acc for optim= 0.1732969517464612\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.005234034266322851\n",
      "Loss on test= 0.008014487102627754\n",
      "acc for Lsat= 0.14641508642929038 \n",
      "acc for Psat= 0.19119012080529918 \n",
      "acc for optim= 0.17745964122329244\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.005330126266926527\n",
      "Loss on test= 0.008030670695006847\n",
      "acc for Lsat= 0.1636226375835383 \n",
      "acc for Psat= 0.18814360210290332 \n",
      "acc for optim= 0.18373356593055193\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.005392453167587519\n",
      "Loss on test= 0.007790765725076199\n",
      "acc for Lsat= 0.1557591285080874 \n",
      "acc for Psat= 0.1846883244209419 \n",
      "acc for optim= 0.18741951374390514\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.005336982663720846\n",
      "Loss on test= 0.007945691235363483\n",
      "acc for Lsat= 0.15547058804430158 \n",
      "acc for Psat= 0.18245508644255604 \n",
      "acc for optim= 0.1847644370350773\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.005282321013510227\n",
      "Loss on test= 0.007684539537876844\n",
      "acc for Lsat= 0.15393788303476644 \n",
      "acc for Psat= 0.18593568576454017 \n",
      "acc for optim= 0.18213016638364338\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.005523772910237312\n",
      "Loss on test= 0.0073834131471812725\n",
      "acc for Lsat= 0.15490333785906008 \n",
      "acc for Psat= 0.19153192583395198 \n",
      "acc for optim= 0.17341097699006883\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.005297645460814238\n",
      "Loss on test= 0.0076699950732290745\n",
      "acc for Lsat= 0.1511348635264573 \n",
      "acc for Psat= 0.18421353169861937 \n",
      "acc for optim= 0.18696432656295536\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.005338875576853752\n",
      "Loss on test= 0.00829432625323534\n",
      "acc for Lsat= 0.1501898452371741 \n",
      "acc for Psat= 0.1765992478526686 \n",
      "acc for optim= 0.17785183946529526\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.005316126625984907\n",
      "Loss on test= 0.00800556130707264\n",
      "acc for Lsat= 0.15347425188531919 \n",
      "acc for Psat= 0.17609703942110427 \n",
      "acc for optim= 0.18574042339345487\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.005190444178879261\n",
      "Loss on test= 0.008329835720360279\n",
      "acc for Lsat= 0.16242309650921521 \n",
      "acc for Psat= 0.19793812789988596 \n",
      "acc for optim= 0.18239107864484722\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.005576638039201498\n",
      "Loss on test= 0.00784585066139698\n",
      "acc for Lsat= 0.15049679329147425 \n",
      "acc for Psat= 0.1844487397286461 \n",
      "acc for optim= 0.17990025504154428\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.005200562532991171\n",
      "Loss on test= 0.008055691607296467\n",
      "acc for Lsat= 0.152692522655516 \n",
      "acc for Psat= 0.1782684485191865 \n",
      "acc for optim= 0.17708522336415328\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.005726898554712534\n",
      "Loss on test= 0.00766360480338335\n",
      "acc for Lsat= 0.15485483454297044 \n",
      "acc for Psat= 0.1787118820206369 \n",
      "acc for optim= 0.18081343760962032\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.005298341624438763\n",
      "Loss on test= 0.0076195597648620605\n",
      "acc for Lsat= 0.15797505021480782 \n",
      "acc for Psat= 0.18193396618360747 \n",
      "acc for optim= 0.181922468743058\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.005457099061459303\n",
      "Loss on test= 0.007962148636579514\n",
      "acc for Lsat= 0.15458724615125932 \n",
      "acc for Psat= 0.1713538693035113 \n",
      "acc for optim= 0.18173410015440256\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.005099359899759293\n",
      "Loss on test= 0.007706495001912117\n",
      "acc for Lsat= 0.16127183021830593 \n",
      "acc for Psat= 0.19786689278963557 \n",
      "acc for optim= 0.187791573333928\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.005045279860496521\n",
      "Loss on test= 0.008119301870465279\n",
      "acc for Lsat= 0.15190215686586167 \n",
      "acc for Psat= 0.19638500180387428 \n",
      "acc for optim= 0.17207661984778452\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.005016536917537451\n",
      "Loss on test= 0.00796173419803381\n",
      "acc for Lsat= 0.15955574697801522 \n",
      "acc for Psat= 0.19187498926719437 \n",
      "acc for optim= 0.18055098493589225\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.0053519816137850285\n",
      "Loss on test= 0.007759133353829384\n",
      "acc for Lsat= 0.15005981654432587 \n",
      "acc for Psat= 0.18808114785504465 \n",
      "acc for optim= 0.18329847754154843\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.005761569831520319\n",
      "Loss on test= 0.007583807222545147\n",
      "acc for Lsat= 0.16540034234058112 \n",
      "acc for Psat= 0.18937552110396982 \n",
      "acc for optim= 0.1845553343336968\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.005270220339298248\n",
      "Loss on test= 0.007555649150162935\n",
      "acc for Lsat= 0.14209914860806092 \n",
      "acc for Psat= 0.19601498867946174 \n",
      "acc for optim= 0.18119004273550493\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.005662151146680117\n",
      "Loss on test= 0.007737334817647934\n",
      "acc for Lsat= 0.1578533008027646 \n",
      "acc for Psat= 0.18406034282922265 \n",
      "acc for optim= 0.17612310283145577\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.005207057110965252\n",
      "Loss on test= 0.007833505049347878\n",
      "acc for Lsat= 0.1513769401703984 \n",
      "acc for Psat= 0.19108702592421933 \n",
      "acc for optim= 0.1882474912825512\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.005296855699270964\n",
      "Loss on test= 0.007942129857838154\n",
      "acc for Lsat= 0.16294429946364453 \n",
      "acc for Psat= 0.1978280323656795 \n",
      "acc for optim= 0.1769507669497827\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.0053874957375228405\n",
      "Loss on test= 0.007946830242872238\n",
      "acc for Lsat= 0.1523959563566051 \n",
      "acc for Psat= 0.17845602533016658 \n",
      "acc for optim= 0.17339498962265665\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.0053681242279708385\n",
      "Loss on test= 0.007614401634782553\n",
      "acc for Lsat= 0.15938774968850994 \n",
      "acc for Psat= 0.18485769688802559 \n",
      "acc for optim= 0.18360576052829378\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.005317487753927708\n",
      "Loss on test= 0.00745266443118453\n",
      "acc for Lsat= 0.15563171829600803 \n",
      "acc for Psat= 0.16907068453023028 \n",
      "acc for optim= 0.1764916151738153\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.005198434926569462\n",
      "Loss on test= 0.007373950444161892\n",
      "acc for Lsat= 0.1489898922112694 \n",
      "acc for Psat= 0.1764842356917769 \n",
      "acc for optim= 0.17600463325068064\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.005226210691034794\n",
      "Loss on test= 0.007614701520651579\n",
      "acc for Lsat= 0.14265308490454326 \n",
      "acc for Psat= 0.19161564234842654 \n",
      "acc for optim= 0.18190294582092945\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.005264857783913612\n",
      "Loss on test= 0.007752999197691679\n",
      "acc for Lsat= 0.1476051732017964 \n",
      "acc for Psat= 0.19054817487981904 \n",
      "acc for optim= 0.18125387901081474\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.005321911070495844\n",
      "Loss on test= 0.007720483001321554\n",
      "acc for Lsat= 0.1511398023577266 \n",
      "acc for Psat= 0.18260395569864232 \n",
      "acc for optim= 0.17725315623559806\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.005318816285580397\n",
      "Loss on test= 0.007478232495486736\n",
      "acc for Lsat= 0.15820686120280356 \n",
      "acc for Psat= 0.1839476697847293 \n",
      "acc for optim= 0.18120118900331988\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.0053162542171776295\n",
      "Loss on test= 0.007551548071205616\n",
      "acc for Lsat= 0.1568210808972477 \n",
      "acc for Psat= 0.178922910716711 \n",
      "acc for optim= 0.18575382182817357\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.0052430760115385056\n",
      "Loss on test= 0.007954847998917103\n",
      "acc for Lsat= 0.1552060691414584 \n",
      "acc for Psat= 0.18868644072857427 \n",
      "acc for optim= 0.182508686614761\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.0053093875758349895\n",
      "Loss on test= 0.00809591356664896\n",
      "acc for Lsat= 0.14997698763866343 \n",
      "acc for Psat= 0.186452312849718 \n",
      "acc for optim= 0.17863792748952412\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.005676551256328821\n",
      "Loss on test= 0.007807275280356407\n",
      "acc for Lsat= 0.15952048285284126 \n",
      "acc for Psat= 0.18535612561743797 \n",
      "acc for optim= 0.18617158686450194\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.0053731114603579044\n",
      "Loss on test= 0.007571781519800425\n",
      "acc for Lsat= 0.15811044929155957 \n",
      "acc for Psat= 0.19203446278898198 \n",
      "acc for optim= 0.17770411461337898\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.005278949625790119\n",
      "Loss on test= 0.00780669366940856\n",
      "acc for Lsat= 0.15538541789788785 \n",
      "acc for Psat= 0.18294634787401295 \n",
      "acc for optim= 0.1789186097841832\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.005234802607446909\n",
      "Loss on test= 0.007753841113299131\n",
      "acc for Lsat= 0.14691616914876293 \n",
      "acc for Psat= 0.1828022053030121 \n",
      "acc for optim= 0.18783265160545554\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.0054630436934530735\n",
      "Loss on test= 0.007882403209805489\n",
      "acc for Lsat= 0.15084178808381873 \n",
      "acc for Psat= 0.1719676203094423 \n",
      "acc for optim= 0.18486485905433836\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.005640240851789713\n",
      "Loss on test= 0.007420772220939398\n",
      "acc for Lsat= 0.14746580883005603 \n",
      "acc for Psat= 0.18936776618061008 \n",
      "acc for optim= 0.17985807243261304\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.005273063201457262\n",
      "Loss on test= 0.008232367224991322\n",
      "acc for Lsat= 0.15735947702263223 \n",
      "acc for Psat= 0.19410007227933584 \n",
      "acc for optim= 0.18083237610322225\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.005456490907818079\n",
      "Loss on test= 0.008121978491544724\n",
      "acc for Lsat= 0.15517027345404877 \n",
      "acc for Psat= 0.18824841450230928 \n",
      "acc for optim= 0.17521324566113153\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.005354432854801416\n",
      "Loss on test= 0.00743179302662611\n",
      "acc for Lsat= 0.16573885169231378 \n",
      "acc for Psat= 0.19924573280092817 \n",
      "acc for optim= 0.17577501861044573\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.005403677001595497\n",
      "Loss on test= 0.00787373911589384\n",
      "acc for Lsat= 0.15719283970450262 \n",
      "acc for Psat= 0.1849702844598529 \n",
      "acc for optim= 0.18187762985547973\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.005459405481815338\n",
      "Loss on test= 0.00776767497882247\n",
      "acc for Lsat= 0.16279722294106042 \n",
      "acc for Psat= 0.19264291878503395 \n",
      "acc for optim= 0.18786290897606092\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.005236937664449215\n",
      "Loss on test= 0.008026598021388054\n",
      "acc for Lsat= 0.14980725655103194 \n",
      "acc for Psat= 0.16700074060158765 \n",
      "acc for optim= 0.17016699149027145\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.005132053978741169\n",
      "Loss on test= 0.00795010756701231\n",
      "acc for Lsat= 0.1426188494513941 \n",
      "acc for Psat= 0.18073263710057438 \n",
      "acc for optim= 0.18143173003722876\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.005338058806955814\n",
      "Loss on test= 0.007627259939908981\n",
      "acc for Lsat= 0.14965334484681914 \n",
      "acc for Psat= 0.1970170266620937 \n",
      "acc for optim= 0.1801327273215274\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.0051170168444514275\n",
      "Loss on test= 0.00796165969222784\n",
      "acc for Lsat= 0.15787335039559203 \n",
      "acc for Psat= 0.18897301525714402 \n",
      "acc for optim= 0.18166283222944019\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.005151553079485893\n",
      "Loss on test= 0.007702616509050131\n",
      "acc for Lsat= 0.15714175290390886 \n",
      "acc for Psat= 0.18967372062377494 \n",
      "acc for optim= 0.17458813506747276\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.005315769463777542\n",
      "Loss on test= 0.00795002095401287\n",
      "acc for Lsat= 0.15305143295334972 \n",
      "acc for Psat= 0.1811299517540811 \n",
      "acc for optim= 0.18435840385252245\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.00527446623891592\n",
      "Loss on test= 0.00796471443027258\n",
      "acc for Lsat= 0.152455634810603 \n",
      "acc for Psat= 0.18274041502836702 \n",
      "acc for optim= 0.17902540813055134\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.005257385782897472\n",
      "Loss on test= 0.0075799995101988316\n",
      "acc for Lsat= 0.14632695573954613 \n",
      "acc for Psat= 0.1849995332724247 \n",
      "acc for optim= 0.1763363136906085\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.00542869046330452\n",
      "Loss on test= 0.00781978014856577\n",
      "acc for Lsat= 0.1594046665718884 \n",
      "acc for Psat= 0.18858041971555498 \n",
      "acc for optim= 0.17977904442919143\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.005236255936324596\n",
      "Loss on test= 0.007486777845770121\n",
      "acc for Lsat= 0.15224799358946287 \n",
      "acc for Psat= 0.1752995989224339 \n",
      "acc for optim= 0.17853100814219167\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.0053451769053936005\n",
      "Loss on test= 0.007494485471397638\n",
      "acc for Lsat= 0.15433645357499967 \n",
      "acc for Psat= 0.20176135661007957 \n",
      "acc for optim= 0.1818029640450478\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.005094332620501518\n",
      "Loss on test= 0.00817163661122322\n",
      "acc for Lsat= 0.15082814786506848 \n",
      "acc for Psat= 0.17725909697884296 \n",
      "acc for optim= 0.18523776072504947\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.005200659856200218\n",
      "Loss on test= 0.007518450729548931\n",
      "acc for Lsat= 0.1534030488692224 \n",
      "acc for Psat= 0.1914204387801516 \n",
      "acc for optim= 0.18052138667482096\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.005418469198048115\n",
      "Loss on test= 0.007853643968701363\n",
      "acc for Lsat= 0.15939257109373595 \n",
      "acc for Psat= 0.17643452422983455 \n",
      "acc for optim= 0.17852023856701962\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.005288322921842337\n",
      "Loss on test= 0.007777967490255833\n",
      "acc for Lsat= 0.15111888416844313 \n",
      "acc for Psat= 0.19640823301523314 \n",
      "acc for optim= 0.18048267691571754\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.005636011250317097\n",
      "Loss on test= 0.0076408083550632\n",
      "acc for Lsat= 0.14869554330476514 \n",
      "acc for Psat= 0.17797507710323562 \n",
      "acc for optim= 0.17912099691581165\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.005182018503546715\n",
      "Loss on test= 0.008030152879655361\n",
      "acc for Lsat= 0.150069253911936 \n",
      "acc for Psat= 0.1872451399098013 \n",
      "acc for optim= 0.18429829682515492\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.005213229916989803\n",
      "Loss on test= 0.0076758237555623055\n",
      "acc for Lsat= 0.1668244432333521 \n",
      "acc for Psat= 0.19382856857006775 \n",
      "acc for optim= 0.1809806049492718\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.005376716144382954\n",
      "Loss on test= 0.007800916209816933\n",
      "acc for Lsat= 0.15006409715193125 \n",
      "acc for Psat= 0.20055674143593813 \n",
      "acc for optim= 0.1857432610190237\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.0052450476214289665\n",
      "Loss on test= 0.0078804362565279\n",
      "acc for Lsat= 0.14130710344952455 \n",
      "acc for Psat= 0.19302922657759647 \n",
      "acc for optim= 0.1819030477495513\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.005120894871652126\n",
      "Loss on test= 0.0075096022337675095\n",
      "acc for Lsat= 0.14891978212370782 \n",
      "acc for Psat= 0.17849551546959908 \n",
      "acc for optim= 0.18440174834627884\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.005704630631953478\n",
      "Loss on test= 0.007244762033224106\n",
      "acc for Lsat= 0.16674428432106353 \n",
      "acc for Psat= 0.17628352782406584 \n",
      "acc for optim= 0.1803800785528557\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.005580344703048468\n",
      "Loss on test= 0.008137802593410015\n",
      "acc for Lsat= 0.15303038831763963 \n",
      "acc for Psat= 0.18437932098559182 \n",
      "acc for optim= 0.18311494926494531\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.005519864149391651\n",
      "Loss on test= 0.008133476600050926\n",
      "acc for Lsat= 0.15499827700693802 \n",
      "acc for Psat= 0.18102152022136161 \n",
      "acc for optim= 0.1822906387840077\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.005926967598497868\n",
      "Loss on test= 0.007545138243585825\n",
      "acc for Lsat= 0.15648250462054122 \n",
      "acc for Psat= 0.1807761842720821 \n",
      "acc for optim= 0.17687563889995828\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.005111529491841793\n",
      "Loss on test= 0.0071882265619933605\n",
      "acc for Lsat= 0.15446060276552118 \n",
      "acc for Psat= 0.1944927929553249 \n",
      "acc for optim= 0.18471169550197017\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.0052123647183179855\n",
      "Loss on test= 0.007842038758099079\n",
      "acc for Lsat= 0.14104966646276001 \n",
      "acc for Psat= 0.18935641045214563 \n",
      "acc for optim= 0.18312655404433378\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.005416185595095158\n",
      "Loss on test= 0.007775561418384314\n",
      "acc for Lsat= 0.15068200103018708 \n",
      "acc for Psat= 0.1765005367544678 \n",
      "acc for optim= 0.17861323785742927\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.005151291377842426\n",
      "Loss on test= 0.007536428514868021\n",
      "acc for Lsat= 0.15009599206892804 \n",
      "acc for Psat= 0.1858003851950701 \n",
      "acc for optim= 0.17836379119467952\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.005224722437560558\n",
      "Loss on test= 0.007950527593493462\n",
      "acc for Lsat= 0.1526045272575279 \n",
      "acc for Psat= 0.17606201245598344 \n",
      "acc for optim= 0.181640028355063\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.005288047716021538\n",
      "Loss on test= 0.007787769194692373\n",
      "acc for Lsat= 0.16177911632656136 \n",
      "acc for Psat= 0.18200036795088473 \n",
      "acc for optim= 0.17903079875352693\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.0051965974271297455\n",
      "Loss on test= 0.007827063091099262\n",
      "acc for Lsat= 0.15972190281923968 \n",
      "acc for Psat= 0.19152839168806973 \n",
      "acc for optim= 0.17845519557230263\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.005106791388243437\n",
      "Loss on test= 0.007272896822541952\n",
      "acc for Lsat= 0.16001544224602154 \n",
      "acc for Psat= 0.1807639863367811 \n",
      "acc for optim= 0.17677880633597598\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.0053719934076070786\n",
      "Loss on test= 0.007529027294367552\n",
      "acc for Lsat= 0.14617656500853568 \n",
      "acc for Psat= 0.1797652147193134 \n",
      "acc for optim= 0.17719080486548605\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.005271261557936668\n",
      "Loss on test= 0.007402225397527218\n",
      "acc for Lsat= 0.15492031165058953 \n",
      "acc for Psat= 0.20479210139572865 \n",
      "acc for optim= 0.17450437090642557\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.005426641087979078\n",
      "Loss on test= 0.007663927506655455\n",
      "acc for Lsat= 0.16094247877748577 \n",
      "acc for Psat= 0.17854216628543104 \n",
      "acc for optim= 0.18066162326388427\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.005379946436733007\n",
      "Loss on test= 0.008006599731743336\n",
      "acc for Lsat= 0.1497703916650861 \n",
      "acc for Psat= 0.19121617528888565 \n",
      "acc for optim= 0.1843278308502078\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.0055358028039336205\n",
      "Loss on test= 0.00784043688327074\n",
      "acc for Lsat= 0.13451067986211082 \n",
      "acc for Psat= 0.18235560548987972 \n",
      "acc for optim= 0.17866188946178138\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.005462641827762127\n",
      "Loss on test= 0.007559789810329676\n",
      "acc for Lsat= 0.15375493625865974 \n",
      "acc for Psat= 0.18332955840303272 \n",
      "acc for optim= 0.18203571277430097\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.005210887640714645\n",
      "Loss on test= 0.007854662835597992\n",
      "acc for Lsat= 0.16197396503344177 \n",
      "acc for Psat= 0.19438826910804072 \n",
      "acc for optim= 0.18591409177089027\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.005187627859413624\n",
      "Loss on test= 0.007772465236485004\n",
      "acc for Lsat= 0.15618647800989402 \n",
      "acc for Psat= 0.1900592148454753 \n",
      "acc for optim= 0.18265143279711427\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.005234592128545046\n",
      "Loss on test= 0.007452775724232197\n",
      "acc for Lsat= 0.15317928066205702 \n",
      "acc for Psat= 0.1718351819712791 \n",
      "acc for optim= 0.18413016681796032\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.005125612486153841\n",
      "Loss on test= 0.007764420006424189\n",
      "acc for Lsat= 0.15716809014461508 \n",
      "acc for Psat= 0.19272262566726747 \n",
      "acc for optim= 0.18005188877835535\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.005393945146352053\n",
      "Loss on test= 0.007737917825579643\n",
      "acc for Lsat= 0.1543311333837232 \n",
      "acc for Psat= 0.17668061805392815 \n",
      "acc for optim= 0.17815088320973893\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.0051822541281580925\n",
      "Loss on test= 0.007798982784152031\n",
      "acc for Lsat= 0.1517663941530656 \n",
      "acc for Psat= 0.18756217366312516 \n",
      "acc for optim= 0.17578760227646495\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.005259388592094183\n",
      "Loss on test= 0.007561332546174526\n",
      "acc for Lsat= 0.14525541258521654 \n",
      "acc for Psat= 0.18640697905116288 \n",
      "acc for optim= 0.17975542802283956\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.005247548688203096\n",
      "Loss on test= 0.007916021160781384\n",
      "acc for Lsat= 0.14965176366013858 \n",
      "acc for Psat= 0.18227906507138378 \n",
      "acc for optim= 0.1806763579259764\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.0051809498108923435\n",
      "Loss on test= 0.007099779322743416\n",
      "acc for Lsat= 0.15046162207107075 \n",
      "acc for Psat= 0.176819916981364 \n",
      "acc for optim= 0.17906516665529812\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.005599903874099255\n",
      "Loss on test= 0.007587302941828966\n",
      "acc for Lsat= 0.15205606488266685 \n",
      "acc for Psat= 0.1890192298104101 \n",
      "acc for optim= 0.1839799071039974\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.005528702866286039\n",
      "Loss on test= 0.008054112084209919\n",
      "acc for Lsat= 0.15132563479347766 \n",
      "acc for Psat= 0.17202697119362592 \n",
      "acc for optim= 0.17468713535125688\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.005123875103890896\n",
      "Loss on test= 0.007674772292375565\n",
      "acc for Lsat= 0.14201004741733445 \n",
      "acc for Psat= 0.1774975893164023 \n",
      "acc for optim= 0.18008756944757015\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.005528545472770929\n",
      "Loss on test= 0.007386487443000078\n",
      "acc for Lsat= 0.1568557076407935 \n",
      "acc for Psat= 0.18702330701740183 \n",
      "acc for optim= 0.18580907342085218\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.005271489266306162\n",
      "Loss on test= 0.007797484286129475\n",
      "acc for Lsat= 0.14939203156582004 \n",
      "acc for Psat= 0.1873261524081902 \n",
      "acc for optim= 0.18339160929288958\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.00501616857945919\n",
      "Loss on test= 0.007751214783638716\n",
      "acc for Lsat= 0.15245036072909762 \n",
      "acc for Psat= 0.18527048375594934 \n",
      "acc for optim= 0.18052858221630916\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.0058054132387042046\n",
      "Loss on test= 0.007470260839909315\n",
      "acc for Lsat= 0.14878736323233946 \n",
      "acc for Psat= 0.1816464813728149 \n",
      "acc for optim= 0.18014608367415885\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.005172074772417545\n",
      "Loss on test= 0.007674689404666424\n",
      "acc for Lsat= 0.1694791991455427 \n",
      "acc for Psat= 0.18043046891765638 \n",
      "acc for optim= 0.1780780294163393\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.005274386145174503\n",
      "Loss on test= 0.007550779730081558\n",
      "acc for Lsat= 0.1487909998011882 \n",
      "acc for Psat= 0.16989810533104005 \n",
      "acc for optim= 0.18250574777284484\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.0051264893263578415\n",
      "Loss on test= 0.007716877851635218\n",
      "acc for Lsat= 0.15963055661184805 \n",
      "acc for Psat= 0.19875834050767704 \n",
      "acc for optim= 0.1779411468731209\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.005342339165508747\n",
      "Loss on test= 0.007946358062326908\n",
      "acc for Lsat= 0.14949830827478808 \n",
      "acc for Psat= 0.18080428854426842 \n",
      "acc for optim= 0.1805562150244769\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.0055829910561442375\n",
      "Loss on test= 0.007690817583352327\n",
      "acc for Lsat= 0.16258069073063794 \n",
      "acc for Psat= 0.19121814449069655 \n",
      "acc for optim= 0.18525698342671634\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.005444884300231934\n",
      "Loss on test= 0.007912453263998032\n",
      "acc for Lsat= 0.15771957340757134 \n",
      "acc for Psat= 0.17872919238508359 \n",
      "acc for optim= 0.17846472569451224\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.005203257314860821\n",
      "Loss on test= 0.00846725795418024\n",
      "acc for Lsat= 0.17383520297029106 \n",
      "acc for Psat= 0.17958575311063438 \n",
      "acc for optim= 0.17694620188477364\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.005048164166510105\n",
      "Loss on test= 0.008089224807918072\n",
      "acc for Lsat= 0.1651975966578783 \n",
      "acc for Psat= 0.179778537151669 \n",
      "acc for optim= 0.17625717075186645\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.0052744620479643345\n",
      "Loss on test= 0.007687795907258987\n",
      "acc for Lsat= 0.15693999984860801 \n",
      "acc for Psat= 0.18286558671045255 \n",
      "acc for optim= 0.18459862805673943\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.005143762566149235\n",
      "Loss on test= 0.0074968961998820305\n",
      "acc for Lsat= 0.15754308633708594 \n",
      "acc for Psat= 0.17525907277442576 \n",
      "acc for optim= 0.18149389411250252\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.005238188896328211\n",
      "Loss on test= 0.0072563705034554005\n",
      "acc for Lsat= 0.15739851677799827 \n",
      "acc for Psat= 0.1928989964411365 \n",
      "acc for optim= 0.1805269204357784\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.005165428854525089\n",
      "Loss on test= 0.0077454145066440105\n",
      "acc for Lsat= 0.1652202440218687 \n",
      "acc for Psat= 0.19621465645165595 \n",
      "acc for optim= 0.18303219131155887\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.005127228330820799\n",
      "Loss on test= 0.00788588635623455\n",
      "acc for Lsat= 0.1650770278702887 \n",
      "acc for Psat= 0.18373789790371345 \n",
      "acc for optim= 0.17969672133536346\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.005314874462783337\n",
      "Loss on test= 0.007642291020601988\n",
      "acc for Lsat= 0.15250850934843002 \n",
      "acc for Psat= 0.17275089707815272 \n",
      "acc for optim= 0.18163605516473\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.005036645568907261\n",
      "Loss on test= 0.007483136840164661\n",
      "acc for Lsat= 0.1436830784883121 \n",
      "acc for Psat= 0.1758143657889049 \n",
      "acc for optim= 0.18098544303955677\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.005243553780019283\n",
      "Loss on test= 0.008069157600402832\n",
      "acc for Lsat= 0.1560032101501136 \n",
      "acc for Psat= 0.18193210985103134 \n",
      "acc for optim= 0.1804193503643218\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.005271674133837223\n",
      "Loss on test= 0.007355363108217716\n",
      "acc for Lsat= 0.16040749129930848 \n",
      "acc for Psat= 0.1798619573401501 \n",
      "acc for optim= 0.18074098458540694\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.005194447003304958\n",
      "Loss on test= 0.007635472808033228\n",
      "acc for Lsat= 0.1581861683503404 \n",
      "acc for Psat= 0.19216414822578493 \n",
      "acc for optim= 0.17328168796127297\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.005333437584340572\n",
      "Loss on test= 0.007878507487475872\n",
      "acc for Lsat= 0.14724640033511277 \n",
      "acc for Psat= 0.19552320290555353 \n",
      "acc for optim= 0.1791458086368292\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.005139251239597797\n",
      "Loss on test= 0.007782768923789263\n",
      "acc for Lsat= 0.15576183438495747 \n",
      "acc for Psat= 0.18000890866964941 \n",
      "acc for optim= 0.17840333517991983\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.005212010350078344\n",
      "Loss on test= 0.007708537857979536\n",
      "acc for Lsat= 0.16066045308233712 \n",
      "acc for Psat= 0.18803207260276456 \n",
      "acc for optim= 0.17172168543653898\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.005140984430909157\n",
      "Loss on test= 0.00745462765917182\n",
      "acc for Lsat= 0.1405824375310524 \n",
      "acc for Psat= 0.17084232558268236 \n",
      "acc for optim= 0.1827402656401706\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.005394271574914455\n",
      "Loss on test= 0.0074045793153345585\n",
      "acc for Lsat= 0.15513596248614495 \n",
      "acc for Psat= 0.18623254168263376 \n",
      "acc for optim= 0.178433246529455\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.00526457792147994\n",
      "Loss on test= 0.007877111434936523\n",
      "acc for Lsat= 0.16992755944665988 \n",
      "acc for Psat= 0.19137949964726253 \n",
      "acc for optim= 0.1870117009110934\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.00546376034617424\n",
      "Loss on test= 0.007864359766244888\n",
      "acc for Lsat= 0.15680112363093104 \n",
      "acc for Psat= 0.185481742630831 \n",
      "acc for optim= 0.17507447260785008\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.005438246764242649\n",
      "Loss on test= 0.008180203847587109\n",
      "acc for Lsat= 0.15021265079267324 \n",
      "acc for Psat= 0.19355540349048975 \n",
      "acc for optim= 0.17635199354897582\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.0050028786063194275\n",
      "Loss on test= 0.0077414074912667274\n",
      "acc for Lsat= 0.15023387900829652 \n",
      "acc for Psat= 0.1883021608193512 \n",
      "acc for optim= 0.1801208872606665\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.0051579782739281654\n",
      "Loss on test= 0.007913678884506226\n",
      "acc for Lsat= 0.1619904516255254 \n",
      "acc for Psat= 0.19870343030827334 \n",
      "acc for optim= 0.17845054375025401\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.005412077531218529\n",
      "Loss on test= 0.007743440102785826\n",
      "acc for Lsat= 0.1412695627295523 \n",
      "acc for Psat= 0.1915456960629481 \n",
      "acc for optim= 0.18497866113502226\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.0052881622686982155\n",
      "Loss on test= 0.007313664071261883\n",
      "acc for Lsat= 0.15842683132180607 \n",
      "acc for Psat= 0.18159640199642202 \n",
      "acc for optim= 0.18888024979187024\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.005496170371770859\n",
      "Loss on test= 0.007451669313013554\n",
      "acc for Lsat= 0.14503362994816643 \n",
      "acc for Psat= 0.18746933447660832 \n",
      "acc for optim= 0.18224063346460156\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.00515954801812768\n",
      "Loss on test= 0.00759371230378747\n",
      "acc for Lsat= 0.15711450298368304 \n",
      "acc for Psat= 0.18890796264206045 \n",
      "acc for optim= 0.17681309535448653\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.005178648047149181\n",
      "Loss on test= 0.007042009383440018\n",
      "acc for Lsat= 0.1497458158225035 \n",
      "acc for Psat= 0.18089088995742506 \n",
      "acc for optim= 0.17825361867564096\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.0054330541752278805\n",
      "Loss on test= 0.0086878826841712\n",
      "acc for Lsat= 0.15232068679990154 \n",
      "acc for Psat= 0.18732544746875884 \n",
      "acc for optim= 0.17843630016174503\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.005142801441252232\n",
      "Loss on test= 0.007820063270628452\n",
      "acc for Lsat= 0.1641844759964323 \n",
      "acc for Psat= 0.19262415266158747 \n",
      "acc for optim= 0.18473196829322436\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.004981867969036102\n",
      "Loss on test= 0.0077301980927586555\n",
      "acc for Lsat= 0.15816592728198406 \n",
      "acc for Psat= 0.1879163548757788 \n",
      "acc for optim= 0.17849568164688878\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.005185790825635195\n",
      "Loss on test= 0.007945170626044273\n",
      "acc for Lsat= 0.15875314026040438 \n",
      "acc for Psat= 0.18193428778704104 \n",
      "acc for optim= 0.17790729139385683\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.005292257759720087\n",
      "Loss on test= 0.008169150911271572\n",
      "acc for Lsat= 0.14959551529905407 \n",
      "acc for Psat= 0.1899489808774202 \n",
      "acc for optim= 0.1804736554813495\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.0050685531459748745\n",
      "Loss on test= 0.007979811169207096\n",
      "acc for Lsat= 0.15962901472445143 \n",
      "acc for Psat= 0.19132508134958906 \n",
      "acc for optim= 0.1728620277992526\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.005053528118878603\n",
      "Loss on test= 0.00797850638628006\n",
      "acc for Lsat= 0.1616716497293368 \n",
      "acc for Psat= 0.1925243981292311 \n",
      "acc for optim= 0.17503400275022837\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.005128354299813509\n",
      "Loss on test= 0.00766874710097909\n",
      "acc for Lsat= 0.15839935460616453 \n",
      "acc for Psat= 0.18188756919770357 \n",
      "acc for optim= 0.17453686302798785\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.005392088089138269\n",
      "Loss on test= 0.0077719190157949924\n",
      "acc for Lsat= 0.1491306432803375 \n",
      "acc for Psat= 0.19045641240587488 \n",
      "acc for optim= 0.18320897766942404\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.00521622970700264\n",
      "Loss on test= 0.007989855483174324\n",
      "acc for Lsat= 0.15014866281070696 \n",
      "acc for Psat= 0.17520452796473915 \n",
      "acc for optim= 0.17728686160636975\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.005418772809207439\n",
      "Loss on test= 0.007638479582965374\n",
      "acc for Lsat= 0.16713833346787352 \n",
      "acc for Psat= 0.19188499161897257 \n",
      "acc for optim= 0.18001864310468502\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.005140561610460281\n",
      "Loss on test= 0.007421163842082024\n",
      "acc for Lsat= 0.14878401564883612 \n",
      "acc for Psat= 0.19015338961340364 \n",
      "acc for optim= 0.1785030018118378\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.005257907323539257\n",
      "Loss on test= 0.007560938596725464\n",
      "acc for Lsat= 0.1521563450469956 \n",
      "acc for Psat= 0.1827074342103843 \n",
      "acc for optim= 0.17910315515349437\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.005223290529102087\n",
      "Loss on test= 0.007096537388861179\n",
      "acc for Lsat= 0.14871421624165884 \n",
      "acc for Psat= 0.19084800422233605 \n",
      "acc for optim= 0.17445962153321234\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.004990683868527412\n",
      "Loss on test= 0.007741179317235947\n",
      "acc for Lsat= 0.15982669786031006 \n",
      "acc for Psat= 0.1919679069060443 \n",
      "acc for optim= 0.18406848846514878\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.004952679388225079\n",
      "Loss on test= 0.008093299344182014\n",
      "acc for Lsat= 0.1670859444157419 \n",
      "acc for Psat= 0.1958525151815876 \n",
      "acc for optim= 0.1889311049593475\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.0051792701706290245\n",
      "Loss on test= 0.007857156917452812\n",
      "acc for Lsat= 0.15622113830959578 \n",
      "acc for Psat= 0.18271574949002137 \n",
      "acc for optim= 0.1839694973791293\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.005208454094827175\n",
      "Loss on test= 0.007709637749940157\n",
      "acc for Lsat= 0.1560344559120942 \n",
      "acc for Psat= 0.1945398666060026 \n",
      "acc for optim= 0.17904036610929264\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.0050764428451657295\n",
      "Loss on test= 0.0076433089561760426\n",
      "acc for Lsat= 0.14891379120938344 \n",
      "acc for Psat= 0.1787645655760511 \n",
      "acc for optim= 0.17864201151843176\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.004949381109327078\n",
      "Loss on test= 0.007936069741845131\n",
      "acc for Lsat= 0.17259125689876678 \n",
      "acc for Psat= 0.18928986757547123 \n",
      "acc for optim= 0.18116659332256665\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.0050966497510671616\n",
      "Loss on test= 0.008004856295883656\n",
      "acc for Lsat= 0.15315051658303747 \n",
      "acc for Psat= 0.19064643403790035 \n",
      "acc for optim= 0.18237116330705935\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.0056400909088552\n",
      "Loss on test= 0.0075569902546703815\n",
      "acc for Lsat= 0.15583297689679101 \n",
      "acc for Psat= 0.19084467864996127 \n",
      "acc for optim= 0.18048395540080506\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.005082912743091583\n",
      "Loss on test= 0.007149307057261467\n",
      "acc for Lsat= 0.16580395442610188 \n",
      "acc for Psat= 0.16528510537683644 \n",
      "acc for optim= 0.17119057801395623\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.005323874298483133\n",
      "Loss on test= 0.00789969228208065\n",
      "acc for Lsat= 0.14924133555184987 \n",
      "acc for Psat= 0.1886718872117764 \n",
      "acc for optim= 0.1767116049298879\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.005300060845911503\n",
      "Loss on test= 0.007959635928273201\n",
      "acc for Lsat= 0.1415954930702087 \n",
      "acc for Psat= 0.1826234526598261 \n",
      "acc for optim= 0.18186297241954294\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.005226177629083395\n",
      "Loss on test= 0.007629069499671459\n",
      "acc for Lsat= 0.15542166844643956 \n",
      "acc for Psat= 0.1764025312382728 \n",
      "acc for optim= 0.1761200604174042\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.0054855127818882465\n",
      "Loss on test= 0.0073643396608531475\n",
      "acc for Lsat= 0.15182808650186147 \n",
      "acc for Psat= 0.18065842027798845 \n",
      "acc for optim= 0.16683418828169586\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.005107930861413479\n",
      "Loss on test= 0.007445461116731167\n",
      "acc for Lsat= 0.14802788333703962 \n",
      "acc for Psat= 0.1873115911184749 \n",
      "acc for optim= 0.18734961002339898\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.005238813813775778\n",
      "Loss on test= 0.007759758736938238\n",
      "acc for Lsat= 0.14499877040102918 \n",
      "acc for Psat= 0.18243272484444295 \n",
      "acc for optim= 0.18220077314670294\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.005180023144930601\n",
      "Loss on test= 0.007791739422827959\n",
      "acc for Lsat= 0.1471338825855217 \n",
      "acc for Psat= 0.18100323445911778 \n",
      "acc for optim= 0.1750168373541082\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.005028395913541317\n",
      "Loss on test= 0.007966670207679272\n",
      "acc for Lsat= 0.150788139869062 \n",
      "acc for Psat= 0.18544011092553922 \n",
      "acc for optim= 0.17195971550355038\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.005142319016158581\n",
      "Loss on test= 0.0077669657766819\n",
      "acc for Lsat= 0.13996800036163864 \n",
      "acc for Psat= 0.18644840632122558 \n",
      "acc for optim= 0.1725147291669645\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.0053650857880711555\n",
      "Loss on test= 0.0082247294485569\n",
      "acc for Lsat= 0.15334203314746073 \n",
      "acc for Psat= 0.17735578205711286 \n",
      "acc for optim= 0.1856440821086194\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.0055229635909199715\n",
      "Loss on test= 0.007752024568617344\n",
      "acc for Lsat= 0.14858680884201142 \n",
      "acc for Psat= 0.17289314130492905 \n",
      "acc for optim= 0.17876884362309195\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.005444312933832407\n",
      "Loss on test= 0.007671445142477751\n",
      "acc for Lsat= 0.16033229216881723 \n",
      "acc for Psat= 0.18538012425567893 \n",
      "acc for optim= 0.17599496688373142\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.005191662348806858\n",
      "Loss on test= 0.007632690016180277\n",
      "acc for Lsat= 0.15554017874366435 \n",
      "acc for Psat= 0.18592319684752004 \n",
      "acc for optim= 0.17550846213612278\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.005286547355353832\n",
      "Loss on test= 0.00771182868629694\n",
      "acc for Lsat= 0.15704191072259985 \n",
      "acc for Psat= 0.208516236351656 \n",
      "acc for optim= 0.1766923001135287\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.005099151283502579\n",
      "Loss on test= 0.008243981748819351\n",
      "acc for Lsat= 0.1442250320602487 \n",
      "acc for Psat= 0.19318617705062993 \n",
      "acc for optim= 0.18168233577620055\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.005179598927497864\n",
      "Loss on test= 0.007945749908685684\n",
      "acc for Lsat= 0.162239649565795 \n",
      "acc for Psat= 0.1863776929004759 \n",
      "acc for optim= 0.17955561252115854\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.0051520816050469875\n",
      "Loss on test= 0.007429319899529219\n",
      "acc for Lsat= 0.15031683093183063 \n",
      "acc for Psat= 0.18620784527500023 \n",
      "acc for optim= 0.17556908944350683\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.00520239258185029\n",
      "Loss on test= 0.0076667373068630695\n",
      "acc for Lsat= 0.15784045331433919 \n",
      "acc for Psat= 0.18256939353848822 \n",
      "acc for optim= 0.18454130225708482\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.005574558395892382\n",
      "Loss on test= 0.007961232215166092\n",
      "acc for Lsat= 0.14633720863465463 \n",
      "acc for Psat= 0.18245296092116137 \n",
      "acc for optim= 0.1846597345141297\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.005361578427255154\n",
      "Loss on test= 0.008151865564286709\n",
      "acc for Lsat= 0.15562730104594819 \n",
      "acc for Psat= 0.19711370153322083 \n",
      "acc for optim= 0.1801419336549159\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.0051607596687972546\n",
      "Loss on test= 0.008035029284656048\n",
      "acc for Lsat= 0.1605389498926119 \n",
      "acc for Psat= 0.18426066873209612 \n",
      "acc for optim= 0.17807620145078962\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.005428905598819256\n",
      "Loss on test= 0.007641728036105633\n",
      "acc for Lsat= 0.14868846935721985 \n",
      "acc for Psat= 0.17846804647591943 \n",
      "acc for optim= 0.18335899036269512\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.0050870017148554325\n",
      "Loss on test= 0.008171259425580502\n",
      "acc for Lsat= 0.14976219866409532 \n",
      "acc for Psat= 0.1952267233040909 \n",
      "acc for optim= 0.17985284302124113\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.005671899300068617\n",
      "Loss on test= 0.007420539855957031\n",
      "acc for Lsat= 0.1600279146589751 \n",
      "acc for Psat= 0.19285306185686704 \n",
      "acc for optim= 0.18397002963837786\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.004987585823982954\n",
      "Loss on test= 0.007459981366991997\n",
      "acc for Lsat= 0.16294810700971732 \n",
      "acc for Psat= 0.19923487560075448 \n",
      "acc for optim= 0.17881673777630538\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.005301808938384056\n",
      "Loss on test= 0.0072277020663022995\n",
      "acc for Lsat= 0.16741671736245273 \n",
      "acc for Psat= 0.19670638209552366 \n",
      "acc for optim= 0.18275579274326684\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.0051780263893306255\n",
      "Loss on test= 0.007500526495277882\n",
      "acc for Lsat= 0.14730983313638718 \n",
      "acc for Psat= 0.18269571877718277 \n",
      "acc for optim= 0.17516610136572425\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.005436600185930729\n",
      "Loss on test= 0.00756307365372777\n",
      "acc for Lsat= 0.15817128974719155 \n",
      "acc for Psat= 0.18529023766359237 \n",
      "acc for optim= 0.17675505777607198\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.005391416139900684\n",
      "Loss on test= 0.007578447926789522\n",
      "acc for Lsat= 0.16198761791093885 \n",
      "acc for Psat= 0.1894666273219389 \n",
      "acc for optim= 0.1825308014884196\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.005498652346432209\n",
      "Loss on test= 0.00766343530267477\n",
      "acc for Lsat= 0.15428965583588683 \n",
      "acc for Psat= 0.19137197721837332 \n",
      "acc for optim= 0.1742916846513313\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.005269498564302921\n",
      "Loss on test= 0.007554388139396906\n",
      "acc for Lsat= 0.15535021008938918 \n",
      "acc for Psat= 0.18170657991660666 \n",
      "acc for optim= 0.18143977766706737\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.005185980349779129\n",
      "Loss on test= 0.0076683154329657555\n",
      "acc for Lsat= 0.15728032503498443 \n",
      "acc for Psat= 0.1978324076141704 \n",
      "acc for optim= 0.1847837812562099\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.005194237921386957\n",
      "Loss on test= 0.0077874744310975075\n",
      "acc for Lsat= 0.14210233322237847 \n",
      "acc for Psat= 0.17865818521859778 \n",
      "acc for optim= 0.18127582340814236\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.005168679635971785\n",
      "Loss on test= 0.007776103913784027\n",
      "acc for Lsat= 0.14670575756806742 \n",
      "acc for Psat= 0.1770327507523003 \n",
      "acc for optim= 0.17672478922138937\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.0053934259340167046\n",
      "Loss on test= 0.007542074657976627\n",
      "acc for Lsat= 0.15501525362979307 \n",
      "acc for Psat= 0.17866514909394146 \n",
      "acc for optim= 0.17205012247050333\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.0051080090925097466\n",
      "Loss on test= 0.00784933939576149\n",
      "acc for Lsat= 0.14693105155220407 \n",
      "acc for Psat= 0.19414502309528409 \n",
      "acc for optim= 0.18047925269681594\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.005421500187367201\n",
      "Loss on test= 0.007751384284347296\n",
      "acc for Lsat= 0.15444576367812202 \n",
      "acc for Psat= 0.1816829625002326 \n",
      "acc for optim= 0.1855791580522162\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.005446922965347767\n",
      "Loss on test= 0.008273306302726269\n",
      "acc for Lsat= 0.16700813949230264 \n",
      "acc for Psat= 0.1732212264719133 \n",
      "acc for optim= 0.17512548366221828\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.005286449566483498\n",
      "Loss on test= 0.007646525278687477\n",
      "acc for Lsat= 0.13968729533804494 \n",
      "acc for Psat= 0.1727745487415766 \n",
      "acc for optim= 0.18074859292589923\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.005333935376256704\n",
      "Loss on test= 0.007697780150920153\n",
      "acc for Lsat= 0.14993801679525173 \n",
      "acc for Psat= 0.18567636131068507 \n",
      "acc for optim= 0.17961938673531117\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.005299481563270092\n",
      "Loss on test= 0.007372119929641485\n",
      "acc for Lsat= 0.15820541823717965 \n",
      "acc for Psat= 0.1887086275323737 \n",
      "acc for optim= 0.17215547364340622\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.0052075469866395\n",
      "Loss on test= 0.00767137436196208\n",
      "acc for Lsat= 0.14253157047296255 \n",
      "acc for Psat= 0.17800221520735593 \n",
      "acc for optim= 0.1830810845451674\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.005156133323907852\n",
      "Loss on test= 0.007580663543194532\n",
      "acc for Lsat= 0.1618850523380746 \n",
      "acc for Psat= 0.19351922706548186 \n",
      "acc for optim= 0.18544577645866933\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.005024113692343235\n",
      "Loss on test= 0.007586358115077019\n",
      "acc for Lsat= 0.15152688764539532 \n",
      "acc for Psat= 0.18278101079402584 \n",
      "acc for optim= 0.1804811259380496\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.005378040485084057\n",
      "Loss on test= 0.007932241074740887\n",
      "acc for Lsat= 0.15470572874731514 \n",
      "acc for Psat= 0.18848149285877894 \n",
      "acc for optim= 0.17818193701754292\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.005756957456469536\n",
      "Loss on test= 0.008265819400548935\n",
      "acc for Lsat= 0.16097176626554144 \n",
      "acc for Psat= 0.17338434377836434 \n",
      "acc for optim= 0.1751301566230946\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.005561443977057934\n",
      "Loss on test= 0.00783594511449337\n",
      "acc for Lsat= 0.1509027244188235 \n",
      "acc for Psat= 0.18852066815158994 \n",
      "acc for optim= 0.1852766229475268\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.005304078105837107\n",
      "Loss on test= 0.00824036542326212\n",
      "acc for Lsat= 0.16264638775939572 \n",
      "acc for Psat= 0.18029735462442345 \n",
      "acc for optim= 0.17513645363396194\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.005274858791381121\n",
      "Loss on test= 0.007613156456500292\n",
      "acc for Lsat= 0.16066205673774736 \n",
      "acc for Psat= 0.19117359760790859 \n",
      "acc for optim= 0.18047195211812456\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.005008991342037916\n",
      "Loss on test= 0.007700418122112751\n",
      "acc for Lsat= 0.1473266690320595 \n",
      "acc for Psat= 0.17737987617671977 \n",
      "acc for optim= 0.18250274590259993\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.005117637105286121\n",
      "Loss on test= 0.007703142706304789\n",
      "acc for Lsat= 0.14423449991851067 \n",
      "acc for Psat= 0.18972208561179166 \n",
      "acc for optim= 0.1793679738064205\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.0054455893114209175\n",
      "Loss on test= 0.007986053824424744\n",
      "acc for Lsat= 0.15076082705359783 \n",
      "acc for Psat= 0.17142517116478048 \n",
      "acc for optim= 0.17552408337608347\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.005166953895241022\n",
      "Loss on test= 0.007904148660600185\n",
      "acc for Lsat= 0.15020830356744957 \n",
      "acc for Psat= 0.17972694110176832 \n",
      "acc for optim= 0.18340501366724685\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.005054644774645567\n",
      "Loss on test= 0.008057246915996075\n",
      "acc for Lsat= 0.1620031076399457 \n",
      "acc for Psat= 0.1853043665876612 \n",
      "acc for optim= 0.18157249764710107\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.005286935716867447\n",
      "Loss on test= 0.007548680994659662\n",
      "acc for Lsat= 0.15986046174915172 \n",
      "acc for Psat= 0.17833642191444446 \n",
      "acc for optim= 0.1766177225865607\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.005219901911914349\n",
      "Loss on test= 0.00785788707435131\n",
      "acc for Lsat= 0.1545695241832663 \n",
      "acc for Psat= 0.17018048894118334 \n",
      "acc for optim= 0.17370071264659437\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.005452373065054417\n",
      "Loss on test= 0.008087772876024246\n",
      "acc for Lsat= 0.15481356544588065 \n",
      "acc for Psat= 0.1932934234954119 \n",
      "acc for optim= 0.17542705019939783\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.005421655718237162\n",
      "Loss on test= 0.00728480564430356\n",
      "acc for Lsat= 0.15146173368003907 \n",
      "acc for Psat= 0.18200058428738572 \n",
      "acc for optim= 0.17617114630645164\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.005288793705403805\n",
      "Loss on test= 0.007592977490276098\n",
      "acc for Lsat= 0.1489483074659146 \n",
      "acc for Psat= 0.17277958944991428 \n",
      "acc for optim= 0.18107277375154987\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.005215404089540243\n",
      "Loss on test= 0.007295073941349983\n",
      "acc for Lsat= 0.15189092277824023 \n",
      "acc for Psat= 0.1848754681207881 \n",
      "acc for optim= 0.17798889870597928\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.00550853693857789\n",
      "Loss on test= 0.0075879571959376335\n",
      "acc for Lsat= 0.1411699102590334 \n",
      "acc for Psat= 0.17777651747971102 \n",
      "acc for optim= 0.17911689811964426\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.005434031598269939\n",
      "Loss on test= 0.007605233695358038\n",
      "acc for Lsat= 0.16373342929482385 \n",
      "acc for Psat= 0.17999807323680306 \n",
      "acc for optim= 0.17141511848742202\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.00513547845184803\n",
      "Loss on test= 0.007693134248256683\n",
      "acc for Lsat= 0.16473877480650534 \n",
      "acc for Psat= 0.19084476271756834 \n",
      "acc for optim= 0.17842027852831782\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.0051268660463392735\n",
      "Loss on test= 0.007992645725607872\n",
      "acc for Lsat= 0.15061383367645875 \n",
      "acc for Psat= 0.17162960078032902 \n",
      "acc for optim= 0.17801476221294982\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.005369238089770079\n",
      "Loss on test= 0.00798824243247509\n",
      "acc for Lsat= 0.1449807271586548 \n",
      "acc for Psat= 0.186421828870027 \n",
      "acc for optim= 0.1808266939034735\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.005488621070981026\n",
      "Loss on test= 0.007765884976834059\n",
      "acc for Lsat= 0.15262488636978305 \n",
      "acc for Psat= 0.1846934110203426 \n",
      "acc for optim= 0.17752429929840546\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.0051682996563613415\n",
      "Loss on test= 0.007799767889082432\n",
      "acc for Lsat= 0.15106660991899487 \n",
      "acc for Psat= 0.1860365117881168 \n",
      "acc for optim= 0.18129456538285252\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.004975033458322287\n",
      "Loss on test= 0.007528301794081926\n",
      "acc for Lsat= 0.159116728400781 \n",
      "acc for Psat= 0.18814150328236465 \n",
      "acc for optim= 0.1768860257123826\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.005164151079952717\n",
      "Loss on test= 0.008433989249169827\n",
      "acc for Lsat= 0.14453050356203706 \n",
      "acc for Psat= 0.1920275008687597 \n",
      "acc for optim= 0.1859180694514672\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.005696086212992668\n",
      "Loss on test= 0.007866467349231243\n",
      "acc for Lsat= 0.1482130831554074 \n",
      "acc for Psat= 0.1924508694580925 \n",
      "acc for optim= 0.17291291207189627\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.005313296802341938\n",
      "Loss on test= 0.007087501231580973\n",
      "acc for Lsat= 0.15301507501824774 \n",
      "acc for Psat= 0.18923013568741315 \n",
      "acc for optim= 0.17926967557346482\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.0050583286210894585\n",
      "Loss on test= 0.008069823496043682\n",
      "acc for Lsat= 0.15404846821587198 \n",
      "acc for Psat= 0.1929328956803475 \n",
      "acc for optim= 0.18229016133461942\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.005664852447807789\n",
      "Loss on test= 0.007572136353701353\n",
      "acc for Lsat= 0.1659202546978629 \n",
      "acc for Psat= 0.19659500465819948 \n",
      "acc for optim= 0.18335482212896154\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.005198461003601551\n",
      "Loss on test= 0.007695109583437443\n",
      "acc for Lsat= 0.15136943807974304 \n",
      "acc for Psat= 0.183473005431292 \n",
      "acc for optim= 0.1807699643709071\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.00529879704117775\n",
      "Loss on test= 0.008212287910282612\n",
      "acc for Lsat= 0.1534028654620357 \n",
      "acc for Psat= 0.20166051940902777 \n",
      "acc for optim= 0.17720358277451329\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.005300725810229778\n",
      "Loss on test= 0.007613156922161579\n",
      "acc for Lsat= 0.1518046767181778 \n",
      "acc for Psat= 0.18058916065769393 \n",
      "acc for optim= 0.18313038265637932\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.005272815003991127\n",
      "Loss on test= 0.007906257174909115\n",
      "acc for Lsat= 0.1518716391455573 \n",
      "acc for Psat= 0.18719649050922943 \n",
      "acc for optim= 0.1779162095562883\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.005465429741889238\n",
      "Loss on test= 0.007529518101364374\n",
      "acc for Lsat= 0.14995918333593405 \n",
      "acc for Psat= 0.18040473391836295 \n",
      "acc for optim= 0.1818948908808229\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.005178791470825672\n",
      "Loss on test= 0.0080214012414217\n",
      "acc for Lsat= 0.15468590268101848 \n",
      "acc for Psat= 0.19012651282923723 \n",
      "acc for optim= 0.17837256811574467\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.005113732069730759\n",
      "Loss on test= 0.007534487638622522\n",
      "acc for Lsat= 0.15342953420629662 \n",
      "acc for Psat= 0.19072128838531513 \n",
      "acc for optim= 0.17631344189485687\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.005058980546891689\n",
      "Loss on test= 0.0077075050212442875\n",
      "acc for Lsat= 0.1497288230673475 \n",
      "acc for Psat= 0.18007962864510654 \n",
      "acc for optim= 0.18504613161427694\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.005286649335175753\n",
      "Loss on test= 0.008121824823319912\n",
      "acc for Lsat= 0.15669374363558924 \n",
      "acc for Psat= 0.1825869992943137 \n",
      "acc for optim= 0.17249927098421974\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.005024335812777281\n",
      "Loss on test= 0.007974953390657902\n",
      "acc for Lsat= 0.16537918524442577 \n",
      "acc for Psat= 0.18008963239577705 \n",
      "acc for optim= 0.18035113433601152\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.005238768644630909\n",
      "Loss on test= 0.007961071096360683\n",
      "acc for Lsat= 0.1545992513384754 \n",
      "acc for Psat= 0.19805491352072138 \n",
      "acc for optim= 0.17956733007349462\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.005333208478987217\n",
      "Loss on test= 0.007419081870466471\n",
      "acc for Lsat= 0.1536476588842352 \n",
      "acc for Psat= 0.18369405722825505 \n",
      "acc for optim= 0.18366075927452719\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.005184775218367577\n",
      "Loss on test= 0.007935214787721634\n",
      "acc for Lsat= 0.1502786715797408 \n",
      "acc for Psat= 0.17821258996178196 \n",
      "acc for optim= 0.1804214196203307\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.005926877725869417\n",
      "Loss on test= 0.007893530651926994\n",
      "acc for Lsat= 0.15229209063736412 \n",
      "acc for Psat= 0.1749319900726121 \n",
      "acc for optim= 0.1764216008479707\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.0051923939026892185\n",
      "Loss on test= 0.007445251103490591\n",
      "acc for Lsat= 0.14341774573206106 \n",
      "acc for Psat= 0.17336290126514228 \n",
      "acc for optim= 0.17701138132786165\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.004949041176587343\n",
      "Loss on test= 0.007702161557972431\n",
      "acc for Lsat= 0.14112009657146105 \n",
      "acc for Psat= 0.18915897131454748 \n",
      "acc for optim= 0.18480907377699146\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.005171691998839378\n",
      "Loss on test= 0.007985556498169899\n",
      "acc for Lsat= 0.15623436140459027 \n",
      "acc for Psat= 0.1748483359365205 \n",
      "acc for optim= 0.18286882375183774\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.005341785494238138\n",
      "Loss on test= 0.008045588620007038\n",
      "acc for Lsat= 0.15565611702775523 \n",
      "acc for Psat= 0.18340442555681727 \n",
      "acc for optim= 0.18590907777304624\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.005198647268116474\n",
      "Loss on test= 0.007736027706414461\n",
      "acc for Lsat= 0.15899378390024707 \n",
      "acc for Psat= 0.1864325427362451 \n",
      "acc for optim= 0.18341879248390067\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.005042194854468107\n",
      "Loss on test= 0.008003278635442257\n",
      "acc for Lsat= 0.1428504970549705 \n",
      "acc for Psat= 0.17871230781063072 \n",
      "acc for optim= 0.17684850801869303\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.005126624833792448\n",
      "Loss on test= 0.007616438437253237\n",
      "acc for Lsat= 0.15367289120445912 \n",
      "acc for Psat= 0.20175520634721414 \n",
      "acc for optim= 0.18079463536507587\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.005364755168557167\n",
      "Loss on test= 0.0073570366948843\n",
      "acc for Lsat= 0.15410370828438794 \n",
      "acc for Psat= 0.19927979686801306 \n",
      "acc for optim= 0.17950917168169236\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.00515351165086031\n",
      "Loss on test= 0.007703943643718958\n",
      "acc for Lsat= 0.1516306571721588 \n",
      "acc for Psat= 0.175287648449942 \n",
      "acc for optim= 0.18172780784060721\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.005122811533510685\n",
      "Loss on test= 0.007319063413888216\n",
      "acc for Lsat= 0.16090681985541644 \n",
      "acc for Psat= 0.19769047410074683 \n",
      "acc for optim= 0.1783360197218364\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.0051038553938269615\n",
      "Loss on test= 0.008204713463783264\n",
      "acc for Lsat= 0.1503432274397203 \n",
      "acc for Psat= 0.1856225308666357 \n",
      "acc for optim= 0.18004457874177787\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.005255102179944515\n",
      "Loss on test= 0.007535711862146854\n",
      "acc for Lsat= 0.14883547173774817 \n",
      "acc for Psat= 0.19184074329181772 \n",
      "acc for optim= 0.1771127987767524\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.005082816816866398\n",
      "Loss on test= 0.008257664740085602\n",
      "acc for Lsat= 0.14996915407265063 \n",
      "acc for Psat= 0.1877169735928173 \n",
      "acc for optim= 0.18052166052359217\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.005260955076664686\n",
      "Loss on test= 0.007867464795708656\n",
      "acc for Lsat= 0.14354156275455396 \n",
      "acc for Psat= 0.1819358251108139 \n",
      "acc for optim= 0.1758336560580246\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.005304899998009205\n",
      "Loss on test= 0.008029135875403881\n",
      "acc for Lsat= 0.14862543188615657 \n",
      "acc for Psat= 0.18745699143666988 \n",
      "acc for optim= 0.17723808704978466\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.005108856596052647\n",
      "Loss on test= 0.00747270043939352\n",
      "acc for Lsat= 0.16068913620117992 \n",
      "acc for Psat= 0.1865383549077154 \n",
      "acc for optim= 0.16823651520478097\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.005086969118565321\n",
      "Loss on test= 0.007703105919063091\n",
      "acc for Lsat= 0.1493482481909641 \n",
      "acc for Psat= 0.17098634923998168 \n",
      "acc for optim= 0.17354599505140003\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.004946976900100708\n",
      "Loss on test= 0.007799300365149975\n",
      "acc for Lsat= 0.14104005051187535 \n",
      "acc for Psat= 0.19592003176303927 \n",
      "acc for optim= 0.17699345253077794\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.005237906705588102\n",
      "Loss on test= 0.007854215800762177\n",
      "acc for Lsat= 0.15840376048677096 \n",
      "acc for Psat= 0.18577598433208758 \n",
      "acc for optim= 0.1777089671426468\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.004990128334611654\n",
      "Loss on test= 0.007706985343247652\n",
      "acc for Lsat= 0.14840911574400276 \n",
      "acc for Psat= 0.17919628384836078 \n",
      "acc for optim= 0.179302014720046\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.005127990618348122\n",
      "Loss on test= 0.007721025496721268\n",
      "acc for Lsat= 0.16364908880309859 \n",
      "acc for Psat= 0.17824332563828707 \n",
      "acc for optim= 0.17862116842336007\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.005420123692601919\n",
      "Loss on test= 0.007421853020787239\n",
      "acc for Lsat= 0.15425490519479115 \n",
      "acc for Psat= 0.19179110263863608 \n",
      "acc for optim= 0.18417774012434435\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.005224436521530151\n",
      "Loss on test= 0.007395100314170122\n",
      "acc for Lsat= 0.1613425517760095 \n",
      "acc for Psat= 0.1918369882465264 \n",
      "acc for optim= 0.1769584979037525\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.005274721421301365\n",
      "Loss on test= 0.008087478578090668\n",
      "acc for Lsat= 0.1385092483035701 \n",
      "acc for Psat= 0.176394087391749 \n",
      "acc for optim= 0.17219272248836265\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.0053641414269804955\n",
      "Loss on test= 0.00787130743265152\n",
      "acc for Lsat= 0.1483495902939944 \n",
      "acc for Psat= 0.17728470865881346 \n",
      "acc for optim= 0.17605914958985522\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.005290464498102665\n",
      "Loss on test= 0.007953297346830368\n",
      "acc for Lsat= 0.1475109188034978 \n",
      "acc for Psat= 0.18149845835656886 \n",
      "acc for optim= 0.1881027656946795\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.0050713918171823025\n",
      "Loss on test= 0.007974482141435146\n",
      "acc for Lsat= 0.14760363630713802 \n",
      "acc for Psat= 0.19960867536109186 \n",
      "acc for optim= 0.17887470666128288\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.005493008531630039\n",
      "Loss on test= 0.007852070033550262\n",
      "acc for Lsat= 0.15187953800548892 \n",
      "acc for Psat= 0.18540162722041953 \n",
      "acc for optim= 0.17687135396342052\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.005566322710365057\n",
      "Loss on test= 0.00801045447587967\n",
      "acc for Lsat= 0.1587894557776754 \n",
      "acc for Psat= 0.1888664756069479 \n",
      "acc for optim= 0.17498538496009014\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.005203165579587221\n",
      "Loss on test= 0.007686941884458065\n",
      "acc for Lsat= 0.15701270013910215 \n",
      "acc for Psat= 0.18700719715218198 \n",
      "acc for optim= 0.18127414311604864\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.005339303053915501\n",
      "Loss on test= 0.007784061599522829\n",
      "acc for Lsat= 0.1512670016746403 \n",
      "acc for Psat= 0.1831678648684441 \n",
      "acc for optim= 0.1741452871340892\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.005363751202821732\n",
      "Loss on test= 0.007968759164214134\n",
      "acc for Lsat= 0.14995950243510228 \n",
      "acc for Psat= 0.19882122500051486 \n",
      "acc for optim= 0.18370147908223816\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.005348519422113895\n",
      "Loss on test= 0.007646994665265083\n",
      "acc for Lsat= 0.15861878294982473 \n",
      "acc for Psat= 0.18859464109206828 \n",
      "acc for optim= 0.17847200200538013\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.005540899932384491\n",
      "Loss on test= 0.007462470326572657\n",
      "acc for Lsat= 0.145504744128576 \n",
      "acc for Psat= 0.18059259896017762 \n",
      "acc for optim= 0.18101966086084206\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.005233629606664181\n",
      "Loss on test= 0.008026020601391792\n",
      "acc for Lsat= 0.143507047661687 \n",
      "acc for Psat= 0.18355419430185155 \n",
      "acc for optim= 0.17715084617375396\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.005412012338638306\n",
      "Loss on test= 0.007441953755915165\n",
      "acc for Lsat= 0.14196051795066136 \n",
      "acc for Psat= 0.1920255195420783 \n",
      "acc for optim= 0.1851071268432205\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.005340893752872944\n",
      "Loss on test= 0.008030597120523453\n",
      "acc for Lsat= 0.1553542680221564 \n",
      "acc for Psat= 0.20415963079039862 \n",
      "acc for optim= 0.18297827656583127\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.006163503043353558\n",
      "Loss on test= 0.007676935754716396\n",
      "acc for Lsat= 0.1495240068203411 \n",
      "acc for Psat= 0.18088051553369028 \n",
      "acc for optim= 0.18245549732132157\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.005021179094910622\n",
      "Loss on test= 0.007803096901625395\n",
      "acc for Lsat= 0.14992225385866448 \n",
      "acc for Psat= 0.18464938638136402 \n",
      "acc for optim= 0.177270415454309\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.005354733671993017\n",
      "Loss on test= 0.007944498211145401\n",
      "acc for Lsat= 0.14601961770295319 \n",
      "acc for Psat= 0.1854697477591575 \n",
      "acc for optim= 0.17259843190654836\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.005293645896017551\n",
      "Loss on test= 0.007448232267051935\n",
      "acc for Lsat= 0.1444964258555613 \n",
      "acc for Psat= 0.1815992556462736 \n",
      "acc for optim= 0.18001339333439648\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.0052048685029149055\n",
      "Loss on test= 0.008029401302337646\n",
      "acc for Lsat= 0.1568190084369548 \n",
      "acc for Psat= 0.17520321239297446 \n",
      "acc for optim= 0.18360893718843907\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.00548655865713954\n",
      "Loss on test= 0.007705583702772856\n",
      "acc for Lsat= 0.15473966645573067 \n",
      "acc for Psat= 0.18318646282461457 \n",
      "acc for optim= 0.17434429940681706\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.005387535784393549\n",
      "Loss on test= 0.007629167754203081\n",
      "acc for Lsat= 0.15037830390470755 \n",
      "acc for Psat= 0.17905242808666996 \n",
      "acc for optim= 0.18189738517527881\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.005583354737609625\n",
      "Loss on test= 0.007491653319448233\n",
      "acc for Lsat= 0.15267195487852955 \n",
      "acc for Psat= 0.18279246822940415 \n",
      "acc for optim= 0.17708201378032368\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.005043179728090763\n",
      "Loss on test= 0.007681633811444044\n",
      "acc for Lsat= 0.1399410404163302 \n",
      "acc for Psat= 0.19207598630045006 \n",
      "acc for optim= 0.17685726387846115\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.005205043591558933\n",
      "Loss on test= 0.008040603250265121\n",
      "acc for Lsat= 0.16267658277156144 \n",
      "acc for Psat= 0.1865894606434282 \n",
      "acc for optim= 0.17885981376023322\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.005736419465392828\n",
      "Loss on test= 0.007569469511508942\n",
      "acc for Lsat= 0.14999696274343344 \n",
      "acc for Psat= 0.18776972636152975 \n",
      "acc for optim= 0.17583448942216326\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.005602236837148666\n",
      "Loss on test= 0.007699780166149139\n",
      "acc for Lsat= 0.15505441570836767 \n",
      "acc for Psat= 0.17605646751080564 \n",
      "acc for optim= 0.1873247711663039\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.0051309773698449135\n",
      "Loss on test= 0.007574828807264566\n",
      "acc for Lsat= 0.15645949651876495 \n",
      "acc for Psat= 0.18054556016567866 \n",
      "acc for optim= 0.18118337817570257\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.005065681412816048\n",
      "Loss on test= 0.008208898827433586\n",
      "acc for Lsat= 0.14165393914512098 \n",
      "acc for Psat= 0.16994332754450134 \n",
      "acc for optim= 0.18217858983982416\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.005330315325409174\n",
      "Loss on test= 0.007957599125802517\n",
      "acc for Lsat= 0.14953477567454923 \n",
      "acc for Psat= 0.16961352836777702 \n",
      "acc for optim= 0.1794150414766904\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.005208111368119717\n",
      "Loss on test= 0.007885215803980827\n",
      "acc for Lsat= 0.14840142215424615 \n",
      "acc for Psat= 0.194207595080184 \n",
      "acc for optim= 0.1775720839625316\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.0049638464115560055\n",
      "Loss on test= 0.007619451265782118\n",
      "acc for Lsat= 0.15365070294761518 \n",
      "acc for Psat= 0.18080532670786345 \n",
      "acc for optim= 0.17774780438430454\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.005189702846109867\n",
      "Loss on test= 0.007722862530499697\n",
      "acc for Lsat= 0.15166931168765943 \n",
      "acc for Psat= 0.17707480418011087 \n",
      "acc for optim= 0.18523042469178555\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.005178830120712519\n",
      "Loss on test= 0.007793687749654055\n",
      "acc for Lsat= 0.13702627550257127 \n",
      "acc for Psat= 0.16869401905006257 \n",
      "acc for optim= 0.1802652896665319\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.005151454824954271\n",
      "Loss on test= 0.007695745211094618\n",
      "acc for Lsat= 0.15570506429811176 \n",
      "acc for Psat= 0.1852702022690448 \n",
      "acc for optim= 0.1728086039776051\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.005208949092775583\n",
      "Loss on test= 0.007767833769321442\n",
      "acc for Lsat= 0.15718666436475107 \n",
      "acc for Psat= 0.1838674020377125 \n",
      "acc for optim= 0.18084584836214476\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.005309318657964468\n",
      "Loss on test= 0.007816936820745468\n",
      "acc for Lsat= 0.15204976147258287 \n",
      "acc for Psat= 0.18521744376387195 \n",
      "acc for optim= 0.18860878885845792\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.00506578991189599\n",
      "Loss on test= 0.007306351326406002\n",
      "acc for Lsat= 0.15063676744237633 \n",
      "acc for Psat= 0.17957801182518646 \n",
      "acc for optim= 0.17499546296627366\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.0049989051185548306\n",
      "Loss on test= 0.007425428833812475\n",
      "acc for Lsat= 0.15441910947003157 \n",
      "acc for Psat= 0.17177701121593109 \n",
      "acc for optim= 0.1764099411435471\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.005297320894896984\n",
      "Loss on test= 0.007573784328997135\n",
      "acc for Lsat= 0.14653614980596133 \n",
      "acc for Psat= 0.19111763477997212 \n",
      "acc for optim= 0.17624029644252542\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.00516303488984704\n",
      "Loss on test= 0.007663278840482235\n",
      "acc for Lsat= 0.15375456318076028 \n",
      "acc for Psat= 0.16791758458435413 \n",
      "acc for optim= 0.17877172731233096\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.005131577141582966\n",
      "Loss on test= 0.007341077085584402\n",
      "acc for Lsat= 0.14524461924142326 \n",
      "acc for Psat= 0.17343356154208286 \n",
      "acc for optim= 0.18243932096281884\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.005614848341792822\n",
      "Loss on test= 0.007199075538665056\n",
      "acc for Lsat= 0.15165536690533893 \n",
      "acc for Psat= 0.19141683322415673 \n",
      "acc for optim= 0.17951811530291423\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.005436957348138094\n",
      "Loss on test= 0.007706173695623875\n",
      "acc for Lsat= 0.1644878706293654 \n",
      "acc for Psat= 0.1813807231296793 \n",
      "acc for optim= 0.17989545460775128\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.0052591548301279545\n",
      "Loss on test= 0.007366288919001818\n",
      "acc for Lsat= 0.14763527031373386 \n",
      "acc for Psat= 0.19549384460122263 \n",
      "acc for optim= 0.18026171258085819\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.00504973204806447\n",
      "Loss on test= 0.0077184331603348255\n",
      "acc for Lsat= 0.15276033396691419 \n",
      "acc for Psat= 0.18533380339575786 \n",
      "acc for optim= 0.17668444102557976\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.005131241865456104\n",
      "Loss on test= 0.008311809040606022\n",
      "acc for Lsat= 0.15644988382538613 \n",
      "acc for Psat= 0.1847265071622535 \n",
      "acc for optim= 0.18302654189126352\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.00518144853413105\n",
      "Loss on test= 0.00797238852828741\n",
      "acc for Lsat= 0.14678479081008308 \n",
      "acc for Psat= 0.1798342521955091 \n",
      "acc for optim= 0.18771805193916452\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.005032605491578579\n",
      "Loss on test= 0.0077896276488900185\n",
      "acc for Lsat= 0.14636895103441155 \n",
      "acc for Psat= 0.17525299977011155 \n",
      "acc for optim= 0.1815851678837045\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.005210542120039463\n",
      "Loss on test= 0.007680283859372139\n",
      "acc for Lsat= 0.15530587881927563 \n",
      "acc for Psat= 0.19469033202622085 \n",
      "acc for optim= 0.18183063024705798\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.00508964154869318\n",
      "Loss on test= 0.007795111741870642\n",
      "acc for Lsat= 0.14739058358703558 \n",
      "acc for Psat= 0.18304728044036653 \n",
      "acc for optim= 0.1849738608300972\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.005244292318820953\n",
      "Loss on test= 0.007462422363460064\n",
      "acc for Lsat= 0.17324697559424598 \n",
      "acc for Psat= 0.19704775588785406 \n",
      "acc for optim= 0.17533045319847945\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.005249199457466602\n",
      "Loss on test= 0.007947491481900215\n",
      "acc for Lsat= 0.15013042389812162 \n",
      "acc for Psat= 0.17687830111903108 \n",
      "acc for optim= 0.1763838554725822\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005236431024968624\n",
      "Loss on test= 0.007586941123008728\n",
      "acc for Lsat= 0.14990211046438237 \n",
      "acc for Psat= 0.17388274815910665 \n",
      "acc for optim= 0.17826661910488628\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.005128645338118076\n",
      "Loss on test= 0.00769109558314085\n",
      "acc for Lsat= 0.14393389662231518 \n",
      "acc for Psat= 0.1782491462313776 \n",
      "acc for optim= 0.17827858723836978\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.005299434997141361\n",
      "Loss on test= 0.008132520131766796\n",
      "acc for Lsat= 0.15961046226677622 \n",
      "acc for Psat= 0.1942578657402382 \n",
      "acc for optim= 0.1717432825214928\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.005306169856339693\n",
      "Loss on test= 0.007845880463719368\n",
      "acc for Lsat= 0.1530812831632755 \n",
      "acc for Psat= 0.18345872895204324 \n",
      "acc for optim= 0.17537092955794462\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.005149052478373051\n",
      "Loss on test= 0.007662953808903694\n",
      "acc for Lsat= 0.14862046636812548 \n",
      "acc for Psat= 0.19293477380549015 \n",
      "acc for optim= 0.17899883821917714\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.005291926208883524\n",
      "Loss on test= 0.008125501684844494\n",
      "acc for Lsat= 0.1637234941678366 \n",
      "acc for Psat= 0.19304982819212754 \n",
      "acc for optim= 0.1821077861876578\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.0051321424543857574\n",
      "Loss on test= 0.007740070577710867\n",
      "acc for Lsat= 0.15973457767481183 \n",
      "acc for Psat= 0.16855430109998915 \n",
      "acc for optim= 0.18075196403918453\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.0054160780273377895\n",
      "Loss on test= 0.007584410719573498\n",
      "acc for Lsat= 0.14657251305923966 \n",
      "acc for Psat= 0.1844283097790035 \n",
      "acc for optim= 0.17526748047866783\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.005111045204102993\n",
      "Loss on test= 0.007718799170106649\n",
      "acc for Lsat= 0.15631013955752993 \n",
      "acc for Psat= 0.1880558260464583 \n",
      "acc for optim= 0.17610525878467864\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.005256377626210451\n",
      "Loss on test= 0.008237171918153763\n",
      "acc for Lsat= 0.16874573496785816 \n",
      "acc for Psat= 0.171203842297288 \n",
      "acc for optim= 0.18109907175979165\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.0048602488823235035\n",
      "Loss on test= 0.007928350940346718\n",
      "acc for Lsat= 0.15084675379502052 \n",
      "acc for Psat= 0.16959716979202863 \n",
      "acc for optim= 0.17530439818839993\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.00529035460203886\n",
      "Loss on test= 0.008303980343043804\n",
      "acc for Lsat= 0.1555194029784914 \n",
      "acc for Psat= 0.1927720820980871 \n",
      "acc for optim= 0.18125024116521732\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.005384954623878002\n",
      "Loss on test= 0.008098688907921314\n",
      "acc for Lsat= 0.14403783940198664 \n",
      "acc for Psat= 0.18963873203706424 \n",
      "acc for optim= 0.1749423484367578\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.005098329391330481\n",
      "Loss on test= 0.00757524324581027\n",
      "acc for Lsat= 0.15322389908260894 \n",
      "acc for Psat= 0.18203509054421046 \n",
      "acc for optim= 0.17994087157589927\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.005173052661120892\n",
      "Loss on test= 0.007416451349854469\n",
      "acc for Lsat= 0.15389508796077161 \n",
      "acc for Psat= 0.17961784579378903 \n",
      "acc for optim= 0.17488363887408565\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.005023004952818155\n",
      "Loss on test= 0.007865013554692268\n",
      "acc for Lsat= 0.15876000732847595 \n",
      "acc for Psat= 0.18919469212242937 \n",
      "acc for optim= 0.17510574227472703\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.005197389051318169\n",
      "Loss on test= 0.007648952770978212\n",
      "acc for Lsat= 0.14841330643498996 \n",
      "acc for Psat= 0.1883061735908936 \n",
      "acc for optim= 0.18424666364778397\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005147490184754133\n",
      "Loss on test= 0.007911251857876778\n",
      "acc for Lsat= 0.16165174729520929 \n",
      "acc for Psat= 0.19119260507315153 \n",
      "acc for optim= 0.18681835955596665\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.005411326419562101\n",
      "Loss on test= 0.007769607938826084\n",
      "acc for Lsat= 0.1518636713303496 \n",
      "acc for Psat= 0.1869232553693363 \n",
      "acc for optim= 0.18290405785178263\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.005304671823978424\n",
      "Loss on test= 0.007952196523547173\n",
      "acc for Lsat= 0.1624064880004105 \n",
      "acc for Psat= 0.19036868111560595 \n",
      "acc for optim= 0.17373524398001897\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.005292694084346294\n",
      "Loss on test= 0.007862362079322338\n",
      "acc for Lsat= 0.15058143526901582 \n",
      "acc for Psat= 0.17223846774136067 \n",
      "acc for optim= 0.1801694505359428\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.005132611375302076\n",
      "Loss on test= 0.007350819185376167\n",
      "acc for Lsat= 0.148605428948487 \n",
      "acc for Psat= 0.18908107895385015 \n",
      "acc for optim= 0.18251511615898544\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.0052190967835485935\n",
      "Loss on test= 0.007619226351380348\n",
      "acc for Lsat= 0.15103205264523076 \n",
      "acc for Psat= 0.1824045049698382 \n",
      "acc for optim= 0.17535186883894208\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.005170959979295731\n",
      "Loss on test= 0.008346730843186378\n",
      "acc for Lsat= 0.15685234629056707 \n",
      "acc for Psat= 0.2019229386898796 \n",
      "acc for optim= 0.17864125552911647\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.004925986286252737\n",
      "Loss on test= 0.007884375751018524\n",
      "acc for Lsat= 0.15311834624778578 \n",
      "acc for Psat= 0.19301621018122636 \n",
      "acc for optim= 0.1850829440934801\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.005339273251593113\n",
      "Loss on test= 0.007742828689515591\n",
      "acc for Lsat= 0.156090096991555 \n",
      "acc for Psat= 0.19965390403121405 \n",
      "acc for optim= 0.17905473001759317\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.005404924042522907\n",
      "Loss on test= 0.00802119541913271\n",
      "acc for Lsat= 0.1477209432609761 \n",
      "acc for Psat= 0.1954996638261469 \n",
      "acc for optim= 0.18327170521348665\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.005053624976426363\n",
      "Loss on test= 0.007375374902039766\n",
      "acc for Lsat= 0.1595804681079691 \n",
      "acc for Psat= 0.181273262754472 \n",
      "acc for optim= 0.185589888756026\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.005315165035426617\n",
      "Loss on test= 0.008337023667991161\n",
      "acc for Lsat= 0.15054612370204565 \n",
      "acc for Psat= 0.1971655884391216 \n",
      "acc for optim= 0.18159099271439028\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.005317159928381443\n",
      "Loss on test= 0.007839608006179333\n",
      "acc for Lsat= 0.16159916096939475 \n",
      "acc for Psat= 0.17479615930275091 \n",
      "acc for optim= 0.18114336729813063\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.005181164480745792\n",
      "Loss on test= 0.006831508595496416\n",
      "acc for Lsat= 0.15364990397585465 \n",
      "acc for Psat= 0.16965660332099985 \n",
      "acc for optim= 0.17349163031174045\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.005251472350209951\n",
      "Loss on test= 0.007502709981054068\n",
      "acc for Lsat= 0.15560790174182687 \n",
      "acc for Psat= 0.1704587931569177 \n",
      "acc for optim= 0.18144379817464648\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.005170612130314112\n",
      "Loss on test= 0.007257998455315828\n",
      "acc for Lsat= 0.14484786552211965 \n",
      "acc for Psat= 0.16802100812735754 \n",
      "acc for optim= 0.17972754587411696\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.005476603750139475\n",
      "Loss on test= 0.007800833787769079\n",
      "acc for Lsat= 0.16576214231184272 \n",
      "acc for Psat= 0.1959091876236508 \n",
      "acc for optim= 0.17646304313914057\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.005550774745643139\n",
      "Loss on test= 0.008050894364714622\n",
      "acc for Lsat= 0.1479229183987806 \n",
      "acc for Psat= 0.18713400896655807 \n",
      "acc for optim= 0.17452115746802788\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.006316183600574732\n",
      "Loss on test= 0.007438821252435446\n",
      "acc for Lsat= 0.1579069142680249 \n",
      "acc for Psat= 0.1770452307233755 \n",
      "acc for optim= 0.17735198558915072\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.005488275550305843\n",
      "Loss on test= 0.007552018854767084\n",
      "acc for Lsat= 0.14970842970708828 \n",
      "acc for Psat= 0.17654998474258196 \n",
      "acc for optim= 0.17408219900981287\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.005315282382071018\n",
      "Loss on test= 0.007830960676074028\n",
      "acc for Lsat= 0.15781660823411017 \n",
      "acc for Psat= 0.18681437455892533 \n",
      "acc for optim= 0.18781151932103132\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.005203975830227137\n",
      "Loss on test= 0.00778989028185606\n",
      "acc for Lsat= 0.1575308915433764 \n",
      "acc for Psat= 0.1728964303673596 \n",
      "acc for optim= 0.1800555933599425\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.005802817177027464\n",
      "Loss on test= 0.0074744937010109425\n",
      "acc for Lsat= 0.1473575230748927 \n",
      "acc for Psat= 0.17524528486728294 \n",
      "acc for optim= 0.17709767459977616\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.005750061012804508\n",
      "Loss on test= 0.00775911146774888\n",
      "acc for Lsat= 0.14548213205170973 \n",
      "acc for Psat= 0.17253116863691698 \n",
      "acc for optim= 0.17297836361170488\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005392004735767841\n",
      "Loss on test= 0.007661273702979088\n",
      "acc for Lsat= 0.15866829992470438 \n",
      "acc for Psat= 0.19413910721644348 \n",
      "acc for optim= 0.17813428240459886\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.005155661143362522\n",
      "Loss on test= 0.007457054685801268\n",
      "acc for Lsat= 0.15043704285759663 \n",
      "acc for Psat= 0.18559788232249375 \n",
      "acc for optim= 0.1789956097680022\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.005157369188964367\n",
      "Loss on test= 0.007862811908125877\n",
      "acc for Lsat= 0.149428654549506 \n",
      "acc for Psat= 0.1769367536232181 \n",
      "acc for optim= 0.17910325495797194\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.005411169491708279\n",
      "Loss on test= 0.007715381681919098\n",
      "acc for Lsat= 0.14624913379275165 \n",
      "acc for Psat= 0.17933443586712275 \n",
      "acc for optim= 0.18478209210624613\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.005222148261964321\n",
      "Loss on test= 0.008069596253335476\n",
      "acc for Lsat= 0.1490605699978616 \n",
      "acc for Psat= 0.1699292728386831 \n",
      "acc for optim= 0.18235892785186344\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.005203033331781626\n",
      "Loss on test= 0.0076799551025033\n",
      "acc for Lsat= 0.15113343336127058 \n",
      "acc for Psat= 0.18468923929918435 \n",
      "acc for optim= 0.17785772829847105\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.00534750847145915\n",
      "Loss on test= 0.00773975346237421\n",
      "acc for Lsat= 0.14160752811843194 \n",
      "acc for Psat= 0.17574519170791705 \n",
      "acc for optim= 0.18203986400765076\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.005374407861381769\n",
      "Loss on test= 0.007521891966462135\n",
      "acc for Lsat= 0.13463302690156004 \n",
      "acc for Psat= 0.1788563925482702 \n",
      "acc for optim= 0.17461954094240534\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.0052331797778606415\n",
      "Loss on test= 0.007374672684818506\n",
      "acc for Lsat= 0.14666482289459934 \n",
      "acc for Psat= 0.16734465796683656 \n",
      "acc for optim= 0.1771653842397576\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.004942959174513817\n",
      "Loss on test= 0.008021923713386059\n",
      "acc for Lsat= 0.1484041223376913 \n",
      "acc for Psat= 0.1924029463277099 \n",
      "acc for optim= 0.18161295438070826\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.005672250874340534\n",
      "Loss on test= 0.007914099842309952\n",
      "acc for Lsat= 0.1656649099096568 \n",
      "acc for Psat= 0.19717452753365863 \n",
      "acc for optim= 0.17929870895678787\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.006097310222685337\n",
      "Loss on test= 0.007536096032708883\n",
      "acc for Lsat= 0.1560381229531753 \n",
      "acc for Psat= 0.17545498630077747 \n",
      "acc for optim= 0.17566594578799044\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.004919883795082569\n",
      "Loss on test= 0.0077913254499435425\n",
      "acc for Lsat= 0.14844793007693818 \n",
      "acc for Psat= 0.18537847177186584 \n",
      "acc for optim= 0.1775894430076673\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.005087003111839294\n",
      "Loss on test= 0.00762519845739007\n",
      "acc for Lsat= 0.14721466421033255 \n",
      "acc for Psat= 0.19635339057889814 \n",
      "acc for optim= 0.17694073119727974\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.005173542536795139\n",
      "Loss on test= 0.007719851098954678\n",
      "acc for Lsat= 0.1497531516013713 \n",
      "acc for Psat= 0.1853699269462148 \n",
      "acc for optim= 0.18143483144498324\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.00520786177366972\n",
      "Loss on test= 0.007410603109747171\n",
      "acc for Lsat= 0.15571540519213456 \n",
      "acc for Psat= 0.1989884002172373 \n",
      "acc for optim= 0.17721417793874308\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.005195531994104385\n",
      "Loss on test= 0.007625668775290251\n",
      "acc for Lsat= 0.14541647056056584 \n",
      "acc for Psat= 0.1847112483161761 \n",
      "acc for optim= 0.18421242162155857\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.005356694106012583\n",
      "Loss on test= 0.008168503642082214\n",
      "acc for Lsat= 0.15903222492903654 \n",
      "acc for Psat= 0.19882592233145976 \n",
      "acc for optim= 0.17534670940491554\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.0051771849393844604\n",
      "Loss on test= 0.007347780745476484\n",
      "acc for Lsat= 0.16292650326597408 \n",
      "acc for Psat= 0.18002015639985836 \n",
      "acc for optim= 0.17987792650810214\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.0052329618483781815\n",
      "Loss on test= 0.007274013478308916\n",
      "acc for Lsat= 0.145876241020322 \n",
      "acc for Psat= 0.17597082972213565 \n",
      "acc for optim= 0.17228119061824668\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.00538665521889925\n",
      "Loss on test= 0.007574133574962616\n",
      "acc for Lsat= 0.14873746358708395 \n",
      "acc for Psat= 0.18522817973690642 \n",
      "acc for optim= 0.17536459691435113\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.0052038924768567085\n",
      "Loss on test= 0.008235620334744453\n",
      "acc for Lsat= 0.15544523848354297 \n",
      "acc for Psat= 0.19072812106383996 \n",
      "acc for optim= 0.1809787708757346\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.005094502586871386\n",
      "Loss on test= 0.007692036684602499\n",
      "acc for Lsat= 0.14935239278625498 \n",
      "acc for Psat= 0.17240044997783652 \n",
      "acc for optim= 0.17654260019619078\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.005184066481888294\n",
      "Loss on test= 0.007366963662207127\n",
      "acc for Lsat= 0.13964010776549227 \n",
      "acc for Psat= 0.17254685457379818 \n",
      "acc for optim= 0.17362942385392313\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.00558731472119689\n",
      "Loss on test= 0.007362126372754574\n",
      "acc for Lsat= 0.14800494207760137 \n",
      "acc for Psat= 0.17641435068722844 \n",
      "acc for optim= 0.17795632505814685\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.005410126410424709\n",
      "Loss on test= 0.008066579699516296\n",
      "acc for Lsat= 0.16014698291365362 \n",
      "acc for Psat= 0.1869470233027537 \n",
      "acc for optim= 0.17856601253609922\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.0052383067086339\n",
      "Loss on test= 0.007533194497227669\n",
      "acc for Lsat= 0.14678991232783015 \n",
      "acc for Psat= 0.18664931969976695 \n",
      "acc for optim= 0.17442941162658887\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.005201343446969986\n",
      "Loss on test= 0.007654407527297735\n",
      "acc for Lsat= 0.14818685858998998 \n",
      "acc for Psat= 0.19507588781492755 \n",
      "acc for optim= 0.173293568490867\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.00523353461176157\n",
      "Loss on test= 0.007813138887286186\n",
      "acc for Lsat= 0.15787417476893723 \n",
      "acc for Psat= 0.199895077396459 \n",
      "acc for optim= 0.18144739169520555\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.005640892777591944\n",
      "Loss on test= 0.007665491662919521\n",
      "acc for Lsat= 0.14651751699628401 \n",
      "acc for Psat= 0.18466479729414445 \n",
      "acc for optim= 0.1816516630618726\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.005408535711467266\n",
      "Loss on test= 0.0077226413413882256\n",
      "acc for Lsat= 0.1429040268743907 \n",
      "acc for Psat= 0.18354371513094997 \n",
      "acc for optim= 0.17564289109117245\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005396867170929909\n",
      "Loss on test= 0.0076627363450825214\n",
      "acc for Lsat= 0.15832307127907444 \n",
      "acc for Psat= 0.1725048957407841 \n",
      "acc for optim= 0.18226100959000177\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.004978924058377743\n",
      "Loss on test= 0.008080455474555492\n",
      "acc for Lsat= 0.15744241079407148 \n",
      "acc for Psat= 0.18050035932416203 \n",
      "acc for optim= 0.1749775398140926\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005284222774207592\n",
      "Loss on test= 0.007867143489420414\n",
      "acc for Lsat= 0.14882754568109807 \n",
      "acc for Psat= 0.18750975271839587 \n",
      "acc for optim= 0.17715737821408317\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.0050942315720021725\n",
      "Loss on test= 0.0075581190176308155\n",
      "acc for Lsat= 0.14580249983748636 \n",
      "acc for Psat= 0.190662328784209 \n",
      "acc for optim= 0.18078533657960075\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.005124275106936693\n",
      "Loss on test= 0.007280018180608749\n",
      "acc for Lsat= 0.1655797087880363 \n",
      "acc for Psat= 0.1736654326649856 \n",
      "acc for optim= 0.1711934443269322\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.005120288580656052\n",
      "Loss on test= 0.00780236441642046\n",
      "acc for Lsat= 0.14683259497263057 \n",
      "acc for Psat= 0.1713841299507309 \n",
      "acc for optim= 0.17384747049244517\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.005088087171316147\n",
      "Loss on test= 0.007670020218938589\n",
      "acc for Lsat= 0.16432707767368707 \n",
      "acc for Psat= 0.19696373278847668 \n",
      "acc for optim= 0.18265691574082757\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.004932285286486149\n",
      "Loss on test= 0.00775783509016037\n",
      "acc for Lsat= 0.16035221582507622 \n",
      "acc for Psat= 0.19946753329360767 \n",
      "acc for optim= 0.17736229237453385\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.005340040195733309\n",
      "Loss on test= 0.007270448841154575\n",
      "acc for Lsat= 0.16156877893706417 \n",
      "acc for Psat= 0.18655470993444248 \n",
      "acc for optim= 0.18025340165649006\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005243820138275623\n",
      "Loss on test= 0.007587565574795008\n",
      "acc for Lsat= 0.15130197717407412 \n",
      "acc for Psat= 0.1820271355828049 \n",
      "acc for optim= 0.17835683876392813\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.005299851298332214\n",
      "Loss on test= 0.0078058368526399136\n",
      "acc for Lsat= 0.14483756358686597 \n",
      "acc for Psat= 0.17015692209068697 \n",
      "acc for optim= 0.17696311424551225\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.005000291857868433\n",
      "Loss on test= 0.00788666121661663\n",
      "acc for Lsat= 0.15355155432375422 \n",
      "acc for Psat= 0.18274546701835132 \n",
      "acc for optim= 0.1765063568232123\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.005135491024702787\n",
      "Loss on test= 0.007850537076592445\n",
      "acc for Lsat= 0.1466547141687994 \n",
      "acc for Psat= 0.19632773611753737 \n",
      "acc for optim= 0.18131778744682975\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.005107210483402014\n",
      "Loss on test= 0.007407571654766798\n",
      "acc for Lsat= 0.15609099573348878 \n",
      "acc for Psat= 0.18535636508738104 \n",
      "acc for optim= 0.17684337609646972\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.005489255301654339\n",
      "Loss on test= 0.007527596782892942\n",
      "acc for Lsat= 0.15235863208978773 \n",
      "acc for Psat= 0.18783088298590822 \n",
      "acc for optim= 0.17528991852366327\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.005106465891003609\n",
      "Loss on test= 0.00808620173484087\n",
      "acc for Lsat= 0.15664174073245987 \n",
      "acc for Psat= 0.18134643509096587 \n",
      "acc for optim= 0.17398153215105938\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.00519506074488163\n",
      "Loss on test= 0.007934805005788803\n",
      "acc for Lsat= 0.15785376917280744 \n",
      "acc for Psat= 0.18138063834110832 \n",
      "acc for optim= 0.16765978486760477\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.005585945677012205\n",
      "Loss on test= 0.007707197219133377\n",
      "acc for Lsat= 0.1697882735498677 \n",
      "acc for Psat= 0.20209078106678044 \n",
      "acc for optim= 0.17416425387959042\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005360200069844723\n",
      "Loss on test= 0.007627272978425026\n",
      "acc for Lsat= 0.1537154884770375 \n",
      "acc for Psat= 0.17302652839437646 \n",
      "acc for optim= 0.1823142010701408\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.00535518117249012\n",
      "Loss on test= 0.007957310415804386\n",
      "acc for Lsat= 0.13545766058812095 \n",
      "acc for Psat= 0.17995105432150849 \n",
      "acc for optim= 0.17814515902599717\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.005225984379649162\n",
      "Loss on test= 0.007474436424672604\n",
      "acc for Lsat= 0.1520289112566388 \n",
      "acc for Psat= 0.18470391463314195 \n",
      "acc for optim= 0.17443168537508025\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.005290024448186159\n",
      "Loss on test= 0.007984037511050701\n",
      "acc for Lsat= 0.13759021647140904 \n",
      "acc for Psat= 0.17817418207364352 \n",
      "acc for optim= 0.17454453303257278\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.0053771985694766045\n",
      "Loss on test= 0.007449666038155556\n",
      "acc for Lsat= 0.16555374692037672 \n",
      "acc for Psat= 0.19104277963588323 \n",
      "acc for optim= 0.1892037518370179\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.005425978917628527\n",
      "Loss on test= 0.007136098574846983\n",
      "acc for Lsat= 0.15171985096149299 \n",
      "acc for Psat= 0.1808721202829534 \n",
      "acc for optim= 0.17901998725299892\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.005336531903594732\n",
      "Loss on test= 0.007869026623666286\n",
      "acc for Lsat= 0.15963883754457575 \n",
      "acc for Psat= 0.18852139156861383 \n",
      "acc for optim= 0.18117240459522704\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.005015427712351084\n",
      "Loss on test= 0.007809752132743597\n",
      "acc for Lsat= 0.14799230441739247 \n",
      "acc for Psat= 0.18592530802997928 \n",
      "acc for optim= 0.17804483610504024\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.005226472392678261\n",
      "Loss on test= 0.00777530437335372\n",
      "acc for Lsat= 0.14942125866729214 \n",
      "acc for Psat= 0.18088790892020296 \n",
      "acc for optim= 0.18617159038902353\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.0055144233629107475\n",
      "Loss on test= 0.007578935939818621\n",
      "acc for Lsat= 0.1503545633391248 \n",
      "acc for Psat= 0.1830212914794383 \n",
      "acc for optim= 0.18299334347553428\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.005201610736548901\n",
      "Loss on test= 0.008052741177380085\n",
      "acc for Lsat= 0.14266904528161176 \n",
      "acc for Psat= 0.1713899478793419 \n",
      "acc for optim= 0.18353109590386682\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.005190043244510889\n",
      "Loss on test= 0.008603044785559177\n",
      "acc for Lsat= 0.14825979623710736 \n",
      "acc for Psat= 0.17126003795162179 \n",
      "acc for optim= 0.1766367028483579\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.00526923593133688\n",
      "Loss on test= 0.007324960548430681\n",
      "acc for Lsat= 0.1508759064792625 \n",
      "acc for Psat= 0.18566275976262375 \n",
      "acc for optim= 0.17987589476683527\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.005067750811576843\n",
      "Loss on test= 0.007869738154113293\n",
      "acc for Lsat= 0.15165875015959723 \n",
      "acc for Psat= 0.17667235424100386 \n",
      "acc for optim= 0.18471669624322068\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.005302081815898418\n",
      "Loss on test= 0.007614475209265947\n",
      "acc for Lsat= 0.15193679010887728 \n",
      "acc for Psat= 0.15756195946004944 \n",
      "acc for optim= 0.1802727495250483\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.005175885744392872\n",
      "Loss on test= 0.007725216913968325\n",
      "acc for Lsat= 0.1494812286039528 \n",
      "acc for Psat= 0.19596519450529204 \n",
      "acc for optim= 0.1849014491285579\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.005187281873077154\n",
      "Loss on test= 0.007514506578445435\n",
      "acc for Lsat= 0.15283304828879438 \n",
      "acc for Psat= 0.17521180240895415 \n",
      "acc for optim= 0.1824917965112483\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.005482756998389959\n",
      "Loss on test= 0.007702231872826815\n",
      "acc for Lsat= 0.16109921845500585 \n",
      "acc for Psat= 0.20093910543545776 \n",
      "acc for optim= 0.1831952259002719\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.005137236323207617\n",
      "Loss on test= 0.0074520353227853775\n",
      "acc for Lsat= 0.14524065499026023 \n",
      "acc for Psat= 0.18769408495291365 \n",
      "acc for optim= 0.18022379494008806\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005379681475460529\n",
      "Loss on test= 0.008082708343863487\n",
      "acc for Lsat= 0.15201547269530014 \n",
      "acc for Psat= 0.18371693933426525 \n",
      "acc for optim= 0.17580534922308289\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.005470870994031429\n",
      "Loss on test= 0.007561573293060064\n",
      "acc for Lsat= 0.15014845311000455 \n",
      "acc for Psat= 0.1771357509823023 \n",
      "acc for optim= 0.17543957230146426\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.005275971721857786\n",
      "Loss on test= 0.0076140472665429115\n",
      "acc for Lsat= 0.1587061535975453 \n",
      "acc for Psat= 0.18028918191882187 \n",
      "acc for optim= 0.1791433800129243\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.005566968582570553\n",
      "Loss on test= 0.007644364144653082\n",
      "acc for Lsat= 0.1535524044284162 \n",
      "acc for Psat= 0.17855963438871453 \n",
      "acc for optim= 0.18167730910917285\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.00520480377599597\n",
      "Loss on test= 0.007741924840956926\n",
      "acc for Lsat= 0.14427891828131206 \n",
      "acc for Psat= 0.19561104073196833 \n",
      "acc for optim= 0.17335953634002316\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.005309821106493473\n",
      "Loss on test= 0.0076516252011060715\n",
      "acc for Lsat= 0.14756842842979212 \n",
      "acc for Psat= 0.18687660225655608 \n",
      "acc for optim= 0.1787558529950625\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.0049912165850400925\n",
      "Loss on test= 0.007439240347594023\n",
      "acc for Lsat= 0.15706879220956357 \n",
      "acc for Psat= 0.19511805592671602 \n",
      "acc for optim= 0.18039446375867138\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.005157109349966049\n",
      "Loss on test= 0.007708823308348656\n",
      "acc for Lsat= 0.14146712510378986 \n",
      "acc for Psat= 0.18316990884104897 \n",
      "acc for optim= 0.18026137473981313\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.005213583819568157\n",
      "Loss on test= 0.007831926457583904\n",
      "acc for Lsat= 0.15096717010944943 \n",
      "acc for Psat= 0.19460013208273402 \n",
      "acc for optim= 0.17132903742885452\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.005343331955373287\n",
      "Loss on test= 0.007870987989008427\n",
      "acc for Lsat= 0.15476117385281765 \n",
      "acc for Psat= 0.18243362237642077 \n",
      "acc for optim= 0.18298844003717826\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.005182900000363588\n",
      "Loss on test= 0.007437656633555889\n",
      "acc for Lsat= 0.14567405627638466 \n",
      "acc for Psat= 0.1796689718209787 \n",
      "acc for optim= 0.17310546741259789\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.005013016983866692\n",
      "Loss on test= 0.007337099406868219\n",
      "acc for Lsat= 0.1536708133178763 \n",
      "acc for Psat= 0.19331842498266 \n",
      "acc for optim= 0.17645505607494566\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.005166736431419849\n",
      "Loss on test= 0.007856359705328941\n",
      "acc for Lsat= 0.15266021617924885 \n",
      "acc for Psat= 0.19045337397437237 \n",
      "acc for optim= 0.1826559569434736\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005162486340850592\n",
      "Loss on test= 0.007864122278988361\n",
      "acc for Lsat= 0.15607306083691017 \n",
      "acc for Psat= 0.17436344593889308 \n",
      "acc for optim= 0.1721597016813829\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.005067034624516964\n",
      "Loss on test= 0.007554890587925911\n",
      "acc for Lsat= 0.15570377207520517 \n",
      "acc for Psat= 0.18315675871763532 \n",
      "acc for optim= 0.1777878382243216\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.0055373674258589745\n",
      "Loss on test= 0.007732924539595842\n",
      "acc for Lsat= 0.1484537896536077 \n",
      "acc for Psat= 0.17458680382715996 \n",
      "acc for optim= 0.18398257514879826\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.005223681218922138\n",
      "Loss on test= 0.00785970687866211\n",
      "acc for Lsat= 0.15746883300484205 \n",
      "acc for Psat= 0.19344689002275833 \n",
      "acc for optim= 0.1811815718542899\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.005036298185586929\n",
      "Loss on test= 0.007355649955570698\n",
      "acc for Lsat= 0.15713061446297272 \n",
      "acc for Psat= 0.21150376874109975 \n",
      "acc for optim= 0.17644881213176422\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.005058029666543007\n",
      "Loss on test= 0.007690819911658764\n",
      "acc for Lsat= 0.14946942125412743 \n",
      "acc for Psat= 0.19149149118647835 \n",
      "acc for optim= 0.17750092162426226\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.00524705508723855\n",
      "Loss on test= 0.007366382982581854\n",
      "acc for Lsat= 0.1575907848673285 \n",
      "acc for Psat= 0.1949840092069668 \n",
      "acc for optim= 0.1770882371034412\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.005515622906386852\n",
      "Loss on test= 0.007322436664253473\n",
      "acc for Lsat= 0.1642302094795789 \n",
      "acc for Psat= 0.1741102353606724 \n",
      "acc for optim= 0.175008320573099\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.005173441953957081\n",
      "Loss on test= 0.007852865383028984\n",
      "acc for Lsat= 0.1459672528716018 \n",
      "acc for Psat= 0.18118973567997884 \n",
      "acc for optim= 0.17975304695154307\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.005208264105021954\n",
      "Loss on test= 0.007272976916283369\n",
      "acc for Lsat= 0.14936859908849612 \n",
      "acc for Psat= 0.19040548962151602 \n",
      "acc for optim= 0.18265551340567773\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.005156931467354298\n",
      "Loss on test= 0.00743648037314415\n",
      "acc for Lsat= 0.13209674485909492 \n",
      "acc for Psat= 0.18491621307120276 \n",
      "acc for optim= 0.17893856856862245\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.0053147501312196255\n",
      "Loss on test= 0.007777245249599218\n",
      "acc for Lsat= 0.15768239281644097 \n",
      "acc for Psat= 0.18962602065647113 \n",
      "acc for optim= 0.18186593071663024\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.005137694533914328\n",
      "Loss on test= 0.008091829717159271\n",
      "acc for Lsat= 0.13957900899905162 \n",
      "acc for Psat= 0.1774316235011268 \n",
      "acc for optim= 0.1771822984385701\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.005239496938884258\n",
      "Loss on test= 0.0077751860953867435\n",
      "acc for Lsat= 0.15649610713838036 \n",
      "acc for Psat= 0.19819245225874912 \n",
      "acc for optim= 0.1857919711190215\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005310238339006901\n",
      "Loss on test= 0.0075248833745718\n",
      "acc for Lsat= 0.16122304755282116 \n",
      "acc for Psat= 0.18625541283371172 \n",
      "acc for optim= 0.18419337002570038\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.005469446070492268\n",
      "Loss on test= 0.007625242229551077\n",
      "acc for Lsat= 0.15351554036434342 \n",
      "acc for Psat= 0.18739212152412635 \n",
      "acc for optim= 0.17704611848677188\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.005031088832765818\n",
      "Loss on test= 0.007449911441653967\n",
      "acc for Lsat= 0.16432886380916004 \n",
      "acc for Psat= 0.19252686844375289 \n",
      "acc for optim= 0.17903307989987804\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005206515081226826\n",
      "Loss on test= 0.008240753784775734\n",
      "acc for Lsat= 0.1570645681542314 \n",
      "acc for Psat= 0.1812379934457627 \n",
      "acc for optim= 0.17749875171861962\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005230826325714588\n",
      "Loss on test= 0.007782256696373224\n",
      "acc for Lsat= 0.14694472986414692 \n",
      "acc for Psat= 0.18466111690618983 \n",
      "acc for optim= 0.17793312307340323\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.005187092814594507\n",
      "Loss on test= 0.00742457015439868\n",
      "acc for Lsat= 0.15406944678894047 \n",
      "acc for Psat= 0.18926092290059954 \n",
      "acc for optim= 0.18103034500162438\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.005254604388028383\n",
      "Loss on test= 0.007797327823936939\n",
      "acc for Lsat= 0.1557547694245796 \n",
      "acc for Psat= 0.19119677729980988 \n",
      "acc for optim= 0.17452055535080735\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.0054612490348517895\n",
      "Loss on test= 0.007877692580223083\n",
      "acc for Lsat= 0.1527222488793071 \n",
      "acc for Psat= 0.1777324413720396 \n",
      "acc for optim= 0.17773631919608604\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.005479191429913044\n",
      "Loss on test= 0.007912100292742252\n",
      "acc for Lsat= 0.15313954608096 \n",
      "acc for Psat= 0.18562113556583396 \n",
      "acc for optim= 0.17635489434059176\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.005570866167545319\n",
      "Loss on test= 0.007552728522568941\n",
      "acc for Lsat= 0.15470737629287618 \n",
      "acc for Psat= 0.18159923905537265 \n",
      "acc for optim= 0.1771073872179602\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005562673322856426\n",
      "Loss on test= 0.007779815699905157\n",
      "acc for Lsat= 0.15047911905600558 \n",
      "acc for Psat= 0.18674388037694878 \n",
      "acc for optim= 0.1863786476429506\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.005055156070739031\n",
      "Loss on test= 0.007486181799322367\n",
      "acc for Lsat= 0.15387201701351977 \n",
      "acc for Psat= 0.1842972714667682 \n",
      "acc for optim= 0.17664999009346682\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.005092274863272905\n",
      "Loss on test= 0.008230824023485184\n",
      "acc for Lsat= 0.15209942433628115 \n",
      "acc for Psat= 0.19243877286694516 \n",
      "acc for optim= 0.1796870177335938\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.00536180566996336\n",
      "Loss on test= 0.007669173646718264\n",
      "acc for Lsat= 0.14710616058833156 \n",
      "acc for Psat= 0.18558993513264588 \n",
      "acc for optim= 0.17932952952148493\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.00510495575144887\n",
      "Loss on test= 0.0077824373729527\n",
      "acc for Lsat= 0.1489831807496423 \n",
      "acc for Psat= 0.19085223356387807 \n",
      "acc for optim= 0.1761950655582697\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.005313565023243427\n",
      "Loss on test= 0.007940087467432022\n",
      "acc for Lsat= 0.16251405279236067 \n",
      "acc for Psat= 0.19565755345895133 \n",
      "acc for optim= 0.18172424843718038\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.0052550677210092545\n",
      "Loss on test= 0.00756539823487401\n",
      "acc for Lsat= 0.15763992828099424 \n",
      "acc for Psat= 0.18034107182499357 \n",
      "acc for optim= 0.17315584774449713\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.005128099583089352\n",
      "Loss on test= 0.007818852551281452\n",
      "acc for Lsat= 0.14473169412956283 \n",
      "acc for Psat= 0.19285979835492115 \n",
      "acc for optim= 0.19086969085953764\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.0052166772074997425\n",
      "Loss on test= 0.00787428580224514\n",
      "acc for Lsat= 0.14814703976048432 \n",
      "acc for Psat= 0.17553239881927452 \n",
      "acc for optim= 0.1781626911772812\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.004955317359417677\n",
      "Loss on test= 0.00768774701282382\n",
      "acc for Lsat= 0.15182242227741075 \n",
      "acc for Psat= 0.1787359745029864 \n",
      "acc for optim= 0.1816918370806322\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.005513015203177929\n",
      "Loss on test= 0.00799793004989624\n",
      "acc for Lsat= 0.14797347493099478 \n",
      "acc for Psat= 0.19670518569907816 \n",
      "acc for optim= 0.18367470932676414\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.005270420573651791\n",
      "Loss on test= 0.00823428574949503\n",
      "acc for Lsat= 0.15027578143254372 \n",
      "acc for Psat= 0.1791326242583025 \n",
      "acc for optim= 0.17734245253053157\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.005066428799182177\n",
      "Loss on test= 0.007839175872504711\n",
      "acc for Lsat= 0.14655707909737056 \n",
      "acc for Psat= 0.18583086969933976 \n",
      "acc for optim= 0.17291835602716404\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.005155512131750584\n",
      "Loss on test= 0.007636576890945435\n",
      "acc for Lsat= 0.1479432809914722 \n",
      "acc for Psat= 0.19369708317003717 \n",
      "acc for optim= 0.18506656075850678\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.005607950501143932\n",
      "Loss on test= 0.007554229348897934\n",
      "acc for Lsat= 0.1615933133178528 \n",
      "acc for Psat= 0.19469212422712293 \n",
      "acc for optim= 0.185500854521715\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.005181526765227318\n",
      "Loss on test= 0.0076365238055586815\n",
      "acc for Lsat= 0.15727865609109448 \n",
      "acc for Psat= 0.18660638489470374 \n",
      "acc for optim= 0.17327882511842782\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005015713162720203\n",
      "Loss on test= 0.008063474670052528\n",
      "acc for Lsat= 0.17125836280689835 \n",
      "acc for Psat= 0.19377620694700812 \n",
      "acc for optim= 0.17848510480527366\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.005353222135454416\n",
      "Loss on test= 0.0075998189859092236\n",
      "acc for Lsat= 0.14508720717095144 \n",
      "acc for Psat= 0.18445573990523326 \n",
      "acc for optim= 0.18476214948736253\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.005414559505879879\n",
      "Loss on test= 0.00765779847279191\n",
      "acc for Lsat= 0.14473442530152617 \n",
      "acc for Psat= 0.18795302260235777 \n",
      "acc for optim= 0.18076790340524357\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.005170055665075779\n",
      "Loss on test= 0.007888988591730595\n",
      "acc for Lsat= 0.15738562120107522 \n",
      "acc for Psat= 0.17751664693284108 \n",
      "acc for optim= 0.1776370403646457\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.005117989145219326\n",
      "Loss on test= 0.007624301128089428\n",
      "acc for Lsat= 0.1609191230471536 \n",
      "acc for Psat= 0.1771626252606826 \n",
      "acc for optim= 0.17425619632169817\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.005844014696776867\n",
      "Loss on test= 0.007810304872691631\n",
      "acc for Lsat= 0.16703900616219053 \n",
      "acc for Psat= 0.17177951286754906 \n",
      "acc for optim= 0.1801542853677004\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.005194780416786671\n",
      "Loss on test= 0.007725575007498264\n",
      "acc for Lsat= 0.15672009861980352 \n",
      "acc for Psat= 0.18258330312425836 \n",
      "acc for optim= 0.18371043425496117\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.005323176272213459\n",
      "Loss on test= 0.007568791043013334\n",
      "acc for Lsat= 0.15788358239038106 \n",
      "acc for Psat= 0.16679635464450437 \n",
      "acc for optim= 0.18340858792042605\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.005151502788066864\n",
      "Loss on test= 0.007900903932750225\n",
      "acc for Lsat= 0.16088210116751248 \n",
      "acc for Psat= 0.17673665980892408 \n",
      "acc for optim= 0.17929087045147335\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.004974733106791973\n",
      "Loss on test= 0.007678474299609661\n",
      "acc for Lsat= 0.14426242886874519 \n",
      "acc for Psat= 0.1762731214539271 \n",
      "acc for optim= 0.1737748024435084\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.005089855287224054\n",
      "Loss on test= 0.007232981733977795\n",
      "acc for Lsat= 0.16342067649257827 \n",
      "acc for Psat= 0.188112578300409 \n",
      "acc for optim= 0.18464381828530574\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.005346058867871761\n",
      "Loss on test= 0.00804296787828207\n",
      "acc for Lsat= 0.1431716076083115 \n",
      "acc for Psat= 0.17126879077099386 \n",
      "acc for optim= 0.1830112661757949\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.005175584461539984\n",
      "Loss on test= 0.007297152187675238\n",
      "acc for Lsat= 0.1542942440473154 \n",
      "acc for Psat= 0.18145567890424585 \n",
      "acc for optim= 0.17987646153921902\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.005058237351477146\n",
      "Loss on test= 0.008126887492835522\n",
      "acc for Lsat= 0.1440989272086881 \n",
      "acc for Psat= 0.1741619664231949 \n",
      "acc for optim= 0.18374048131858606\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.005341081880033016\n",
      "Loss on test= 0.007898231968283653\n",
      "acc for Lsat= 0.152643958256641 \n",
      "acc for Psat= 0.18360590977273636 \n",
      "acc for optim= 0.17724517760259198\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.005236322991549969\n",
      "Loss on test= 0.008099660277366638\n",
      "acc for Lsat= 0.14386121333039034 \n",
      "acc for Psat= 0.17800648626833238 \n",
      "acc for optim= 0.18076002786840603\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.005294544622302055\n",
      "Loss on test= 0.007831620052456856\n",
      "acc for Lsat= 0.15735531168699754 \n",
      "acc for Psat= 0.18632844116645636 \n",
      "acc for optim= 0.17996043852267055\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.005146462004631758\n",
      "Loss on test= 0.007509415969252586\n",
      "acc for Lsat= 0.16349277639299722 \n",
      "acc for Psat= 0.1817726415845367 \n",
      "acc for optim= 0.1827958184462346\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.005149160977452993\n",
      "Loss on test= 0.007654549553990364\n",
      "acc for Lsat= 0.15261382471205148 \n",
      "acc for Psat= 0.2024547666575584 \n",
      "acc for optim= 0.18044566408242957\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.005134194623678923\n",
      "Loss on test= 0.008394810371100903\n",
      "acc for Lsat= 0.15591617237249786 \n",
      "acc for Psat= 0.18066165267211218 \n",
      "acc for optim= 0.18203729231704455\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.005788277368992567\n",
      "Loss on test= 0.007627733983099461\n",
      "acc for Lsat= 0.1530141503480931 \n",
      "acc for Psat= 0.1933689628811706 \n",
      "acc for optim= 0.18404493637986052\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.005242565646767616\n",
      "Loss on test= 0.007946336641907692\n",
      "acc for Lsat= 0.15567824920242437 \n",
      "acc for Psat= 0.18402598427234554 \n",
      "acc for optim= 0.18152046231872623\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005150975193828344\n",
      "Loss on test= 0.008128805086016655\n",
      "acc for Lsat= 0.15566239246075636 \n",
      "acc for Psat= 0.19979697817919365 \n",
      "acc for optim= 0.18039741530273964\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.00540566723793745\n",
      "Loss on test= 0.007737372536212206\n",
      "acc for Lsat= 0.1449325115512484 \n",
      "acc for Psat= 0.19284740900429972 \n",
      "acc for optim= 0.18137385042414803\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.0052162231877446175\n",
      "Loss on test= 0.007863063365221024\n",
      "acc for Lsat= 0.16347319609409228 \n",
      "acc for Psat= 0.19363416924339827 \n",
      "acc for optim= 0.18373570947251358\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.005362044554203749\n",
      "Loss on test= 0.007691027130931616\n",
      "acc for Lsat= 0.15611392096769003 \n",
      "acc for Psat= 0.18889962097975332 \n",
      "acc for optim= 0.17812061090175957\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.005346117541193962\n",
      "Loss on test= 0.007379183080047369\n",
      "acc for Lsat= 0.15338112286198502 \n",
      "acc for Psat= 0.18436240912357835 \n",
      "acc for optim= 0.17897948331989683\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.005095120053738356\n",
      "Loss on test= 0.007999029941856861\n",
      "acc for Lsat= 0.1491955583809315 \n",
      "acc for Psat= 0.18094403727746333 \n",
      "acc for optim= 0.1838248296983201\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.005186343565583229\n",
      "Loss on test= 0.007955247536301613\n",
      "acc for Lsat= 0.16718443658071203 \n",
      "acc for Psat= 0.18716976034558058 \n",
      "acc for optim= 0.18194647479180215\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.0052305785939097404\n",
      "Loss on test= 0.008176124654710293\n",
      "acc for Lsat= 0.14850397590570702 \n",
      "acc for Psat= 0.1724207048577287 \n",
      "acc for optim= 0.18290580983128643\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.0050187427550554276\n",
      "Loss on test= 0.007562670391052961\n",
      "acc for Lsat= 0.14916941527521513 \n",
      "acc for Psat= 0.17693397625784588 \n",
      "acc for optim= 0.17471755297098798\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.0054161567240953445\n",
      "Loss on test= 0.007418907713145018\n",
      "acc for Lsat= 0.14858704747146206 \n",
      "acc for Psat= 0.17773657407665044 \n",
      "acc for optim= 0.17869499021879642\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.005516943987458944\n",
      "Loss on test= 0.007277979515492916\n",
      "acc for Lsat= 0.1594457144822284 \n",
      "acc for Psat= 0.19579161209269946 \n",
      "acc for optim= 0.1806355089978811\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.005179843865334988\n",
      "Loss on test= 0.008063218556344509\n",
      "acc for Lsat= 0.16065315603217506 \n",
      "acc for Psat= 0.1885715796654189 \n",
      "acc for optim= 0.18798570750647636\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.0053765857592225075\n",
      "Loss on test= 0.007621139753609896\n",
      "acc for Lsat= 0.14706548953220844 \n",
      "acc for Psat= 0.17372433021721873 \n",
      "acc for optim= 0.1816200115344846\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005053855013102293\n",
      "Loss on test= 0.00792330875992775\n",
      "acc for Lsat= 0.15735578283850776 \n",
      "acc for Psat= 0.19018618549252708 \n",
      "acc for optim= 0.17682007795169216\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005198146216571331\n",
      "Loss on test= 0.007937997579574585\n",
      "acc for Lsat= 0.16582866855744333 \n",
      "acc for Psat= 0.19382897602330051 \n",
      "acc for optim= 0.17797228072852958\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.005285725928843021\n",
      "Loss on test= 0.007445562165230513\n",
      "acc for Lsat= 0.15588474855033038 \n",
      "acc for Psat= 0.1918050393449299 \n",
      "acc for optim= 0.17639901210844028\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.005575900431722403\n",
      "Loss on test= 0.007635837886482477\n",
      "acc for Lsat= 0.1592014258693079 \n",
      "acc for Psat= 0.17745010767391592 \n",
      "acc for optim= 0.1767054881917725\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.00533545296639204\n",
      "Loss on test= 0.007635883521288633\n",
      "acc for Lsat= 0.1562308909348594 \n",
      "acc for Psat= 0.18761659881451212 \n",
      "acc for optim= 0.18542543173114936\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.005051357671618462\n",
      "Loss on test= 0.007746096234768629\n",
      "acc for Lsat= 0.14318406877153722 \n",
      "acc for Psat= 0.1714321516450403 \n",
      "acc for optim= 0.17626502305941014\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.0052994294092059135\n",
      "Loss on test= 0.007694052066653967\n",
      "acc for Lsat= 0.15419937371726952 \n",
      "acc for Psat= 0.18984944871407322 \n",
      "acc for optim= 0.18061646549403285\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.005058895330876112\n",
      "Loss on test= 0.007409987039864063\n",
      "acc for Lsat= 0.15022628370807964 \n",
      "acc for Psat= 0.19048391017599078 \n",
      "acc for optim= 0.1765039099158994\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.005237098783254623\n",
      "Loss on test= 0.007684275973588228\n",
      "acc for Lsat= 0.14962596127626937 \n",
      "acc for Psat= 0.19452918335608374 \n",
      "acc for optim= 0.18192832463899947\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.005201407708227634\n",
      "Loss on test= 0.007846649736166\n",
      "acc for Lsat= 0.14660916503822502 \n",
      "acc for Psat= 0.17620914765914183 \n",
      "acc for optim= 0.1825787076821024\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005072546191513538\n",
      "Loss on test= 0.007632202468812466\n",
      "acc for Lsat= 0.15632145752763896 \n",
      "acc for Psat= 0.18689444980934286 \n",
      "acc for optim= 0.1793995302285022\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.00537188071757555\n",
      "Loss on test= 0.008277936838567257\n",
      "acc for Lsat= 0.15591820743274645 \n",
      "acc for Psat= 0.17848181379386452 \n",
      "acc for optim= 0.18202492246179094\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.005373304709792137\n",
      "Loss on test= 0.007545999716967344\n",
      "acc for Lsat= 0.1471065847389209 \n",
      "acc for Psat= 0.19123007817212712 \n",
      "acc for optim= 0.17236783820009774\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.005301638972014189\n",
      "Loss on test= 0.007586908992379904\n",
      "acc for Lsat= 0.16317300810268698 \n",
      "acc for Psat= 0.1812453426827188 \n",
      "acc for optim= 0.18377208023133582\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.005277021788060665\n",
      "Loss on test= 0.008061064407229424\n",
      "acc for Lsat= 0.16722145583013026 \n",
      "acc for Psat= 0.19362986386413916 \n",
      "acc for optim= 0.18255341720068827\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.0052133118733763695\n",
      "Loss on test= 0.007733751554042101\n",
      "acc for Lsat= 0.1462196963814423 \n",
      "acc for Psat= 0.19293927294183064 \n",
      "acc for optim= 0.17426175017751463\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.005226714536547661\n",
      "Loss on test= 0.007887559942901134\n",
      "acc for Lsat= 0.16310626711442563 \n",
      "acc for Psat= 0.19514151381187478 \n",
      "acc for optim= 0.18884975310781452\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.005221739411354065\n",
      "Loss on test= 0.00783105194568634\n",
      "acc for Lsat= 0.15905707753015316 \n",
      "acc for Psat= 0.18556256330232335 \n",
      "acc for optim= 0.17716170421717536\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.00545432697981596\n",
      "Loss on test= 0.008259434252977371\n",
      "acc for Lsat= 0.1487226198823382 \n",
      "acc for Psat= 0.19300536373878263 \n",
      "acc for optim= 0.18255870499634794\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.0051607307977974415\n",
      "Loss on test= 0.007658602204173803\n",
      "acc for Lsat= 0.14483664517207873 \n",
      "acc for Psat= 0.18315464553621705 \n",
      "acc for optim= 0.17838978620749882\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.0052513303235173225\n",
      "Loss on test= 0.007632701192051172\n",
      "acc for Lsat= 0.14565852895955417 \n",
      "acc for Psat= 0.1892766557600956 \n",
      "acc for optim= 0.17576020198652795\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.005523585714399815\n",
      "Loss on test= 0.007350721396505833\n",
      "acc for Lsat= 0.14815398564363724 \n",
      "acc for Psat= 0.17095944281232345 \n",
      "acc for optim= 0.18388130649557857\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.004976196680217981\n",
      "Loss on test= 0.00813303142786026\n",
      "acc for Lsat= 0.15880826550964544 \n",
      "acc for Psat= 0.186207559676464 \n",
      "acc for optim= 0.18063527171702323\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.005090391729027033\n",
      "Loss on test= 0.007800230290740728\n",
      "acc for Lsat= 0.1524085081891498 \n",
      "acc for Psat= 0.18810579652256776 \n",
      "acc for optim= 0.17690754142689105\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.005134461913257837\n",
      "Loss on test= 0.007657622452825308\n",
      "acc for Lsat= 0.1545433224606343 \n",
      "acc for Psat= 0.19704484866367133 \n",
      "acc for optim= 0.17789299762197083\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.0051641566678881645\n",
      "Loss on test= 0.008196787908673286\n",
      "acc for Lsat= 0.15477395067793892 \n",
      "acc for Psat= 0.17473083126070513 \n",
      "acc for optim= 0.1781882205663142\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.005386651959270239\n",
      "Loss on test= 0.0072044371627271175\n",
      "acc for Lsat= 0.14904172232023394 \n",
      "acc for Psat= 0.17985514222365637 \n",
      "acc for optim= 0.18372513112558633\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.0050413962453603745\n",
      "Loss on test= 0.008040440268814564\n",
      "acc for Lsat= 0.14587470615936238 \n",
      "acc for Psat= 0.20409851300274404 \n",
      "acc for optim= 0.18137734518825366\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.005217663012444973\n",
      "Loss on test= 0.007586623076349497\n",
      "acc for Lsat= 0.15484747771397003 \n",
      "acc for Psat= 0.19132133244964308 \n",
      "acc for optim= 0.1756617776753732\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.005287391133606434\n",
      "Loss on test= 0.007598010823130608\n",
      "acc for Lsat= 0.14670015530871036 \n",
      "acc for Psat= 0.16967038950180544 \n",
      "acc for optim= 0.18314587556237935\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.00519826402887702\n",
      "Loss on test= 0.00778489513322711\n",
      "acc for Lsat= 0.15612875278752877 \n",
      "acc for Psat= 0.17403364596305393 \n",
      "acc for optim= 0.18533566227625506\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.005172859411686659\n",
      "Loss on test= 0.007575751282274723\n",
      "acc for Lsat= 0.160867771825402 \n",
      "acc for Psat= 0.17419022425596953 \n",
      "acc for optim= 0.1759580585531381\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.005138419568538666\n",
      "Loss on test= 0.007605229038745165\n",
      "acc for Lsat= 0.14913787228288128 \n",
      "acc for Psat= 0.19022736277414073 \n",
      "acc for optim= 0.17545910300457943\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.005512879695743322\n",
      "Loss on test= 0.007778352126479149\n",
      "acc for Lsat= 0.14690325033863372 \n",
      "acc for Psat= 0.19373294752664658 \n",
      "acc for optim= 0.18032920640038297\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.0050001079216599464\n",
      "Loss on test= 0.008071745745837688\n",
      "acc for Lsat= 0.1584774161022458 \n",
      "acc for Psat= 0.17865895652403047 \n",
      "acc for optim= 0.18011625648063959\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005645992234349251\n",
      "Loss on test= 0.007678419817239046\n",
      "acc for Lsat= 0.15398979819910297 \n",
      "acc for Psat= 0.18748260497451438 \n",
      "acc for optim= 0.18400369319744164\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.004912056028842926\n",
      "Loss on test= 0.007408055942505598\n",
      "acc for Lsat= 0.15376526949660982 \n",
      "acc for Psat= 0.17549959379420083 \n",
      "acc for optim= 0.1854279508516498\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.005402605049312115\n",
      "Loss on test= 0.0077659692615270615\n",
      "acc for Lsat= 0.15527343475441144 \n",
      "acc for Psat= 0.17095733767062365 \n",
      "acc for optim= 0.18223495736057854\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.005048319697380066\n",
      "Loss on test= 0.007358405739068985\n",
      "acc for Lsat= 0.14263152796736933 \n",
      "acc for Psat= 0.19055246921279087 \n",
      "acc for optim= 0.18285230831791777\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.005365136079490185\n",
      "Loss on test= 0.007640897296369076\n",
      "acc for Lsat= 0.1571313704326787 \n",
      "acc for Psat= 0.19691962620737719 \n",
      "acc for optim= 0.1829957064624769\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.0050560226663947105\n",
      "Loss on test= 0.007566857151687145\n",
      "acc for Lsat= 0.15143680037316565 \n",
      "acc for Psat= 0.18400313630165746 \n",
      "acc for optim= 0.17634450120347567\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.004995348397642374\n",
      "Loss on test= 0.007734997663646936\n",
      "acc for Lsat= 0.15377091131133475 \n",
      "acc for Psat= 0.1861244202732704 \n",
      "acc for optim= 0.17315931465556905\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.00522299250587821\n",
      "Loss on test= 0.007863132283091545\n",
      "acc for Lsat= 0.15288863221152885 \n",
      "acc for Psat= 0.1734247323684299 \n",
      "acc for optim= 0.1881674572761499\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.00544388871639967\n",
      "Loss on test= 0.007649431005120277\n",
      "acc for Lsat= 0.1524823415520616 \n",
      "acc for Psat= 0.1909546249193048 \n",
      "acc for optim= 0.18013542159923285\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.005244997330009937\n",
      "Loss on test= 0.007925770245492458\n",
      "acc for Lsat= 0.15981661059710456 \n",
      "acc for Psat= 0.19586336632716264 \n",
      "acc for optim= 0.18097613776812604\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.004965913016349077\n",
      "Loss on test= 0.00815548375248909\n",
      "acc for Lsat= 0.14663404670437097 \n",
      "acc for Psat= 0.18385500077341424 \n",
      "acc for optim= 0.18203169201466363\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.0053531029261648655\n",
      "Loss on test= 0.008055990561842918\n",
      "acc for Lsat= 0.15540092071541203 \n",
      "acc for Psat= 0.18947932093450037 \n",
      "acc for optim= 0.18206849603066375\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.005317115690559149\n",
      "Loss on test= 0.007787201087921858\n",
      "acc for Lsat= 0.1629348552325878 \n",
      "acc for Psat= 0.18902595278207732 \n",
      "acc for optim= 0.18109790661074526\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.005763599183410406\n",
      "Loss on test= 0.00753028504550457\n",
      "acc for Lsat= 0.1495792661022517 \n",
      "acc for Psat= 0.1789484759300306 \n",
      "acc for optim= 0.17442142180678602\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005148189142346382\n",
      "Loss on test= 0.00747043127194047\n",
      "acc for Lsat= 0.17087867124174094 \n",
      "acc for Psat= 0.18759963787241923 \n",
      "acc for optim= 0.18198600403809936\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.005162573419511318\n",
      "Loss on test= 0.0076198093593120575\n",
      "acc for Lsat= 0.14385960735075298 \n",
      "acc for Psat= 0.19227269657956222 \n",
      "acc for optim= 0.18319645130503007\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.005155713297426701\n",
      "Loss on test= 0.008173302747309208\n",
      "acc for Lsat= 0.1535392202944571 \n",
      "acc for Psat= 0.18336121274938913 \n",
      "acc for optim= 0.17905473834453303\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.005178079940378666\n",
      "Loss on test= 0.007411361206322908\n",
      "acc for Lsat= 0.15600775971011063 \n",
      "acc for Psat= 0.18605372805575857 \n",
      "acc for optim= 0.1799554921011327\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.005220439285039902\n",
      "Loss on test= 0.007760775741189718\n",
      "acc for Lsat= 0.15666772385593503 \n",
      "acc for Psat= 0.17652991425788 \n",
      "acc for optim= 0.17302233962968114\n",
      "Fold 3\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.10144132375717163\n",
      "Loss on test= 0.04102899879217148\n",
      "acc for Lsat= 0.7569106958219428 \n",
      "acc for Psat= 0.9546269159153348 \n",
      "acc for optim= 0.235779369034667\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.03395834565162659\n",
      "Loss on test= 0.027079636231064796\n",
      "acc for Lsat= 0.5418789591228009 \n",
      "acc for Psat= 0.7483384442103447 \n",
      "acc for optim= 0.22456985911675043\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.024639548733830452\n",
      "Loss on test= 0.024796687066555023\n",
      "acc for Lsat= 0.49010743020220704 \n",
      "acc for Psat= 0.5585802707401272 \n",
      "acc for optim= 0.2513242022157265\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.022376494482159615\n",
      "Loss on test= 0.02423919178545475\n",
      "acc for Lsat= 0.4142081236920976 \n",
      "acc for Psat= 0.6704072665155972 \n",
      "acc for optim= 0.2232931431879091\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.02096632868051529\n",
      "Loss on test= 0.02223588526248932\n",
      "acc for Lsat= 0.5229931332554562 \n",
      "acc for Psat= 0.5375406875839976 \n",
      "acc for optim= 0.2504427725685852\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.022427041083574295\n",
      "Loss on test= 0.023306183516979218\n",
      "acc for Lsat= 0.46470636686073524 \n",
      "acc for Psat= 0.6383453781202199 \n",
      "acc for optim= 0.2507322891004628\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.02040547877550125\n",
      "Loss on test= 0.020657822489738464\n",
      "acc for Lsat= 0.5018229451374013 \n",
      "acc for Psat= 0.4751914675126604 \n",
      "acc for optim= 0.20983072093489474\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.020877240225672722\n",
      "Loss on test= 0.02021961286664009\n",
      "acc for Lsat= 0.5947592365860817 \n",
      "acc for Psat= 0.41284774186902634 \n",
      "acc for optim= 0.20238437032953027\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.01884765364229679\n",
      "Loss on test= 0.018914902582764626\n",
      "acc for Lsat= 0.4127623698876438 \n",
      "acc for Psat= 0.4588685863296364 \n",
      "acc for optim= 0.20822110578997946\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.018311072140932083\n",
      "Loss on test= 0.016955409198999405\n",
      "acc for Lsat= 0.3433807696196724 \n",
      "acc for Psat= 0.5257053540415535 \n",
      "acc for optim= 0.1996124013590428\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.01629057712852955\n",
      "Loss on test= 0.01621854119002819\n",
      "acc for Lsat= 0.3508561498514132 \n",
      "acc for Psat= 0.37389213996557674 \n",
      "acc for optim= 0.1991656130401143\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.015409725718200207\n",
      "Loss on test= 0.015877678990364075\n",
      "acc for Lsat= 0.3530526835914152 \n",
      "acc for Psat= 0.3973009283387209 \n",
      "acc for optim= 0.20916401382047134\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.01584724895656109\n",
      "Loss on test= 0.01587211713194847\n",
      "acc for Lsat= 0.37161318912632674 \n",
      "acc for Psat= 0.4657457848811392 \n",
      "acc for optim= 0.1980634490889688\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.016030797734856606\n",
      "Loss on test= 0.01520618051290512\n",
      "acc for Lsat= 0.32668572544448504 \n",
      "acc for Psat= 0.4384981181575596 \n",
      "acc for optim= 0.20147330139345704\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.01579996943473816\n",
      "Loss on test= 0.01642950065433979\n",
      "acc for Lsat= 0.34674407651102346 \n",
      "acc for Psat= 0.4517032548724139 \n",
      "acc for optim= 0.20980529392435843\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.016143450513482094\n",
      "Loss on test= 0.016161685809493065\n",
      "acc for Lsat= 0.43666179144046974 \n",
      "acc for Psat= 0.3437167233970688 \n",
      "acc for optim= 0.197747049828205\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.01555570401251316\n",
      "Loss on test= 0.014559727162122726\n",
      "acc for Lsat= 0.2925058625012514 \n",
      "acc for Psat= 0.33591311391610956 \n",
      "acc for optim= 0.2221117726457496\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.014886388555169106\n",
      "Loss on test= 0.016628941521048546\n",
      "acc for Lsat= 0.3285948627101654 \n",
      "acc for Psat= 0.4810346378948631 \n",
      "acc for optim= 0.20830614860035998\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.01568223536014557\n",
      "Loss on test= 0.018349729478359222\n",
      "acc for Lsat= 0.3130051844272396 \n",
      "acc for Psat= 0.589625374772815 \n",
      "acc for optim= 0.20115124985163452\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.015038986690342426\n",
      "Loss on test= 0.01777522638440132\n",
      "acc for Lsat= 0.4103167261287081 \n",
      "acc for Psat= 0.4561080409929569 \n",
      "acc for optim= 0.22001226371065685\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.016613785177469254\n",
      "Loss on test= 0.016305238008499146\n",
      "acc for Lsat= 0.3666553351051006 \n",
      "acc for Psat= 0.3596641489121391 \n",
      "acc for optim= 0.19217103680602435\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.013676335103809834\n",
      "Loss on test= 0.014584594406187534\n",
      "acc for Lsat= 0.3176595353528086 \n",
      "acc for Psat= 0.4205323322141757 \n",
      "acc for optim= 0.1965089015022386\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.013370809145271778\n",
      "Loss on test= 0.012755240313708782\n",
      "acc for Lsat= 0.38220730991003515 \n",
      "acc for Psat= 0.3397500612461447 \n",
      "acc for optim= 0.18853477829290538\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.012719365768134594\n",
      "Loss on test= 0.013102728873491287\n",
      "acc for Lsat= 0.36433552309382156 \n",
      "acc for Psat= 0.3145239698498311 \n",
      "acc for optim= 0.2033711831327757\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.0129252253100276\n",
      "Loss on test= 0.013101333752274513\n",
      "acc for Lsat= 0.27809299784712493 \n",
      "acc for Psat= 0.37540645020952845 \n",
      "acc for optim= 0.1963050134170831\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.012354963459074497\n",
      "Loss on test= 0.01308095920830965\n",
      "acc for Lsat= 0.2629889553855555 \n",
      "acc for Psat= 0.38861424664004907 \n",
      "acc for optim= 0.19532633814941633\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.012005778029561043\n",
      "Loss on test= 0.023641536012291908\n",
      "acc for Lsat= 0.33649524183577445 \n",
      "acc for Psat= 0.7127806096917904 \n",
      "acc for optim= 0.19589553632559714\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.018429499119520187\n",
      "Loss on test= 0.015143541619181633\n",
      "acc for Lsat= 0.3722749520439586 \n",
      "acc for Psat= 0.3692564056682416 \n",
      "acc for optim= 0.1895278025700016\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.013926835730671883\n",
      "Loss on test= 0.011926380917429924\n",
      "acc for Lsat= 0.314796781362813 \n",
      "acc for Psat= 0.33797062001130007 \n",
      "acc for optim= 0.1911079070702592\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.01224470417946577\n",
      "Loss on test= 0.011150474660098553\n",
      "acc for Lsat= 0.2796839912093748 \n",
      "acc for Psat= 0.29847764878564315 \n",
      "acc for optim= 0.19226575700869616\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.012626590207219124\n",
      "Loss on test= 0.01322221290320158\n",
      "acc for Lsat= 0.2854913577208387 \n",
      "acc for Psat= 0.3593587799721539 \n",
      "acc for optim= 0.19471094553372212\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.01659717597067356\n",
      "Loss on test= 0.014348993077874184\n",
      "acc for Lsat= 0.34532688604562817 \n",
      "acc for Psat= 0.39504482801206847 \n",
      "acc for optim= 0.19809893504029416\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.013719280250370502\n",
      "Loss on test= 0.013433975167572498\n",
      "acc for Lsat= 0.2700296736887244 \n",
      "acc for Psat= 0.3625576334631406 \n",
      "acc for optim= 0.19795904648771745\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.012028863653540611\n",
      "Loss on test= 0.013562574982643127\n",
      "acc for Lsat= 0.2716295438551451 \n",
      "acc for Psat= 0.4528352519541647 \n",
      "acc for optim= 0.1904094545985572\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.012440549209713936\n",
      "Loss on test= 0.013689669780433178\n",
      "acc for Lsat= 0.34096299473150465 \n",
      "acc for Psat= 0.3216346529951762 \n",
      "acc for optim= 0.21183468861138968\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.012151604518294334\n",
      "Loss on test= 0.013324905186891556\n",
      "acc for Lsat= 0.26640386946192085 \n",
      "acc for Psat= 0.38754701934197583 \n",
      "acc for optim= 0.1968679827521555\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.01267736591398716\n",
      "Loss on test= 0.01208316721022129\n",
      "acc for Lsat= 0.2525711518669163 \n",
      "acc for Psat= 0.34033722299013713 \n",
      "acc for optim= 0.20083498713869571\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.011529400013387203\n",
      "Loss on test= 0.01289954874664545\n",
      "acc for Lsat= 0.25157381652197874 \n",
      "acc for Psat= 0.3748598686385075 \n",
      "acc for optim= 0.20564456655468302\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.011779815889894962\n",
      "Loss on test= 0.013880046084523201\n",
      "acc for Lsat= 0.2549540863097569 \n",
      "acc for Psat= 0.40338309727958405 \n",
      "acc for optim= 0.20694983798369276\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.012136036530137062\n",
      "Loss on test= 0.01429363340139389\n",
      "acc for Lsat= 0.27893262427819315 \n",
      "acc for Psat= 0.40162395468806145 \n",
      "acc for optim= 0.21552082528939878\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.010667472146451473\n",
      "Loss on test= 0.010945900343358517\n",
      "acc for Lsat= 0.24815497049349972 \n",
      "acc for Psat= 0.33358586403945856 \n",
      "acc for optim= 0.18736044946699174\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.009843721985816956\n",
      "Loss on test= 0.012134472839534283\n",
      "acc for Lsat= 0.2576473800343324 \n",
      "acc for Psat= 0.347820999822961 \n",
      "acc for optim= 0.1969482298790607\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.010015619918704033\n",
      "Loss on test= 0.01045258715748787\n",
      "acc for Lsat= 0.22548713655159502 \n",
      "acc for Psat= 0.2818074500159128 \n",
      "acc for optim= 0.18152682123682842\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.009417077526450157\n",
      "Loss on test= 0.010300915688276291\n",
      "acc for Lsat= 0.23408742701466823 \n",
      "acc for Psat= 0.2753690787851543 \n",
      "acc for optim= 0.18530768239221795\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.009899435564875603\n",
      "Loss on test= 0.011211272329092026\n",
      "acc for Lsat= 0.2217870319223978 \n",
      "acc for Psat= 0.29629635954749023 \n",
      "acc for optim= 0.19990000765795485\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.009300249628722668\n",
      "Loss on test= 0.010601009242236614\n",
      "acc for Lsat= 0.21300385686641438 \n",
      "acc for Psat= 0.2862275741126037 \n",
      "acc for optim= 0.20617899770283551\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.010796306654810905\n",
      "Loss on test= 0.010759128257632256\n",
      "acc for Lsat= 0.27253312135914903 \n",
      "acc for Psat= 0.2736750714992341 \n",
      "acc for optim= 0.20010998541404318\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.009933636523783207\n",
      "Loss on test= 0.010460780933499336\n",
      "acc for Lsat= 0.2503622452591042 \n",
      "acc for Psat= 0.24663104723535906 \n",
      "acc for optim= 0.18651335205516364\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.010056034661829472\n",
      "Loss on test= 0.01181077491492033\n",
      "acc for Lsat= 0.2941415790437919 \n",
      "acc for Psat= 0.29129374472741193 \n",
      "acc for optim= 0.1879960446583191\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.01220930926501751\n",
      "Loss on test= 0.010828990489244461\n",
      "acc for Lsat= 0.261497384311868 \n",
      "acc for Psat= 0.32252780400735676 \n",
      "acc for optim= 0.19831991203197996\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.010675450786948204\n",
      "Loss on test= 0.012003078125417233\n",
      "acc for Lsat= 0.24743387280948093 \n",
      "acc for Psat= 0.2879333569717614 \n",
      "acc for optim= 0.2102259126110155\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.009954617358744144\n",
      "Loss on test= 0.011691275984048843\n",
      "acc for Lsat= 0.23176764377285955 \n",
      "acc for Psat= 0.2987343849030277 \n",
      "acc for optim= 0.20074542987400848\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.009959868155419827\n",
      "Loss on test= 0.010340032167732716\n",
      "acc for Lsat= 0.20709176931805054 \n",
      "acc for Psat= 0.31757030782640955 \n",
      "acc for optim= 0.18494233580956954\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.009603598155081272\n",
      "Loss on test= 0.010944830253720284\n",
      "acc for Lsat= 0.2229232977905891 \n",
      "acc for Psat= 0.3332427685406654 \n",
      "acc for optim= 0.2011916640230844\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.010611462406814098\n",
      "Loss on test= 0.010545129887759686\n",
      "acc for Lsat= 0.26473540704784204 \n",
      "acc for Psat= 0.27904097702445796 \n",
      "acc for optim= 0.18739038037296507\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.010996593162417412\n",
      "Loss on test= 0.01193811185657978\n",
      "acc for Lsat= 0.21267650411540612 \n",
      "acc for Psat= 0.3051308518737463 \n",
      "acc for optim= 0.19654646936506337\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.009876182302832603\n",
      "Loss on test= 0.01017103809863329\n",
      "acc for Lsat= 0.19814463614516692 \n",
      "acc for Psat= 0.27286702335552604 \n",
      "acc for optim= 0.2083101738908435\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.00898068305104971\n",
      "Loss on test= 0.010980380699038506\n",
      "acc for Lsat= 0.21765057531683554 \n",
      "acc for Psat= 0.3099094204188584 \n",
      "acc for optim= 0.20124443893857133\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.009909523651003838\n",
      "Loss on test= 0.010920464061200619\n",
      "acc for Lsat= 0.23901406313162907 \n",
      "acc for Psat= 0.32672506206187985 \n",
      "acc for optim= 0.19014031095735606\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.010354672558605671\n",
      "Loss on test= 0.010539917275309563\n",
      "acc for Lsat= 0.2311660835007492 \n",
      "acc for Psat= 0.32242876131576104 \n",
      "acc for optim= 0.2034371092400254\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.008770971558988094\n",
      "Loss on test= 0.01012330874800682\n",
      "acc for Lsat= 0.2045141968273054 \n",
      "acc for Psat= 0.247869414368026 \n",
      "acc for optim= 0.19607973732645853\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.008983063511550426\n",
      "Loss on test= 0.009366823360323906\n",
      "acc for Lsat= 0.2237891466643081 \n",
      "acc for Psat= 0.26046072347624016 \n",
      "acc for optim= 0.19931559476364008\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.009934996254742146\n",
      "Loss on test= 0.009994929656386375\n",
      "acc for Lsat= 0.23810482024306767 \n",
      "acc for Psat= 0.25494687905054175 \n",
      "acc for optim= 0.18563390986261064\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.009700972586870193\n",
      "Loss on test= 0.009448652155697346\n",
      "acc for Lsat= 0.19156291274101947 \n",
      "acc for Psat= 0.26936520996511165 \n",
      "acc for optim= 0.18788675290394524\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.008868565782904625\n",
      "Loss on test= 0.009012846276164055\n",
      "acc for Lsat= 0.2141719626784983 \n",
      "acc for Psat= 0.2601242029340938 \n",
      "acc for optim= 0.1885584320237509\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.008809303864836693\n",
      "Loss on test= 0.010219410061836243\n",
      "acc for Lsat= 0.23298896893030643 \n",
      "acc for Psat= 0.2720656418149955 \n",
      "acc for optim= 0.19068702689160166\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.008768976666033268\n",
      "Loss on test= 0.010485547594726086\n",
      "acc for Lsat= 0.20557188019490436 \n",
      "acc for Psat= 0.3475807066537348 \n",
      "acc for optim= 0.19883180379492543\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.009026123210787773\n",
      "Loss on test= 0.011925645172595978\n",
      "acc for Lsat= 0.19837510415117188 \n",
      "acc for Psat= 0.36498242163206224 \n",
      "acc for optim= 0.1936196765099026\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.01639801636338234\n",
      "Loss on test= 0.014149495400488377\n",
      "acc for Lsat= 0.3106467331885589 \n",
      "acc for Psat= 0.39330971846433327 \n",
      "acc for optim= 0.1960810431790706\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.014968467876315117\n",
      "Loss on test= 0.012961825355887413\n",
      "acc for Lsat= 0.3263798963473671 \n",
      "acc for Psat= 0.3120505687006564 \n",
      "acc for optim= 0.21574113156615954\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.01257768739014864\n",
      "Loss on test= 0.010601573623716831\n",
      "acc for Lsat= 0.28255236810912976 \n",
      "acc for Psat= 0.2730667978891584 \n",
      "acc for optim= 0.18775449853646187\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.011764814145863056\n",
      "Loss on test= 0.012101643718779087\n",
      "acc for Lsat= 0.23917946579072197 \n",
      "acc for Psat= 0.39304796721916035 \n",
      "acc for optim= 0.1964819025184356\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.01044212095439434\n",
      "Loss on test= 0.010509179905056953\n",
      "acc for Lsat= 0.24195288508619014 \n",
      "acc for Psat= 0.3076282982052243 \n",
      "acc for optim= 0.18181938541304993\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.009960232302546501\n",
      "Loss on test= 0.010180840268731117\n",
      "acc for Lsat= 0.261253417259274 \n",
      "acc for Psat= 0.2757409110608068 \n",
      "acc for optim= 0.17786273051947393\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.009663669392466545\n",
      "Loss on test= 0.010488871484994888\n",
      "acc for Lsat= 0.26811439046153385 \n",
      "acc for Psat= 0.2959002335677992 \n",
      "acc for optim= 0.19178380369034367\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.008930162526667118\n",
      "Loss on test= 0.009985915385186672\n",
      "acc for Lsat= 0.23033440273491756 \n",
      "acc for Psat= 0.2585736336186528 \n",
      "acc for optim= 0.1892128582772814\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.009921031072735786\n",
      "Loss on test= 0.009959660470485687\n",
      "acc for Lsat= 0.20201384402261893 \n",
      "acc for Psat= 0.2736560529831713 \n",
      "acc for optim= 0.19540774972086436\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.009583543054759502\n",
      "Loss on test= 0.009197677485644817\n",
      "acc for Lsat= 0.20127251810226285 \n",
      "acc for Psat= 0.29662592825174455 \n",
      "acc for optim= 0.18866807269837782\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.0087773771956563\n",
      "Loss on test= 0.009483042173087597\n",
      "acc for Lsat= 0.21684954649550253 \n",
      "acc for Psat= 0.24843132114283584 \n",
      "acc for optim= 0.18524657708552636\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.009620072320103645\n",
      "Loss on test= 0.011028746142983437\n",
      "acc for Lsat= 0.29572919072243614 \n",
      "acc for Psat= 0.3028451174299126 \n",
      "acc for optim= 0.18906170366340047\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.011432811617851257\n",
      "Loss on test= 0.011606249958276749\n",
      "acc for Lsat= 0.23643682752964926 \n",
      "acc for Psat= 0.3426881932447374 \n",
      "acc for optim= 0.2004967630270212\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.009665755555033684\n",
      "Loss on test= 0.009924069978296757\n",
      "acc for Lsat= 0.23087737837417022 \n",
      "acc for Psat= 0.24765129305315434 \n",
      "acc for optim= 0.1861132137195902\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.009792417287826538\n",
      "Loss on test= 0.00967856589704752\n",
      "acc for Lsat= 0.23614951426923833 \n",
      "acc for Psat= 0.24816331210065268 \n",
      "acc for optim= 0.1835491069787197\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.010622739791870117\n",
      "Loss on test= 0.010733185335993767\n",
      "acc for Lsat= 0.24044621830145813 \n",
      "acc for Psat= 0.3152933646001105 \n",
      "acc for optim= 0.19136049673171165\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.009520305320620537\n",
      "Loss on test= 0.009579403325915337\n",
      "acc for Lsat= 0.2121374372031242 \n",
      "acc for Psat= 0.28914160359313057 \n",
      "acc for optim= 0.19107828357974527\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.009078949689865112\n",
      "Loss on test= 0.009885434992611408\n",
      "acc for Lsat= 0.20439713896819023 \n",
      "acc for Psat= 0.25990734451038183 \n",
      "acc for optim= 0.19120498496703192\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.008606362156569958\n",
      "Loss on test= 0.010339210741221905\n",
      "acc for Lsat= 0.21072704493426947 \n",
      "acc for Psat= 0.31170760903900613 \n",
      "acc for optim= 0.1958446569032738\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.009008204564452171\n",
      "Loss on test= 0.009091047570109367\n",
      "acc for Lsat= 0.19146925749211405 \n",
      "acc for Psat= 0.2289818661688201 \n",
      "acc for optim= 0.18496307119971417\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.008599519729614258\n",
      "Loss on test= 0.008982427418231964\n",
      "acc for Lsat= 0.19637563558520565 \n",
      "acc for Psat= 0.2460936282763065 \n",
      "acc for optim= 0.1970718084267707\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.008271098136901855\n",
      "Loss on test= 0.00904951523989439\n",
      "acc for Lsat= 0.2030780024832252 \n",
      "acc for Psat= 0.2547037663747419 \n",
      "acc for optim= 0.1936127083146082\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.008009969256818295\n",
      "Loss on test= 0.009324894286692142\n",
      "acc for Lsat= 0.20341836304287425 \n",
      "acc for Psat= 0.2441491056653503 \n",
      "acc for optim= 0.1872501358115038\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.008731444366276264\n",
      "Loss on test= 0.008718437515199184\n",
      "acc for Lsat= 0.1927669655286648 \n",
      "acc for Psat= 0.24728743280742135 \n",
      "acc for optim= 0.1843767735577278\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.008852923288941383\n",
      "Loss on test= 0.009432807564735413\n",
      "acc for Lsat= 0.1981398983228738 \n",
      "acc for Psat= 0.2897062885151321 \n",
      "acc for optim= 0.18976179120039233\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.008284335024654865\n",
      "Loss on test= 0.00879514217376709\n",
      "acc for Lsat= 0.17984485645305182 \n",
      "acc for Psat= 0.24130067120928347 \n",
      "acc for optim= 0.19248254600316897\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.00859045796096325\n",
      "Loss on test= 0.010421155020594597\n",
      "acc for Lsat= 0.1927240772494382 \n",
      "acc for Psat= 0.2925600695263472 \n",
      "acc for optim= 0.20238268588684866\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.008669075556099415\n",
      "Loss on test= 0.010809684172272682\n",
      "acc for Lsat= 0.23156247944074881 \n",
      "acc for Psat= 0.2956981237043081 \n",
      "acc for optim= 0.1913489269936213\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.008225062862038612\n",
      "Loss on test= 0.008847738616168499\n",
      "acc for Lsat= 0.19146802925306625 \n",
      "acc for Psat= 0.23751086466029653 \n",
      "acc for optim= 0.19147230918618438\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.008255806751549244\n",
      "Loss on test= 0.009004202671349049\n",
      "acc for Lsat= 0.20058893316929213 \n",
      "acc for Psat= 0.2694559091908216 \n",
      "acc for optim= 0.18624733827061585\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.007948918268084526\n",
      "Loss on test= 0.009156294167041779\n",
      "acc for Lsat= 0.1798905300956456 \n",
      "acc for Psat= 0.24617195670687608 \n",
      "acc for optim= 0.19193582274744928\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.008254429325461388\n",
      "Loss on test= 0.008608910255134106\n",
      "acc for Lsat= 0.184922613796862 \n",
      "acc for Psat= 0.25005966685578745 \n",
      "acc for optim= 0.17824727951216923\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.007647132966667414\n",
      "Loss on test= 0.008901075460016727\n",
      "acc for Lsat= 0.16811250153982432 \n",
      "acc for Psat= 0.2312124333423839 \n",
      "acc for optim= 0.18304647883537728\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.007892431691288948\n",
      "Loss on test= 0.009342570789158344\n",
      "acc for Lsat= 0.18147959220795662 \n",
      "acc for Psat= 0.2602790842440896 \n",
      "acc for optim= 0.1909057587539762\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.00793975405395031\n",
      "Loss on test= 0.009344711899757385\n",
      "acc for Lsat= 0.18180427072993402 \n",
      "acc for Psat= 0.2724941086875214 \n",
      "acc for optim= 0.18232963103605396\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.007982243783771992\n",
      "Loss on test= 0.009005696512758732\n",
      "acc for Lsat= 0.18922916661059525 \n",
      "acc for Psat= 0.2402478858315172 \n",
      "acc for optim= 0.1934310047658252\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.008534658700227737\n",
      "Loss on test= 0.009139970876276493\n",
      "acc for Lsat= 0.2037166200459889 \n",
      "acc for Psat= 0.2347774684085648 \n",
      "acc for optim= 0.19922309788172973\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.00897678080946207\n",
      "Loss on test= 0.008792883716523647\n",
      "acc for Lsat= 0.16624187196311008 \n",
      "acc for Psat= 0.24247449685010264 \n",
      "acc for optim= 0.18373124205400465\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.007926147431135178\n",
      "Loss on test= 0.009054794907569885\n",
      "acc for Lsat= 0.23186208120409826 \n",
      "acc for Psat= 0.25177920909567936 \n",
      "acc for optim= 0.17445085736942958\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.008223457261919975\n",
      "Loss on test= 0.011496791616082191\n",
      "acc for Lsat= 0.23157598785979705 \n",
      "acc for Psat= 0.34165772837309977 \n",
      "acc for optim= 0.19134981246821614\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.008191319182515144\n",
      "Loss on test= 0.009708757512271404\n",
      "acc for Lsat= 0.22037329674759482 \n",
      "acc for Psat= 0.2525901717469707 \n",
      "acc for optim= 0.19081770294106404\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.00838320143520832\n",
      "Loss on test= 0.008469464257359505\n",
      "acc for Lsat= 0.187974625465567 \n",
      "acc for Psat= 0.21828011791813418 \n",
      "acc for optim= 0.19251374514471953\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.007460230030119419\n",
      "Loss on test= 0.008641322143375874\n",
      "acc for Lsat= 0.19828797130097375 \n",
      "acc for Psat= 0.21643379972460414 \n",
      "acc for optim= 0.19815348833684857\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.007515306118875742\n",
      "Loss on test= 0.008740792982280254\n",
      "acc for Lsat= 0.1749065634665713 \n",
      "acc for Psat= 0.21731361837553806 \n",
      "acc for optim= 0.19534059237807103\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.007376648485660553\n",
      "Loss on test= 0.009188561700284481\n",
      "acc for Lsat= 0.1779645412496184 \n",
      "acc for Psat= 0.26981090011693476 \n",
      "acc for optim= 0.19291089862703392\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.00728385616093874\n",
      "Loss on test= 0.0087902145460248\n",
      "acc for Lsat= 0.19691228619080084 \n",
      "acc for Psat= 0.23226671224168013 \n",
      "acc for optim= 0.18448640397391053\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.007727771997451782\n",
      "Loss on test= 0.00972660817205906\n",
      "acc for Lsat= 0.18678234643341027 \n",
      "acc for Psat= 0.24025493450023874 \n",
      "acc for optim= 0.19070164034535275\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.007426809519529343\n",
      "Loss on test= 0.009221065789461136\n",
      "acc for Lsat= 0.1935701063357496 \n",
      "acc for Psat= 0.24953162651661723 \n",
      "acc for optim= 0.20230333062316305\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.007376301102340221\n",
      "Loss on test= 0.008607177995145321\n",
      "acc for Lsat= 0.17468500478521418 \n",
      "acc for Psat= 0.24969130151095936 \n",
      "acc for optim= 0.1893744971270608\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.007599838078022003\n",
      "Loss on test= 0.008922283537685871\n",
      "acc for Lsat= 0.16842053787674008 \n",
      "acc for Psat= 0.21558402661047113 \n",
      "acc for optim= 0.19046711482195428\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.0079889427870512\n",
      "Loss on test= 0.00862086284905672\n",
      "acc for Lsat= 0.20258283609921326 \n",
      "acc for Psat= 0.23367555083083866 \n",
      "acc for optim= 0.19227576221560785\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.007785860449075699\n",
      "Loss on test= 0.008197379298508167\n",
      "acc for Lsat= 0.18372112100993543 \n",
      "acc for Psat= 0.23728739900002663 \n",
      "acc for optim= 0.18856025422039654\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.007909848354756832\n",
      "Loss on test= 0.009042682126164436\n",
      "acc for Lsat= 0.22041711757011084 \n",
      "acc for Psat= 0.2196747398428804 \n",
      "acc for optim= 0.1828855801295474\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.008736955933272839\n",
      "Loss on test= 0.008546249009668827\n",
      "acc for Lsat= 0.1840284502874205 \n",
      "acc for Psat= 0.2732173958350523 \n",
      "acc for optim= 0.19082186875610085\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.00851269718259573\n",
      "Loss on test= 0.008700898848474026\n",
      "acc for Lsat= 0.18428533767907285 \n",
      "acc for Psat= 0.23280466376500492 \n",
      "acc for optim= 0.18220836071375773\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.008049894124269485\n",
      "Loss on test= 0.009104191325604916\n",
      "acc for Lsat= 0.1847153771599014 \n",
      "acc for Psat= 0.26207062034876294 \n",
      "acc for optim= 0.18569206208654787\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.007433985825628042\n",
      "Loss on test= 0.008427849970757961\n",
      "acc for Lsat= 0.19084376033403164 \n",
      "acc for Psat= 0.22881235221522997 \n",
      "acc for optim= 0.1909161168939747\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.007139876484870911\n",
      "Loss on test= 0.008220196701586246\n",
      "acc for Lsat= 0.16976306320265408 \n",
      "acc for Psat= 0.24033540366093445 \n",
      "acc for optim= 0.19100153005074091\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.007116890046745539\n",
      "Loss on test= 0.008907250128686428\n",
      "acc for Lsat= 0.18008062664159863 \n",
      "acc for Psat= 0.24347200288254095 \n",
      "acc for optim= 0.19907760177815303\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.007310164161026478\n",
      "Loss on test= 0.009089227765798569\n",
      "acc for Lsat= 0.16680485475541199 \n",
      "acc for Psat= 0.2218357867885717 \n",
      "acc for optim= 0.19300635775745206\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.006903931498527527\n",
      "Loss on test= 0.008499384857714176\n",
      "acc for Lsat= 0.16516763198697085 \n",
      "acc for Psat= 0.2309101077304298 \n",
      "acc for optim= 0.1972674980274875\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.00735710933804512\n",
      "Loss on test= 0.008594581857323647\n",
      "acc for Lsat= 0.1860096690893845 \n",
      "acc for Psat= 0.27373025095735326 \n",
      "acc for optim= 0.18512361945675546\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.007832355797290802\n",
      "Loss on test= 0.008672919124364853\n",
      "acc for Lsat= 0.17259414224488448 \n",
      "acc for Psat= 0.22886246381571793 \n",
      "acc for optim= 0.18426187969992303\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.007466799579560757\n",
      "Loss on test= 0.008211304433643818\n",
      "acc for Lsat= 0.16259896360479914 \n",
      "acc for Psat= 0.20504523840385536 \n",
      "acc for optim= 0.187201002279495\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.007864885032176971\n",
      "Loss on test= 0.0080521609634161\n",
      "acc for Lsat= 0.1621695033530323 \n",
      "acc for Psat= 0.2197591862164163 \n",
      "acc for optim= 0.19953004889339057\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.00751414243131876\n",
      "Loss on test= 0.008579658344388008\n",
      "acc for Lsat= 0.18948168153416547 \n",
      "acc for Psat= 0.22217299899475917 \n",
      "acc for optim= 0.1822951473110092\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.007292852737009525\n",
      "Loss on test= 0.009346656501293182\n",
      "acc for Lsat= 0.18102083933409915 \n",
      "acc for Psat= 0.2545956278006073 \n",
      "acc for optim= 0.18539605043317023\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.007593425456434488\n",
      "Loss on test= 0.008643880486488342\n",
      "acc for Lsat= 0.19853901777666474 \n",
      "acc for Psat= 0.20997021588874737 \n",
      "acc for optim= 0.18608407881759778\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.007092718034982681\n",
      "Loss on test= 0.008234974928200245\n",
      "acc for Lsat= 0.15862953518994427 \n",
      "acc for Psat= 0.23357197425016163 \n",
      "acc for optim= 0.18379439460761082\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.007392474450170994\n",
      "Loss on test= 0.008114422671496868\n",
      "acc for Lsat= 0.17676714839658045 \n",
      "acc for Psat= 0.2069411370849817 \n",
      "acc for optim= 0.18744194362919442\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.006906603462994099\n",
      "Loss on test= 0.008242160081863403\n",
      "acc for Lsat= 0.18976869491476672 \n",
      "acc for Psat= 0.21064917129220165 \n",
      "acc for optim= 0.18708672362912188\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.006768742110580206\n",
      "Loss on test= 0.008160923607647419\n",
      "acc for Lsat= 0.1748146231150728 \n",
      "acc for Psat= 0.2196043289852137 \n",
      "acc for optim= 0.18639413501717128\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.007351925130933523\n",
      "Loss on test= 0.008685439825057983\n",
      "acc for Lsat= 0.1781708630098156 \n",
      "acc for Psat= 0.20628468933139285 \n",
      "acc for optim= 0.1852589876745965\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.007906416431069374\n",
      "Loss on test= 0.00887882336974144\n",
      "acc for Lsat= 0.21917094050307345 \n",
      "acc for Psat= 0.2395591589900833 \n",
      "acc for optim= 0.1878456173174572\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.007148770149797201\n",
      "Loss on test= 0.008559352718293667\n",
      "acc for Lsat= 0.18515861906200937 \n",
      "acc for Psat= 0.24429484609608465 \n",
      "acc for optim= 0.19198192488421212\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.007228477392345667\n",
      "Loss on test= 0.008048751391470432\n",
      "acc for Lsat= 0.18011354529814122 \n",
      "acc for Psat= 0.23153070724086425 \n",
      "acc for optim= 0.18675955349787474\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.007158299442380667\n",
      "Loss on test= 0.008468396961688995\n",
      "acc for Lsat= 0.17024133313160017 \n",
      "acc for Psat= 0.21293401218049962 \n",
      "acc for optim= 0.18172225490046406\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.006985252257436514\n",
      "Loss on test= 0.008250170387327671\n",
      "acc for Lsat= 0.1765530993855419 \n",
      "acc for Psat= 0.22510127028389298 \n",
      "acc for optim= 0.18693810015245052\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.0068702613934874535\n",
      "Loss on test= 0.008433482609689236\n",
      "acc for Lsat= 0.19339283795943032 \n",
      "acc for Psat= 0.19539739290847763 \n",
      "acc for optim= 0.1836913205895069\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.007197544910013676\n",
      "Loss on test= 0.008380580693483353\n",
      "acc for Lsat= 0.15002593819985213 \n",
      "acc for Psat= 0.2613503631285476 \n",
      "acc for optim= 0.18632408559730765\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.006925356574356556\n",
      "Loss on test= 0.008315871469676495\n",
      "acc for Lsat= 0.1679774180635966 \n",
      "acc for Psat= 0.21243221593284065 \n",
      "acc for optim= 0.20059491602988289\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.006821054965257645\n",
      "Loss on test= 0.008435631170868874\n",
      "acc for Lsat= 0.1656320521391625 \n",
      "acc for Psat= 0.22286770519663077 \n",
      "acc for optim= 0.20359918178187028\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.006824950687587261\n",
      "Loss on test= 0.0077767278999090195\n",
      "acc for Lsat= 0.18408118387532504 \n",
      "acc for Psat= 0.20714166858195343 \n",
      "acc for optim= 0.17818346710486307\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.0067182546481490135\n",
      "Loss on test= 0.008494771085679531\n",
      "acc for Lsat= 0.161199112610651 \n",
      "acc for Psat= 0.22395697992145214 \n",
      "acc for optim= 0.18039875788881396\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.006832809187471867\n",
      "Loss on test= 0.007864200510084629\n",
      "acc for Lsat= 0.17136042136985227 \n",
      "acc for Psat= 0.2028848418217824 \n",
      "acc for optim= 0.1834890980059739\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.0067448122426867485\n",
      "Loss on test= 0.00784451887011528\n",
      "acc for Lsat= 0.15492960295485347 \n",
      "acc for Psat= 0.22841424655959347 \n",
      "acc for optim= 0.1873206100033474\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.007015797309577465\n",
      "Loss on test= 0.008279918693006039\n",
      "acc for Lsat= 0.1710019881982112 \n",
      "acc for Psat= 0.22078543119323363 \n",
      "acc for optim= 0.18728840410018524\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.007661386393010616\n",
      "Loss on test= 0.008593308739364147\n",
      "acc for Lsat= 0.19054647350462428 \n",
      "acc for Psat= 0.22583369152681504 \n",
      "acc for optim= 0.18516184376742592\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.007010971195995808\n",
      "Loss on test= 0.007836280390620232\n",
      "acc for Lsat= 0.16124955184803513 \n",
      "acc for Psat= 0.24140002238443722 \n",
      "acc for optim= 0.17377999061196145\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.006637204438447952\n",
      "Loss on test= 0.00800305139273405\n",
      "acc for Lsat= 0.1689786779710481 \n",
      "acc for Psat= 0.2278264651711145 \n",
      "acc for optim= 0.1853796448720787\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.006604302674531937\n",
      "Loss on test= 0.007816901430487633\n",
      "acc for Lsat= 0.17750242116257975 \n",
      "acc for Psat= 0.2322273469350652 \n",
      "acc for optim= 0.19034455207221354\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.006462914403527975\n",
      "Loss on test= 0.008419163525104523\n",
      "acc for Lsat= 0.1819295702150977 \n",
      "acc for Psat= 0.21197283645179582 \n",
      "acc for optim= 0.18624910151425628\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.006649435963481665\n",
      "Loss on test= 0.00796103198081255\n",
      "acc for Lsat= 0.16989295135450655 \n",
      "acc for Psat= 0.22477067327661227 \n",
      "acc for optim= 0.18726299106540373\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.006829506251960993\n",
      "Loss on test= 0.007984590716660023\n",
      "acc for Lsat= 0.16730717194846786 \n",
      "acc for Psat= 0.21540073214907993 \n",
      "acc for optim= 0.181482831464197\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.00687097292393446\n",
      "Loss on test= 0.00824090838432312\n",
      "acc for Lsat= 0.16746357494772443 \n",
      "acc for Psat= 0.23509772572223647 \n",
      "acc for optim= 0.18621716254131226\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.006694082170724869\n",
      "Loss on test= 0.00781372468918562\n",
      "acc for Lsat= 0.1671027747727167 \n",
      "acc for Psat= 0.20407459960475594 \n",
      "acc for optim= 0.18674072102933634\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.006719375494867563\n",
      "Loss on test= 0.008049461990594864\n",
      "acc for Lsat= 0.16568890281873716 \n",
      "acc for Psat= 0.20527866936334577 \n",
      "acc for optim= 0.19372667485855702\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.006931991316378117\n",
      "Loss on test= 0.008399983868002892\n",
      "acc for Lsat= 0.16555746162002982 \n",
      "acc for Psat= 0.19945030081482817 \n",
      "acc for optim= 0.18030258217448614\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.007075692526996136\n",
      "Loss on test= 0.008149933069944382\n",
      "acc for Lsat= 0.16895191186932146 \n",
      "acc for Psat= 0.2175765427386724 \n",
      "acc for optim= 0.17814180460857745\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.006722563412040472\n",
      "Loss on test= 0.008486143313348293\n",
      "acc for Lsat= 0.1837236960286601 \n",
      "acc for Psat= 0.24713430416457294 \n",
      "acc for optim= 0.1813947931412258\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.006652391515672207\n",
      "Loss on test= 0.007507605478167534\n",
      "acc for Lsat= 0.16381934819281194 \n",
      "acc for Psat= 0.21552201545440408 \n",
      "acc for optim= 0.17783513547715227\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.006774400360882282\n",
      "Loss on test= 0.007858925499022007\n",
      "acc for Lsat= 0.16617018461521318 \n",
      "acc for Psat= 0.21085270879843623 \n",
      "acc for optim= 0.18482423233341608\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.006770805921405554\n",
      "Loss on test= 0.008018404245376587\n",
      "acc for Lsat= 0.18281334188717158 \n",
      "acc for Psat= 0.21812199123211387 \n",
      "acc for optim= 0.18303144368892688\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.006763467099517584\n",
      "Loss on test= 0.007709504570811987\n",
      "acc for Lsat= 0.19055075384256598 \n",
      "acc for Psat= 0.2062843336392152 \n",
      "acc for optim= 0.18998986022541162\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.007046205457299948\n",
      "Loss on test= 0.007642436306923628\n",
      "acc for Lsat= 0.1715254142285004 \n",
      "acc for Psat= 0.22869723531032043 \n",
      "acc for optim= 0.18546630975477335\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.006670838687568903\n",
      "Loss on test= 0.008168372325599194\n",
      "acc for Lsat= 0.16940212553957684 \n",
      "acc for Psat= 0.21108626181710144 \n",
      "acc for optim= 0.1835918770700342\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.006488385144621134\n",
      "Loss on test= 0.007691455073654652\n",
      "acc for Lsat= 0.16392268717754632 \n",
      "acc for Psat= 0.22185019684619592 \n",
      "acc for optim= 0.18745332077211418\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.007425367832183838\n",
      "Loss on test= 0.008114833384752274\n",
      "acc for Lsat= 0.16184041191877216 \n",
      "acc for Psat= 0.21355582567587394 \n",
      "acc for optim= 0.1833348647851619\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.006870103068649769\n",
      "Loss on test= 0.008240417577326298\n",
      "acc for Lsat= 0.1914079847321922 \n",
      "acc for Psat= 0.20514809046547525 \n",
      "acc for optim= 0.18247470351157435\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.007278414908796549\n",
      "Loss on test= 0.008345221169292927\n",
      "acc for Lsat= 0.15848528059947564 \n",
      "acc for Psat= 0.2353673587614035 \n",
      "acc for optim= 0.19895851118642777\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.007060717791318893\n",
      "Loss on test= 0.00821324810385704\n",
      "acc for Lsat= 0.1621996046553488 \n",
      "acc for Psat= 0.21956475285954438 \n",
      "acc for optim= 0.19800127144677748\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.006617954932153225\n",
      "Loss on test= 0.00768411997705698\n",
      "acc for Lsat= 0.16873603793103 \n",
      "acc for Psat= 0.2166225691450966 \n",
      "acc for optim= 0.1844547569549444\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.00659329304471612\n",
      "Loss on test= 0.0075392769649624825\n",
      "acc for Lsat= 0.17301967602936918 \n",
      "acc for Psat= 0.20788150758436713 \n",
      "acc for optim= 0.18394166340776644\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.006713570095598698\n",
      "Loss on test= 0.008250722661614418\n",
      "acc for Lsat= 0.1565075883206713 \n",
      "acc for Psat= 0.20952254138967083 \n",
      "acc for optim= 0.18399560275911278\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.006571315228939056\n",
      "Loss on test= 0.008154424838721752\n",
      "acc for Lsat= 0.17317886532345866 \n",
      "acc for Psat= 0.21519960280526648 \n",
      "acc for optim= 0.19693175698859525\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.006429919507354498\n",
      "Loss on test= 0.007793452125042677\n",
      "acc for Lsat= 0.1600907737215538 \n",
      "acc for Psat= 0.21215430135785251 \n",
      "acc for optim= 0.19291390961906338\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.006194215267896652\n",
      "Loss on test= 0.007942561991512775\n",
      "acc for Lsat= 0.17743672507921937 \n",
      "acc for Psat= 0.19809215188095133 \n",
      "acc for optim= 0.1808513839353166\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.006563390139490366\n",
      "Loss on test= 0.008411755785346031\n",
      "acc for Lsat= 0.1684241952367898 \n",
      "acc for Psat= 0.24132347214989913 \n",
      "acc for optim= 0.1876241513060837\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.007335427217185497\n",
      "Loss on test= 0.008858849294483662\n",
      "acc for Lsat= 0.17809763732137252 \n",
      "acc for Psat= 0.2477535250600519 \n",
      "acc for optim= 0.19746183231167616\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.006707014981657267\n",
      "Loss on test= 0.008007793687283993\n",
      "acc for Lsat= 0.17814109295064615 \n",
      "acc for Psat= 0.22465320049296514 \n",
      "acc for optim= 0.18184207435353797\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.006203087978065014\n",
      "Loss on test= 0.007754389196634293\n",
      "acc for Lsat= 0.1505966749708321 \n",
      "acc for Psat= 0.20904481385459506 \n",
      "acc for optim= 0.18558174171971661\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.0061233253218233585\n",
      "Loss on test= 0.0077999550849199295\n",
      "acc for Lsat= 0.1552015391403626 \n",
      "acc for Psat= 0.19919041669889367 \n",
      "acc for optim= 0.18752130373251305\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.0066291517578065395\n",
      "Loss on test= 0.007994331419467926\n",
      "acc for Lsat= 0.1600686538857637 \n",
      "acc for Psat= 0.2302044193138231 \n",
      "acc for optim= 0.18801478907703537\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.006883045192807913\n",
      "Loss on test= 0.008032594807446003\n",
      "acc for Lsat= 0.1634322083375768 \n",
      "acc for Psat= 0.22505775473765707 \n",
      "acc for optim= 0.18954739050527455\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.007207025773823261\n",
      "Loss on test= 0.008416819386184216\n",
      "acc for Lsat= 0.1845930707602777 \n",
      "acc for Psat= 0.21361672995253236 \n",
      "acc for optim= 0.1947422831775347\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.006469572428613901\n",
      "Loss on test= 0.00820197444409132\n",
      "acc for Lsat= 0.1663377319771766 \n",
      "acc for Psat= 0.22105808819273914 \n",
      "acc for optim= 0.18338015306520097\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.006418353412300348\n",
      "Loss on test= 0.008193112909793854\n",
      "acc for Lsat= 0.1863735523639766 \n",
      "acc for Psat= 0.22246323827898404 \n",
      "acc for optim= 0.18712158509430887\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.006364445202052593\n",
      "Loss on test= 0.007967842742800713\n",
      "acc for Lsat= 0.16402764382913373 \n",
      "acc for Psat= 0.20031587175116491 \n",
      "acc for optim= 0.19678683888365622\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.006742068566381931\n",
      "Loss on test= 0.008719614706933498\n",
      "acc for Lsat= 0.15915455765550818 \n",
      "acc for Psat= 0.23082807422414603 \n",
      "acc for optim= 0.20362151970697537\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.006955438759177923\n",
      "Loss on test= 0.008208183571696281\n",
      "acc for Lsat= 0.15968588902199923 \n",
      "acc for Psat= 0.21139833921123846 \n",
      "acc for optim= 0.19404616396708155\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.006505998317152262\n",
      "Loss on test= 0.007984137162566185\n",
      "acc for Lsat= 0.16955370131276976 \n",
      "acc for Psat= 0.21638273767226177 \n",
      "acc for optim= 0.17938429850161258\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.00661900918930769\n",
      "Loss on test= 0.007637020666152239\n",
      "acc for Lsat= 0.16339853474440685 \n",
      "acc for Psat= 0.21819883304052665 \n",
      "acc for optim= 0.17802627148091427\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.006519616581499577\n",
      "Loss on test= 0.007915864698588848\n",
      "acc for Lsat= 0.16343241561295802 \n",
      "acc for Psat= 0.22189874469677603 \n",
      "acc for optim= 0.18784103587567502\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.006746694445610046\n",
      "Loss on test= 0.008141092956066132\n",
      "acc for Lsat= 0.16568903685976813 \n",
      "acc for Psat= 0.21926268744664115 \n",
      "acc for optim= 0.18684382409040556\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.006497383117675781\n",
      "Loss on test= 0.007596390321850777\n",
      "acc for Lsat= 0.15639303974040544 \n",
      "acc for Psat= 0.2088886157172488 \n",
      "acc for optim= 0.18923149694660946\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.00619399081915617\n",
      "Loss on test= 0.007813643664121628\n",
      "acc for Lsat= 0.1521766348474766 \n",
      "acc for Psat= 0.1908901378126876 \n",
      "acc for optim= 0.18548723102096834\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.0063737668097019196\n",
      "Loss on test= 0.007984448224306107\n",
      "acc for Lsat= 0.17470320563412226 \n",
      "acc for Psat= 0.21305708143417343 \n",
      "acc for optim= 0.1946576353021302\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.006330141332000494\n",
      "Loss on test= 0.008120577782392502\n",
      "acc for Lsat= 0.17508393692150406 \n",
      "acc for Psat= 0.21592874418577698 \n",
      "acc for optim= 0.18537779111547784\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.006064022891223431\n",
      "Loss on test= 0.00804456602782011\n",
      "acc for Lsat= 0.15956667576931782 \n",
      "acc for Psat= 0.21224665935981454 \n",
      "acc for optim= 0.1857803032797433\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.006245738826692104\n",
      "Loss on test= 0.007930041290819645\n",
      "acc for Lsat= 0.17310531400792972 \n",
      "acc for Psat= 0.2040270238687269 \n",
      "acc for optim= 0.18665216969112391\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.006368331611156464\n",
      "Loss on test= 0.0075109959580004215\n",
      "acc for Lsat= 0.15802163287222415 \n",
      "acc for Psat= 0.20791820771381503 \n",
      "acc for optim= 0.18361179888206458\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.006122823338955641\n",
      "Loss on test= 0.007449053227901459\n",
      "acc for Lsat= 0.16684750650377683 \n",
      "acc for Psat= 0.20398767742509172 \n",
      "acc for optim= 0.19093157318506587\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.006238144356757402\n",
      "Loss on test= 0.007877080701291561\n",
      "acc for Lsat= 0.18556907906647405 \n",
      "acc for Psat= 0.1883925806791102 \n",
      "acc for optim= 0.19159698555070417\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.00655989209190011\n",
      "Loss on test= 0.00810333900153637\n",
      "acc for Lsat= 0.14997680905794145 \n",
      "acc for Psat= 0.21451360236139602 \n",
      "acc for optim= 0.18696714953713112\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.005964652635157108\n",
      "Loss on test= 0.00856182910501957\n",
      "acc for Lsat= 0.16192702291930308 \n",
      "acc for Psat= 0.2182488295271111 \n",
      "acc for optim= 0.1839089657302152\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.006051265634596348\n",
      "Loss on test= 0.007658443879336119\n",
      "acc for Lsat= 0.16685558550840351 \n",
      "acc for Psat= 0.22012191641079568 \n",
      "acc for optim= 0.18634224810215766\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.005938507616519928\n",
      "Loss on test= 0.007679464761167765\n",
      "acc for Lsat= 0.1496237999600259 \n",
      "acc for Psat= 0.22266016501444774 \n",
      "acc for optim= 0.17890669962173694\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.0062715038657188416\n",
      "Loss on test= 0.007758220192044973\n",
      "acc for Lsat= 0.1458212822087903 \n",
      "acc for Psat= 0.2050337015934571 \n",
      "acc for optim= 0.18336963927049807\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.0063985311426222324\n",
      "Loss on test= 0.008168385364115238\n",
      "acc for Lsat= 0.1580793408425544 \n",
      "acc for Psat= 0.2294623577182914 \n",
      "acc for optim= 0.18752442610032138\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.006063101813197136\n",
      "Loss on test= 0.00765600660815835\n",
      "acc for Lsat= 0.15542396671152062 \n",
      "acc for Psat= 0.20291568869763038 \n",
      "acc for optim= 0.18801284712857613\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.006232209037989378\n",
      "Loss on test= 0.008031350560486317\n",
      "acc for Lsat= 0.15114884929527284 \n",
      "acc for Psat= 0.2055834169780118 \n",
      "acc for optim= 0.19742340516092896\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.00619850680232048\n",
      "Loss on test= 0.00799553468823433\n",
      "acc for Lsat= 0.1599431027148728 \n",
      "acc for Psat= 0.20797246737714825 \n",
      "acc for optim= 0.18456216338834894\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.006147637963294983\n",
      "Loss on test= 0.007754461839795113\n",
      "acc for Lsat= 0.16333182157183326 \n",
      "acc for Psat= 0.2125546627111168 \n",
      "acc for optim= 0.1768027570696937\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.006057596765458584\n",
      "Loss on test= 0.0077197193168103695\n",
      "acc for Lsat= 0.1679189493999908 \n",
      "acc for Psat= 0.1974899697333162 \n",
      "acc for optim= 0.18429811905275603\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.006220468319952488\n",
      "Loss on test= 0.007474080193787813\n",
      "acc for Lsat= 0.1605964044757859 \n",
      "acc for Psat= 0.21122341929690638 \n",
      "acc for optim= 0.18493806793484227\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.005733627360314131\n",
      "Loss on test= 0.007557359989732504\n",
      "acc for Lsat= 0.15933932284633706 \n",
      "acc for Psat= 0.19718508884972955 \n",
      "acc for optim= 0.18273550633142596\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.0062446678057312965\n",
      "Loss on test= 0.007515534292906523\n",
      "acc for Lsat= 0.17706570192125673 \n",
      "acc for Psat= 0.20935911473505137 \n",
      "acc for optim= 0.18063902602155052\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.005995865445584059\n",
      "Loss on test= 0.007490470539778471\n",
      "acc for Lsat= 0.16014860875095377 \n",
      "acc for Psat= 0.19784442935847213 \n",
      "acc for optim= 0.18578845196037141\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.005948960781097412\n",
      "Loss on test= 0.007980241440236568\n",
      "acc for Lsat= 0.15794189632736666 \n",
      "acc for Psat= 0.20106821532521518 \n",
      "acc for optim= 0.17956686575408476\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.006103229708969593\n",
      "Loss on test= 0.007584843784570694\n",
      "acc for Lsat= 0.16479849862450063 \n",
      "acc for Psat= 0.19744779857927094 \n",
      "acc for optim= 0.19225885991701763\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.006091243587434292\n",
      "Loss on test= 0.007543947547674179\n",
      "acc for Lsat= 0.17219424003999503 \n",
      "acc for Psat= 0.21173663022648828 \n",
      "acc for optim= 0.18416963630340627\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.005988632328808308\n",
      "Loss on test= 0.007522023282945156\n",
      "acc for Lsat= 0.1491257515748329 \n",
      "acc for Psat= 0.19441698671807153 \n",
      "acc for optim= 0.18994515496115277\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.006325763650238514\n",
      "Loss on test= 0.008212572894990444\n",
      "acc for Lsat= 0.1515817581455521 \n",
      "acc for Psat= 0.19976367679373055 \n",
      "acc for optim= 0.18662211763840475\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.006048558279871941\n",
      "Loss on test= 0.007912171073257923\n",
      "acc for Lsat= 0.16754895300121567 \n",
      "acc for Psat= 0.2005842701661721 \n",
      "acc for optim= 0.18487270065014572\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.005979917943477631\n",
      "Loss on test= 0.007695416919887066\n",
      "acc for Lsat= 0.159035010772116 \n",
      "acc for Psat= 0.18721856914773644 \n",
      "acc for optim= 0.18102521062981275\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.005943323951214552\n",
      "Loss on test= 0.007504882290959358\n",
      "acc for Lsat= 0.1499765063265766 \n",
      "acc for Psat= 0.20188168084103858 \n",
      "acc for optim= 0.18438981198324042\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.00660550594329834\n",
      "Loss on test= 0.007972950115799904\n",
      "acc for Lsat= 0.15385879623535714 \n",
      "acc for Psat= 0.21534923371118417 \n",
      "acc for optim= 0.19074538306086936\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.006476718001067638\n",
      "Loss on test= 0.007540369872003794\n",
      "acc for Lsat= 0.17647689959820603 \n",
      "acc for Psat= 0.1997361602860915 \n",
      "acc for optim= 0.1788126795293122\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.006145081482827663\n",
      "Loss on test= 0.007503383792936802\n",
      "acc for Lsat= 0.17008133198852177 \n",
      "acc for Psat= 0.19161069966837396 \n",
      "acc for optim= 0.18396303608171932\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.0058153853751719\n",
      "Loss on test= 0.00789097510278225\n",
      "acc for Lsat= 0.16047013244919905 \n",
      "acc for Psat= 0.20491103999484636 \n",
      "acc for optim= 0.17890209167752966\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.006289376411587\n",
      "Loss on test= 0.007794761098921299\n",
      "acc for Lsat= 0.16226201434672208 \n",
      "acc for Psat= 0.2073137396077967 \n",
      "acc for optim= 0.18504510866334953\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.006188513711094856\n",
      "Loss on test= 0.007670250721275806\n",
      "acc for Lsat= 0.1802237159160317 \n",
      "acc for Psat= 0.1915494676944647 \n",
      "acc for optim= 0.17875509562078656\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.0063797966577112675\n",
      "Loss on test= 0.007523349951952696\n",
      "acc for Lsat= 0.15164132258915877 \n",
      "acc for Psat= 0.21828165251883816 \n",
      "acc for optim= 0.1861519879455388\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.009603877551853657\n",
      "Loss on test= 0.009119274094700813\n",
      "acc for Lsat= 0.19079153684908276 \n",
      "acc for Psat= 0.27672759557952037 \n",
      "acc for optim= 0.18960810521146146\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.006991024129092693\n",
      "Loss on test= 0.008083594031631947\n",
      "acc for Lsat= 0.15899571584552893 \n",
      "acc for Psat= 0.21549770200594526 \n",
      "acc for optim= 0.18831071860851628\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.006425199098885059\n",
      "Loss on test= 0.007827702909708023\n",
      "acc for Lsat= 0.1739601928622416 \n",
      "acc for Psat= 0.1974546256170276 \n",
      "acc for optim= 0.17991706017947748\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.006633136421442032\n",
      "Loss on test= 0.007917196489870548\n",
      "acc for Lsat= 0.17118373130654274 \n",
      "acc for Psat= 0.21581828378934842 \n",
      "acc for optim= 0.1854151196847479\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.006280694156885147\n",
      "Loss on test= 0.007838909514248371\n",
      "acc for Lsat= 0.1568253289854257 \n",
      "acc for Psat= 0.20255219305399805 \n",
      "acc for optim= 0.18563873624051233\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.006211116444319487\n",
      "Loss on test= 0.007840686477720737\n",
      "acc for Lsat= 0.1528410348793364 \n",
      "acc for Psat= 0.2134196952764006 \n",
      "acc for optim= 0.18512203877974973\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.006239705253392458\n",
      "Loss on test= 0.00758328614756465\n",
      "acc for Lsat= 0.15991028988491515 \n",
      "acc for Psat= 0.20558274813572738 \n",
      "acc for optim= 0.18511943346419998\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.006162499543279409\n",
      "Loss on test= 0.007870158180594444\n",
      "acc for Lsat= 0.15612687124664607 \n",
      "acc for Psat= 0.2123482419872565 \n",
      "acc for optim= 0.18850448941487483\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.005867359694093466\n",
      "Loss on test= 0.007834667339920998\n",
      "acc for Lsat= 0.15556597106528972 \n",
      "acc for Psat= 0.20643952055147194 \n",
      "acc for optim= 0.1965291162016687\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.005855085793882608\n",
      "Loss on test= 0.007242449093610048\n",
      "acc for Lsat= 0.16611785742658317 \n",
      "acc for Psat= 0.1947461555818798 \n",
      "acc for optim= 0.18163549908744037\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.005866790656000376\n",
      "Loss on test= 0.007775119040161371\n",
      "acc for Lsat= 0.16983547521407763 \n",
      "acc for Psat= 0.1955047213024895 \n",
      "acc for optim= 0.1811984108692249\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.005763472057878971\n",
      "Loss on test= 0.007801685016602278\n",
      "acc for Lsat= 0.15948760027207098 \n",
      "acc for Psat= 0.19666096937086922 \n",
      "acc for optim= 0.18729157684510192\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.005952260456979275\n",
      "Loss on test= 0.007716297637671232\n",
      "acc for Lsat= 0.16889513494135797 \n",
      "acc for Psat= 0.20449183797387438 \n",
      "acc for optim= 0.18146132201376622\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.006096662022173405\n",
      "Loss on test= 0.0076098064891994\n",
      "acc for Lsat= 0.15710332500366647 \n",
      "acc for Psat= 0.19165436753881027 \n",
      "acc for optim= 0.18564597508210695\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.006025843322277069\n",
      "Loss on test= 0.0075465538538992405\n",
      "acc for Lsat= 0.15310597527222555 \n",
      "acc for Psat= 0.2018876659943432 \n",
      "acc for optim= 0.19054961855271374\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.007368513382971287\n",
      "Loss on test= 0.007278437726199627\n",
      "acc for Lsat= 0.16142580633463918 \n",
      "acc for Psat= 0.19808013553628087 \n",
      "acc for optim= 0.18228101147354014\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.006457348354160786\n",
      "Loss on test= 0.008023517206311226\n",
      "acc for Lsat= 0.16049311354557877 \n",
      "acc for Psat= 0.2143925613590104 \n",
      "acc for optim= 0.18657965437465227\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.006779220886528492\n",
      "Loss on test= 0.007726841140538454\n",
      "acc for Lsat= 0.1582337919832589 \n",
      "acc for Psat= 0.20292346767430408 \n",
      "acc for optim= 0.18115959926813718\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.006171909160912037\n",
      "Loss on test= 0.008456693030893803\n",
      "acc for Lsat= 0.1626463911246096 \n",
      "acc for Psat= 0.2122437446078545 \n",
      "acc for optim= 0.19465562099358066\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.005794639233499765\n",
      "Loss on test= 0.007064054720103741\n",
      "acc for Lsat= 0.15841997349968745 \n",
      "acc for Psat= 0.20142697896378986 \n",
      "acc for optim= 0.18314327397307412\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.006431276910007\n",
      "Loss on test= 0.008052004501223564\n",
      "acc for Lsat= 0.16364049825122673 \n",
      "acc for Psat= 0.20726886242818943 \n",
      "acc for optim= 0.1799766060785528\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.005922425072640181\n",
      "Loss on test= 0.0076911267824471\n",
      "acc for Lsat= 0.15903017812935238 \n",
      "acc for Psat= 0.19739205597949475 \n",
      "acc for optim= 0.19447763712549979\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.005755712278187275\n",
      "Loss on test= 0.00715892668813467\n",
      "acc for Lsat= 0.14873972291853965 \n",
      "acc for Psat= 0.19706074186623646 \n",
      "acc for optim= 0.18058111348826836\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.005764942616224289\n",
      "Loss on test= 0.00799981877207756\n",
      "acc for Lsat= 0.16001587842407897 \n",
      "acc for Psat= 0.19683343683117543 \n",
      "acc for optim= 0.17438720855823733\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.006088525988161564\n",
      "Loss on test= 0.007324439939111471\n",
      "acc for Lsat= 0.1561989037479075 \n",
      "acc for Psat= 0.19033240906543053 \n",
      "acc for optim= 0.18391907099895866\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.005752924829721451\n",
      "Loss on test= 0.007501730229705572\n",
      "acc for Lsat= 0.14768227482276952 \n",
      "acc for Psat= 0.21059149111712688 \n",
      "acc for optim= 0.18376134961059118\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.005814548581838608\n",
      "Loss on test= 0.007354873698204756\n",
      "acc for Lsat= 0.15974572678802718 \n",
      "acc for Psat= 0.21598272078754532 \n",
      "acc for optim= 0.18850976335601385\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.00603449996560812\n",
      "Loss on test= 0.007388507481664419\n",
      "acc for Lsat= 0.16538782927482465 \n",
      "acc for Psat= 0.1955145724482508 \n",
      "acc for optim= 0.18701009249131456\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.005936292000114918\n",
      "Loss on test= 0.007569797802716494\n",
      "acc for Lsat= 0.15281336179926808 \n",
      "acc for Psat= 0.2094796206538764 \n",
      "acc for optim= 0.18582834197973097\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.006146260537207127\n",
      "Loss on test= 0.0074388980865478516\n",
      "acc for Lsat= 0.1784485746257114 \n",
      "acc for Psat= 0.20541660481850144 \n",
      "acc for optim= 0.18806761828800816\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.0054948898032307625\n",
      "Loss on test= 0.007361043244600296\n",
      "acc for Lsat= 0.14468683207514466 \n",
      "acc for Psat= 0.19166047823668808 \n",
      "acc for optim= 0.19063278518762194\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.005625142250210047\n",
      "Loss on test= 0.007935231551527977\n",
      "acc for Lsat= 0.157495875012599 \n",
      "acc for Psat= 0.20735685435413825 \n",
      "acc for optim= 0.18771410842958577\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.005792662501335144\n",
      "Loss on test= 0.007790651638060808\n",
      "acc for Lsat= 0.15619747818039242 \n",
      "acc for Psat= 0.20988830535855815 \n",
      "acc for optim= 0.17703000517847345\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.0057336920872330666\n",
      "Loss on test= 0.007640174124389887\n",
      "acc for Lsat= 0.14856545493573514 \n",
      "acc for Psat= 0.20163178721702368 \n",
      "acc for optim= 0.18498922910113805\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.005847617983818054\n",
      "Loss on test= 0.00716101611033082\n",
      "acc for Lsat= 0.15712303873304218 \n",
      "acc for Psat= 0.20293950400120564 \n",
      "acc for optim= 0.18034092140132102\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.005878820549696684\n",
      "Loss on test= 0.007436777930706739\n",
      "acc for Lsat= 0.15243026880455798 \n",
      "acc for Psat= 0.1891974973580113 \n",
      "acc for optim= 0.1800624547302952\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.005678374785929918\n",
      "Loss on test= 0.007634424138814211\n",
      "acc for Lsat= 0.15709359966119232 \n",
      "acc for Psat= 0.21035000174707108 \n",
      "acc for optim= 0.1794361372582794\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.00586642324924469\n",
      "Loss on test= 0.00785155687481165\n",
      "acc for Lsat= 0.15938608643344077 \n",
      "acc for Psat= 0.18846547999342933 \n",
      "acc for optim= 0.18675005096769473\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.005635793786495924\n",
      "Loss on test= 0.007816407829523087\n",
      "acc for Lsat= 0.15284132450422058 \n",
      "acc for Psat= 0.2014108146090427 \n",
      "acc for optim= 0.18830460254026607\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.0057967049069702625\n",
      "Loss on test= 0.007616776507347822\n",
      "acc for Lsat= 0.1453971438983944 \n",
      "acc for Psat= 0.19101955778877724 \n",
      "acc for optim= 0.18340784335493676\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.005960940383374691\n",
      "Loss on test= 0.007356300484389067\n",
      "acc for Lsat= 0.15361195986901532 \n",
      "acc for Psat= 0.19707608294757237 \n",
      "acc for optim= 0.18539273023517558\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.005708594340831041\n",
      "Loss on test= 0.007470527198165655\n",
      "acc for Lsat= 0.15185620682695727 \n",
      "acc for Psat= 0.186102311399605 \n",
      "acc for optim= 0.18818976028534187\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.005881477613002062\n",
      "Loss on test= 0.007709898520261049\n",
      "acc for Lsat= 0.1621654066500983 \n",
      "acc for Psat= 0.2191463598496754 \n",
      "acc for optim= 0.17327066864264884\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.0057111321948468685\n",
      "Loss on test= 0.007478588726371527\n",
      "acc for Lsat= 0.15732580007504304 \n",
      "acc for Psat= 0.19496434648887667 \n",
      "acc for optim= 0.17943620418816744\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.005727781914174557\n",
      "Loss on test= 0.0076706744730472565\n",
      "acc for Lsat= 0.1401179425349673 \n",
      "acc for Psat= 0.19936244639713072 \n",
      "acc for optim= 0.18314180878013922\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.0058649457059800625\n",
      "Loss on test= 0.007427805103361607\n",
      "acc for Lsat= 0.15539501157406047 \n",
      "acc for Psat= 0.18073349121462298 \n",
      "acc for optim= 0.17864842614479606\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.005669810809195042\n",
      "Loss on test= 0.007537254132330418\n",
      "acc for Lsat= 0.14814760295745055 \n",
      "acc for Psat= 0.18921936599568265 \n",
      "acc for optim= 0.1852634036418272\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.0058279382064938545\n",
      "Loss on test= 0.00733547518029809\n",
      "acc for Lsat= 0.14266593684957624 \n",
      "acc for Psat= 0.1871126336182017 \n",
      "acc for optim= 0.1873012251358052\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.005949888378381729\n",
      "Loss on test= 0.007649882696568966\n",
      "acc for Lsat= 0.14547014208462808 \n",
      "acc for Psat= 0.19039821656035322 \n",
      "acc for optim= 0.18998504161575167\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.005658427253365517\n",
      "Loss on test= 0.00761039461940527\n",
      "acc for Lsat= 0.15989303073586256 \n",
      "acc for Psat= 0.20103824298636086 \n",
      "acc for optim= 0.1835238039217671\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.006048324517905712\n",
      "Loss on test= 0.0074470010586082935\n",
      "acc for Lsat= 0.15196531653274462 \n",
      "acc for Psat= 0.19135411632796903 \n",
      "acc for optim= 0.18785234009694368\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.005716132000088692\n",
      "Loss on test= 0.007437035441398621\n",
      "acc for Lsat= 0.15464102195897406 \n",
      "acc for Psat= 0.22278879278598995 \n",
      "acc for optim= 0.18739811741636273\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.005942696239799261\n",
      "Loss on test= 0.007173333317041397\n",
      "acc for Lsat= 0.15301725200709473 \n",
      "acc for Psat= 0.19291011580556142 \n",
      "acc for optim= 0.19095805480114383\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.005721271503716707\n",
      "Loss on test= 0.007052816916257143\n",
      "acc for Lsat= 0.1556687550420766 \n",
      "acc for Psat= 0.1855588971371915 \n",
      "acc for optim= 0.18014815444876744\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.0059935287572443485\n",
      "Loss on test= 0.007731397170573473\n",
      "acc for Lsat= 0.16423571591311303 \n",
      "acc for Psat= 0.2036057322915857 \n",
      "acc for optim= 0.1737671501358177\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.005812463350594044\n",
      "Loss on test= 0.007797045633196831\n",
      "acc for Lsat= 0.16669181960970775 \n",
      "acc for Psat= 0.1999719291237912 \n",
      "acc for optim= 0.19157423508644808\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.005643581971526146\n",
      "Loss on test= 0.00733716506510973\n",
      "acc for Lsat= 0.1559147523868768 \n",
      "acc for Psat= 0.18347489791922272 \n",
      "acc for optim= 0.18145398579139002\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.005582947749644518\n",
      "Loss on test= 0.007642635144293308\n",
      "acc for Lsat= 0.1558609635747118 \n",
      "acc for Psat= 0.1932695259350604 \n",
      "acc for optim= 0.18948871092889916\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.00546527374535799\n",
      "Loss on test= 0.0077411215752363205\n",
      "acc for Lsat= 0.15711335271585458 \n",
      "acc for Psat= 0.19639191875486162 \n",
      "acc for optim= 0.18686130431473072\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.0056205084547400475\n",
      "Loss on test= 0.0075761559419333935\n",
      "acc for Lsat= 0.15704668125917287 \n",
      "acc for Psat= 0.1948973153925777 \n",
      "acc for optim= 0.17884646047958264\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.005581516772508621\n",
      "Loss on test= 0.007524900138378143\n",
      "acc for Lsat= 0.14565053885940035 \n",
      "acc for Psat= 0.19571009806469922 \n",
      "acc for optim= 0.18124714937938002\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.006189823150634766\n",
      "Loss on test= 0.007375355809926987\n",
      "acc for Lsat= 0.15484346280182898 \n",
      "acc for Psat= 0.19329192986250016 \n",
      "acc for optim= 0.18056019154925007\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.005601341370493174\n",
      "Loss on test= 0.007778321858495474\n",
      "acc for Lsat= 0.14937841464578341 \n",
      "acc for Psat= 0.20688608996756183 \n",
      "acc for optim= 0.19350845636470723\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.005823410581797361\n",
      "Loss on test= 0.007525534834712744\n",
      "acc for Lsat= 0.1532803609030184 \n",
      "acc for Psat= 0.18171771037827444 \n",
      "acc for optim= 0.18373408988075232\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.005607472267001867\n",
      "Loss on test= 0.0075784409418702126\n",
      "acc for Lsat= 0.152686994683883 \n",
      "acc for Psat= 0.18818777301009995 \n",
      "acc for optim= 0.17700291405909993\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.005670522805303335\n",
      "Loss on test= 0.0078086452558636665\n",
      "acc for Lsat= 0.14562178179745747 \n",
      "acc for Psat= 0.19375997924314597 \n",
      "acc for optim= 0.183060237220832\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.005596228409558535\n",
      "Loss on test= 0.007283114828169346\n",
      "acc for Lsat= 0.15789513714080983 \n",
      "acc for Psat= 0.20062332606653027 \n",
      "acc for optim= 0.18948064800554631\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.005817685276269913\n",
      "Loss on test= 0.006929626688361168\n",
      "acc for Lsat= 0.14909815788669817 \n",
      "acc for Psat= 0.1965129689618823 \n",
      "acc for optim= 0.18061454565088708\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.005908065475523472\n",
      "Loss on test= 0.007325895596295595\n",
      "acc for Lsat= 0.15031127092432323 \n",
      "acc for Psat= 0.20076382867288184 \n",
      "acc for optim= 0.17704222962454907\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.005734824109822512\n",
      "Loss on test= 0.007555611431598663\n",
      "acc for Lsat= 0.1620933648756706 \n",
      "acc for Psat= 0.19164335865502463 \n",
      "acc for optim= 0.18348704804591195\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.005750452168285847\n",
      "Loss on test= 0.007389629725366831\n",
      "acc for Lsat= 0.1507934696537244 \n",
      "acc for Psat= 0.19188039680851288 \n",
      "acc for optim= 0.1842506854515332\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.005611763335764408\n",
      "Loss on test= 0.007527590729296207\n",
      "acc for Lsat= 0.1505364179448988 \n",
      "acc for Psat= 0.1853681970778929 \n",
      "acc for optim= 0.18322976033936147\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.00546862930059433\n",
      "Loss on test= 0.007727491669356823\n",
      "acc for Lsat= 0.15791981243471173 \n",
      "acc for Psat= 0.19428429228032282 \n",
      "acc for optim= 0.18736133294439586\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.005527825094759464\n",
      "Loss on test= 0.0078610610216856\n",
      "acc for Lsat= 0.15577179604651525 \n",
      "acc for Psat= 0.20542407926996467 \n",
      "acc for optim= 0.1844128155842286\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.005467935930937529\n",
      "Loss on test= 0.007920862175524235\n",
      "acc for Lsat= 0.14438000777049265 \n",
      "acc for Psat= 0.1752042574937776 \n",
      "acc for optim= 0.18130564613183808\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.0055292872712016106\n",
      "Loss on test= 0.007453953847289085\n",
      "acc for Lsat= 0.15643365070239076 \n",
      "acc for Psat= 0.19320399772163985 \n",
      "acc for optim= 0.18866706333394148\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.005659379530698061\n",
      "Loss on test= 0.007850920781493187\n",
      "acc for Lsat= 0.15759498192356197 \n",
      "acc for Psat= 0.20396498300776375 \n",
      "acc for optim= 0.17480659264015305\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.0053539033979177475\n",
      "Loss on test= 0.007303131744265556\n",
      "acc for Lsat= 0.1511992591509565 \n",
      "acc for Psat= 0.19117841149325346 \n",
      "acc for optim= 0.18192808102467098\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.005616743117570877\n",
      "Loss on test= 0.007366638630628586\n",
      "acc for Lsat= 0.15694806828615868 \n",
      "acc for Psat= 0.1915158948219824 \n",
      "acc for optim= 0.18706379854051133\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.005630974657833576\n",
      "Loss on test= 0.007732760161161423\n",
      "acc for Lsat= 0.1512893801008267 \n",
      "acc for Psat= 0.1917854441287851 \n",
      "acc for optim= 0.18556431336156626\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.005368330981582403\n",
      "Loss on test= 0.0071277916431427\n",
      "acc for Lsat= 0.14114673940773068 \n",
      "acc for Psat= 0.19451804940634576 \n",
      "acc for optim= 0.18495273838167034\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.005605763755738735\n",
      "Loss on test= 0.007738318759948015\n",
      "acc for Lsat= 0.14987063922518082 \n",
      "acc for Psat= 0.1964009183779603 \n",
      "acc for optim= 0.18270041764220968\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.006012770812958479\n",
      "Loss on test= 0.007555989548563957\n",
      "acc for Lsat= 0.14602396595778447 \n",
      "acc for Psat= 0.19689513232642938 \n",
      "acc for optim= 0.17958701808457875\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.0056550996378064156\n",
      "Loss on test= 0.007380267605185509\n",
      "acc for Lsat= 0.16468528162203272 \n",
      "acc for Psat= 0.19027343561880475 \n",
      "acc for optim= 0.19056839316197838\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.005622204393148422\n",
      "Loss on test= 0.007289983332157135\n",
      "acc for Lsat= 0.15342760697096877 \n",
      "acc for Psat= 0.1953728650868336 \n",
      "acc for optim= 0.18624920216422397\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.006249789614230394\n",
      "Loss on test= 0.007670736871659756\n",
      "acc for Lsat= 0.14862345931173654 \n",
      "acc for Psat= 0.1861901077525843 \n",
      "acc for optim= 0.18096331927148132\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.005808716639876366\n",
      "Loss on test= 0.007333527319133282\n",
      "acc for Lsat= 0.1598207907522189 \n",
      "acc for Psat= 0.193760254516168 \n",
      "acc for optim= 0.18560575922115202\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.005893896333873272\n",
      "Loss on test= 0.007608878891915083\n",
      "acc for Lsat= 0.15238626879958633 \n",
      "acc for Psat= 0.19075579718595034 \n",
      "acc for optim= 0.18613215827566312\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.0057958755642175674\n",
      "Loss on test= 0.0071166446432471275\n",
      "acc for Lsat= 0.15512952155631118 \n",
      "acc for Psat= 0.18723337350415112 \n",
      "acc for optim= 0.17621286827154825\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.005558792967349291\n",
      "Loss on test= 0.007373251486569643\n",
      "acc for Lsat= 0.1464418191687952 \n",
      "acc for Psat= 0.19606490283364766 \n",
      "acc for optim= 0.18272632465499347\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.0056146797724068165\n",
      "Loss on test= 0.007415425963699818\n",
      "acc for Lsat= 0.14840797087937196 \n",
      "acc for Psat= 0.20028189380865993 \n",
      "acc for optim= 0.1910318561157853\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.005431140307337046\n",
      "Loss on test= 0.007886655628681183\n",
      "acc for Lsat= 0.15499696357836032 \n",
      "acc for Psat= 0.18285931271413097 \n",
      "acc for optim= 0.18094434867895468\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.005924148019403219\n",
      "Loss on test= 0.0072923097759485245\n",
      "acc for Lsat= 0.13670601448040365 \n",
      "acc for Psat= 0.20916603787900684 \n",
      "acc for optim= 0.17798893210539196\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.005526318680495024\n",
      "Loss on test= 0.007527891546487808\n",
      "acc for Lsat= 0.15210032166233745 \n",
      "acc for Psat= 0.21526977792859353 \n",
      "acc for optim= 0.19365302984408087\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.005612820386886597\n",
      "Loss on test= 0.0076722330413758755\n",
      "acc for Lsat= 0.1516343424434499 \n",
      "acc for Psat= 0.20059569784269293 \n",
      "acc for optim= 0.18408983380001298\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.005680857691913843\n",
      "Loss on test= 0.007454707287251949\n",
      "acc for Lsat= 0.15368755575513743 \n",
      "acc for Psat= 0.18767613854743997 \n",
      "acc for optim= 0.1818762362381199\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.0054595279507339\n",
      "Loss on test= 0.007329828105866909\n",
      "acc for Lsat= 0.13742435202117032 \n",
      "acc for Psat= 0.18566834673354188 \n",
      "acc for optim= 0.18423623906154582\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.005753756035119295\n",
      "Loss on test= 0.007514430675655603\n",
      "acc for Lsat= 0.16208604017242056 \n",
      "acc for Psat= 0.19508946887446477 \n",
      "acc for optim= 0.17690310533937129\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.005394254811108112\n",
      "Loss on test= 0.00819019228219986\n",
      "acc for Lsat= 0.16426552496831406 \n",
      "acc for Psat= 0.19678696812870988 \n",
      "acc for optim= 0.1880273161055908\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.005483684130012989\n",
      "Loss on test= 0.007234352175146341\n",
      "acc for Lsat= 0.15174711477507638 \n",
      "acc for Psat= 0.21601086665578492 \n",
      "acc for optim= 0.18554949868455162\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.006172007415443659\n",
      "Loss on test= 0.007266233209520578\n",
      "acc for Lsat= 0.13775095087981815 \n",
      "acc for Psat= 0.19073527889788058 \n",
      "acc for optim= 0.17750807000327948\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.005353567190468311\n",
      "Loss on test= 0.007674653548747301\n",
      "acc for Lsat= 0.15323266565769178 \n",
      "acc for Psat= 0.17668226947969773 \n",
      "acc for optim= 0.18544106275266892\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.005665481556206942\n",
      "Loss on test= 0.007568657398223877\n",
      "acc for Lsat= 0.14543421466817666 \n",
      "acc for Psat= 0.19314820951401432 \n",
      "acc for optim= 0.18668898621661834\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.005413082428276539\n",
      "Loss on test= 0.007321944925934076\n",
      "acc for Lsat= 0.14722381695965686 \n",
      "acc for Psat= 0.19134845874614853 \n",
      "acc for optim= 0.172276524605886\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.005663852207362652\n",
      "Loss on test= 0.006969803012907505\n",
      "acc for Lsat= 0.1563781158914637 \n",
      "acc for Psat= 0.19818594172581663 \n",
      "acc for optim= 0.18564671611749248\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.005448633339256048\n",
      "Loss on test= 0.007654459681361914\n",
      "acc for Lsat= 0.14795638971091782 \n",
      "acc for Psat= 0.19204363091541055 \n",
      "acc for optim= 0.18813497471903665\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.005628474522382021\n",
      "Loss on test= 0.007148647215217352\n",
      "acc for Lsat= 0.1517836920571605 \n",
      "acc for Psat= 0.19838687235048874 \n",
      "acc for optim= 0.18307592197126693\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.005319383926689625\n",
      "Loss on test= 0.007764783222228289\n",
      "acc for Lsat= 0.15738341212577997 \n",
      "acc for Psat= 0.18434033877880418 \n",
      "acc for optim= 0.18248539571745748\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.005445669870823622\n",
      "Loss on test= 0.007365829311311245\n",
      "acc for Lsat= 0.14632835451792162 \n",
      "acc for Psat= 0.1783708224966206 \n",
      "acc for optim= 0.1845429372069136\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.005411791615188122\n",
      "Loss on test= 0.007373458240181208\n",
      "acc for Lsat= 0.14324921573565694 \n",
      "acc for Psat= 0.18964424511726916 \n",
      "acc for optim= 0.18847417832738325\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.005528521724045277\n",
      "Loss on test= 0.007137966342270374\n",
      "acc for Lsat= 0.14713456266679892 \n",
      "acc for Psat= 0.20101118938363782 \n",
      "acc for optim= 0.1826493644419524\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.005748674273490906\n",
      "Loss on test= 0.007144377566874027\n",
      "acc for Lsat= 0.15177069546399088 \n",
      "acc for Psat= 0.1843026723892077 \n",
      "acc for optim= 0.173266177020488\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.005514140240848064\n",
      "Loss on test= 0.007238674908876419\n",
      "acc for Lsat= 0.138711565571048 \n",
      "acc for Psat= 0.1943646194791177 \n",
      "acc for optim= 0.18809722591397643\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.005464901681989431\n",
      "Loss on test= 0.00726186390966177\n",
      "acc for Lsat= 0.15089787574080354 \n",
      "acc for Psat= 0.1927084957702719 \n",
      "acc for optim= 0.18672595427058575\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.006220675073564053\n",
      "Loss on test= 0.007796581368893385\n",
      "acc for Lsat= 0.1554671203822554 \n",
      "acc for Psat= 0.21791362079827986 \n",
      "acc for optim= 0.1894201211584064\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.005463054403662682\n",
      "Loss on test= 0.007458769716322422\n",
      "acc for Lsat= 0.15423068719563937 \n",
      "acc for Psat= 0.19126188941858135 \n",
      "acc for optim= 0.1856994644918005\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.006135615520179272\n",
      "Loss on test= 0.007472354918718338\n",
      "acc for Lsat= 0.1500343436680612 \n",
      "acc for Psat= 0.18851557923881643 \n",
      "acc for optim= 0.18196704693894344\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.005642824340611696\n",
      "Loss on test= 0.007913046516478062\n",
      "acc for Lsat= 0.14336949633014556 \n",
      "acc for Psat= 0.19264101674245884 \n",
      "acc for optim= 0.18362500620023042\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.005509461276233196\n",
      "Loss on test= 0.007857682183384895\n",
      "acc for Lsat= 0.14927484080974074 \n",
      "acc for Psat= 0.18851576801045936 \n",
      "acc for optim= 0.1839822685617007\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.0054416111670434475\n",
      "Loss on test= 0.007998415268957615\n",
      "acc for Lsat= 0.15092890109670287 \n",
      "acc for Psat= 0.19075875740124248 \n",
      "acc for optim= 0.18134273732964667\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.005373291205614805\n",
      "Loss on test= 0.006932304706424475\n",
      "acc for Lsat= 0.15348063968503695 \n",
      "acc for Psat= 0.19198872293565103 \n",
      "acc for optim= 0.17920412997959456\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.005684933625161648\n",
      "Loss on test= 0.007605269551277161\n",
      "acc for Lsat= 0.15822974897808487 \n",
      "acc for Psat= 0.19800289149413297 \n",
      "acc for optim= 0.18757551382925575\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.005544763989746571\n",
      "Loss on test= 0.0074032205156981945\n",
      "acc for Lsat= 0.14013690926481923 \n",
      "acc for Psat= 0.1940949312586826 \n",
      "acc for optim= 0.18668872850153168\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.0054555428214371204\n",
      "Loss on test= 0.00800179224461317\n",
      "acc for Lsat= 0.14592749901100627 \n",
      "acc for Psat= 0.18870109658073786 \n",
      "acc for optim= 0.18663215404529063\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.005673705600202084\n",
      "Loss on test= 0.007092915941029787\n",
      "acc for Lsat= 0.15446150516404114 \n",
      "acc for Psat= 0.20248645339924537 \n",
      "acc for optim= 0.1821991358883679\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.00523367989808321\n",
      "Loss on test= 0.007744202855974436\n",
      "acc for Lsat= 0.15051417527648767 \n",
      "acc for Psat= 0.1942588479718056 \n",
      "acc for optim= 0.18406538605309147\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.005349398590624332\n",
      "Loss on test= 0.007533257827162743\n",
      "acc for Lsat= 0.14192373172182507 \n",
      "acc for Psat= 0.1847224268930598 \n",
      "acc for optim= 0.19532891792463727\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.005505917128175497\n",
      "Loss on test= 0.006946424022316933\n",
      "acc for Lsat= 0.15287222625519775 \n",
      "acc for Psat= 0.18918786726998868 \n",
      "acc for optim= 0.18278747962627437\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.005649195984005928\n",
      "Loss on test= 0.007446207571774721\n",
      "acc for Lsat= 0.14210487041988823 \n",
      "acc for Psat= 0.19223766126793992 \n",
      "acc for optim= 0.17655565349736296\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.005587504245340824\n",
      "Loss on test= 0.0066521004773676395\n",
      "acc for Lsat= 0.14880261565520445 \n",
      "acc for Psat= 0.20117419004024267 \n",
      "acc for optim= 0.1818766332585002\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.005534729920327663\n",
      "Loss on test= 0.006926674861460924\n",
      "acc for Lsat= 0.14781901521081503 \n",
      "acc for Psat= 0.17891879033614103 \n",
      "acc for optim= 0.18102470070732468\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.0055738287046551704\n",
      "Loss on test= 0.007355336099863052\n",
      "acc for Lsat= 0.146371757736254 \n",
      "acc for Psat= 0.19578423334321876 \n",
      "acc for optim= 0.18556994464425905\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.00575638934969902\n",
      "Loss on test= 0.007387318182736635\n",
      "acc for Lsat= 0.1448402028947832 \n",
      "acc for Psat= 0.19984344301695675 \n",
      "acc for optim= 0.19126644352942154\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.005593960639089346\n",
      "Loss on test= 0.007576304022222757\n",
      "acc for Lsat= 0.14601439073716183 \n",
      "acc for Psat= 0.19757204016567528 \n",
      "acc for optim= 0.18468986622832684\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.005752647761255503\n",
      "Loss on test= 0.007573866285383701\n",
      "acc for Lsat= 0.14242077294706565 \n",
      "acc for Psat= 0.20232923850169038 \n",
      "acc for optim= 0.1820795392403837\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.005818143952637911\n",
      "Loss on test= 0.007235361263155937\n",
      "acc for Lsat= 0.14617381712543914 \n",
      "acc for Psat= 0.1764113370709877 \n",
      "acc for optim= 0.18992817233656303\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.005536616779863834\n",
      "Loss on test= 0.007328374311327934\n",
      "acc for Lsat= 0.15020153702458092 \n",
      "acc for Psat= 0.18260903204943923 \n",
      "acc for optim= 0.18503171906340868\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.005642774049192667\n",
      "Loss on test= 0.007589609827846289\n",
      "acc for Lsat= 0.15076234679245468 \n",
      "acc for Psat= 0.2017331784617797 \n",
      "acc for optim= 0.18080171299697526\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.005316880531609058\n",
      "Loss on test= 0.007185190450400114\n",
      "acc for Lsat= 0.15219970832394672 \n",
      "acc for Psat= 0.19070440627058174 \n",
      "acc for optim= 0.18209920374859795\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.005594373214989901\n",
      "Loss on test= 0.007359728217124939\n",
      "acc for Lsat= 0.13450495603205218 \n",
      "acc for Psat= 0.1738423841347017 \n",
      "acc for optim= 0.17566097529202349\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.005321762524545193\n",
      "Loss on test= 0.007333933841437101\n",
      "acc for Lsat= 0.15368078660702267 \n",
      "acc for Psat= 0.1940007858360749 \n",
      "acc for optim= 0.18318765203150744\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.00568531034514308\n",
      "Loss on test= 0.007024163845926523\n",
      "acc for Lsat= 0.15467533518896118 \n",
      "acc for Psat= 0.18248691887607402 \n",
      "acc for optim= 0.1813978590044483\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.005482002627104521\n",
      "Loss on test= 0.007326516322791576\n",
      "acc for Lsat= 0.14852388319769325 \n",
      "acc for Psat= 0.1945064722781726 \n",
      "acc for optim= 0.18623287461308732\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.005772909615188837\n",
      "Loss on test= 0.007418782450258732\n",
      "acc for Lsat= 0.14560359068153822 \n",
      "acc for Psat= 0.19478888540284434 \n",
      "acc for optim= 0.18264972168081975\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.005222914274781942\n",
      "Loss on test= 0.007841955870389938\n",
      "acc for Lsat= 0.13834422629104248 \n",
      "acc for Psat= 0.1817681302053121 \n",
      "acc for optim= 0.18645542305168986\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.005615784786641598\n",
      "Loss on test= 0.007314678281545639\n",
      "acc for Lsat= 0.15745818356489075 \n",
      "acc for Psat= 0.19562803279898572 \n",
      "acc for optim= 0.1840109565176001\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.005481785163283348\n",
      "Loss on test= 0.007570748217403889\n",
      "acc for Lsat= 0.14851207239018968 \n",
      "acc for Psat= 0.19761070117056675 \n",
      "acc for optim= 0.19002657119360308\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.005318553652614355\n",
      "Loss on test= 0.007715533021837473\n",
      "acc for Lsat= 0.1459950488018727 \n",
      "acc for Psat= 0.186102159890789 \n",
      "acc for optim= 0.1771489001637359\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.005489002913236618\n",
      "Loss on test= 0.007443447597324848\n",
      "acc for Lsat= 0.14597966420515746 \n",
      "acc for Psat= 0.18458612267997643 \n",
      "acc for optim= 0.1804884523412854\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.00537083949893713\n",
      "Loss on test= 0.007745471317321062\n",
      "acc for Lsat= 0.15269035637244147 \n",
      "acc for Psat= 0.19254981224219025 \n",
      "acc for optim= 0.18737706614879615\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.0052616288885474205\n",
      "Loss on test= 0.007766046095639467\n",
      "acc for Lsat= 0.14899161499772282 \n",
      "acc for Psat= 0.20079430465130366 \n",
      "acc for optim= 0.18946157456413829\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.005371513776481152\n",
      "Loss on test= 0.007907315157353878\n",
      "acc for Lsat= 0.15065910849242173 \n",
      "acc for Psat= 0.1989763307522555 \n",
      "acc for optim= 0.1829798800090698\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.004998598247766495\n",
      "Loss on test= 0.0076500424183905125\n",
      "acc for Lsat= 0.14510390734925988 \n",
      "acc for Psat= 0.2028169974700937 \n",
      "acc for optim= 0.18362836224202556\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.005463858600705862\n",
      "Loss on test= 0.007201231550425291\n",
      "acc for Lsat= 0.14881130475569976 \n",
      "acc for Psat= 0.1908224495494219 \n",
      "acc for optim= 0.17952042700127377\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.005257931537926197\n",
      "Loss on test= 0.007189372554421425\n",
      "acc for Lsat= 0.1467722832367681 \n",
      "acc for Psat= 0.19241771559368392 \n",
      "acc for optim= 0.19060005543259217\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.0054035307839512825\n",
      "Loss on test= 0.007252139039337635\n",
      "acc for Lsat= 0.1405612800781783 \n",
      "acc for Psat= 0.21214029753970012 \n",
      "acc for optim= 0.18487657009591502\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.0052336822263896465\n",
      "Loss on test= 0.007606840692460537\n",
      "acc for Lsat= 0.15875164786197216 \n",
      "acc for Psat= 0.18838960126893534 \n",
      "acc for optim= 0.1848915036368975\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.005566941108554602\n",
      "Loss on test= 0.007391968742012978\n",
      "acc for Lsat= 0.14976896144379098 \n",
      "acc for Psat= 0.19897178475588528 \n",
      "acc for optim= 0.182515860367261\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.005526325665414333\n",
      "Loss on test= 0.007976789027452469\n",
      "acc for Lsat= 0.14331271224388029 \n",
      "acc for Psat= 0.1831859323012902 \n",
      "acc for optim= 0.18847546892385686\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.005625804420560598\n",
      "Loss on test= 0.007293860428035259\n",
      "acc for Lsat= 0.14968339408515022 \n",
      "acc for Psat= 0.18311019230702677 \n",
      "acc for optim= 0.1855726590888674\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.005602662451565266\n",
      "Loss on test= 0.0074492148123681545\n",
      "acc for Lsat= 0.14214775731622958 \n",
      "acc for Psat= 0.18570951518898957 \n",
      "acc for optim= 0.18477914000510193\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.005423611029982567\n",
      "Loss on test= 0.007485105190426111\n",
      "acc for Lsat= 0.15347132063766591 \n",
      "acc for Psat= 0.18852192679397212 \n",
      "acc for optim= 0.18327392650897936\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.005493710748851299\n",
      "Loss on test= 0.007364245597273111\n",
      "acc for Lsat= 0.14500892738206694 \n",
      "acc for Psat= 0.18348358837235432 \n",
      "acc for optim= 0.18214753897036196\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.005631778854876757\n",
      "Loss on test= 0.007196333259344101\n",
      "acc for Lsat= 0.13919070537858566 \n",
      "acc for Psat= 0.17108689336503138 \n",
      "acc for optim= 0.1827177453065815\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.005484967492520809\n",
      "Loss on test= 0.007774875964969397\n",
      "acc for Lsat= 0.16048843595733653 \n",
      "acc for Psat= 0.1891519366443867 \n",
      "acc for optim= 0.18395359620001533\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.005311797372996807\n",
      "Loss on test= 0.007349660154432058\n",
      "acc for Lsat= 0.1449166053761041 \n",
      "acc for Psat= 0.20118304408311874 \n",
      "acc for optim= 0.18370092108055613\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.005400095134973526\n",
      "Loss on test= 0.007205354981124401\n",
      "acc for Lsat= 0.13960351690909537 \n",
      "acc for Psat= 0.18925301322282184 \n",
      "acc for optim= 0.18282223739871206\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.0053015886805951595\n",
      "Loss on test= 0.007228724658489227\n",
      "acc for Lsat= 0.1466804427905848 \n",
      "acc for Psat= 0.1867020573781433 \n",
      "acc for optim= 0.18146200675830307\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.005552168935537338\n",
      "Loss on test= 0.007377292960882187\n",
      "acc for Lsat= 0.14508482829899505 \n",
      "acc for Psat= 0.193984259319631 \n",
      "acc for optim= 0.18418517499316683\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.005620142444968224\n",
      "Loss on test= 0.007161917630583048\n",
      "acc for Lsat= 0.14457282588223652 \n",
      "acc for Psat= 0.1907788738253389 \n",
      "acc for optim= 0.1882524739050108\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.005621098913252354\n",
      "Loss on test= 0.007367477286607027\n",
      "acc for Lsat= 0.14537309140699808 \n",
      "acc for Psat= 0.1931926915976486 \n",
      "acc for optim= 0.18151639578988027\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.005504726432263851\n",
      "Loss on test= 0.00774744525551796\n",
      "acc for Lsat= 0.1485535409745651 \n",
      "acc for Psat= 0.2022948237083047 \n",
      "acc for optim= 0.1771074035467806\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.0053346892818808556\n",
      "Loss on test= 0.007675439119338989\n",
      "acc for Lsat= 0.1485450377544678 \n",
      "acc for Psat= 0.18994174834997316 \n",
      "acc for optim= 0.1823478376262413\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.0055915312841534615\n",
      "Loss on test= 0.007262897677719593\n",
      "acc for Lsat= 0.1508543235263415 \n",
      "acc for Psat= 0.19529347233932282 \n",
      "acc for optim= 0.18297722688332185\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.005779200233519077\n",
      "Loss on test= 0.006890634540468454\n",
      "acc for Lsat= 0.13863788494541116 \n",
      "acc for Psat= 0.19473522683380354 \n",
      "acc for optim= 0.18037497840342723\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.0054745241068303585\n",
      "Loss on test= 0.007455853745341301\n",
      "acc for Lsat= 0.14264600804276717 \n",
      "acc for Psat= 0.19825319920587314 \n",
      "acc for optim= 0.18416160596515524\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.0056010582484304905\n",
      "Loss on test= 0.007225773762911558\n",
      "acc for Lsat= 0.14470131493619162 \n",
      "acc for Psat= 0.17945323166490884 \n",
      "acc for optim= 0.18505668457073626\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.005131907295435667\n",
      "Loss on test= 0.007725850213319063\n",
      "acc for Lsat= 0.1455595312743127 \n",
      "acc for Psat= 0.18365801024361852 \n",
      "acc for optim= 0.17842812956249737\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.00529351644217968\n",
      "Loss on test= 0.007381617557257414\n",
      "acc for Lsat= 0.14525615132631367 \n",
      "acc for Psat= 0.18149151352795267 \n",
      "acc for optim= 0.19195567483729378\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.005735504440963268\n",
      "Loss on test= 0.007403949275612831\n",
      "acc for Lsat= 0.1457544098902693 \n",
      "acc for Psat= 0.18789485237278716 \n",
      "acc for optim= 0.18400235780348742\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.005492298863828182\n",
      "Loss on test= 0.00744106899946928\n",
      "acc for Lsat= 0.15342936667796897 \n",
      "acc for Psat= 0.18920208702925936 \n",
      "acc for optim= 0.1806001753555005\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.005296292714774609\n",
      "Loss on test= 0.007341262884438038\n",
      "acc for Lsat= 0.1432876152457568 \n",
      "acc for Psat= 0.19279450430290498 \n",
      "acc for optim= 0.17958490705789357\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.005756053142249584\n",
      "Loss on test= 0.0072487941943109035\n",
      "acc for Lsat= 0.14260317919457133 \n",
      "acc for Psat= 0.17720171301816515 \n",
      "acc for optim= 0.18689423806556943\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.005228586494922638\n",
      "Loss on test= 0.007508442271500826\n",
      "acc for Lsat= 0.1502579471435623 \n",
      "acc for Psat= 0.19574178098686626 \n",
      "acc for optim= 0.1840709823813503\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.0053115529008209705\n",
      "Loss on test= 0.007816786877810955\n",
      "acc for Lsat= 0.14438384212076388 \n",
      "acc for Psat= 0.19528625437486 \n",
      "acc for optim= 0.18671196813382146\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.0055060493759810925\n",
      "Loss on test= 0.007307065185159445\n",
      "acc for Lsat= 0.1474370543184675 \n",
      "acc for Psat= 0.20078314967180572 \n",
      "acc for optim= 0.19012740297552166\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.00510809663683176\n",
      "Loss on test= 0.0072660064324736595\n",
      "acc for Lsat= 0.15335150784497975 \n",
      "acc for Psat= 0.20342539327360354 \n",
      "acc for optim= 0.1804956248556798\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.005564506631344557\n",
      "Loss on test= 0.0074844518676400185\n",
      "acc for Lsat= 0.14832832555584305 \n",
      "acc for Psat= 0.19718602112986788 \n",
      "acc for optim= 0.1897286867608362\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.005167287774384022\n",
      "Loss on test= 0.0077352444641292095\n",
      "acc for Lsat= 0.1515471798847773 \n",
      "acc for Psat= 0.1976398901426096 \n",
      "acc for optim= 0.18798477453681578\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.005360399838536978\n",
      "Loss on test= 0.007541459519416094\n",
      "acc for Lsat= 0.14539713041334926 \n",
      "acc for Psat= 0.1904310130239388 \n",
      "acc for optim= 0.18667813260613972\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.005136149935424328\n",
      "Loss on test= 0.007343111094087362\n",
      "acc for Lsat= 0.15510918633012435 \n",
      "acc for Psat= 0.1958711136542318 \n",
      "acc for optim= 0.1782284385545683\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.005205848719924688\n",
      "Loss on test= 0.00710654491558671\n",
      "acc for Lsat= 0.14722720684376775 \n",
      "acc for Psat= 0.19492326730687637 \n",
      "acc for optim= 0.18952023056373915\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.005441557615995407\n",
      "Loss on test= 0.007693348452448845\n",
      "acc for Lsat= 0.14458023377739038 \n",
      "acc for Psat= 0.16815725092806655 \n",
      "acc for optim= 0.18847755013247494\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.005617052316665649\n",
      "Loss on test= 0.007906361483037472\n",
      "acc for Lsat= 0.14209627033474656 \n",
      "acc for Psat= 0.1986139094537185 \n",
      "acc for optim= 0.1933444099512226\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.005490646231919527\n",
      "Loss on test= 0.007440462242811918\n",
      "acc for Lsat= 0.1592797257741875 \n",
      "acc for Psat= 0.2010315857204555 \n",
      "acc for optim= 0.18609824261960162\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.005259516183286905\n",
      "Loss on test= 0.00739556597545743\n",
      "acc for Lsat= 0.15878931295325155 \n",
      "acc for Psat= 0.20216406871207807 \n",
      "acc for optim= 0.17823389922850766\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.005287340376526117\n",
      "Loss on test= 0.0075546978041529655\n",
      "acc for Lsat= 0.14793834415998047 \n",
      "acc for Psat= 0.1981145426111876 \n",
      "acc for optim= 0.18755253591306592\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.005333855282515287\n",
      "Loss on test= 0.007437663618475199\n",
      "acc for Lsat= 0.14557648106543997 \n",
      "acc for Psat= 0.18955358731060395 \n",
      "acc for optim= 0.17997464071577568\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.005377355497330427\n",
      "Loss on test= 0.007470279466360807\n",
      "acc for Lsat= 0.15157747635862134 \n",
      "acc for Psat= 0.19551280108905497 \n",
      "acc for optim= 0.18852093392013589\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.005241751670837402\n",
      "Loss on test= 0.007845791056752205\n",
      "acc for Lsat= 0.1495971193575285 \n",
      "acc for Psat= 0.19503937645158806 \n",
      "acc for optim= 0.18487553790547565\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.005170841701328754\n",
      "Loss on test= 0.007761228829622269\n",
      "acc for Lsat= 0.15384399089714146 \n",
      "acc for Psat= 0.18322073930481328 \n",
      "acc for optim= 0.18467436940790932\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.005384289193898439\n",
      "Loss on test= 0.0074248844757676125\n",
      "acc for Lsat= 0.1582875948457513 \n",
      "acc for Psat= 0.19055316550485393 \n",
      "acc for optim= 0.18122135550919233\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.005479360930621624\n",
      "Loss on test= 0.007469288073480129\n",
      "acc for Lsat= 0.15899254171994562 \n",
      "acc for Psat= 0.18673677411976225 \n",
      "acc for optim= 0.1840807447934091\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.005419476889073849\n",
      "Loss on test= 0.006965139880776405\n",
      "acc for Lsat= 0.14037790466767935 \n",
      "acc for Psat= 0.18800228032453814 \n",
      "acc for optim= 0.1894004707266653\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.005483352579176426\n",
      "Loss on test= 0.0073323920369148254\n",
      "acc for Lsat= 0.15007344477649656 \n",
      "acc for Psat= 0.19170288012466072 \n",
      "acc for optim= 0.18513343188310277\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.005215245299041271\n",
      "Loss on test= 0.007247161120176315\n",
      "acc for Lsat= 0.14730642848480188 \n",
      "acc for Psat= 0.18969978384032357 \n",
      "acc for optim= 0.18354918496625033\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.005154683254659176\n",
      "Loss on test= 0.0076695941388607025\n",
      "acc for Lsat= 0.13834328983250058 \n",
      "acc for Psat= 0.1969468587845231 \n",
      "acc for optim= 0.18639654601832517\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.005516226403415203\n",
      "Loss on test= 0.007560501806437969\n",
      "acc for Lsat= 0.14953911185157714 \n",
      "acc for Psat= 0.1879779752684074 \n",
      "acc for optim= 0.18660112336949736\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.005691052880138159\n",
      "Loss on test= 0.007658370770514011\n",
      "acc for Lsat= 0.15296296268762624 \n",
      "acc for Psat= 0.19472532369688794 \n",
      "acc for optim= 0.1847302507028961\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.005223751999437809\n",
      "Loss on test= 0.007172628305852413\n",
      "acc for Lsat= 0.1553474256056256 \n",
      "acc for Psat= 0.1915123974810904 \n",
      "acc for optim= 0.19473314793230814\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.0056945267133414745\n",
      "Loss on test= 0.007287479471415281\n",
      "acc for Lsat= 0.146292913676293 \n",
      "acc for Psat= 0.19334343656893727 \n",
      "acc for optim= 0.17659902310601938\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.005262958351522684\n",
      "Loss on test= 0.0074189938604831696\n",
      "acc for Lsat= 0.15824641609663662 \n",
      "acc for Psat= 0.20262202181002664 \n",
      "acc for optim= 0.17620844194192256\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.005207176320254803\n",
      "Loss on test= 0.007330200169235468\n",
      "acc for Lsat= 0.14607962590420895 \n",
      "acc for Psat= 0.20466024234993993 \n",
      "acc for optim= 0.1848567359937645\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.005549623630940914\n",
      "Loss on test= 0.007534209173172712\n",
      "acc for Lsat= 0.14813592512423907 \n",
      "acc for Psat= 0.18806015335588303 \n",
      "acc for optim= 0.18478116180958154\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.005266345571726561\n",
      "Loss on test= 0.007538173347711563\n",
      "acc for Lsat= 0.1403627913653255 \n",
      "acc for Psat= 0.1937583488265251 \n",
      "acc for optim= 0.1875542037315203\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.005296858958899975\n",
      "Loss on test= 0.00737404590472579\n",
      "acc for Lsat= 0.14688485995942696 \n",
      "acc for Psat= 0.1857537490918805 \n",
      "acc for optim= 0.186231651343775\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.005179033149033785\n",
      "Loss on test= 0.007553257048130035\n",
      "acc for Lsat= 0.1435140707316335 \n",
      "acc for Psat= 0.1878752046648306 \n",
      "acc for optim= 0.1858245144598186\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.00517125241458416\n",
      "Loss on test= 0.007464832626283169\n",
      "acc for Lsat= 0.15221987512787102 \n",
      "acc for Psat= 0.2012317521841128 \n",
      "acc for optim= 0.18903020286663497\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.005196381360292435\n",
      "Loss on test= 0.007767302915453911\n",
      "acc for Lsat= 0.14618562853238623 \n",
      "acc for Psat= 0.19417614859269292 \n",
      "acc for optim= 0.181422809429169\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.005535135045647621\n",
      "Loss on test= 0.007458190433681011\n",
      "acc for Lsat= 0.14293482722046585 \n",
      "acc for Psat= 0.19110024891579983 \n",
      "acc for optim= 0.18722177121643221\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.0052415914833545685\n",
      "Loss on test= 0.006883710157126188\n",
      "acc for Lsat= 0.1603730257856278 \n",
      "acc for Psat= 0.19337820520980087 \n",
      "acc for optim= 0.1886906968673966\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.00678191939368844\n",
      "Loss on test= 0.00732347322627902\n",
      "acc for Lsat= 0.1424897886690069 \n",
      "acc for Psat= 0.1748279870762566 \n",
      "acc for optim= 0.1862560650320403\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.005662239156663418\n",
      "Loss on test= 0.007633739151060581\n",
      "acc for Lsat= 0.13221141017735344 \n",
      "acc for Psat= 0.1900940243783598 \n",
      "acc for optim= 0.18379090835042602\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.005434841383248568\n",
      "Loss on test= 0.00783274695277214\n",
      "acc for Lsat= 0.14160600037564006 \n",
      "acc for Psat= 0.18204279525508937 \n",
      "acc for optim= 0.18461976226755097\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.005485490895807743\n",
      "Loss on test= 0.007251787930727005\n",
      "acc for Lsat= 0.15028898490384818 \n",
      "acc for Psat= 0.19289214511627506 \n",
      "acc for optim= 0.1825675581024624\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.005352775566279888\n",
      "Loss on test= 0.00759918661788106\n",
      "acc for Lsat= 0.13743942116576124 \n",
      "acc for Psat= 0.19720480866638607 \n",
      "acc for optim= 0.17838803402321857\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.00532842893153429\n",
      "Loss on test= 0.007304050959646702\n",
      "acc for Lsat= 0.14028849745413563 \n",
      "acc for Psat= 0.18598955744117895 \n",
      "acc for optim= 0.18971688394343145\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.005305057857185602\n",
      "Loss on test= 0.007371537387371063\n",
      "acc for Lsat= 0.1517461058532926 \n",
      "acc for Psat= 0.18369026968530455 \n",
      "acc for optim= 0.18495589738833856\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.00542433699592948\n",
      "Loss on test= 0.007120367139577866\n",
      "acc for Lsat= 0.15207153382161478 \n",
      "acc for Psat= 0.1922042844776965 \n",
      "acc for optim= 0.18419633918297745\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.005570097826421261\n",
      "Loss on test= 0.007283387240022421\n",
      "acc for Lsat= 0.14031202816199245 \n",
      "acc for Psat= 0.19407528853177505 \n",
      "acc for optim= 0.17528071268188497\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.005385926924645901\n",
      "Loss on test= 0.007200705353170633\n",
      "acc for Lsat= 0.14649305461748927 \n",
      "acc for Psat= 0.19470496687994693 \n",
      "acc for optim= 0.18160589780032513\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.005246590357273817\n",
      "Loss on test= 0.00745866633951664\n",
      "acc for Lsat= 0.13716981754233665 \n",
      "acc for Psat= 0.190940604993375 \n",
      "acc for optim= 0.1860538426237028\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.0052847289480268955\n",
      "Loss on test= 0.00759884575381875\n",
      "acc for Lsat= 0.15306194698534425 \n",
      "acc for Psat= 0.19119504887580138 \n",
      "acc for optim= 0.18059719495139406\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.005570113658905029\n",
      "Loss on test= 0.007073192857205868\n",
      "acc for Lsat= 0.15150951928336012 \n",
      "acc for Psat= 0.18998256757970877 \n",
      "acc for optim= 0.1813580432660706\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.005610181484371424\n",
      "Loss on test= 0.007221298757940531\n",
      "acc for Lsat= 0.15079366335698755 \n",
      "acc for Psat= 0.19311910978481212 \n",
      "acc for optim= 0.18560540026648267\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.005119489971548319\n",
      "Loss on test= 0.007521193008869886\n",
      "acc for Lsat= 0.14339175510528443 \n",
      "acc for Psat= 0.18046348724203168 \n",
      "acc for optim= 0.18752643693291934\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.005349353887140751\n",
      "Loss on test= 0.007511193864047527\n",
      "acc for Lsat= 0.14476231364285208 \n",
      "acc for Psat= 0.19057609160568137 \n",
      "acc for optim= 0.1742273225172062\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.005420577712357044\n",
      "Loss on test= 0.007390150334686041\n",
      "acc for Lsat= 0.1511882255378668 \n",
      "acc for Psat= 0.21382081986549997 \n",
      "acc for optim= 0.1785144814114529\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.005398680455982685\n",
      "Loss on test= 0.007632491644471884\n",
      "acc for Lsat= 0.14873168697765815 \n",
      "acc for Psat= 0.19163022312072303 \n",
      "acc for optim= 0.19094276196079055\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.0054055387154221535\n",
      "Loss on test= 0.007481230888515711\n",
      "acc for Lsat= 0.14267769777331718 \n",
      "acc for Psat= 0.18399472663324082 \n",
      "acc for optim= 0.18154601237391213\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.005276220850646496\n",
      "Loss on test= 0.00720963254570961\n",
      "acc for Lsat= 0.14268877617289602 \n",
      "acc for Psat= 0.18977050990024658 \n",
      "acc for optim= 0.19158066127212625\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.005226850509643555\n",
      "Loss on test= 0.007160857319831848\n",
      "acc for Lsat= 0.14781450538153637 \n",
      "acc for Psat= 0.184909490955546 \n",
      "acc for optim= 0.18897559084971513\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.005040078889578581\n",
      "Loss on test= 0.0074828015640378\n",
      "acc for Lsat= 0.14040168206833425 \n",
      "acc for Psat= 0.18058694759574642 \n",
      "acc for optim= 0.18347601357434273\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.005099263973534107\n",
      "Loss on test= 0.007451541256159544\n",
      "acc for Lsat= 0.1357330732078093 \n",
      "acc for Psat= 0.18231333702937202 \n",
      "acc for optim= 0.19068440695705471\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.005536471493542194\n",
      "Loss on test= 0.007648005150258541\n",
      "acc for Lsat= 0.14257570783737436 \n",
      "acc for Psat= 0.191748784186288 \n",
      "acc for optim= 0.1880557100847745\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.00527846347540617\n",
      "Loss on test= 0.006943092215806246\n",
      "acc for Lsat= 0.14650956087909853 \n",
      "acc for Psat= 0.18077977232283868 \n",
      "acc for optim= 0.18294153624275303\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.004959927871823311\n",
      "Loss on test= 0.007266686297953129\n",
      "acc for Lsat= 0.1414910098129395 \n",
      "acc for Psat= 0.19441971439852945 \n",
      "acc for optim= 0.18802063094741153\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.005542655475437641\n",
      "Loss on test= 0.008019774220883846\n",
      "acc for Lsat= 0.15590950182188668 \n",
      "acc for Psat= 0.19281672455358975 \n",
      "acc for optim= 0.1846624530856612\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.005087622907012701\n",
      "Loss on test= 0.007355979178100824\n",
      "acc for Lsat= 0.14677008051890642 \n",
      "acc for Psat= 0.1834820109625637 \n",
      "acc for optim= 0.18749782521979974\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.005591088905930519\n",
      "Loss on test= 0.007590518333017826\n",
      "acc for Lsat= 0.14618072614296088 \n",
      "acc for Psat= 0.18437885333646517 \n",
      "acc for optim= 0.19050825262894533\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.00523908156901598\n",
      "Loss on test= 0.007268757093697786\n",
      "acc for Lsat= 0.14660598776173459 \n",
      "acc for Psat= 0.1900417737101947 \n",
      "acc for optim= 0.1865340177981244\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.005555609241127968\n",
      "Loss on test= 0.007137853652238846\n",
      "acc for Lsat= 0.14218915738928758 \n",
      "acc for Psat= 0.1910025500274477 \n",
      "acc for optim= 0.18588199044222806\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.005257331766188145\n",
      "Loss on test= 0.007110910955816507\n",
      "acc for Lsat= 0.15719501157291232 \n",
      "acc for Psat= 0.20151922998484223 \n",
      "acc for optim= 0.18693773117904994\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.0052736299112439156\n",
      "Loss on test= 0.007565104402601719\n",
      "acc for Lsat= 0.1501795007351053 \n",
      "acc for Psat= 0.17498704687173128 \n",
      "acc for optim= 0.18140086128040536\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.005562362726777792\n",
      "Loss on test= 0.007524853106588125\n",
      "acc for Lsat= 0.14452518325541874 \n",
      "acc for Psat= 0.19561058675076384 \n",
      "acc for optim= 0.17554560728852073\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.005426769144833088\n",
      "Loss on test= 0.007451396901160479\n",
      "acc for Lsat= 0.14642942973153025 \n",
      "acc for Psat= 0.18382818920902344 \n",
      "acc for optim= 0.18292179392120175\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.005403163842856884\n",
      "Loss on test= 0.0072343358770012856\n",
      "acc for Lsat= 0.1508955652819809 \n",
      "acc for Psat= 0.19381648355848766 \n",
      "acc for optim= 0.18065735762194562\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.005238106939941645\n",
      "Loss on test= 0.007186093833297491\n",
      "acc for Lsat= 0.15292769352042834 \n",
      "acc for Psat= 0.2003410967326433 \n",
      "acc for optim= 0.18495126180827892\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.005286811850965023\n",
      "Loss on test= 0.007317832205444574\n",
      "acc for Lsat= 0.14185969656696887 \n",
      "acc for Psat= 0.18705112482907754 \n",
      "acc for optim= 0.18890323705883452\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.005240573547780514\n",
      "Loss on test= 0.007269955240190029\n",
      "acc for Lsat= 0.15633190998871482 \n",
      "acc for Psat= 0.1937851925628626 \n",
      "acc for optim= 0.18919325435541753\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.005253123119473457\n",
      "Loss on test= 0.007432728074491024\n",
      "acc for Lsat= 0.13033978083880893 \n",
      "acc for Psat= 0.18634684761665518 \n",
      "acc for optim= 0.1775255634253568\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.005341812036931515\n",
      "Loss on test= 0.0073442910797894\n",
      "acc for Lsat= 0.15329712232800016 \n",
      "acc for Psat= 0.1955913077360835 \n",
      "acc for optim= 0.18210967913571532\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.005474156234413385\n",
      "Loss on test= 0.007224553730338812\n",
      "acc for Lsat= 0.14735794994315957 \n",
      "acc for Psat= 0.19280854162386024 \n",
      "acc for optim= 0.18334229783780995\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.00535146240144968\n",
      "Loss on test= 0.007154311519116163\n",
      "acc for Lsat= 0.14744348253143025 \n",
      "acc for Psat= 0.19304468147017703 \n",
      "acc for optim= 0.18358385924251797\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.005474335514008999\n",
      "Loss on test= 0.007459293585270643\n",
      "acc for Lsat= 0.14771117177756946 \n",
      "acc for Psat= 0.18232791113254965 \n",
      "acc for optim= 0.18664818202927802\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.005345976911485195\n",
      "Loss on test= 0.007635090034455061\n",
      "acc for Lsat= 0.13958172692085205 \n",
      "acc for Psat= 0.197612105781159 \n",
      "acc for optim= 0.19214052780546614\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.005182597786188126\n",
      "Loss on test= 0.008178113959729671\n",
      "acc for Lsat= 0.14951362322717615 \n",
      "acc for Psat= 0.17998886559231084 \n",
      "acc for optim= 0.17874905242876638\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.005134542938321829\n",
      "Loss on test= 0.007485541980713606\n",
      "acc for Lsat= 0.14127733699908693 \n",
      "acc for Psat= 0.19603915181388834 \n",
      "acc for optim= 0.18603819429904955\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.005281728692352772\n",
      "Loss on test= 0.007098325528204441\n",
      "acc for Lsat= 0.150007942453939 \n",
      "acc for Psat= 0.1994165741004523 \n",
      "acc for optim= 0.1790597833144468\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.005360699724406004\n",
      "Loss on test= 0.007542859762907028\n",
      "acc for Lsat= 0.14441685217363973 \n",
      "acc for Psat= 0.17752990224036067 \n",
      "acc for optim= 0.1806674493006316\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.005609354004263878\n",
      "Loss on test= 0.007153207901865244\n",
      "acc for Lsat= 0.15275107346132558 \n",
      "acc for Psat= 0.1915628789202692 \n",
      "acc for optim= 0.18521294941797425\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.005806534551084042\n",
      "Loss on test= 0.007136342581361532\n",
      "acc for Lsat= 0.15108196455939982 \n",
      "acc for Psat= 0.1910353104952488 \n",
      "acc for optim= 0.18290673784060466\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.005085726734250784\n",
      "Loss on test= 0.007675603963434696\n",
      "acc for Lsat= 0.14581668235506617 \n",
      "acc for Psat= 0.18853709436037014 \n",
      "acc for optim= 0.18355625774978554\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.005717996973544359\n",
      "Loss on test= 0.007551900111138821\n",
      "acc for Lsat= 0.13989444408359647 \n",
      "acc for Psat= 0.18817873328378362 \n",
      "acc for optim= 0.18595968564880677\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.0052525876089930534\n",
      "Loss on test= 0.007220044732093811\n",
      "acc for Lsat= 0.14475916625863156 \n",
      "acc for Psat= 0.1791505870840619 \n",
      "acc for optim= 0.17804414409747252\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.005533304996788502\n",
      "Loss on test= 0.007643438410013914\n",
      "acc for Lsat= 0.14504589456857322 \n",
      "acc for Psat= 0.19488643713163778 \n",
      "acc for optim= 0.1820028542006602\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.005258497316390276\n",
      "Loss on test= 0.007673089858144522\n",
      "acc for Lsat= 0.1576047696585416 \n",
      "acc for Psat= 0.21513084288892625 \n",
      "acc for optim= 0.17542818160441354\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.0053036026656627655\n",
      "Loss on test= 0.007429555989801884\n",
      "acc for Lsat= 0.14703461976595925 \n",
      "acc for Psat= 0.19052097906409113 \n",
      "acc for optim= 0.1842581545865377\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.0056093353778123856\n",
      "Loss on test= 0.007759517058730125\n",
      "acc for Lsat= 0.15064135284647803 \n",
      "acc for Psat= 0.18141051566926764 \n",
      "acc for optim= 0.18409269933329253\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.005078363232314587\n",
      "Loss on test= 0.007235383149236441\n",
      "acc for Lsat= 0.14356566409859042 \n",
      "acc for Psat= 0.1979378355052475 \n",
      "acc for optim= 0.1738825015028076\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.005175333935767412\n",
      "Loss on test= 0.007563353516161442\n",
      "acc for Lsat= 0.15167207983227018 \n",
      "acc for Psat= 0.19918760148594614 \n",
      "acc for optim= 0.1868093539899612\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.005562557373195887\n",
      "Loss on test= 0.007210057694464922\n",
      "acc for Lsat= 0.1418302504790443 \n",
      "acc for Psat= 0.19064678969739585 \n",
      "acc for optim= 0.18512309370614916\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.005324759520590305\n",
      "Loss on test= 0.007214406505227089\n",
      "acc for Lsat= 0.14928861865036658 \n",
      "acc for Psat= 0.1896847626297414 \n",
      "acc for optim= 0.18572372878581042\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.0053045060485601425\n",
      "Loss on test= 0.007498591672629118\n",
      "acc for Lsat= 0.15093256630553084 \n",
      "acc for Psat= 0.19366956350210382 \n",
      "acc for optim= 0.1893365666615685\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.005321868229657412\n",
      "Loss on test= 0.007485203444957733\n",
      "acc for Lsat= 0.15152057431052346 \n",
      "acc for Psat= 0.18546257475200187 \n",
      "acc for optim= 0.17779001356598723\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.005226545967161655\n",
      "Loss on test= 0.0075413999147713184\n",
      "acc for Lsat= 0.14694409968968877 \n",
      "acc for Psat= 0.19961765436989973 \n",
      "acc for optim= 0.182885562562857\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.005488977767527103\n",
      "Loss on test= 0.007635981310158968\n",
      "acc for Lsat= 0.1479135260148619 \n",
      "acc for Psat= 0.20482112578131625 \n",
      "acc for optim= 0.18985523087627132\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.005352875683456659\n",
      "Loss on test= 0.007789861876517534\n",
      "acc for Lsat= 0.15164438648183723 \n",
      "acc for Psat= 0.18517534990649914 \n",
      "acc for optim= 0.18545387416646708\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.005317344330251217\n",
      "Loss on test= 0.0074391793459653854\n",
      "acc for Lsat= 0.14572004771127736 \n",
      "acc for Psat= 0.19694106334564657 \n",
      "acc for optim= 0.19344849064275832\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.00524943508207798\n",
      "Loss on test= 0.0070945098996162415\n",
      "acc for Lsat= 0.13799315607900442 \n",
      "acc for Psat= 0.19964681127047562 \n",
      "acc for optim= 0.18030485447751907\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.00539421895518899\n",
      "Loss on test= 0.007554224692285061\n",
      "acc for Lsat= 0.14711470436545748 \n",
      "acc for Psat= 0.18379600217077333 \n",
      "acc for optim= 0.1828052358227576\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.0053117237985134125\n",
      "Loss on test= 0.007210679817944765\n",
      "acc for Lsat= 0.14260765000434447 \n",
      "acc for Psat= 0.17404594494098583 \n",
      "acc for optim= 0.18304111821954824\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.005322213750332594\n",
      "Loss on test= 0.007569097448140383\n",
      "acc for Lsat= 0.14685246310603317 \n",
      "acc for Psat= 0.2001489471452364 \n",
      "acc for optim= 0.18516627240597536\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.005093349143862724\n",
      "Loss on test= 0.007124347146600485\n",
      "acc for Lsat= 0.14754373347959251 \n",
      "acc for Psat= 0.18836666539093846 \n",
      "acc for optim= 0.19292225536787033\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.005090142134577036\n",
      "Loss on test= 0.007081737741827965\n",
      "acc for Lsat= 0.15581332205949336 \n",
      "acc for Psat= 0.17766122977577578 \n",
      "acc for optim= 0.18688568373756545\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.005194840952754021\n",
      "Loss on test= 0.007635313551872969\n",
      "acc for Lsat= 0.15168378411173883 \n",
      "acc for Psat= 0.18588088453274038 \n",
      "acc for optim= 0.17885916688418413\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.0053367288783192635\n",
      "Loss on test= 0.007305482402443886\n",
      "acc for Lsat= 0.14097799145135662 \n",
      "acc for Psat= 0.19297144973505534 \n",
      "acc for optim= 0.18334039280011669\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.005172231234610081\n",
      "Loss on test= 0.006928928662091494\n",
      "acc for Lsat= 0.14920914551075243 \n",
      "acc for Psat= 0.1932931994869265 \n",
      "acc for optim= 0.18295288174546737\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.00509521272033453\n",
      "Loss on test= 0.007068075705319643\n",
      "acc for Lsat= 0.13490119248582813 \n",
      "acc for Psat= 0.17512335907095342 \n",
      "acc for optim= 0.1839701015027011\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.005564292427152395\n",
      "Loss on test= 0.007481468841433525\n",
      "acc for Lsat= 0.14747492816369812 \n",
      "acc for Psat= 0.18407706055889425 \n",
      "acc for optim= 0.18061025158280783\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.005087400786578655\n",
      "Loss on test= 0.007469107862561941\n",
      "acc for Lsat= 0.15065505874808877 \n",
      "acc for Psat= 0.18950273382819074 \n",
      "acc for optim= 0.18030654429419912\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.005196613259613514\n",
      "Loss on test= 0.007365725468844175\n",
      "acc for Lsat= 0.14018744185375193 \n",
      "acc for Psat= 0.19233701192310126 \n",
      "acc for optim= 0.18471376917775353\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.005235192831605673\n",
      "Loss on test= 0.0074768466874957085\n",
      "acc for Lsat= 0.15003954008580414 \n",
      "acc for Psat= 0.1986830054504652 \n",
      "acc for optim= 0.1885002551548809\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.005316977389156818\n",
      "Loss on test= 0.007161101326346397\n",
      "acc for Lsat= 0.160332770910511 \n",
      "acc for Psat= 0.20084356152214927 \n",
      "acc for optim= 0.18125940135872892\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.005745741073042154\n",
      "Loss on test= 0.007365018595010042\n",
      "acc for Lsat= 0.1446780548224867 \n",
      "acc for Psat= 0.19322123682369968 \n",
      "acc for optim= 0.18735667148091617\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.005002864636480808\n",
      "Loss on test= 0.007245775777846575\n",
      "acc for Lsat= 0.14981814305542313 \n",
      "acc for Psat= 0.18506602837568623 \n",
      "acc for optim= 0.18749272010678456\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.005195850506424904\n",
      "Loss on test= 0.007477287203073502\n",
      "acc for Lsat= 0.14601672508116414 \n",
      "acc for Psat= 0.18428816679966448 \n",
      "acc for optim= 0.1826197816371979\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.005202150903642178\n",
      "Loss on test= 0.007366359233856201\n",
      "acc for Lsat= 0.15190516036599264 \n",
      "acc for Psat= 0.18712470479553842 \n",
      "acc for optim= 0.1808704863347765\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.005186965223401785\n",
      "Loss on test= 0.007051223888993263\n",
      "acc for Lsat= 0.13643103418719085 \n",
      "acc for Psat= 0.19404318009781818 \n",
      "acc for optim= 0.18894285854552972\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.005151459015905857\n",
      "Loss on test= 0.007196367718279362\n",
      "acc for Lsat= 0.1432908957274478 \n",
      "acc for Psat= 0.18589953878650167 \n",
      "acc for optim= 0.18540950815697185\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.006102851592004299\n",
      "Loss on test= 0.007225315552204847\n",
      "acc for Lsat= 0.1423830736196623 \n",
      "acc for Psat= 0.19458347790659603 \n",
      "acc for optim= 0.1817146686934885\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.005386788863688707\n",
      "Loss on test= 0.006923451088368893\n",
      "acc for Lsat= 0.14322668245275977 \n",
      "acc for Psat= 0.18789902870795216 \n",
      "acc for optim= 0.18399848787831602\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.005124744027853012\n",
      "Loss on test= 0.007415404077619314\n",
      "acc for Lsat= 0.15179529042254186 \n",
      "acc for Psat= 0.18855379523182686 \n",
      "acc for optim= 0.18375259532944346\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.005619706120342016\n",
      "Loss on test= 0.0070965103805065155\n",
      "acc for Lsat= 0.14702832510028813 \n",
      "acc for Psat= 0.20179070887837147 \n",
      "acc for optim= 0.17808342640589708\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.005213131196796894\n",
      "Loss on test= 0.007710614707320929\n",
      "acc for Lsat= 0.1537345101754849 \n",
      "acc for Psat= 0.18927046683174176 \n",
      "acc for optim= 0.18279645744688258\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.005412836093455553\n",
      "Loss on test= 0.007246168330311775\n",
      "acc for Lsat= 0.14569380044494373 \n",
      "acc for Psat= 0.1823298971897724 \n",
      "acc for optim= 0.18779882318912777\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.0057095373049378395\n",
      "Loss on test= 0.007426980882883072\n",
      "acc for Lsat= 0.15062005617274124 \n",
      "acc for Psat= 0.18202180300579696 \n",
      "acc for optim= 0.18105900093188346\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.00532406335696578\n",
      "Loss on test= 0.007118378300219774\n",
      "acc for Lsat= 0.1452472857245412 \n",
      "acc for Psat= 0.20142530371281356 \n",
      "acc for optim= 0.19002978923753452\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.005156275350600481\n",
      "Loss on test= 0.00697334622964263\n",
      "acc for Lsat= 0.14591888140329518 \n",
      "acc for Psat= 0.18421249615608667 \n",
      "acc for optim= 0.18996213212090193\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.005134803708642721\n",
      "Loss on test= 0.007355343550443649\n",
      "acc for Lsat= 0.15035212503204154 \n",
      "acc for Psat= 0.19900008447031245 \n",
      "acc for optim= 0.18479797859699085\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.00510169193148613\n",
      "Loss on test= 0.007623187266290188\n",
      "acc for Lsat= 0.14042134136514983 \n",
      "acc for Psat= 0.20124864236386797 \n",
      "acc for optim= 0.1774448031668368\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.0051759108901023865\n",
      "Loss on test= 0.007254202850162983\n",
      "acc for Lsat= 0.13732529772864463 \n",
      "acc for Psat= 0.18588009619738022 \n",
      "acc for optim= 0.18399848585879644\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.005165024660527706\n",
      "Loss on test= 0.007796396967023611\n",
      "acc for Lsat= 0.14167475524868006 \n",
      "acc for Psat= 0.1828067518759244 \n",
      "acc for optim= 0.1818461091685124\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.005005246959626675\n",
      "Loss on test= 0.007224253378808498\n",
      "acc for Lsat= 0.14815987115181967 \n",
      "acc for Psat= 0.18940809729287675 \n",
      "acc for optim= 0.1769493874057471\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.005414296872913837\n",
      "Loss on test= 0.007268895395100117\n",
      "acc for Lsat= 0.1483319971494789 \n",
      "acc for Psat= 0.1917123050245716 \n",
      "acc for optim= 0.1848203525277328\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.005436396691948175\n",
      "Loss on test= 0.007568634580820799\n",
      "acc for Lsat= 0.1412464808560068 \n",
      "acc for Psat= 0.1851683588232845 \n",
      "acc for optim= 0.18765820531722266\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.0051889000460505486\n",
      "Loss on test= 0.006990412250161171\n",
      "acc for Lsat= 0.15866423197077267 \n",
      "acc for Psat= 0.1865982458108013 \n",
      "acc for optim= 0.18646674174544506\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.005192380398511887\n",
      "Loss on test= 0.007131203543394804\n",
      "acc for Lsat= 0.1493316681525044 \n",
      "acc for Psat= 0.1825789769298443 \n",
      "acc for optim= 0.18857923726566503\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.005264338571578264\n",
      "Loss on test= 0.007392390631139278\n",
      "acc for Lsat= 0.14011827943589897 \n",
      "acc for Psat= 0.19055197513127914 \n",
      "acc for optim= 0.19665799849261945\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.005216152407228947\n",
      "Loss on test= 0.007591173984110355\n",
      "acc for Lsat= 0.14647343036447666 \n",
      "acc for Psat= 0.17913688027011765 \n",
      "acc for optim= 0.1775757443046266\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.005299472250044346\n",
      "Loss on test= 0.007271568290889263\n",
      "acc for Lsat= 0.1416162491217351 \n",
      "acc for Psat= 0.18470419353841744 \n",
      "acc for optim= 0.1844658571064518\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.005090272519737482\n",
      "Loss on test= 0.007229112554341555\n",
      "acc for Lsat= 0.1436419481653949 \n",
      "acc for Psat= 0.17519680222659323 \n",
      "acc for optim= 0.18508429953248287\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.005185538902878761\n",
      "Loss on test= 0.007309825159609318\n",
      "acc for Lsat= 0.15005855822657066 \n",
      "acc for Psat= 0.1931473317307985 \n",
      "acc for optim= 0.18827737251069535\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.005395260639488697\n",
      "Loss on test= 0.007628389168530703\n",
      "acc for Lsat= 0.14293159276283285 \n",
      "acc for Psat= 0.18029075079505927 \n",
      "acc for optim= 0.17939755056400739\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.0052185975946486\n",
      "Loss on test= 0.00732064712792635\n",
      "acc for Lsat= 0.14521874391748646 \n",
      "acc for Psat= 0.191802397745259 \n",
      "acc for optim= 0.18287252130170092\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.005211302079260349\n",
      "Loss on test= 0.007474856451153755\n",
      "acc for Lsat= 0.13755969732816592 \n",
      "acc for Psat= 0.18469369231766666 \n",
      "acc for optim= 0.18872179045861007\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.005267900414764881\n",
      "Loss on test= 0.0072266580536961555\n",
      "acc for Lsat= 0.14132285739083347 \n",
      "acc for Psat= 0.19383305874572052 \n",
      "acc for optim= 0.189607286884938\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.005316359456628561\n",
      "Loss on test= 0.006764957681298256\n",
      "acc for Lsat= 0.15640632697594825 \n",
      "acc for Psat= 0.18435418837437537 \n",
      "acc for optim= 0.18401124650349107\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.005259585566818714\n",
      "Loss on test= 0.007364810910075903\n",
      "acc for Lsat= 0.13531635399052844 \n",
      "acc for Psat= 0.18281670874633565 \n",
      "acc for optim= 0.1908636448193021\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.005373541731387377\n",
      "Loss on test= 0.007176204584538937\n",
      "acc for Lsat= 0.13219586817796256 \n",
      "acc for Psat= 0.1860455357101288 \n",
      "acc for optim= 0.17609197932431955\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.005287581589072943\n",
      "Loss on test= 0.007084502372890711\n",
      "acc for Lsat= 0.1479240950754248 \n",
      "acc for Psat= 0.19078005224401437 \n",
      "acc for optim= 0.18648934995328062\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.0049910093657672405\n",
      "Loss on test= 0.0076788947917521\n",
      "acc for Lsat= 0.14773430331175016 \n",
      "acc for Psat= 0.20102935549669487 \n",
      "acc for optim= 0.18108904660435118\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.0052823214791715145\n",
      "Loss on test= 0.0072837150655686855\n",
      "acc for Lsat= 0.14254664009547655 \n",
      "acc for Psat= 0.19491582988733389 \n",
      "acc for optim= 0.18176996307981919\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.005262439139187336\n",
      "Loss on test= 0.007385094650089741\n",
      "acc for Lsat= 0.1477324164346563 \n",
      "acc for Psat= 0.19103841855301384 \n",
      "acc for optim= 0.1843521071969127\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.005604100413620472\n",
      "Loss on test= 0.0074209836311638355\n",
      "acc for Lsat= 0.14257030288200276 \n",
      "acc for Psat= 0.19708530643695324 \n",
      "acc for optim= 0.18539834017712684\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.005233219359070063\n",
      "Loss on test= 0.007157094310969114\n",
      "acc for Lsat= 0.15015682775167496 \n",
      "acc for Psat= 0.18517452688490757 \n",
      "acc for optim= 0.18220571959124054\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.00518770981580019\n",
      "Loss on test= 0.007782001048326492\n",
      "acc for Lsat= 0.13273515586629625 \n",
      "acc for Psat= 0.1843592384637841 \n",
      "acc for optim= 0.18266318601863382\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.0058093625120818615\n",
      "Loss on test= 0.007520087994635105\n",
      "acc for Lsat= 0.15093929105300885 \n",
      "acc for Psat= 0.19750394677117344 \n",
      "acc for optim= 0.18210218496526187\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.005290449596941471\n",
      "Loss on test= 0.007348840590566397\n",
      "acc for Lsat= 0.15512150990791984 \n",
      "acc for Psat= 0.1945811358028565 \n",
      "acc for optim= 0.1846525096832622\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.0051882038824260235\n",
      "Loss on test= 0.007398966699838638\n",
      "acc for Lsat= 0.15624553776426303 \n",
      "acc for Psat= 0.18158494728067737 \n",
      "acc for optim= 0.1820631545853847\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.005227661691606045\n",
      "Loss on test= 0.006948952563107014\n",
      "acc for Lsat= 0.15587033990199953 \n",
      "acc for Psat= 0.19816025743436558 \n",
      "acc for optim= 0.1832120234934605\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.005562551319599152\n",
      "Loss on test= 0.007171170320361853\n",
      "acc for Lsat= 0.1482158055675949 \n",
      "acc for Psat= 0.19728781108641386 \n",
      "acc for optim= 0.1918988157287011\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.005259621888399124\n",
      "Loss on test= 0.007513462100178003\n",
      "acc for Lsat= 0.14587278243146654 \n",
      "acc for Psat= 0.19530892028572558 \n",
      "acc for optim= 0.17807033644258197\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.005096883047372103\n",
      "Loss on test= 0.007348870392888784\n",
      "acc for Lsat= 0.14520436734355677 \n",
      "acc for Psat= 0.18576627368256296 \n",
      "acc for optim= 0.18228941361141224\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.005322969518601894\n",
      "Loss on test= 0.007520586717873812\n",
      "acc for Lsat= 0.15242335401049845 \n",
      "acc for Psat= 0.20021663919324056 \n",
      "acc for optim= 0.17352153536897977\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.005341782234609127\n",
      "Loss on test= 0.007252205163240433\n",
      "acc for Lsat= 0.1417893374726161 \n",
      "acc for Psat= 0.18706992311931794 \n",
      "acc for optim= 0.1823162915155513\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.005246561951935291\n",
      "Loss on test= 0.007138238288462162\n",
      "acc for Lsat= 0.15174645313012153 \n",
      "acc for Psat= 0.1903012585612472 \n",
      "acc for optim= 0.18331666717727546\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.005131558980792761\n",
      "Loss on test= 0.007608672603964806\n",
      "acc for Lsat= 0.13994341395994778 \n",
      "acc for Psat= 0.19006321461199494 \n",
      "acc for optim= 0.1858077420510989\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.005001897923648357\n",
      "Loss on test= 0.007363446056842804\n",
      "acc for Lsat= 0.14767886097189878 \n",
      "acc for Psat= 0.1930690201480308 \n",
      "acc for optim= 0.1918388915687158\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.005243736319243908\n",
      "Loss on test= 0.007292693480849266\n",
      "acc for Lsat= 0.1509708059661579 \n",
      "acc for Psat= 0.18538871834400017 \n",
      "acc for optim= 0.18434910337912055\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.005413999781012535\n",
      "Loss on test= 0.007464441936463118\n",
      "acc for Lsat= 0.1491511656031524 \n",
      "acc for Psat= 0.18641222508883745 \n",
      "acc for optim= 0.17856389628968977\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.005165042821317911\n",
      "Loss on test= 0.00739837484434247\n",
      "acc for Lsat= 0.14151362496874947 \n",
      "acc for Psat= 0.20058790918775513 \n",
      "acc for optim= 0.19514537429986675\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.005356903187930584\n",
      "Loss on test= 0.007028067484498024\n",
      "acc for Lsat= 0.13420649507697519 \n",
      "acc for Psat= 0.18024976965465553 \n",
      "acc for optim= 0.1830945446563419\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.00561853451654315\n",
      "Loss on test= 0.007336393930017948\n",
      "acc for Lsat= 0.13927577361693513 \n",
      "acc for Psat= 0.1777852698935379 \n",
      "acc for optim= 0.18372207251689912\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.005454749800264835\n",
      "Loss on test= 0.007078149821609259\n",
      "acc for Lsat= 0.15082762874109426 \n",
      "acc for Psat= 0.17625967691672514 \n",
      "acc for optim= 0.18711867896710202\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.005306619219481945\n",
      "Loss on test= 0.007432354614138603\n",
      "acc for Lsat= 0.1509950771640463 \n",
      "acc for Psat= 0.20253314399637556 \n",
      "acc for optim= 0.19012873552693818\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.005202540662139654\n",
      "Loss on test= 0.007334445137530565\n",
      "acc for Lsat= 0.1460552887028736 \n",
      "acc for Psat= 0.18692553595403116 \n",
      "acc for optim= 0.1813518012263125\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.0056082396768033504\n",
      "Loss on test= 0.0074652195908129215\n",
      "acc for Lsat= 0.14869486057031595 \n",
      "acc for Psat= 0.1907246783630518 \n",
      "acc for optim= 0.18806186356137078\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.005753397010266781\n",
      "Loss on test= 0.0077571384608745575\n",
      "acc for Lsat= 0.14607369450653795 \n",
      "acc for Psat= 0.17837960061037028 \n",
      "acc for optim= 0.18382079579951394\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.005334978923201561\n",
      "Loss on test= 0.007750470656901598\n",
      "acc for Lsat= 0.1522588982407722 \n",
      "acc for Psat= 0.17660912497207182 \n",
      "acc for optim= 0.17835831229773458\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.005502262152731419\n",
      "Loss on test= 0.007363467942923307\n",
      "acc for Lsat= 0.1456512128941898 \n",
      "acc for Psat= 0.18945476973551462 \n",
      "acc for optim= 0.18196783488936966\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.0051735504530370235\n",
      "Loss on test= 0.007401847280561924\n",
      "acc for Lsat= 0.14138999886717266 \n",
      "acc for Psat= 0.18803613912815145 \n",
      "acc for optim= 0.19284226098765817\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.005426408722996712\n",
      "Loss on test= 0.007591891568154097\n",
      "acc for Lsat= 0.1551657878312847 \n",
      "acc for Psat= 0.17861384636203406 \n",
      "acc for optim= 0.1856705424154452\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.005607901141047478\n",
      "Loss on test= 0.007551101967692375\n",
      "acc for Lsat= 0.14246423961709206 \n",
      "acc for Psat= 0.18538868497803304 \n",
      "acc for optim= 0.1824320963354873\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.00561529491096735\n",
      "Loss on test= 0.007391940802335739\n",
      "acc for Lsat= 0.14790064666504193 \n",
      "acc for Psat= 0.20682771270235878 \n",
      "acc for optim= 0.18333799845546667\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.0054281121119856834\n",
      "Loss on test= 0.007522673811763525\n",
      "acc for Lsat= 0.15542135462093312 \n",
      "acc for Psat= 0.19822682488755491 \n",
      "acc for optim= 0.18006256930148382\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.005320299416780472\n",
      "Loss on test= 0.007483833935111761\n",
      "acc for Lsat= 0.1434970994071129 \n",
      "acc for Psat= 0.18929441207638162 \n",
      "acc for optim= 0.1807304729839222\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.0051473332569003105\n",
      "Loss on test= 0.007468975614756346\n",
      "acc for Lsat= 0.14511891046079012 \n",
      "acc for Psat= 0.19606826008120018 \n",
      "acc for optim= 0.18742774095881032\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.005343025084584951\n",
      "Loss on test= 0.007234643679112196\n",
      "acc for Lsat= 0.14572057739934563 \n",
      "acc for Psat= 0.1917321286704315 \n",
      "acc for optim= 0.1833933959249407\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.005141757428646088\n",
      "Loss on test= 0.007464311085641384\n",
      "acc for Lsat= 0.15861415719521826 \n",
      "acc for Psat= 0.2025778647624796 \n",
      "acc for optim= 0.18105049934166628\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.005296472460031509\n",
      "Loss on test= 0.007609409745782614\n",
      "acc for Lsat= 0.15424355169410864 \n",
      "acc for Psat= 0.19309903767673664 \n",
      "acc for optim= 0.18351393880529643\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.005275639705359936\n",
      "Loss on test= 0.007050482090562582\n",
      "acc for Lsat= 0.151130320092083 \n",
      "acc for Psat= 0.1887700102043903 \n",
      "acc for optim= 0.18655412788846393\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.00518553564324975\n",
      "Loss on test= 0.007110072765499353\n",
      "acc for Lsat= 0.16426233196570003 \n",
      "acc for Psat= 0.18950243213573723 \n",
      "acc for optim= 0.18689238090663537\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.005158201791346073\n",
      "Loss on test= 0.007645587436854839\n",
      "acc for Lsat= 0.14559709155840464 \n",
      "acc for Psat= 0.19120632007133148 \n",
      "acc for optim= 0.1824975117876912\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.005729024298489094\n",
      "Loss on test= 0.007122927810996771\n",
      "acc for Lsat= 0.1478954550327321 \n",
      "acc for Psat= 0.18399519488982644 \n",
      "acc for optim= 0.1836674687751525\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.005128323100507259\n",
      "Loss on test= 0.007772087585180998\n",
      "acc for Lsat= 0.13867755006296467 \n",
      "acc for Psat= 0.19133578289346007 \n",
      "acc for optim= 0.18004476111382245\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.005242038052529097\n",
      "Loss on test= 0.007204771973192692\n",
      "acc for Lsat= 0.13319106721357427 \n",
      "acc for Psat= 0.18310598851540355 \n",
      "acc for optim= 0.18031509916959368\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.00506643857806921\n",
      "Loss on test= 0.006764746271073818\n",
      "acc for Lsat= 0.14790938767221887 \n",
      "acc for Psat= 0.19671671878180055 \n",
      "acc for optim= 0.18573643141578822\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.005427057854831219\n",
      "Loss on test= 0.007676679641008377\n",
      "acc for Lsat= 0.13951174373801448 \n",
      "acc for Psat= 0.18114545378417968 \n",
      "acc for optim= 0.18704232670382032\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.005484176799654961\n",
      "Loss on test= 0.0074546681717038155\n",
      "acc for Lsat= 0.1491330763103238 \n",
      "acc for Psat= 0.18199881820282976 \n",
      "acc for optim= 0.1829931582904375\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.005337393842637539\n",
      "Loss on test= 0.007338437717407942\n",
      "acc for Lsat= 0.15599182723853433 \n",
      "acc for Psat= 0.19670217010597163 \n",
      "acc for optim= 0.17747595532936594\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.005592639092355967\n",
      "Loss on test= 0.00722396420314908\n",
      "acc for Lsat= 0.15538971831480072 \n",
      "acc for Psat= 0.193267104288441 \n",
      "acc for optim= 0.18264708851242714\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.005397614557296038\n",
      "Loss on test= 0.007410337217152119\n",
      "acc for Lsat= 0.15883758940169068 \n",
      "acc for Psat= 0.18927282835337805 \n",
      "acc for optim= 0.17897988361207248\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.005316001363098621\n",
      "Loss on test= 0.007495759520679712\n",
      "acc for Lsat= 0.14665969716705626 \n",
      "acc for Psat= 0.2073289913251771 \n",
      "acc for optim= 0.18395609692357\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.005155813880264759\n",
      "Loss on test= 0.007355676032602787\n",
      "acc for Lsat= 0.16296773709158308 \n",
      "acc for Psat= 0.1864148172756493 \n",
      "acc for optim= 0.18119019232470862\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.00530645065009594\n",
      "Loss on test= 0.007172534707933664\n",
      "acc for Lsat= 0.14366878661933952 \n",
      "acc for Psat= 0.18318417410186844 \n",
      "acc for optim= 0.18939533018713176\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.005117884837090969\n",
      "Loss on test= 0.0074583678506314754\n",
      "acc for Lsat= 0.14534673730186262 \n",
      "acc for Psat= 0.1852760632130218 \n",
      "acc for optim= 0.1822301356152433\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.005218985490500927\n",
      "Loss on test= 0.007270280737429857\n",
      "acc for Lsat= 0.14411836304719994 \n",
      "acc for Psat= 0.1714710132638756 \n",
      "acc for optim= 0.18198571792559423\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.005097019020467997\n",
      "Loss on test= 0.007336715701967478\n",
      "acc for Lsat= 0.14571793255626156 \n",
      "acc for Psat= 0.18733541197434533 \n",
      "acc for optim= 0.1886285346796255\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.0052068596705794334\n",
      "Loss on test= 0.007332140579819679\n",
      "acc for Lsat= 0.15016606118507134 \n",
      "acc for Psat= 0.1889833646643235 \n",
      "acc for optim= 0.17633112606637324\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.005381113849580288\n",
      "Loss on test= 0.007238177116960287\n",
      "acc for Lsat= 0.16411424868808847 \n",
      "acc for Psat= 0.18221719774125825 \n",
      "acc for optim= 0.17655657392640964\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.005016250070184469\n",
      "Loss on test= 0.007349886000156403\n",
      "acc for Lsat= 0.14325164752462727 \n",
      "acc for Psat= 0.1778520559384411 \n",
      "acc for optim= 0.1845564384250062\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.0055895401164889336\n",
      "Loss on test= 0.0073661645874381065\n",
      "acc for Lsat= 0.15080735885197502 \n",
      "acc for Psat= 0.18439592161639518 \n",
      "acc for optim= 0.1897492712907747\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.005498003214597702\n",
      "Loss on test= 0.007325460202991962\n",
      "acc for Lsat= 0.149840779259007 \n",
      "acc for Psat= 0.19865580645323536 \n",
      "acc for optim= 0.19242056542043726\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.00515747768804431\n",
      "Loss on test= 0.0075097163207829\n",
      "acc for Lsat= 0.14899378000723343 \n",
      "acc for Psat= 0.17276239502230875 \n",
      "acc for optim= 0.1774200813622585\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.005554393399506807\n",
      "Loss on test= 0.007075479254126549\n",
      "acc for Lsat= 0.14654799103202512 \n",
      "acc for Psat= 0.19335464119823406 \n",
      "acc for optim= 0.18012242616444338\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.005326166749000549\n",
      "Loss on test= 0.007438647095113993\n",
      "acc for Lsat= 0.1481244307760909 \n",
      "acc for Psat= 0.1861939976110169 \n",
      "acc for optim= 0.1889985366487784\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.005138338077813387\n",
      "Loss on test= 0.007683564908802509\n",
      "acc for Lsat= 0.13686097270282382 \n",
      "acc for Psat= 0.1898746567053079 \n",
      "acc for optim= 0.18117948120658392\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.00532224727794528\n",
      "Loss on test= 0.007241380400955677\n",
      "acc for Lsat= 0.14133920274788445 \n",
      "acc for Psat= 0.1722346553391945 \n",
      "acc for optim= 0.17424527163479905\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.005223771557211876\n",
      "Loss on test= 0.007395156659185886\n",
      "acc for Lsat= 0.15100359606721675 \n",
      "acc for Psat= 0.1839261063855508 \n",
      "acc for optim= 0.18653177442586483\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.0052314139902591705\n",
      "Loss on test= 0.0076475064270198345\n",
      "acc for Lsat= 0.13865610082580357 \n",
      "acc for Psat= 0.18848483190703832 \n",
      "acc for optim= 0.18381743788629482\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.005245978944003582\n",
      "Loss on test= 0.007441725581884384\n",
      "acc for Lsat= 0.15274545490134844 \n",
      "acc for Psat= 0.17914559913066322 \n",
      "acc for optim= 0.18447202617878888\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.005282958038151264\n",
      "Loss on test= 0.007091420702636242\n",
      "acc for Lsat= 0.15427872359554176 \n",
      "acc for Psat= 0.1845114018098207 \n",
      "acc for optim= 0.1856394307126795\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.005147435702383518\n",
      "Loss on test= 0.007226538844406605\n",
      "acc for Lsat= 0.14199779684183983 \n",
      "acc for Psat= 0.18048088130938103 \n",
      "acc for optim= 0.1827329099573363\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.005227253306657076\n",
      "Loss on test= 0.007389531470835209\n",
      "acc for Lsat= 0.13178165880972748 \n",
      "acc for Psat= 0.18584104968295967 \n",
      "acc for optim= 0.17475514027116376\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.005852116271853447\n",
      "Loss on test= 0.006964122876524925\n",
      "acc for Lsat= 0.14680244356616148 \n",
      "acc for Psat= 0.1908070779634548 \n",
      "acc for optim= 0.18428111061621763\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.005152915604412556\n",
      "Loss on test= 0.007497010286897421\n",
      "acc for Lsat= 0.14559018593653655 \n",
      "acc for Psat= 0.19323351987767354 \n",
      "acc for optim= 0.1816197023024691\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.005097388289868832\n",
      "Loss on test= 0.007237170357257128\n",
      "acc for Lsat= 0.16752221685582314 \n",
      "acc for Psat= 0.19106207184921034 \n",
      "acc for optim= 0.18867632692458383\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.005152754485607147\n",
      "Loss on test= 0.007307395804673433\n",
      "acc for Lsat= 0.1533159582795514 \n",
      "acc for Psat= 0.1933272827307877 \n",
      "acc for optim= 0.18057992492437927\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.005135495215654373\n",
      "Loss on test= 0.007365223485976458\n",
      "acc for Lsat= 0.14318278426004832 \n",
      "acc for Psat= 0.20191081863347074 \n",
      "acc for optim= 0.18339099784345428\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.004972901660948992\n",
      "Loss on test= 0.007068472448736429\n",
      "acc for Lsat= 0.1457548319208474 \n",
      "acc for Psat= 0.1897298177919989 \n",
      "acc for optim= 0.1808696903867459\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.0052882106974720955\n",
      "Loss on test= 0.007852809503674507\n",
      "acc for Lsat= 0.14022787175294904 \n",
      "acc for Psat= 0.1834398145541228 \n",
      "acc for optim= 0.18609157998198797\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.005611732602119446\n",
      "Loss on test= 0.007292920257896185\n",
      "acc for Lsat= 0.14024739679250653 \n",
      "acc for Psat= 0.19456004418912687 \n",
      "acc for optim= 0.17760212099509787\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.00567548256367445\n",
      "Loss on test= 0.0073611377738416195\n",
      "acc for Lsat= 0.16330269230825475 \n",
      "acc for Psat= 0.18020727161402036 \n",
      "acc for optim= 0.1781596342693312\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.005470410455018282\n",
      "Loss on test= 0.007326735649257898\n",
      "acc for Lsat= 0.15213029153309152 \n",
      "acc for Psat= 0.20277159095319086 \n",
      "acc for optim= 0.17994074641133384\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.0052558546885848045\n",
      "Loss on test= 0.007695319131016731\n",
      "acc for Lsat= 0.14570066323313008 \n",
      "acc for Psat= 0.18187103281102954 \n",
      "acc for optim= 0.17871044028443514\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.005041994620114565\n",
      "Loss on test= 0.007205620873719454\n",
      "acc for Lsat= 0.14729743287402403 \n",
      "acc for Psat= 0.19611658589059455 \n",
      "acc for optim= 0.18864925645671587\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.005256070289760828\n",
      "Loss on test= 0.007116914261132479\n",
      "acc for Lsat= 0.14926666429191904 \n",
      "acc for Psat= 0.18528082432400925 \n",
      "acc for optim= 0.18259839375635045\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.005313493311405182\n",
      "Loss on test= 0.0073462072759866714\n",
      "acc for Lsat= 0.1494173222961912 \n",
      "acc for Psat= 0.1726007296623601 \n",
      "acc for optim= 0.1783929981913448\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.005258921999484301\n",
      "Loss on test= 0.007560531608760357\n",
      "acc for Lsat= 0.14698221217955418 \n",
      "acc for Psat= 0.1764543614522497 \n",
      "acc for optim= 0.18583486471000724\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.0052039423026144505\n",
      "Loss on test= 0.007133456412702799\n",
      "acc for Lsat= 0.14447577565290096 \n",
      "acc for Psat= 0.19041170722720993 \n",
      "acc for optim= 0.19889696319320346\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.005448373965919018\n",
      "Loss on test= 0.007100993301719427\n",
      "acc for Lsat= 0.14877446180373644 \n",
      "acc for Psat= 0.17516594801129598 \n",
      "acc for optim= 0.18703888059463963\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.005257479380816221\n",
      "Loss on test= 0.0077786813490092754\n",
      "acc for Lsat= 0.14007569679288578 \n",
      "acc for Psat= 0.19364561721349524 \n",
      "acc for optim= 0.1858825528105343\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.004977394826710224\n",
      "Loss on test= 0.007386552169919014\n",
      "acc for Lsat= 0.14703520967083084 \n",
      "acc for Psat= 0.1849234224577529 \n",
      "acc for optim= 0.18280375761220416\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.005365130491554737\n",
      "Loss on test= 0.007455423939973116\n",
      "acc for Lsat= 0.14014855839720483 \n",
      "acc for Psat= 0.19029168192255233 \n",
      "acc for optim= 0.19025869358437839\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.005439381115138531\n",
      "Loss on test= 0.007452577818185091\n",
      "acc for Lsat= 0.13870997322383566 \n",
      "acc for Psat= 0.18276585775492407 \n",
      "acc for optim= 0.17863939979617469\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.005341023672372103\n",
      "Loss on test= 0.0072626955807209015\n",
      "acc for Lsat= 0.13718084425390623 \n",
      "acc for Psat= 0.18930976712106742 \n",
      "acc for optim= 0.18581899489132023\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.005414071958512068\n",
      "Loss on test= 0.007272507529705763\n",
      "acc for Lsat= 0.15458062412961554 \n",
      "acc for Psat= 0.1795581256040395 \n",
      "acc for optim= 0.17901073984972815\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.005180432461202145\n",
      "Loss on test= 0.007483622990548611\n",
      "acc for Lsat= 0.14416093899053523 \n",
      "acc for Psat= 0.18819407620913345 \n",
      "acc for optim= 0.18312606701405995\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.005005394108593464\n",
      "Loss on test= 0.00765955401584506\n",
      "acc for Lsat= 0.13364709300489058 \n",
      "acc for Psat= 0.19063504012225227 \n",
      "acc for optim= 0.18483678661544473\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.00510012311860919\n",
      "Loss on test= 0.007545012980699539\n",
      "acc for Lsat= 0.14811743559147858 \n",
      "acc for Psat= 0.1919459516085211 \n",
      "acc for optim= 0.18238345330092506\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.005410037003457546\n",
      "Loss on test= 0.007455987390130758\n",
      "acc for Lsat= 0.14855642039071174 \n",
      "acc for Psat= 0.1889940050201582 \n",
      "acc for optim= 0.19231735586787987\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.005436393432319164\n",
      "Loss on test= 0.007682895753532648\n",
      "acc for Lsat= 0.15269928278180114 \n",
      "acc for Psat= 0.19255784872278084 \n",
      "acc for optim= 0.18525306395303695\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.005186513066291809\n",
      "Loss on test= 0.00740601122379303\n",
      "acc for Lsat= 0.13551047164431512 \n",
      "acc for Psat= 0.18773612071011886 \n",
      "acc for optim= 0.1895303119262146\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.005537340883165598\n",
      "Loss on test= 0.0075954594649374485\n",
      "acc for Lsat= 0.14741323038985282 \n",
      "acc for Psat= 0.1820863548994492 \n",
      "acc for optim= 0.18125236582844262\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.005179774947464466\n",
      "Loss on test= 0.007165105082094669\n",
      "acc for Lsat= 0.14112773590079952 \n",
      "acc for Psat= 0.1958758065346285 \n",
      "acc for optim= 0.19179437835634014\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.005449988879263401\n",
      "Loss on test= 0.007785293739289045\n",
      "acc for Lsat= 0.15532558386683556 \n",
      "acc for Psat= 0.2030181969451092 \n",
      "acc for optim= 0.18540547459012233\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.005168505944311619\n",
      "Loss on test= 0.007264895364642143\n",
      "acc for Lsat= 0.13596917332291267 \n",
      "acc for Psat= 0.1840685108319673 \n",
      "acc for optim= 0.18455704594294342\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.005132013466209173\n",
      "Loss on test= 0.007899654097855091\n",
      "acc for Lsat= 0.13448266966791336 \n",
      "acc for Psat= 0.18966256431513848 \n",
      "acc for optim= 0.1933187944234633\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.005045649595558643\n",
      "Loss on test= 0.00764812808483839\n",
      "acc for Lsat= 0.1400509080214075 \n",
      "acc for Psat= 0.18043618354599036 \n",
      "acc for optim= 0.18414916438007628\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.005241771228611469\n",
      "Loss on test= 0.007122417911887169\n",
      "acc for Lsat= 0.15177554185759873 \n",
      "acc for Psat= 0.19820240366608516 \n",
      "acc for optim= 0.19387485247138042\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.005564401857554913\n",
      "Loss on test= 0.0072479089722037315\n",
      "acc for Lsat= 0.13981214432774844 \n",
      "acc for Psat= 0.18380378776828216 \n",
      "acc for optim= 0.18081253026783864\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.005152976140379906\n",
      "Loss on test= 0.0070256199687719345\n",
      "acc for Lsat= 0.1447312661574497 \n",
      "acc for Psat= 0.19307652376744835 \n",
      "acc for optim= 0.1881174338786907\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.0053475345484912395\n",
      "Loss on test= 0.007404460106045008\n",
      "acc for Lsat= 0.13953597586817626 \n",
      "acc for Psat= 0.18026010303502352 \n",
      "acc for optim= 0.18895308956271037\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.00503672007471323\n",
      "Loss on test= 0.007509689778089523\n",
      "acc for Lsat= 0.152626167512098 \n",
      "acc for Psat= 0.18485600905240987 \n",
      "acc for optim= 0.18198938855622726\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.005477110389620066\n",
      "Loss on test= 0.0073408093303442\n",
      "acc for Lsat= 0.1478252870269257 \n",
      "acc for Psat= 0.1857485518388099 \n",
      "acc for optim= 0.18866347729545238\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.005132567603141069\n",
      "Loss on test= 0.007373275700956583\n",
      "acc for Lsat= 0.14015082804076792 \n",
      "acc for Psat= 0.18032312513928223 \n",
      "acc for optim= 0.179716007179031\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.005144782830029726\n",
      "Loss on test= 0.007043065503239632\n",
      "acc for Lsat= 0.13863783029278312 \n",
      "acc for Psat= 0.18597290718352583 \n",
      "acc for optim= 0.18750791490997845\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.0048739006742835045\n",
      "Loss on test= 0.007248988840728998\n",
      "acc for Lsat= 0.14096498570679764 \n",
      "acc for Psat= 0.20521863485499453 \n",
      "acc for optim= 0.1932621373510614\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.005111359991133213\n",
      "Loss on test= 0.007169094868004322\n",
      "acc for Lsat= 0.14148798477900362 \n",
      "acc for Psat= 0.18675552114470267 \n",
      "acc for optim= 0.183483698223832\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.0050582000985741615\n",
      "Loss on test= 0.0072280787862837315\n",
      "acc for Lsat= 0.14059860893777099 \n",
      "acc for Psat= 0.1917246519107005 \n",
      "acc for optim= 0.18488633484349654\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.005184196401387453\n",
      "Loss on test= 0.0076397801749408245\n",
      "acc for Lsat= 0.15344534209055338 \n",
      "acc for Psat= 0.18974822616723716 \n",
      "acc for optim= 0.18317488158383163\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.005165595095604658\n",
      "Loss on test= 0.007345023564994335\n",
      "acc for Lsat= 0.15612979886234407 \n",
      "acc for Psat= 0.17771648193476244 \n",
      "acc for optim= 0.1832866242835377\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.005103028379380703\n",
      "Loss on test= 0.00752738444134593\n",
      "acc for Lsat= 0.14135485316524626 \n",
      "acc for Psat= 0.19424741689276073 \n",
      "acc for optim= 0.17672772452093996\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.0050890217535197735\n",
      "Loss on test= 0.007439814042299986\n",
      "acc for Lsat= 0.14246357541386281 \n",
      "acc for Psat= 0.19626682102718376 \n",
      "acc for optim= 0.1785952730741749\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.005121796391904354\n",
      "Loss on test= 0.007450842298567295\n",
      "acc for Lsat= 0.1487064197512542 \n",
      "acc for Psat= 0.18274045171441328 \n",
      "acc for optim= 0.18231022401147934\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.005097156390547752\n",
      "Loss on test= 0.007365768309682608\n",
      "acc for Lsat= 0.1658526621644431 \n",
      "acc for Psat= 0.20209334860155054 \n",
      "acc for optim= 0.18027046419771725\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.0051648966036736965\n",
      "Loss on test= 0.0075715165585279465\n",
      "acc for Lsat= 0.14702054617284047 \n",
      "acc for Psat= 0.17729252625455255 \n",
      "acc for optim= 0.1818740709419515\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.0051498329266905785\n",
      "Loss on test= 0.007270393893122673\n",
      "acc for Lsat= 0.14789999961398817 \n",
      "acc for Psat= 0.18515950984924603 \n",
      "acc for optim= 0.1842566951338324\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.00522562675178051\n",
      "Loss on test= 0.007209207396954298\n",
      "acc for Lsat= 0.1409285447565499 \n",
      "acc for Psat= 0.18855034218505637 \n",
      "acc for optim= 0.1902534259822922\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.00500096520408988\n",
      "Loss on test= 0.007255049422383308\n",
      "acc for Lsat= 0.1402238429065977 \n",
      "acc for Psat= 0.18240533396172276 \n",
      "acc for optim= 0.18581195778488258\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.005054161883890629\n",
      "Loss on test= 0.007081915158778429\n",
      "acc for Lsat= 0.14560235875656782 \n",
      "acc for Psat= 0.18768194294820892 \n",
      "acc for optim= 0.18274620191058616\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.005267190746963024\n",
      "Loss on test= 0.007493745535612106\n",
      "acc for Lsat= 0.14535760463684888 \n",
      "acc for Psat= 0.18058031157143872 \n",
      "acc for optim= 0.18084138875434053\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.00530599057674408\n",
      "Loss on test= 0.00723482808098197\n",
      "acc for Lsat= 0.13595952044134257 \n",
      "acc for Psat= 0.18240744674494339 \n",
      "acc for optim= 0.18315933411778715\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.005306822247803211\n",
      "Loss on test= 0.007442830596119165\n",
      "acc for Lsat= 0.1460757741312397 \n",
      "acc for Psat= 0.18895770876676027 \n",
      "acc for optim= 0.18105711087462356\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.005114329047501087\n",
      "Loss on test= 0.0074175638146698475\n",
      "acc for Lsat= 0.1426522320899807 \n",
      "acc for Psat= 0.19328250861170865 \n",
      "acc for optim= 0.1834873026021237\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.005200532730668783\n",
      "Loss on test= 0.007593330927193165\n",
      "acc for Lsat= 0.14685804015903384 \n",
      "acc for Psat= 0.1798907854964529 \n",
      "acc for optim= 0.1880746211680907\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.005431128665804863\n",
      "Loss on test= 0.0071544949896633625\n",
      "acc for Lsat= 0.14833908566353904 \n",
      "acc for Psat= 0.1874134736412327 \n",
      "acc for optim= 0.1819914094700581\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.0052071064710617065\n",
      "Loss on test= 0.007302441168576479\n",
      "acc for Lsat= 0.15166297559972305 \n",
      "acc for Psat= 0.1917865943911745 \n",
      "acc for optim= 0.18621279222844933\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.005109640769660473\n",
      "Loss on test= 0.007370829116553068\n",
      "acc for Lsat= 0.14821625087122992 \n",
      "acc for Psat= 0.1882576267704459 \n",
      "acc for optim= 0.1862988277218213\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.005192138254642487\n",
      "Loss on test= 0.0071729449555277824\n",
      "acc for Lsat= 0.15026902991125635 \n",
      "acc for Psat= 0.20065365113875233 \n",
      "acc for optim= 0.1936833226649648\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.0053284550085663795\n",
      "Loss on test= 0.007302828133106232\n",
      "acc for Lsat= 0.13862415077832727 \n",
      "acc for Psat= 0.19012168089050005 \n",
      "acc for optim= 0.18072361909597348\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.00560283288359642\n",
      "Loss on test= 0.007284518331289291\n",
      "acc for Lsat= 0.1447433474893514 \n",
      "acc for Psat= 0.18399620938740316 \n",
      "acc for optim= 0.18290375846955298\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.0053393226116895676\n",
      "Loss on test= 0.006959282793104649\n",
      "acc for Lsat= 0.13685364541215975 \n",
      "acc for Psat= 0.19738024465709192 \n",
      "acc for optim= 0.18496867110303863\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.005169576499611139\n",
      "Loss on test= 0.007186390925198793\n",
      "acc for Lsat= 0.14865731707025992 \n",
      "acc for Psat= 0.18125580519048468 \n",
      "acc for optim= 0.18826159914572854\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.005124970804899931\n",
      "Loss on test= 0.00716388737782836\n",
      "acc for Lsat= 0.14835080988342553 \n",
      "acc for Psat= 0.1853424234682175 \n",
      "acc for optim= 0.18376601123857908\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.005052913445979357\n",
      "Loss on test= 0.007444977294653654\n",
      "acc for Lsat= 0.13964942631494925 \n",
      "acc for Psat= 0.18695799863179688 \n",
      "acc for optim= 0.18419115893551355\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.004851270467042923\n",
      "Loss on test= 0.007523830514401197\n",
      "acc for Lsat= 0.14784676179091338 \n",
      "acc for Psat= 0.18961281544628142 \n",
      "acc for optim= 0.18236266596657397\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.00514677818864584\n",
      "Loss on test= 0.0073108188807964325\n",
      "acc for Lsat= 0.1441007781217851 \n",
      "acc for Psat= 0.20041507336627845 \n",
      "acc for optim= 0.184410732110092\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.004991869907826185\n",
      "Loss on test= 0.007437244988977909\n",
      "acc for Lsat= 0.1520340644292625 \n",
      "acc for Psat= 0.19268961576993013 \n",
      "acc for optim= 0.1874774515766223\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.00544815044850111\n",
      "Loss on test= 0.007221227511763573\n",
      "acc for Lsat= 0.14174825755543397 \n",
      "acc for Psat= 0.18433756378105245 \n",
      "acc for optim= 0.18491367942042417\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.005217855796217918\n",
      "Loss on test= 0.006927405949681997\n",
      "acc for Lsat= 0.13452073400305797 \n",
      "acc for Psat= 0.18829944325633896 \n",
      "acc for optim= 0.19718322573519756\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.005395744927227497\n",
      "Loss on test= 0.0072858091443777084\n",
      "acc for Lsat= 0.1421284526895701 \n",
      "acc for Psat= 0.18289621517817933 \n",
      "acc for optim= 0.18557783291411784\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.0051000784151256084\n",
      "Loss on test= 0.007099441718310118\n",
      "acc for Lsat= 0.14431171590943256 \n",
      "acc for Psat= 0.18099067991954412 \n",
      "acc for optim= 0.19290442414508777\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.005407900549471378\n",
      "Loss on test= 0.007621252443641424\n",
      "acc for Lsat= 0.14616703008524068 \n",
      "acc for Psat= 0.18885133148869498 \n",
      "acc for optim= 0.18678224947242464\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.005423561669886112\n",
      "Loss on test= 0.007246398366987705\n",
      "acc for Lsat= 0.1471460226990023 \n",
      "acc for Psat= 0.19673206122252387 \n",
      "acc for optim= 0.18261589284334523\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.005201319698244333\n",
      "Loss on test= 0.007264601532369852\n",
      "acc for Lsat= 0.1541511139866789 \n",
      "acc for Psat= 0.1990038992302706 \n",
      "acc for optim= 0.1769940108177021\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.005168044473975897\n",
      "Loss on test= 0.0075104720890522\n",
      "acc for Lsat= 0.1415792604077218 \n",
      "acc for Psat= 0.2017359360804415 \n",
      "acc for optim= 0.1846408469753233\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.005013910122215748\n",
      "Loss on test= 0.007336795330047607\n",
      "acc for Lsat= 0.15005723140984925 \n",
      "acc for Psat= 0.2026099185554738 \n",
      "acc for optim= 0.18463885003479472\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.0052840253338217735\n",
      "Loss on test= 0.007449659984558821\n",
      "acc for Lsat= 0.14877872604525602 \n",
      "acc for Psat= 0.19380148032080902 \n",
      "acc for optim= 0.17955008556167681\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.0053419554606080055\n",
      "Loss on test= 0.007146865129470825\n",
      "acc for Lsat= 0.14613280572439927 \n",
      "acc for Psat= 0.1911134974863075 \n",
      "acc for optim= 0.18424638011106328\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.005222559906542301\n",
      "Loss on test= 0.007390813436359167\n",
      "acc for Lsat= 0.13928866243740395 \n",
      "acc for Psat= 0.1952283358510553 \n",
      "acc for optim= 0.17735426742244764\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.005459941923618317\n",
      "Loss on test= 0.0074979569762945175\n",
      "acc for Lsat= 0.14269930752372126 \n",
      "acc for Psat= 0.18348560486156798 \n",
      "acc for optim= 0.19027837590547278\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.005152990110218525\n",
      "Loss on test= 0.007241357117891312\n",
      "acc for Lsat= 0.1472460907563323 \n",
      "acc for Psat= 0.19559857322238997 \n",
      "acc for optim= 0.17917772500859727\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.005132470745593309\n",
      "Loss on test= 0.00728329923003912\n",
      "acc for Lsat= 0.14691444732111375 \n",
      "acc for Psat= 0.18613725654519883 \n",
      "acc for optim= 0.1936602504759336\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.005360833834856749\n",
      "Loss on test= 0.007465376053005457\n",
      "acc for Lsat= 0.14056496937037827 \n",
      "acc for Psat= 0.1926291705798606 \n",
      "acc for optim= 0.18232698148626025\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.005408704746514559\n",
      "Loss on test= 0.007791461888700724\n",
      "acc for Lsat= 0.1493759989673577 \n",
      "acc for Psat= 0.18800077911840415 \n",
      "acc for optim= 0.18593466720929308\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.005276530049741268\n",
      "Loss on test= 0.008225207217037678\n",
      "acc for Lsat= 0.14984241452733185 \n",
      "acc for Psat= 0.1902312174094001 \n",
      "acc for optim= 0.17967421371169143\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005323219113051891\n",
      "Loss on test= 0.007638539653271437\n",
      "acc for Lsat= 0.1384494281564763 \n",
      "acc for Psat= 0.17897118740127285 \n",
      "acc for optim= 0.1782058284373679\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.0052355509251356125\n",
      "Loss on test= 0.007345652207732201\n",
      "acc for Lsat= 0.14781442933599465 \n",
      "acc for Psat= 0.190651105124824 \n",
      "acc for optim= 0.18038572160456498\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.005287661217153072\n",
      "Loss on test= 0.007488039787858725\n",
      "acc for Lsat= 0.12864375615322612 \n",
      "acc for Psat= 0.19195542134999174 \n",
      "acc for optim= 0.1882560402085264\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.005314371548593044\n",
      "Loss on test= 0.007485003676265478\n",
      "acc for Lsat= 0.1372728696394498 \n",
      "acc for Psat= 0.19639558967519705 \n",
      "acc for optim= 0.1803017185433657\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.005228567402809858\n",
      "Loss on test= 0.007406412158161402\n",
      "acc for Lsat= 0.15315045637945018 \n",
      "acc for Psat= 0.1862597407555574 \n",
      "acc for optim= 0.1796534336885804\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.005204451270401478\n",
      "Loss on test= 0.00743484403938055\n",
      "acc for Lsat= 0.1485359009164462 \n",
      "acc for Psat= 0.1863354084739408 \n",
      "acc for optim= 0.18057361516689302\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.0051323589868843555\n",
      "Loss on test= 0.00738472631201148\n",
      "acc for Lsat= 0.14956886151067905 \n",
      "acc for Psat= 0.1957676349155038 \n",
      "acc for optim= 0.18640510752781858\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.005345834884792566\n",
      "Loss on test= 0.007481199689209461\n",
      "acc for Lsat= 0.13356344439967185 \n",
      "acc for Psat= 0.18769166153990643 \n",
      "acc for optim= 0.18129972163697544\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.00539753120392561\n",
      "Loss on test= 0.007566969376057386\n",
      "acc for Lsat= 0.15506273164365203 \n",
      "acc for Psat= 0.19486611860739372 \n",
      "acc for optim= 0.18570494459919082\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.005216219462454319\n",
      "Loss on test= 0.0072760130278766155\n",
      "acc for Lsat= 0.14851716762297923 \n",
      "acc for Psat= 0.19158596205286543 \n",
      "acc for optim= 0.1851495775498018\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.005367442034184933\n",
      "Loss on test= 0.0073930248618125916\n",
      "acc for Lsat= 0.14266698071485018 \n",
      "acc for Psat= 0.1833661278125784 \n",
      "acc for optim= 0.18816577217448122\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.005312622990459204\n",
      "Loss on test= 0.007115669548511505\n",
      "acc for Lsat= 0.1325112685705745 \n",
      "acc for Psat= 0.18687972050163987 \n",
      "acc for optim= 0.18526984546505312\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.005024527199566364\n",
      "Loss on test= 0.007810924202203751\n",
      "acc for Lsat= 0.1542787532894643 \n",
      "acc for Psat= 0.18876992835067824 \n",
      "acc for optim= 0.17948251797669265\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.005291925277560949\n",
      "Loss on test= 0.007239148486405611\n",
      "acc for Lsat= 0.16116284947827092 \n",
      "acc for Psat= 0.17446280608266654 \n",
      "acc for optim= 0.1863797604602563\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.005418216343969107\n",
      "Loss on test= 0.007396386004984379\n",
      "acc for Lsat= 0.13753561015149243 \n",
      "acc for Psat= 0.1790712095043225 \n",
      "acc for optim= 0.1806903370808749\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.0051038628444075584\n",
      "Loss on test= 0.007318188901990652\n",
      "acc for Lsat= 0.15384094781434587 \n",
      "acc for Psat= 0.17431168001036343 \n",
      "acc for optim= 0.17967290674454578\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.005485065747052431\n",
      "Loss on test= 0.0073624164797365665\n",
      "acc for Lsat= 0.14261138988467942 \n",
      "acc for Psat= 0.1854114059809229 \n",
      "acc for optim= 0.1893012951670184\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005176495760679245\n",
      "Loss on test= 0.0072114234790205956\n",
      "acc for Lsat= 0.13269308395242438 \n",
      "acc for Psat= 0.18874984187327828 \n",
      "acc for optim= 0.19229049123022093\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.005096716340631247\n",
      "Loss on test= 0.007705825846642256\n",
      "acc for Lsat= 0.14976076583538325 \n",
      "acc for Psat= 0.19167828028620848 \n",
      "acc for optim= 0.18427428985997407\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.005640216171741486\n",
      "Loss on test= 0.007215915713459253\n",
      "acc for Lsat= 0.13904755167662144 \n",
      "acc for Psat= 0.18713866534765017 \n",
      "acc for optim= 0.18188099273968084\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.00527263805270195\n",
      "Loss on test= 0.007911228574812412\n",
      "acc for Lsat= 0.13336780349424368 \n",
      "acc for Psat= 0.177866568010621 \n",
      "acc for optim= 0.19368133572098173\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.005241887643933296\n",
      "Loss on test= 0.007280764169991016\n",
      "acc for Lsat= 0.14738950674406817 \n",
      "acc for Psat= 0.2001839322877712 \n",
      "acc for optim= 0.18599476009057683\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.005229123402386904\n",
      "Loss on test= 0.0070338319055736065\n",
      "acc for Lsat= 0.14751799665146925 \n",
      "acc for Psat= 0.18687992638188455 \n",
      "acc for optim= 0.19079979686662898\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.0049246205016970634\n",
      "Loss on test= 0.007347683887928724\n",
      "acc for Lsat= 0.1489379584903783 \n",
      "acc for Psat= 0.1777327232746041 \n",
      "acc for optim= 0.17767697685176542\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.005241249222308397\n",
      "Loss on test= 0.007062349934130907\n",
      "acc for Lsat= 0.1463300632627549 \n",
      "acc for Psat= 0.1876167630275676 \n",
      "acc for optim= 0.18123551323899206\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.005431712605059147\n",
      "Loss on test= 0.006754634436219931\n",
      "acc for Lsat= 0.1407212164375137 \n",
      "acc for Psat= 0.18131190168632066 \n",
      "acc for optim= 0.18158536797325456\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.005233726929873228\n",
      "Loss on test= 0.007504676003009081\n",
      "acc for Lsat= 0.13727418148363407 \n",
      "acc for Psat= 0.19037198943227193 \n",
      "acc for optim= 0.18889613094678545\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.0053677624091506\n",
      "Loss on test= 0.007396886590868235\n",
      "acc for Lsat= 0.13352150749006036 \n",
      "acc for Psat= 0.1828258034736791 \n",
      "acc for optim= 0.19005591781870995\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.005643215961754322\n",
      "Loss on test= 0.0077402167953550816\n",
      "acc for Lsat= 0.15326206713564672 \n",
      "acc for Psat= 0.18957727173244063 \n",
      "acc for optim= 0.18125169673690297\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.0054857442155480385\n",
      "Loss on test= 0.007229633163660765\n",
      "acc for Lsat= 0.13451824744420934 \n",
      "acc for Psat= 0.18805806965206476 \n",
      "acc for optim= 0.1794595232800214\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.00534656411036849\n",
      "Loss on test= 0.007356956135481596\n",
      "acc for Lsat= 0.14814376002614155 \n",
      "acc for Psat= 0.2069993585670657 \n",
      "acc for optim= 0.18801968717293005\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.005270059686154127\n",
      "Loss on test= 0.007836013101041317\n",
      "acc for Lsat= 0.1493861957149748 \n",
      "acc for Psat= 0.1754296384971268 \n",
      "acc for optim= 0.1873308204894038\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.005303576122969389\n",
      "Loss on test= 0.007367145735770464\n",
      "acc for Lsat= 0.14563151622949322 \n",
      "acc for Psat= 0.19105926855578576 \n",
      "acc for optim= 0.1862742285056662\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.0050646839663386345\n",
      "Loss on test= 0.00727824866771698\n",
      "acc for Lsat= 0.13617251487296136 \n",
      "acc for Psat= 0.18382123595725774 \n",
      "acc for optim= 0.1882702756781402\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.00555263739079237\n",
      "Loss on test= 0.0075278268195688725\n",
      "acc for Lsat= 0.14053613416484145 \n",
      "acc for Psat= 0.1883153059586623 \n",
      "acc for optim= 0.18523233495404579\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.0052693551406264305\n",
      "Loss on test= 0.007099551148712635\n",
      "acc for Lsat= 0.14506343904926564 \n",
      "acc for Psat= 0.1821268379774143 \n",
      "acc for optim= 0.18098011011711979\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.005239077843725681\n",
      "Loss on test= 0.007501218933612108\n",
      "acc for Lsat= 0.15448126736150475 \n",
      "acc for Psat= 0.18727747250742424 \n",
      "acc for optim= 0.1790219289077003\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.0057474588975310326\n",
      "Loss on test= 0.007391277700662613\n",
      "acc for Lsat= 0.151471991609156 \n",
      "acc for Psat= 0.19855549835149566 \n",
      "acc for optim= 0.18147595563103572\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.005109697114676237\n",
      "Loss on test= 0.0075717708095908165\n",
      "acc for Lsat= 0.14017658994674348 \n",
      "acc for Psat= 0.18097315723969618 \n",
      "acc for optim= 0.19013647011617918\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.005079525522887707\n",
      "Loss on test= 0.007555701304227114\n",
      "acc for Lsat= 0.14698318228512988 \n",
      "acc for Psat= 0.17974194708513097 \n",
      "acc for optim= 0.18358933729125324\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.005410050507634878\n",
      "Loss on test= 0.007116703782230616\n",
      "acc for Lsat= 0.14461268869679056 \n",
      "acc for Psat= 0.18620540068606983 \n",
      "acc for optim= 0.1866000245706957\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005218254402279854\n",
      "Loss on test= 0.007338431663811207\n",
      "acc for Lsat= 0.1574351108476489 \n",
      "acc for Psat= 0.1767162796506872 \n",
      "acc for optim= 0.183249450727656\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.0053513916209340096\n",
      "Loss on test= 0.007586962077766657\n",
      "acc for Lsat= 0.1417986688908327 \n",
      "acc for Psat= 0.19332855905570304 \n",
      "acc for optim= 0.18865652507625244\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.00509145762771368\n",
      "Loss on test= 0.0074256411753594875\n",
      "acc for Lsat= 0.15598589328087134 \n",
      "acc for Psat= 0.18457209266885374 \n",
      "acc for optim= 0.18512237407343432\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.0052755456417799\n",
      "Loss on test= 0.0072506386786699295\n",
      "acc for Lsat= 0.14672396901143775 \n",
      "acc for Psat= 0.19001940055215946 \n",
      "acc for optim= 0.18389972013203792\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.005052984692156315\n",
      "Loss on test= 0.007658819202333689\n",
      "acc for Lsat= 0.15162948294252646 \n",
      "acc for Psat= 0.1716273840970062 \n",
      "acc for optim= 0.17948160954630843\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.005252658389508724\n",
      "Loss on test= 0.0076116640120744705\n",
      "acc for Lsat= 0.14400600108430628 \n",
      "acc for Psat= 0.1871365157675502 \n",
      "acc for optim= 0.18397127445558178\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.005218100268393755\n",
      "Loss on test= 0.007232756819576025\n",
      "acc for Lsat= 0.13880432629194417 \n",
      "acc for Psat= 0.18938668668060182 \n",
      "acc for optim= 0.17150593196961753\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.005151959136128426\n",
      "Loss on test= 0.00768417539075017\n",
      "acc for Lsat= 0.137884658318658 \n",
      "acc for Psat= 0.17855181534503603 \n",
      "acc for optim= 0.1846864514577691\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.005552308633923531\n",
      "Loss on test= 0.007342393510043621\n",
      "acc for Lsat= 0.16040422046188738 \n",
      "acc for Psat= 0.18175762890013636 \n",
      "acc for optim= 0.18607957120622187\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.005281304940581322\n",
      "Loss on test= 0.007323010824620724\n",
      "acc for Lsat= 0.14835153174470656 \n",
      "acc for Psat= 0.18118511614393057 \n",
      "acc for optim= 0.1863547989270329\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.005302119068801403\n",
      "Loss on test= 0.006721462123095989\n",
      "acc for Lsat= 0.14860584008179178 \n",
      "acc for Psat= 0.18442556243828787 \n",
      "acc for optim= 0.1789460801036974\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.005305818747729063\n",
      "Loss on test= 0.007210030220448971\n",
      "acc for Lsat= 0.14416595850842165 \n",
      "acc for Psat= 0.18318708054683186 \n",
      "acc for optim= 0.18688867505235202\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.0055065397173166275\n",
      "Loss on test= 0.006930094677954912\n",
      "acc for Lsat= 0.14593406441725493 \n",
      "acc for Psat= 0.18902551380995677 \n",
      "acc for optim= 0.181757440340522\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.005215193144977093\n",
      "Loss on test= 0.007847256027162075\n",
      "acc for Lsat= 0.1453503294885836 \n",
      "acc for Psat= 0.20592836440945442 \n",
      "acc for optim= 0.18383725230938938\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.005215728189796209\n",
      "Loss on test= 0.007261177059262991\n",
      "acc for Lsat= 0.13447194016217942 \n",
      "acc for Psat= 0.17765401948174675 \n",
      "acc for optim= 0.189765492803608\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.005109819583594799\n",
      "Loss on test= 0.0074008130468428135\n",
      "acc for Lsat= 0.15307411072078184 \n",
      "acc for Psat= 0.1966464538050846 \n",
      "acc for optim= 0.17323896438341405\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.005272839218378067\n",
      "Loss on test= 0.007163486909121275\n",
      "acc for Lsat= 0.14283930079016233 \n",
      "acc for Psat= 0.18968891905139765 \n",
      "acc for optim= 0.18325441191245476\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.005231390707194805\n",
      "Loss on test= 0.0070591941475868225\n",
      "acc for Lsat= 0.1325001461542074 \n",
      "acc for Psat= 0.18831502342177744 \n",
      "acc for optim= 0.19035085985612613\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.004949899856001139\n",
      "Loss on test= 0.0076895407401025295\n",
      "acc for Lsat= 0.1403882834419716 \n",
      "acc for Psat= 0.17756047378309436 \n",
      "acc for optim= 0.18577391971952328\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.005173310171812773\n",
      "Loss on test= 0.007384647149592638\n",
      "acc for Lsat= 0.14733069280170089 \n",
      "acc for Psat= 0.19985111313719364 \n",
      "acc for optim= 0.18530057872416306\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.005367572419345379\n",
      "Loss on test= 0.007111626211553812\n",
      "acc for Lsat= 0.14241030675313268 \n",
      "acc for Psat= 0.19524476745005576 \n",
      "acc for optim= 0.18498459249535923\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.005140596069395542\n",
      "Loss on test= 0.007469767238944769\n",
      "acc for Lsat= 0.1466857462165282 \n",
      "acc for Psat= 0.19404088475924658 \n",
      "acc for optim= 0.17665904084197628\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.005095667205750942\n",
      "Loss on test= 0.007555501069873571\n",
      "acc for Lsat= 0.14940472858516676 \n",
      "acc for Psat= 0.19457301295951168 \n",
      "acc for optim= 0.19034292152090396\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.005066275596618652\n",
      "Loss on test= 0.007536708377301693\n",
      "acc for Lsat= 0.14555166210868534 \n",
      "acc for Psat= 0.19839995263266513 \n",
      "acc for optim= 0.18307034237783584\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.005406166892498732\n",
      "Loss on test= 0.007260704878717661\n",
      "acc for Lsat= 0.14174870533904932 \n",
      "acc for Psat= 0.18188218728898733 \n",
      "acc for optim= 0.1843604141018033\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.0053223236463963985\n",
      "Loss on test= 0.007335553411394358\n",
      "acc for Lsat= 0.14230245752622694 \n",
      "acc for Psat= 0.19359758714000222 \n",
      "acc for optim= 0.1915856633991858\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.0051383874379098415\n",
      "Loss on test= 0.007477647624909878\n",
      "acc for Lsat= 0.14310269873154152 \n",
      "acc for Psat= 0.18150845467574325 \n",
      "acc for optim= 0.17808878403595937\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.005186417605727911\n",
      "Loss on test= 0.007509991992264986\n",
      "acc for Lsat= 0.15087263583717103 \n",
      "acc for Psat= 0.19490007946072585 \n",
      "acc for optim= 0.18514861818994624\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.005202186293900013\n",
      "Loss on test= 0.007436790037900209\n",
      "acc for Lsat= 0.151221439758789 \n",
      "acc for Psat= 0.20668041990062253 \n",
      "acc for optim= 0.17986118319371838\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.005314485169947147\n",
      "Loss on test= 0.007307351101189852\n",
      "acc for Lsat= 0.1322724872903832 \n",
      "acc for Psat= 0.1862593214305859 \n",
      "acc for optim= 0.1825345724975675\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.005264940671622753\n",
      "Loss on test= 0.007695603184401989\n",
      "acc for Lsat= 0.14409828881263642 \n",
      "acc for Psat= 0.18601833493792314 \n",
      "acc for optim= 0.1853547025532996\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005342388059943914\n",
      "Loss on test= 0.007378370966762304\n",
      "acc for Lsat= 0.14180320838330787 \n",
      "acc for Psat= 0.1910029097693041 \n",
      "acc for optim= 0.17561149757439423\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.005193869583308697\n",
      "Loss on test= 0.007374558597803116\n",
      "acc for Lsat= 0.15842235751352732 \n",
      "acc for Psat= 0.18831965977318402 \n",
      "acc for optim= 0.18239838043409096\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005025127436965704\n",
      "Loss on test= 0.007473067846149206\n",
      "acc for Lsat= 0.1418002328649354 \n",
      "acc for Psat= 0.18772436983313576 \n",
      "acc for optim= 0.18778879044672425\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.005063480231910944\n",
      "Loss on test= 0.00761227123439312\n",
      "acc for Lsat= 0.1386544121475127 \n",
      "acc for Psat= 0.18022197901608125 \n",
      "acc for optim= 0.18777001217001912\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.005360303446650505\n",
      "Loss on test= 0.007283691316843033\n",
      "acc for Lsat= 0.1514902657871211 \n",
      "acc for Psat= 0.18481993903673147 \n",
      "acc for optim= 0.18533368685039917\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.005429291166365147\n",
      "Loss on test= 0.007398733403533697\n",
      "acc for Lsat= 0.16290984842243994 \n",
      "acc for Psat= 0.19317193695691845 \n",
      "acc for optim= 0.18162352527018452\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.005589093081653118\n",
      "Loss on test= 0.007329212035983801\n",
      "acc for Lsat= 0.1295729587535893 \n",
      "acc for Psat= 0.18094906652666873 \n",
      "acc for optim= 0.18483980971800743\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.005092189647257328\n",
      "Loss on test= 0.007535015232861042\n",
      "acc for Lsat= 0.15393351621813234 \n",
      "acc for Psat= 0.1991202392611561 \n",
      "acc for optim= 0.18493519913057843\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.005263724364340305\n",
      "Loss on test= 0.0069304341450333595\n",
      "acc for Lsat= 0.14470935699579565 \n",
      "acc for Psat= 0.1959563257966618 \n",
      "acc for optim= 0.18088659405446855\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005037671886384487\n",
      "Loss on test= 0.0074439565651118755\n",
      "acc for Lsat= 0.14271825783500508 \n",
      "acc for Psat= 0.19772891776033175 \n",
      "acc for optim= 0.1801205033684516\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.0056577762588858604\n",
      "Loss on test= 0.007449462544173002\n",
      "acc for Lsat= 0.13823864568391295 \n",
      "acc for Psat= 0.17903093808849693 \n",
      "acc for optim= 0.17889835917759214\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.005332716275006533\n",
      "Loss on test= 0.0073558432050049305\n",
      "acc for Lsat= 0.13812690871160813 \n",
      "acc for Psat= 0.17790385286722593 \n",
      "acc for optim= 0.19078228287484694\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.005368673242628574\n",
      "Loss on test= 0.007407705299556255\n",
      "acc for Lsat= 0.13684697159848436 \n",
      "acc for Psat= 0.18581481192024332 \n",
      "acc for optim= 0.1907705861643304\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.005202324129641056\n",
      "Loss on test= 0.007159107830375433\n",
      "acc for Lsat= 0.1471212848654536 \n",
      "acc for Psat= 0.1951752074642396 \n",
      "acc for optim= 0.18525226396913105\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.005223320331424475\n",
      "Loss on test= 0.007505962625145912\n",
      "acc for Lsat= 0.14783869114166248 \n",
      "acc for Psat= 0.1832267394274107 \n",
      "acc for optim= 0.1868759870697118\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.00526453135535121\n",
      "Loss on test= 0.007680317386984825\n",
      "acc for Lsat= 0.14952228036785467 \n",
      "acc for Psat= 0.18964287655534925 \n",
      "acc for optim= 0.18186454394728244\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.005087538156658411\n",
      "Loss on test= 0.0074212378822267056\n",
      "acc for Lsat= 0.14454904780475056 \n",
      "acc for Psat= 0.19536118876984815 \n",
      "acc for optim= 0.1829350430220671\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.005347359925508499\n",
      "Loss on test= 0.007336510345339775\n",
      "acc for Lsat= 0.1480560647354263 \n",
      "acc for Psat= 0.18333908363253063 \n",
      "acc for optim= 0.19102165004654528\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005318391136825085\n",
      "Loss on test= 0.007321679964661598\n",
      "acc for Lsat= 0.14511411929267867 \n",
      "acc for Psat= 0.16809955094518717 \n",
      "acc for optim= 0.19315378641973052\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.0053838929161429405\n",
      "Loss on test= 0.007107939571142197\n",
      "acc for Lsat= 0.14704922548164595 \n",
      "acc for Psat= 0.18015876584743593 \n",
      "acc for optim= 0.18017389527502942\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.005174322985112667\n",
      "Loss on test= 0.007397863548249006\n",
      "acc for Lsat= 0.13935264975880274 \n",
      "acc for Psat= 0.1912519949160089 \n",
      "acc for optim= 0.18309349565858357\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.0049002221785485744\n",
      "Loss on test= 0.0073089078068733215\n",
      "acc for Lsat= 0.1475622413950957 \n",
      "acc for Psat= 0.19629313951185484 \n",
      "acc for optim= 0.18392646731045403\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.0052073015831410885\n",
      "Loss on test= 0.0074179344810545444\n",
      "acc for Lsat= 0.1519967914178212 \n",
      "acc for Psat= 0.19430616055963537 \n",
      "acc for optim= 0.18918182181850932\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.005285231396555901\n",
      "Loss on test= 0.007139718625694513\n",
      "acc for Lsat= 0.14705614548770055 \n",
      "acc for Psat= 0.18690345329623745 \n",
      "acc for optim= 0.18532411742842847\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.005056440364569426\n",
      "Loss on test= 0.007459573447704315\n",
      "acc for Lsat= 0.14384081780750183 \n",
      "acc for Psat= 0.19046253206162544 \n",
      "acc for optim= 0.18889689688307432\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.005300682969391346\n",
      "Loss on test= 0.007481843698769808\n",
      "acc for Lsat= 0.13894425316362596 \n",
      "acc for Psat= 0.18595500010997057 \n",
      "acc for optim= 0.18058536126560792\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.005299554672092199\n",
      "Loss on test= 0.007381333038210869\n",
      "acc for Lsat= 0.14394510647808736 \n",
      "acc for Psat= 0.18007143870459824 \n",
      "acc for optim= 0.18051005551614416\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.005258805118501186\n",
      "Loss on test= 0.007374436594545841\n",
      "acc for Lsat= 0.13461616107474508 \n",
      "acc for Psat= 0.17390182711781368 \n",
      "acc for optim= 0.18660444854147976\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.0052940985187888145\n",
      "Loss on test= 0.006963490508496761\n",
      "acc for Lsat= 0.14300128441975743 \n",
      "acc for Psat= 0.20426596658853965 \n",
      "acc for optim= 0.1796226846551824\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.005370432510972023\n",
      "Loss on test= 0.007558172103017569\n",
      "acc for Lsat= 0.14203596811314098 \n",
      "acc for Psat= 0.180923190100317 \n",
      "acc for optim= 0.1853186572004934\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.00536893866956234\n",
      "Loss on test= 0.007348144892603159\n",
      "acc for Lsat= 0.14493321978017595 \n",
      "acc for Psat= 0.19028488323016124 \n",
      "acc for optim= 0.18352672388738014\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.005382426083087921\n",
      "Loss on test= 0.007463889662176371\n",
      "acc for Lsat= 0.15233239811009225 \n",
      "acc for Psat= 0.17880435639240427 \n",
      "acc for optim= 0.1857481564673763\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.005275220610201359\n",
      "Loss on test= 0.0072778561152517796\n",
      "acc for Lsat= 0.1361916409260555 \n",
      "acc for Psat= 0.19687610579288153 \n",
      "acc for optim= 0.1858893543721337\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.005236177239567041\n",
      "Loss on test= 0.007766807917505503\n",
      "acc for Lsat= 0.1355292619034251 \n",
      "acc for Psat= 0.1820929218564549 \n",
      "acc for optim= 0.18639229098754767\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.0051553151570260525\n",
      "Loss on test= 0.007332244422286749\n",
      "acc for Lsat= 0.14330073370136412 \n",
      "acc for Psat= 0.19180727508682452 \n",
      "acc for optim= 0.1821760023552848\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.00546348886564374\n",
      "Loss on test= 0.007666495628654957\n",
      "acc for Lsat= 0.14225044573445378 \n",
      "acc for Psat= 0.17623219856931294 \n",
      "acc for optim= 0.184651973732312\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.00526522658765316\n",
      "Loss on test= 0.0071031274273991585\n",
      "acc for Lsat= 0.13317039141576492 \n",
      "acc for Psat= 0.16868929833251997 \n",
      "acc for optim= 0.18856108064322397\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005309614352881908\n",
      "Loss on test= 0.0072831762954592705\n",
      "acc for Lsat= 0.14313703234332278 \n",
      "acc for Psat= 0.1954791010013919 \n",
      "acc for optim= 0.19287681138814716\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.005334143061190844\n",
      "Loss on test= 0.007417670451104641\n",
      "acc for Lsat= 0.16235562093846012 \n",
      "acc for Psat= 0.19931766620634855 \n",
      "acc for optim= 0.18758924754773512\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.005193304270505905\n",
      "Loss on test= 0.007566183339804411\n",
      "acc for Lsat= 0.15641537845182685 \n",
      "acc for Psat= 0.19414267538832958 \n",
      "acc for optim= 0.18704991999955858\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.0053971814922988415\n",
      "Loss on test= 0.00689578615128994\n",
      "acc for Lsat= 0.1391317187356152 \n",
      "acc for Psat= 0.1858062206786584 \n",
      "acc for optim= 0.1823682014795104\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.005437734071165323\n",
      "Loss on test= 0.007714256644248962\n",
      "acc for Lsat= 0.1562811087507785 \n",
      "acc for Psat= 0.19467205508253307 \n",
      "acc for optim= 0.18311199771591508\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.00524535495787859\n",
      "Loss on test= 0.007463398855179548\n",
      "acc for Lsat= 0.13658650720598878 \n",
      "acc for Psat= 0.1879053069291957 \n",
      "acc for optim= 0.18430784168561584\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.005151995457708836\n",
      "Loss on test= 0.007064868696033955\n",
      "acc for Lsat= 0.15227311754200348 \n",
      "acc for Psat= 0.18991336897931627 \n",
      "acc for optim= 0.19003919320959659\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.005182476248592138\n",
      "Loss on test= 0.007455719634890556\n",
      "acc for Lsat= 0.14543789903553142 \n",
      "acc for Psat= 0.19257283557862898 \n",
      "acc for optim= 0.1846355269691901\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.005416105501353741\n",
      "Loss on test= 0.007283964194357395\n",
      "acc for Lsat= 0.14873942381131738 \n",
      "acc for Psat= 0.18022822497668295 \n",
      "acc for optim= 0.1861971750374517\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.00538658257573843\n",
      "Loss on test= 0.007546073291450739\n",
      "acc for Lsat= 0.13166570002914474 \n",
      "acc for Psat= 0.17313736633657187 \n",
      "acc for optim= 0.18536737323261523\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.005202355794608593\n",
      "Loss on test= 0.007442455738782883\n",
      "acc for Lsat= 0.14797220640170738 \n",
      "acc for Psat= 0.1790575722944312 \n",
      "acc for optim= 0.18096107382636964\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.005209804512560368\n",
      "Loss on test= 0.006965885870158672\n",
      "acc for Lsat= 0.1447109380992679 \n",
      "acc for Psat= 0.19700563609920688 \n",
      "acc for optim= 0.18646963199974634\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.005236699245870113\n",
      "Loss on test= 0.0069809118285775185\n",
      "acc for Lsat= 0.1403164604110987 \n",
      "acc for Psat= 0.18274144407335027 \n",
      "acc for optim= 0.19223512186913094\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005428990349173546\n",
      "Loss on test= 0.007223957683891058\n",
      "acc for Lsat= 0.14018606342428716 \n",
      "acc for Psat= 0.18723696733220885 \n",
      "acc for optim= 0.189070296180091\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.00533709954470396\n",
      "Loss on test= 0.007224385626614094\n",
      "acc for Lsat= 0.14832211885502042 \n",
      "acc for Psat= 0.20610397863697993 \n",
      "acc for optim= 0.1846765513828132\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.005355543456971645\n",
      "Loss on test= 0.007566583342850208\n",
      "acc for Lsat= 0.1406011434546748 \n",
      "acc for Psat= 0.19478736700333624 \n",
      "acc for optim= 0.18415660174662765\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.0050299642607569695\n",
      "Loss on test= 0.0074820066802203655\n",
      "acc for Lsat= 0.13099572600025805 \n",
      "acc for Psat= 0.17989441067262812 \n",
      "acc for optim= 0.18508840559248918\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.0052624354138970375\n",
      "Loss on test= 0.007540143094956875\n",
      "acc for Lsat= 0.15265029432045937 \n",
      "acc for Psat= 0.19452550043037053 \n",
      "acc for optim= 0.18169704680941753\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.0053503988310694695\n",
      "Loss on test= 0.007586865220218897\n",
      "acc for Lsat= 0.13675403163737815 \n",
      "acc for Psat= 0.19374016288851129 \n",
      "acc for optim= 0.18279566678312056\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.005631309002637863\n",
      "Loss on test= 0.007206402253359556\n",
      "acc for Lsat= 0.13835585649205434 \n",
      "acc for Psat= 0.18970004522707312 \n",
      "acc for optim= 0.186493831370732\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.005083599593490362\n",
      "Loss on test= 0.0072608040645718575\n",
      "acc for Lsat= 0.1417932675449086 \n",
      "acc for Psat= 0.1883268335099393 \n",
      "acc for optim= 0.18839437784499452\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.005200990475714207\n",
      "Loss on test= 0.007194837089627981\n",
      "acc for Lsat= 0.1412695736204442 \n",
      "acc for Psat= 0.1708140325646649 \n",
      "acc for optim= 0.18324399954986711\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.005363293923437595\n",
      "Loss on test= 0.007450347766280174\n",
      "acc for Lsat= 0.15604825869591937 \n",
      "acc for Psat= 0.19051170515499583 \n",
      "acc for optim= 0.178674677310542\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.0056152865290641785\n",
      "Loss on test= 0.007146413438022137\n",
      "acc for Lsat= 0.13705173380129979 \n",
      "acc for Psat= 0.17764675537425811 \n",
      "acc for optim= 0.18827404439617254\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.005122304894030094\n",
      "Loss on test= 0.007430782541632652\n",
      "acc for Lsat= 0.1423296123102773 \n",
      "acc for Psat= 0.2056583981106027 \n",
      "acc for optim= 0.18406448027493097\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.00526539608836174\n",
      "Loss on test= 0.0074593909084796906\n",
      "acc for Lsat= 0.14176444090101495 \n",
      "acc for Psat= 0.1944029281003645 \n",
      "acc for optim= 0.18581658213649357\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.005307980813086033\n",
      "Loss on test= 0.007222249172627926\n",
      "acc for Lsat= 0.13976090040561728 \n",
      "acc for Psat= 0.18811870772291156 \n",
      "acc for optim= 0.18681267420837624\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005404158495366573\n",
      "Loss on test= 0.007401382550597191\n",
      "acc for Lsat= 0.1353845942847299 \n",
      "acc for Psat= 0.19140919457081434 \n",
      "acc for optim= 0.1853315986881842\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.005073176231235266\n",
      "Loss on test= 0.007424609269946814\n",
      "acc for Lsat= 0.15656408320870976 \n",
      "acc for Psat= 0.1856016546922457 \n",
      "acc for optim= 0.18229171248519274\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.005440497305244207\n",
      "Loss on test= 0.007172947283834219\n",
      "acc for Lsat= 0.15464408177869074 \n",
      "acc for Psat= 0.17966428332357118 \n",
      "acc for optim= 0.19040358680401562\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005200316663831472\n",
      "Loss on test= 0.007815013639628887\n",
      "acc for Lsat= 0.15061322467546664 \n",
      "acc for Psat= 0.18651823978618237 \n",
      "acc for optim= 0.1891338499096894\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005426631309092045\n",
      "Loss on test= 0.007444740738719702\n",
      "acc for Lsat= 0.14521619036305147 \n",
      "acc for Psat= 0.18037285428288102 \n",
      "acc for optim= 0.19011465307767886\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.00534718157723546\n",
      "Loss on test= 0.007383787538856268\n",
      "acc for Lsat= 0.14585026266954107 \n",
      "acc for Psat= 0.18507816904314153 \n",
      "acc for optim= 0.18659406322337016\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.005294731818139553\n",
      "Loss on test= 0.007455486338585615\n",
      "acc for Lsat= 0.14208813437979217 \n",
      "acc for Psat= 0.18459912072342333 \n",
      "acc for optim= 0.18523740619382836\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.005104393698275089\n",
      "Loss on test= 0.007322797551751137\n",
      "acc for Lsat= 0.14116856239585313 \n",
      "acc for Psat= 0.18839238442778283 \n",
      "acc for optim= 0.17667706999908675\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.005561501253396273\n",
      "Loss on test= 0.007222303654998541\n",
      "acc for Lsat= 0.14647809721483682 \n",
      "acc for Psat= 0.18129246832925033 \n",
      "acc for optim= 0.18648178574235988\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.005222340114414692\n",
      "Loss on test= 0.007042672019451857\n",
      "acc for Lsat= 0.14198984088200586 \n",
      "acc for Psat= 0.18382650864545302 \n",
      "acc for optim= 0.17989147393239022\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005272235255688429\n",
      "Loss on test= 0.007357876282185316\n",
      "acc for Lsat= 0.14253137240695174 \n",
      "acc for Psat= 0.19150423045550688 \n",
      "acc for optim= 0.18480645782131985\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.005299947690218687\n",
      "Loss on test= 0.007136618718504906\n",
      "acc for Lsat= 0.15866813040414796 \n",
      "acc for Psat= 0.19456500564091153 \n",
      "acc for optim= 0.188772891975174\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.0050216554664075375\n",
      "Loss on test= 0.006968609057366848\n",
      "acc for Lsat= 0.14394087132207714 \n",
      "acc for Psat= 0.18631649911785345 \n",
      "acc for optim= 0.17844715929345883\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.005165371112525463\n",
      "Loss on test= 0.007377109490334988\n",
      "acc for Lsat= 0.14777512408861676 \n",
      "acc for Psat= 0.19389793695462104 \n",
      "acc for optim= 0.18161980816445572\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.005191443953663111\n",
      "Loss on test= 0.006847627926617861\n",
      "acc for Lsat= 0.14512842439738155 \n",
      "acc for Psat= 0.1798570391809812 \n",
      "acc for optim= 0.18218566003669678\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.0053774518892169\n",
      "Loss on test= 0.007276044227182865\n",
      "acc for Lsat= 0.13990257212483767 \n",
      "acc for Psat= 0.18627995886824658 \n",
      "acc for optim= 0.18157313542486336\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.005039785522967577\n",
      "Loss on test= 0.007510952185839415\n",
      "acc for Lsat= 0.14438986667454792 \n",
      "acc for Psat= 0.19047996410832846 \n",
      "acc for optim= 0.18797740313924896\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.005201506428420544\n",
      "Loss on test= 0.007609779480844736\n",
      "acc for Lsat= 0.1465772727821175 \n",
      "acc for Psat= 0.19061048633025837 \n",
      "acc for optim= 0.18074899224195148\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.005253489129245281\n",
      "Loss on test= 0.007513470947742462\n",
      "acc for Lsat= 0.13802091909026665 \n",
      "acc for Psat= 0.18757972282438146 \n",
      "acc for optim= 0.19079580285231446\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.005161340348422527\n",
      "Loss on test= 0.0075132111087441444\n",
      "acc for Lsat= 0.14356989037879117 \n",
      "acc for Psat= 0.17906430580073082 \n",
      "acc for optim= 0.1865721195310232\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.005131299141794443\n",
      "Loss on test= 0.007316787727177143\n",
      "acc for Lsat= 0.14324258256762776 \n",
      "acc for Psat= 0.18319274866724478 \n",
      "acc for optim= 0.1824899584213348\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.0052216011099517345\n",
      "Loss on test= 0.007569991517812014\n",
      "acc for Lsat= 0.14394313816160545 \n",
      "acc for Psat= 0.17610765136434833 \n",
      "acc for optim= 0.17507451226301185\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.004943612962961197\n",
      "Loss on test= 0.007243284024298191\n",
      "acc for Lsat= 0.14771940180646317 \n",
      "acc for Psat= 0.1878148319854279 \n",
      "acc for optim= 0.1813596733861038\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.005244733765721321\n",
      "Loss on test= 0.007355791516602039\n",
      "acc for Lsat= 0.14883568381794515 \n",
      "acc for Psat= 0.17957441135410784 \n",
      "acc for optim= 0.18040166028009988\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.005275769624859095\n",
      "Loss on test= 0.007290982641279697\n",
      "acc for Lsat= 0.15381703318392984 \n",
      "acc for Psat= 0.21116492950259869 \n",
      "acc for optim= 0.18241587205328139\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.005166849587112665\n",
      "Loss on test= 0.007469094358384609\n",
      "acc for Lsat= 0.14156543589311607 \n",
      "acc for Psat= 0.1867286510869086 \n",
      "acc for optim= 0.18498808566908367\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005359594244509935\n",
      "Loss on test= 0.007081794552505016\n",
      "acc for Lsat= 0.15221144562371489 \n",
      "acc for Psat= 0.19569758901002313 \n",
      "acc for optim= 0.1916750494829669\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.005345345474779606\n",
      "Loss on test= 0.007415166590362787\n",
      "acc for Lsat= 0.1341770480924141 \n",
      "acc for Psat= 0.18876612616596042 \n",
      "acc for optim= 0.18876774842835597\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.0050539616495370865\n",
      "Loss on test= 0.0072828857228159904\n",
      "acc for Lsat= 0.1452385543454362 \n",
      "acc for Psat= 0.18176646141991873 \n",
      "acc for optim= 0.18205166980528775\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.004913710989058018\n",
      "Loss on test= 0.007572872098535299\n",
      "acc for Lsat= 0.15721517332875337 \n",
      "acc for Psat= 0.19411064585266238 \n",
      "acc for optim= 0.1817402745902416\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.005211242474615574\n",
      "Loss on test= 0.007293973118066788\n",
      "acc for Lsat= 0.14349941187824475 \n",
      "acc for Psat= 0.18946222012851113 \n",
      "acc for optim= 0.18207967289564578\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.005296749994158745\n",
      "Loss on test= 0.007326827384531498\n",
      "acc for Lsat= 0.14515746655085765 \n",
      "acc for Psat= 0.1896666598941398 \n",
      "acc for optim= 0.1844365004850857\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.005214681848883629\n",
      "Loss on test= 0.006961079780012369\n",
      "acc for Lsat= 0.14434666143592875 \n",
      "acc for Psat= 0.2008467628182099 \n",
      "acc for optim= 0.18157190024398542\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.005281110294163227\n",
      "Loss on test= 0.007481563836336136\n",
      "acc for Lsat= 0.1451227663789082 \n",
      "acc for Psat= 0.19174645870359094 \n",
      "acc for optim= 0.18214634246045922\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.005142095498740673\n",
      "Loss on test= 0.00758076086640358\n",
      "acc for Lsat= 0.13795758052409404 \n",
      "acc for Psat= 0.19575100995315864 \n",
      "acc for optim= 0.18678228817379186\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.005582395009696484\n",
      "Loss on test= 0.007442130241543055\n",
      "acc for Lsat= 0.139203329381178 \n",
      "acc for Psat= 0.17304796689527766 \n",
      "acc for optim= 0.1883882267028475\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.005334922112524509\n",
      "Loss on test= 0.007450120057910681\n",
      "acc for Lsat= 0.14944513633060122 \n",
      "acc for Psat= 0.18456667327879334 \n",
      "acc for optim= 0.18154245530461252\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.005140785593539476\n",
      "Loss on test= 0.0076105850748717785\n",
      "acc for Lsat= 0.15182045451766185 \n",
      "acc for Psat= 0.1833340435359936 \n",
      "acc for optim= 0.1867701761712717\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.00508723733946681\n",
      "Loss on test= 0.007304683327674866\n",
      "acc for Lsat= 0.15591048774973595 \n",
      "acc for Psat= 0.20511511750595612 \n",
      "acc for optim= 0.1922435180049344\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.005386522971093655\n",
      "Loss on test= 0.0076108877547085285\n",
      "acc for Lsat= 0.14755890252618273 \n",
      "acc for Psat= 0.19911414023152874 \n",
      "acc for optim= 0.18098203205087482\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.005228737369179726\n",
      "Loss on test= 0.007506235968321562\n",
      "acc for Lsat= 0.13997527973375237 \n",
      "acc for Psat= 0.1834871223204021 \n",
      "acc for optim= 0.18336416399201805\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.005236630327999592\n",
      "Loss on test= 0.007249115500599146\n",
      "acc for Lsat= 0.14229222122659968 \n",
      "acc for Psat= 0.19507727572144787 \n",
      "acc for optim= 0.18731279408876006\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.0050486009567976\n",
      "Loss on test= 0.0072022234089672565\n",
      "acc for Lsat= 0.1445449079250436 \n",
      "acc for Psat= 0.1925428026819556 \n",
      "acc for optim= 0.18917410837955864\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.005277084652334452\n",
      "Loss on test= 0.007254158146679401\n",
      "acc for Lsat= 0.14184668471132114 \n",
      "acc for Psat= 0.1983152798609808 \n",
      "acc for optim= 0.18349853516794878\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.005421337205916643\n",
      "Loss on test= 0.007547309622168541\n",
      "acc for Lsat= 0.14401737044901267 \n",
      "acc for Psat= 0.19080261777529156 \n",
      "acc for optim= 0.19000899264546967\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.00538856303319335\n",
      "Loss on test= 0.00763908913359046\n",
      "acc for Lsat= 0.1576691637213489 \n",
      "acc for Psat= 0.17904006978420572 \n",
      "acc for optim= 0.18059065934637042\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.005275646690279245\n",
      "Loss on test= 0.007480727043002844\n",
      "acc for Lsat= 0.13813178420847388 \n",
      "acc for Psat= 0.18418125583900932 \n",
      "acc for optim= 0.18150666006015362\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.005299360956996679\n",
      "Loss on test= 0.007578894961625338\n",
      "acc for Lsat= 0.14785983821398152 \n",
      "acc for Psat= 0.19053194895672962 \n",
      "acc for optim= 0.1823212316213939\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005199785344302654\n",
      "Loss on test= 0.007425681687891483\n",
      "acc for Lsat= 0.14354603952579353 \n",
      "acc for Psat= 0.20038928546652687 \n",
      "acc for optim= 0.1848818836606817\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.005533437244594097\n",
      "Loss on test= 0.007027288433164358\n",
      "acc for Lsat= 0.15491015764022986 \n",
      "acc for Psat= 0.18953637500784024 \n",
      "acc for optim= 0.17602465965739283\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.0052725630812346935\n",
      "Loss on test= 0.0073584867641329765\n",
      "acc for Lsat= 0.1461392180379633 \n",
      "acc for Psat= 0.1852966307851364 \n",
      "acc for optim= 0.18722197182866143\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.005357316229492426\n",
      "Loss on test= 0.0076440381817519665\n",
      "acc for Lsat= 0.14680294560652715 \n",
      "acc for Psat= 0.18873291231126937 \n",
      "acc for optim= 0.17527150635633304\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.0051880176179111\n",
      "Loss on test= 0.0072754682041704655\n",
      "acc for Lsat= 0.1527314824691962 \n",
      "acc for Psat= 0.20066992751891405 \n",
      "acc for optim= 0.1849332301941372\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.0054529523476958275\n",
      "Loss on test= 0.006875650957226753\n",
      "acc for Lsat= 0.14611326319561055 \n",
      "acc for Psat= 0.19921765947589445 \n",
      "acc for optim= 0.19105689891258093\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.005051376763731241\n",
      "Loss on test= 0.007508305832743645\n",
      "acc for Lsat= 0.1463916894937789 \n",
      "acc for Psat= 0.1795337308438678 \n",
      "acc for optim= 0.18659463981614968\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.004989972338080406\n",
      "Loss on test= 0.006907975301146507\n",
      "acc for Lsat= 0.1459864856627556 \n",
      "acc for Psat= 0.18288983749912777 \n",
      "acc for optim= 0.1831484863834196\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.005396182183176279\n",
      "Loss on test= 0.0076095908880233765\n",
      "acc for Lsat= 0.14332317033101286 \n",
      "acc for Psat= 0.18865884465745605 \n",
      "acc for optim= 0.1951915895505274\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.005135933868587017\n",
      "Loss on test= 0.007070691324770451\n",
      "acc for Lsat= 0.13820549843214514 \n",
      "acc for Psat= 0.18392692688073903 \n",
      "acc for optim= 0.1811216432246242\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.005865870974957943\n",
      "Loss on test= 0.0071237096562981606\n",
      "acc for Lsat= 0.1462020508649179 \n",
      "acc for Psat= 0.19781001554115019 \n",
      "acc for optim= 0.18499074177055516\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.004989253357052803\n",
      "Loss on test= 0.007852844893932343\n",
      "acc for Lsat= 0.14103710400379552 \n",
      "acc for Psat= 0.195894120599262 \n",
      "acc for optim= 0.18404774528357476\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.005259004887193441\n",
      "Loss on test= 0.007678190711885691\n",
      "acc for Lsat= 0.1437697144328296 \n",
      "acc for Psat= 0.1959820439937891 \n",
      "acc for optim= 0.18645175598412905\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005128307733684778\n",
      "Loss on test= 0.007213253062218428\n",
      "acc for Lsat= 0.1427049405513318 \n",
      "acc for Psat= 0.1840449048794012 \n",
      "acc for optim= 0.19658316474896473\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005596315488219261\n",
      "Loss on test= 0.0073785376735031605\n",
      "acc for Lsat= 0.14403290279862302 \n",
      "acc for Psat= 0.19172536746682753 \n",
      "acc for optim= 0.17667939124598367\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.00522718857973814\n",
      "Loss on test= 0.007977064698934555\n",
      "acc for Lsat= 0.1346187626942038 \n",
      "acc for Psat= 0.18803277919832312 \n",
      "acc for optim= 0.1911343093938576\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.005320291500538588\n",
      "Loss on test= 0.007026326842606068\n",
      "acc for Lsat= 0.14910402285072524 \n",
      "acc for Psat= 0.17819277411498527 \n",
      "acc for optim= 0.17141735200144229\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.00514462124556303\n",
      "Loss on test= 0.00697331503033638\n",
      "acc for Lsat= 0.14110074046174767 \n",
      "acc for Psat= 0.17254115663827627 \n",
      "acc for optim= 0.1790694409968965\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.005159680265933275\n",
      "Loss on test= 0.007221975363790989\n",
      "acc for Lsat= 0.1437958994332117 \n",
      "acc for Psat= 0.19922917657201397 \n",
      "acc for optim= 0.18275017414916428\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.005391090176999569\n",
      "Loss on test= 0.007520708721131086\n",
      "acc for Lsat= 0.1434977539782565 \n",
      "acc for Psat= 0.19284724610629606 \n",
      "acc for optim= 0.18694482925834638\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.005202236585319042\n",
      "Loss on test= 0.007617217022925615\n",
      "acc for Lsat= 0.14748104551642918 \n",
      "acc for Psat= 0.20424134748506925 \n",
      "acc for optim= 0.18770106631506722\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.005168401636183262\n",
      "Loss on test= 0.007857702672481537\n",
      "acc for Lsat= 0.14820567935659382 \n",
      "acc for Psat= 0.17957805627174522 \n",
      "acc for optim= 0.185065300390506\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.005449715070426464\n",
      "Loss on test= 0.007423221133649349\n",
      "acc for Lsat= 0.14598670655224075 \n",
      "acc for Psat= 0.19465825054040714 \n",
      "acc for optim= 0.18082297223956004\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005312248598784208\n",
      "Loss on test= 0.007439454086124897\n",
      "acc for Lsat= 0.15151682501166416 \n",
      "acc for Psat= 0.1835037801030176 \n",
      "acc for optim= 0.18683776028829313\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.005186975933611393\n",
      "Loss on test= 0.006921472493559122\n",
      "acc for Lsat= 0.1428329978967429 \n",
      "acc for Psat= 0.1742141114058809 \n",
      "acc for optim= 0.18178369860359483\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.00540817528963089\n",
      "Loss on test= 0.007221645675599575\n",
      "acc for Lsat= 0.13512776471487414 \n",
      "acc for Psat= 0.18318593770181607 \n",
      "acc for optim= 0.19338414322558148\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.00535124447196722\n",
      "Loss on test= 0.007341659162193537\n",
      "acc for Lsat= 0.143076619394906 \n",
      "acc for Psat= 0.18916975435052738 \n",
      "acc for optim= 0.18336668070424805\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.005084084812551737\n",
      "Loss on test= 0.007550905458629131\n",
      "acc for Lsat= 0.1418561403234785 \n",
      "acc for Psat= 0.19722627236691043 \n",
      "acc for optim= 0.19094467836604634\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.0052075255662202835\n",
      "Loss on test= 0.0072340103797614574\n",
      "acc for Lsat= 0.13219588563250775 \n",
      "acc for Psat= 0.19805098873731053 \n",
      "acc for optim= 0.18113186279632396\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.005159903317689896\n",
      "Loss on test= 0.0072675710543990135\n",
      "acc for Lsat= 0.14577861354909608 \n",
      "acc for Psat= 0.18633303511582436 \n",
      "acc for optim= 0.18136657811014256\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.0051613859832286835\n",
      "Loss on test= 0.007407677825540304\n",
      "acc for Lsat= 0.1572738832552711 \n",
      "acc for Psat= 0.18382690280645353 \n",
      "acc for optim= 0.1820734849972574\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.005245932377874851\n",
      "Loss on test= 0.007184178568422794\n",
      "acc for Lsat= 0.14217741427805702 \n",
      "acc for Psat= 0.18185640514795343 \n",
      "acc for optim= 0.1798440554851979\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.005318860989063978\n",
      "Loss on test= 0.007453421130776405\n",
      "acc for Lsat= 0.1436825850707494 \n",
      "acc for Psat= 0.18343546519162834 \n",
      "acc for optim= 0.18684869841252622\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.005249085370451212\n",
      "Loss on test= 0.007092694751918316\n",
      "acc for Lsat= 0.1365251396909131 \n",
      "acc for Psat= 0.1903097406675711 \n",
      "acc for optim= 0.18533224537033496\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.005261455196887255\n",
      "Loss on test= 0.007106435485184193\n",
      "acc for Lsat= 0.15072639312511157 \n",
      "acc for Psat= 0.2019478482212375 \n",
      "acc for optim= 0.18219656905986667\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.005360812414437532\n",
      "Loss on test= 0.007385352626442909\n",
      "acc for Lsat= 0.1590519129237557 \n",
      "acc for Psat= 0.1907373828454407 \n",
      "acc for optim= 0.18446787117296243\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.00543323066085577\n",
      "Loss on test= 0.007346906699240208\n",
      "acc for Lsat= 0.1479906249209307 \n",
      "acc for Psat= 0.18965233884614388 \n",
      "acc for optim= 0.1867846866179788\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.005140510853379965\n",
      "Loss on test= 0.007367445155978203\n",
      "acc for Lsat= 0.15464327291110302 \n",
      "acc for Psat= 0.18439719715751096 \n",
      "acc for optim= 0.1926429580729865\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.005144626367837191\n",
      "Loss on test= 0.007849746383726597\n",
      "acc for Lsat= 0.14594283832473773 \n",
      "acc for Psat= 0.18647223213271497 \n",
      "acc for optim= 0.18775548244584123\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.0052528390660882\n",
      "Loss on test= 0.0072487895376980305\n",
      "acc for Lsat= 0.1415929135694703 \n",
      "acc for Psat= 0.19154084912142488 \n",
      "acc for optim= 0.18777467101033715\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.005538825877010822\n",
      "Loss on test= 0.007143065799027681\n",
      "acc for Lsat= 0.1456169723529277 \n",
      "acc for Psat= 0.20361937032732205 \n",
      "acc for optim= 0.18233149918177943\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.00553347310051322\n",
      "Loss on test= 0.007425021380186081\n",
      "acc for Lsat= 0.1419362173898558 \n",
      "acc for Psat= 0.18314633846328762 \n",
      "acc for optim= 0.18914961789917872\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.005391078069806099\n",
      "Loss on test= 0.0071030547842383385\n",
      "acc for Lsat= 0.15057752942513736 \n",
      "acc for Psat= 0.18746006063235252 \n",
      "acc for optim= 0.17967176860070513\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.005167563445866108\n",
      "Loss on test= 0.007467395160347223\n",
      "acc for Lsat= 0.14053133660765196 \n",
      "acc for Psat= 0.18022299430239563 \n",
      "acc for optim= 0.19033304007044521\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.005168677307665348\n",
      "Loss on test= 0.007433203514665365\n",
      "acc for Lsat= 0.14235345362113086 \n",
      "acc for Psat= 0.19482853638349848 \n",
      "acc for optim= 0.1873926389090274\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.005168808624148369\n",
      "Loss on test= 0.007574126124382019\n",
      "acc for Lsat= 0.14522774526066926 \n",
      "acc for Psat= 0.19514172644216995 \n",
      "acc for optim= 0.18364106863508092\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.005031181033700705\n",
      "Loss on test= 0.007031485438346863\n",
      "acc for Lsat= 0.1426326627360364 \n",
      "acc for Psat= 0.17925599112087617 \n",
      "acc for optim= 0.1836778358525795\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.005338932387530804\n",
      "Loss on test= 0.007205783389508724\n",
      "acc for Lsat= 0.13390891265589744 \n",
      "acc for Psat= 0.18851730444346418 \n",
      "acc for optim= 0.1875941976725475\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005122935399413109\n",
      "Loss on test= 0.0072310869581997395\n",
      "acc for Lsat= 0.13837384641414782 \n",
      "acc for Psat= 0.19554389343276377 \n",
      "acc for optim= 0.18514007083337122\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.005023493897169828\n",
      "Loss on test= 0.007425977382808924\n",
      "acc for Lsat= 0.15049213979550213 \n",
      "acc for Psat= 0.19463300835379385 \n",
      "acc for optim= 0.1891056972040535\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.005146147683262825\n",
      "Loss on test= 0.00747264176607132\n",
      "acc for Lsat= 0.14993010803476953 \n",
      "acc for Psat= 0.20885445420548213 \n",
      "acc for optim= 0.18694594468116058\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.004920003470033407\n",
      "Loss on test= 0.007420626003295183\n",
      "acc for Lsat= 0.13571725558865524 \n",
      "acc for Psat= 0.20124829984995246 \n",
      "acc for optim= 0.18565876784168572\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.005079147405922413\n",
      "Loss on test= 0.007290783803910017\n",
      "acc for Lsat= 0.1523430292877239 \n",
      "acc for Psat= 0.18609927911368643 \n",
      "acc for optim= 0.18616430588752664\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.0056206644512712955\n",
      "Loss on test= 0.006995835807174444\n",
      "acc for Lsat= 0.13625864028982193 \n",
      "acc for Psat= 0.16553234803179265 \n",
      "acc for optim= 0.18343375683342275\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.005214357748627663\n",
      "Loss on test= 0.007460018619894981\n",
      "acc for Lsat= 0.14900369525049265 \n",
      "acc for Psat= 0.19172422699305824 \n",
      "acc for optim= 0.19497997609814477\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.005722688511013985\n",
      "Loss on test= 0.0076719289645552635\n",
      "acc for Lsat= 0.14715872928614682 \n",
      "acc for Psat= 0.18353958055873204 \n",
      "acc for optim= 0.18077390435038204\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.005086112301796675\n",
      "Loss on test= 0.0071359178982675076\n",
      "acc for Lsat= 0.16051010897404086 \n",
      "acc for Psat= 0.19354744813649258 \n",
      "acc for optim= 0.18505532892085\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.005230157636106014\n",
      "Loss on test= 0.007291643880307674\n",
      "acc for Lsat= 0.13087490740171098 \n",
      "acc for Psat= 0.18116948996578938 \n",
      "acc for optim= 0.18250868699711853\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.00526021933183074\n",
      "Loss on test= 0.007454507984220982\n",
      "acc for Lsat= 0.14307667834571655 \n",
      "acc for Psat= 0.18873025529204915 \n",
      "acc for optim= 0.18721757298168443\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.005054469220340252\n",
      "Loss on test= 0.007016859017312527\n",
      "acc for Lsat= 0.137102552169369 \n",
      "acc for Psat= 0.18248057141270274 \n",
      "acc for optim= 0.17759256654148958\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.005102706141769886\n",
      "Loss on test= 0.007300481665879488\n",
      "acc for Lsat= 0.15230328196442122 \n",
      "acc for Psat= 0.1900911150118489 \n",
      "acc for optim= 0.18129444113001228\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.005185373593121767\n",
      "Loss on test= 0.007580927573144436\n",
      "acc for Lsat= 0.15379977207554535 \n",
      "acc for Psat= 0.1894901650311873 \n",
      "acc for optim= 0.18542035402595083\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005327445454895496\n",
      "Loss on test= 0.00688265822827816\n",
      "acc for Lsat= 0.14755403945741594 \n",
      "acc for Psat= 0.18644688057820083 \n",
      "acc for optim= 0.1835592387566633\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.005290719214826822\n",
      "Loss on test= 0.007499727886170149\n",
      "acc for Lsat= 0.1440972448521309 \n",
      "acc for Psat= 0.19564819125931893 \n",
      "acc for optim= 0.18991492642700428\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.0051085492596030235\n",
      "Loss on test= 0.007698358502238989\n",
      "acc for Lsat= 0.16025782317365903 \n",
      "acc for Psat= 0.19500944655900057 \n",
      "acc for optim= 0.18574322738921362\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.005633610766381025\n",
      "Loss on test= 0.007378464099019766\n",
      "acc for Lsat= 0.13428846839548195 \n",
      "acc for Psat= 0.18311391429528098 \n",
      "acc for optim= 0.19135731830601352\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.005093023646622896\n",
      "Loss on test= 0.007100854068994522\n",
      "acc for Lsat= 0.13924319586281467 \n",
      "acc for Psat= 0.18869967302727345 \n",
      "acc for optim= 0.17833589494102406\n",
      "Fold 4\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.15473712980747223\n",
      "Loss on test= 0.08144979923963547\n",
      "acc for Lsat= 0.5267642060164973 \n",
      "acc for Psat= 1.566355790077617 \n",
      "acc for optim= 0.307882842747423\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.05498557165265083\n",
      "Loss on test= 0.04666735604405403\n",
      "acc for Lsat= 1.017900253853715 \n",
      "acc for Psat= 0.7240272645304193 \n",
      "acc for optim= 0.3037559407417754\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.034458208829164505\n",
      "Loss on test= 0.02846135012805462\n",
      "acc for Lsat= 0.3911279174644256 \n",
      "acc for Psat= 0.6729259942921612 \n",
      "acc for optim= 0.23376120524218527\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.028793159872293472\n",
      "Loss on test= 0.02533417008817196\n",
      "acc for Lsat= 0.4614326423537902 \n",
      "acc for Psat= 0.5374062795650031 \n",
      "acc for optim= 0.21154325060454793\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.025719795376062393\n",
      "Loss on test= 0.02379886992275715\n",
      "acc for Lsat= 0.4226189694670792 \n",
      "acc for Psat= 0.5735370656780776 \n",
      "acc for optim= 0.2126486793946719\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.024261271581053734\n",
      "Loss on test= 0.025771131739020348\n",
      "acc for Lsat= 0.48249957815364203 \n",
      "acc for Psat= 0.5615763652321623 \n",
      "acc for optim= 0.21654800664973217\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.02561071887612343\n",
      "Loss on test= 0.031077006831765175\n",
      "acc for Lsat= 0.5908389207666557 \n",
      "acc for Psat= 0.47148679113320885 \n",
      "acc for optim= 0.19990029072095106\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.025015737861394882\n",
      "Loss on test= 0.024397751316428185\n",
      "acc for Lsat= 0.4097627188273721 \n",
      "acc for Psat= 0.5618070190833484 \n",
      "acc for optim= 0.22285719781495691\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.02164107747375965\n",
      "Loss on test= 0.022747742012143135\n",
      "acc for Lsat= 0.34625182285920153 \n",
      "acc for Psat= 0.5219139016477666 \n",
      "acc for optim= 0.2189866850827606\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.02040153741836548\n",
      "Loss on test= 0.022962048649787903\n",
      "acc for Lsat= 0.3433789959532346 \n",
      "acc for Psat= 0.6049051281064749 \n",
      "acc for optim= 0.21757876454245634\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.02041403390467167\n",
      "Loss on test= 0.02481069229543209\n",
      "acc for Lsat= 0.5627751720771499 \n",
      "acc for Psat= 0.44502727855149593 \n",
      "acc for optim= 0.2117060505052204\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.02078389748930931\n",
      "Loss on test= 0.020353520289063454\n",
      "acc for Lsat= 0.35086215173588975 \n",
      "acc for Psat= 0.5574661470207264 \n",
      "acc for optim= 0.20145990473130473\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.019452493637800217\n",
      "Loss on test= 0.018323689699172974\n",
      "acc for Lsat= 0.367167589199714 \n",
      "acc for Psat= 0.4663517660079677 \n",
      "acc for optim= 0.21562538214550797\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.018402233719825745\n",
      "Loss on test= 0.019351903349161148\n",
      "acc for Lsat= 0.3415977696323248 \n",
      "acc for Psat= 0.5710144936738796 \n",
      "acc for optim= 0.19437882344803362\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.018435874953866005\n",
      "Loss on test= 0.022521687671542168\n",
      "acc for Lsat= 0.40846210451201215 \n",
      "acc for Psat= 0.40281530408738336 \n",
      "acc for optim= 0.18695957906215954\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.017772315070033073\n",
      "Loss on test= 0.024393856525421143\n",
      "acc for Lsat= 0.5260762778385618 \n",
      "acc for Psat= 0.39789910376468884 \n",
      "acc for optim= 0.19624545329444104\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.01874706521630287\n",
      "Loss on test= 0.017163773998618126\n",
      "acc for Lsat= 0.35883866512773893 \n",
      "acc for Psat= 0.40608440977483073 \n",
      "acc for optim= 0.18463525807801787\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.016709817573428154\n",
      "Loss on test= 0.021524056792259216\n",
      "acc for Lsat= 0.3228960571826825 \n",
      "acc for Psat= 0.6616814568738041 \n",
      "acc for optim= 0.21217794036874396\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.019351087510585785\n",
      "Loss on test= 0.023395854979753494\n",
      "acc for Lsat= 0.32487566005572155 \n",
      "acc for Psat= 0.6209746072198585 \n",
      "acc for optim= 0.1942276171836086\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.01710810884833336\n",
      "Loss on test= 0.017333859577775\n",
      "acc for Lsat= 0.28591941214540756 \n",
      "acc for Psat= 0.4349696358612387 \n",
      "acc for optim= 0.19249235465010955\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.01539318822324276\n",
      "Loss on test= 0.016569998115301132\n",
      "acc for Lsat= 0.2848661672130235 \n",
      "acc for Psat= 0.45911506126772184 \n",
      "acc for optim= 0.19775807727414535\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.015037337318062782\n",
      "Loss on test= 0.016742471605539322\n",
      "acc for Lsat= 0.40966295223706023 \n",
      "acc for Psat= 0.35652456325936877 \n",
      "acc for optim= 0.19274373673232745\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.015427052974700928\n",
      "Loss on test= 0.018170105293393135\n",
      "acc for Lsat= 0.3800346859314738 \n",
      "acc for Psat= 0.4259643653835185 \n",
      "acc for optim= 0.18870439729347946\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.013583198189735413\n",
      "Loss on test= 0.013958179391920567\n",
      "acc for Lsat= 0.2926842847613801 \n",
      "acc for Psat= 0.3600027589219027 \n",
      "acc for optim= 0.2110432917907377\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.01343091856688261\n",
      "Loss on test= 0.01673249714076519\n",
      "acc for Lsat= 0.3631453970057859 \n",
      "acc for Psat= 0.35493068202994155 \n",
      "acc for optim= 0.18627626979570897\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.014636044390499592\n",
      "Loss on test= 0.016393598169088364\n",
      "acc for Lsat= 0.3185079889064254 \n",
      "acc for Psat= 0.4273423467396346 \n",
      "acc for optim= 0.23404019826505004\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.017463790252804756\n",
      "Loss on test= 0.016361571848392487\n",
      "acc for Lsat= 0.27697863696471287 \n",
      "acc for Psat= 0.3818781004626052 \n",
      "acc for optim= 0.19287081926099223\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.015581754967570305\n",
      "Loss on test= 0.014608030207455158\n",
      "acc for Lsat= 0.31123507953130597 \n",
      "acc for Psat= 0.3794777273788254 \n",
      "acc for optim= 0.18551513626408137\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.014388824813067913\n",
      "Loss on test= 0.016147516667842865\n",
      "acc for Lsat= 0.2744684327286897 \n",
      "acc for Psat= 0.4057008978811505 \n",
      "acc for optim= 0.1835700950287588\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.014624573290348053\n",
      "Loss on test= 0.015965018421411514\n",
      "acc for Lsat= 0.27972478619013286 \n",
      "acc for Psat= 0.5328862771374693 \n",
      "acc for optim= 0.19702280758265558\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.014208845794200897\n",
      "Loss on test= 0.012888248078525066\n",
      "acc for Lsat= 0.2568709034634922 \n",
      "acc for Psat= 0.3522972369555109 \n",
      "acc for optim= 0.18847247682832427\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.013294795528054237\n",
      "Loss on test= 0.01325780525803566\n",
      "acc for Lsat= 0.2844402539181202 \n",
      "acc for Psat= 0.37232270113480675 \n",
      "acc for optim= 0.1800359974943529\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.01291930116713047\n",
      "Loss on test= 0.014110163785517216\n",
      "acc for Lsat= 0.3856857173641014 \n",
      "acc for Psat= 0.35544152100872034 \n",
      "acc for optim= 0.1844271469273467\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.016201507300138474\n",
      "Loss on test= 0.015347711741924286\n",
      "acc for Lsat= 0.32548645796553904 \n",
      "acc for Psat= 0.4546337260855133 \n",
      "acc for optim= 0.1931777151568686\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.014833560213446617\n",
      "Loss on test= 0.01542341522872448\n",
      "acc for Lsat= 0.30656615516946645 \n",
      "acc for Psat= 0.33942691299942185 \n",
      "acc for optim= 0.18493070275614373\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.013746130280196667\n",
      "Loss on test= 0.014067340642213821\n",
      "acc for Lsat= 0.2797377260146113 \n",
      "acc for Psat= 0.3981113305021474 \n",
      "acc for optim= 0.18348725300032234\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.01273522712290287\n",
      "Loss on test= 0.013338192366063595\n",
      "acc for Lsat= 0.23648635582677777 \n",
      "acc for Psat= 0.4521923294504646 \n",
      "acc for optim= 0.17984935114633474\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.011823677457869053\n",
      "Loss on test= 0.012811709195375443\n",
      "acc for Lsat= 0.23938963318732184 \n",
      "acc for Psat= 0.3548552239641975 \n",
      "acc for optim= 0.20118488663550826\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.01228397898375988\n",
      "Loss on test= 0.011955181136727333\n",
      "acc for Lsat= 0.24866351714833893 \n",
      "acc for Psat= 0.3025955640573482 \n",
      "acc for optim= 0.17947950738741728\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.011256318539381027\n",
      "Loss on test= 0.012792984023690224\n",
      "acc for Lsat= 0.2821245200595185 \n",
      "acc for Psat= 0.30108357550667936 \n",
      "acc for optim= 0.1786035541983199\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.011996726505458355\n",
      "Loss on test= 0.011952088214457035\n",
      "acc for Lsat= 0.2278200607258277 \n",
      "acc for Psat= 0.36307494573631005 \n",
      "acc for optim= 0.17800297643225946\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.011582457460463047\n",
      "Loss on test= 0.014655997976660728\n",
      "acc for Lsat= 0.279416615510222 \n",
      "acc for Psat= 0.38236397700193414 \n",
      "acc for optim= 0.18715802116021932\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.012749490328133106\n",
      "Loss on test= 0.012672406621277332\n",
      "acc for Lsat= 0.22709733052331893 \n",
      "acc for Psat= 0.4034688743054638 \n",
      "acc for optim= 0.17727535608583359\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.011037847027182579\n",
      "Loss on test= 0.012177283875644207\n",
      "acc for Lsat= 0.2297305502291372 \n",
      "acc for Psat= 0.3388941088805861 \n",
      "acc for optim= 0.17609317646377154\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.011476414278149605\n",
      "Loss on test= 0.011974629014730453\n",
      "acc for Lsat= 0.23891438733763443 \n",
      "acc for Psat= 0.3575587303705941 \n",
      "acc for optim= 0.18287478811746907\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.010656798258423805\n",
      "Loss on test= 0.012728020548820496\n",
      "acc for Lsat= 0.22607751905082699 \n",
      "acc for Psat= 0.3598675388354258 \n",
      "acc for optim= 0.1829032340686249\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.011911656707525253\n",
      "Loss on test= 0.012624429538846016\n",
      "acc for Lsat= 0.2541726976383065 \n",
      "acc for Psat= 0.3755305553038345 \n",
      "acc for optim= 0.17967119663753395\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.011382335796952248\n",
      "Loss on test= 0.011683433316648006\n",
      "acc for Lsat= 0.24804007214929175 \n",
      "acc for Psat= 0.3332479691438255 \n",
      "acc for optim= 0.18499819457170277\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.010676136240363121\n",
      "Loss on test= 0.01118004135787487\n",
      "acc for Lsat= 0.20688405458578749 \n",
      "acc for Psat= 0.32124251631454975 \n",
      "acc for optim= 0.1712206100659506\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.01074496190994978\n",
      "Loss on test= 0.010408977046608925\n",
      "acc for Lsat= 0.2387533823967163 \n",
      "acc for Psat= 0.31170448474337914 \n",
      "acc for optim= 0.17402605094976026\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.011011337861418724\n",
      "Loss on test= 0.011082369834184647\n",
      "acc for Lsat= 0.22593536753451726 \n",
      "acc for Psat= 0.331119814521197 \n",
      "acc for optim= 0.1774888359757377\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.011206626892089844\n",
      "Loss on test= 0.012964227236807346\n",
      "acc for Lsat= 0.24555603699562079 \n",
      "acc for Psat= 0.4025378853311671 \n",
      "acc for optim= 0.18360948986125744\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.010308429598808289\n",
      "Loss on test= 0.011361745186150074\n",
      "acc for Lsat= 0.2371520771698446 \n",
      "acc for Psat= 0.3470777640012322 \n",
      "acc for optim= 0.1849594259720017\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.010037395171821117\n",
      "Loss on test= 0.010929741896688938\n",
      "acc for Lsat= 0.22525192665233904 \n",
      "acc for Psat= 0.2681253831216457 \n",
      "acc for optim= 0.16537476308380453\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.009514991194009781\n",
      "Loss on test= 0.010546605102717876\n",
      "acc for Lsat= 0.21963625957256136 \n",
      "acc for Psat= 0.31679265278078556 \n",
      "acc for optim= 0.17697385091670467\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.011880130507051945\n",
      "Loss on test= 0.011529514566063881\n",
      "acc for Lsat= 0.21995113753202203 \n",
      "acc for Psat= 0.3806247457762661 \n",
      "acc for optim= 0.17742808934369841\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.011219365522265434\n",
      "Loss on test= 0.011862725019454956\n",
      "acc for Lsat= 0.24262682154286103 \n",
      "acc for Psat= 0.35160604583435373 \n",
      "acc for optim= 0.17752374369511761\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.011077459901571274\n",
      "Loss on test= 0.012032524682581425\n",
      "acc for Lsat= 0.22235678047300544 \n",
      "acc for Psat= 0.32646227832959934 \n",
      "acc for optim= 0.17482108037735594\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.01164962537586689\n",
      "Loss on test= 0.010937110520899296\n",
      "acc for Lsat= 0.2332957490569839 \n",
      "acc for Psat= 0.3021359621842018 \n",
      "acc for optim= 0.17701283154534903\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.010240374132990837\n",
      "Loss on test= 0.009915390983223915\n",
      "acc for Lsat= 0.24581617770876857 \n",
      "acc for Psat= 0.27879787771122866 \n",
      "acc for optim= 0.17548742012586444\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.010464606806635857\n",
      "Loss on test= 0.011178071610629559\n",
      "acc for Lsat= 0.19815565661420342 \n",
      "acc for Psat= 0.3135702661652744 \n",
      "acc for optim= 0.17066023172314476\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.00940642785280943\n",
      "Loss on test= 0.01029895432293415\n",
      "acc for Lsat= 0.21524108137294162 \n",
      "acc for Psat= 0.2903455092014409 \n",
      "acc for optim= 0.17387123506594465\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.010356975719332695\n",
      "Loss on test= 0.010944105684757233\n",
      "acc for Lsat= 0.20882368212886399 \n",
      "acc for Psat= 0.29180975709345236 \n",
      "acc for optim= 0.18361197223597717\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.010177291929721832\n",
      "Loss on test= 0.010953112505376339\n",
      "acc for Lsat= 0.20646732680377414 \n",
      "acc for Psat= 0.319223072810755 \n",
      "acc for optim= 0.17763108726260232\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.009311305359005928\n",
      "Loss on test= 0.010778531432151794\n",
      "acc for Lsat= 0.2086230990913941 \n",
      "acc for Psat= 0.31160431213325773 \n",
      "acc for optim= 0.17208364420125766\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.009234985336661339\n",
      "Loss on test= 0.009598635137081146\n",
      "acc for Lsat= 0.20983349715710664 \n",
      "acc for Psat= 0.27591164189726725 \n",
      "acc for optim= 0.1746584152615797\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.009080221876502037\n",
      "Loss on test= 0.00965586956590414\n",
      "acc for Lsat= 0.20309573854472426 \n",
      "acc for Psat= 0.2640377620257987 \n",
      "acc for optim= 0.18035059064377643\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.009154817089438438\n",
      "Loss on test= 0.010715208016335964\n",
      "acc for Lsat= 0.24583441036730455 \n",
      "acc for Psat= 0.2520313183319007 \n",
      "acc for optim= 0.17762170416650316\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.010407105088233948\n",
      "Loss on test= 0.011430460959672928\n",
      "acc for Lsat= 0.27110270954578825 \n",
      "acc for Psat= 0.27983672610468796 \n",
      "acc for optim= 0.1774494872527716\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.010842246934771538\n",
      "Loss on test= 0.012080041691660881\n",
      "acc for Lsat= 0.24930665452094353 \n",
      "acc for Psat= 0.3915533783303604 \n",
      "acc for optim= 0.1641911196974717\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.010744484141469002\n",
      "Loss on test= 0.011133543215692043\n",
      "acc for Lsat= 0.2099806465521516 \n",
      "acc for Psat= 0.3118757281935255 \n",
      "acc for optim= 0.17660940533759623\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.012082298286259174\n",
      "Loss on test= 0.012021454982459545\n",
      "acc for Lsat= 0.26099430586318256 \n",
      "acc for Psat= 0.3179829032706158 \n",
      "acc for optim= 0.16446351584764657\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.010060714557766914\n",
      "Loss on test= 0.010081647895276546\n",
      "acc for Lsat= 0.20971661404645467 \n",
      "acc for Psat= 0.2925345719024753 \n",
      "acc for optim= 0.1728630258383508\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.00945626012980938\n",
      "Loss on test= 0.009972279891371727\n",
      "acc for Lsat= 0.21811324715705924 \n",
      "acc for Psat= 0.3164323347206533 \n",
      "acc for optim= 0.16544402205140987\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.009050956927239895\n",
      "Loss on test= 0.010207077488303185\n",
      "acc for Lsat= 0.2410069915450743 \n",
      "acc for Psat= 0.2651302146458174 \n",
      "acc for optim= 0.16923214739191414\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.009311738424003124\n",
      "Loss on test= 0.009835097938776016\n",
      "acc for Lsat= 0.217967383794727 \n",
      "acc for Psat= 0.2782211667241635 \n",
      "acc for optim= 0.17069285214885715\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.009095477871596813\n",
      "Loss on test= 0.010037971660494804\n",
      "acc for Lsat= 0.19798439440076987 \n",
      "acc for Psat= 0.3437782227813617 \n",
      "acc for optim= 0.1705974719769581\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.008823320269584656\n",
      "Loss on test= 0.009232313372194767\n",
      "acc for Lsat= 0.2180609472229319 \n",
      "acc for Psat= 0.2673142632324493 \n",
      "acc for optim= 0.16822000706995852\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.009758878499269485\n",
      "Loss on test= 0.010721474885940552\n",
      "acc for Lsat= 0.23418390821726595 \n",
      "acc for Psat= 0.2370811982759748 \n",
      "acc for optim= 0.1605385619341625\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.010452387854456902\n",
      "Loss on test= 0.010600296780467033\n",
      "acc for Lsat= 0.26820569615543927 \n",
      "acc for Psat= 0.2755345436559272 \n",
      "acc for optim= 0.16816509348611333\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.009195303544402122\n",
      "Loss on test= 0.009314880706369877\n",
      "acc for Lsat= 0.21585352938416125 \n",
      "acc for Psat= 0.25268472655696345 \n",
      "acc for optim= 0.17463503766167512\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.00919970590621233\n",
      "Loss on test= 0.010069985873997211\n",
      "acc for Lsat= 0.19811107689678406 \n",
      "acc for Psat= 0.3371862222285957 \n",
      "acc for optim= 0.16698828675043692\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.011339512653648853\n",
      "Loss on test= 0.010919792577624321\n",
      "acc for Lsat= 0.2636190530351653 \n",
      "acc for Psat= 0.25948148063559573 \n",
      "acc for optim= 0.17318193774258137\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.011429207399487495\n",
      "Loss on test= 0.011056998744606972\n",
      "acc for Lsat= 0.2164420171984334 \n",
      "acc for Psat= 0.32804428978563577 \n",
      "acc for optim= 0.18674898956364142\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.010203734040260315\n",
      "Loss on test= 0.01014235895127058\n",
      "acc for Lsat= 0.22631148386319153 \n",
      "acc for Psat= 0.2864030058449898 \n",
      "acc for optim= 0.1709642797975694\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.009305736981332302\n",
      "Loss on test= 0.009662074968218803\n",
      "acc for Lsat= 0.2168562730675044 \n",
      "acc for Psat= 0.2781594109987233 \n",
      "acc for optim= 0.17534953500158498\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.008981489576399326\n",
      "Loss on test= 0.010097372345626354\n",
      "acc for Lsat= 0.19836675314095298 \n",
      "acc for Psat= 0.28028367902762946 \n",
      "acc for optim= 0.17592353888359838\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.009885389357805252\n",
      "Loss on test= 0.010007500648498535\n",
      "acc for Lsat= 0.19844702919830615 \n",
      "acc for Psat= 0.3447258023900117 \n",
      "acc for optim= 0.1699909453097059\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.010375885292887688\n",
      "Loss on test= 0.009726591408252716\n",
      "acc for Lsat= 0.2085523027503008 \n",
      "acc for Psat= 0.2760141160505152 \n",
      "acc for optim= 0.16969914098201533\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.01048889197409153\n",
      "Loss on test= 0.009880326688289642\n",
      "acc for Lsat= 0.21912498849818146 \n",
      "acc for Psat= 0.26020774704969074 \n",
      "acc for optim= 0.16727194711871324\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.009217007085680962\n",
      "Loss on test= 0.00917721912264824\n",
      "acc for Lsat= 0.19380998691752913 \n",
      "acc for Psat= 0.2744789086473098 \n",
      "acc for optim= 0.17076035745854137\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.00878564827144146\n",
      "Loss on test= 0.010391000658273697\n",
      "acc for Lsat= 0.1880638529565405 \n",
      "acc for Psat= 0.2893912938812301 \n",
      "acc for optim= 0.16766313101168814\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.009208155795931816\n",
      "Loss on test= 0.008947964757680893\n",
      "acc for Lsat= 0.1721468608737656 \n",
      "acc for Psat= 0.2628868340484065 \n",
      "acc for optim= 0.17898541697010886\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.008828261867165565\n",
      "Loss on test= 0.0088339913636446\n",
      "acc for Lsat= 0.20364731127671998 \n",
      "acc for Psat= 0.23441268661112877 \n",
      "acc for optim= 0.16917770215554437\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.009307682514190674\n",
      "Loss on test= 0.009427481330931187\n",
      "acc for Lsat= 0.19183292841544988 \n",
      "acc for Psat= 0.2664662159269401 \n",
      "acc for optim= 0.16518497906365723\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.008390546776354313\n",
      "Loss on test= 0.009628832340240479\n",
      "acc for Lsat= 0.21442791844057835 \n",
      "acc for Psat= 0.27404149279349527 \n",
      "acc for optim= 0.17878290742538397\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.009674029424786568\n",
      "Loss on test= 0.009225363843142986\n",
      "acc for Lsat= 0.21297723263975415 \n",
      "acc for Psat= 0.23646980042828888 \n",
      "acc for optim= 0.16652863536671292\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.008162720128893852\n",
      "Loss on test= 0.008661332540214062\n",
      "acc for Lsat= 0.19883959888944355 \n",
      "acc for Psat= 0.25230313776028496 \n",
      "acc for optim= 0.16724702698506844\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.0087505541741848\n",
      "Loss on test= 0.009915919043123722\n",
      "acc for Lsat= 0.22542150933486332 \n",
      "acc for Psat= 0.2618919225043205 \n",
      "acc for optim= 0.1750201279476865\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.008738232776522636\n",
      "Loss on test= 0.0086430748924613\n",
      "acc for Lsat= 0.19317278636707239 \n",
      "acc for Psat= 0.27133003387325366 \n",
      "acc for optim= 0.17456531546414508\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.007921033538877964\n",
      "Loss on test= 0.009341845288872719\n",
      "acc for Lsat= 0.18544534729616183 \n",
      "acc for Psat= 0.2806645406871108 \n",
      "acc for optim= 0.16231928386393416\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.008082889951765537\n",
      "Loss on test= 0.008959854952991009\n",
      "acc for Lsat= 0.1885842593402991 \n",
      "acc for Psat= 0.24010601169964085 \n",
      "acc for optim= 0.16360436074951468\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.008441468700766563\n",
      "Loss on test= 0.009812030009925365\n",
      "acc for Lsat= 0.17492654176073943 \n",
      "acc for Psat= 0.27343859257210873 \n",
      "acc for optim= 0.17246594511269026\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.008307503536343575\n",
      "Loss on test= 0.009451933205127716\n",
      "acc for Lsat= 0.19275233887515764 \n",
      "acc for Psat= 0.2812144357630922 \n",
      "acc for optim= 0.1639512194373996\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.008354940451681614\n",
      "Loss on test= 0.008904404006898403\n",
      "acc for Lsat= 0.18955960580143985 \n",
      "acc for Psat= 0.23528304323992982 \n",
      "acc for optim= 0.15703666550431736\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.008067796006798744\n",
      "Loss on test= 0.0086939362809062\n",
      "acc for Lsat= 0.17714638161648552 \n",
      "acc for Psat= 0.24690561114073747 \n",
      "acc for optim= 0.166743665933609\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.007997729815542698\n",
      "Loss on test= 0.00871883425861597\n",
      "acc for Lsat= 0.20869086368551448 \n",
      "acc for Psat= 0.2514162381553687 \n",
      "acc for optim= 0.16862269199689942\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.00791839323937893\n",
      "Loss on test= 0.008341348730027676\n",
      "acc for Lsat= 0.18984872149273735 \n",
      "acc for Psat= 0.24258398814317694 \n",
      "acc for optim= 0.16639322784431584\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.007754673715680838\n",
      "Loss on test= 0.008545788004994392\n",
      "acc for Lsat= 0.1784871941825199 \n",
      "acc for Psat= 0.24552861223775954 \n",
      "acc for optim= 0.16029008673828432\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.0077804275788366795\n",
      "Loss on test= 0.010454933159053326\n",
      "acc for Lsat= 0.19030782588233705 \n",
      "acc for Psat= 0.32120875871423477 \n",
      "acc for optim= 0.17369061305195277\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.00859495997428894\n",
      "Loss on test= 0.008620575070381165\n",
      "acc for Lsat= 0.1928846288258668 \n",
      "acc for Psat= 0.25594904884661657 \n",
      "acc for optim= 0.1613186683320654\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.007732849568128586\n",
      "Loss on test= 0.008416635915637016\n",
      "acc for Lsat= 0.20213711815848032 \n",
      "acc for Psat= 0.26373016938345784 \n",
      "acc for optim= 0.1744119258712\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.00773238530382514\n",
      "Loss on test= 0.008594118990004063\n",
      "acc for Lsat= 0.18574943618086018 \n",
      "acc for Psat= 0.26445467152945756 \n",
      "acc for optim= 0.1799117032388897\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.007939253002405167\n",
      "Loss on test= 0.00849399995058775\n",
      "acc for Lsat= 0.18038148865500678 \n",
      "acc for Psat= 0.22634071872157396 \n",
      "acc for optim= 0.1645925142567559\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.00832991674542427\n",
      "Loss on test= 0.008996866643428802\n",
      "acc for Lsat= 0.22099196298513563 \n",
      "acc for Psat= 0.25962575858413073 \n",
      "acc for optim= 0.1633483574932277\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.008877189829945564\n",
      "Loss on test= 0.009058305062353611\n",
      "acc for Lsat= 0.22125956906620262 \n",
      "acc for Psat= 0.24396841529275856 \n",
      "acc for optim= 0.16736533372657236\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.00804781261831522\n",
      "Loss on test= 0.008598772808909416\n",
      "acc for Lsat= 0.21217042780252265 \n",
      "acc for Psat= 0.23573455092665113 \n",
      "acc for optim= 0.17033074314870153\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.007625013589859009\n",
      "Loss on test= 0.00909201055765152\n",
      "acc for Lsat= 0.18042461804206603 \n",
      "acc for Psat= 0.239197798526739 \n",
      "acc for optim= 0.16843564894396743\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.007620937190949917\n",
      "Loss on test= 0.008809145539999008\n",
      "acc for Lsat= 0.1967436365443511 \n",
      "acc for Psat= 0.2502496894875534 \n",
      "acc for optim= 0.16799245937498378\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.008161024190485477\n",
      "Loss on test= 0.008502883836627007\n",
      "acc for Lsat= 0.2281002956847126 \n",
      "acc for Psat= 0.21832539167075768 \n",
      "acc for optim= 0.16830927432384954\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.00837666355073452\n",
      "Loss on test= 0.008434836752712727\n",
      "acc for Lsat= 0.1869557215321664 \n",
      "acc for Psat= 0.24821242385898853 \n",
      "acc for optim= 0.16281110839307553\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.008067633956670761\n",
      "Loss on test= 0.008857578039169312\n",
      "acc for Lsat= 0.1928986646937298 \n",
      "acc for Psat= 0.23656255921910013 \n",
      "acc for optim= 0.16846364147609985\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.0076539404690265656\n",
      "Loss on test= 0.008381987921893597\n",
      "acc for Lsat= 0.20075018426277447 \n",
      "acc for Psat= 0.22692555236920225 \n",
      "acc for optim= 0.16511499580848946\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.007772682700306177\n",
      "Loss on test= 0.00879350584000349\n",
      "acc for Lsat= 0.18413632220109605 \n",
      "acc for Psat= 0.24512429950385714 \n",
      "acc for optim= 0.1710553941373679\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.0075998627580702305\n",
      "Loss on test= 0.008982478640973568\n",
      "acc for Lsat= 0.1776963717401501 \n",
      "acc for Psat= 0.2827762322347672 \n",
      "acc for optim= 0.1621577428137601\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.007810974959284067\n",
      "Loss on test= 0.008656215853989124\n",
      "acc for Lsat= 0.18089438997835042 \n",
      "acc for Psat= 0.2509058564061635 \n",
      "acc for optim= 0.16688332082379273\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.007689849939197302\n",
      "Loss on test= 0.009528101421892643\n",
      "acc for Lsat= 0.22222665951140683 \n",
      "acc for Psat= 0.24085849386155148 \n",
      "acc for optim= 0.1694505699051422\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.008418801240622997\n",
      "Loss on test= 0.00919845886528492\n",
      "acc for Lsat= 0.21398680957347216 \n",
      "acc for Psat= 0.2404299366868055 \n",
      "acc for optim= 0.16589789081261813\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.008716193959116936\n",
      "Loss on test= 0.008327577263116837\n",
      "acc for Lsat= 0.1912370001685378 \n",
      "acc for Psat= 0.21886575916041542 \n",
      "acc for optim= 0.1625937590902274\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.007301353849470615\n",
      "Loss on test= 0.008828416466712952\n",
      "acc for Lsat= 0.20561669201238966 \n",
      "acc for Psat= 0.2306474077732867 \n",
      "acc for optim= 0.16980321703280216\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.007750317454338074\n",
      "Loss on test= 0.00853138417005539\n",
      "acc for Lsat= 0.19230668278831844 \n",
      "acc for Psat= 0.2355086641273553 \n",
      "acc for optim= 0.1634132907531209\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.007207290269434452\n",
      "Loss on test= 0.008486680686473846\n",
      "acc for Lsat= 0.17227530137704472 \n",
      "acc for Psat= 0.22906181564928865 \n",
      "acc for optim= 0.16953239046098267\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.007520279381424189\n",
      "Loss on test= 0.008301702328026295\n",
      "acc for Lsat= 0.18434646640308813 \n",
      "acc for Psat= 0.23214425210245565 \n",
      "acc for optim= 0.16062009597195268\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.007918747141957283\n",
      "Loss on test= 0.008186430670320988\n",
      "acc for Lsat= 0.1958572845993808 \n",
      "acc for Psat= 0.2482019082082008 \n",
      "acc for optim= 0.16177934771458538\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.007403614930808544\n",
      "Loss on test= 0.008192585781216621\n",
      "acc for Lsat= 0.1845103381783105 \n",
      "acc for Psat= 0.21307312330253972 \n",
      "acc for optim= 0.17046009538987208\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.007811998017132282\n",
      "Loss on test= 0.0078221270814538\n",
      "acc for Lsat= 0.19384835139365456 \n",
      "acc for Psat= 0.24294007240611387 \n",
      "acc for optim= 0.16292311011118907\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.007115497253835201\n",
      "Loss on test= 0.00863197073340416\n",
      "acc for Lsat= 0.18810797246143443 \n",
      "acc for Psat= 0.2630104963566543 \n",
      "acc for optim= 0.16747102393104588\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.0077310181222856045\n",
      "Loss on test= 0.007982498966157436\n",
      "acc for Lsat= 0.170693807971576 \n",
      "acc for Psat= 0.2480853613924052 \n",
      "acc for optim= 0.16192968612857409\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.007512617856264114\n",
      "Loss on test= 0.008098759688436985\n",
      "acc for Lsat= 0.19220069358349573 \n",
      "acc for Psat= 0.24117481967044962 \n",
      "acc for optim= 0.16757894113672264\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.007580989506095648\n",
      "Loss on test= 0.008697304874658585\n",
      "acc for Lsat= 0.19374316410909667 \n",
      "acc for Psat= 0.22920783568101125 \n",
      "acc for optim= 0.1766683620385459\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.007596522569656372\n",
      "Loss on test= 0.008356311358511448\n",
      "acc for Lsat= 0.198294173675345 \n",
      "acc for Psat= 0.25062949762481157 \n",
      "acc for optim= 0.1667581491344074\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.007521938532590866\n",
      "Loss on test= 0.008933438919484615\n",
      "acc for Lsat= 0.2129566245090186 \n",
      "acc for Psat= 0.26116763418769373 \n",
      "acc for optim= 0.1635324965578458\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.0076741790398955345\n",
      "Loss on test= 0.009286807850003242\n",
      "acc for Lsat= 0.18282921865399254 \n",
      "acc for Psat= 0.24127474126404105 \n",
      "acc for optim= 0.1596578108890127\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.0074344202876091\n",
      "Loss on test= 0.009596999734640121\n",
      "acc for Lsat= 0.1988635729132869 \n",
      "acc for Psat= 0.23270013982002608 \n",
      "acc for optim= 0.16744374183586752\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.007198959589004517\n",
      "Loss on test= 0.009150857105851173\n",
      "acc for Lsat= 0.16902934325339852 \n",
      "acc for Psat= 0.25225440891589357 \n",
      "acc for optim= 0.1668873669373513\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.007450444158166647\n",
      "Loss on test= 0.008605193346738815\n",
      "acc for Lsat= 0.16930565800313593 \n",
      "acc for Psat= 0.2325880465641633 \n",
      "acc for optim= 0.16305054445258632\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.007601371966302395\n",
      "Loss on test= 0.008149650879204273\n",
      "acc for Lsat= 0.17620028050852077 \n",
      "acc for Psat= 0.25011597729715535 \n",
      "acc for optim= 0.170394866984933\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.007760991342365742\n",
      "Loss on test= 0.008910518139600754\n",
      "acc for Lsat= 0.1953969961410144 \n",
      "acc for Psat= 0.23279814746337713 \n",
      "acc for optim= 0.1653244532326992\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.007647961378097534\n",
      "Loss on test= 0.00855201669037342\n",
      "acc for Lsat= 0.16331150521997545 \n",
      "acc for Psat= 0.23131729750321475 \n",
      "acc for optim= 0.1638707009278673\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.007355822715908289\n",
      "Loss on test= 0.008716849610209465\n",
      "acc for Lsat= 0.16460103882346913 \n",
      "acc for Psat= 0.23229286630149382 \n",
      "acc for optim= 0.17174718737980108\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.0070819975808262825\n",
      "Loss on test= 0.00926894973963499\n",
      "acc for Lsat= 0.18283133488596937 \n",
      "acc for Psat= 0.2713456773870915 \n",
      "acc for optim= 0.16754754436561137\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.007412400096654892\n",
      "Loss on test= 0.007626303005963564\n",
      "acc for Lsat= 0.17395017978384114 \n",
      "acc for Psat= 0.22240289008611294 \n",
      "acc for optim= 0.16479392402102125\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.0073957378044724464\n",
      "Loss on test= 0.009208581410348415\n",
      "acc for Lsat= 0.1658865325799838 \n",
      "acc for Psat= 0.2272050598777435 \n",
      "acc for optim= 0.17337961726338644\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.008243680000305176\n",
      "Loss on test= 0.00827033817768097\n",
      "acc for Lsat= 0.18885102799843584 \n",
      "acc for Psat= 0.26057690816881807 \n",
      "acc for optim= 0.17288866238601766\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.008641494438052177\n",
      "Loss on test= 0.009259382262825966\n",
      "acc for Lsat= 0.18101963289683212 \n",
      "acc for Psat= 0.29848318798620194 \n",
      "acc for optim= 0.16769424559563764\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.008335648104548454\n",
      "Loss on test= 0.008371343836188316\n",
      "acc for Lsat= 0.17571624734813013 \n",
      "acc for Psat= 0.24662466553864298 \n",
      "acc for optim= 0.1707045543358707\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.007194546516984701\n",
      "Loss on test= 0.007747996598482132\n",
      "acc for Lsat= 0.16266812661025276 \n",
      "acc for Psat= 0.2384164938458898 \n",
      "acc for optim= 0.16589704950103445\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.007185996510088444\n",
      "Loss on test= 0.008601331152021885\n",
      "acc for Lsat= 0.1696157057770551 \n",
      "acc for Psat= 0.23123671755759564 \n",
      "acc for optim= 0.16935650969160812\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.007132182363420725\n",
      "Loss on test= 0.00796534400433302\n",
      "acc for Lsat= 0.18263838474188365 \n",
      "acc for Psat= 0.23341628396654593 \n",
      "acc for optim= 0.1622459461108579\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.007663169410079718\n",
      "Loss on test= 0.008621268905699253\n",
      "acc for Lsat= 0.163180209734271 \n",
      "acc for Psat= 0.24203631012017274 \n",
      "acc for optim= 0.17023100425054122\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.007301853038370609\n",
      "Loss on test= 0.00849891547113657\n",
      "acc for Lsat= 0.16874368739339188 \n",
      "acc for Psat= 0.23817973579051066 \n",
      "acc for optim= 0.16929910801251832\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.006978745572268963\n",
      "Loss on test= 0.008409836329519749\n",
      "acc for Lsat= 0.18148018469209554 \n",
      "acc for Psat= 0.21434135744844365 \n",
      "acc for optim= 0.16353223690105656\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.006931220181286335\n",
      "Loss on test= 0.007746037561446428\n",
      "acc for Lsat= 0.16347540307209874 \n",
      "acc for Psat= 0.22703593287494828 \n",
      "acc for optim= 0.15952731890177005\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.006824522279202938\n",
      "Loss on test= 0.00841942336410284\n",
      "acc for Lsat= 0.18833343092399923 \n",
      "acc for Psat= 0.21388543717125164 \n",
      "acc for optim= 0.1598351066403442\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.00688526313751936\n",
      "Loss on test= 0.007764053996652365\n",
      "acc for Lsat= 0.1730624029797895 \n",
      "acc for Psat= 0.21751640914580556 \n",
      "acc for optim= 0.16832099325046493\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.007551045157015324\n",
      "Loss on test= 0.008644351735711098\n",
      "acc for Lsat= 0.1837968862867441 \n",
      "acc for Psat= 0.22643920448379684 \n",
      "acc for optim= 0.16986320234449165\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.007365007884800434\n",
      "Loss on test= 0.008101647719740868\n",
      "acc for Lsat= 0.1749348325210673 \n",
      "acc for Psat= 0.22854233223364734 \n",
      "acc for optim= 0.166319542297269\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.007541229482740164\n",
      "Loss on test= 0.008578438311815262\n",
      "acc for Lsat= 0.17692574723623694 \n",
      "acc for Psat= 0.23751413754004314 \n",
      "acc for optim= 0.16294179497874478\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.0076985531486570835\n",
      "Loss on test= 0.007463932037353516\n",
      "acc for Lsat= 0.16616883671224178 \n",
      "acc for Psat= 0.20913788443793863 \n",
      "acc for optim= 0.16809220915339643\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.007269603665918112\n",
      "Loss on test= 0.007328019477427006\n",
      "acc for Lsat= 0.1641184300172799 \n",
      "acc for Psat= 0.22317888985233397 \n",
      "acc for optim= 0.17127094476666974\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.0075874654576182365\n",
      "Loss on test= 0.0082019604742527\n",
      "acc for Lsat= 0.17046807769353914 \n",
      "acc for Psat= 0.243575361515319 \n",
      "acc for optim= 0.17397618926145503\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.00704705948010087\n",
      "Loss on test= 0.008150054141879082\n",
      "acc for Lsat= 0.16490380982324465 \n",
      "acc for Psat= 0.24448370215574616 \n",
      "acc for optim= 0.16967746645906848\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.006931870244443417\n",
      "Loss on test= 0.008171219378709793\n",
      "acc for Lsat= 0.18551490954593391 \n",
      "acc for Psat= 0.23138137002681672 \n",
      "acc for optim= 0.16525138132844225\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.007272378541529179\n",
      "Loss on test= 0.008600182831287384\n",
      "acc for Lsat= 0.18351099200367346 \n",
      "acc for Psat= 0.2218514031776395 \n",
      "acc for optim= 0.16388938332030922\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.006943944841623306\n",
      "Loss on test= 0.00994529202580452\n",
      "acc for Lsat= 0.17868300350607166 \n",
      "acc for Psat= 0.23496600910642076 \n",
      "acc for optim= 0.17762580951418133\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.007007370702922344\n",
      "Loss on test= 0.008338487707078457\n",
      "acc for Lsat= 0.18073552810342708 \n",
      "acc for Psat= 0.21400253859982676 \n",
      "acc for optim= 0.16693875645249165\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.0072896466590464115\n",
      "Loss on test= 0.00805151928216219\n",
      "acc for Lsat= 0.17008250416409162 \n",
      "acc for Psat= 0.20889646070933 \n",
      "acc for optim= 0.16442765260695433\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.007264132611453533\n",
      "Loss on test= 0.009087043814361095\n",
      "acc for Lsat= 0.16945197309766225 \n",
      "acc for Psat= 0.24655149181194022 \n",
      "acc for optim= 0.16869254342287962\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.008649809285998344\n",
      "Loss on test= 0.009242230094969273\n",
      "acc for Lsat= 0.21073097447429584 \n",
      "acc for Psat= 0.22789827548349123 \n",
      "acc for optim= 0.1696414117804408\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.007613726891577244\n",
      "Loss on test= 0.008682699874043465\n",
      "acc for Lsat= 0.17695593392308495 \n",
      "acc for Psat= 0.2575018646278071 \n",
      "acc for optim= 0.1698084927077959\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.006939456798136234\n",
      "Loss on test= 0.009044911712408066\n",
      "acc for Lsat= 0.1739123823581603 \n",
      "acc for Psat= 0.2748227364611697 \n",
      "acc for optim= 0.1690406373511145\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.007352782879024744\n",
      "Loss on test= 0.007865062914788723\n",
      "acc for Lsat= 0.17221260046153178 \n",
      "acc for Psat= 0.22494276176649527 \n",
      "acc for optim= 0.1722992561272819\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.007219942752271891\n",
      "Loss on test= 0.008164802566170692\n",
      "acc for Lsat= 0.18316543803428162 \n",
      "acc for Psat= 0.22711230091994902 \n",
      "acc for optim= 0.16315110318785433\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.006862202193588018\n",
      "Loss on test= 0.007612950634211302\n",
      "acc for Lsat= 0.17249029462758192 \n",
      "acc for Psat= 0.22793667801449716 \n",
      "acc for optim= 0.1730064405086374\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.006877250969409943\n",
      "Loss on test= 0.008197970688343048\n",
      "acc for Lsat= 0.1887611225102341 \n",
      "acc for Psat= 0.2369613284111542 \n",
      "acc for optim= 0.16640776230297127\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.007328280713409185\n",
      "Loss on test= 0.008039684034883976\n",
      "acc for Lsat= 0.17717168969789246 \n",
      "acc for Psat= 0.23803456933003828 \n",
      "acc for optim= 0.1698421641512484\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.006951645947992802\n",
      "Loss on test= 0.00771696912124753\n",
      "acc for Lsat= 0.1780229779990909 \n",
      "acc for Psat= 0.20970352244349655 \n",
      "acc for optim= 0.16939414125546567\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.006494611501693726\n",
      "Loss on test= 0.007498378399759531\n",
      "acc for Lsat= 0.1763327596657604 \n",
      "acc for Psat= 0.20526110914237147 \n",
      "acc for optim= 0.1685186598239062\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.007088260259479284\n",
      "Loss on test= 0.008155187591910362\n",
      "acc for Lsat= 0.1738185995769855 \n",
      "acc for Psat= 0.22928463103264937 \n",
      "acc for optim= 0.16419999687837009\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.007113095372915268\n",
      "Loss on test= 0.00802944041788578\n",
      "acc for Lsat= 0.17072685209644928 \n",
      "acc for Psat= 0.24613121565608842 \n",
      "acc for optim= 0.1577805523710043\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.007140807807445526\n",
      "Loss on test= 0.008320096880197525\n",
      "acc for Lsat= 0.1829110818888351 \n",
      "acc for Psat= 0.25557652315846263 \n",
      "acc for optim= 0.168186780035741\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.007181215099990368\n",
      "Loss on test= 0.0074216811917722225\n",
      "acc for Lsat= 0.18678970050303356 \n",
      "acc for Psat= 0.21037751555969542 \n",
      "acc for optim= 0.16232806745817366\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.006992485374212265\n",
      "Loss on test= 0.007604219950735569\n",
      "acc for Lsat= 0.17505121068632015 \n",
      "acc for Psat= 0.227699717191777 \n",
      "acc for optim= 0.16509742364745403\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.0071457019075751305\n",
      "Loss on test= 0.008035111241042614\n",
      "acc for Lsat= 0.19113073901609198 \n",
      "acc for Psat= 0.23060532753951238 \n",
      "acc for optim= 0.17131722006696556\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.007272067479789257\n",
      "Loss on test= 0.007726001553237438\n",
      "acc for Lsat= 0.17132478352468156 \n",
      "acc for Psat= 0.2222439831400435 \n",
      "acc for optim= 0.16684455129415868\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.007001013495028019\n",
      "Loss on test= 0.00791738647967577\n",
      "acc for Lsat= 0.1920613211751381 \n",
      "acc for Psat= 0.2174736182205379 \n",
      "acc for optim= 0.17016689853922112\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.006824299693107605\n",
      "Loss on test= 0.008889463730156422\n",
      "acc for Lsat= 0.16383067607406343 \n",
      "acc for Psat= 0.22613706208276943 \n",
      "acc for optim= 0.17125847460931076\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.006889979355037212\n",
      "Loss on test= 0.007467198185622692\n",
      "acc for Lsat= 0.16917253966504311 \n",
      "acc for Psat= 0.23403643573802269 \n",
      "acc for optim= 0.1668448996495827\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.006793654058128595\n",
      "Loss on test= 0.007930748164653778\n",
      "acc for Lsat= 0.1749476400570425 \n",
      "acc for Psat= 0.2420947228116556 \n",
      "acc for optim= 0.1649745445854038\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.006631417665630579\n",
      "Loss on test= 0.0079543711617589\n",
      "acc for Lsat= 0.1792627397043585 \n",
      "acc for Psat= 0.2227381905063712 \n",
      "acc for optim= 0.16760377460636475\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.007221144624054432\n",
      "Loss on test= 0.007750962860882282\n",
      "acc for Lsat= 0.16859285782375677 \n",
      "acc for Psat= 0.22272575364799285 \n",
      "acc for optim= 0.16552207472612013\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.007610694505274296\n",
      "Loss on test= 0.009218555875122547\n",
      "acc for Lsat= 0.18148851932444396 \n",
      "acc for Psat= 0.306808206739241 \n",
      "acc for optim= 0.1642194344393993\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.0067284442484378815\n",
      "Loss on test= 0.007958940230309963\n",
      "acc for Lsat= 0.17615568042774762 \n",
      "acc for Psat= 0.2421940861258381 \n",
      "acc for optim= 0.16750914414039217\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.006658048834651709\n",
      "Loss on test= 0.008450468070805073\n",
      "acc for Lsat= 0.17805838317297337 \n",
      "acc for Psat= 0.21774407053956968 \n",
      "acc for optim= 0.165815658748272\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.00650180596858263\n",
      "Loss on test= 0.008337536826729774\n",
      "acc for Lsat= 0.1750611197863363 \n",
      "acc for Psat= 0.21884800957622708 \n",
      "acc for optim= 0.1631475606779606\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.006453557405620813\n",
      "Loss on test= 0.008364341221749783\n",
      "acc for Lsat= 0.17603966140142474 \n",
      "acc for Psat= 0.22211847551983827 \n",
      "acc for optim= 0.16724013953248315\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.007080687675625086\n",
      "Loss on test= 0.008213955909013748\n",
      "acc for Lsat= 0.19028764810960846 \n",
      "acc for Psat= 0.21968038918729108 \n",
      "acc for optim= 0.16773362052426521\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.00730136688798666\n",
      "Loss on test= 0.007813908159732819\n",
      "acc for Lsat= 0.17759612071047323 \n",
      "acc for Psat= 0.2235204631445398 \n",
      "acc for optim= 0.16813625628224071\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.006676036864519119\n",
      "Loss on test= 0.007809625472873449\n",
      "acc for Lsat= 0.1678928689737747 \n",
      "acc for Psat= 0.22368825669705747 \n",
      "acc for optim= 0.17551288755179276\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.006687675602734089\n",
      "Loss on test= 0.007877063006162643\n",
      "acc for Lsat= 0.15907249805502227 \n",
      "acc for Psat= 0.20570156119599725 \n",
      "acc for optim= 0.1703905871710511\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.006630587391555309\n",
      "Loss on test= 0.00787191092967987\n",
      "acc for Lsat= 0.16235111119928408 \n",
      "acc for Psat= 0.19202980683482163 \n",
      "acc for optim= 0.16125384745375085\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.0066152834333479404\n",
      "Loss on test= 0.007638733368366957\n",
      "acc for Lsat= 0.1698723631536924 \n",
      "acc for Psat= 0.20466394281419392 \n",
      "acc for optim= 0.1647298366193026\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.0063614072278141975\n",
      "Loss on test= 0.007190657313913107\n",
      "acc for Lsat= 0.1633016153990642 \n",
      "acc for Psat= 0.2132683432342286 \n",
      "acc for optim= 0.16488376350989412\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.006471564527601004\n",
      "Loss on test= 0.007541153114289045\n",
      "acc for Lsat= 0.1750376681566284 \n",
      "acc for Psat= 0.22508069287611507 \n",
      "acc for optim= 0.16212647055661245\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.006951052695512772\n",
      "Loss on test= 0.00739103090018034\n",
      "acc for Lsat= 0.1751594107178208 \n",
      "acc for Psat= 0.19570223188646077 \n",
      "acc for optim= 0.16752086121132825\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.006798841059207916\n",
      "Loss on test= 0.008209945634007454\n",
      "acc for Lsat= 0.17984107807507646 \n",
      "acc for Psat= 0.20807644546444176 \n",
      "acc for optim= 0.16236188362236134\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.006725986488163471\n",
      "Loss on test= 0.00805661827325821\n",
      "acc for Lsat= 0.1567817651181955 \n",
      "acc for Psat= 0.21695848051095992 \n",
      "acc for optim= 0.1710932122035807\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.006718286778777838\n",
      "Loss on test= 0.008107277564704418\n",
      "acc for Lsat= 0.15951516656109635 \n",
      "acc for Psat= 0.2285152733158015 \n",
      "acc for optim= 0.17643967224437682\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.006530202925205231\n",
      "Loss on test= 0.007974257692694664\n",
      "acc for Lsat= 0.16346267187809496 \n",
      "acc for Psat= 0.21844314780987067 \n",
      "acc for optim= 0.16412508827786831\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.006645786575973034\n",
      "Loss on test= 0.00784445833414793\n",
      "acc for Lsat= 0.16167919650906698 \n",
      "acc for Psat= 0.20713749438716045 \n",
      "acc for optim= 0.16685208577517666\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.006546098738908768\n",
      "Loss on test= 0.008769465610384941\n",
      "acc for Lsat= 0.1778536121746464 \n",
      "acc for Psat= 0.23126462609507142 \n",
      "acc for optim= 0.16646823400012972\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.006414227187633514\n",
      "Loss on test= 0.007841655984520912\n",
      "acc for Lsat= 0.1742318422232037 \n",
      "acc for Psat= 0.22862568020316787 \n",
      "acc for optim= 0.1612560932067906\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.006567982491105795\n",
      "Loss on test= 0.0070997318252921104\n",
      "acc for Lsat= 0.17538343400562748 \n",
      "acc for Psat= 0.20222487904715397 \n",
      "acc for optim= 0.16755198659698553\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.006712275091558695\n",
      "Loss on test= 0.00751316174864769\n",
      "acc for Lsat= 0.17790710012252886 \n",
      "acc for Psat= 0.19086730977440192 \n",
      "acc for optim= 0.1643997362087725\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.006770249456167221\n",
      "Loss on test= 0.007205691188573837\n",
      "acc for Lsat= 0.17442215908946518 \n",
      "acc for Psat= 0.2100350354656913 \n",
      "acc for optim= 0.17009508055754075\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.006651255302131176\n",
      "Loss on test= 0.007573538925498724\n",
      "acc for Lsat= 0.16982970633658534 \n",
      "acc for Psat= 0.21003343619589435 \n",
      "acc for optim= 0.16269210261258404\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.006502763368189335\n",
      "Loss on test= 0.00733985984697938\n",
      "acc for Lsat= 0.1693770208563961 \n",
      "acc for Psat= 0.22507306184814327 \n",
      "acc for optim= 0.1645797633104118\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.006460326258093119\n",
      "Loss on test= 0.007559903897345066\n",
      "acc for Lsat= 0.1817026021075435 \n",
      "acc for Psat= 0.25020653180411606 \n",
      "acc for optim= 0.16559675021295542\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.006416879594326019\n",
      "Loss on test= 0.008258242160081863\n",
      "acc for Lsat= 0.16851027305390626 \n",
      "acc for Psat= 0.21565517609992416 \n",
      "acc for optim= 0.1621735830358077\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.006460397504270077\n",
      "Loss on test= 0.0075765447691082954\n",
      "acc for Lsat= 0.15966434935369045 \n",
      "acc for Psat= 0.22447455142945297 \n",
      "acc for optim= 0.16311180734797953\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.006505460944026709\n",
      "Loss on test= 0.007646594196557999\n",
      "acc for Lsat= 0.15445740641816139 \n",
      "acc for Psat= 0.21123745326397914 \n",
      "acc for optim= 0.160327194152294\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.0063649313524365425\n",
      "Loss on test= 0.0076078507117927074\n",
      "acc for Lsat= 0.1563692630344017 \n",
      "acc for Psat= 0.1969619578178056 \n",
      "acc for optim= 0.16045286398458286\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.00654017785564065\n",
      "Loss on test= 0.007076586131006479\n",
      "acc for Lsat= 0.17403226681416242 \n",
      "acc for Psat= 0.20201696973627045 \n",
      "acc for optim= 0.16422545022276788\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.006168358959257603\n",
      "Loss on test= 0.007591110188513994\n",
      "acc for Lsat= 0.1626424800782664 \n",
      "acc for Psat= 0.2267123229704324 \n",
      "acc for optim= 0.16817688063573336\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.006320806685835123\n",
      "Loss on test= 0.008344972506165504\n",
      "acc for Lsat= 0.1657333974295189 \n",
      "acc for Psat= 0.19918094218592158 \n",
      "acc for optim= 0.16337290096986987\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.0067520602606236935\n",
      "Loss on test= 0.007478895131498575\n",
      "acc for Lsat= 0.1772728779607979 \n",
      "acc for Psat= 0.21023010956428823 \n",
      "acc for optim= 0.16243915754221533\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.006672754883766174\n",
      "Loss on test= 0.007808230351656675\n",
      "acc for Lsat= 0.16555299372717616 \n",
      "acc for Psat= 0.2195039776207299 \n",
      "acc for optim= 0.16781792236934798\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.006346928887069225\n",
      "Loss on test= 0.007931049913167953\n",
      "acc for Lsat= 0.1714182575076311 \n",
      "acc for Psat= 0.2212427713689857 \n",
      "acc for optim= 0.16893493846845126\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.006246669217944145\n",
      "Loss on test= 0.008158947341144085\n",
      "acc for Lsat= 0.15186927220521715 \n",
      "acc for Psat= 0.2266939979008414 \n",
      "acc for optim= 0.15853998263263464\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.006324686110019684\n",
      "Loss on test= 0.0076844473369419575\n",
      "acc for Lsat= 0.16803932517316558 \n",
      "acc for Psat= 0.2019375258148266 \n",
      "acc for optim= 0.16489755457339209\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.006261908914893866\n",
      "Loss on test= 0.007841570302844048\n",
      "acc for Lsat= 0.17169806683420769 \n",
      "acc for Psat= 0.20786695122379106 \n",
      "acc for optim= 0.16778299447500192\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.007012189831584692\n",
      "Loss on test= 0.007755641359835863\n",
      "acc for Lsat= 0.1749964979427607 \n",
      "acc for Psat= 0.21964629549193426 \n",
      "acc for optim= 0.1727706460419615\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.0065700882114470005\n",
      "Loss on test= 0.0071173463948071\n",
      "acc for Lsat= 0.1728680844220226 \n",
      "acc for Psat= 0.20822081035079404 \n",
      "acc for optim= 0.17305500501064014\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.006325332913547754\n",
      "Loss on test= 0.007467201910912991\n",
      "acc for Lsat= 0.17102307509840847 \n",
      "acc for Psat= 0.21015355877819678 \n",
      "acc for optim= 0.16929847795523886\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.006637254264205694\n",
      "Loss on test= 0.007571771275252104\n",
      "acc for Lsat= 0.16529232631494734 \n",
      "acc for Psat= 0.19343136140607206 \n",
      "acc for optim= 0.1636952419690089\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.006181374192237854\n",
      "Loss on test= 0.0075118886306881905\n",
      "acc for Lsat= 0.1651296578977948 \n",
      "acc for Psat= 0.20670607631690188 \n",
      "acc for optim= 0.17450242386749168\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.0063827307894825935\n",
      "Loss on test= 0.00782709289342165\n",
      "acc for Lsat= 0.16594595733541445 \n",
      "acc for Psat= 0.20570923655897905 \n",
      "acc for optim= 0.16745910938298636\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.0066907890141010284\n",
      "Loss on test= 0.007793338969349861\n",
      "acc for Lsat= 0.17692905027468472 \n",
      "acc for Psat= 0.19802818709257303 \n",
      "acc for optim= 0.1675297613274764\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.006462369114160538\n",
      "Loss on test= 0.007775136269629002\n",
      "acc for Lsat= 0.17303303953095103 \n",
      "acc for Psat= 0.20521851718849426 \n",
      "acc for optim= 0.1646903952700086\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.006213515996932983\n",
      "Loss on test= 0.0075236037373542786\n",
      "acc for Lsat= 0.17713494179694012 \n",
      "acc for Psat= 0.21022185944516944 \n",
      "acc for optim= 0.17056715240793638\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.005944270174950361\n",
      "Loss on test= 0.0074784341268241405\n",
      "acc for Lsat= 0.1691208644589141 \n",
      "acc for Psat= 0.19619248689526356 \n",
      "acc for optim= 0.16023830522546453\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.006798136979341507\n",
      "Loss on test= 0.007615352049469948\n",
      "acc for Lsat= 0.16349655203177732 \n",
      "acc for Psat= 0.19827122096350172 \n",
      "acc for optim= 0.16921908062459046\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.006126368883997202\n",
      "Loss on test= 0.007460855413228273\n",
      "acc for Lsat= 0.17754442832913617 \n",
      "acc for Psat= 0.2026985172883676 \n",
      "acc for optim= 0.16649860711920944\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.006344924680888653\n",
      "Loss on test= 0.008070728741586208\n",
      "acc for Lsat= 0.17296294393676304 \n",
      "acc for Psat= 0.20457686183813836 \n",
      "acc for optim= 0.15404540911988646\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.006524165626615286\n",
      "Loss on test= 0.007815694436430931\n",
      "acc for Lsat= 0.17558479596933227 \n",
      "acc for Psat= 0.2062149253118851 \n",
      "acc for optim= 0.16322098102336596\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.006556929554790258\n",
      "Loss on test= 0.0073732296004891396\n",
      "acc for Lsat= 0.16875474447514252 \n",
      "acc for Psat= 0.19855450847354092 \n",
      "acc for optim= 0.1637818394522717\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.0065034837462008\n",
      "Loss on test= 0.007768682669848204\n",
      "acc for Lsat= 0.16483072513412897 \n",
      "acc for Psat= 0.22063887180897912 \n",
      "acc for optim= 0.17213165566523667\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.006200357340276241\n",
      "Loss on test= 0.0078414436429739\n",
      "acc for Lsat= 0.15754642044104583 \n",
      "acc for Psat= 0.20122796415158578 \n",
      "acc for optim= 0.1620502928485636\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.006317857652902603\n",
      "Loss on test= 0.007707925513386726\n",
      "acc for Lsat= 0.15882397356794262 \n",
      "acc for Psat= 0.21406647048706426 \n",
      "acc for optim= 0.15554708305547837\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.006696584168821573\n",
      "Loss on test= 0.007633999455720186\n",
      "acc for Lsat= 0.16897499558676157 \n",
      "acc for Psat= 0.2039608051006102 \n",
      "acc for optim= 0.17301273647024007\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.006270288024097681\n",
      "Loss on test= 0.00737220561131835\n",
      "acc for Lsat= 0.16778816434766594 \n",
      "acc for Psat= 0.21109822676440732 \n",
      "acc for optim= 0.16895869711803302\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.006390527822077274\n",
      "Loss on test= 0.007330284919589758\n",
      "acc for Lsat= 0.1788166480186609 \n",
      "acc for Psat= 0.2198952245155777 \n",
      "acc for optim= 0.16717502743876006\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.0068103233352303505\n",
      "Loss on test= 0.0077936952002346516\n",
      "acc for Lsat= 0.16234301190582853 \n",
      "acc for Psat= 0.21508912584953369 \n",
      "acc for optim= 0.17045153340484115\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.0064523047767579556\n",
      "Loss on test= 0.007485445123165846\n",
      "acc for Lsat= 0.15329321222033898 \n",
      "acc for Psat= 0.21304384387922704 \n",
      "acc for optim= 0.1761190114764222\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.006165366619825363\n",
      "Loss on test= 0.00788955669850111\n",
      "acc for Lsat= 0.15737119064431115 \n",
      "acc for Psat= 0.22640388972034342 \n",
      "acc for optim= 0.17572339433653292\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.006328544579446316\n",
      "Loss on test= 0.00809603650122881\n",
      "acc for Lsat= 0.1533438863553351 \n",
      "acc for Psat= 0.23585011761480004 \n",
      "acc for optim= 0.16481184255576037\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.006342860870063305\n",
      "Loss on test= 0.0075597302056849\n",
      "acc for Lsat= 0.1634582255841004 \n",
      "acc for Psat= 0.20552435257552254 \n",
      "acc for optim= 0.15930074795061477\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.0062519824132323265\n",
      "Loss on test= 0.007934859953820705\n",
      "acc for Lsat= 0.19073715114125842 \n",
      "acc for Psat= 0.20837467311973087 \n",
      "acc for optim= 0.1635115587528982\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.006376561708748341\n",
      "Loss on test= 0.007879383862018585\n",
      "acc for Lsat= 0.1798928402249747 \n",
      "acc for Psat= 0.21609888119836812 \n",
      "acc for optim= 0.16673892221783793\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.0068703703582286835\n",
      "Loss on test= 0.007668408565223217\n",
      "acc for Lsat= 0.15653833501684083 \n",
      "acc for Psat= 0.1982476940665768 \n",
      "acc for optim= 0.16859911123517762\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.00628260150551796\n",
      "Loss on test= 0.007750716060400009\n",
      "acc for Lsat= 0.15920912245365784 \n",
      "acc for Psat= 0.21546910991739543 \n",
      "acc for optim= 0.1667363774901653\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.006099041551351547\n",
      "Loss on test= 0.008072596974670887\n",
      "acc for Lsat= 0.15430281822575392 \n",
      "acc for Psat= 0.23033647094395196 \n",
      "acc for optim= 0.16565937856613033\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.006204782519489527\n",
      "Loss on test= 0.007696316111832857\n",
      "acc for Lsat= 0.17026575058870413 \n",
      "acc for Psat= 0.21649742210927977 \n",
      "acc for optim= 0.1625736577951609\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.006122049875557423\n",
      "Loss on test= 0.007427823729813099\n",
      "acc for Lsat= 0.16255129502425886 \n",
      "acc for Psat= 0.2001899016823178 \n",
      "acc for optim= 0.16633888881264225\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.00617660628631711\n",
      "Loss on test= 0.007117484230548143\n",
      "acc for Lsat= 0.15199446439949155 \n",
      "acc for Psat= 0.18442951340083277 \n",
      "acc for optim= 0.16330906776883106\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.006004782859236002\n",
      "Loss on test= 0.008035830222070217\n",
      "acc for Lsat= 0.1722135003745846 \n",
      "acc for Psat= 0.24290690028276124 \n",
      "acc for optim= 0.16211987019203541\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.00616521155461669\n",
      "Loss on test= 0.007698396686464548\n",
      "acc for Lsat= 0.16782960194872967 \n",
      "acc for Psat= 0.22736872822183687 \n",
      "acc for optim= 0.16684143966680287\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.006101944018155336\n",
      "Loss on test= 0.0078202523291111\n",
      "acc for Lsat= 0.16575036341148872 \n",
      "acc for Psat= 0.19525522258758668 \n",
      "acc for optim= 0.16210722726708676\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.006178306881338358\n",
      "Loss on test= 0.007605269551277161\n",
      "acc for Lsat= 0.1509032921390379 \n",
      "acc for Psat= 0.18935280146943712 \n",
      "acc for optim= 0.16412157504412594\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.006083465181291103\n",
      "Loss on test= 0.0075849611312150955\n",
      "acc for Lsat= 0.16591649573471887 \n",
      "acc for Psat= 0.22472958554008968 \n",
      "acc for optim= 0.17445519460960612\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.006231696344912052\n",
      "Loss on test= 0.007195335812866688\n",
      "acc for Lsat= 0.15883929292312593 \n",
      "acc for Psat= 0.1949183794763321 \n",
      "acc for optim= 0.1644874111123261\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.0061926147900521755\n",
      "Loss on test= 0.007678760681301355\n",
      "acc for Lsat= 0.1733837600602604 \n",
      "acc for Psat= 0.19607416652524692 \n",
      "acc for optim= 0.16467885587280465\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.006006242707371712\n",
      "Loss on test= 0.007477632258087397\n",
      "acc for Lsat= 0.1558855622705286 \n",
      "acc for Psat= 0.22088596279137448 \n",
      "acc for optim= 0.16621840372118626\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.006050394382327795\n",
      "Loss on test= 0.007411253172904253\n",
      "acc for Lsat= 0.1642953429151647 \n",
      "acc for Psat= 0.19647008142172603 \n",
      "acc for optim= 0.16366094507841913\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.006103615276515484\n",
      "Loss on test= 0.008200828917324543\n",
      "acc for Lsat= 0.16705039517732612 \n",
      "acc for Psat= 0.19943839282476816 \n",
      "acc for optim= 0.16839623910190774\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.006142049096524715\n",
      "Loss on test= 0.0075884475372731686\n",
      "acc for Lsat= 0.16208586682599863 \n",
      "acc for Psat= 0.2167420056803614 \n",
      "acc for optim= 0.1706848472244198\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.006003991700708866\n",
      "Loss on test= 0.007554745301604271\n",
      "acc for Lsat= 0.16417397242650145 \n",
      "acc for Psat= 0.2193795147596202 \n",
      "acc for optim= 0.1628278357537891\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.006088244263082743\n",
      "Loss on test= 0.006964266300201416\n",
      "acc for Lsat= 0.1574363804498657 \n",
      "acc for Psat= 0.20135414388706357 \n",
      "acc for optim= 0.17657464698260483\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.005912312306463718\n",
      "Loss on test= 0.007841731421649456\n",
      "acc for Lsat= 0.17562567845567084 \n",
      "acc for Psat= 0.2074847397789527 \n",
      "acc for optim= 0.16899113830056836\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.006909164600074291\n",
      "Loss on test= 0.007051342166960239\n",
      "acc for Lsat= 0.15991455234009172 \n",
      "acc for Psat= 0.20558031166438012 \n",
      "acc for optim= 0.16941980510409999\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.006285197101533413\n",
      "Loss on test= 0.007923091761767864\n",
      "acc for Lsat= 0.15414953847629492 \n",
      "acc for Psat= 0.22508796169384399 \n",
      "acc for optim= 0.16834325669927344\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.006456402596086264\n",
      "Loss on test= 0.007511321920901537\n",
      "acc for Lsat= 0.16685162898130165 \n",
      "acc for Psat= 0.19354995417973545 \n",
      "acc for optim= 0.16562735042954627\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.006461777724325657\n",
      "Loss on test= 0.008119347505271435\n",
      "acc for Lsat= 0.1651484767271809 \n",
      "acc for Psat= 0.20372229324459082 \n",
      "acc for optim= 0.1641578262180045\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.006071650423109531\n",
      "Loss on test= 0.007120656780898571\n",
      "acc for Lsat= 0.15553648260662514 \n",
      "acc for Psat= 0.20072959397659926 \n",
      "acc for optim= 0.16717625423143695\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.006401084363460541\n",
      "Loss on test= 0.007623724639415741\n",
      "acc for Lsat= 0.1669699646921859 \n",
      "acc for Psat= 0.21670441562844225 \n",
      "acc for optim= 0.16739233580291973\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.006021398585289717\n",
      "Loss on test= 0.007432740647345781\n",
      "acc for Lsat= 0.1449134284984435 \n",
      "acc for Psat= 0.20953262146465962 \n",
      "acc for optim= 0.1611549794254061\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.00654096994549036\n",
      "Loss on test= 0.007497552782297134\n",
      "acc for Lsat= 0.15827000926584617 \n",
      "acc for Psat= 0.19244207612116684 \n",
      "acc for optim= 0.16506625865967792\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.00635271891951561\n",
      "Loss on test= 0.007479604333639145\n",
      "acc for Lsat= 0.15642564214883395 \n",
      "acc for Psat= 0.20310867674358676 \n",
      "acc for optim= 0.16161895185464717\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.005990137811750174\n",
      "Loss on test= 0.007449457887560129\n",
      "acc for Lsat= 0.15600842935964465 \n",
      "acc for Psat= 0.22897793440841002 \n",
      "acc for optim= 0.1643232445202035\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.006016238126903772\n",
      "Loss on test= 0.007342508062720299\n",
      "acc for Lsat= 0.1633367765274998 \n",
      "acc for Psat= 0.19228338504927692 \n",
      "acc for optim= 0.16069527729338065\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.006254509091377258\n",
      "Loss on test= 0.007538356352597475\n",
      "acc for Lsat= 0.16040827460132814 \n",
      "acc for Psat= 0.21540960357066427 \n",
      "acc for optim= 0.17122502818276158\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.006428278051316738\n",
      "Loss on test= 0.007623101118952036\n",
      "acc for Lsat= 0.18207716888969488 \n",
      "acc for Psat= 0.21635471044497595 \n",
      "acc for optim= 0.16760294926476849\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.006203437224030495\n",
      "Loss on test= 0.0073241498321294785\n",
      "acc for Lsat= 0.15610239632030734 \n",
      "acc for Psat= 0.20171619834164617 \n",
      "acc for optim= 0.16689259553782368\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.006229175720363855\n",
      "Loss on test= 0.007521407213062048\n",
      "acc for Lsat= 0.16502805485993197 \n",
      "acc for Psat= 0.20769044921664734 \n",
      "acc for optim= 0.16234525344258205\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.005987436044961214\n",
      "Loss on test= 0.007162399124354124\n",
      "acc for Lsat= 0.15815492366768846 \n",
      "acc for Psat= 0.2130481883952896 \n",
      "acc for optim= 0.17472216369904822\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.005936556961387396\n",
      "Loss on test= 0.007986588403582573\n",
      "acc for Lsat= 0.16956776989581918 \n",
      "acc for Psat= 0.21525751935083373 \n",
      "acc for optim= 0.16645317233404236\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.005863099824637175\n",
      "Loss on test= 0.007127707824110985\n",
      "acc for Lsat= 0.17405690122052234 \n",
      "acc for Psat= 0.19032725023409183 \n",
      "acc for optim= 0.16145104587223136\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.005917827598750591\n",
      "Loss on test= 0.007951632142066956\n",
      "acc for Lsat= 0.16995212185715677 \n",
      "acc for Psat= 0.20193028403656008 \n",
      "acc for optim= 0.16596561052548303\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.006095681805163622\n",
      "Loss on test= 0.007520916406065226\n",
      "acc for Lsat= 0.1728856558859974 \n",
      "acc for Psat= 0.2185686757788062 \n",
      "acc for optim= 0.16800973013818232\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.005833405535668135\n",
      "Loss on test= 0.007913744077086449\n",
      "acc for Lsat= 0.16278902602603385 \n",
      "acc for Psat= 0.2049516497640756 \n",
      "acc for optim= 0.16593228612881397\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.006119368132203817\n",
      "Loss on test= 0.007849647663533688\n",
      "acc for Lsat= 0.16368501565116647 \n",
      "acc for Psat= 0.21271711738692353 \n",
      "acc for optim= 0.16672252710721625\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.006171584594994783\n",
      "Loss on test= 0.0075035374611616135\n",
      "acc for Lsat= 0.15830417180388068 \n",
      "acc for Psat= 0.20961175218938286 \n",
      "acc for optim= 0.16306938358685613\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.0059922849759459496\n",
      "Loss on test= 0.008222019299864769\n",
      "acc for Lsat= 0.17304173367494932 \n",
      "acc for Psat= 0.23223966722239237 \n",
      "acc for optim= 0.17185794458129122\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.0061208768747746944\n",
      "Loss on test= 0.008164113387465477\n",
      "acc for Lsat= 0.1585855285144701 \n",
      "acc for Psat= 0.20091572986576003 \n",
      "acc for optim= 0.1677990557020912\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.0061472998932003975\n",
      "Loss on test= 0.007706210482865572\n",
      "acc for Lsat= 0.16132838467162744 \n",
      "acc for Psat= 0.204558547220544 \n",
      "acc for optim= 0.16161075857273288\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.006259842310100794\n",
      "Loss on test= 0.007927218452095985\n",
      "acc for Lsat= 0.16797500839476 \n",
      "acc for Psat= 0.2104703399667146 \n",
      "acc for optim= 0.16290090500780754\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.005830713082104921\n",
      "Loss on test= 0.007522073108702898\n",
      "acc for Lsat= 0.16293942649642648 \n",
      "acc for Psat= 0.2052404402312441 \n",
      "acc for optim= 0.17004661762163226\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.005987636279314756\n",
      "Loss on test= 0.007366117089986801\n",
      "acc for Lsat= 0.13948296431583718 \n",
      "acc for Psat= 0.21294400201813168 \n",
      "acc for optim= 0.17124521502057\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.0058566611260175705\n",
      "Loss on test= 0.007667411584407091\n",
      "acc for Lsat= 0.15907651680811752 \n",
      "acc for Psat= 0.225613074019536 \n",
      "acc for optim= 0.1657334245079613\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.005892982240766287\n",
      "Loss on test= 0.007230783812701702\n",
      "acc for Lsat= 0.16326814992553706 \n",
      "acc for Psat= 0.22455475370716457 \n",
      "acc for optim= 0.17262577093082296\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.006105945445597172\n",
      "Loss on test= 0.00786888599395752\n",
      "acc for Lsat= 0.15199724344067184 \n",
      "acc for Psat= 0.18380185065263324 \n",
      "acc for optim= 0.1739515754503015\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.006677975412458181\n",
      "Loss on test= 0.007780480198562145\n",
      "acc for Lsat= 0.18528049530597526 \n",
      "acc for Psat= 0.19926966477574812 \n",
      "acc for optim= 0.16421914214848496\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.006089072208851576\n",
      "Loss on test= 0.008159681223332882\n",
      "acc for Lsat= 0.1591586452580561 \n",
      "acc for Psat= 0.19152058124175814 \n",
      "acc for optim= 0.1723604155857055\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.006057831458747387\n",
      "Loss on test= 0.007546956650912762\n",
      "acc for Lsat= 0.15704112268918 \n",
      "acc for Psat= 0.18944672306419397 \n",
      "acc for optim= 0.17166331022835649\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.006048167590051889\n",
      "Loss on test= 0.007117379456758499\n",
      "acc for Lsat= 0.1527813024795996 \n",
      "acc for Psat= 0.18842435300833982 \n",
      "acc for optim= 0.16438792486461337\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.005731143988668919\n",
      "Loss on test= 0.007840794511139393\n",
      "acc for Lsat= 0.15570456602736604 \n",
      "acc for Psat= 0.22623357028188948 \n",
      "acc for optim= 0.16283008661235637\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.006267552264034748\n",
      "Loss on test= 0.007195627316832542\n",
      "acc for Lsat= 0.16622000831125885 \n",
      "acc for Psat= 0.19134546309408015 \n",
      "acc for optim= 0.1617787084734014\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.00696654012426734\n",
      "Loss on test= 0.007953733205795288\n",
      "acc for Lsat= 0.1514067590101164 \n",
      "acc for Psat= 0.21223463272164408 \n",
      "acc for optim= 0.16805991202764134\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.006112494505941868\n",
      "Loss on test= 0.007545907981693745\n",
      "acc for Lsat= 0.16200877615607526 \n",
      "acc for Psat= 0.2058430921112795 \n",
      "acc for optim= 0.16823992932111084\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.005944384261965752\n",
      "Loss on test= 0.008011363446712494\n",
      "acc for Lsat= 0.16228070979972264 \n",
      "acc for Psat= 0.21478618972020636 \n",
      "acc for optim= 0.1695402665716428\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.005799910519272089\n",
      "Loss on test= 0.007110774051398039\n",
      "acc for Lsat= 0.1629538652882148 \n",
      "acc for Psat= 0.18593490341273672 \n",
      "acc for optim= 0.16929903020891438\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.005967776756733656\n",
      "Loss on test= 0.007566126063466072\n",
      "acc for Lsat= 0.15806085077583404 \n",
      "acc for Psat= 0.21914807153716837 \n",
      "acc for optim= 0.16389034653047183\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.005896982736885548\n",
      "Loss on test= 0.007315330673009157\n",
      "acc for Lsat= 0.17094131371685778 \n",
      "acc for Psat= 0.20218452182941932 \n",
      "acc for optim= 0.16441551660775344\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.005946916528046131\n",
      "Loss on test= 0.00729540316388011\n",
      "acc for Lsat= 0.16199385084853066 \n",
      "acc for Psat= 0.22175440335604285 \n",
      "acc for optim= 0.17245810685648783\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.006093760021030903\n",
      "Loss on test= 0.007399385329335928\n",
      "acc for Lsat= 0.1568135389939836 \n",
      "acc for Psat= 0.20429124074404081 \n",
      "acc for optim= 0.16768053639928246\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.005772292148321867\n",
      "Loss on test= 0.008304963819682598\n",
      "acc for Lsat= 0.14947165858198996 \n",
      "acc for Psat= 0.2035970092541932 \n",
      "acc for optim= 0.1611866426292032\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.005969106685370207\n",
      "Loss on test= 0.00754390237852931\n",
      "acc for Lsat= 0.15655240070429768 \n",
      "acc for Psat= 0.21191485090043824 \n",
      "acc for optim= 0.16535346654299113\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.00641525536775589\n",
      "Loss on test= 0.00817608181387186\n",
      "acc for Lsat= 0.15651649327483028 \n",
      "acc for Psat= 0.19917430170109404 \n",
      "acc for optim= 0.1722987339786086\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.006101985927671194\n",
      "Loss on test= 0.007142342161387205\n",
      "acc for Lsat= 0.15158046161496846 \n",
      "acc for Psat= 0.20062727440953956 \n",
      "acc for optim= 0.16713253813910253\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.005880598910152912\n",
      "Loss on test= 0.007259635254740715\n",
      "acc for Lsat= 0.15891634937552376 \n",
      "acc for Psat= 0.18273609641817262 \n",
      "acc for optim= 0.16286388440744676\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.0059952521696686745\n",
      "Loss on test= 0.007422988303005695\n",
      "acc for Lsat= 0.15666120327936608 \n",
      "acc for Psat= 0.2101079946098521 \n",
      "acc for optim= 0.15934655075295462\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.006142229773104191\n",
      "Loss on test= 0.006985594052821398\n",
      "acc for Lsat= 0.16223029461579558 \n",
      "acc for Psat= 0.20374586098735817 \n",
      "acc for optim= 0.16162044938289194\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.005866317078471184\n",
      "Loss on test= 0.007210101466625929\n",
      "acc for Lsat= 0.1625458352531108 \n",
      "acc for Psat= 0.20217581123846476 \n",
      "acc for optim= 0.16464317981708368\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.0060103340074419975\n",
      "Loss on test= 0.007871028035879135\n",
      "acc for Lsat= 0.15528975297834297 \n",
      "acc for Psat= 0.21828221476762785 \n",
      "acc for optim= 0.16309753971491162\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.005841156933456659\n",
      "Loss on test= 0.007434661965817213\n",
      "acc for Lsat= 0.1543068556920396 \n",
      "acc for Psat= 0.20194205548232574 \n",
      "acc for optim= 0.16704444222740988\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.00578692089766264\n",
      "Loss on test= 0.007259513717144728\n",
      "acc for Lsat= 0.1599560063113802 \n",
      "acc for Psat= 0.2004099482533018 \n",
      "acc for optim= 0.16206734487376573\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.005740488413721323\n",
      "Loss on test= 0.006582709029316902\n",
      "acc for Lsat= 0.16454793868975745 \n",
      "acc for Psat= 0.2164552421403522 \n",
      "acc for optim= 0.1650834620378713\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.006079304963350296\n",
      "Loss on test= 0.007367943879216909\n",
      "acc for Lsat= 0.16515813117739975 \n",
      "acc for Psat= 0.20213850184847584 \n",
      "acc for optim= 0.1621040329970725\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.006019547116011381\n",
      "Loss on test= 0.007666991092264652\n",
      "acc for Lsat= 0.16101357893358448 \n",
      "acc for Psat= 0.18046613652869814 \n",
      "acc for optim= 0.17258577917351342\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.005717034451663494\n",
      "Loss on test= 0.0071781957522034645\n",
      "acc for Lsat= 0.1670448622719736 \n",
      "acc for Psat= 0.21089664606366032 \n",
      "acc for optim= 0.16885299263860779\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.005756349768489599\n",
      "Loss on test= 0.007596109062433243\n",
      "acc for Lsat= 0.16832835700049936 \n",
      "acc for Psat= 0.2154668906276099 \n",
      "acc for optim= 0.1662030918435165\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.005758075974881649\n",
      "Loss on test= 0.007161961402744055\n",
      "acc for Lsat= 0.1555563936772428 \n",
      "acc for Psat= 0.20517358291802593 \n",
      "acc for optim= 0.1621530957200343\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.0058710211887955666\n",
      "Loss on test= 0.007360571529716253\n",
      "acc for Lsat= 0.14439807773561056 \n",
      "acc for Psat= 0.19871598018317094 \n",
      "acc for optim= 0.16350200696558248\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.006109206937253475\n",
      "Loss on test= 0.007577014155685902\n",
      "acc for Lsat= 0.1564614506304783 \n",
      "acc for Psat= 0.2154338509233699 \n",
      "acc for optim= 0.1710714216146534\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.006014517042785883\n",
      "Loss on test= 0.007756891194730997\n",
      "acc for Lsat= 0.15287125369010982 \n",
      "acc for Psat= 0.19455937220024128 \n",
      "acc for optim= 0.1701600714768932\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.006067131645977497\n",
      "Loss on test= 0.007409189362078905\n",
      "acc for Lsat= 0.1664441635442867 \n",
      "acc for Psat= 0.1985678925774858 \n",
      "acc for optim= 0.1617167049559925\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.00578582938760519\n",
      "Loss on test= 0.007439263164997101\n",
      "acc for Lsat= 0.16001502302261528 \n",
      "acc for Psat= 0.2182125486910618 \n",
      "acc for optim= 0.15969959378841744\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.006195989437401295\n",
      "Loss on test= 0.007908935658633709\n",
      "acc for Lsat= 0.16497731452777248 \n",
      "acc for Psat= 0.2006826208318492 \n",
      "acc for optim= 0.16679811099134806\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.006357140839099884\n",
      "Loss on test= 0.0075295534916222095\n",
      "acc for Lsat= 0.14732357840815685 \n",
      "acc for Psat= 0.20870991818335854 \n",
      "acc for optim= 0.16187341996014393\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.005852309055626392\n",
      "Loss on test= 0.007952972315251827\n",
      "acc for Lsat= 0.17087659789654847 \n",
      "acc for Psat= 0.2142378326780239 \n",
      "acc for optim= 0.17323365263224838\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.005802258849143982\n",
      "Loss on test= 0.007307338062673807\n",
      "acc for Lsat= 0.16354100118280526 \n",
      "acc for Psat= 0.1866429147225629 \n",
      "acc for optim= 0.16813211214430934\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.006109338253736496\n",
      "Loss on test= 0.007311859168112278\n",
      "acc for Lsat= 0.15700307001023875 \n",
      "acc for Psat= 0.19947361614140988 \n",
      "acc for optim= 0.15850775682626933\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.006751236505806446\n",
      "Loss on test= 0.0074462671764194965\n",
      "acc for Lsat= 0.15909317821449387 \n",
      "acc for Psat= 0.18145529566328508 \n",
      "acc for optim= 0.1714778451451299\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.006440442055463791\n",
      "Loss on test= 0.007842223159968853\n",
      "acc for Lsat= 0.14828991794521676 \n",
      "acc for Psat= 0.21012996489784588 \n",
      "acc for optim= 0.17491814210488735\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.005884363315999508\n",
      "Loss on test= 0.0070667993277311325\n",
      "acc for Lsat= 0.1593574402595252 \n",
      "acc for Psat= 0.1995961544852032 \n",
      "acc for optim= 0.17212504295338343\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.005799867678433657\n",
      "Loss on test= 0.007512079086154699\n",
      "acc for Lsat= 0.17047546182560627 \n",
      "acc for Psat= 0.1969906090315981 \n",
      "acc for optim= 0.16602594720764605\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.005944353993982077\n",
      "Loss on test= 0.007386258337646723\n",
      "acc for Lsat= 0.16736965115882502 \n",
      "acc for Psat= 0.20779249845759667 \n",
      "acc for optim= 0.175603164287597\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.006113545037806034\n",
      "Loss on test= 0.007261150516569614\n",
      "acc for Lsat= 0.16354117124650597 \n",
      "acc for Psat= 0.20427395119484454 \n",
      "acc for optim= 0.1665173845039299\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.006014347076416016\n",
      "Loss on test= 0.007445647846907377\n",
      "acc for Lsat= 0.15726153119667585 \n",
      "acc for Psat= 0.1933246956456865 \n",
      "acc for optim= 0.16252187703259968\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.00594725739210844\n",
      "Loss on test= 0.007674049120396376\n",
      "acc for Lsat= 0.14638007064278383 \n",
      "acc for Psat= 0.21299632505440252 \n",
      "acc for optim= 0.16810648678687448\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.005814950447529554\n",
      "Loss on test= 0.007176471874117851\n",
      "acc for Lsat= 0.16861753944540397 \n",
      "acc for Psat= 0.20502741640294353 \n",
      "acc for optim= 0.16511738986066984\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.005766628310084343\n",
      "Loss on test= 0.007345182355493307\n",
      "acc for Lsat= 0.15716151476546178 \n",
      "acc for Psat= 0.22635305766226174 \n",
      "acc for optim= 0.1727806463537043\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.0061602238565683365\n",
      "Loss on test= 0.007233579643070698\n",
      "acc for Lsat= 0.16891763568970328 \n",
      "acc for Psat= 0.19931108472777195 \n",
      "acc for optim= 0.164522601975859\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.0058235349133610725\n",
      "Loss on test= 0.006984497886151075\n",
      "acc for Lsat= 0.15381781100677175 \n",
      "acc for Psat= 0.19396459830192025 \n",
      "acc for optim= 0.16450629525008748\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.006204778328537941\n",
      "Loss on test= 0.0073335254564881325\n",
      "acc for Lsat= 0.16039496627049407 \n",
      "acc for Psat= 0.19557455944691282 \n",
      "acc for optim= 0.16479555410621033\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.006216393783688545\n",
      "Loss on test= 0.007469414733350277\n",
      "acc for Lsat= 0.16848975197606736 \n",
      "acc for Psat= 0.19516267603526624 \n",
      "acc for optim= 0.16051685288109527\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.00588743481785059\n",
      "Loss on test= 0.007265194319188595\n",
      "acc for Lsat= 0.16646750204982694 \n",
      "acc for Psat= 0.20961615550389026 \n",
      "acc for optim= 0.16018108604175274\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.0058571044355630875\n",
      "Loss on test= 0.007752174511551857\n",
      "acc for Lsat= 0.1557567058413549 \n",
      "acc for Psat= 0.19513652812175217 \n",
      "acc for optim= 0.16941322328009428\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.005885030142962933\n",
      "Loss on test= 0.007379956543445587\n",
      "acc for Lsat= 0.1601727038228762 \n",
      "acc for Psat= 0.19834725398829847 \n",
      "acc for optim= 0.16842619855353821\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.0058270469307899475\n",
      "Loss on test= 0.007748442701995373\n",
      "acc for Lsat= 0.15231156131161042 \n",
      "acc for Psat= 0.19961259926585329 \n",
      "acc for optim= 0.16430272342385266\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.005990836303681135\n",
      "Loss on test= 0.007039512507617474\n",
      "acc for Lsat= 0.16196312983844766 \n",
      "acc for Psat= 0.19537892005063753 \n",
      "acc for optim= 0.16575293206403674\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.005983974784612656\n",
      "Loss on test= 0.007561031728982925\n",
      "acc for Lsat= 0.14848309333634668 \n",
      "acc for Psat= 0.19229306849215913 \n",
      "acc for optim= 0.16113461785487923\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.006418147590011358\n",
      "Loss on test= 0.007984663359820843\n",
      "acc for Lsat= 0.15647755569308905 \n",
      "acc for Psat= 0.20370513383035746 \n",
      "acc for optim= 0.1676491802184247\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.0059951902367174625\n",
      "Loss on test= 0.007879734970629215\n",
      "acc for Lsat= 0.1607645520688508 \n",
      "acc for Psat= 0.20494634969697667 \n",
      "acc for optim= 0.1686642760594116\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.005898153875023127\n",
      "Loss on test= 0.0076287658885121346\n",
      "acc for Lsat= 0.1607617446019116 \n",
      "acc for Psat= 0.19416117854950735 \n",
      "acc for optim= 0.1626881618346622\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.0057829697616398335\n",
      "Loss on test= 0.0074156285263597965\n",
      "acc for Lsat= 0.1441674853233381 \n",
      "acc for Psat= 0.19310931712021617 \n",
      "acc for optim= 0.16741108078982864\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.00622462946921587\n",
      "Loss on test= 0.007329212035983801\n",
      "acc for Lsat= 0.14965143381946217 \n",
      "acc for Psat= 0.2127115902002351 \n",
      "acc for optim= 0.17506737604963432\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.005828609690070152\n",
      "Loss on test= 0.0077835144475102425\n",
      "acc for Lsat= 0.1729769471085897 \n",
      "acc for Psat= 0.21412241428128642 \n",
      "acc for optim= 0.15969851851371714\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.005714069586247206\n",
      "Loss on test= 0.0073888543993234634\n",
      "acc for Lsat= 0.16166401732575575 \n",
      "acc for Psat= 0.1928244014795427 \n",
      "acc for optim= 0.1620485735978439\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.005753785837441683\n",
      "Loss on test= 0.0077541787177324295\n",
      "acc for Lsat= 0.1661784243720324 \n",
      "acc for Psat= 0.19057128913827948 \n",
      "acc for optim= 0.16701569634882854\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.005529933143407106\n",
      "Loss on test= 0.007152684032917023\n",
      "acc for Lsat= 0.1660696480652226 \n",
      "acc for Psat= 0.20821193430236862 \n",
      "acc for optim= 0.16351172249615345\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.005838800687342882\n",
      "Loss on test= 0.007484864443540573\n",
      "acc for Lsat= 0.15725318984077008 \n",
      "acc for Psat= 0.20003826710410783 \n",
      "acc for optim= 0.1590242308547308\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.0058585526421666145\n",
      "Loss on test= 0.007539866492152214\n",
      "acc for Lsat= 0.15225182990505376 \n",
      "acc for Psat= 0.20355432899821488 \n",
      "acc for optim= 0.16668272581291155\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.005792312789708376\n",
      "Loss on test= 0.007547460496425629\n",
      "acc for Lsat= 0.15097094642711215 \n",
      "acc for Psat= 0.20479402755531215 \n",
      "acc for optim= 0.16827475784396886\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.006455333437770605\n",
      "Loss on test= 0.006961681880056858\n",
      "acc for Lsat= 0.15688129956528665 \n",
      "acc for Psat= 0.18727374750506284 \n",
      "acc for optim= 0.16676569568779565\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.005985512863844633\n",
      "Loss on test= 0.007305010687559843\n",
      "acc for Lsat= 0.16223667623402674 \n",
      "acc for Psat= 0.21507913545403842 \n",
      "acc for optim= 0.16385728508829459\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.005663878750056028\n",
      "Loss on test= 0.007671548519283533\n",
      "acc for Lsat= 0.17663775973251475 \n",
      "acc for Psat= 0.19640854645585337 \n",
      "acc for optim= 0.16118117648779917\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.006068202201277018\n",
      "Loss on test= 0.007376920431852341\n",
      "acc for Lsat= 0.15586081062955018 \n",
      "acc for Psat= 0.20400514097609482 \n",
      "acc for optim= 0.1652843131973851\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.005738396663218737\n",
      "Loss on test= 0.007407178170979023\n",
      "acc for Lsat= 0.15130436370210326 \n",
      "acc for Psat= 0.19305315562644373 \n",
      "acc for optim= 0.1640455730824319\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.005771069321781397\n",
      "Loss on test= 0.00726085901260376\n",
      "acc for Lsat= 0.15112794298224427 \n",
      "acc for Psat= 0.19656192271447298 \n",
      "acc for optim= 0.16627625569464546\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.0059909517876803875\n",
      "Loss on test= 0.007600178476423025\n",
      "acc for Lsat= 0.14977785867341167 \n",
      "acc for Psat= 0.19990574825983531 \n",
      "acc for optim= 0.1688062248823088\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.006245055235922337\n",
      "Loss on test= 0.007416261825710535\n",
      "acc for Lsat= 0.17292567553031105 \n",
      "acc for Psat= 0.218082842689206 \n",
      "acc for optim= 0.16424422915395134\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.005950520746409893\n",
      "Loss on test= 0.007242895197123289\n",
      "acc for Lsat= 0.1590140535870231 \n",
      "acc for Psat= 0.21085851595548102 \n",
      "acc for optim= 0.16832314596900746\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.005713875871151686\n",
      "Loss on test= 0.007441884372383356\n",
      "acc for Lsat= 0.1615445221867794 \n",
      "acc for Psat= 0.1999675408344464 \n",
      "acc for optim= 0.16641579174706675\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.005862757563591003\n",
      "Loss on test= 0.007129170466214418\n",
      "acc for Lsat= 0.15909042563632925 \n",
      "acc for Psat= 0.21146521367453283 \n",
      "acc for optim= 0.16904700308538148\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.005936379078775644\n",
      "Loss on test= 0.007252315059304237\n",
      "acc for Lsat= 0.15489367290579362 \n",
      "acc for Psat= 0.1932838677600423 \n",
      "acc for optim= 0.16730809706763258\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.005828247405588627\n",
      "Loss on test= 0.00713634816929698\n",
      "acc for Lsat= 0.15257167901507898 \n",
      "acc for Psat= 0.185088862769008 \n",
      "acc for optim= 0.16062305511899108\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.005887064151465893\n",
      "Loss on test= 0.007526030298322439\n",
      "acc for Lsat= 0.1551127095975852 \n",
      "acc for Psat= 0.1966251410093525 \n",
      "acc for optim= 0.16401752066592395\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.00579569349065423\n",
      "Loss on test= 0.007178307510912418\n",
      "acc for Lsat= 0.15162820843292676 \n",
      "acc for Psat= 0.19335441557293545 \n",
      "acc for optim= 0.16390763592875762\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.005794980563223362\n",
      "Loss on test= 0.007596840616315603\n",
      "acc for Lsat= 0.15414569690605515 \n",
      "acc for Psat= 0.21066157819834905 \n",
      "acc for optim= 0.1596484495407747\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.005901814438402653\n",
      "Loss on test= 0.0077766901813447475\n",
      "acc for Lsat= 0.1558910636882084 \n",
      "acc for Psat= 0.20507955910641792 \n",
      "acc for optim= 0.1654302505493836\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.005894242320209742\n",
      "Loss on test= 0.0075649903155863285\n",
      "acc for Lsat= 0.1518163947754214 \n",
      "acc for Psat= 0.20202950549456977 \n",
      "acc for optim= 0.15860446577769566\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.005826886743307114\n",
      "Loss on test= 0.007224294822663069\n",
      "acc for Lsat= 0.1572015805242938 \n",
      "acc for Psat= 0.20083904973341946 \n",
      "acc for optim= 0.16295032447364302\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.005873491056263447\n",
      "Loss on test= 0.00708256708458066\n",
      "acc for Lsat= 0.15514260928116005 \n",
      "acc for Psat= 0.19915265648225733 \n",
      "acc for optim= 0.17002008452192788\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.005675740074366331\n",
      "Loss on test= 0.007438905071467161\n",
      "acc for Lsat= 0.15402930396958253 \n",
      "acc for Psat= 0.2008271867621186 \n",
      "acc for optim= 0.16184344667727585\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.00571983540430665\n",
      "Loss on test= 0.007588718086481094\n",
      "acc for Lsat= 0.1483954634082305 \n",
      "acc for Psat= 0.19594746206077884 \n",
      "acc for optim= 0.1661585908472828\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.005611819680780172\n",
      "Loss on test= 0.007104876916855574\n",
      "acc for Lsat= 0.15358277803610632 \n",
      "acc for Psat= 0.2108799418501535 \n",
      "acc for optim= 0.16819625236590194\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.005732180550694466\n",
      "Loss on test= 0.0077441236935555935\n",
      "acc for Lsat= 0.14529296513885398 \n",
      "acc for Psat= 0.19117858109281963 \n",
      "acc for optim= 0.16213128116844436\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.006781711243093014\n",
      "Loss on test= 0.0070449891500175\n",
      "acc for Lsat= 0.15727985561920757 \n",
      "acc for Psat= 0.20157493936426588 \n",
      "acc for optim= 0.16994083644974917\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.0058634597808122635\n",
      "Loss on test= 0.006694707088172436\n",
      "acc for Lsat= 0.17354554635292246 \n",
      "acc for Psat= 0.19614890375955615 \n",
      "acc for optim= 0.16704710258216765\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.005783145781606436\n",
      "Loss on test= 0.007302567362785339\n",
      "acc for Lsat= 0.15620733155720087 \n",
      "acc for Psat= 0.19877416058854996 \n",
      "acc for optim= 0.16479192840824758\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.005971564911305904\n",
      "Loss on test= 0.007088826037943363\n",
      "acc for Lsat= 0.1503765365808294 \n",
      "acc for Psat= 0.19457315766905267 \n",
      "acc for optim= 0.17402403011925702\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.006331183016300201\n",
      "Loss on test= 0.007828040048480034\n",
      "acc for Lsat= 0.15887879611531627 \n",
      "acc for Psat= 0.19663876809988964 \n",
      "acc for optim= 0.169467905895941\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.005740409716963768\n",
      "Loss on test= 0.007401299197226763\n",
      "acc for Lsat= 0.15647185045699055 \n",
      "acc for Psat= 0.20084148854337877 \n",
      "acc for optim= 0.1684643035662956\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.005886268336325884\n",
      "Loss on test= 0.007450821343809366\n",
      "acc for Lsat= 0.16101755550709462 \n",
      "acc for Psat= 0.21068344789492272 \n",
      "acc for optim= 0.16447427102343606\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.005970554891973734\n",
      "Loss on test= 0.007893105037510395\n",
      "acc for Lsat= 0.16537747932147123 \n",
      "acc for Psat= 0.19035165487196046 \n",
      "acc for optim= 0.16655990774857765\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.006126990541815758\n",
      "Loss on test= 0.007037561386823654\n",
      "acc for Lsat= 0.16095447545741365 \n",
      "acc for Psat= 0.19016879466276418 \n",
      "acc for optim= 0.15733805084450755\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.005709543824195862\n",
      "Loss on test= 0.00733414338901639\n",
      "acc for Lsat= 0.1528313635428604 \n",
      "acc for Psat= 0.20311542422363732 \n",
      "acc for optim= 0.16649913709528638\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.0056847017258405685\n",
      "Loss on test= 0.00730222649872303\n",
      "acc for Lsat= 0.14418498394957394 \n",
      "acc for Psat= 0.20216065659932028 \n",
      "acc for optim= 0.1653014019534343\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.005719064734876156\n",
      "Loss on test= 0.007705727592110634\n",
      "acc for Lsat= 0.14984957592258397 \n",
      "acc for Psat= 0.19358405519895194 \n",
      "acc for optim= 0.1695329779121628\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.005733969621360302\n",
      "Loss on test= 0.007048035506159067\n",
      "acc for Lsat= 0.174936459003566 \n",
      "acc for Psat= 0.1925552686267975 \n",
      "acc for optim= 0.15968394363795207\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.005688562523573637\n",
      "Loss on test= 0.007471924182027578\n",
      "acc for Lsat= 0.16427939675221617 \n",
      "acc for Psat= 0.21247765827832407 \n",
      "acc for optim= 0.15818870276886374\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.006143387872725725\n",
      "Loss on test= 0.007269452791661024\n",
      "acc for Lsat= 0.15875289486415806 \n",
      "acc for Psat= 0.18399506844961863 \n",
      "acc for optim= 0.162297288558568\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.006237192079424858\n",
      "Loss on test= 0.00798823032528162\n",
      "acc for Lsat= 0.15883999212633543 \n",
      "acc for Psat= 0.21093937473211316 \n",
      "acc for optim= 0.16518454557040432\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.005670512095093727\n",
      "Loss on test= 0.007130719721317291\n",
      "acc for Lsat= 0.16106562574563899 \n",
      "acc for Psat= 0.2125580905913757 \n",
      "acc for optim= 0.15992067860874545\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.006029665935784578\n",
      "Loss on test= 0.007306452374905348\n",
      "acc for Lsat= 0.1568734118199439 \n",
      "acc for Psat= 0.19564536343687444 \n",
      "acc for optim= 0.16683726411992225\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.005995397921651602\n",
      "Loss on test= 0.007262697443366051\n",
      "acc for Lsat= 0.16879583082293526 \n",
      "acc for Psat= 0.21207575307945248 \n",
      "acc for optim= 0.16549780832023406\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.005811531562358141\n",
      "Loss on test= 0.007275446783751249\n",
      "acc for Lsat= 0.15451299847031133 \n",
      "acc for Psat= 0.19119858743172505 \n",
      "acc for optim= 0.16640519244242344\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.005997044965624809\n",
      "Loss on test= 0.007401689887046814\n",
      "acc for Lsat= 0.15970638024651246 \n",
      "acc for Psat= 0.18470253316737084 \n",
      "acc for optim= 0.16682551762157838\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.005846015177667141\n",
      "Loss on test= 0.0073151555843651295\n",
      "acc for Lsat= 0.1614956679910452 \n",
      "acc for Psat= 0.1941525957367734 \n",
      "acc for optim= 0.1631514789603391\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.006206394173204899\n",
      "Loss on test= 0.007143516093492508\n",
      "acc for Lsat= 0.1669768498311598 \n",
      "acc for Psat= 0.20148640669706722 \n",
      "acc for optim= 0.15650322280478757\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.005934401415288448\n",
      "Loss on test= 0.00696511659771204\n",
      "acc for Lsat= 0.1610282301097406 \n",
      "acc for Psat= 0.1864561294923063 \n",
      "acc for optim= 0.16733221380377844\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.006059304811060429\n",
      "Loss on test= 0.007346729282289743\n",
      "acc for Lsat= 0.1540878677365683 \n",
      "acc for Psat= 0.1977135122835743 \n",
      "acc for optim= 0.16480973936334925\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.005578226409852505\n",
      "Loss on test= 0.007309973239898682\n",
      "acc for Lsat= 0.16217801898172063 \n",
      "acc for Psat= 0.1928926818226426 \n",
      "acc for optim= 0.16130885082052746\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.005668186582624912\n",
      "Loss on test= 0.007651492487639189\n",
      "acc for Lsat= 0.15040274496575756 \n",
      "acc for Psat= 0.1970254223149644 \n",
      "acc for optim= 0.16577303789586562\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.005800154525786638\n",
      "Loss on test= 0.007318763993680477\n",
      "acc for Lsat= 0.1551385109140118 \n",
      "acc for Psat= 0.20522679853525974 \n",
      "acc for optim= 0.1688408626789288\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.005967029836028814\n",
      "Loss on test= 0.007196471560746431\n",
      "acc for Lsat= 0.17203707346581992 \n",
      "acc for Psat= 0.21413376178500837 \n",
      "acc for optim= 0.17229844821849838\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.005870013497769833\n",
      "Loss on test= 0.007136229891330004\n",
      "acc for Lsat= 0.16371307945085048 \n",
      "acc for Psat= 0.2044973185430491 \n",
      "acc for optim= 0.17096394880132781\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.005645825061947107\n",
      "Loss on test= 0.007155676372349262\n",
      "acc for Lsat= 0.1434738455386069 \n",
      "acc for Psat= 0.2029620146292756 \n",
      "acc for optim= 0.1721749265304171\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.0057004718109965324\n",
      "Loss on test= 0.007538143545389175\n",
      "acc for Lsat= 0.16850570522665742 \n",
      "acc for Psat= 0.18814860128651595 \n",
      "acc for optim= 0.16827779971859913\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.005783480126410723\n",
      "Loss on test= 0.0075178202241659164\n",
      "acc for Lsat= 0.1502787417339993 \n",
      "acc for Psat= 0.19723633424384657 \n",
      "acc for optim= 0.16652757165587095\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.005593050736933947\n",
      "Loss on test= 0.007494691759347916\n",
      "acc for Lsat= 0.1522110577817762 \n",
      "acc for Psat= 0.20231275808268426 \n",
      "acc for optim= 0.1662909606515075\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.006038458552211523\n",
      "Loss on test= 0.007796295918524265\n",
      "acc for Lsat= 0.1535182869596193 \n",
      "acc for Psat= 0.18570220265461163 \n",
      "acc for optim= 0.1635017819150368\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.005826147738844156\n",
      "Loss on test= 0.007594822905957699\n",
      "acc for Lsat= 0.16026668047258577 \n",
      "acc for Psat= 0.2105410469777989 \n",
      "acc for optim= 0.1580532983664927\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.005511402152478695\n",
      "Loss on test= 0.007616409100592136\n",
      "acc for Lsat= 0.14752787213684745 \n",
      "acc for Psat= 0.20415878171095486 \n",
      "acc for optim= 0.167406229950396\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.005794447846710682\n",
      "Loss on test= 0.007511890958994627\n",
      "acc for Lsat= 0.16100979673067398 \n",
      "acc for Psat= 0.20851528863265126 \n",
      "acc for optim= 0.16763612378872197\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.005991042125970125\n",
      "Loss on test= 0.007258311845362186\n",
      "acc for Lsat= 0.1618954552158133 \n",
      "acc for Psat= 0.19832831211273605 \n",
      "acc for optim= 0.16514328129381536\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.005636072717607021\n",
      "Loss on test= 0.007721854839473963\n",
      "acc for Lsat= 0.15831913005762932 \n",
      "acc for Psat= 0.20103829862706393 \n",
      "acc for optim= 0.16984737111507442\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.0057274047285318375\n",
      "Loss on test= 0.007223461288958788\n",
      "acc for Lsat= 0.15572038430811935 \n",
      "acc for Psat= 0.18886466837243834 \n",
      "acc for optim= 0.1676677795756822\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.006004403345286846\n",
      "Loss on test= 0.007267058361321688\n",
      "acc for Lsat= 0.15780220752043772 \n",
      "acc for Psat= 0.21493573949842135 \n",
      "acc for optim= 0.17623292562040332\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.005946246907114983\n",
      "Loss on test= 0.0071117207407951355\n",
      "acc for Lsat= 0.1528251208985209 \n",
      "acc for Psat= 0.18878695740417928 \n",
      "acc for optim= 0.16268073023749194\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.005589064676314592\n",
      "Loss on test= 0.007013700902462006\n",
      "acc for Lsat= 0.162657866405012 \n",
      "acc for Psat= 0.1977488801044557 \n",
      "acc for optim= 0.16401271516930496\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.005849730223417282\n",
      "Loss on test= 0.007572815287858248\n",
      "acc for Lsat= 0.15418584254679088 \n",
      "acc for Psat= 0.19616914896970064 \n",
      "acc for optim= 0.16243868275053158\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.005631596315652132\n",
      "Loss on test= 0.0070136734284460545\n",
      "acc for Lsat= 0.1485357769897597 \n",
      "acc for Psat= 0.2132028902838146 \n",
      "acc for optim= 0.16770311834546595\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.005542374216020107\n",
      "Loss on test= 0.006902605760842562\n",
      "acc for Lsat= 0.16136869159708425 \n",
      "acc for Psat= 0.19596956523865763 \n",
      "acc for optim= 0.1678526551603935\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.00556608522310853\n",
      "Loss on test= 0.007497915532439947\n",
      "acc for Lsat= 0.1573585161367206 \n",
      "acc for Psat= 0.20602409775382227 \n",
      "acc for optim= 0.16365014660242777\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.005743716843426228\n",
      "Loss on test= 0.007510927971452475\n",
      "acc for Lsat= 0.15633648745830125 \n",
      "acc for Psat= 0.20587382653191855 \n",
      "acc for optim= 0.1668098705836007\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.005636010784655809\n",
      "Loss on test= 0.007428610697388649\n",
      "acc for Lsat= 0.15550999419069964 \n",
      "acc for Psat= 0.19535847879243923 \n",
      "acc for optim= 0.17045829011600647\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.005598547402769327\n",
      "Loss on test= 0.00705644441768527\n",
      "acc for Lsat= 0.1475833237247511 \n",
      "acc for Psat= 0.17112378433050224 \n",
      "acc for optim= 0.160853815697645\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.006008388474583626\n",
      "Loss on test= 0.0070516555570065975\n",
      "acc for Lsat= 0.14979580797629094 \n",
      "acc for Psat= 0.19933811024472606 \n",
      "acc for optim= 0.16079355016380328\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.005749712698161602\n",
      "Loss on test= 0.007251546252518892\n",
      "acc for Lsat= 0.15569576483151157 \n",
      "acc for Psat= 0.20512420190879924 \n",
      "acc for optim= 0.16998422500929322\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.0058477092534303665\n",
      "Loss on test= 0.00750834820792079\n",
      "acc for Lsat= 0.16729295236902067 \n",
      "acc for Psat= 0.20666929091246738 \n",
      "acc for optim= 0.1546127165217319\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.005964588839560747\n",
      "Loss on test= 0.007233398500829935\n",
      "acc for Lsat= 0.15001486805763828 \n",
      "acc for Psat= 0.18765413740937995 \n",
      "acc for optim= 0.1730876884622629\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.006097387056797743\n",
      "Loss on test= 0.006926544476300478\n",
      "acc for Lsat= 0.14357986783696583 \n",
      "acc for Psat= 0.20106791298851737 \n",
      "acc for optim= 0.17152503661231183\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.005879437550902367\n",
      "Loss on test= 0.00736162019893527\n",
      "acc for Lsat= 0.15936751681710135 \n",
      "acc for Psat= 0.18171020680036565 \n",
      "acc for optim= 0.16001046446951672\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.005895849782973528\n",
      "Loss on test= 0.007423285860568285\n",
      "acc for Lsat= 0.15441185025971566 \n",
      "acc for Psat= 0.19456751260397856 \n",
      "acc for optim= 0.1699160550505335\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.006040411535650492\n",
      "Loss on test= 0.007402092684060335\n",
      "acc for Lsat= 0.1733754010407777 \n",
      "acc for Psat= 0.21935170578214983 \n",
      "acc for optim= 0.1729090930006589\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.005855188705027103\n",
      "Loss on test= 0.007524781860411167\n",
      "acc for Lsat= 0.14930316148097741 \n",
      "acc for Psat= 0.19196205596910926 \n",
      "acc for optim= 0.16409027619653793\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.006279091350734234\n",
      "Loss on test= 0.007437560707330704\n",
      "acc for Lsat= 0.15853489961543837 \n",
      "acc for Psat= 0.2081054951145636 \n",
      "acc for optim= 0.16211979266410678\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.0060697561129927635\n",
      "Loss on test= 0.007941262796521187\n",
      "acc for Lsat= 0.16054462332247002 \n",
      "acc for Psat= 0.19082396043594316 \n",
      "acc for optim= 0.17255287469349434\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.005847338121384382\n",
      "Loss on test= 0.0070589808747172356\n",
      "acc for Lsat= 0.16042085406265497 \n",
      "acc for Psat= 0.19927162108748442 \n",
      "acc for optim= 0.16075783880812985\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.005631749052554369\n",
      "Loss on test= 0.0074251205660402775\n",
      "acc for Lsat= 0.143514304410296 \n",
      "acc for Psat= 0.20804133803419556 \n",
      "acc for optim= 0.16167616545695995\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.005658323876559734\n",
      "Loss on test= 0.007450450677424669\n",
      "acc for Lsat= 0.15977877613937588 \n",
      "acc for Psat= 0.20051619775896723 \n",
      "acc for optim= 0.1706179401814388\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.0058165960945189\n",
      "Loss on test= 0.007273258175700903\n",
      "acc for Lsat= 0.17490503602894023 \n",
      "acc for Psat= 0.21415007197084363 \n",
      "acc for optim= 0.16765810123732558\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.005666637327522039\n",
      "Loss on test= 0.0068059805780649185\n",
      "acc for Lsat= 0.1612000121827119 \n",
      "acc for Psat= 0.20853804443298732 \n",
      "acc for optim= 0.16851297000739876\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.00568268122151494\n",
      "Loss on test= 0.007831605151295662\n",
      "acc for Lsat= 0.1644422587531153 \n",
      "acc for Psat= 0.18900553790745556 \n",
      "acc for optim= 0.17070103468388687\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.005908934865146875\n",
      "Loss on test= 0.007367638871073723\n",
      "acc for Lsat= 0.15917772358497145 \n",
      "acc for Psat= 0.19459709311018653 \n",
      "acc for optim= 0.17025867490647514\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.005912089254707098\n",
      "Loss on test= 0.007213021162897348\n",
      "acc for Lsat= 0.1611791834796275 \n",
      "acc for Psat= 0.203027358195233 \n",
      "acc for optim= 0.1658177564141997\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.005810263566672802\n",
      "Loss on test= 0.007189161144196987\n",
      "acc for Lsat= 0.14494878108905185 \n",
      "acc for Psat= 0.20249181846242598 \n",
      "acc for optim= 0.16261659525811947\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.005609224084764719\n",
      "Loss on test= 0.007555545773357153\n",
      "acc for Lsat= 0.15757694217914595 \n",
      "acc for Psat= 0.19752816943543366 \n",
      "acc for optim= 0.1599664249028018\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.005890415981411934\n",
      "Loss on test= 0.007372252643108368\n",
      "acc for Lsat= 0.15981420009496208 \n",
      "acc for Psat= 0.22721413375435734 \n",
      "acc for optim= 0.16445996673342572\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.005968901328742504\n",
      "Loss on test= 0.0074041117914021015\n",
      "acc for Lsat= 0.15430211921739698 \n",
      "acc for Psat= 0.20854665593198332 \n",
      "acc for optim= 0.16640997036459443\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.00623620068654418\n",
      "Loss on test= 0.007410046178847551\n",
      "acc for Lsat= 0.172177266692132 \n",
      "acc for Psat= 0.1813016532209404 \n",
      "acc for optim= 0.16817705036049374\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.005824348423629999\n",
      "Loss on test= 0.00769452890381217\n",
      "acc for Lsat= 0.15449412330759874 \n",
      "acc for Psat= 0.19908464933596703 \n",
      "acc for optim= 0.16926146534492917\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.005520781502127647\n",
      "Loss on test= 0.007231904659420252\n",
      "acc for Lsat= 0.15840342142676447 \n",
      "acc for Psat= 0.20390588318257302 \n",
      "acc for optim= 0.15701321873290952\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.00568510964512825\n",
      "Loss on test= 0.006842968985438347\n",
      "acc for Lsat= 0.1452755079564608 \n",
      "acc for Psat= 0.19529641382167207 \n",
      "acc for optim= 0.16269066784078576\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.005894009955227375\n",
      "Loss on test= 0.007493107579648495\n",
      "acc for Lsat= 0.14931259978773476 \n",
      "acc for Psat= 0.18538893980306162 \n",
      "acc for optim= 0.17056609786203375\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.005751757882535458\n",
      "Loss on test= 0.007772487122565508\n",
      "acc for Lsat= 0.15058063584624135 \n",
      "acc for Psat= 0.19581565662348246 \n",
      "acc for optim= 0.1648000999204967\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.005491573829203844\n",
      "Loss on test= 0.007313637528568506\n",
      "acc for Lsat= 0.16000643927054328 \n",
      "acc for Psat= 0.22099656036555898 \n",
      "acc for optim= 0.1716970392884534\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.005529690999537706\n",
      "Loss on test= 0.0070874691009521484\n",
      "acc for Lsat= 0.15132392012059964 \n",
      "acc for Psat= 0.19259967542564513 \n",
      "acc for optim= 0.16412600283911757\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.005661995615810156\n",
      "Loss on test= 0.007575222756713629\n",
      "acc for Lsat= 0.16452335661561535 \n",
      "acc for Psat= 0.18829659440508875 \n",
      "acc for optim= 0.16476653298860716\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.005622034892439842\n",
      "Loss on test= 0.007522557396441698\n",
      "acc for Lsat= 0.15745886043553836 \n",
      "acc for Psat= 0.20775146965074856 \n",
      "acc for optim= 0.16175637770268578\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.005606483668088913\n",
      "Loss on test= 0.007548426743596792\n",
      "acc for Lsat= 0.1485342099837058 \n",
      "acc for Psat= 0.19325616218912564 \n",
      "acc for optim= 0.1640055795681098\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.005781278014183044\n",
      "Loss on test= 0.006853834725916386\n",
      "acc for Lsat= 0.17577306340767268 \n",
      "acc for Psat= 0.20776114750607702 \n",
      "acc for optim= 0.16176688263419878\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.005665854550898075\n",
      "Loss on test= 0.007185311987996101\n",
      "acc for Lsat= 0.14013978363831572 \n",
      "acc for Psat= 0.19884112711659954 \n",
      "acc for optim= 0.16426267113354875\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.005663986783474684\n",
      "Loss on test= 0.007454289123415947\n",
      "acc for Lsat= 0.16075702540606993 \n",
      "acc for Psat= 0.19109944369659193 \n",
      "acc for optim= 0.1651784570880051\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.0059023960493505\n",
      "Loss on test= 0.007832608185708523\n",
      "acc for Lsat= 0.14848274291184307 \n",
      "acc for Psat= 0.1908892067752351 \n",
      "acc for optim= 0.1663011591342347\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.005743115674704313\n",
      "Loss on test= 0.007086497265845537\n",
      "acc for Lsat= 0.1630655846230258 \n",
      "acc for Psat= 0.18576039919003723 \n",
      "acc for optim= 0.16746877402919544\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.005498033482581377\n",
      "Loss on test= 0.0075135366059839725\n",
      "acc for Lsat= 0.15737660304398932 \n",
      "acc for Psat= 0.19782361698019144 \n",
      "acc for optim= 0.15896182306813167\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.005722210742533207\n",
      "Loss on test= 0.007145858369767666\n",
      "acc for Lsat= 0.15881081548229348 \n",
      "acc for Psat= 0.20771819243265305 \n",
      "acc for optim= 0.16714514590390447\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.005626729689538479\n",
      "Loss on test= 0.00754421716555953\n",
      "acc for Lsat= 0.1496280459299699 \n",
      "acc for Psat= 0.18250175504811628 \n",
      "acc for optim= 0.16178405972304524\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.0056115128099918365\n",
      "Loss on test= 0.007586524356156588\n",
      "acc for Lsat= 0.1492171091296649 \n",
      "acc for Psat= 0.19752228871774172 \n",
      "acc for optim= 0.16496886597568414\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.005505314562469721\n",
      "Loss on test= 0.0076710074208676815\n",
      "acc for Lsat= 0.16491602968813882 \n",
      "acc for Psat= 0.2021483927760006 \n",
      "acc for optim= 0.16633485029146197\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.005909896455705166\n",
      "Loss on test= 0.007298257667571306\n",
      "acc for Lsat= 0.17007059112423076 \n",
      "acc for Psat= 0.20082575367075642 \n",
      "acc for optim= 0.1710134606254974\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.005731998477131128\n",
      "Loss on test= 0.007530063856393099\n",
      "acc for Lsat= 0.14236659855490214 \n",
      "acc for Psat= 0.1910367146849806 \n",
      "acc for optim= 0.1647918054453273\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.005468047223985195\n",
      "Loss on test= 0.00754966726526618\n",
      "acc for Lsat= 0.15798764783806993 \n",
      "acc for Psat= 0.1973136407210583 \n",
      "acc for optim= 0.16973318560735978\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.005708091426640749\n",
      "Loss on test= 0.007322484161704779\n",
      "acc for Lsat= 0.1603554784938632 \n",
      "acc for Psat= 0.2099971028220397 \n",
      "acc for optim= 0.16620229967143654\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.005576141178607941\n",
      "Loss on test= 0.006981140002608299\n",
      "acc for Lsat= 0.15597222565722674 \n",
      "acc for Psat= 0.20004777950497124 \n",
      "acc for optim= 0.16545846058154998\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.0057871900498867035\n",
      "Loss on test= 0.0073026749305427074\n",
      "acc for Lsat= 0.157482703473251 \n",
      "acc for Psat= 0.20923679969698136 \n",
      "acc for optim= 0.1672185278734284\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.005647546611726284\n",
      "Loss on test= 0.007033296395093203\n",
      "acc for Lsat= 0.1727540533646863 \n",
      "acc for Psat= 0.2009933105479071 \n",
      "acc for optim= 0.16747428257529792\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.00609893724322319\n",
      "Loss on test= 0.0080629987642169\n",
      "acc for Lsat= 0.15468617885251393 \n",
      "acc for Psat= 0.20381588151174612 \n",
      "acc for optim= 0.1646675978691821\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.005737511906772852\n",
      "Loss on test= 0.007292223162949085\n",
      "acc for Lsat= 0.17087217299692278 \n",
      "acc for Psat= 0.20217330392027136 \n",
      "acc for optim= 0.16320118626329636\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.00575519073754549\n",
      "Loss on test= 0.006927843671292067\n",
      "acc for Lsat= 0.16077617252127221 \n",
      "acc for Psat= 0.2014675328424644 \n",
      "acc for optim= 0.16295334519436735\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.005944834556430578\n",
      "Loss on test= 0.007183995097875595\n",
      "acc for Lsat= 0.15588048479641925 \n",
      "acc for Psat= 0.20810146510607486 \n",
      "acc for optim= 0.1679422524223318\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.005571698769927025\n",
      "Loss on test= 0.007277422118932009\n",
      "acc for Lsat= 0.16153080997006686 \n",
      "acc for Psat= 0.1869520040860659 \n",
      "acc for optim= 0.1666428137372141\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.00581866130232811\n",
      "Loss on test= 0.007232266012579203\n",
      "acc for Lsat= 0.15970351499501523 \n",
      "acc for Psat= 0.19079210924625886 \n",
      "acc for optim= 0.1655332431055166\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.005889460910111666\n",
      "Loss on test= 0.0069511327892541885\n",
      "acc for Lsat= 0.15173346960617012 \n",
      "acc for Psat= 0.18725586934396846 \n",
      "acc for optim= 0.16773650864803338\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.005693227984011173\n",
      "Loss on test= 0.007252411916851997\n",
      "acc for Lsat= 0.1553289159032188 \n",
      "acc for Psat= 0.19046751661187986 \n",
      "acc for optim= 0.16637885662432203\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.006057158578187227\n",
      "Loss on test= 0.007359692361205816\n",
      "acc for Lsat= 0.15652092648269303 \n",
      "acc for Psat= 0.20210253500310918 \n",
      "acc for optim= 0.16794064573096265\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.0059051900170743465\n",
      "Loss on test= 0.007452036254107952\n",
      "acc for Lsat= 0.16123393437535058 \n",
      "acc for Psat= 0.20837269490871 \n",
      "acc for optim= 0.17342535385339078\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.005532869137823582\n",
      "Loss on test= 0.00787807535380125\n",
      "acc for Lsat= 0.1632803708810615 \n",
      "acc for Psat= 0.20239010745054492 \n",
      "acc for optim= 0.1659517482582472\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.005471805110573769\n",
      "Loss on test= 0.006988555658608675\n",
      "acc for Lsat= 0.15196434491739577 \n",
      "acc for Psat= 0.20135054458925103 \n",
      "acc for optim= 0.16554552042316723\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.005545377265661955\n",
      "Loss on test= 0.007276243530213833\n",
      "acc for Lsat= 0.14944952383988583 \n",
      "acc for Psat= 0.19904477018873698 \n",
      "acc for optim= 0.16966504884643296\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.005912824533879757\n",
      "Loss on test= 0.007776133716106415\n",
      "acc for Lsat= 0.15679215345394293 \n",
      "acc for Psat= 0.2092983255422384 \n",
      "acc for optim= 0.17258825939812805\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.005872725043445826\n",
      "Loss on test= 0.006896375212818384\n",
      "acc for Lsat= 0.161249023148519 \n",
      "acc for Psat= 0.20071518988314907 \n",
      "acc for optim= 0.17495190672318547\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.0057198358699679375\n",
      "Loss on test= 0.007423589937388897\n",
      "acc for Lsat= 0.1642438626489373 \n",
      "acc for Psat= 0.18823439163896807 \n",
      "acc for optim= 0.16332491167971758\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.005937014706432819\n",
      "Loss on test= 0.006822754163295031\n",
      "acc for Lsat= 0.14469777676076476 \n",
      "acc for Psat= 0.19682222657233905 \n",
      "acc for optim= 0.16413327185150817\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.005436162929981947\n",
      "Loss on test= 0.0072135222144424915\n",
      "acc for Lsat= 0.15136940858732875 \n",
      "acc for Psat= 0.1926833498593206 \n",
      "acc for optim= 0.17112851402317708\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.005614134017378092\n",
      "Loss on test= 0.007056878879666328\n",
      "acc for Lsat= 0.15111904262992568 \n",
      "acc for Psat= 0.1886490238016494 \n",
      "acc for optim= 0.16794415897056156\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.005630562547594309\n",
      "Loss on test= 0.007242899853736162\n",
      "acc for Lsat= 0.15530461092094497 \n",
      "acc for Psat= 0.20336582960835733 \n",
      "acc for optim= 0.17108058398293682\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.005942922551184893\n",
      "Loss on test= 0.007284931838512421\n",
      "acc for Lsat= 0.13653570661000664 \n",
      "acc for Psat= 0.19111856075335812 \n",
      "acc for optim= 0.1664859321191678\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.005422026384621859\n",
      "Loss on test= 0.006595022045075893\n",
      "acc for Lsat= 0.16355193536022494 \n",
      "acc for Psat= 0.21942982027745142 \n",
      "acc for optim= 0.16476830023027894\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.00577990896999836\n",
      "Loss on test= 0.007212250493466854\n",
      "acc for Lsat= 0.15141284855156106 \n",
      "acc for Psat= 0.18353197326994364 \n",
      "acc for optim= 0.1689273105553527\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.0056823003105819225\n",
      "Loss on test= 0.007123891729861498\n",
      "acc for Lsat= 0.15610820177053178 \n",
      "acc for Psat= 0.1804543199086348 \n",
      "acc for optim= 0.16740598758400158\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.005492717958986759\n",
      "Loss on test= 0.007224332541227341\n",
      "acc for Lsat= 0.148845293530889 \n",
      "acc for Psat= 0.20116163432659184 \n",
      "acc for optim= 0.16658159908418713\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.005901271477341652\n",
      "Loss on test= 0.007189150899648666\n",
      "acc for Lsat= 0.1598481943193426 \n",
      "acc for Psat= 0.19759559464625648 \n",
      "acc for optim= 0.16537701906215305\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.005437534302473068\n",
      "Loss on test= 0.007470071315765381\n",
      "acc for Lsat= 0.15432250215824633 \n",
      "acc for Psat= 0.20431191269079316 \n",
      "acc for optim= 0.16349817479504503\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.005529148504137993\n",
      "Loss on test= 0.007287671323865652\n",
      "acc for Lsat= 0.1569700624461698 \n",
      "acc for Psat= 0.19254784553758342 \n",
      "acc for optim= 0.16590611867718283\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.005510945804417133\n",
      "Loss on test= 0.00731627969071269\n",
      "acc for Lsat= 0.15090053461932912 \n",
      "acc for Psat= 0.20779121025669633 \n",
      "acc for optim= 0.16861178332545648\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.005871360655874014\n",
      "Loss on test= 0.007759968284517527\n",
      "acc for Lsat= 0.1570270702259073 \n",
      "acc for Psat= 0.19271277170516746 \n",
      "acc for optim= 0.16300024072416355\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.0056714145466685295\n",
      "Loss on test= 0.007283054292201996\n",
      "acc for Lsat= 0.14794981939299223 \n",
      "acc for Psat= 0.18789213530444462 \n",
      "acc for optim= 0.1660160837700728\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.005545455031096935\n",
      "Loss on test= 0.006948397494852543\n",
      "acc for Lsat= 0.16466268308453078 \n",
      "acc for Psat= 0.18361442927652818 \n",
      "acc for optim= 0.16515983300527834\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.0058123585768043995\n",
      "Loss on test= 0.007484335917979479\n",
      "acc for Lsat= 0.15047086764501072 \n",
      "acc for Psat= 0.19539488117386145 \n",
      "acc for optim= 0.16351795105901012\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.005794747732579708\n",
      "Loss on test= 0.007342434022575617\n",
      "acc for Lsat= 0.14487876084224763 \n",
      "acc for Psat= 0.19986148592405265 \n",
      "acc for optim= 0.17587588866905415\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.005591880064457655\n",
      "Loss on test= 0.0071836113929748535\n",
      "acc for Lsat= 0.16302917692557428 \n",
      "acc for Psat= 0.20760740702780972 \n",
      "acc for optim= 0.16224941754089592\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.005772360134869814\n",
      "Loss on test= 0.0072389147244393826\n",
      "acc for Lsat= 0.16058089915437807 \n",
      "acc for Psat= 0.19839317634163547 \n",
      "acc for optim= 0.1729709739216649\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.005839667748659849\n",
      "Loss on test= 0.007955786772072315\n",
      "acc for Lsat= 0.15382701061269055 \n",
      "acc for Psat= 0.19519882861822538 \n",
      "acc for optim= 0.16301077641966585\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.0060004000551998615\n",
      "Loss on test= 0.007669649086892605\n",
      "acc for Lsat= 0.14451841556096878 \n",
      "acc for Psat= 0.1994303642255903 \n",
      "acc for optim= 0.16075713876022343\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.005634180270135403\n",
      "Loss on test= 0.007469230331480503\n",
      "acc for Lsat= 0.15247395961301127 \n",
      "acc for Psat= 0.19734769628915677 \n",
      "acc for optim= 0.17300915705039144\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.005823775194585323\n",
      "Loss on test= 0.007530389819294214\n",
      "acc for Lsat= 0.1669862888944259 \n",
      "acc for Psat= 0.18670735488431986 \n",
      "acc for optim= 0.16869781955420116\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.0055970922112464905\n",
      "Loss on test= 0.007704485207796097\n",
      "acc for Lsat= 0.15132221259514525 \n",
      "acc for Psat= 0.18788487239307572 \n",
      "acc for optim= 0.16003286265560568\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.005569943226873875\n",
      "Loss on test= 0.007033255882561207\n",
      "acc for Lsat= 0.16211100499256376 \n",
      "acc for Psat= 0.19993066254957412 \n",
      "acc for optim= 0.16344463419909666\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.005817442201077938\n",
      "Loss on test= 0.007038740441203117\n",
      "acc for Lsat= 0.1539998536608869 \n",
      "acc for Psat= 0.19449472378588237 \n",
      "acc for optim= 0.16483207891741003\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.005606601480394602\n",
      "Loss on test= 0.007200054358690977\n",
      "acc for Lsat= 0.15846540520509675 \n",
      "acc for Psat= 0.20758760411361019 \n",
      "acc for optim= 0.16588759533851025\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.005709298886358738\n",
      "Loss on test= 0.007502790540456772\n",
      "acc for Lsat= 0.1678453609652695 \n",
      "acc for Psat= 0.19490090234617352 \n",
      "acc for optim= 0.17137540559891276\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.005628623999655247\n",
      "Loss on test= 0.007107781711965799\n",
      "acc for Lsat= 0.15575397292507018 \n",
      "acc for Psat= 0.19819751639867614 \n",
      "acc for optim= 0.1676652926657746\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.0063090696930885315\n",
      "Loss on test= 0.006991895381361246\n",
      "acc for Lsat= 0.15353373070772294 \n",
      "acc for Psat= 0.19723170790139044 \n",
      "acc for optim= 0.1630502916815248\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.00567074166610837\n",
      "Loss on test= 0.00727491220459342\n",
      "acc for Lsat= 0.1525609714187086 \n",
      "acc for Psat= 0.19625812505532178 \n",
      "acc for optim= 0.16173437216269523\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.005959296599030495\n",
      "Loss on test= 0.007361346390098333\n",
      "acc for Lsat= 0.15581967101945757 \n",
      "acc for Psat= 0.18998736999432755 \n",
      "acc for optim= 0.15630722708492464\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.005740003660321236\n",
      "Loss on test= 0.007528459653258324\n",
      "acc for Lsat= 0.15404497069539502 \n",
      "acc for Psat= 0.20233986828324468 \n",
      "acc for optim= 0.1688108236290377\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.006162297446280718\n",
      "Loss on test= 0.007359348237514496\n",
      "acc for Lsat= 0.15978435626421428 \n",
      "acc for Psat= 0.2090799774150135 \n",
      "acc for optim= 0.1669112314246824\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.005882172845304012\n",
      "Loss on test= 0.007814817130565643\n",
      "acc for Lsat= 0.15550769708275824 \n",
      "acc for Psat= 0.20151494515594096 \n",
      "acc for optim= 0.17016120025144746\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.0057570431381464005\n",
      "Loss on test= 0.007372671738266945\n",
      "acc for Lsat= 0.152273423478368 \n",
      "acc for Psat= 0.1888373361743956 \n",
      "acc for optim= 0.16672506938959455\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.005784143228083849\n",
      "Loss on test= 0.007589065004140139\n",
      "acc for Lsat= 0.15825872319277193 \n",
      "acc for Psat= 0.20101446562263442 \n",
      "acc for optim= 0.17249088812771884\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.005589510779827833\n",
      "Loss on test= 0.007084894925355911\n",
      "acc for Lsat= 0.14509971388257834 \n",
      "acc for Psat= 0.20628153225387919 \n",
      "acc for optim= 0.1575583732482733\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.005606485065072775\n",
      "Loss on test= 0.0073898849077522755\n",
      "acc for Lsat= 0.1690378754429775 \n",
      "acc for Psat= 0.21132964879449945 \n",
      "acc for optim= 0.16278649582809074\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.005700134206563234\n",
      "Loss on test= 0.008054579608142376\n",
      "acc for Lsat= 0.1588045946482691 \n",
      "acc for Psat= 0.2054225086943737 \n",
      "acc for optim= 0.16375017724778565\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.005768612027168274\n",
      "Loss on test= 0.0074160234071314335\n",
      "acc for Lsat= 0.15005026226006848 \n",
      "acc for Psat= 0.1982650777056897 \n",
      "acc for optim= 0.16177567123572845\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.0054168193601071835\n",
      "Loss on test= 0.007447080221027136\n",
      "acc for Lsat= 0.1604962601612673 \n",
      "acc for Psat= 0.18654904545493067 \n",
      "acc for optim= 0.16374683652691482\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.0063265301287174225\n",
      "Loss on test= 0.007360135670751333\n",
      "acc for Lsat= 0.15427340256941474 \n",
      "acc for Psat= 0.1829911366788304 \n",
      "acc for optim= 0.16390323807510687\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.0054539283737540245\n",
      "Loss on test= 0.008030327036976814\n",
      "acc for Lsat= 0.15190520967169832 \n",
      "acc for Psat= 0.17570626225034308 \n",
      "acc for optim= 0.16670115181757447\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.005524275358766317\n",
      "Loss on test= 0.007498405873775482\n",
      "acc for Lsat= 0.16869743755583452 \n",
      "acc for Psat= 0.1980963903438485 \n",
      "acc for optim= 0.16225765495681296\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.0056273071095347404\n",
      "Loss on test= 0.0075759198516607285\n",
      "acc for Lsat= 0.16446686445689593 \n",
      "acc for Psat= 0.2125757467531271 \n",
      "acc for optim= 0.1711619811017089\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.005885197781026363\n",
      "Loss on test= 0.00730287516489625\n",
      "acc for Lsat= 0.14970950292868035 \n",
      "acc for Psat= 0.19927235028981308 \n",
      "acc for optim= 0.16985537447302496\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.005666620098054409\n",
      "Loss on test= 0.00731481472030282\n",
      "acc for Lsat= 0.15482177998871566 \n",
      "acc for Psat= 0.1752191871831484 \n",
      "acc for optim= 0.1624575122300589\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.005694277584552765\n",
      "Loss on test= 0.007453782483935356\n",
      "acc for Lsat= 0.16388656834839865 \n",
      "acc for Psat= 0.20577039007425735 \n",
      "acc for optim= 0.16524799541461943\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.005614862777292728\n",
      "Loss on test= 0.007256534416228533\n",
      "acc for Lsat= 0.15253850498769173 \n",
      "acc for Psat= 0.2055895557243484 \n",
      "acc for optim= 0.16730023068757574\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.005898927804082632\n",
      "Loss on test= 0.007067618425935507\n",
      "acc for Lsat= 0.15914495003936416 \n",
      "acc for Psat= 0.20327799871943691 \n",
      "acc for optim= 0.1683975566543074\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.0056531368754804134\n",
      "Loss on test= 0.007082934491336346\n",
      "acc for Lsat= 0.15358251585609844 \n",
      "acc for Psat= 0.19039862442448674 \n",
      "acc for optim= 0.17070898079870606\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.005990654695779085\n",
      "Loss on test= 0.00722764665260911\n",
      "acc for Lsat= 0.1637951357564965 \n",
      "acc for Psat= 0.19069492227749013 \n",
      "acc for optim= 0.16503037414837965\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.00564990658313036\n",
      "Loss on test= 0.007117331027984619\n",
      "acc for Lsat= 0.15815980822233422 \n",
      "acc for Psat= 0.19651580750407865 \n",
      "acc for optim= 0.16734436797104552\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.005599985830485821\n",
      "Loss on test= 0.0070680296048521996\n",
      "acc for Lsat= 0.1485835007246828 \n",
      "acc for Psat= 0.19189243364170744 \n",
      "acc for optim= 0.16566394313169858\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.005609982647001743\n",
      "Loss on test= 0.007321557961404324\n",
      "acc for Lsat= 0.16038008508917526 \n",
      "acc for Psat= 0.18812106395382186 \n",
      "acc for optim= 0.16883246245503913\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.00563214672729373\n",
      "Loss on test= 0.007247858215123415\n",
      "acc for Lsat= 0.15908456126089135 \n",
      "acc for Psat= 0.19688869984095275 \n",
      "acc for optim= 0.17087866600221652\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.005700336303561926\n",
      "Loss on test= 0.007394904736429453\n",
      "acc for Lsat= 0.1680350323295465 \n",
      "acc for Psat= 0.203150281224583 \n",
      "acc for optim= 0.1702712172407134\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.00611288845539093\n",
      "Loss on test= 0.007612223736941814\n",
      "acc for Lsat= 0.16424289945051165 \n",
      "acc for Psat= 0.21286815071257106 \n",
      "acc for optim= 0.1592070407564771\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.005756180267781019\n",
      "Loss on test= 0.007705995813012123\n",
      "acc for Lsat= 0.14966312147572935 \n",
      "acc for Psat= 0.19876607282232248 \n",
      "acc for optim= 0.16733519234446442\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.006046423222869635\n",
      "Loss on test= 0.007475933525711298\n",
      "acc for Lsat= 0.15202933177294697 \n",
      "acc for Psat= 0.20942533798630303 \n",
      "acc for optim= 0.1692671344325435\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.005416275002062321\n",
      "Loss on test= 0.007607902400195599\n",
      "acc for Lsat= 0.1537554671463903 \n",
      "acc for Psat= 0.2020385491284809 \n",
      "acc for optim= 0.16089196070376496\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.005619200877845287\n",
      "Loss on test= 0.007379143964499235\n",
      "acc for Lsat= 0.15403313591912174 \n",
      "acc for Psat= 0.21179969829135503 \n",
      "acc for optim= 0.1728223889550866\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.005701983347535133\n",
      "Loss on test= 0.007148683071136475\n",
      "acc for Lsat= 0.15295202893044677 \n",
      "acc for Psat= 0.20619612533372988 \n",
      "acc for optim= 0.1632468743536041\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.0055000027641654015\n",
      "Loss on test= 0.007328386884182692\n",
      "acc for Lsat= 0.1524680544939045 \n",
      "acc for Psat= 0.20453373030377706 \n",
      "acc for optim= 0.1734421168030316\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.005763496737927198\n",
      "Loss on test= 0.007739601656794548\n",
      "acc for Lsat= 0.1590182419237013 \n",
      "acc for Psat= 0.19655003602555418 \n",
      "acc for optim= 0.16578210655019665\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.005794810596853495\n",
      "Loss on test= 0.007423270493745804\n",
      "acc for Lsat= 0.14585976470834347 \n",
      "acc for Psat= 0.19565323815513097 \n",
      "acc for optim= 0.16452376446648517\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.005798524245619774\n",
      "Loss on test= 0.008213508874177933\n",
      "acc for Lsat= 0.15586174671208014 \n",
      "acc for Psat= 0.1908777540285793 \n",
      "acc for optim= 0.16499639373097558\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.005577157251536846\n",
      "Loss on test= 0.007417522370815277\n",
      "acc for Lsat= 0.14361941064612513 \n",
      "acc for Psat= 0.19519393325718426 \n",
      "acc for optim= 0.16319388569882293\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.005622471682727337\n",
      "Loss on test= 0.00725648133084178\n",
      "acc for Lsat= 0.15202131552762949 \n",
      "acc for Psat= 0.20278619074474516 \n",
      "acc for optim= 0.16506012679119672\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.0055846055038273335\n",
      "Loss on test= 0.007022112607955933\n",
      "acc for Lsat= 0.14872752173358125 \n",
      "acc for Psat= 0.1810559081016719 \n",
      "acc for optim= 0.1681627710064545\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.005600261501967907\n",
      "Loss on test= 0.007306220009922981\n",
      "acc for Lsat= 0.1507898886399878 \n",
      "acc for Psat= 0.1852137530332271 \n",
      "acc for optim= 0.1672093448075504\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.005759949330240488\n",
      "Loss on test= 0.006760681048035622\n",
      "acc for Lsat= 0.15145503867887053 \n",
      "acc for Psat= 0.19312742681654751 \n",
      "acc for optim= 0.17091588958502427\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.005838916637003422\n",
      "Loss on test= 0.007128250319510698\n",
      "acc for Lsat= 0.16776410766235997 \n",
      "acc for Psat= 0.1913962771894685 \n",
      "acc for optim= 0.16800849396744016\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.00566285103559494\n",
      "Loss on test= 0.00748251611366868\n",
      "acc for Lsat= 0.15726071744451117 \n",
      "acc for Psat= 0.19367991825603864 \n",
      "acc for optim= 0.16146009087803026\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.005492863245308399\n",
      "Loss on test= 0.007598628289997578\n",
      "acc for Lsat= 0.14749294407303123 \n",
      "acc for Psat= 0.20036777412828027 \n",
      "acc for optim= 0.16411855633229352\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.005658071022480726\n",
      "Loss on test= 0.007240247912704945\n",
      "acc for Lsat= 0.1557887838965427 \n",
      "acc for Psat= 0.1946423422052815 \n",
      "acc for optim= 0.16465413706032675\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.005979790352284908\n",
      "Loss on test= 0.007201687432825565\n",
      "acc for Lsat= 0.1580542667953061 \n",
      "acc for Psat= 0.19844368006318394 \n",
      "acc for optim= 0.16290343057580833\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.005712438374757767\n",
      "Loss on test= 0.0075466749258339405\n",
      "acc for Lsat= 0.16175187217285397 \n",
      "acc for Psat= 0.19418219423139102 \n",
      "acc for optim= 0.17036564346683425\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.005559971556067467\n",
      "Loss on test= 0.0074427262879908085\n",
      "acc for Lsat= 0.14960172346938158 \n",
      "acc for Psat= 0.19748391894314468 \n",
      "acc for optim= 0.17220340342734192\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.006454743444919586\n",
      "Loss on test= 0.007424469571560621\n",
      "acc for Lsat= 0.1593078311715947 \n",
      "acc for Psat= 0.19229718035938156 \n",
      "acc for optim= 0.1633801257356593\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.005839770659804344\n",
      "Loss on test= 0.007407036609947681\n",
      "acc for Lsat= 0.15896229063557674 \n",
      "acc for Psat= 0.19752599175696903 \n",
      "acc for optim= 0.16556639927420308\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.005531950853765011\n",
      "Loss on test= 0.007581416983157396\n",
      "acc for Lsat= 0.16035263197397295 \n",
      "acc for Psat= 0.19885255788361317 \n",
      "acc for optim= 0.16480757380511515\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.005688946694135666\n",
      "Loss on test= 0.007709306199103594\n",
      "acc for Lsat= 0.1603696698782828 \n",
      "acc for Psat= 0.19094514928550124 \n",
      "acc for optim= 0.1647970590582041\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.005695250816643238\n",
      "Loss on test= 0.0070729381404817104\n",
      "acc for Lsat= 0.14846553642295118 \n",
      "acc for Psat= 0.1829980114859922 \n",
      "acc for optim= 0.16137492534948789\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.005545798223465681\n",
      "Loss on test= 0.00747152604162693\n",
      "acc for Lsat= 0.15314262492475328 \n",
      "acc for Psat= 0.20559767799826004 \n",
      "acc for optim= 0.16784350292024308\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.00542582618072629\n",
      "Loss on test= 0.007070716470479965\n",
      "acc for Lsat= 0.15180372921549562 \n",
      "acc for Psat= 0.20630612927022904 \n",
      "acc for optim= 0.16725134496122873\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.005605488084256649\n",
      "Loss on test= 0.007221202366054058\n",
      "acc for Lsat= 0.152289696643129 \n",
      "acc for Psat= 0.18906915271044022 \n",
      "acc for optim= 0.164670489601539\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.0056301564909517765\n",
      "Loss on test= 0.007099108770489693\n",
      "acc for Lsat= 0.1580618746960383 \n",
      "acc for Psat= 0.19649037287482748 \n",
      "acc for optim= 0.16630198361216586\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.005690610967576504\n",
      "Loss on test= 0.006785918027162552\n",
      "acc for Lsat= 0.14791263315781805 \n",
      "acc for Psat= 0.20399897967839278 \n",
      "acc for optim= 0.1638314514857007\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.005811258684843779\n",
      "Loss on test= 0.0066345143131911755\n",
      "acc for Lsat= 0.1500841317112466 \n",
      "acc for Psat= 0.20279852326417372 \n",
      "acc for optim= 0.16715428486531295\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.006109206471592188\n",
      "Loss on test= 0.00749381585046649\n",
      "acc for Lsat= 0.1618024920940697 \n",
      "acc for Psat= 0.21023406343149081 \n",
      "acc for optim= 0.16836630835190233\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.005756237544119358\n",
      "Loss on test= 0.007842927239835262\n",
      "acc for Lsat= 0.16390335283368124 \n",
      "acc for Psat= 0.19864901746585048 \n",
      "acc for optim= 0.16863176994728016\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.005617275834083557\n",
      "Loss on test= 0.0070306723937392235\n",
      "acc for Lsat= 0.14863561153875618 \n",
      "acc for Psat= 0.1891876832673662 \n",
      "acc for optim= 0.1668427458579736\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.005784622393548489\n",
      "Loss on test= 0.007365794386714697\n",
      "acc for Lsat= 0.15196737684882017 \n",
      "acc for Psat= 0.1935674315986422 \n",
      "acc for optim= 0.16733142738497708\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.005859727505594492\n",
      "Loss on test= 0.007428588345646858\n",
      "acc for Lsat= 0.16246430299580708 \n",
      "acc for Psat= 0.18236784180645357 \n",
      "acc for optim= 0.16179398072389198\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.005893722642213106\n",
      "Loss on test= 0.007121123839169741\n",
      "acc for Lsat= 0.15866077559967678 \n",
      "acc for Psat= 0.19334359624769948 \n",
      "acc for optim= 0.17115272066716825\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.005903107114136219\n",
      "Loss on test= 0.007700325921177864\n",
      "acc for Lsat= 0.15214723649081205 \n",
      "acc for Psat= 0.1976476537476539 \n",
      "acc for optim= 0.1588543699400883\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.006014158017933369\n",
      "Loss on test= 0.0073159802705049515\n",
      "acc for Lsat= 0.16927235247338282 \n",
      "acc for Psat= 0.22759042834847798 \n",
      "acc for optim= 0.16394888099491\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.005606375634670258\n",
      "Loss on test= 0.007738096173852682\n",
      "acc for Lsat= 0.14688857414589843 \n",
      "acc for Psat= 0.20051904406673351 \n",
      "acc for optim= 0.16314965502700585\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.005514510907232761\n",
      "Loss on test= 0.007221015635877848\n",
      "acc for Lsat= 0.15386002160290058 \n",
      "acc for Psat= 0.20347138293427186 \n",
      "acc for optim= 0.16078273825286354\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.005543135572224855\n",
      "Loss on test= 0.007600151933729649\n",
      "acc for Lsat= 0.14760028763109298 \n",
      "acc for Psat= 0.20385531719075517 \n",
      "acc for optim= 0.16474428679816233\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.005755010060966015\n",
      "Loss on test= 0.007284012157469988\n",
      "acc for Lsat= 0.14933525056360655 \n",
      "acc for Psat= 0.19347720715058891 \n",
      "acc for optim= 0.16427862232214138\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.005802932661026716\n",
      "Loss on test= 0.0072032734751701355\n",
      "acc for Lsat= 0.1550257500132248 \n",
      "acc for Psat= 0.2040071317597796 \n",
      "acc for optim= 0.1702606810867542\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.006132976152002811\n",
      "Loss on test= 0.007498003076761961\n",
      "acc for Lsat= 0.16416945024622512 \n",
      "acc for Psat= 0.19094493258887613 \n",
      "acc for optim= 0.16596659054620894\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.0059705921448767185\n",
      "Loss on test= 0.007358328439295292\n",
      "acc for Lsat= 0.15713355737217305 \n",
      "acc for Psat= 0.19480658516566438 \n",
      "acc for optim= 0.16531369270543095\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.005787334404885769\n",
      "Loss on test= 0.007612589746713638\n",
      "acc for Lsat= 0.15468666467693498 \n",
      "acc for Psat= 0.17583412621551972 \n",
      "acc for optim= 0.16454413537676524\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.005632285960018635\n",
      "Loss on test= 0.00736364908516407\n",
      "acc for Lsat= 0.15057460196510905 \n",
      "acc for Psat= 0.18305749621005638 \n",
      "acc for optim= 0.17178425254284968\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.005878564901649952\n",
      "Loss on test= 0.00674364622682333\n",
      "acc for Lsat= 0.14826853520506 \n",
      "acc for Psat= 0.1870463663912531 \n",
      "acc for optim= 0.16083775830720398\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.00584497069939971\n",
      "Loss on test= 0.007609958294779062\n",
      "acc for Lsat= 0.1650565021096912 \n",
      "acc for Psat= 0.19451910811895076 \n",
      "acc for optim= 0.16409388412499598\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.005847270600497723\n",
      "Loss on test= 0.007058779709041119\n",
      "acc for Lsat= 0.14282523679058448 \n",
      "acc for Psat= 0.22421588723750052 \n",
      "acc for optim= 0.16625160769212105\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.00586368702352047\n",
      "Loss on test= 0.007342219818383455\n",
      "acc for Lsat= 0.15728822697305167 \n",
      "acc for Psat= 0.19209965847463148 \n",
      "acc for optim= 0.16816565602102707\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.005579213611781597\n",
      "Loss on test= 0.007501651532948017\n",
      "acc for Lsat= 0.1499264895837739 \n",
      "acc for Psat= 0.19291534809563615 \n",
      "acc for optim= 0.16196301741178193\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.0056319283321499825\n",
      "Loss on test= 0.007441361900418997\n",
      "acc for Lsat= 0.16226419404675788 \n",
      "acc for Psat= 0.2118074003339852 \n",
      "acc for optim= 0.16449647674921014\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.005610879510641098\n",
      "Loss on test= 0.00711571890860796\n",
      "acc for Lsat= 0.1635265674136701 \n",
      "acc for Psat= 0.18968820773598502 \n",
      "acc for optim= 0.16673876549857744\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.005591177847236395\n",
      "Loss on test= 0.007284657098352909\n",
      "acc for Lsat= 0.15455904491722858 \n",
      "acc for Psat= 0.1956622027645086 \n",
      "acc for optim= 0.16208683830374837\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.005820539779961109\n",
      "Loss on test= 0.007528664544224739\n",
      "acc for Lsat= 0.1605921267760826 \n",
      "acc for Psat= 0.1944391753226824 \n",
      "acc for optim= 0.16393431522120094\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.005866196937859058\n",
      "Loss on test= 0.007584421895444393\n",
      "acc for Lsat= 0.1605560632617228 \n",
      "acc for Psat= 0.21278739128162566 \n",
      "acc for optim= 0.15793276995603667\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.005422408692538738\n",
      "Loss on test= 0.007197751197963953\n",
      "acc for Lsat= 0.15124806513774616 \n",
      "acc for Psat= 0.19265563060390214 \n",
      "acc for optim= 0.1613043620855143\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.0055079772137105465\n",
      "Loss on test= 0.007351769600063562\n",
      "acc for Lsat= 0.16962965008729713 \n",
      "acc for Psat= 0.20870351905860082 \n",
      "acc for optim= 0.16450005047676702\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.005673479754477739\n",
      "Loss on test= 0.007540532387793064\n",
      "acc for Lsat= 0.1589364837672844 \n",
      "acc for Psat= 0.19709082600783717 \n",
      "acc for optim= 0.17072582907104467\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.005507578141987324\n",
      "Loss on test= 0.007487898226827383\n",
      "acc for Lsat= 0.14569861954746036 \n",
      "acc for Psat= 0.1983602840499189 \n",
      "acc for optim= 0.16698131968735308\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.00609617168083787\n",
      "Loss on test= 0.00768052926287055\n",
      "acc for Lsat= 0.15878573964334658 \n",
      "acc for Psat= 0.20513339775889258 \n",
      "acc for optim= 0.17114519930032432\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.005731021054089069\n",
      "Loss on test= 0.0072348453104496\n",
      "acc for Lsat= 0.1571845773508253 \n",
      "acc for Psat= 0.2124938381076256 \n",
      "acc for optim= 0.16531780345178615\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.005654816050082445\n",
      "Loss on test= 0.007452957797795534\n",
      "acc for Lsat= 0.1543330956249475 \n",
      "acc for Psat= 0.19629102148321748 \n",
      "acc for optim= 0.165204185951066\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.005709323100745678\n",
      "Loss on test= 0.007309485226869583\n",
      "acc for Lsat= 0.1520933319835496 \n",
      "acc for Psat= 0.2189568258860133 \n",
      "acc for optim= 0.16639131363144918\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.005720044020563364\n",
      "Loss on test= 0.007028091698884964\n",
      "acc for Lsat= 0.14976564732522868 \n",
      "acc for Psat= 0.20609807516457743 \n",
      "acc for optim= 0.1668081086985843\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.005867178551852703\n",
      "Loss on test= 0.0071648769080638885\n",
      "acc for Lsat= 0.15539414750289965 \n",
      "acc for Psat= 0.19093825124704172 \n",
      "acc for optim= 0.16188511701270206\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.005602790974080563\n",
      "Loss on test= 0.007140600588172674\n",
      "acc for Lsat= 0.1425923731203034 \n",
      "acc for Psat= 0.2030994462314993 \n",
      "acc for optim= 0.16588952821272915\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.005699646659195423\n",
      "Loss on test= 0.007291032467037439\n",
      "acc for Lsat= 0.16762758114062187 \n",
      "acc for Psat= 0.19986419240466022 \n",
      "acc for optim= 0.16425332323920944\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.005674990825355053\n",
      "Loss on test= 0.0072127473540604115\n",
      "acc for Lsat= 0.15437179182009145 \n",
      "acc for Psat= 0.2128732662526776 \n",
      "acc for optim= 0.1665099141845426\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.005617693066596985\n",
      "Loss on test= 0.00751659506931901\n",
      "acc for Lsat= 0.16172933586888383 \n",
      "acc for Psat= 0.2057883845684195 \n",
      "acc for optim= 0.16567956483312196\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.005420468747615814\n",
      "Loss on test= 0.007558311335742474\n",
      "acc for Lsat= 0.15949553211150905 \n",
      "acc for Psat= 0.19412406093162315 \n",
      "acc for optim= 0.16455404343926558\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.005894041620194912\n",
      "Loss on test= 0.00747620640322566\n",
      "acc for Lsat= 0.1507527351265842 \n",
      "acc for Psat= 0.19801263402857375 \n",
      "acc for optim= 0.162980017084323\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.005415444727987051\n",
      "Loss on test= 0.00707979965955019\n",
      "acc for Lsat= 0.17223237874449163 \n",
      "acc for Psat= 0.21091650153708752 \n",
      "acc for optim= 0.165052548060041\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.005492147523909807\n",
      "Loss on test= 0.007205084431916475\n",
      "acc for Lsat= 0.1575608768131103 \n",
      "acc for Psat= 0.19906282804039932 \n",
      "acc for optim= 0.17188209124015869\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.0054477667436003685\n",
      "Loss on test= 0.00682808319106698\n",
      "acc for Lsat= 0.1479171150521548 \n",
      "acc for Psat= 0.18905252780551549 \n",
      "acc for optim= 0.16637905598465413\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.005777460988610983\n",
      "Loss on test= 0.007698745466768742\n",
      "acc for Lsat= 0.14747901676894457 \n",
      "acc for Psat= 0.18975678772940377 \n",
      "acc for optim= 0.16841908574684478\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.0059365928173065186\n",
      "Loss on test= 0.007158995606005192\n",
      "acc for Lsat= 0.15367514759160913 \n",
      "acc for Psat= 0.18804731210655548 \n",
      "acc for optim= 0.16723938397166213\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.005817677825689316\n",
      "Loss on test= 0.007564350962638855\n",
      "acc for Lsat= 0.151553600826148 \n",
      "acc for Psat= 0.19485369058885063 \n",
      "acc for optim= 0.17157390274190473\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.005603838711977005\n",
      "Loss on test= 0.007222416345030069\n",
      "acc for Lsat= 0.15327067668969574 \n",
      "acc for Psat= 0.18299433303363316 \n",
      "acc for optim= 0.16542528894000885\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.005940662231296301\n",
      "Loss on test= 0.007147258147597313\n",
      "acc for Lsat= 0.15546719126372796 \n",
      "acc for Psat= 0.1982335942240096 \n",
      "acc for optim= 0.16951452048321744\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.005551566835492849\n",
      "Loss on test= 0.0070014577358961105\n",
      "acc for Lsat= 0.15980473267998485 \n",
      "acc for Psat= 0.1907482318944664 \n",
      "acc for optim= 0.16991205453094033\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.005590775981545448\n",
      "Loss on test= 0.007217637728899717\n",
      "acc for Lsat= 0.16142645480195214 \n",
      "acc for Psat= 0.20239726606848055 \n",
      "acc for optim= 0.17008498969762662\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.005710209719836712\n",
      "Loss on test= 0.0071147894486784935\n",
      "acc for Lsat= 0.15502663337702854 \n",
      "acc for Psat= 0.20099762914129524 \n",
      "acc for optim= 0.16825153581646832\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.0057241604663431644\n",
      "Loss on test= 0.006978844758123159\n",
      "acc for Lsat= 0.152579038714719 \n",
      "acc for Psat= 0.19633528195196556 \n",
      "acc for optim= 0.16719453109687835\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.0060781678184866905\n",
      "Loss on test= 0.007166804745793343\n",
      "acc for Lsat= 0.14679849678192472 \n",
      "acc for Psat= 0.19593730012496902 \n",
      "acc for optim= 0.16582302798013218\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.005512659437954426\n",
      "Loss on test= 0.007154664024710655\n",
      "acc for Lsat= 0.16493597410993316 \n",
      "acc for Psat= 0.21500723972214295 \n",
      "acc for optim= 0.16522596226966954\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.00555024016648531\n",
      "Loss on test= 0.00777326337993145\n",
      "acc for Lsat= 0.17116117536235356 \n",
      "acc for Psat= 0.20166950125102198 \n",
      "acc for optim= 0.16271089206880995\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.00579100800678134\n",
      "Loss on test= 0.00770843168720603\n",
      "acc for Lsat= 0.15218150205485576 \n",
      "acc for Psat= 0.20006665132470336 \n",
      "acc for optim= 0.16566724357105503\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.005583827383816242\n",
      "Loss on test= 0.006998986005783081\n",
      "acc for Lsat= 0.1567555729756857 \n",
      "acc for Psat= 0.18869029362286396 \n",
      "acc for optim= 0.17627463830967977\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.005763037130236626\n",
      "Loss on test= 0.0076094926334917545\n",
      "acc for Lsat= 0.16379505017396354 \n",
      "acc for Psat= 0.1955431876177365 \n",
      "acc for optim= 0.1679965949965141\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.00569226685911417\n",
      "Loss on test= 0.007156600244343281\n",
      "acc for Lsat= 0.14946974245755032 \n",
      "acc for Psat= 0.19627860058919663 \n",
      "acc for optim= 0.171629382885962\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.0055310893803834915\n",
      "Loss on test= 0.007061185780912638\n",
      "acc for Lsat= 0.15586061127456172 \n",
      "acc for Psat= 0.19230499563311212 \n",
      "acc for optim= 0.1704895133996138\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.006104440428316593\n",
      "Loss on test= 0.007819531485438347\n",
      "acc for Lsat= 0.15217753159699077 \n",
      "acc for Psat= 0.2076163686069538 \n",
      "acc for optim= 0.16638547161949005\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.005699983332306147\n",
      "Loss on test= 0.007067566271871328\n",
      "acc for Lsat= 0.15054694360167886 \n",
      "acc for Psat= 0.1953742361030175 \n",
      "acc for optim= 0.15476705076298905\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.005754013545811176\n",
      "Loss on test= 0.007409181911498308\n",
      "acc for Lsat= 0.15042203673596694 \n",
      "acc for Psat= 0.18716059990778763 \n",
      "acc for optim= 0.17040299072854037\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.005662163719534874\n",
      "Loss on test= 0.00732395937666297\n",
      "acc for Lsat= 0.14335117913185252 \n",
      "acc for Psat= 0.198979312204231 \n",
      "acc for optim= 0.16893175126803175\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.0056063211522996426\n",
      "Loss on test= 0.007109411992132664\n",
      "acc for Lsat= 0.15558577557411674 \n",
      "acc for Psat= 0.19285152543214013 \n",
      "acc for optim= 0.16581813337144893\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.005546989850699902\n",
      "Loss on test= 0.007656469475477934\n",
      "acc for Lsat= 0.15378244807142152 \n",
      "acc for Psat= 0.20427743217842959 \n",
      "acc for optim= 0.1672035480854216\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.006191438529640436\n",
      "Loss on test= 0.007647892460227013\n",
      "acc for Lsat= 0.15805368242789153 \n",
      "acc for Psat= 0.19227264395078356 \n",
      "acc for optim= 0.16506825856192678\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.006149246823042631\n",
      "Loss on test= 0.007223137188702822\n",
      "acc for Lsat= 0.15901274261805307 \n",
      "acc for Psat= 0.19732092939256157 \n",
      "acc for optim= 0.1674570736232916\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.005491894669830799\n",
      "Loss on test= 0.007300784345716238\n",
      "acc for Lsat= 0.16720164360203704 \n",
      "acc for Psat= 0.1933357429094269 \n",
      "acc for optim= 0.15350779679643953\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.005441814661026001\n",
      "Loss on test= 0.00756897684186697\n",
      "acc for Lsat= 0.1522430093703242 \n",
      "acc for Psat= 0.19416342111243332 \n",
      "acc for optim= 0.16934235963176508\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.005692466162145138\n",
      "Loss on test= 0.0071542575024068356\n",
      "acc for Lsat= 0.15260194593899287 \n",
      "acc for Psat= 0.21967872409150005 \n",
      "acc for optim= 0.17107141016425229\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.005726469215005636\n",
      "Loss on test= 0.007000807672739029\n",
      "acc for Lsat= 0.1647245902854369 \n",
      "acc for Psat= 0.1908334524443251 \n",
      "acc for optim= 0.1748821134995822\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.005507303401827812\n",
      "Loss on test= 0.007140955422073603\n",
      "acc for Lsat= 0.14666851196842665 \n",
      "acc for Psat= 0.19056802762225727 \n",
      "acc for optim= 0.16635364553391108\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.005493121687322855\n",
      "Loss on test= 0.007726006209850311\n",
      "acc for Lsat= 0.15438802548699448 \n",
      "acc for Psat= 0.18815473879794362 \n",
      "acc for optim= 0.17005141728021372\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.00563130434602499\n",
      "Loss on test= 0.00796077586710453\n",
      "acc for Lsat= 0.15047641014260407 \n",
      "acc for Psat= 0.19621986714604736 \n",
      "acc for optim= 0.16326885483968148\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.005675977095961571\n",
      "Loss on test= 0.007068547420203686\n",
      "acc for Lsat= 0.15292909276255667 \n",
      "acc for Psat= 0.20306839424063314 \n",
      "acc for optim= 0.15875374742699636\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.005669912789016962\n",
      "Loss on test= 0.006883752532303333\n",
      "acc for Lsat= 0.15320743533236844 \n",
      "acc for Psat= 0.1967936594947623 \n",
      "acc for optim= 0.1691833598824069\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.005700374022126198\n",
      "Loss on test= 0.006796068511903286\n",
      "acc for Lsat= 0.1536110420345871 \n",
      "acc for Psat= 0.19096390631042237 \n",
      "acc for optim= 0.16410776288573034\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.005589497275650501\n",
      "Loss on test= 0.006986846216022968\n",
      "acc for Lsat= 0.1510473805644965 \n",
      "acc for Psat= 0.1915623854708354 \n",
      "acc for optim= 0.16839269316033842\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.00531000504270196\n",
      "Loss on test= 0.0075945183634757996\n",
      "acc for Lsat= 0.15631356170538385 \n",
      "acc for Psat= 0.19828673679511383 \n",
      "acc for optim= 0.16896522441176606\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.005650294478982687\n",
      "Loss on test= 0.007212749216705561\n",
      "acc for Lsat= 0.14518713396191443 \n",
      "acc for Psat= 0.20450159154853118 \n",
      "acc for optim= 0.17175629318235672\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.006161737255752087\n",
      "Loss on test= 0.007379320915788412\n",
      "acc for Lsat= 0.15698140706393685 \n",
      "acc for Psat= 0.1994680186896776 \n",
      "acc for optim= 0.1655888671318802\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.00591959897428751\n",
      "Loss on test= 0.007630264386534691\n",
      "acc for Lsat= 0.15913858611029802 \n",
      "acc for Psat= 0.20861221803247273 \n",
      "acc for optim= 0.1647170931940801\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.005495954304933548\n",
      "Loss on test= 0.0075034936890006065\n",
      "acc for Lsat= 0.14411500854782433 \n",
      "acc for Psat= 0.17601288314202618 \n",
      "acc for optim= 0.1689531963377167\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.006062565837055445\n",
      "Loss on test= 0.007335700560361147\n",
      "acc for Lsat= 0.15700891918357707 \n",
      "acc for Psat= 0.20289189069241773 \n",
      "acc for optim= 0.16941776055228117\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.00541731109842658\n",
      "Loss on test= 0.007267461158335209\n",
      "acc for Lsat= 0.1551099452232087 \n",
      "acc for Psat= 0.1950396448862357 \n",
      "acc for optim= 0.16543357249150878\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.006016664672642946\n",
      "Loss on test= 0.0070319692604243755\n",
      "acc for Lsat= 0.15188538157419287 \n",
      "acc for Psat= 0.19980379630044318 \n",
      "acc for optim= 0.16665140779452306\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.0054878247901797295\n",
      "Loss on test= 0.007439585868269205\n",
      "acc for Lsat= 0.1611867565470824 \n",
      "acc for Psat= 0.20047880061396367 \n",
      "acc for optim= 0.16886348112535923\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.005607246421277523\n",
      "Loss on test= 0.006851482205092907\n",
      "acc for Lsat= 0.16578227033281362 \n",
      "acc for Psat= 0.1981504388266867 \n",
      "acc for optim= 0.16779376157887707\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.005583657883107662\n",
      "Loss on test= 0.007629530504345894\n",
      "acc for Lsat= 0.155050420138191 \n",
      "acc for Psat= 0.18881247517887548 \n",
      "acc for optim= 0.16878047109892608\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.00548035791143775\n",
      "Loss on test= 0.007399352733045816\n",
      "acc for Lsat= 0.15809300796164116 \n",
      "acc for Psat= 0.20708235802441896 \n",
      "acc for optim= 0.16768837672845294\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.005600600503385067\n",
      "Loss on test= 0.007527021691203117\n",
      "acc for Lsat= 0.150473004086425 \n",
      "acc for Psat= 0.19497506728121003 \n",
      "acc for optim= 0.16741413991341508\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.005624790675938129\n",
      "Loss on test= 0.0074571664445102215\n",
      "acc for Lsat= 0.14724484310660998 \n",
      "acc for Psat= 0.20776084799159197 \n",
      "acc for optim= 0.16712095238875263\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.005484213121235371\n",
      "Loss on test= 0.0073155732825398445\n",
      "acc for Lsat= 0.1553878534417294 \n",
      "acc for Psat= 0.19073574813140068 \n",
      "acc for optim= 0.1647992983821123\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.005579750053584576\n",
      "Loss on test= 0.007112625055015087\n",
      "acc for Lsat= 0.1433305396885443 \n",
      "acc for Psat= 0.18017217136125585 \n",
      "acc for optim= 0.16855967544080291\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.005518516059964895\n",
      "Loss on test= 0.007184685207903385\n",
      "acc for Lsat= 0.14965384100388723 \n",
      "acc for Psat= 0.1946719178227616 \n",
      "acc for optim= 0.17088665239146497\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.005631383508443832\n",
      "Loss on test= 0.007334994617849588\n",
      "acc for Lsat= 0.17106297770443518 \n",
      "acc for Psat= 0.18594969869877562 \n",
      "acc for optim= 0.16856671077290886\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.005625017918646336\n",
      "Loss on test= 0.007451613899320364\n",
      "acc for Lsat= 0.15384285736458803 \n",
      "acc for Psat= 0.20387133007807576 \n",
      "acc for optim= 0.16387299560241833\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.005520923994481564\n",
      "Loss on test= 0.0073707797564566135\n",
      "acc for Lsat= 0.1522318129499298 \n",
      "acc for Psat= 0.18860169641146834 \n",
      "acc for optim= 0.1647553800109041\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.005853503011167049\n",
      "Loss on test= 0.007531702518463135\n",
      "acc for Lsat= 0.16294995908278087 \n",
      "acc for Psat= 0.19794154712151674 \n",
      "acc for optim= 0.16370194275425956\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.0055523826740682125\n",
      "Loss on test= 0.00795903429389\n",
      "acc for Lsat= 0.167208759976383 \n",
      "acc for Psat= 0.19704622387056828 \n",
      "acc for optim= 0.16925169294318337\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.005454041995108128\n",
      "Loss on test= 0.007475866936147213\n",
      "acc for Lsat= 0.15089884780225207 \n",
      "acc for Psat= 0.20663080292064567 \n",
      "acc for optim= 0.15737422745117582\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.005916398949921131\n",
      "Loss on test= 0.0073537155985832214\n",
      "acc for Lsat= 0.13988496651319543 \n",
      "acc for Psat= 0.18174208150985727 \n",
      "acc for optim= 0.1588066830722516\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.005610776133835316\n",
      "Loss on test= 0.007702006492763758\n",
      "acc for Lsat= 0.14962157802121928 \n",
      "acc for Psat= 0.22034460203951134 \n",
      "acc for optim= 0.16817259353081712\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.0055441162548959255\n",
      "Loss on test= 0.007109404541552067\n",
      "acc for Lsat= 0.15516960778995034 \n",
      "acc for Psat= 0.20280519008787243 \n",
      "acc for optim= 0.1656767782323887\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.005448277108371258\n",
      "Loss on test= 0.007485228590667248\n",
      "acc for Lsat= 0.14317686778999442 \n",
      "acc for Psat= 0.21146467303796138 \n",
      "acc for optim= 0.1676057396942657\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.005687581840902567\n",
      "Loss on test= 0.006949057336896658\n",
      "acc for Lsat= 0.1561628262564868 \n",
      "acc for Psat= 0.19523238680567823 \n",
      "acc for optim= 0.17102938642652352\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.0060875811614096165\n",
      "Loss on test= 0.007108943071216345\n",
      "acc for Lsat= 0.16576126622891085 \n",
      "acc for Psat= 0.19908288172980557 \n",
      "acc for optim= 0.17104088408618662\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.005798733327537775\n",
      "Loss on test= 0.0073821404948830605\n",
      "acc for Lsat= 0.1596430490335419 \n",
      "acc for Psat= 0.19041596365077268 \n",
      "acc for optim= 0.16130386234271116\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.006019595079123974\n",
      "Loss on test= 0.00699983024969697\n",
      "acc for Lsat= 0.16426444216822197 \n",
      "acc for Psat= 0.18562331114013939 \n",
      "acc for optim= 0.1614374260571747\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.005430910736322403\n",
      "Loss on test= 0.007635579910129309\n",
      "acc for Lsat= 0.15365418224313038 \n",
      "acc for Psat= 0.19065692218356445 \n",
      "acc for optim= 0.164006451545016\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.005879937205463648\n",
      "Loss on test= 0.007195280399173498\n",
      "acc for Lsat= 0.16402229659457798 \n",
      "acc for Psat= 0.17971130368403793 \n",
      "acc for optim= 0.1659365280222178\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.005773534066975117\n",
      "Loss on test= 0.007501478772610426\n",
      "acc for Lsat= 0.1621017854053863 \n",
      "acc for Psat= 0.2140512691644692 \n",
      "acc for optim= 0.1658857682956474\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.005371749401092529\n",
      "Loss on test= 0.007387081626802683\n",
      "acc for Lsat= 0.1490280681410919 \n",
      "acc for Psat= 0.1844013048792029 \n",
      "acc for optim= 0.16226577805377257\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.0057528093457221985\n",
      "Loss on test= 0.007265017367899418\n",
      "acc for Lsat= 0.1440626132854482 \n",
      "acc for Psat= 0.18767333666710032 \n",
      "acc for optim= 0.17330992870819067\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.005575943272560835\n",
      "Loss on test= 0.007110727950930595\n",
      "acc for Lsat= 0.15655984624010344 \n",
      "acc for Psat= 0.19947471425975444 \n",
      "acc for optim= 0.17348901104624764\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.005913351196795702\n",
      "Loss on test= 0.007472768425941467\n",
      "acc for Lsat= 0.1612923670717151 \n",
      "acc for Psat= 0.20653099089056506 \n",
      "acc for optim= 0.1650798551767366\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.006010829471051693\n",
      "Loss on test= 0.007130201440304518\n",
      "acc for Lsat= 0.1421972334093403 \n",
      "acc for Psat= 0.20224369206679527 \n",
      "acc for optim= 0.16439250929330734\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005569026339799166\n",
      "Loss on test= 0.007430220488458872\n",
      "acc for Lsat= 0.15807171180647736 \n",
      "acc for Psat= 0.20177385038638976 \n",
      "acc for optim= 0.1591961139269158\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.005682291463017464\n",
      "Loss on test= 0.007308343891054392\n",
      "acc for Lsat= 0.1579267647102109 \n",
      "acc for Psat= 0.19235303329235157 \n",
      "acc for optim= 0.16542982489259944\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.005622687749564648\n",
      "Loss on test= 0.00772909726947546\n",
      "acc for Lsat= 0.15476283960685622 \n",
      "acc for Psat= 0.18889286005392394 \n",
      "acc for optim= 0.16761586857002064\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.0054742624051868916\n",
      "Loss on test= 0.006951391696929932\n",
      "acc for Lsat= 0.15731699614934472 \n",
      "acc for Psat= 0.19505286268149427 \n",
      "acc for optim= 0.1634940551956505\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.005427521653473377\n",
      "Loss on test= 0.007612762972712517\n",
      "acc for Lsat= 0.1679156615700359 \n",
      "acc for Psat= 0.20439772512916415 \n",
      "acc for optim= 0.15870055079037423\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.005448620766401291\n",
      "Loss on test= 0.007219589781016111\n",
      "acc for Lsat= 0.1469036995395579 \n",
      "acc for Psat= 0.19098120292183013 \n",
      "acc for optim= 0.1596373790977179\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.00566205196082592\n",
      "Loss on test= 0.007700873073190451\n",
      "acc for Lsat= 0.15384587195595023 \n",
      "acc for Psat= 0.20067734522668676 \n",
      "acc for optim= 0.16774610975627466\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.005915896035730839\n",
      "Loss on test= 0.007469399366527796\n",
      "acc for Lsat= 0.16591955551068435 \n",
      "acc for Psat= 0.21007365459522812 \n",
      "acc for optim= 0.16897758680517921\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.005716133397072554\n",
      "Loss on test= 0.007609164342284203\n",
      "acc for Lsat= 0.15329143582474913 \n",
      "acc for Psat= 0.18743647743554664 \n",
      "acc for optim= 0.16252899874249668\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.005544140934944153\n",
      "Loss on test= 0.007327357307076454\n",
      "acc for Lsat= 0.15904743685431805 \n",
      "acc for Psat= 0.2099327906286802 \n",
      "acc for optim= 0.1711851784333226\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.005742767825722694\n",
      "Loss on test= 0.007248504087328911\n",
      "acc for Lsat= 0.1591900390990796 \n",
      "acc for Psat= 0.19474730491242181 \n",
      "acc for optim= 0.16605858417670624\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.005488353781402111\n",
      "Loss on test= 0.007940513081848621\n",
      "acc for Lsat= 0.16037214062844363 \n",
      "acc for Psat= 0.20189794389374524 \n",
      "acc for optim= 0.16507056585647123\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.005742132198065519\n",
      "Loss on test= 0.007224831730127335\n",
      "acc for Lsat= 0.1562004464703276 \n",
      "acc for Psat= 0.1989762082111976 \n",
      "acc for optim= 0.1652718641480324\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.005569335073232651\n",
      "Loss on test= 0.007236343342810869\n",
      "acc for Lsat= 0.1597902624959462 \n",
      "acc for Psat= 0.18019555398085552 \n",
      "acc for optim= 0.16288748278614654\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.005794486962258816\n",
      "Loss on test= 0.0076588233932852745\n",
      "acc for Lsat= 0.15135265524154642 \n",
      "acc for Psat= 0.1919291243250062 \n",
      "acc for optim= 0.16775955636893755\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.005567987449467182\n",
      "Loss on test= 0.00701904296875\n",
      "acc for Lsat= 0.15994636287653177 \n",
      "acc for Psat= 0.2140877541067908 \n",
      "acc for optim= 0.16387027464425344\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.0061130644753575325\n",
      "Loss on test= 0.007547678891569376\n",
      "acc for Lsat= 0.15673086040340303 \n",
      "acc for Psat= 0.20319431640997865 \n",
      "acc for optim= 0.15824378790442648\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005353101063519716\n",
      "Loss on test= 0.007754907477647066\n",
      "acc for Lsat= 0.15311273136328846 \n",
      "acc for Psat= 0.17509540875698057 \n",
      "acc for optim= 0.16957502517833462\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.005605264566838741\n",
      "Loss on test= 0.0072379345074296\n",
      "acc for Lsat= 0.1588263067243178 \n",
      "acc for Psat= 0.20597314653292176 \n",
      "acc for optim= 0.16110703853363567\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.0056873769499361515\n",
      "Loss on test= 0.007298290729522705\n",
      "acc for Lsat= 0.16004774569935493 \n",
      "acc for Psat= 0.18318192921846066 \n",
      "acc for optim= 0.17289954195806725\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.005332597065716982\n",
      "Loss on test= 0.007499333471059799\n",
      "acc for Lsat= 0.15890408249650165 \n",
      "acc for Psat= 0.19502351474249258 \n",
      "acc for optim= 0.1695678486584182\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.0053666261956095695\n",
      "Loss on test= 0.007638291921466589\n",
      "acc for Lsat= 0.16052514922568484 \n",
      "acc for Psat= 0.1899039761514449 \n",
      "acc for optim= 0.17026900004931406\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.005912014748901129\n",
      "Loss on test= 0.007058970630168915\n",
      "acc for Lsat= 0.1385416955888924 \n",
      "acc for Psat= 0.18435598863231506 \n",
      "acc for optim= 0.16091586447694933\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.005631713662296534\n",
      "Loss on test= 0.00715959258377552\n",
      "acc for Lsat= 0.15274511563647003 \n",
      "acc for Psat= 0.19197310980554425 \n",
      "acc for optim= 0.16727917314608215\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.005730591714382172\n",
      "Loss on test= 0.007095846813172102\n",
      "acc for Lsat= 0.1515718548207498 \n",
      "acc for Psat= 0.19747424125137022 \n",
      "acc for optim= 0.17157440921291708\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.006197293289005756\n",
      "Loss on test= 0.006901295389980078\n",
      "acc for Lsat= 0.1591209966562198 \n",
      "acc for Psat= 0.20031736133330058 \n",
      "acc for optim= 0.1689205925877313\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.005532599985599518\n",
      "Loss on test= 0.007416396867483854\n",
      "acc for Lsat= 0.14598567450617547 \n",
      "acc for Psat= 0.19610108102206142 \n",
      "acc for optim= 0.1636896947348685\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.005592522211372852\n",
      "Loss on test= 0.0073601072654128075\n",
      "acc for Lsat= 0.1524814800437555 \n",
      "acc for Psat= 0.20016458391814995 \n",
      "acc for optim= 0.16908679165224713\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.005509928334504366\n",
      "Loss on test= 0.007211919873952866\n",
      "acc for Lsat= 0.15485648973599234 \n",
      "acc for Psat= 0.18766376858569497 \n",
      "acc for optim= 0.17133180114677268\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.005564792547374964\n",
      "Loss on test= 0.007327638566493988\n",
      "acc for Lsat= 0.153265390080375 \n",
      "acc for Psat= 0.20882541682727665 \n",
      "acc for optim= 0.16781435548743248\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.005622523836791515\n",
      "Loss on test= 0.007001395337283611\n",
      "acc for Lsat= 0.15789217594610222 \n",
      "acc for Psat= 0.19541341601403384 \n",
      "acc for optim= 0.1663300969554078\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.00558149628341198\n",
      "Loss on test= 0.007000585552304983\n",
      "acc for Lsat= 0.14435624712123918 \n",
      "acc for Psat= 0.19486209290754813 \n",
      "acc for optim= 0.17093999471675728\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.005834360606968403\n",
      "Loss on test= 0.007979288697242737\n",
      "acc for Lsat= 0.14761944024396115 \n",
      "acc for Psat= 0.1867966268121906 \n",
      "acc for optim= 0.1675202653212301\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.005620048381388187\n",
      "Loss on test= 0.007060033734887838\n",
      "acc for Lsat= 0.1582999269890248 \n",
      "acc for Psat= 0.20379367422648384 \n",
      "acc for optim= 0.1668155854954823\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.00610154215246439\n",
      "Loss on test= 0.007275232579559088\n",
      "acc for Lsat= 0.15359977648791964 \n",
      "acc for Psat= 0.20203792704555557 \n",
      "acc for optim= 0.15792240842443997\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.005558306816965342\n",
      "Loss on test= 0.007578734774142504\n",
      "acc for Lsat= 0.15250009191356081 \n",
      "acc for Psat= 0.20722636307024808 \n",
      "acc for optim= 0.17124755938993538\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.005533733405172825\n",
      "Loss on test= 0.00672328332439065\n",
      "acc for Lsat= 0.15910611624140522 \n",
      "acc for Psat= 0.1982270220269785 \n",
      "acc for optim= 0.1662418043872601\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.005522805266082287\n",
      "Loss on test= 0.007103368174284697\n",
      "acc for Lsat= 0.15178864807025033 \n",
      "acc for Psat= 0.19863998054519114 \n",
      "acc for optim= 0.16519461767063343\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.005848556291311979\n",
      "Loss on test= 0.0072176712565124035\n",
      "acc for Lsat= 0.14858089100258648 \n",
      "acc for Psat= 0.18591886742382127 \n",
      "acc for optim= 0.17144737810900312\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.005555225536227226\n",
      "Loss on test= 0.007317377254366875\n",
      "acc for Lsat= 0.1476455737108586 \n",
      "acc for Psat= 0.1912073433660658 \n",
      "acc for optim= 0.16839828646445282\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.005839676596224308\n",
      "Loss on test= 0.007144373841583729\n",
      "acc for Lsat= 0.16030763002975126 \n",
      "acc for Psat= 0.195562681694683 \n",
      "acc for optim= 0.16756661725841218\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005637683905661106\n",
      "Loss on test= 0.007705796509981155\n",
      "acc for Lsat= 0.15307468478663322 \n",
      "acc for Psat= 0.21053581328749596 \n",
      "acc for optim= 0.1587678047255842\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.005692463833838701\n",
      "Loss on test= 0.007177418563514948\n",
      "acc for Lsat= 0.16943205276735082 \n",
      "acc for Psat= 0.2072876818134587 \n",
      "acc for optim= 0.17095871029620166\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.005403413437306881\n",
      "Loss on test= 0.006667776498943567\n",
      "acc for Lsat= 0.1652301009801659 \n",
      "acc for Psat= 0.20565569180895987 \n",
      "acc for optim= 0.16286109935544282\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.005719035863876343\n",
      "Loss on test= 0.007281132973730564\n",
      "acc for Lsat= 0.1607867283191242 \n",
      "acc for Psat= 0.204241797537686 \n",
      "acc for optim= 0.16652089685161567\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.0057013873010873795\n",
      "Loss on test= 0.007382528856396675\n",
      "acc for Lsat= 0.16031522786275285 \n",
      "acc for Psat= 0.20057238039661288 \n",
      "acc for optim= 0.16279885631310373\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.00559473130851984\n",
      "Loss on test= 0.0077887349762022495\n",
      "acc for Lsat= 0.14290276255275383 \n",
      "acc for Psat= 0.17650507720927786 \n",
      "acc for optim= 0.16998366125111208\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.005605904385447502\n",
      "Loss on test= 0.006506022065877914\n",
      "acc for Lsat= 0.15543923457771597 \n",
      "acc for Psat= 0.1936371958610447 \n",
      "acc for optim= 0.16523332131933993\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.0055999914184212685\n",
      "Loss on test= 0.0074877189472317696\n",
      "acc for Lsat= 0.1462530066832694 \n",
      "acc for Psat= 0.1945053612478421 \n",
      "acc for optim= 0.16666573971995632\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.005711713340133429\n",
      "Loss on test= 0.007520051207393408\n",
      "acc for Lsat= 0.15044422639678443 \n",
      "acc for Psat= 0.20192382654378413 \n",
      "acc for optim= 0.16706805464994834\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.005383421666920185\n",
      "Loss on test= 0.007093666587024927\n",
      "acc for Lsat= 0.1605543516290023 \n",
      "acc for Psat= 0.18941663508007653 \n",
      "acc for optim= 0.16482123313051816\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.005416598636657\n",
      "Loss on test= 0.007467679679393768\n",
      "acc for Lsat= 0.15062807255775715 \n",
      "acc for Psat= 0.20024099567156955 \n",
      "acc for optim= 0.15592267589613062\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.005319781135767698\n",
      "Loss on test= 0.006970623042434454\n",
      "acc for Lsat= 0.16333667411789543 \n",
      "acc for Psat= 0.19549775075159784 \n",
      "acc for optim= 0.16520343071849802\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.005557608790695667\n",
      "Loss on test= 0.007161118555814028\n",
      "acc for Lsat= 0.15517482050505113 \n",
      "acc for Psat= 0.18825163057829697 \n",
      "acc for optim= 0.16774516415049429\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.005924546159803867\n",
      "Loss on test= 0.006826783996075392\n",
      "acc for Lsat= 0.14868271750737683 \n",
      "acc for Psat= 0.21906786122679955 \n",
      "acc for optim= 0.1735916109255622\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.005614680238068104\n",
      "Loss on test= 0.007338020484894514\n",
      "acc for Lsat= 0.15930009672196857 \n",
      "acc for Psat= 0.1985778560840833 \n",
      "acc for optim= 0.16297587764892654\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.005518529564142227\n",
      "Loss on test= 0.006914706900715828\n",
      "acc for Lsat= 0.15537688003272795 \n",
      "acc for Psat= 0.19982338137619318 \n",
      "acc for optim= 0.17079910154498065\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.0055926283821463585\n",
      "Loss on test= 0.007219950668513775\n",
      "acc for Lsat= 0.14767015444651077 \n",
      "acc for Psat= 0.18613758050749787 \n",
      "acc for optim= 0.16390983809518522\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.005725467577576637\n",
      "Loss on test= 0.007049972657114267\n",
      "acc for Lsat= 0.14986603027744005 \n",
      "acc for Psat= 0.1999298461888474 \n",
      "acc for optim= 0.169819347103905\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.005451517179608345\n",
      "Loss on test= 0.007328899577260017\n",
      "acc for Lsat= 0.1518342631088463 \n",
      "acc for Psat= 0.200237656787389 \n",
      "acc for optim= 0.16808325603344768\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.005627100355923176\n",
      "Loss on test= 0.007146432064473629\n",
      "acc for Lsat= 0.1606057483883962 \n",
      "acc for Psat= 0.2049381734862481 \n",
      "acc for optim= 0.1702928724813229\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.005621585063636303\n",
      "Loss on test= 0.006737892050296068\n",
      "acc for Lsat= 0.16413245954871422 \n",
      "acc for Psat= 0.20996273394998977 \n",
      "acc for optim= 0.16723742742896783\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.005854559596627951\n",
      "Loss on test= 0.007304141763597727\n",
      "acc for Lsat= 0.16186695615722813 \n",
      "acc for Psat= 0.1948101224534244 \n",
      "acc for optim= 0.16923280818536726\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.005643107928335667\n",
      "Loss on test= 0.007011566776782274\n",
      "acc for Lsat= 0.15749175103298257 \n",
      "acc for Psat= 0.20147514864344332 \n",
      "acc for optim= 0.1699955364861886\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.005768957547843456\n",
      "Loss on test= 0.007069384679198265\n",
      "acc for Lsat= 0.15622689071145734 \n",
      "acc for Psat= 0.19627104654037927 \n",
      "acc for optim= 0.16738430530378656\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.006277089472860098\n",
      "Loss on test= 0.0074845049530267715\n",
      "acc for Lsat= 0.15384104268579576 \n",
      "acc for Psat= 0.1995811154644127 \n",
      "acc for optim= 0.16710421459612887\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.005667780991643667\n",
      "Loss on test= 0.00758423563092947\n",
      "acc for Lsat= 0.14794267927559826 \n",
      "acc for Psat= 0.19607533528870277 \n",
      "acc for optim= 0.17083886762852896\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.005750013515353203\n",
      "Loss on test= 0.006870845332741737\n",
      "acc for Lsat= 0.15615012871147302 \n",
      "acc for Psat= 0.1963607913738147 \n",
      "acc for optim= 0.1676457376951699\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.006012044381350279\n",
      "Loss on test= 0.007416076492518187\n",
      "acc for Lsat= 0.15782288471492079 \n",
      "acc for Psat= 0.20014492980067114 \n",
      "acc for optim= 0.17480394803970425\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.005510603543370962\n",
      "Loss on test= 0.007498438004404306\n",
      "acc for Lsat= 0.1435509923446664 \n",
      "acc for Psat= 0.19556811561762188 \n",
      "acc for optim= 0.1658323752136565\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.005572972819209099\n",
      "Loss on test= 0.007445398718118668\n",
      "acc for Lsat= 0.1464700257948592 \n",
      "acc for Psat= 0.17588772885329623 \n",
      "acc for optim= 0.16525448188872732\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.005898953881114721\n",
      "Loss on test= 0.007765388581901789\n",
      "acc for Lsat= 0.1539379261045709 \n",
      "acc for Psat= 0.19013933616262846 \n",
      "acc for optim= 0.1715532794587131\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005648326128721237\n",
      "Loss on test= 0.007608288433402777\n",
      "acc for Lsat= 0.16066724668642446 \n",
      "acc for Psat= 0.20587733956779064 \n",
      "acc for optim= 0.16367307625897992\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.005688642617315054\n",
      "Loss on test= 0.007317684590816498\n",
      "acc for Lsat= 0.15324165596680137 \n",
      "acc for Psat= 0.1943661072535715 \n",
      "acc for optim= 0.16890881448892542\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005613080225884914\n",
      "Loss on test= 0.007168639916926622\n",
      "acc for Lsat= 0.14336188210352882 \n",
      "acc for Psat= 0.19255493405755975 \n",
      "acc for optim= 0.16226994470181708\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.005570961628109217\n",
      "Loss on test= 0.007665397133678198\n",
      "acc for Lsat= 0.1450982392541339 \n",
      "acc for Psat= 0.1981568692323368 \n",
      "acc for optim= 0.16116901566665695\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.005627935286611319\n",
      "Loss on test= 0.007206438574939966\n",
      "acc for Lsat= 0.15836391288569562 \n",
      "acc for Psat= 0.20396262719706235 \n",
      "acc for optim= 0.16344736536361704\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.005859182216227055\n",
      "Loss on test= 0.007108108140528202\n",
      "acc for Lsat= 0.16079055257179758 \n",
      "acc for Psat= 0.1889960652541705 \n",
      "acc for optim= 0.16236510824538064\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.005489726550877094\n",
      "Loss on test= 0.007139250636100769\n",
      "acc for Lsat= 0.1412707538697506 \n",
      "acc for Psat= 0.18459130950046887 \n",
      "acc for optim= 0.16649358079226717\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.005499000195413828\n",
      "Loss on test= 0.007487175054848194\n",
      "acc for Lsat= 0.16428123079431167 \n",
      "acc for Psat= 0.20413196564396294 \n",
      "acc for optim= 0.16544134455778803\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.00632075872272253\n",
      "Loss on test= 0.0070470827631652355\n",
      "acc for Lsat= 0.14980160871303075 \n",
      "acc for Psat= 0.19339979426586068 \n",
      "acc for optim= 0.17227344690377397\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005580940283834934\n",
      "Loss on test= 0.006623240653425455\n",
      "acc for Lsat= 0.15035894538593655 \n",
      "acc for Psat= 0.20021429369846344 \n",
      "acc for optim= 0.1651403719185256\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.0054985047318041325\n",
      "Loss on test= 0.007252473384141922\n",
      "acc for Lsat= 0.14658933942584076 \n",
      "acc for Psat= 0.20806141146954882 \n",
      "acc for optim= 0.16606785109434583\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.006016008090227842\n",
      "Loss on test= 0.007462303154170513\n",
      "acc for Lsat= 0.15433678987453173 \n",
      "acc for Psat= 0.18727108011485963 \n",
      "acc for optim= 0.16802346501909732\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.005376980174332857\n",
      "Loss on test= 0.0070051574148237705\n",
      "acc for Lsat= 0.16614247724684872 \n",
      "acc for Psat= 0.19120169862165864 \n",
      "acc for optim= 0.16242968312552444\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.005667620338499546\n",
      "Loss on test= 0.007711482234299183\n",
      "acc for Lsat= 0.16704436490821775 \n",
      "acc for Psat= 0.19627687312485115 \n",
      "acc for optim= 0.16349824476273483\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.0056867441162467\n",
      "Loss on test= 0.007493525743484497\n",
      "acc for Lsat= 0.15304435791798912 \n",
      "acc for Psat= 0.19148499948873382 \n",
      "acc for optim= 0.16375204014351408\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.005667448975145817\n",
      "Loss on test= 0.007015830837190151\n",
      "acc for Lsat= 0.16078946253763832 \n",
      "acc for Psat= 0.18677527883746584 \n",
      "acc for optim= 0.16694157378114455\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.005683894269168377\n",
      "Loss on test= 0.007471790537238121\n",
      "acc for Lsat= 0.16058774421365596 \n",
      "acc for Psat= 0.20182767877752175 \n",
      "acc for optim= 0.161980091592442\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.0057774693705141544\n",
      "Loss on test= 0.007608639542013407\n",
      "acc for Lsat= 0.15570786809033454 \n",
      "acc for Psat= 0.1933319559987333 \n",
      "acc for optim= 0.17011513523719288\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005736237391829491\n",
      "Loss on test= 0.007241853978484869\n",
      "acc for Lsat= 0.1607040632124914 \n",
      "acc for Psat= 0.2108021158966919 \n",
      "acc for optim= 0.15862624147904753\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.0055171228013932705\n",
      "Loss on test= 0.007402072194963694\n",
      "acc for Lsat= 0.14578513669643978 \n",
      "acc for Psat= 0.20436946653310575 \n",
      "acc for optim= 0.1647729806792846\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.005458054132759571\n",
      "Loss on test= 0.007099870592355728\n",
      "acc for Lsat= 0.15821767743585297 \n",
      "acc for Psat= 0.19775153272193627 \n",
      "acc for optim= 0.17160449466156605\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.005650098901242018\n",
      "Loss on test= 0.0074167195707559586\n",
      "acc for Lsat= 0.15697453550719578 \n",
      "acc for Psat= 0.18878022933256675 \n",
      "acc for optim= 0.16577951605660748\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.005481528118252754\n",
      "Loss on test= 0.007051682099699974\n",
      "acc for Lsat= 0.14752036097743854 \n",
      "acc for Psat= 0.2048787034034145 \n",
      "acc for optim= 0.16153813456299668\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.006046963389962912\n",
      "Loss on test= 0.006826231721788645\n",
      "acc for Lsat= 0.16464933286550776 \n",
      "acc for Psat= 0.21363095364077245 \n",
      "acc for optim= 0.1690031652080208\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.005921564530581236\n",
      "Loss on test= 0.007202772423624992\n",
      "acc for Lsat= 0.14669952048880971 \n",
      "acc for Psat= 0.19440005412497025 \n",
      "acc for optim= 0.16585625775528645\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.006058824248611927\n",
      "Loss on test= 0.007047649938613176\n",
      "acc for Lsat= 0.1558535320417131 \n",
      "acc for Psat= 0.21510069072017537 \n",
      "acc for optim= 0.16541638629602604\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.005522099789232016\n",
      "Loss on test= 0.007410574704408646\n",
      "acc for Lsat= 0.15353528600191835 \n",
      "acc for Psat= 0.2046525493437867 \n",
      "acc for optim= 0.1630357013074452\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.005696461535990238\n",
      "Loss on test= 0.007361787371337414\n",
      "acc for Lsat= 0.14922521954944326 \n",
      "acc for Psat= 0.21732099361252039 \n",
      "acc for optim= 0.1602704387149448\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.0055397143587470055\n",
      "Loss on test= 0.007294787093997002\n",
      "acc for Lsat= 0.16190985073908004 \n",
      "acc for Psat= 0.20596486480837903 \n",
      "acc for optim= 0.16672426894017053\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.006268023047596216\n",
      "Loss on test= 0.007242599967867136\n",
      "acc for Lsat= 0.15435226041628963 \n",
      "acc for Psat= 0.20221766442018485 \n",
      "acc for optim= 0.16860744934846345\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.005460837390273809\n",
      "Loss on test= 0.007156009320169687\n",
      "acc for Lsat= 0.14984320802079729 \n",
      "acc for Psat= 0.19559266209205398 \n",
      "acc for optim= 0.16412056642496237\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.005485388915985823\n",
      "Loss on test= 0.007365601137280464\n",
      "acc for Lsat= 0.15502222579809433 \n",
      "acc for Psat= 0.19165180983808136 \n",
      "acc for optim= 0.16515936080253535\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.0058103036135435104\n",
      "Loss on test= 0.0074370563961565495\n",
      "acc for Lsat= 0.15434245510526826 \n",
      "acc for Psat= 0.19691042234266146 \n",
      "acc for optim= 0.16148633059404302\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.005493409000337124\n",
      "Loss on test= 0.007134113926440477\n",
      "acc for Lsat= 0.14797724268578574 \n",
      "acc for Psat= 0.1953029318369131 \n",
      "acc for optim= 0.16600280744672494\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.0057758064940571785\n",
      "Loss on test= 0.00772448442876339\n",
      "acc for Lsat= 0.15177148324132086 \n",
      "acc for Psat= 0.1989680841172946 \n",
      "acc for optim= 0.16340520831996758\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.005695989355444908\n",
      "Loss on test= 0.006958354730159044\n",
      "acc for Lsat= 0.1548858902424757 \n",
      "acc for Psat= 0.18575437698478917 \n",
      "acc for optim= 0.15914876765767627\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.0055080074816942215\n",
      "Loss on test= 0.006898277439177036\n",
      "acc for Lsat= 0.14490985873500725 \n",
      "acc for Psat= 0.19703833473021867 \n",
      "acc for optim= 0.16533777890526538\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005578192882239819\n",
      "Loss on test= 0.0077881342731416225\n",
      "acc for Lsat= 0.15663571420858508 \n",
      "acc for Psat= 0.2091954433271417 \n",
      "acc for optim= 0.16365584901516844\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.0057201264426112175\n",
      "Loss on test= 0.007266914006322622\n",
      "acc for Lsat= 0.14943627701222048 \n",
      "acc for Psat= 0.2045523408788913 \n",
      "acc for optim= 0.17156863686834753\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.00571084301918745\n",
      "Loss on test= 0.007365772500634193\n",
      "acc for Lsat= 0.16470836140425327 \n",
      "acc for Psat= 0.21782403462132263 \n",
      "acc for optim= 0.16342700961519216\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.005746156442910433\n",
      "Loss on test= 0.007143287919461727\n",
      "acc for Lsat= 0.158145797005511 \n",
      "acc for Psat= 0.2082476561221573 \n",
      "acc for optim= 0.17096183705553947\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.005787062458693981\n",
      "Loss on test= 0.007379326969385147\n",
      "acc for Lsat= 0.16604838676017816 \n",
      "acc for Psat= 0.19642625889496604 \n",
      "acc for optim= 0.1677025683560088\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.00567838829010725\n",
      "Loss on test= 0.007645717356353998\n",
      "acc for Lsat= 0.15210946146971316 \n",
      "acc for Psat= 0.19160053163396384 \n",
      "acc for optim= 0.16492346166823915\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.005566983949393034\n",
      "Loss on test= 0.007762381341308355\n",
      "acc for Lsat= 0.14785200811227875 \n",
      "acc for Psat= 0.21019429625980518 \n",
      "acc for optim= 0.16625311312162638\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.0056123132817447186\n",
      "Loss on test= 0.007216311059892178\n",
      "acc for Lsat= 0.1501555947885089 \n",
      "acc for Psat= 0.1832736628575701 \n",
      "acc for optim= 0.1679370800388183\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.005406470503658056\n",
      "Loss on test= 0.007432785350829363\n",
      "acc for Lsat= 0.15342873986466926 \n",
      "acc for Psat= 0.20360557719927708 \n",
      "acc for optim= 0.16173598758683572\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.005768117494881153\n",
      "Loss on test= 0.007902545854449272\n",
      "acc for Lsat= 0.14535568124523052 \n",
      "acc for Psat= 0.20582311454049662 \n",
      "acc for optim= 0.16252805085005392\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.005817323457449675\n",
      "Loss on test= 0.007002283353358507\n",
      "acc for Lsat= 0.16692392491949265 \n",
      "acc for Psat= 0.2140329539979098 \n",
      "acc for optim= 0.17022941791849425\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.005811047740280628\n",
      "Loss on test= 0.007409463170915842\n",
      "acc for Lsat= 0.1498005788550964 \n",
      "acc for Psat= 0.18549627141347613 \n",
      "acc for optim= 0.1642540069531576\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.005541503895074129\n",
      "Loss on test= 0.007142291869968176\n",
      "acc for Lsat= 0.14803174774772698 \n",
      "acc for Psat= 0.19574042225932153 \n",
      "acc for optim= 0.16528093730801807\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005575832910835743\n",
      "Loss on test= 0.007073814515024424\n",
      "acc for Lsat= 0.16629462771529913 \n",
      "acc for Psat= 0.19287205637112015 \n",
      "acc for optim= 0.16762297148790045\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.005750546231865883\n",
      "Loss on test= 0.007109126076102257\n",
      "acc for Lsat= 0.16149172983609414 \n",
      "acc for Psat= 0.19653365261257305 \n",
      "acc for optim= 0.1660369653648842\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.005811719223856926\n",
      "Loss on test= 0.007029832806438208\n",
      "acc for Lsat= 0.16076026861823056 \n",
      "acc for Psat= 0.20207624709993205 \n",
      "acc for optim= 0.16506305442269906\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.005838601849973202\n",
      "Loss on test= 0.007544635329395533\n",
      "acc for Lsat= 0.15947169521231908 \n",
      "acc for Psat= 0.2059605512626805 \n",
      "acc for optim= 0.17377105368459675\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.005669992882758379\n",
      "Loss on test= 0.007672295905649662\n",
      "acc for Lsat= 0.15401354501225825 \n",
      "acc for Psat= 0.19481149567386563 \n",
      "acc for optim= 0.16494509162701912\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.00572649110108614\n",
      "Loss on test= 0.0069276574067771435\n",
      "acc for Lsat= 0.16028604920434414 \n",
      "acc for Psat= 0.20507087659350307 \n",
      "acc for optim= 0.15974554091778567\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.0056563569232821465\n",
      "Loss on test= 0.007013573311269283\n",
      "acc for Lsat= 0.137631144602096 \n",
      "acc for Psat= 0.20062651397110742 \n",
      "acc for optim= 0.1655569433477005\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.0059876819141209126\n",
      "Loss on test= 0.007182917091995478\n",
      "acc for Lsat= 0.16040241139307312 \n",
      "acc for Psat= 0.1970378132842359 \n",
      "acc for optim= 0.1573239779611286\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.006105874199420214\n",
      "Loss on test= 0.007319247350096703\n",
      "acc for Lsat= 0.147468629591625 \n",
      "acc for Psat= 0.19619026630983274 \n",
      "acc for optim= 0.16948256232774794\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.005616196896880865\n",
      "Loss on test= 0.007742773741483688\n",
      "acc for Lsat= 0.14110740219924187 \n",
      "acc for Psat= 0.1876653416645255 \n",
      "acc for optim= 0.16394146484605296\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.005439346190541983\n",
      "Loss on test= 0.007133117876946926\n",
      "acc for Lsat= 0.15566700123494767 \n",
      "acc for Psat= 0.186706403006998 \n",
      "acc for optim= 0.17196291702623923\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.00571347214281559\n",
      "Loss on test= 0.007054419722408056\n",
      "acc for Lsat= 0.14743112021232727 \n",
      "acc for Psat= 0.18481771095380803 \n",
      "acc for optim= 0.1682570481178595\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.005589764565229416\n",
      "Loss on test= 0.0073258900083601475\n",
      "acc for Lsat= 0.1570177157744183 \n",
      "acc for Psat= 0.2071428431270522 \n",
      "acc for optim= 0.16706681052902375\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.005668932572007179\n",
      "Loss on test= 0.007489434443414211\n",
      "acc for Lsat= 0.15905916421697094 \n",
      "acc for Psat= 0.20620762068028256 \n",
      "acc for optim= 0.1702954267352041\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005533370189368725\n",
      "Loss on test= 0.007241650950163603\n",
      "acc for Lsat= 0.1611846700067857 \n",
      "acc for Psat= 0.1986402483207563 \n",
      "acc for optim= 0.16539257866937332\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.005527389235794544\n",
      "Loss on test= 0.006846212316304445\n",
      "acc for Lsat= 0.1448789713902353 \n",
      "acc for Psat= 0.18985894108491713 \n",
      "acc for optim= 0.1639259255235465\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.005829996429383755\n",
      "Loss on test= 0.007560521364212036\n",
      "acc for Lsat= 0.1527588105880747 \n",
      "acc for Psat= 0.18979159490983993 \n",
      "acc for optim= 0.16994603047239\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005702792201191187\n",
      "Loss on test= 0.007578082382678986\n",
      "acc for Lsat= 0.15819800143572885 \n",
      "acc for Psat= 0.21311395184615708 \n",
      "acc for optim= 0.15560875446425912\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005567069165408611\n",
      "Loss on test= 0.007305795792490244\n",
      "acc for Lsat= 0.15758742314484733 \n",
      "acc for Psat= 0.20555433295552664 \n",
      "acc for optim= 0.16037255072742929\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.005635251756757498\n",
      "Loss on test= 0.00773276574909687\n",
      "acc for Lsat= 0.15230168724569995 \n",
      "acc for Psat= 0.19334760032871884 \n",
      "acc for optim= 0.15702274264195232\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.0058380477130413055\n",
      "Loss on test= 0.007192628923803568\n",
      "acc for Lsat= 0.1546070789882043 \n",
      "acc for Psat= 0.2082637594753235 \n",
      "acc for optim= 0.16413879455994007\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.005556896328926086\n",
      "Loss on test= 0.007808635476976633\n",
      "acc for Lsat= 0.1484714110025976 \n",
      "acc for Psat= 0.1728122586804274 \n",
      "acc for optim= 0.16531554749922553\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.00565200112760067\n",
      "Loss on test= 0.0071390653029084206\n",
      "acc for Lsat= 0.16084961892662905 \n",
      "acc for Psat= 0.19438521135617506 \n",
      "acc for optim= 0.16229882384936675\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.005754920653998852\n",
      "Loss on test= 0.007217691745609045\n",
      "acc for Lsat= 0.15689127569656522 \n",
      "acc for Psat= 0.20182734310539194 \n",
      "acc for optim= 0.16707855321945944\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005509335547685623\n",
      "Loss on test= 0.0077242180705070496\n",
      "acc for Lsat= 0.162551729637389 \n",
      "acc for Psat= 0.21079771550234835 \n",
      "acc for optim= 0.15945262338694893\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.005549205467104912\n",
      "Loss on test= 0.006996778771281242\n",
      "acc for Lsat= 0.15025280659973475 \n",
      "acc for Psat= 0.1857430549739234 \n",
      "acc for optim= 0.16434344089796124\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.005382477305829525\n",
      "Loss on test= 0.0074950591661036015\n",
      "acc for Lsat= 0.1613518590754524 \n",
      "acc for Psat= 0.19785990107586973 \n",
      "acc for optim= 0.16202850230553448\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.0055323438718914986\n",
      "Loss on test= 0.007193201221525669\n",
      "acc for Lsat= 0.154024392889324 \n",
      "acc for Psat= 0.1878196463896544 \n",
      "acc for optim= 0.1617686189711094\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.005517303012311459\n",
      "Loss on test= 0.007433147169649601\n",
      "acc for Lsat= 0.15028683475251395 \n",
      "acc for Psat= 0.21015599718284947 \n",
      "acc for optim= 0.1648210081880145\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.005657327361404896\n",
      "Loss on test= 0.007399727124720812\n",
      "acc for Lsat= 0.14667332583463935 \n",
      "acc for Psat= 0.19830392644231085 \n",
      "acc for optim= 0.16930902078900426\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.0056730532087385654\n",
      "Loss on test= 0.007137693930417299\n",
      "acc for Lsat= 0.15527755825810868 \n",
      "acc for Psat= 0.1916529119922207 \n",
      "acc for optim= 0.16267337719986186\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.005618539173156023\n",
      "Loss on test= 0.00718208821490407\n",
      "acc for Lsat= 0.14928844227516627 \n",
      "acc for Psat= 0.19964866407070553 \n",
      "acc for optim= 0.16495337920095465\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.005515626631677151\n",
      "Loss on test= 0.007370001170784235\n",
      "acc for Lsat= 0.14421894490531814 \n",
      "acc for Psat= 0.19839774692492163 \n",
      "acc for optim= 0.16145714803629357\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.005718603730201721\n",
      "Loss on test= 0.007486275397241116\n",
      "acc for Lsat= 0.1499050985002646 \n",
      "acc for Psat= 0.2030957555989964 \n",
      "acc for optim= 0.17218042792958496\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.005994700826704502\n",
      "Loss on test= 0.006920809857547283\n",
      "acc for Lsat= 0.15745890173282412 \n",
      "acc for Psat= 0.20843478739204374 \n",
      "acc for optim= 0.16579728498434662\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.005603305529803038\n",
      "Loss on test= 0.00762146944180131\n",
      "acc for Lsat= 0.15395538399461656 \n",
      "acc for Psat= 0.1935997249312378 \n",
      "acc for optim= 0.1633739708827381\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.005576734431087971\n",
      "Loss on test= 0.006839335430413485\n",
      "acc for Lsat= 0.1682333028997432 \n",
      "acc for Psat= 0.21392631297883363 \n",
      "acc for optim= 0.16552555277289013\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.005597545299679041\n",
      "Loss on test= 0.00703609362244606\n",
      "acc for Lsat= 0.1558461616575321 \n",
      "acc for Psat= 0.19995271116456964 \n",
      "acc for optim= 0.16321983437519522\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.005591788329184055\n",
      "Loss on test= 0.006870213430374861\n",
      "acc for Lsat= 0.1602012082289324 \n",
      "acc for Psat= 0.18670428410367124 \n",
      "acc for optim= 0.1634058730058433\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.005551826674491167\n",
      "Loss on test= 0.0072556184604763985\n",
      "acc for Lsat= 0.1435306443232608 \n",
      "acc for Psat= 0.19905234883295098 \n",
      "acc for optim= 0.15991427901155147\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005645835306495428\n",
      "Loss on test= 0.007065757177770138\n",
      "acc for Lsat= 0.1598210579374057 \n",
      "acc for Psat= 0.19488957430060463 \n",
      "acc for optim= 0.16618265198891005\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.005625339224934578\n",
      "Loss on test= 0.007657385431230068\n",
      "acc for Lsat= 0.15134502193579435 \n",
      "acc for Psat= 0.19457819094350867 \n",
      "acc for optim= 0.16286547068071353\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.0063705542124807835\n",
      "Loss on test= 0.007060947362333536\n",
      "acc for Lsat= 0.15897651598178095 \n",
      "acc for Psat= 0.19092065236515932 \n",
      "acc for optim= 0.1725262974260912\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.005712357349693775\n",
      "Loss on test= 0.007315776310861111\n",
      "acc for Lsat= 0.15735134069395604 \n",
      "acc for Psat= 0.19996698206504349 \n",
      "acc for optim= 0.16506351815196915\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.005633636377751827\n",
      "Loss on test= 0.00764507707208395\n",
      "acc for Lsat= 0.14283548480418146 \n",
      "acc for Psat= 0.18633816332888378 \n",
      "acc for optim= 0.16654871773734173\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.005678977817296982\n",
      "Loss on test= 0.007573035545647144\n",
      "acc for Lsat= 0.14643971964174912 \n",
      "acc for Psat= 0.19093153272511162 \n",
      "acc for optim= 0.15548486609821072\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.005803124979138374\n",
      "Loss on test= 0.007137683220207691\n",
      "acc for Lsat= 0.14771326520369527 \n",
      "acc for Psat= 0.1946747654446374 \n",
      "acc for optim= 0.16058493685941058\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.005569633562117815\n",
      "Loss on test= 0.007185648195445538\n",
      "acc for Lsat= 0.15595303407481864 \n",
      "acc for Psat= 0.19906181717438426 \n",
      "acc for optim= 0.16395106171038323\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.005432853940874338\n",
      "Loss on test= 0.007548393215984106\n",
      "acc for Lsat= 0.15660305369538485 \n",
      "acc for Psat= 0.2039718353798323 \n",
      "acc for optim= 0.1570136666277397\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.005890227854251862\n",
      "Loss on test= 0.007005335297435522\n",
      "acc for Lsat= 0.1506638349608335 \n",
      "acc for Psat= 0.19396454709368285 \n",
      "acc for optim= 0.15860454545921235\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.005846548825502396\n",
      "Loss on test= 0.007037151604890823\n",
      "acc for Lsat= 0.14735658212992378 \n",
      "acc for Psat= 0.19634955869485446 \n",
      "acc for optim= 0.16552929524611992\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.005544321611523628\n",
      "Loss on test= 0.007554676383733749\n",
      "acc for Lsat= 0.15723965883171034 \n",
      "acc for Psat= 0.18649087344023368 \n",
      "acc for optim= 0.16417012321772284\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.005612014327198267\n",
      "Loss on test= 0.007156554143875837\n",
      "acc for Lsat= 0.15494181704411633 \n",
      "acc for Psat= 0.19748356229984432 \n",
      "acc for optim= 0.16387050141815143\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.0055922046303749084\n",
      "Loss on test= 0.007945280522108078\n",
      "acc for Lsat= 0.14956284060746958 \n",
      "acc for Psat= 0.18103144074414215 \n",
      "acc for optim= 0.1687606219295436\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.005749221425503492\n",
      "Loss on test= 0.007138715125620365\n",
      "acc for Lsat= 0.16175582361861787 \n",
      "acc for Psat= 0.20809088837561487 \n",
      "acc for optim= 0.16367980284991124\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.005730046890676022\n",
      "Loss on test= 0.007167805917561054\n",
      "acc for Lsat= 0.1633169584540215 \n",
      "acc for Psat= 0.17992781724658657 \n",
      "acc for optim= 0.16906091959763067\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.00556065933778882\n",
      "Loss on test= 0.006932583171874285\n",
      "acc for Lsat= 0.15294516778619746 \n",
      "acc for Psat= 0.2190696184370728 \n",
      "acc for optim= 0.16373294860936394\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.005718594882637262\n",
      "Loss on test= 0.007668099831789732\n",
      "acc for Lsat= 0.15226206391797875 \n",
      "acc for Psat= 0.2009329689369865 \n",
      "acc for optim= 0.16666321750297536\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.005630679428577423\n",
      "Loss on test= 0.007213646546006203\n",
      "acc for Lsat= 0.15246574768479762 \n",
      "acc for Psat= 0.1946312488911704 \n",
      "acc for optim= 0.1699721063184743\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.005543315317481756\n",
      "Loss on test= 0.007416329812258482\n",
      "acc for Lsat= 0.1595736344715153 \n",
      "acc for Psat= 0.20414112161551068 \n",
      "acc for optim= 0.16497332589580585\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.0056759691797196865\n",
      "Loss on test= 0.0069276620633900166\n",
      "acc for Lsat= 0.1653402824378496 \n",
      "acc for Psat= 0.209858335025578 \n",
      "acc for optim= 0.16727010996670647\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.005499124526977539\n",
      "Loss on test= 0.007385164964944124\n",
      "acc for Lsat= 0.15554425600280633 \n",
      "acc for Psat= 0.18776825643488068 \n",
      "acc for optim= 0.16143532330804833\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005318887531757355\n",
      "Loss on test= 0.007802965585142374\n",
      "acc for Lsat= 0.1574327250529409 \n",
      "acc for Psat= 0.1982198684737177 \n",
      "acc for optim= 0.16926671417285002\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.005522490479052067\n",
      "Loss on test= 0.007551165763288736\n",
      "acc for Lsat= 0.15655899166881457 \n",
      "acc for Psat= 0.20003122765948753 \n",
      "acc for optim= 0.1651739635401726\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.005884070415049791\n",
      "Loss on test= 0.007231582421809435\n",
      "acc for Lsat= 0.14832729340824832 \n",
      "acc for Psat= 0.2030326573838018 \n",
      "acc for optim= 0.17164924633784648\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.005705555900931358\n",
      "Loss on test= 0.007146686781197786\n",
      "acc for Lsat= 0.15229801217716218 \n",
      "acc for Psat= 0.1891531027082476 \n",
      "acc for optim= 0.16789547182399145\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.0055811177007853985\n",
      "Loss on test= 0.007588842883706093\n",
      "acc for Lsat= 0.15829777623747177 \n",
      "acc for Psat= 0.19479253395636123 \n",
      "acc for optim= 0.16503240924498416\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.005618984345346689\n",
      "Loss on test= 0.007143914233893156\n",
      "acc for Lsat= 0.15529338357126585 \n",
      "acc for Psat= 0.19852670163536906 \n",
      "acc for optim= 0.16876324056783695\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.005920393392443657\n",
      "Loss on test= 0.007682764437049627\n",
      "acc for Lsat= 0.1507703005771351 \n",
      "acc for Psat= 0.19060790402791844 \n",
      "acc for optim= 0.1659465868438243\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.005807862617075443\n",
      "Loss on test= 0.007157838437706232\n",
      "acc for Lsat= 0.15751925099652536 \n",
      "acc for Psat= 0.19423515629586305 \n",
      "acc for optim= 0.16516494022631736\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.005632304586470127\n",
      "Loss on test= 0.0074519501067698\n",
      "acc for Lsat= 0.15528786067362324 \n",
      "acc for Psat= 0.18741524713724608 \n",
      "acc for optim= 0.17055337669663742\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.0059385718777775764\n",
      "Loss on test= 0.007346525322645903\n",
      "acc for Lsat= 0.15326813653676358 \n",
      "acc for Psat= 0.20028361587166849 \n",
      "acc for optim= 0.1660169266689603\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.005523715168237686\n",
      "Loss on test= 0.007041015196591616\n",
      "acc for Lsat= 0.15863446583341592 \n",
      "acc for Psat= 0.1917640607565504 \n",
      "acc for optim= 0.16943325561616326\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.00607471214607358\n",
      "Loss on test= 0.007314223330467939\n",
      "acc for Lsat= 0.14393846946577618 \n",
      "acc for Psat= 0.20036831180141385 \n",
      "acc for optim= 0.16484209691941523\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.005693926475942135\n",
      "Loss on test= 0.007454636972397566\n",
      "acc for Lsat= 0.16372433810048265 \n",
      "acc for Psat= 0.20738851892414548 \n",
      "acc for optim= 0.1675529937549937\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005511958617717028\n",
      "Loss on test= 0.007127861957997084\n",
      "acc for Lsat= 0.1528161610013874 \n",
      "acc for Psat= 0.20263668933681014 \n",
      "acc for optim= 0.16542444181166682\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005371192470192909\n",
      "Loss on test= 0.0070778727531433105\n",
      "acc for Lsat= 0.15300171840287075 \n",
      "acc for Psat= 0.2082187089759887 \n",
      "acc for optim= 0.15612867613052034\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.005546461790800095\n",
      "Loss on test= 0.007229540962725878\n",
      "acc for Lsat= 0.16870238623070363 \n",
      "acc for Psat= 0.20573432792825472 \n",
      "acc for optim= 0.16790193382394883\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.005453083664178848\n",
      "Loss on test= 0.007252241484820843\n",
      "acc for Lsat= 0.16119049902715277 \n",
      "acc for Psat= 0.2023282250923345 \n",
      "acc for optim= 0.16802628164744524\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.006057211197912693\n",
      "Loss on test= 0.007315504364669323\n",
      "acc for Lsat= 0.15448022729804983 \n",
      "acc for Psat= 0.1912788545393939 \n",
      "acc for optim= 0.17088961847580694\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.0054506585001945496\n",
      "Loss on test= 0.0072596995159983635\n",
      "acc for Lsat= 0.161035805204158 \n",
      "acc for Psat= 0.20822826555904314 \n",
      "acc for optim= 0.16846756530948534\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.005418060813099146\n",
      "Loss on test= 0.007402281742542982\n",
      "acc for Lsat= 0.14689416855756865 \n",
      "acc for Psat= 0.17751312171105205 \n",
      "acc for optim= 0.16170675789605307\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.0054860650561749935\n",
      "Loss on test= 0.006987827364355326\n",
      "acc for Lsat= 0.16429845995124673 \n",
      "acc for Psat= 0.1882121247460791 \n",
      "acc for optim= 0.16419914806887628\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.0057136802934110165\n",
      "Loss on test= 0.006889355834573507\n",
      "acc for Lsat= 0.1465545828103042 \n",
      "acc for Psat= 0.20054632374848866 \n",
      "acc for optim= 0.16083838248627305\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.005664278287440538\n",
      "Loss on test= 0.007521436084061861\n",
      "acc for Lsat= 0.15168471248886264 \n",
      "acc for Psat= 0.19145150018787224 \n",
      "acc for optim= 0.17267521966132335\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005498555488884449\n",
      "Loss on test= 0.007046904880553484\n",
      "acc for Lsat= 0.15165331328428946 \n",
      "acc for Psat= 0.19293772821432956 \n",
      "acc for optim= 0.16116526430858238\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.0055524432100355625\n",
      "Loss on test= 0.007738848216831684\n",
      "acc for Lsat= 0.15018358312968974 \n",
      "acc for Psat= 0.18552923959443254 \n",
      "acc for optim= 0.16630666565787444\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.005496512167155743\n",
      "Loss on test= 0.007505538873374462\n",
      "acc for Lsat= 0.14770066067986726 \n",
      "acc for Psat= 0.2016128028512047 \n",
      "acc for optim= 0.1709403371007075\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.0054577067494392395\n",
      "Loss on test= 0.007567805238068104\n",
      "acc for Lsat= 0.1461440329571621 \n",
      "acc for Psat= 0.19565944719418396 \n",
      "acc for optim= 0.1592213339689016\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.005457127001136541\n",
      "Loss on test= 0.007131622638553381\n",
      "acc for Lsat= 0.15623709341457695 \n",
      "acc for Psat= 0.1918902297810075 \n",
      "acc for optim= 0.16818567228476808\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.005503339227288961\n",
      "Loss on test= 0.007691900711506605\n",
      "acc for Lsat= 0.1581759032056682 \n",
      "acc for Psat= 0.1992321541831069 \n",
      "acc for optim= 0.1708386422923602\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.005461825989186764\n",
      "Loss on test= 0.006978231016546488\n",
      "acc for Lsat= 0.15644688594643189 \n",
      "acc for Psat= 0.18834205323498177 \n",
      "acc for optim= 0.17310614964297827\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.0056265476159751415\n",
      "Loss on test= 0.007710506208240986\n",
      "acc for Lsat= 0.1558585646820396 \n",
      "acc for Psat= 0.2031057913489945 \n",
      "acc for optim= 0.17083955420387267\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.0055426242761313915\n",
      "Loss on test= 0.007309066131711006\n",
      "acc for Lsat= 0.1524613196821788 \n",
      "acc for Psat= 0.18687073010636387 \n",
      "acc for optim= 0.16021916808037576\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.005526496563106775\n",
      "Loss on test= 0.007390851620584726\n",
      "acc for Lsat= 0.1484500439318477 \n",
      "acc for Psat= 0.19048923929679956 \n",
      "acc for optim= 0.16251231723934503\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.0054578883573412895\n",
      "Loss on test= 0.006618817336857319\n",
      "acc for Lsat= 0.1431233281607465 \n",
      "acc for Psat= 0.2098028821488995 \n",
      "acc for optim= 0.161230055037905\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.005951463244855404\n",
      "Loss on test= 0.0070784976705908775\n",
      "acc for Lsat= 0.15002405434426067 \n",
      "acc for Psat= 0.19274635465780357 \n",
      "acc for optim= 0.16152575746546957\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.005685856565833092\n",
      "Loss on test= 0.007533475290983915\n",
      "acc for Lsat= 0.15862423913900695 \n",
      "acc for Psat= 0.21323810486680234 \n",
      "acc for optim= 0.16985894239614488\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.005600259639322758\n",
      "Loss on test= 0.007208336144685745\n",
      "acc for Lsat= 0.15231096922891352 \n",
      "acc for Psat= 0.19083205426600205 \n",
      "acc for optim= 0.15922894969323845\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.005666923243552446\n",
      "Loss on test= 0.007231852971017361\n",
      "acc for Lsat= 0.16738340008209962 \n",
      "acc for Psat= 0.1996671385377489 \n",
      "acc for optim= 0.17174617042860443\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.00563739612698555\n",
      "Loss on test= 0.007330756168812513\n",
      "acc for Lsat= 0.14969132302785063 \n",
      "acc for Psat= 0.1915180309509599 \n",
      "acc for optim= 0.16173840022457908\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.005547652952373028\n",
      "Loss on test= 0.007511371746659279\n",
      "acc for Lsat= 0.15233877332276116 \n",
      "acc for Psat= 0.19894015656280348 \n",
      "acc for optim= 0.16426158719390752\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.005573873408138752\n",
      "Loss on test= 0.007664691656827927\n",
      "acc for Lsat= 0.15029394272905697 \n",
      "acc for Psat= 0.18707024746643167 \n",
      "acc for optim= 0.16587061001003156\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.006070246919989586\n",
      "Loss on test= 0.007085714023560286\n",
      "acc for Lsat= 0.15947105123176714 \n",
      "acc for Psat= 0.2043594089642045 \n",
      "acc for optim= 0.16817307905914247\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.005402599461376667\n",
      "Loss on test= 0.006862740498036146\n",
      "acc for Lsat= 0.15849518916859734 \n",
      "acc for Psat= 0.21928058956085597 \n",
      "acc for optim= 0.1636530934061977\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.0055197798646986485\n",
      "Loss on test= 0.007338584866374731\n",
      "acc for Lsat= 0.14055000276201726 \n",
      "acc for Psat= 0.18421987898640152 \n",
      "acc for optim= 0.1557383009588506\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.005253332667052746\n",
      "Loss on test= 0.007633665110915899\n",
      "acc for Lsat= 0.15123971633490968 \n",
      "acc for Psat= 0.21048455762802853 \n",
      "acc for optim= 0.1682708188849425\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.005866203922778368\n",
      "Loss on test= 0.00697594927623868\n",
      "acc for Lsat= 0.15384707311435497 \n",
      "acc for Psat= 0.1961104617179295 \n",
      "acc for optim= 0.16542641916846643\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.005604713223874569\n",
      "Loss on test= 0.007450481876730919\n",
      "acc for Lsat= 0.15697930950564562 \n",
      "acc for Psat= 0.19621121920941045 \n",
      "acc for optim= 0.1646291680519515\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.005588073283433914\n",
      "Loss on test= 0.007471015676856041\n",
      "acc for Lsat= 0.15218452897235812 \n",
      "acc for Psat= 0.18235819722768148 \n",
      "acc for optim= 0.1658442535363214\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005555903539061546\n",
      "Loss on test= 0.007160611916333437\n",
      "acc for Lsat= 0.15515372435885316 \n",
      "acc for Psat= 0.1996837893926508 \n",
      "acc for optim= 0.16152213139909885\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.005682406947016716\n",
      "Loss on test= 0.007239786442369223\n",
      "acc for Lsat= 0.15254683562021962 \n",
      "acc for Psat= 0.18801773418977735 \n",
      "acc for optim= 0.16738815612987937\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.005433238111436367\n",
      "Loss on test= 0.007260738406330347\n",
      "acc for Lsat= 0.15759973686157924 \n",
      "acc for Psat= 0.18089228090982823 \n",
      "acc for optim= 0.16630134335136973\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.005656756926327944\n",
      "Loss on test= 0.007490739692002535\n",
      "acc for Lsat= 0.16012378168658767 \n",
      "acc for Psat= 0.21546119515684845 \n",
      "acc for optim= 0.17093078578892928\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.0056030284613370895\n",
      "Loss on test= 0.007711857557296753\n",
      "acc for Lsat= 0.15166161913638476 \n",
      "acc for Psat= 0.18800733096064565 \n",
      "acc for optim= 0.1640419072761643\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.0055868905037641525\n",
      "Loss on test= 0.00788229051977396\n",
      "acc for Lsat= 0.1624862639170014 \n",
      "acc for Psat= 0.19453787073568984 \n",
      "acc for optim= 0.16221100838824373\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.005684281699359417\n",
      "Loss on test= 0.007054861169308424\n",
      "acc for Lsat= 0.16718678598303624 \n",
      "acc for Psat= 0.20777878306183933 \n",
      "acc for optim= 0.16736600365247348\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.0055666533298790455\n",
      "Loss on test= 0.007479300256818533\n",
      "acc for Lsat= 0.16423594580245676 \n",
      "acc for Psat= 0.19553053361501116 \n",
      "acc for optim= 0.16196615805689124\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.005697906482964754\n",
      "Loss on test= 0.007062568794935942\n",
      "acc for Lsat= 0.1509334468801857 \n",
      "acc for Psat= 0.2140557087646782 \n",
      "acc for optim= 0.16693863679123394\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.005752465222030878\n",
      "Loss on test= 0.007343054749071598\n",
      "acc for Lsat= 0.15264611916662363 \n",
      "acc for Psat= 0.19722134624245255 \n",
      "acc for optim= 0.16441084124399807\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.005811723414808512\n",
      "Loss on test= 0.007251359522342682\n",
      "acc for Lsat= 0.16366517663223393 \n",
      "acc for Psat= 0.1902118150641012 \n",
      "acc for optim= 0.16923470487073827\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.00577242998406291\n",
      "Loss on test= 0.007284664083272219\n",
      "acc for Lsat= 0.16140418010000446 \n",
      "acc for Psat= 0.19885754281517545 \n",
      "acc for optim= 0.16710277447060942\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.005458476021885872\n",
      "Loss on test= 0.007611987646669149\n",
      "acc for Lsat= 0.1523570195333765 \n",
      "acc for Psat= 0.1895931425992949 \n",
      "acc for optim= 0.1664034033231936\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.005362889729440212\n",
      "Loss on test= 0.006622680462896824\n",
      "acc for Lsat= 0.16192870510412086 \n",
      "acc for Psat= 0.21654132534310863 \n",
      "acc for optim= 0.17061595616301095\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005653752945363522\n",
      "Loss on test= 0.007619116920977831\n",
      "acc for Lsat= 0.14282101819226822 \n",
      "acc for Psat= 0.18578764350586724 \n",
      "acc for optim= 0.16287603312759796\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.005632404703646898\n",
      "Loss on test= 0.007375035434961319\n",
      "acc for Lsat= 0.1574695062851266 \n",
      "acc for Psat= 0.19036766169497316 \n",
      "acc for optim= 0.168685088610872\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.005705852061510086\n",
      "Loss on test= 0.007744409143924713\n",
      "acc for Lsat= 0.1534812667550229 \n",
      "acc for Psat= 0.1959516583439955 \n",
      "acc for optim= 0.17032865648364007\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.005496759433299303\n",
      "Loss on test= 0.007254067342728376\n",
      "acc for Lsat= 0.16662538210998792 \n",
      "acc for Psat= 0.1950897462761457 \n",
      "acc for optim= 0.1661799822010283\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.00546369981020689\n",
      "Loss on test= 0.007658988703042269\n",
      "acc for Lsat= 0.1499067257247201 \n",
      "acc for Psat= 0.2046503463656962 \n",
      "acc for optim= 0.16688389233428008\n",
      "Fold 5\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.11331626027822495\n",
      "Loss on test= 0.04933598265051842\n",
      "acc for Lsat= 0.5760303207245641 \n",
      "acc for Psat= 0.639317812766311 \n",
      "acc for optim= 0.28945484328098964\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.03693685680627823\n",
      "Loss on test= 0.029008977115154266\n",
      "acc for Lsat= 0.40402801201266586 \n",
      "acc for Psat= 0.7054926611719745 \n",
      "acc for optim= 0.2724520161989351\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.030304735526442528\n",
      "Loss on test= 0.026416663080453873\n",
      "acc for Lsat= 0.39926821323737627 \n",
      "acc for Psat= 0.5459485587606695 \n",
      "acc for optim= 0.2814542812806722\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.02773786522448063\n",
      "Loss on test= 0.02395451068878174\n",
      "acc for Lsat= 0.38251258554910383 \n",
      "acc for Psat= 0.5908776860000932 \n",
      "acc for optim= 0.25866714780997546\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.02586139366030693\n",
      "Loss on test= 0.022538144141435623\n",
      "acc for Lsat= 0.4331265371827195 \n",
      "acc for Psat= 0.5744091374833962 \n",
      "acc for optim= 0.2219708819209491\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.024579321965575218\n",
      "Loss on test= 0.024288926273584366\n",
      "acc for Lsat= 0.5768179283170106 \n",
      "acc for Psat= 0.4515324494236561 \n",
      "acc for optim= 0.21615050409092249\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.023238081485033035\n",
      "Loss on test= 0.021242886781692505\n",
      "acc for Lsat= 0.46004124007752684 \n",
      "acc for Psat= 0.5358559986912325 \n",
      "acc for optim= 0.26548974177691337\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.02310217171907425\n",
      "Loss on test= 0.021176166832447052\n",
      "acc for Lsat= 0.38395476251722266 \n",
      "acc for Psat= 0.5817154093614978 \n",
      "acc for optim= 0.2734982568366056\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.023271238431334496\n",
      "Loss on test= 0.023485224694013596\n",
      "acc for Lsat= 0.664542881441379 \n",
      "acc for Psat= 0.43484564919910224 \n",
      "acc for optim= 0.24654206303616252\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.020970109850168228\n",
      "Loss on test= 0.016731755807995796\n",
      "acc for Lsat= 0.3551785812115862 \n",
      "acc for Psat= 0.43393305127860093 \n",
      "acc for optim= 0.233354260175695\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.020377332344651222\n",
      "Loss on test= 0.03158751130104065\n",
      "acc for Lsat= 0.6623191410150822 \n",
      "acc for Psat= 0.440982456477817 \n",
      "acc for optim= 0.22517591633940817\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.02519378997385502\n",
      "Loss on test= 0.01899993233382702\n",
      "acc for Lsat= 0.4055550459390659 \n",
      "acc for Psat= 0.40303154881589387 \n",
      "acc for optim= 0.2321649890769937\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.019892534241080284\n",
      "Loss on test= 0.02342901937663555\n",
      "acc for Lsat= 0.3137464860228051 \n",
      "acc for Psat= 0.8275444493090856 \n",
      "acc for optim= 0.2520865904877237\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.019054334610700607\n",
      "Loss on test= 0.01605248637497425\n",
      "acc for Lsat= 0.33951518250262885 \n",
      "acc for Psat= 0.48698429921078956 \n",
      "acc for optim= 0.21442640406598687\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.018531452864408493\n",
      "Loss on test= 0.019276462495326996\n",
      "acc for Lsat= 0.31908270639985736 \n",
      "acc for Psat= 0.5927301927166705 \n",
      "acc for optim= 0.20355179205834562\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.019428202882409096\n",
      "Loss on test= 0.015267778187990189\n",
      "acc for Lsat= 0.3314232384892883 \n",
      "acc for Psat= 0.4059119494280732 \n",
      "acc for optim= 0.2179043268513881\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.02130666747689247\n",
      "Loss on test= 0.01810533180832863\n",
      "acc for Lsat= 0.3433760658898925 \n",
      "acc for Psat= 0.4904199618632432 \n",
      "acc for optim= 0.21491110854377574\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.019038911908864975\n",
      "Loss on test= 0.01805526576936245\n",
      "acc for Lsat= 0.4298333303014305 \n",
      "acc for Psat= 0.4274065423535458 \n",
      "acc for optim= 0.2046709513940589\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.01782681606709957\n",
      "Loss on test= 0.015302936546504498\n",
      "acc for Lsat= 0.29863220698774606 \n",
      "acc for Psat= 0.44368731949839085 \n",
      "acc for optim= 0.19923804601058975\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.015942011028528214\n",
      "Loss on test= 0.014052247628569603\n",
      "acc for Lsat= 0.2887051313455201 \n",
      "acc for Psat= 0.37517966821972953 \n",
      "acc for optim= 0.20315506417624182\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.015761738643050194\n",
      "Loss on test= 0.013723345473408699\n",
      "acc for Lsat= 0.3342535923672153 \n",
      "acc for Psat= 0.4131997366687741 \n",
      "acc for optim= 0.21150423734540455\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.015273508615791798\n",
      "Loss on test= 0.012856980785727501\n",
      "acc for Lsat= 0.3148800087600305 \n",
      "acc for Psat= 0.40969109177345137 \n",
      "acc for optim= 0.20535843518990107\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.014650436118245125\n",
      "Loss on test= 0.013683155179023743\n",
      "acc for Lsat= 0.3375391321077363 \n",
      "acc for Psat= 0.39805855117495514 \n",
      "acc for optim= 0.19443018984232768\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.014058242551982403\n",
      "Loss on test= 0.018490111455321312\n",
      "acc for Lsat= 0.2865692259285782 \n",
      "acc for Psat= 0.590911267910794 \n",
      "acc for optim= 0.2163084748284567\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.01571294665336609\n",
      "Loss on test= 0.014485994353890419\n",
      "acc for Lsat= 0.3499711637097014 \n",
      "acc for Psat= 0.32509707242849695 \n",
      "acc for optim= 0.19856781900142792\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.017115946859121323\n",
      "Loss on test= 0.015180429443717003\n",
      "acc for Lsat= 0.37523170234101105 \n",
      "acc for Psat= 0.4964501766944075 \n",
      "acc for optim= 0.18711804715312014\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.015253948979079723\n",
      "Loss on test= 0.012604021467268467\n",
      "acc for Lsat= 0.2898440060625616 \n",
      "acc for Psat= 0.38601740111490007 \n",
      "acc for optim= 0.1978453313565401\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.014245554804801941\n",
      "Loss on test= 0.012895484454929829\n",
      "acc for Lsat= 0.3007607651666879 \n",
      "acc for Psat= 0.3361726793303951 \n",
      "acc for optim= 0.18812595492378678\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.013584333471953869\n",
      "Loss on test= 0.0146919721737504\n",
      "acc for Lsat= 0.2963557075651851 \n",
      "acc for Psat= 0.33676818085941257 \n",
      "acc for optim= 0.2187987004550838\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.015085953287780285\n",
      "Loss on test= 0.01325184851884842\n",
      "acc for Lsat= 0.32319587899341445 \n",
      "acc for Psat= 0.3565785292629534 \n",
      "acc for optim= 0.23291366604599553\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.013003033585846424\n",
      "Loss on test= 0.012302594259381294\n",
      "acc for Lsat= 0.2796437927431114 \n",
      "acc for Psat= 0.3447786236859354 \n",
      "acc for optim= 0.185330254476151\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.01308341883122921\n",
      "Loss on test= 0.011077675968408585\n",
      "acc for Lsat= 0.24814968719223485 \n",
      "acc for Psat= 0.31903862026405566 \n",
      "acc for optim= 0.19411014534574056\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.012694351375102997\n",
      "Loss on test= 0.01330575905740261\n",
      "acc for Lsat= 0.32812763733148087 \n",
      "acc for Psat= 0.31469062484312255 \n",
      "acc for optim= 0.19022384689678057\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.012174608185887337\n",
      "Loss on test= 0.011459139175713062\n",
      "acc for Lsat= 0.29561130162729254 \n",
      "acc for Psat= 0.32772132676189236 \n",
      "acc for optim= 0.1920192373023353\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.013269148766994476\n",
      "Loss on test= 0.011247183196246624\n",
      "acc for Lsat= 0.22671194920014803 \n",
      "acc for Psat= 0.3134604452154981 \n",
      "acc for optim= 0.192173292534235\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.01237568724900484\n",
      "Loss on test= 0.012887194752693176\n",
      "acc for Lsat= 0.2495084591685092 \n",
      "acc for Psat= 0.45478313984502045 \n",
      "acc for optim= 0.19561440539832578\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.012119654566049576\n",
      "Loss on test= 0.010647257789969444\n",
      "acc for Lsat= 0.2550286618313279 \n",
      "acc for Psat= 0.30169657081266343 \n",
      "acc for optim= 0.18155124078306262\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.01164355967193842\n",
      "Loss on test= 0.011308875866234303\n",
      "acc for Lsat= 0.2571343739728871 \n",
      "acc for Psat= 0.30549238274393026 \n",
      "acc for optim= 0.19271439439998786\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.01144927367568016\n",
      "Loss on test= 0.009884551167488098\n",
      "acc for Lsat= 0.2327126594115293 \n",
      "acc for Psat= 0.2943225704172634 \n",
      "acc for optim= 0.18187990317182098\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.011051038280129433\n",
      "Loss on test= 0.01063337828963995\n",
      "acc for Lsat= 0.2533591968476864 \n",
      "acc for Psat= 0.3064689648007501 \n",
      "acc for optim= 0.1773988190769279\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.01123214140534401\n",
      "Loss on test= 0.01263030432164669\n",
      "acc for Lsat= 0.24277197828699576 \n",
      "acc for Psat= 0.4481713982131027 \n",
      "acc for optim= 0.18130556805761622\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.011832446791231632\n",
      "Loss on test= 0.013417905196547508\n",
      "acc for Lsat= 0.3468683408016003 \n",
      "acc for Psat= 0.32437574639763744 \n",
      "acc for optim= 0.1843431551454085\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.015138286165893078\n",
      "Loss on test= 0.013176999054849148\n",
      "acc for Lsat= 0.3262980558382744 \n",
      "acc for Psat= 0.3644475851383549 \n",
      "acc for optim= 0.17938894001730302\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.011801166459918022\n",
      "Loss on test= 0.00974083598703146\n",
      "acc for Lsat= 0.22938803165967836 \n",
      "acc for Psat= 0.2987636313063749 \n",
      "acc for optim= 0.17798524473328142\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.011505159549415112\n",
      "Loss on test= 0.010014685802161694\n",
      "acc for Lsat= 0.22297986848890536 \n",
      "acc for Psat= 0.2783048039946331 \n",
      "acc for optim= 0.1745985303805057\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.012636041268706322\n",
      "Loss on test= 0.010647681541740894\n",
      "acc for Lsat= 0.27039677887576724 \n",
      "acc for Psat= 0.3068841401624997 \n",
      "acc for optim= 0.18404255406568437\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.013359097763895988\n",
      "Loss on test= 0.012040340341627598\n",
      "acc for Lsat= 0.3179483774717378 \n",
      "acc for Psat= 0.290742108341379 \n",
      "acc for optim= 0.1867855395136981\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.013286707922816277\n",
      "Loss on test= 0.012349008582532406\n",
      "acc for Lsat= 0.2628316800780384 \n",
      "acc for Psat= 0.4799987704103782 \n",
      "acc for optim= 0.19017895549120306\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.012046346440911293\n",
      "Loss on test= 0.010821346193552017\n",
      "acc for Lsat= 0.25501341718958964 \n",
      "acc for Psat= 0.29571865500851735 \n",
      "acc for optim= 0.18494022036139227\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.011687498539686203\n",
      "Loss on test= 0.009695037268102169\n",
      "acc for Lsat= 0.23431758737405303 \n",
      "acc for Psat= 0.2930022381665949 \n",
      "acc for optim= 0.17197615818815215\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.011045623570680618\n",
      "Loss on test= 0.009733961895108223\n",
      "acc for Lsat= 0.26348432232969304 \n",
      "acc for Psat= 0.2747592021039397 \n",
      "acc for optim= 0.16504686122701015\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.011030199937522411\n",
      "Loss on test= 0.00921274907886982\n",
      "acc for Lsat= 0.1967062638265741 \n",
      "acc for Psat= 0.2687619517908477 \n",
      "acc for optim= 0.17548065773501503\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.01033874787390232\n",
      "Loss on test= 0.009153596125543118\n",
      "acc for Lsat= 0.22978744003998086 \n",
      "acc for Psat= 0.2946219368169817 \n",
      "acc for optim= 0.1805888432532274\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.010168792679905891\n",
      "Loss on test= 0.008859744295477867\n",
      "acc for Lsat= 0.2120860181944483 \n",
      "acc for Psat= 0.2528580122179787 \n",
      "acc for optim= 0.17368382938214783\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.009392616339027882\n",
      "Loss on test= 0.010177373886108398\n",
      "acc for Lsat= 0.20606045058821557 \n",
      "acc for Psat= 0.34661628667486555 \n",
      "acc for optim= 0.18474204563969923\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.010365653783082962\n",
      "Loss on test= 0.009705944918096066\n",
      "acc for Lsat= 0.2117060991859094 \n",
      "acc for Psat= 0.35069668475217874 \n",
      "acc for optim= 0.18608154459941376\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.012195823714137077\n",
      "Loss on test= 0.013432033360004425\n",
      "acc for Lsat= 0.3033270432323706 \n",
      "acc for Psat= 0.39999937901452765 \n",
      "acc for optim= 0.18727414290664993\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.012521862983703613\n",
      "Loss on test= 0.009651641361415386\n",
      "acc for Lsat= 0.23429170276656686 \n",
      "acc for Psat= 0.3040276833550363 \n",
      "acc for optim= 0.17479332691882965\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.009972898289561272\n",
      "Loss on test= 0.01113130059093237\n",
      "acc for Lsat= 0.23884714202970633 \n",
      "acc for Psat= 0.3061772324740276 \n",
      "acc for optim= 0.18796963393540594\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.009855460375547409\n",
      "Loss on test= 0.00913246814161539\n",
      "acc for Lsat= 0.2295032414630605 \n",
      "acc for Psat= 0.2767370246904215 \n",
      "acc for optim= 0.1765184184852186\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.010330918245017529\n",
      "Loss on test= 0.008743075653910637\n",
      "acc for Lsat= 0.2273045969592621 \n",
      "acc for Psat= 0.2561265449423236 \n",
      "acc for optim= 0.1772108495796527\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.009440308436751366\n",
      "Loss on test= 0.011442855931818485\n",
      "acc for Lsat= 0.257558176627375 \n",
      "acc for Psat= 0.3238384627011895 \n",
      "acc for optim= 0.18415878864967067\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.01068677008152008\n",
      "Loss on test= 0.009343230165541172\n",
      "acc for Lsat= 0.2648922801575028 \n",
      "acc for Psat= 0.2832135707305646 \n",
      "acc for optim= 0.17213993165985544\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.010180764831602573\n",
      "Loss on test= 0.00877558533102274\n",
      "acc for Lsat= 0.23391977765470492 \n",
      "acc for Psat= 0.2682305734245809 \n",
      "acc for optim= 0.18928957824885356\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.009289379231631756\n",
      "Loss on test= 0.008761657401919365\n",
      "acc for Lsat= 0.20482544010413475 \n",
      "acc for Psat= 0.25657803211895536 \n",
      "acc for optim= 0.17627982722068603\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.009092863649129868\n",
      "Loss on test= 0.008569519966840744\n",
      "acc for Lsat= 0.2135677409449928 \n",
      "acc for Psat= 0.29783352480401654 \n",
      "acc for optim= 0.18148341038718543\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.009096738882362843\n",
      "Loss on test= 0.009058970957994461\n",
      "acc for Lsat= 0.20980958388545778 \n",
      "acc for Psat= 0.255959807865543 \n",
      "acc for optim= 0.1748397340910265\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.010428501293063164\n",
      "Loss on test= 0.00902258139103651\n",
      "acc for Lsat= 0.2301908841142889 \n",
      "acc for Psat= 0.33305786919062497 \n",
      "acc for optim= 0.17240546173730972\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.010325310751795769\n",
      "Loss on test= 0.00956032332032919\n",
      "acc for Lsat= 0.2649780655233953 \n",
      "acc for Psat= 0.2408730890907225 \n",
      "acc for optim= 0.18004908061693192\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.011703637428581715\n",
      "Loss on test= 0.01102400291711092\n",
      "acc for Lsat= 0.2651749510041316 \n",
      "acc for Psat= 0.3325496875289751 \n",
      "acc for optim= 0.18969219072710447\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.009718405082821846\n",
      "Loss on test= 0.008351918309926987\n",
      "acc for Lsat= 0.23386171248829238 \n",
      "acc for Psat= 0.23289510135493074 \n",
      "acc for optim= 0.17427218039386494\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.009713923558592796\n",
      "Loss on test= 0.008854529820382595\n",
      "acc for Lsat= 0.19543371235409782 \n",
      "acc for Psat= 0.28751298247952944 \n",
      "acc for optim= 0.17106882034377272\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.008777719922363758\n",
      "Loss on test= 0.008033998310565948\n",
      "acc for Lsat= 0.19661006636187134 \n",
      "acc for Psat= 0.2615883500052122 \n",
      "acc for optim= 0.18162616894534622\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.00920791458338499\n",
      "Loss on test= 0.007929595187306404\n",
      "acc for Lsat= 0.17592107990726097 \n",
      "acc for Psat= 0.24002028697887895 \n",
      "acc for optim= 0.174586222836076\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.009430784732103348\n",
      "Loss on test= 0.008215724490582943\n",
      "acc for Lsat= 0.1774735211377551 \n",
      "acc for Psat= 0.2459264051906772 \n",
      "acc for optim= 0.17831892751855777\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.00876913033425808\n",
      "Loss on test= 0.008258078247308731\n",
      "acc for Lsat= 0.18367068082033122 \n",
      "acc for Psat= 0.2596203923881909 \n",
      "acc for optim= 0.17588111820981883\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.008881389163434505\n",
      "Loss on test= 0.007992422208189964\n",
      "acc for Lsat= 0.1938883755490619 \n",
      "acc for Psat= 0.2513049680533529 \n",
      "acc for optim= 0.173469178996776\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.008902674540877342\n",
      "Loss on test= 0.008835317566990852\n",
      "acc for Lsat= 0.18359854373848067 \n",
      "acc for Psat= 0.27773181250171936 \n",
      "acc for optim= 0.17040930448947322\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.008803470060229301\n",
      "Loss on test= 0.008837733417749405\n",
      "acc for Lsat= 0.2596658717401967 \n",
      "acc for Psat= 0.2510788785102854 \n",
      "acc for optim= 0.17305577944345835\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.009301284328103065\n",
      "Loss on test= 0.008980304934084415\n",
      "acc for Lsat= 0.24772384171603157 \n",
      "acc for Psat= 0.2624724309166252 \n",
      "acc for optim= 0.16893028691023962\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.008965512737631798\n",
      "Loss on test= 0.008011874742805958\n",
      "acc for Lsat= 0.1857323121611548 \n",
      "acc for Psat= 0.2213638401326922 \n",
      "acc for optim= 0.1647244553413761\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.00860060378909111\n",
      "Loss on test= 0.009012183174490929\n",
      "acc for Lsat= 0.215883683982748 \n",
      "acc for Psat= 0.2464480074628287 \n",
      "acc for optim= 0.169994772694524\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.008808400481939316\n",
      "Loss on test= 0.008083044551312923\n",
      "acc for Lsat= 0.20736389521716475 \n",
      "acc for Psat= 0.2366339033824529 \n",
      "acc for optim= 0.1691708576583044\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.009358176961541176\n",
      "Loss on test= 0.008115848526358604\n",
      "acc for Lsat= 0.22773919726357428 \n",
      "acc for Psat= 0.2562443678998236 \n",
      "acc for optim= 0.1742955048002692\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.010288442485034466\n",
      "Loss on test= 0.007731948979198933\n",
      "acc for Lsat= 0.19413432603373695 \n",
      "acc for Psat= 0.25575772818391684 \n",
      "acc for optim= 0.16849407403554278\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.009216477163136005\n",
      "Loss on test= 0.008483655750751495\n",
      "acc for Lsat= 0.2158220693930892 \n",
      "acc for Psat= 0.26779220431172823 \n",
      "acc for optim= 0.18072507024025086\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.009141207672655582\n",
      "Loss on test= 0.008448520675301552\n",
      "acc for Lsat= 0.20262158078095707 \n",
      "acc for Psat= 0.2446943294856178 \n",
      "acc for optim= 0.18008313498509376\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.008155034855008125\n",
      "Loss on test= 0.007515644654631615\n",
      "acc for Lsat= 0.17702639800044098 \n",
      "acc for Psat= 0.2341108904143826 \n",
      "acc for optim= 0.17608348090071843\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.008209789171814919\n",
      "Loss on test= 0.007880933582782745\n",
      "acc for Lsat= 0.1915554185324925 \n",
      "acc for Psat= 0.23961998614936791 \n",
      "acc for optim= 0.17043289730065792\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.008551804348826408\n",
      "Loss on test= 0.008825327269732952\n",
      "acc for Lsat= 0.2115507819966237 \n",
      "acc for Psat= 0.2832124492539032 \n",
      "acc for optim= 0.17493681115533424\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.009952543303370476\n",
      "Loss on test= 0.009337873198091984\n",
      "acc for Lsat= 0.19452822526122948 \n",
      "acc for Psat= 0.29392438827990935 \n",
      "acc for optim= 0.20394703249416513\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.009796938858926296\n",
      "Loss on test= 0.00791182927787304\n",
      "acc for Lsat= 0.21705490396583269 \n",
      "acc for Psat= 0.27020934172409783 \n",
      "acc for optim= 0.17312205879010076\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.008857284672558308\n",
      "Loss on test= 0.008165284059941769\n",
      "acc for Lsat= 0.22675637736855472 \n",
      "acc for Psat= 0.22265354413863608 \n",
      "acc for optim= 0.16655455290184348\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.008658263832330704\n",
      "Loss on test= 0.007999798282980919\n",
      "acc for Lsat= 0.19084301957494168 \n",
      "acc for Psat= 0.23257375086865723 \n",
      "acc for optim= 0.1752956204720368\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.00865253433585167\n",
      "Loss on test= 0.008642449043691158\n",
      "acc for Lsat= 0.19118624036849216 \n",
      "acc for Psat= 0.27670104514323673 \n",
      "acc for optim= 0.17611807581623176\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.009369916282594204\n",
      "Loss on test= 0.008412056602537632\n",
      "acc for Lsat= 0.22150701206548667 \n",
      "acc for Psat= 0.2526859479925794 \n",
      "acc for optim= 0.17619255250071741\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.008355891332030296\n",
      "Loss on test= 0.00754897017031908\n",
      "acc for Lsat= 0.1982304309413088 \n",
      "acc for Psat= 0.2385944804763536 \n",
      "acc for optim= 0.17995656625764658\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.008103723637759686\n",
      "Loss on test= 0.007734674494713545\n",
      "acc for Lsat= 0.19674483595519007 \n",
      "acc for Psat= 0.23491703502330014 \n",
      "acc for optim= 0.17199913211296633\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.00811651349067688\n",
      "Loss on test= 0.007588556967675686\n",
      "acc for Lsat= 0.1974728195076273 \n",
      "acc for Psat= 0.22632564229463212 \n",
      "acc for optim= 0.17740764292491387\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.007950598374009132\n",
      "Loss on test= 0.007711612153798342\n",
      "acc for Lsat= 0.18767198870172266 \n",
      "acc for Psat= 0.21884466753967227 \n",
      "acc for optim= 0.16988790087367514\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.008815576322376728\n",
      "Loss on test= 0.007766746450215578\n",
      "acc for Lsat= 0.18629044832520522 \n",
      "acc for Psat= 0.24902606528313434 \n",
      "acc for optim= 0.17484638917328577\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.008708192966878414\n",
      "Loss on test= 0.007940292358398438\n",
      "acc for Lsat= 0.18404344383070864 \n",
      "acc for Psat= 0.2451266818290546 \n",
      "acc for optim= 0.17629538891931468\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.008185304701328278\n",
      "Loss on test= 0.007791898213326931\n",
      "acc for Lsat= 0.19604487663218903 \n",
      "acc for Psat= 0.23841425748105394 \n",
      "acc for optim= 0.17296998900243035\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.008232565596699715\n",
      "Loss on test= 0.007158696185797453\n",
      "acc for Lsat= 0.17870897964734705 \n",
      "acc for Psat= 0.2260680231506188 \n",
      "acc for optim= 0.16934442292272922\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.007953254505991936\n",
      "Loss on test= 0.006964878179132938\n",
      "acc for Lsat= 0.19525296996694944 \n",
      "acc for Psat= 0.2429291688726421 \n",
      "acc for optim= 0.16473482300491132\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.007570905145257711\n",
      "Loss on test= 0.0075527080334723\n",
      "acc for Lsat= 0.1788345992603324 \n",
      "acc for Psat= 0.21938632398110922 \n",
      "acc for optim= 0.17115030458090125\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.00831894762814045\n",
      "Loss on test= 0.007357687223702669\n",
      "acc for Lsat= 0.19980375589960309 \n",
      "acc for Psat= 0.2293179158651896 \n",
      "acc for optim= 0.1712324102546592\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.007695748005062342\n",
      "Loss on test= 0.0076381065882742405\n",
      "acc for Lsat= 0.22273462607418415 \n",
      "acc for Psat= 0.2365789182739882 \n",
      "acc for optim= 0.17412975271180897\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.008060773834586143\n",
      "Loss on test= 0.00785770546644926\n",
      "acc for Lsat= 0.1804726139961009 \n",
      "acc for Psat= 0.2551169120649364 \n",
      "acc for optim= 0.16968688421184197\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.008614856749773026\n",
      "Loss on test= 0.008411790244281292\n",
      "acc for Lsat= 0.21031075901949214 \n",
      "acc for Psat= 0.24529681401384507 \n",
      "acc for optim= 0.16946722591509583\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.007893992587924004\n",
      "Loss on test= 0.007743569556623697\n",
      "acc for Lsat= 0.17612406085875099 \n",
      "acc for Psat= 0.2661206918953704 \n",
      "acc for optim= 0.1770394173337752\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.007904850877821445\n",
      "Loss on test= 0.007366099860519171\n",
      "acc for Lsat= 0.20420761062672027 \n",
      "acc for Psat= 0.2189919852170727 \n",
      "acc for optim= 0.17239702143420113\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.007731462363153696\n",
      "Loss on test= 0.007631679996848106\n",
      "acc for Lsat= 0.20086185391324374 \n",
      "acc for Psat= 0.25196604111392173 \n",
      "acc for optim= 0.1662849331366234\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.007547350134700537\n",
      "Loss on test= 0.007419239729642868\n",
      "acc for Lsat= 0.19994014730380244 \n",
      "acc for Psat= 0.2465037899675825 \n",
      "acc for optim= 0.1727744876983438\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.007773098535835743\n",
      "Loss on test= 0.007554482668638229\n",
      "acc for Lsat= 0.2288688325235376 \n",
      "acc for Psat= 0.21655475252697276 \n",
      "acc for optim= 0.16531779385156564\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.0077737607061862946\n",
      "Loss on test= 0.007250883616507053\n",
      "acc for Lsat= 0.17064213763252586 \n",
      "acc for Psat= 0.23156178359259072 \n",
      "acc for optim= 0.16527057209060017\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.008034874685108662\n",
      "Loss on test= 0.007565222214907408\n",
      "acc for Lsat= 0.18364027262422958 \n",
      "acc for Psat= 0.21619451769034104 \n",
      "acc for optim= 0.17029906083738094\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.007610356900840998\n",
      "Loss on test= 0.007145729847252369\n",
      "acc for Lsat= 0.18892751926771884 \n",
      "acc for Psat= 0.2240290773219475 \n",
      "acc for optim= 0.17308722953130795\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.007709711790084839\n",
      "Loss on test= 0.007428240962326527\n",
      "acc for Lsat= 0.17485565741901424 \n",
      "acc for Psat= 0.2491058149016233 \n",
      "acc for optim= 0.16993074516157933\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.007405053824186325\n",
      "Loss on test= 0.007652398198843002\n",
      "acc for Lsat= 0.2074886739471561 \n",
      "acc for Psat= 0.2357237081936576 \n",
      "acc for optim= 0.1699637301153118\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.007643336895853281\n",
      "Loss on test= 0.007600376382470131\n",
      "acc for Lsat= 0.18302823629909667 \n",
      "acc for Psat= 0.22858009894200043 \n",
      "acc for optim= 0.1685608822050825\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.00794338621199131\n",
      "Loss on test= 0.00875469297170639\n",
      "acc for Lsat= 0.23766627997383247 \n",
      "acc for Psat= 0.2332636784441525 \n",
      "acc for optim= 0.16400288691355125\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.008299381472170353\n",
      "Loss on test= 0.007285040803253651\n",
      "acc for Lsat= 0.16806916097993962 \n",
      "acc for Psat= 0.24323957827720852 \n",
      "acc for optim= 0.17006631926666815\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.007551542017608881\n",
      "Loss on test= 0.007471046876162291\n",
      "acc for Lsat= 0.18281600545007798 \n",
      "acc for Psat= 0.21430422160965315 \n",
      "acc for optim= 0.17044323382428733\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.007349009625613689\n",
      "Loss on test= 0.006786242593079805\n",
      "acc for Lsat= 0.17472197794676073 \n",
      "acc for Psat= 0.21316852428965638 \n",
      "acc for optim= 0.17108166564683444\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.007684401236474514\n",
      "Loss on test= 0.007299826014786959\n",
      "acc for Lsat= 0.1852152267335456 \n",
      "acc for Psat= 0.21679105818687677 \n",
      "acc for optim= 0.18075374067440383\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.008004619739949703\n",
      "Loss on test= 0.007021055091172457\n",
      "acc for Lsat= 0.19242793894395543 \n",
      "acc for Psat= 0.22957392599334422 \n",
      "acc for optim= 0.17255585753978192\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.007214558310806751\n",
      "Loss on test= 0.007912132889032364\n",
      "acc for Lsat= 0.18958908213172718 \n",
      "acc for Psat= 0.256176094046687 \n",
      "acc for optim= 0.16873456093360534\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.00747188413515687\n",
      "Loss on test= 0.007469932548701763\n",
      "acc for Lsat= 0.19033928428028452 \n",
      "acc for Psat= 0.21469604489231314 \n",
      "acc for optim= 0.1717369933051561\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.00722140958532691\n",
      "Loss on test= 0.006652707699686289\n",
      "acc for Lsat= 0.176517053405739 \n",
      "acc for Psat= 0.2103934905631086 \n",
      "acc for optim= 0.169674424568695\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.00702000642195344\n",
      "Loss on test= 0.007047560065984726\n",
      "acc for Lsat= 0.17586954088346532 \n",
      "acc for Psat= 0.21327245478961068 \n",
      "acc for optim= 0.16558566461794352\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.007146787829697132\n",
      "Loss on test= 0.006807807367295027\n",
      "acc for Lsat= 0.17157246619975863 \n",
      "acc for Psat= 0.21500054148200434 \n",
      "acc for optim= 0.16587909716038324\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.007268680725246668\n",
      "Loss on test= 0.007015611510723829\n",
      "acc for Lsat= 0.1737982383699225 \n",
      "acc for Psat= 0.21609059667188987 \n",
      "acc for optim= 0.16267849129517792\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.006781107746064663\n",
      "Loss on test= 0.007119619753211737\n",
      "acc for Lsat= 0.18593860678374768 \n",
      "acc for Psat= 0.21346389817257153 \n",
      "acc for optim= 0.16668417709068487\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.007544319145381451\n",
      "Loss on test= 0.006609547883272171\n",
      "acc for Lsat= 0.18497554193227933 \n",
      "acc for Psat= 0.22278331234654197 \n",
      "acc for optim= 0.1712076657846738\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.007478184066712856\n",
      "Loss on test= 0.0070761507377028465\n",
      "acc for Lsat= 0.1911326632506718 \n",
      "acc for Psat= 0.22255996178881432 \n",
      "acc for optim= 0.16786905876055483\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.00727195804938674\n",
      "Loss on test= 0.007240891922265291\n",
      "acc for Lsat= 0.1783380926495082 \n",
      "acc for Psat= 0.21341763137340913 \n",
      "acc for optim= 0.1692238643238718\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.007459490559995174\n",
      "Loss on test= 0.007116093300282955\n",
      "acc for Lsat= 0.17143565043043651 \n",
      "acc for Psat= 0.23124341065518284 \n",
      "acc for optim= 0.16561445659036045\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.0070335641503334045\n",
      "Loss on test= 0.007139940746128559\n",
      "acc for Lsat= 0.19634419672294198 \n",
      "acc for Psat= 0.22309852379763528 \n",
      "acc for optim= 0.16621083654596883\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.0070139458402991295\n",
      "Loss on test= 0.006479053292423487\n",
      "acc for Lsat= 0.17216559237994722 \n",
      "acc for Psat= 0.19492295809418392 \n",
      "acc for optim= 0.1653195251467386\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.00737204123288393\n",
      "Loss on test= 0.007395684253424406\n",
      "acc for Lsat= 0.1852578105655934 \n",
      "acc for Psat= 0.26200619447579393 \n",
      "acc for optim= 0.17663993924153876\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.007438997272402048\n",
      "Loss on test= 0.00667235441505909\n",
      "acc for Lsat= 0.17461326433857138 \n",
      "acc for Psat= 0.21441936846326304 \n",
      "acc for optim= 0.17299784255809472\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.006848908960819244\n",
      "Loss on test= 0.007015678565949202\n",
      "acc for Lsat= 0.16960871214024173 \n",
      "acc for Psat= 0.23188761990941054 \n",
      "acc for optim= 0.16954669726248658\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.007257424294948578\n",
      "Loss on test= 0.006997926160693169\n",
      "acc for Lsat= 0.18364508182772238 \n",
      "acc for Psat= 0.20068616684732318 \n",
      "acc for optim= 0.17150636827611349\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.007567060645669699\n",
      "Loss on test= 0.006788116414099932\n",
      "acc for Lsat= 0.1684348201783771 \n",
      "acc for Psat= 0.20745559243912823 \n",
      "acc for optim= 0.16987251435429407\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.007175636477768421\n",
      "Loss on test= 0.007159239146858454\n",
      "acc for Lsat= 0.17499664308883528 \n",
      "acc for Psat= 0.2096927844896363 \n",
      "acc for optim= 0.1678388673470539\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.006876513361930847\n",
      "Loss on test= 0.0062819537706673145\n",
      "acc for Lsat= 0.18796069720681502 \n",
      "acc for Psat= 0.19256925847158066 \n",
      "acc for optim= 0.16657894119261535\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.007369919680058956\n",
      "Loss on test= 0.007278427481651306\n",
      "acc for Lsat= 0.16871671502966984 \n",
      "acc for Psat= 0.22673144393970762 \n",
      "acc for optim= 0.16924372281689296\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.007379735354334116\n",
      "Loss on test= 0.0074973925948143005\n",
      "acc for Lsat= 0.19553276612881387 \n",
      "acc for Psat= 0.2080282201089698 \n",
      "acc for optim= 0.17030027936666928\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.007402648683637381\n",
      "Loss on test= 0.00689317611977458\n",
      "acc for Lsat= 0.17884520713724655 \n",
      "acc for Psat= 0.21439293593656822 \n",
      "acc for optim= 0.16254113282527408\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.007361975498497486\n",
      "Loss on test= 0.006650593131780624\n",
      "acc for Lsat= 0.19416246342751364 \n",
      "acc for Psat= 0.21178798087095826 \n",
      "acc for optim= 0.16458587169830427\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.00763055169954896\n",
      "Loss on test= 0.006984893698245287\n",
      "acc for Lsat= 0.16525226451998545 \n",
      "acc for Psat= 0.21069724167154177 \n",
      "acc for optim= 0.1764985732863978\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.006899066269397736\n",
      "Loss on test= 0.0069164102897048\n",
      "acc for Lsat= 0.17378639905602808 \n",
      "acc for Psat= 0.22066548425917987 \n",
      "acc for optim= 0.17618437450661584\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.007365432567894459\n",
      "Loss on test= 0.006905389949679375\n",
      "acc for Lsat= 0.18260665814560212 \n",
      "acc for Psat= 0.21563280464062223 \n",
      "acc for optim= 0.17120705885988216\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.007122465409338474\n",
      "Loss on test= 0.00632074847817421\n",
      "acc for Lsat= 0.16766357928224396 \n",
      "acc for Psat= 0.22228117340461917 \n",
      "acc for optim= 0.17379440225424153\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.007192193064838648\n",
      "Loss on test= 0.0070104137994349\n",
      "acc for Lsat= 0.1669850817872698 \n",
      "acc for Psat= 0.20166926158565388 \n",
      "acc for optim= 0.16131204287046816\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.006945442408323288\n",
      "Loss on test= 0.007037540432065725\n",
      "acc for Lsat= 0.16636864556663777 \n",
      "acc for Psat= 0.2166552139772484 \n",
      "acc for optim= 0.16843388122749767\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.006814734078943729\n",
      "Loss on test= 0.006560632027685642\n",
      "acc for Lsat= 0.17890384679274457 \n",
      "acc for Psat= 0.21537049750140944 \n",
      "acc for optim= 0.16651826453792146\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.006683351006358862\n",
      "Loss on test= 0.006653269752860069\n",
      "acc for Lsat= 0.15201206036221204 \n",
      "acc for Psat= 0.19348216769390464 \n",
      "acc for optim= 0.15826844413398353\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.007353085093200207\n",
      "Loss on test= 0.006480762735009193\n",
      "acc for Lsat= 0.17482521014711386 \n",
      "acc for Psat= 0.2080703867257756 \n",
      "acc for optim= 0.1697744358621407\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.006866678595542908\n",
      "Loss on test= 0.0064073544926941395\n",
      "acc for Lsat= 0.16312739767332668 \n",
      "acc for Psat= 0.204908032777536 \n",
      "acc for optim= 0.16898242360110716\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.006857443600893021\n",
      "Loss on test= 0.006841625086963177\n",
      "acc for Lsat= 0.1945536308477205 \n",
      "acc for Psat= 0.20209804741326018 \n",
      "acc for optim= 0.1691005896330338\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.00669578742235899\n",
      "Loss on test= 0.006680286023765802\n",
      "acc for Lsat= 0.15632600663840526 \n",
      "acc for Psat= 0.20988979261429583 \n",
      "acc for optim= 0.16836771426920885\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.006901262793689966\n",
      "Loss on test= 0.007511948700994253\n",
      "acc for Lsat= 0.17693796806661488 \n",
      "acc for Psat= 0.22985811620238847 \n",
      "acc for optim= 0.16730028470686148\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.006970175541937351\n",
      "Loss on test= 0.007412954233586788\n",
      "acc for Lsat= 0.17058427491393247 \n",
      "acc for Psat= 0.19856692804419626 \n",
      "acc for optim= 0.1641216566007523\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.007242797873914242\n",
      "Loss on test= 0.007090756203979254\n",
      "acc for Lsat= 0.16790659678832734 \n",
      "acc for Psat= 0.2362201432241356 \n",
      "acc for optim= 0.15714662636546264\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.007151763886213303\n",
      "Loss on test= 0.0068372092209756374\n",
      "acc for Lsat= 0.15752042068939534 \n",
      "acc for Psat= 0.2052874210386033 \n",
      "acc for optim= 0.16092364549728447\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.007099764887243509\n",
      "Loss on test= 0.006935365032404661\n",
      "acc for Lsat= 0.2003750863189229 \n",
      "acc for Psat= 0.19449715262477393 \n",
      "acc for optim= 0.17139169110279134\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.007330308668315411\n",
      "Loss on test= 0.0073674567975103855\n",
      "acc for Lsat= 0.17932346935124427 \n",
      "acc for Psat= 0.2099269848897076 \n",
      "acc for optim= 0.16314429613173803\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.007131581194698811\n",
      "Loss on test= 0.006945917848497629\n",
      "acc for Lsat= 0.1685149527841904 \n",
      "acc for Psat= 0.20665706811839196 \n",
      "acc for optim= 0.16901075503498805\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.006902450229972601\n",
      "Loss on test= 0.006674428936094046\n",
      "acc for Lsat= 0.17537726450455757 \n",
      "acc for Psat= 0.21241189990119655 \n",
      "acc for optim= 0.17460591093423303\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.006933815777301788\n",
      "Loss on test= 0.006564261391758919\n",
      "acc for Lsat= 0.1580897035833914 \n",
      "acc for Psat= 0.20649213895438331 \n",
      "acc for optim= 0.1787031906490886\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.006657873280346394\n",
      "Loss on test= 0.0067353020422160625\n",
      "acc for Lsat= 0.17586663846560127 \n",
      "acc for Psat= 0.21137146620560804 \n",
      "acc for optim= 0.15890663774878733\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.006827914621680975\n",
      "Loss on test= 0.007078874856233597\n",
      "acc for Lsat= 0.16901901075702358 \n",
      "acc for Psat= 0.20429133277273828 \n",
      "acc for optim= 0.17280630386877255\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.006935633718967438\n",
      "Loss on test= 0.006958623882383108\n",
      "acc for Lsat= 0.17090679335514786 \n",
      "acc for Psat= 0.19754647537779643 \n",
      "acc for optim= 0.1727883509417507\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.006702052894979715\n",
      "Loss on test= 0.006448897998780012\n",
      "acc for Lsat= 0.16092087806500188 \n",
      "acc for Psat= 0.19986012935198053 \n",
      "acc for optim= 0.17382578067316914\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.006703564431518316\n",
      "Loss on test= 0.006314276251941919\n",
      "acc for Lsat= 0.16314701735744344 \n",
      "acc for Psat= 0.20908718319098296 \n",
      "acc for optim= 0.1711385179963726\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.00664472347125411\n",
      "Loss on test= 0.006469869054853916\n",
      "acc for Lsat= 0.1683285124035033 \n",
      "acc for Psat= 0.20420009333060168 \n",
      "acc for optim= 0.16936646588261192\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.00687069445848465\n",
      "Loss on test= 0.006645063403993845\n",
      "acc for Lsat= 0.17926258543245285 \n",
      "acc for Psat= 0.20140064048877113 \n",
      "acc for optim= 0.1721136334056386\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.006760263349860907\n",
      "Loss on test= 0.006964856293052435\n",
      "acc for Lsat= 0.1590061608329797 \n",
      "acc for Psat= 0.20199545470293473 \n",
      "acc for optim= 0.16610743430544256\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.006816653069108725\n",
      "Loss on test= 0.006701638922095299\n",
      "acc for Lsat= 0.17065722434361633 \n",
      "acc for Psat= 0.19548138798759357 \n",
      "acc for optim= 0.1733510487655189\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.006433775182813406\n",
      "Loss on test= 0.006447894033044577\n",
      "acc for Lsat= 0.166747659062356 \n",
      "acc for Psat= 0.2066220829970648 \n",
      "acc for optim= 0.16920413717200034\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.006614225450903177\n",
      "Loss on test= 0.006368344184011221\n",
      "acc for Lsat= 0.16280815713718289 \n",
      "acc for Psat= 0.2195726586129091 \n",
      "acc for optim= 0.17631998029919188\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.006571450736373663\n",
      "Loss on test= 0.006578507367521524\n",
      "acc for Lsat= 0.17385199311061486 \n",
      "acc for Psat= 0.20758641424081212 \n",
      "acc for optim= 0.16925604245071987\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.006956149823963642\n",
      "Loss on test= 0.006768551655113697\n",
      "acc for Lsat= 0.17339601588614864 \n",
      "acc for Psat= 0.2100643068250721 \n",
      "acc for optim= 0.17250766927666475\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.006941519677639008\n",
      "Loss on test= 0.006567824631929398\n",
      "acc for Lsat= 0.1561267083274109 \n",
      "acc for Psat= 0.20165127941224054 \n",
      "acc for optim= 0.1648671326780936\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.006484250072389841\n",
      "Loss on test= 0.0064855702221393585\n",
      "acc for Lsat= 0.1620244321535479 \n",
      "acc for Psat= 0.20118721357392164 \n",
      "acc for optim= 0.16602148937040437\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.0063651613891124725\n",
      "Loss on test= 0.006787301506847143\n",
      "acc for Lsat= 0.16447054059817226 \n",
      "acc for Psat= 0.22080090041255643 \n",
      "acc for optim= 0.17193827314119114\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.006726948078721762\n",
      "Loss on test= 0.006647228728979826\n",
      "acc for Lsat= 0.18075816721853907 \n",
      "acc for Psat= 0.20408396553324504 \n",
      "acc for optim= 0.16373566058736302\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.006608281284570694\n",
      "Loss on test= 0.006536243017762899\n",
      "acc for Lsat= 0.1677070006735806 \n",
      "acc for Psat= 0.19622113625547605 \n",
      "acc for optim= 0.16296989509881643\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.006450908724218607\n",
      "Loss on test= 0.006224251817911863\n",
      "acc for Lsat= 0.1596314611604254 \n",
      "acc for Psat= 0.18714943506953413 \n",
      "acc for optim= 0.16627972407503144\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.006660766899585724\n",
      "Loss on test= 0.006435695104300976\n",
      "acc for Lsat= 0.1651910277403181 \n",
      "acc for Psat= 0.21823094106683905 \n",
      "acc for optim= 0.16614308881482548\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.0064727240242064\n",
      "Loss on test= 0.006901347078382969\n",
      "acc for Lsat= 0.16344639113875198 \n",
      "acc for Psat= 0.19226622555164438 \n",
      "acc for optim= 0.16550525880936862\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.006258024834096432\n",
      "Loss on test= 0.006940803490579128\n",
      "acc for Lsat= 0.1609352586325258 \n",
      "acc for Psat= 0.2002003074316384 \n",
      "acc for optim= 0.1769689038243206\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.006568379700183868\n",
      "Loss on test= 0.006522107869386673\n",
      "acc for Lsat= 0.15744590017616322 \n",
      "acc for Psat= 0.2008487322999424 \n",
      "acc for optim= 0.16604088412876408\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.006493234541267157\n",
      "Loss on test= 0.0063310121186077595\n",
      "acc for Lsat= 0.1533359979678205 \n",
      "acc for Psat= 0.20596335363578144 \n",
      "acc for optim= 0.16086398024249393\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.007229458540678024\n",
      "Loss on test= 0.0066968216560781\n",
      "acc for Lsat= 0.16903837068334648 \n",
      "acc for Psat= 0.21116545851739338 \n",
      "acc for optim= 0.17258793316499071\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.007026118226349354\n",
      "Loss on test= 0.006446818355470896\n",
      "acc for Lsat= 0.17086605860767734 \n",
      "acc for Psat= 0.19962491258108353 \n",
      "acc for optim= 0.17110850703711697\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.006680308375507593\n",
      "Loss on test= 0.006618421524763107\n",
      "acc for Lsat= 0.1553676592551561 \n",
      "acc for Psat= 0.18617737729285583 \n",
      "acc for optim= 0.16605701084615143\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.006682899780571461\n",
      "Loss on test= 0.00682069594040513\n",
      "acc for Lsat= 0.14976703073508793 \n",
      "acc for Psat= 0.19562040996350363 \n",
      "acc for optim= 0.1700231536646511\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.006500641815364361\n",
      "Loss on test= 0.006515606306493282\n",
      "acc for Lsat= 0.16141286912129918 \n",
      "acc for Psat= 0.19424653878000367 \n",
      "acc for optim= 0.17369900252173853\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.006319449283182621\n",
      "Loss on test= 0.006208827253431082\n",
      "acc for Lsat= 0.16015460183424113 \n",
      "acc for Psat= 0.206105291874522 \n",
      "acc for optim= 0.1669404743991212\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.006567658390849829\n",
      "Loss on test= 0.006361291278153658\n",
      "acc for Lsat= 0.15610911431169788 \n",
      "acc for Psat= 0.20002626937348394 \n",
      "acc for optim= 0.16681068309575137\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.006486883852630854\n",
      "Loss on test= 0.006656517740339041\n",
      "acc for Lsat= 0.16246836058486283 \n",
      "acc for Psat= 0.2026680746502205 \n",
      "acc for optim= 0.16422469087329608\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.006593007594347\n",
      "Loss on test= 0.007143838331103325\n",
      "acc for Lsat= 0.1685577094623605 \n",
      "acc for Psat= 0.20820830714899366 \n",
      "acc for optim= 0.16479529515300023\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.006430815905332565\n",
      "Loss on test= 0.0063940491527318954\n",
      "acc for Lsat= 0.16109606677028884 \n",
      "acc for Psat= 0.1790987750005786 \n",
      "acc for optim= 0.16840985734693203\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.006605358328670263\n",
      "Loss on test= 0.00651326822116971\n",
      "acc for Lsat= 0.1747075208288152 \n",
      "acc for Psat= 0.20494737834237864 \n",
      "acc for optim= 0.16344844936374117\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.006326085422188044\n",
      "Loss on test= 0.006535100284963846\n",
      "acc for Lsat= 0.1688804035544487 \n",
      "acc for Psat= 0.18236394110827547 \n",
      "acc for optim= 0.1649557457611797\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.006255748216062784\n",
      "Loss on test= 0.006859130691736937\n",
      "acc for Lsat= 0.1767821950885681 \n",
      "acc for Psat= 0.21376912961093725 \n",
      "acc for optim= 0.16595766032238674\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.006754105444997549\n",
      "Loss on test= 0.0068397787399590015\n",
      "acc for Lsat= 0.18427012942074875 \n",
      "acc for Psat= 0.1882390160014334 \n",
      "acc for optim= 0.16219217536720967\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.008329368196427822\n",
      "Loss on test= 0.006849201396107674\n",
      "acc for Lsat= 0.16567628971913154 \n",
      "acc for Psat= 0.2030834500334363 \n",
      "acc for optim= 0.1755949102078763\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.006708502769470215\n",
      "Loss on test= 0.007192546967417002\n",
      "acc for Lsat= 0.1606959726027362 \n",
      "acc for Psat= 0.1942808824507844 \n",
      "acc for optim= 0.18234898138421085\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.006552047096192837\n",
      "Loss on test= 0.006727835163474083\n",
      "acc for Lsat= 0.15892711595716108 \n",
      "acc for Psat= 0.2090071062117502 \n",
      "acc for optim= 0.17519032206732474\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.006204324774444103\n",
      "Loss on test= 0.006378643214702606\n",
      "acc for Lsat= 0.16601473603695327 \n",
      "acc for Psat= 0.21259207350075948 \n",
      "acc for optim= 0.1685251594234838\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.0063143325969576836\n",
      "Loss on test= 0.006628809031099081\n",
      "acc for Lsat= 0.1646555179377949 \n",
      "acc for Psat= 0.2006198114326193 \n",
      "acc for optim= 0.16963057427945716\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.006273115985095501\n",
      "Loss on test= 0.006506874691694975\n",
      "acc for Lsat= 0.17398250350331673 \n",
      "acc for Psat= 0.20892768281866933 \n",
      "acc for optim= 0.16731370846510935\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.00639283936470747\n",
      "Loss on test= 0.006589209660887718\n",
      "acc for Lsat= 0.15810230344087345 \n",
      "acc for Psat= 0.18498329735956476 \n",
      "acc for optim= 0.16830672997424043\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.006194625049829483\n",
      "Loss on test= 0.006365992594510317\n",
      "acc for Lsat= 0.14752495790856554 \n",
      "acc for Psat= 0.19917181283693577 \n",
      "acc for optim= 0.16741884114644415\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.006839039269834757\n",
      "Loss on test= 0.0062613715417683125\n",
      "acc for Lsat= 0.1620916487836111 \n",
      "acc for Psat= 0.20208717387123798 \n",
      "acc for optim= 0.17101797004256622\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.006283959839493036\n",
      "Loss on test= 0.006506077013909817\n",
      "acc for Lsat= 0.16772260981398163 \n",
      "acc for Psat= 0.18521456965207136 \n",
      "acc for optim= 0.17347362357264262\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.006219719536602497\n",
      "Loss on test= 0.00675151078030467\n",
      "acc for Lsat= 0.18384481891588933 \n",
      "acc for Psat= 0.19683154519746598 \n",
      "acc for optim= 0.16418202062038187\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.006750383414328098\n",
      "Loss on test= 0.006618205923587084\n",
      "acc for Lsat= 0.16846400659949304 \n",
      "acc for Psat= 0.20356369160371451 \n",
      "acc for optim= 0.17352763180859285\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.006188465282320976\n",
      "Loss on test= 0.006637764163315296\n",
      "acc for Lsat= 0.15124645572399995 \n",
      "acc for Psat= 0.18989687496414562 \n",
      "acc for optim= 0.1644546646417737\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.006124965846538544\n",
      "Loss on test= 0.006359948311001062\n",
      "acc for Lsat= 0.15528840586966758 \n",
      "acc for Psat= 0.18983381247056313 \n",
      "acc for optim= 0.16263226556904675\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.0061857388354837894\n",
      "Loss on test= 0.006509178783744574\n",
      "acc for Lsat= 0.1471373231325787 \n",
      "acc for Psat= 0.18063868954625042 \n",
      "acc for optim= 0.1614344691469565\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.00616447813808918\n",
      "Loss on test= 0.006342303939163685\n",
      "acc for Lsat= 0.1704189244726817 \n",
      "acc for Psat= 0.17563611090900835 \n",
      "acc for optim= 0.16653302255769825\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.0062101674266159534\n",
      "Loss on test= 0.006560772657394409\n",
      "acc for Lsat= 0.16280043057870258 \n",
      "acc for Psat= 0.19966871077461992 \n",
      "acc for optim= 0.1730490839805408\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.006083434447646141\n",
      "Loss on test= 0.006192774977535009\n",
      "acc for Lsat= 0.16667006773278728 \n",
      "acc for Psat= 0.18633932419222413 \n",
      "acc for optim= 0.16725615037215844\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.00622347928583622\n",
      "Loss on test= 0.006563961505889893\n",
      "acc for Lsat= 0.16569542868146825 \n",
      "acc for Psat= 0.19390998006641835 \n",
      "acc for optim= 0.1658160219963289\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.006177959032356739\n",
      "Loss on test= 0.006150675471872091\n",
      "acc for Lsat= 0.15749151512339224 \n",
      "acc for Psat= 0.18235645231916797 \n",
      "acc for optim= 0.16509735850927054\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.0065011754631996155\n",
      "Loss on test= 0.006575731560587883\n",
      "acc for Lsat= 0.16369075824613455 \n",
      "acc for Psat= 0.1930596365723148 \n",
      "acc for optim= 0.15995189982569455\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.006548017263412476\n",
      "Loss on test= 0.006220080424100161\n",
      "acc for Lsat= 0.16160495985455842 \n",
      "acc for Psat= 0.2083978645064578 \n",
      "acc for optim= 0.16118083098267785\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.006583576090633869\n",
      "Loss on test= 0.006796952337026596\n",
      "acc for Lsat= 0.1641121747273738 \n",
      "acc for Psat= 0.2031752721541542 \n",
      "acc for optim= 0.1592218465179388\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.006238309200853109\n",
      "Loss on test= 0.00613408163189888\n",
      "acc for Lsat= 0.15562711800138473 \n",
      "acc for Psat= 0.19277613692932197 \n",
      "acc for optim= 0.1663469965216612\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.0059776208363473415\n",
      "Loss on test= 0.006064038258045912\n",
      "acc for Lsat= 0.17276327924442203 \n",
      "acc for Psat= 0.2059763561155586 \n",
      "acc for optim= 0.16677578194219558\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.00683421129360795\n",
      "Loss on test= 0.006541729439049959\n",
      "acc for Lsat= 0.16752232964526095 \n",
      "acc for Psat= 0.20246582194307788 \n",
      "acc for optim= 0.1753993700864366\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.006443148013204336\n",
      "Loss on test= 0.0065377140417695045\n",
      "acc for Lsat= 0.1459704246383435 \n",
      "acc for Psat= 0.183636881429015 \n",
      "acc for optim= 0.1718589706735716\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.005868026055395603\n",
      "Loss on test= 0.006539039313793182\n",
      "acc for Lsat= 0.16191521618022872 \n",
      "acc for Psat= 0.18481591888951504 \n",
      "acc for optim= 0.1597111524592276\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.0062990919686853886\n",
      "Loss on test= 0.0062814257107675076\n",
      "acc for Lsat= 0.17867439146832081 \n",
      "acc for Psat= 0.18920077997828513 \n",
      "acc for optim= 0.1717733793937769\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.006183593533933163\n",
      "Loss on test= 0.006609178148210049\n",
      "acc for Lsat= 0.16591410624372596 \n",
      "acc for Psat= 0.1911860638416418 \n",
      "acc for optim= 0.1679343791721488\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.006098565645515919\n",
      "Loss on test= 0.0066866944544017315\n",
      "acc for Lsat= 0.16600246387591097 \n",
      "acc for Psat= 0.18614681760520965 \n",
      "acc for optim= 0.16110190107147437\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.006503818091005087\n",
      "Loss on test= 0.006683694198727608\n",
      "acc for Lsat= 0.16218861117243355 \n",
      "acc for Psat= 0.18613128877229623 \n",
      "acc for optim= 0.16901751073813504\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.006929269526153803\n",
      "Loss on test= 0.006620555650442839\n",
      "acc for Lsat= 0.16815029413574833 \n",
      "acc for Psat= 0.19459498190076746 \n",
      "acc for optim= 0.17170599550657645\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.006334339734166861\n",
      "Loss on test= 0.0066378298215568066\n",
      "acc for Lsat= 0.15629023663982555 \n",
      "acc for Psat= 0.19578771161652156 \n",
      "acc for optim= 0.17407513124730867\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.006353975273668766\n",
      "Loss on test= 0.00646244827657938\n",
      "acc for Lsat= 0.15998100354813313 \n",
      "acc for Psat= 0.18385212850973076 \n",
      "acc for optim= 0.17145298143966145\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.00647002924233675\n",
      "Loss on test= 0.006108653731644154\n",
      "acc for Lsat= 0.15739401095951372 \n",
      "acc for Psat= 0.17928715382328592 \n",
      "acc for optim= 0.17412992916162365\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.006656289100646973\n",
      "Loss on test= 0.00590160908177495\n",
      "acc for Lsat= 0.1633045184002334 \n",
      "acc for Psat= 0.1940368832928724 \n",
      "acc for optim= 0.15992126460129882\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.005967504344880581\n",
      "Loss on test= 0.006441453006118536\n",
      "acc for Lsat= 0.14988629195827716 \n",
      "acc for Psat= 0.1841267333644819 \n",
      "acc for optim= 0.16602712711796438\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.006132022477686405\n",
      "Loss on test= 0.006473172921687365\n",
      "acc for Lsat= 0.15286842231792835 \n",
      "acc for Psat= 0.1824802564499999 \n",
      "acc for optim= 0.16381057946080127\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.0059891678392887115\n",
      "Loss on test= 0.006625226233154535\n",
      "acc for Lsat= 0.16523731902821875 \n",
      "acc for Psat= 0.18701835946200443 \n",
      "acc for optim= 0.16812693135599133\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.006440832279622555\n",
      "Loss on test= 0.006195270922034979\n",
      "acc for Lsat= 0.15271510181330206 \n",
      "acc for Psat= 0.19154836599615815 \n",
      "acc for optim= 0.16472397861051846\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.00638097757473588\n",
      "Loss on test= 0.006256318651139736\n",
      "acc for Lsat= 0.1499270984443042 \n",
      "acc for Psat= 0.17294630164845434 \n",
      "acc for optim= 0.1583278820922476\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.006239905022084713\n",
      "Loss on test= 0.006584499031305313\n",
      "acc for Lsat= 0.15988876363357957 \n",
      "acc for Psat= 0.19539784367585586 \n",
      "acc for optim= 0.16813832723586172\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.006022338289767504\n",
      "Loss on test= 0.0066594406962394714\n",
      "acc for Lsat= 0.15514204485922076 \n",
      "acc for Psat= 0.19914450560234578 \n",
      "acc for optim= 0.1669905462069437\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.00618265476077795\n",
      "Loss on test= 0.006290461868047714\n",
      "acc for Lsat= 0.161147791008965 \n",
      "acc for Psat= 0.1789441827369747 \n",
      "acc for optim= 0.16728287038591796\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.006154310889542103\n",
      "Loss on test= 0.006470136810094118\n",
      "acc for Lsat= 0.1686819201015646 \n",
      "acc for Psat= 0.19016945467860824 \n",
      "acc for optim= 0.15406451349024525\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.006171275861561298\n",
      "Loss on test= 0.00639018090441823\n",
      "acc for Lsat= 0.1566022331145073 \n",
      "acc for Psat= 0.1913388961258146 \n",
      "acc for optim= 0.16349794900800543\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.006809075828641653\n",
      "Loss on test= 0.006050458177924156\n",
      "acc for Lsat= 0.1575552019176119 \n",
      "acc for Psat= 0.1948505266714597 \n",
      "acc for optim= 0.16418288571847847\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.006700786761939526\n",
      "Loss on test= 0.0063917627558112144\n",
      "acc for Lsat= 0.15709964766381326 \n",
      "acc for Psat= 0.19972925459446966 \n",
      "acc for optim= 0.17176567111393345\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.006090727634727955\n",
      "Loss on test= 0.006172006484121084\n",
      "acc for Lsat= 0.16999447492989483 \n",
      "acc for Psat= 0.1971647740572645 \n",
      "acc for optim= 0.15998539631942013\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.0060716127045452595\n",
      "Loss on test= 0.0064244940876960754\n",
      "acc for Lsat= 0.15024388463247842 \n",
      "acc for Psat= 0.19239972914238918 \n",
      "acc for optim= 0.17066540898069105\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.005816373974084854\n",
      "Loss on test= 0.006450552027672529\n",
      "acc for Lsat= 0.15236024713929988 \n",
      "acc for Psat= 0.19208455912188674 \n",
      "acc for optim= 0.1682690899935551\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.0065710172057151794\n",
      "Loss on test= 0.00624173553660512\n",
      "acc for Lsat= 0.15656818184967258 \n",
      "acc for Psat= 0.19461985907839902 \n",
      "acc for optim= 0.16800192724550753\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.006649530027061701\n",
      "Loss on test= 0.006318721920251846\n",
      "acc for Lsat= 0.16884533666135346 \n",
      "acc for Psat= 0.19725965056100814 \n",
      "acc for optim= 0.16914785620360445\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.006052226759493351\n",
      "Loss on test= 0.006076108664274216\n",
      "acc for Lsat= 0.1539143811205219 \n",
      "acc for Psat= 0.19051970894921755 \n",
      "acc for optim= 0.15959793592619015\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.005856822710484266\n",
      "Loss on test= 0.006474286317825317\n",
      "acc for Lsat= 0.15648204812428868 \n",
      "acc for Psat= 0.198259595028682 \n",
      "acc for optim= 0.164707220945847\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.006311473436653614\n",
      "Loss on test= 0.006447866093367338\n",
      "acc for Lsat= 0.15193606270563056 \n",
      "acc for Psat= 0.18295545616706252 \n",
      "acc for optim= 0.1634265835927494\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.005906443577259779\n",
      "Loss on test= 0.0061239697970449924\n",
      "acc for Lsat= 0.16516529983577516 \n",
      "acc for Psat= 0.18307243754426933 \n",
      "acc for optim= 0.16078406678680635\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.005889133550226688\n",
      "Loss on test= 0.0061621349304914474\n",
      "acc for Lsat= 0.1431099596265398 \n",
      "acc for Psat= 0.18763645725156808 \n",
      "acc for optim= 0.16676884647458792\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.006936801131814718\n",
      "Loss on test= 0.006086626090109348\n",
      "acc for Lsat= 0.1505261824286894 \n",
      "acc for Psat= 0.18595355769808283 \n",
      "acc for optim= 0.16653642138260127\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.0064070820808410645\n",
      "Loss on test= 0.006591251119971275\n",
      "acc for Lsat= 0.14782704287361292 \n",
      "acc for Psat= 0.18151840173241446 \n",
      "acc for optim= 0.16985997340029305\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.005961044691503048\n",
      "Loss on test= 0.006521123461425304\n",
      "acc for Lsat= 0.16634408137770598 \n",
      "acc for Psat= 0.2044735929012665 \n",
      "acc for optim= 0.16570045840449357\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.0060325367376208305\n",
      "Loss on test= 0.0060584270395338535\n",
      "acc for Lsat= 0.15173728133620482 \n",
      "acc for Psat= 0.19002000928290042 \n",
      "acc for optim= 0.16656017569771617\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.006018534768372774\n",
      "Loss on test= 0.0061685629189014435\n",
      "acc for Lsat= 0.14890082613259675 \n",
      "acc for Psat= 0.19136196554821655 \n",
      "acc for optim= 0.1651606277652375\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.0059739332646131516\n",
      "Loss on test= 0.006444940343499184\n",
      "acc for Lsat= 0.15998230123583257 \n",
      "acc for Psat= 0.1811286329343289 \n",
      "acc for optim= 0.16933794389955975\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.0060401661321520805\n",
      "Loss on test= 0.006563679315149784\n",
      "acc for Lsat= 0.1682672954243646 \n",
      "acc for Psat= 0.19494897996067817 \n",
      "acc for optim= 0.16628911005920868\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.00601105485111475\n",
      "Loss on test= 0.007049627602100372\n",
      "acc for Lsat= 0.14877675716024746 \n",
      "acc for Psat= 0.20835990946962724 \n",
      "acc for optim= 0.1653802940259367\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.0061403922736644745\n",
      "Loss on test= 0.006431514397263527\n",
      "acc for Lsat= 0.14661956540992116 \n",
      "acc for Psat= 0.19661449504382603 \n",
      "acc for optim= 0.16280575335657008\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.006100261118263006\n",
      "Loss on test= 0.006287203636020422\n",
      "acc for Lsat= 0.1679650959862228 \n",
      "acc for Psat= 0.1977999588383026 \n",
      "acc for optim= 0.16284296484673624\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.005780874285846949\n",
      "Loss on test= 0.006280920002609491\n",
      "acc for Lsat= 0.16145056809198383 \n",
      "acc for Psat= 0.19218191252792347 \n",
      "acc for optim= 0.15939235120146755\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.005760294385254383\n",
      "Loss on test= 0.006581991445273161\n",
      "acc for Lsat= 0.1634000330522168 \n",
      "acc for Psat= 0.18234433489422253 \n",
      "acc for optim= 0.16342942296741073\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.0064464048482477665\n",
      "Loss on test= 0.006200296338647604\n",
      "acc for Lsat= 0.16111066881338226 \n",
      "acc for Psat= 0.17556892888258846 \n",
      "acc for optim= 0.1650948410285026\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.006673191674053669\n",
      "Loss on test= 0.005909164436161518\n",
      "acc for Lsat= 0.1706499951592929 \n",
      "acc for Psat= 0.1879968099675874 \n",
      "acc for optim= 0.16411750511174208\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.006942832376807928\n",
      "Loss on test= 0.006344269495457411\n",
      "acc for Lsat= 0.15624745171311977 \n",
      "acc for Psat= 0.19215564819350534 \n",
      "acc for optim= 0.16675031947155222\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.006138114258646965\n",
      "Loss on test= 0.006451571825891733\n",
      "acc for Lsat= 0.14982689115482184 \n",
      "acc for Psat= 0.18434722486141017 \n",
      "acc for optim= 0.1609566864202593\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.005926801823079586\n",
      "Loss on test= 0.00631796196103096\n",
      "acc for Lsat= 0.15948496287088407 \n",
      "acc for Psat= 0.18027952351134088 \n",
      "acc for optim= 0.16705212415249437\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.006365156266838312\n",
      "Loss on test= 0.006288280710577965\n",
      "acc for Lsat= 0.1579803575342712 \n",
      "acc for Psat= 0.1811392846010572 \n",
      "acc for optim= 0.168900965065619\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.005890947300940752\n",
      "Loss on test= 0.006665491499006748\n",
      "acc for Lsat= 0.14925240500387355 \n",
      "acc for Psat= 0.19839105483213226 \n",
      "acc for optim= 0.16752710276785246\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.006003199145197868\n",
      "Loss on test= 0.006380900274962187\n",
      "acc for Lsat= 0.16024711361349575 \n",
      "acc for Psat= 0.17660844002384693 \n",
      "acc for optim= 0.1654268271614202\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.005938073620200157\n",
      "Loss on test= 0.006490557920187712\n",
      "acc for Lsat= 0.1572899641026361 \n",
      "acc for Psat= 0.19688415388408742 \n",
      "acc for optim= 0.16724981423896798\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.0057166563346982\n",
      "Loss on test= 0.006368936970829964\n",
      "acc for Lsat= 0.15419432561726262 \n",
      "acc for Psat= 0.18053933300130875 \n",
      "acc for optim= 0.17300776806025436\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.0058433981612324715\n",
      "Loss on test= 0.006570943631231785\n",
      "acc for Lsat= 0.15927166960786143 \n",
      "acc for Psat= 0.19300942619018197 \n",
      "acc for optim= 0.15933512165650085\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.005663217511028051\n",
      "Loss on test= 0.0061578694730997086\n",
      "acc for Lsat= 0.15311349898411655 \n",
      "acc for Psat= 0.19507716142984688 \n",
      "acc for optim= 0.1622194315152258\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.006265606731176376\n",
      "Loss on test= 0.006456328090280294\n",
      "acc for Lsat= 0.15380110069756303 \n",
      "acc for Psat= 0.19087912942679813 \n",
      "acc for optim= 0.16036153924117078\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.006621955428272486\n",
      "Loss on test= 0.006092844996601343\n",
      "acc for Lsat= 0.16324336659239574 \n",
      "acc for Psat= 0.18529238756660174 \n",
      "acc for optim= 0.1648192214197181\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.00594535656273365\n",
      "Loss on test= 0.006765381433069706\n",
      "acc for Lsat= 0.15762117259685315 \n",
      "acc for Psat= 0.17932096910357598 \n",
      "acc for optim= 0.1654738924315306\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.006050055846571922\n",
      "Loss on test= 0.006346122361719608\n",
      "acc for Lsat= 0.16110629364600038 \n",
      "acc for Psat= 0.19190065343787924 \n",
      "acc for optim= 0.1667829957109834\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.0058266641572117805\n",
      "Loss on test= 0.006424714345484972\n",
      "acc for Lsat= 0.15324217540795962 \n",
      "acc for Psat= 0.1946564717658177 \n",
      "acc for optim= 0.16741646570869204\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.0057986159808933735\n",
      "Loss on test= 0.005912553519010544\n",
      "acc for Lsat= 0.1739373355119138 \n",
      "acc for Psat= 0.20341804713062317 \n",
      "acc for optim= 0.16546756397034842\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.005855775438249111\n",
      "Loss on test= 0.0065261186100542545\n",
      "acc for Lsat= 0.15157211271007776 \n",
      "acc for Psat= 0.1861718511651652 \n",
      "acc for optim= 0.1652117926531021\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.005803341045975685\n",
      "Loss on test= 0.006421334575861692\n",
      "acc for Lsat= 0.16106233599091896 \n",
      "acc for Psat= 0.17660660160587124 \n",
      "acc for optim= 0.16453615809202987\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.0061467308551073074\n",
      "Loss on test= 0.006121139042079449\n",
      "acc for Lsat= 0.14751086736054514 \n",
      "acc for Psat= 0.18583490075543524 \n",
      "acc for optim= 0.16899677044826514\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.005962729454040527\n",
      "Loss on test= 0.006332083139568567\n",
      "acc for Lsat= 0.15093160605546638 \n",
      "acc for Psat= 0.17075076596043262 \n",
      "acc for optim= 0.16487204149159312\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.006284908391535282\n",
      "Loss on test= 0.006047398783266544\n",
      "acc for Lsat= 0.15915720390888755 \n",
      "acc for Psat= 0.18880971012652287 \n",
      "acc for optim= 0.16504401377341177\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.006276838481426239\n",
      "Loss on test= 0.006504443474113941\n",
      "acc for Lsat= 0.15139552695317895 \n",
      "acc for Psat= 0.20571538990985633 \n",
      "acc for optim= 0.17186327768588958\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.006060103885829449\n",
      "Loss on test= 0.006416307762265205\n",
      "acc for Lsat= 0.1546805703743422 \n",
      "acc for Psat= 0.17216749700381742 \n",
      "acc for optim= 0.16665614030407894\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.005629600025713444\n",
      "Loss on test= 0.006467834115028381\n",
      "acc for Lsat= 0.14479815862771336 \n",
      "acc for Psat= 0.19019410417445737 \n",
      "acc for optim= 0.16933011684234428\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.005880139302462339\n",
      "Loss on test= 0.006028319709002972\n",
      "acc for Lsat= 0.15640436786147727 \n",
      "acc for Psat= 0.1877343891673248 \n",
      "acc for optim= 0.16029411503872415\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.005681147798895836\n",
      "Loss on test= 0.006389210000634193\n",
      "acc for Lsat= 0.14811617789153567 \n",
      "acc for Psat= 0.1779011444217281 \n",
      "acc for optim= 0.1642864985567075\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.005624033976346254\n",
      "Loss on test= 0.006261787842959166\n",
      "acc for Lsat= 0.15000475181312467 \n",
      "acc for Psat= 0.19462013396808542 \n",
      "acc for optim= 0.15939512183268548\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.005759442690759897\n",
      "Loss on test= 0.006375569850206375\n",
      "acc for Lsat= 0.14893403857584744 \n",
      "acc for Psat= 0.17043504123518732 \n",
      "acc for optim= 0.16217640971747746\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.0058212680742144585\n",
      "Loss on test= 0.006231927312910557\n",
      "acc for Lsat= 0.1481597556818475 \n",
      "acc for Psat= 0.17776269367142183 \n",
      "acc for optim= 0.16661789135885288\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.00572920311242342\n",
      "Loss on test= 0.006490628235042095\n",
      "acc for Lsat= 0.1488413017733618 \n",
      "acc for Psat= 0.18565119026032215 \n",
      "acc for optim= 0.17045353029570237\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.0056686908937990665\n",
      "Loss on test= 0.007001038175076246\n",
      "acc for Lsat= 0.16162117029061698 \n",
      "acc for Psat= 0.18939661685793402 \n",
      "acc for optim= 0.1652419799347179\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.005891799461096525\n",
      "Loss on test= 0.006110657937824726\n",
      "acc for Lsat= 0.14970561610424754 \n",
      "acc for Psat= 0.1781914830593331 \n",
      "acc for optim= 0.16393428670479077\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.005778374616056681\n",
      "Loss on test= 0.0062979720532894135\n",
      "acc for Lsat= 0.16020418170431142 \n",
      "acc for Psat= 0.18873288089855092 \n",
      "acc for optim= 0.16967357785331721\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.006556499749422073\n",
      "Loss on test= 0.006234011612832546\n",
      "acc for Lsat= 0.17037762865561565 \n",
      "acc for Psat= 0.19522299376449007 \n",
      "acc for optim= 0.16682578565192133\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.005843336693942547\n",
      "Loss on test= 0.006691065151244402\n",
      "acc for Lsat= 0.15930182611814045 \n",
      "acc for Psat= 0.18922873188352182 \n",
      "acc for optim= 0.16335148305448963\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.005779992323368788\n",
      "Loss on test= 0.0064004771411418915\n",
      "acc for Lsat= 0.14919532916554418 \n",
      "acc for Psat= 0.18386390453937357 \n",
      "acc for optim= 0.16319277545830357\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.005505210720002651\n",
      "Loss on test= 0.0063578179106116295\n",
      "acc for Lsat= 0.14392072425594127 \n",
      "acc for Psat= 0.18749539449273753 \n",
      "acc for optim= 0.15999344718445963\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.005804486572742462\n",
      "Loss on test= 0.00639383913949132\n",
      "acc for Lsat= 0.16761804411939696 \n",
      "acc for Psat= 0.18976642905932958 \n",
      "acc for optim= 0.16276358815411499\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.005618004128336906\n",
      "Loss on test= 0.005959310103207827\n",
      "acc for Lsat= 0.1481458143946585 \n",
      "acc for Psat= 0.17721925060890736 \n",
      "acc for optim= 0.17295405476995301\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.005574447568506002\n",
      "Loss on test= 0.006475471425801516\n",
      "acc for Lsat= 0.16102474614601872 \n",
      "acc for Psat= 0.18507007136673773 \n",
      "acc for optim= 0.1645664253715592\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.005616871174424887\n",
      "Loss on test= 0.005941422190517187\n",
      "acc for Lsat= 0.14615362822161662 \n",
      "acc for Psat= 0.19271914093892595 \n",
      "acc for optim= 0.15961857701262427\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.005810891278088093\n",
      "Loss on test= 0.006432233843952417\n",
      "acc for Lsat= 0.15189892458767615 \n",
      "acc for Psat= 0.18183500707973954 \n",
      "acc for optim= 0.15975789382667796\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.005783747415989637\n",
      "Loss on test= 0.005907533224672079\n",
      "acc for Lsat= 0.14309693917404998 \n",
      "acc for Psat= 0.18414967770604265 \n",
      "acc for optim= 0.1717116757267399\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.005949207581579685\n",
      "Loss on test= 0.006555831991136074\n",
      "acc for Lsat= 0.14487425018651565 \n",
      "acc for Psat= 0.18557930098632808 \n",
      "acc for optim= 0.15504745201390907\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.0055790008045732975\n",
      "Loss on test= 0.006453593261539936\n",
      "acc for Lsat= 0.15431533673421297 \n",
      "acc for Psat= 0.18076609675352628 \n",
      "acc for optim= 0.16357398009572757\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.005967727862298489\n",
      "Loss on test= 0.0065977792255580425\n",
      "acc for Lsat= 0.1616850261824572 \n",
      "acc for Psat= 0.18552742750235054 \n",
      "acc for optim= 0.16611843434941084\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.0058784219436347485\n",
      "Loss on test= 0.005758162122219801\n",
      "acc for Lsat= 0.15568426448821288 \n",
      "acc for Psat= 0.19180508737230947 \n",
      "acc for optim= 0.1638574341640304\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.005842666141688824\n",
      "Loss on test= 0.006181731820106506\n",
      "acc for Lsat= 0.14744132522466882 \n",
      "acc for Psat= 0.19004730952247123 \n",
      "acc for optim= 0.1679993361959875\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.005696976091712713\n",
      "Loss on test= 0.005977651569992304\n",
      "acc for Lsat= 0.15336323264722912 \n",
      "acc for Psat= 0.1861736803723988 \n",
      "acc for optim= 0.17182553485513008\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.005644220858812332\n",
      "Loss on test= 0.006264019291847944\n",
      "acc for Lsat= 0.15683621755614113 \n",
      "acc for Psat= 0.19725650364120842 \n",
      "acc for optim= 0.16678736562588725\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.005772354546934366\n",
      "Loss on test= 0.00674797035753727\n",
      "acc for Lsat= 0.14586752355733285 \n",
      "acc for Psat= 0.19262339701975284 \n",
      "acc for optim= 0.16678629655230667\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.00608048727735877\n",
      "Loss on test= 0.005815110169351101\n",
      "acc for Lsat= 0.15803493049804915 \n",
      "acc for Psat= 0.17661927740154482 \n",
      "acc for optim= 0.16465524276241386\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.0057319519110023975\n",
      "Loss on test= 0.006381417158991098\n",
      "acc for Lsat= 0.14352564608485469 \n",
      "acc for Psat= 0.17122162951568723 \n",
      "acc for optim= 0.16480577940781616\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.005713279824703932\n",
      "Loss on test= 0.006048709619790316\n",
      "acc for Lsat= 0.1504923514622816 \n",
      "acc for Psat= 0.1749922413828632 \n",
      "acc for optim= 0.16971670202033015\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.0055205440148711205\n",
      "Loss on test= 0.006481568329036236\n",
      "acc for Lsat= 0.14653380701621826 \n",
      "acc for Psat= 0.17806152749155862 \n",
      "acc for optim= 0.1665151793643313\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.005946388002485037\n",
      "Loss on test= 0.0062240008264780045\n",
      "acc for Lsat= 0.14658867477822943 \n",
      "acc for Psat= 0.18958063325811308 \n",
      "acc for optim= 0.16257083937945607\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.00560158584266901\n",
      "Loss on test= 0.006359289400279522\n",
      "acc for Lsat= 0.15584889691094983 \n",
      "acc for Psat= 0.17886482601370815 \n",
      "acc for optim= 0.16557466759839848\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.005551339127123356\n",
      "Loss on test= 0.006394384894520044\n",
      "acc for Lsat= 0.15662705670568908 \n",
      "acc for Psat= 0.20048576377851784 \n",
      "acc for optim= 0.16634404400371197\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.005892939865589142\n",
      "Loss on test= 0.006341169588267803\n",
      "acc for Lsat= 0.1436717495814607 \n",
      "acc for Psat= 0.18402265672587226 \n",
      "acc for optim= 0.1605711269982495\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.005945214070379734\n",
      "Loss on test= 0.00625375472009182\n",
      "acc for Lsat= 0.14903497915403902 \n",
      "acc for Psat= 0.18343639749667195 \n",
      "acc for optim= 0.165448508902117\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.006166202016174793\n",
      "Loss on test= 0.0063372086733579636\n",
      "acc for Lsat= 0.15586532356511404 \n",
      "acc for Psat= 0.1693705348687754 \n",
      "acc for optim= 0.16557615306323822\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.006422191858291626\n",
      "Loss on test= 0.0063162436708807945\n",
      "acc for Lsat= 0.15591287901625037 \n",
      "acc for Psat= 0.1856422111758443 \n",
      "acc for optim= 0.17049640745542882\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.006119965575635433\n",
      "Loss on test= 0.006013015750795603\n",
      "acc for Lsat= 0.1558748594411748 \n",
      "acc for Psat= 0.18250294725322852 \n",
      "acc for optim= 0.166782150417948\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.005984033457934856\n",
      "Loss on test= 0.0063689472153782845\n",
      "acc for Lsat= 0.14812601603659206 \n",
      "acc for Psat= 0.17855626596366894 \n",
      "acc for optim= 0.16536988990579837\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.00577277597039938\n",
      "Loss on test= 0.006103989668190479\n",
      "acc for Lsat= 0.15487927796193168 \n",
      "acc for Psat= 0.17415029908812865 \n",
      "acc for optim= 0.1633849372568189\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.005574922543019056\n",
      "Loss on test= 0.006494635250419378\n",
      "acc for Lsat= 0.15473810797399787 \n",
      "acc for Psat= 0.18950686941770684 \n",
      "acc for optim= 0.16607801000488404\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.005591808818280697\n",
      "Loss on test= 0.005812007002532482\n",
      "acc for Lsat= 0.14131746755332733 \n",
      "acc for Psat= 0.18251468189915673 \n",
      "acc for optim= 0.16259031812302563\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.005764084868133068\n",
      "Loss on test= 0.006451868452131748\n",
      "acc for Lsat= 0.15845305170562332 \n",
      "acc for Psat= 0.18770832780370017 \n",
      "acc for optim= 0.16648980087112086\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.005845168139785528\n",
      "Loss on test= 0.005892481654882431\n",
      "acc for Lsat= 0.16922905218375267 \n",
      "acc for Psat= 0.18014708262291873 \n",
      "acc for optim= 0.16096026751939893\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.006138965487480164\n",
      "Loss on test= 0.005872979760169983\n",
      "acc for Lsat= 0.1465561168810322 \n",
      "acc for Psat= 0.17941949068545746 \n",
      "acc for optim= 0.16636860337381282\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.005797258578240871\n",
      "Loss on test= 0.006413443014025688\n",
      "acc for Lsat= 0.16481539996905772 \n",
      "acc for Psat= 0.1787312321827917 \n",
      "acc for optim= 0.16336280400206366\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.006037749350070953\n",
      "Loss on test= 0.006345100700855255\n",
      "acc for Lsat= 0.15904213340440573 \n",
      "acc for Psat= 0.1854484966299573 \n",
      "acc for optim= 0.16510927063550374\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.0055982572957873344\n",
      "Loss on test= 0.006653014104813337\n",
      "acc for Lsat= 0.15115615237107285 \n",
      "acc for Psat= 0.18047018140756993 \n",
      "acc for optim= 0.16605879680547467\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.005802228581160307\n",
      "Loss on test= 0.006356854923069477\n",
      "acc for Lsat= 0.15904061434777134 \n",
      "acc for Psat= 0.190250147845535 \n",
      "acc for optim= 0.16349201520072815\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.006716937758028507\n",
      "Loss on test= 0.006147823296487331\n",
      "acc for Lsat= 0.14061180634632112 \n",
      "acc for Psat= 0.17942138182774156 \n",
      "acc for optim= 0.16992354973822404\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.005763844586908817\n",
      "Loss on test= 0.006101848557591438\n",
      "acc for Lsat= 0.1546102816097774 \n",
      "acc for Psat= 0.18666633249558204 \n",
      "acc for optim= 0.16582270217919864\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.006077984813600779\n",
      "Loss on test= 0.006230015307664871\n",
      "acc for Lsat= 0.15836410959228323 \n",
      "acc for Psat= 0.18129157355669734 \n",
      "acc for optim= 0.16054202285308972\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.00568731501698494\n",
      "Loss on test= 0.006349978502839804\n",
      "acc for Lsat= 0.1555988170718011 \n",
      "acc for Psat= 0.18043577445987766 \n",
      "acc for optim= 0.16663484948345644\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.005799355451017618\n",
      "Loss on test= 0.0062115974724292755\n",
      "acc for Lsat= 0.1565636869090548 \n",
      "acc for Psat= 0.17941945848431148 \n",
      "acc for optim= 0.16204682080138125\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.0057420372031629086\n",
      "Loss on test= 0.006278788670897484\n",
      "acc for Lsat= 0.14902102752878774 \n",
      "acc for Psat= 0.17557544831155997 \n",
      "acc for optim= 0.1679938556319179\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.005493421573191881\n",
      "Loss on test= 0.006039015483111143\n",
      "acc for Lsat= 0.1448653254974786 \n",
      "acc for Psat= 0.1814436621486866 \n",
      "acc for optim= 0.17019116979651297\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.00622133631259203\n",
      "Loss on test= 0.006258833687752485\n",
      "acc for Lsat= 0.16335142172708894 \n",
      "acc for Psat= 0.17999379806569776 \n",
      "acc for optim= 0.1726797048231495\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.0059079453349113464\n",
      "Loss on test= 0.0060285781510174274\n",
      "acc for Lsat= 0.1505191893385748 \n",
      "acc for Psat= 0.17896829533360165 \n",
      "acc for optim= 0.16677985134286202\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.005896177142858505\n",
      "Loss on test= 0.005878874100744724\n",
      "acc for Lsat= 0.14540136146939314 \n",
      "acc for Psat= 0.17978968901681852 \n",
      "acc for optim= 0.16517581560145148\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.006153966300189495\n",
      "Loss on test= 0.005962039809674025\n",
      "acc for Lsat= 0.14828526109426482 \n",
      "acc for Psat= 0.17437400937530778 \n",
      "acc for optim= 0.16318199827038057\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.005541594233363867\n",
      "Loss on test= 0.006092903669923544\n",
      "acc for Lsat= 0.1476436056444788 \n",
      "acc for Psat= 0.18697654556778362 \n",
      "acc for optim= 0.16027265308256888\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.005501738749444485\n",
      "Loss on test= 0.00609462708234787\n",
      "acc for Lsat= 0.14650881905559562 \n",
      "acc for Psat= 0.17509440849897773 \n",
      "acc for optim= 0.1689430319681214\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.005459730513393879\n",
      "Loss on test= 0.006342494394630194\n",
      "acc for Lsat= 0.15139734575106975 \n",
      "acc for Psat= 0.1892451283934175 \n",
      "acc for optim= 0.16520881995589273\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.005636559333652258\n",
      "Loss on test= 0.006190882995724678\n",
      "acc for Lsat= 0.15382489844732994 \n",
      "acc for Psat= 0.18462538332821513 \n",
      "acc for optim= 0.16824378497196268\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.005846578627824783\n",
      "Loss on test= 0.0061577302403748035\n",
      "acc for Lsat= 0.14997359611414618 \n",
      "acc for Psat= 0.17929363189509415 \n",
      "acc for optim= 0.16590138407916472\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.005691605620086193\n",
      "Loss on test= 0.006638341583311558\n",
      "acc for Lsat= 0.1605800643948777 \n",
      "acc for Psat= 0.19091683600983414 \n",
      "acc for optim= 0.1683554533109466\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.00557828601449728\n",
      "Loss on test= 0.006336189340800047\n",
      "acc for Lsat= 0.15223652173523586 \n",
      "acc for Psat= 0.17402386873555903 \n",
      "acc for optim= 0.15902491134847133\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.005483502522110939\n",
      "Loss on test= 0.006374610587954521\n",
      "acc for Lsat= 0.14545157045301538 \n",
      "acc for Psat= 0.18542525165356014 \n",
      "acc for optim= 0.16566317522073867\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.005776867736130953\n",
      "Loss on test= 0.006263062823563814\n",
      "acc for Lsat= 0.15882878717727822 \n",
      "acc for Psat= 0.17475508436385054 \n",
      "acc for optim= 0.16574707000123215\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.005658650770783424\n",
      "Loss on test= 0.006087468937039375\n",
      "acc for Lsat= 0.1519862421398952 \n",
      "acc for Psat= 0.20055384688522118 \n",
      "acc for optim= 0.15521825958447927\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.0056723738089203835\n",
      "Loss on test= 0.006439208984375\n",
      "acc for Lsat= 0.14531267504360465 \n",
      "acc for Psat= 0.1852355934418051 \n",
      "acc for optim= 0.1583752974153584\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.005635127890855074\n",
      "Loss on test= 0.006110168527811766\n",
      "acc for Lsat= 0.14470988244374597 \n",
      "acc for Psat= 0.19258311118197735 \n",
      "acc for optim= 0.15881661911548467\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.005375680048018694\n",
      "Loss on test= 0.005971693433821201\n",
      "acc for Lsat= 0.15435300788643663 \n",
      "acc for Psat= 0.17613982410345716 \n",
      "acc for optim= 0.16525162753561268\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.005674754269421101\n",
      "Loss on test= 0.006398570258170366\n",
      "acc for Lsat= 0.16821461092932607 \n",
      "acc for Psat= 0.19558192412159023 \n",
      "acc for optim= 0.16151225045876821\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.0057336618192493916\n",
      "Loss on test= 0.006159844808280468\n",
      "acc for Lsat= 0.1600862281251943 \n",
      "acc for Psat= 0.18071795171164892 \n",
      "acc for optim= 0.1655817835026833\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.005495082587003708\n",
      "Loss on test= 0.006079484708607197\n",
      "acc for Lsat= 0.1447795526750508 \n",
      "acc for Psat= 0.1705574553963713 \n",
      "acc for optim= 0.16387143926241732\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.0062044523656368256\n",
      "Loss on test= 0.006314862985163927\n",
      "acc for Lsat= 0.1597066027652396 \n",
      "acc for Psat= 0.17314248704007965 \n",
      "acc for optim= 0.16229005406561048\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.005906646139919758\n",
      "Loss on test= 0.0061597214080393314\n",
      "acc for Lsat= 0.1512396193243044 \n",
      "acc for Psat= 0.1837520984612161 \n",
      "acc for optim= 0.1720037145862646\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.005793617106974125\n",
      "Loss on test= 0.006567177828401327\n",
      "acc for Lsat= 0.15540841953699155 \n",
      "acc for Psat= 0.1811181515170887 \n",
      "acc for optim= 0.16337426753407422\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.005584393162280321\n",
      "Loss on test= 0.0061311544850468636\n",
      "acc for Lsat= 0.1669042005505199 \n",
      "acc for Psat= 0.1845218951481091 \n",
      "acc for optim= 0.16369525628616713\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.0058754123747348785\n",
      "Loss on test= 0.006184312980622053\n",
      "acc for Lsat= 0.14450960915505154 \n",
      "acc for Psat= 0.18061153122641863 \n",
      "acc for optim= 0.16984524693164485\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.005433906801044941\n",
      "Loss on test= 0.0058474112302064896\n",
      "acc for Lsat= 0.14213333576364198 \n",
      "acc for Psat= 0.1889766836203024 \n",
      "acc for optim= 0.16286501499927283\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.005644659977406263\n",
      "Loss on test= 0.006082973908632994\n",
      "acc for Lsat= 0.15390543365301412 \n",
      "acc for Psat= 0.1681562201677226 \n",
      "acc for optim= 0.15994522431445476\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.005679982248693705\n",
      "Loss on test= 0.005633000284433365\n",
      "acc for Lsat= 0.1443945770288367 \n",
      "acc for Psat= 0.1811880051509523 \n",
      "acc for optim= 0.1689640565008139\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.005608703941106796\n",
      "Loss on test= 0.0063615222461521626\n",
      "acc for Lsat= 0.15905480871022848 \n",
      "acc for Psat= 0.19432726585607762 \n",
      "acc for optim= 0.16206010305752108\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.005837954115122557\n",
      "Loss on test= 0.00618533743545413\n",
      "acc for Lsat= 0.1527564890342248 \n",
      "acc for Psat= 0.17836605607680825 \n",
      "acc for optim= 0.1691041621391482\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.005608725361526012\n",
      "Loss on test= 0.005809886381030083\n",
      "acc for Lsat= 0.1486816756396753 \n",
      "acc for Psat= 0.17099173873067514 \n",
      "acc for optim= 0.16578575654592762\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.00557083822786808\n",
      "Loss on test= 0.005850806832313538\n",
      "acc for Lsat= 0.157737369270667 \n",
      "acc for Psat= 0.17333218464780537 \n",
      "acc for optim= 0.17016633708052886\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.0055558704771101475\n",
      "Loss on test= 0.006207548547536135\n",
      "acc for Lsat= 0.15532793717034335 \n",
      "acc for Psat= 0.18809852375091649 \n",
      "acc for optim= 0.16366939620047113\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.005443974398076534\n",
      "Loss on test= 0.006391890347003937\n",
      "acc for Lsat= 0.15758718387767687 \n",
      "acc for Psat= 0.17997594844353323 \n",
      "acc for optim= 0.1653366558177427\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.005504861008375883\n",
      "Loss on test= 0.005983557552099228\n",
      "acc for Lsat= 0.1494133918225521 \n",
      "acc for Psat= 0.1776326877208733 \n",
      "acc for optim= 0.1633803058330487\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.00548607436940074\n",
      "Loss on test= 0.006060575135052204\n",
      "acc for Lsat= 0.15619217145312042 \n",
      "acc for Psat= 0.1866161587568893 \n",
      "acc for optim= 0.16746375088033183\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.00556951854377985\n",
      "Loss on test= 0.006297434214502573\n",
      "acc for Lsat= 0.15175274130802402 \n",
      "acc for Psat= 0.1901791198316534 \n",
      "acc for optim= 0.16621060745540595\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.005479198880493641\n",
      "Loss on test= 0.005980480462312698\n",
      "acc for Lsat= 0.13949853929354175 \n",
      "acc for Psat= 0.1797467522176181 \n",
      "acc for optim= 0.16058236505572882\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.0056402599439024925\n",
      "Loss on test= 0.006102290470153093\n",
      "acc for Lsat= 0.14334916848189305 \n",
      "acc for Psat= 0.19316891580781914 \n",
      "acc for optim= 0.16309382708353892\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.005387462209910154\n",
      "Loss on test= 0.006427140906453133\n",
      "acc for Lsat= 0.15291572434860606 \n",
      "acc for Psat= 0.17272350402295086 \n",
      "acc for optim= 0.16420897423675224\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.0058757890947163105\n",
      "Loss on test= 0.005920520983636379\n",
      "acc for Lsat= 0.14531229768028545 \n",
      "acc for Psat= 0.17387006562050494 \n",
      "acc for optim= 0.16985173887766652\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.005526668392121792\n",
      "Loss on test= 0.005982768721878529\n",
      "acc for Lsat= 0.1512299448740287 \n",
      "acc for Psat= 0.1892424085582072 \n",
      "acc for optim= 0.1630077324859172\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.0057436502538621426\n",
      "Loss on test= 0.006474739406257868\n",
      "acc for Lsat= 0.15348488713879918 \n",
      "acc for Psat= 0.19364894205689065 \n",
      "acc for optim= 0.1597377515981951\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.005594947841018438\n",
      "Loss on test= 0.006166502367705107\n",
      "acc for Lsat= 0.16069624824124984 \n",
      "acc for Psat= 0.18739425534035126 \n",
      "acc for optim= 0.16118884789127644\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.005631390493363142\n",
      "Loss on test= 0.006197978742420673\n",
      "acc for Lsat= 0.15162865133129716 \n",
      "acc for Psat= 0.18467899929335127 \n",
      "acc for optim= 0.16436055642800773\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.005443209782242775\n",
      "Loss on test= 0.006111087743192911\n",
      "acc for Lsat= 0.15135473163023622 \n",
      "acc for Psat= 0.18176343483567908 \n",
      "acc for optim= 0.16233530583577688\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.005707991309463978\n",
      "Loss on test= 0.005950022488832474\n",
      "acc for Lsat= 0.1593972971433567 \n",
      "acc for Psat= 0.19069349961011808 \n",
      "acc for optim= 0.1650350140886702\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.005392414517700672\n",
      "Loss on test= 0.0057775950990617275\n",
      "acc for Lsat= 0.15040970726731162 \n",
      "acc for Psat= 0.18825945873500505 \n",
      "acc for optim= 0.1571842907172185\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.005539821460843086\n",
      "Loss on test= 0.006057563237845898\n",
      "acc for Lsat= 0.1568146764085109 \n",
      "acc for Psat= 0.17977265699739858 \n",
      "acc for optim= 0.16431600147206168\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.005565263796597719\n",
      "Loss on test= 0.006496035028249025\n",
      "acc for Lsat= 0.15538983147431043 \n",
      "acc for Psat= 0.18313685883996916 \n",
      "acc for optim= 0.16882537969838463\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.005271790083497763\n",
      "Loss on test= 0.005875326693058014\n",
      "acc for Lsat= 0.15981968171745692 \n",
      "acc for Psat= 0.18453898517382483 \n",
      "acc for optim= 0.16074395333578978\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.005607273895293474\n",
      "Loss on test= 0.006171291694045067\n",
      "acc for Lsat= 0.15261673658984126 \n",
      "acc for Psat= 0.1810909056157202 \n",
      "acc for optim= 0.1619412193891638\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.005637098103761673\n",
      "Loss on test= 0.006200055591762066\n",
      "acc for Lsat= 0.15597345062920853 \n",
      "acc for Psat= 0.18869397452895026 \n",
      "acc for optim= 0.1660856126384909\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.005704036448150873\n",
      "Loss on test= 0.006025644019246101\n",
      "acc for Lsat= 0.13808578876555136 \n",
      "acc for Psat= 0.17488989535534036 \n",
      "acc for optim= 0.16325940199620492\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.0058440594002604485\n",
      "Loss on test= 0.0058571649715304375\n",
      "acc for Lsat= 0.16221565751565933 \n",
      "acc for Psat= 0.18517569556801777 \n",
      "acc for optim= 0.16789447671545815\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.005635966546833515\n",
      "Loss on test= 0.006228236015886068\n",
      "acc for Lsat= 0.15874605756009677 \n",
      "acc for Psat= 0.18501810287335338 \n",
      "acc for optim= 0.15726672043636755\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.005608508363366127\n",
      "Loss on test= 0.006027292925864458\n",
      "acc for Lsat= 0.15372432583005963 \n",
      "acc for Psat= 0.17364230676769798 \n",
      "acc for optim= 0.16088796995664167\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.00550529919564724\n",
      "Loss on test= 0.006166818086057901\n",
      "acc for Lsat= 0.16021933966768584 \n",
      "acc for Psat= 0.1853059111205483 \n",
      "acc for optim= 0.16255763067413487\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.00567432027310133\n",
      "Loss on test= 0.005959733854979277\n",
      "acc for Lsat= 0.16900081012004864 \n",
      "acc for Psat= 0.1804135949076077 \n",
      "acc for optim= 0.16547138005710726\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.0053045665845274925\n",
      "Loss on test= 0.0060959309339523315\n",
      "acc for Lsat= 0.16568236249187945 \n",
      "acc for Psat= 0.19273953052780585 \n",
      "acc for optim= 0.1641859849311839\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.005532798822969198\n",
      "Loss on test= 0.006140654906630516\n",
      "acc for Lsat= 0.1504284608771368 \n",
      "acc for Psat= 0.1785239589069474 \n",
      "acc for optim= 0.16687467371764378\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.005561360158026218\n",
      "Loss on test= 0.006171673070639372\n",
      "acc for Lsat= 0.1436114025462541 \n",
      "acc for Psat= 0.16550506401127663 \n",
      "acc for optim= 0.16619355294807647\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.005721399560570717\n",
      "Loss on test= 0.0059728012420237064\n",
      "acc for Lsat= 0.14490195727875155 \n",
      "acc for Psat= 0.17692815471396658 \n",
      "acc for optim= 0.16663291567085373\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.005707300268113613\n",
      "Loss on test= 0.0063585578463971615\n",
      "acc for Lsat= 0.16078687119746168 \n",
      "acc for Psat= 0.17526150229005297 \n",
      "acc for optim= 0.16308397391856816\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.005649940110743046\n",
      "Loss on test= 0.006052828393876553\n",
      "acc for Lsat= 0.16531854399621151 \n",
      "acc for Psat= 0.18040041678936267 \n",
      "acc for optim= 0.1651529470471509\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.005481696221977472\n",
      "Loss on test= 0.006299986038357019\n",
      "acc for Lsat= 0.14963202063417916 \n",
      "acc for Psat= 0.1851617092552946 \n",
      "acc for optim= 0.16672942808307525\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.005341715179383755\n",
      "Loss on test= 0.00623983284458518\n",
      "acc for Lsat= 0.14678656556090094 \n",
      "acc for Psat= 0.17189453817091951 \n",
      "acc for optim= 0.1651506458708757\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.005832669325172901\n",
      "Loss on test= 0.00605747802183032\n",
      "acc for Lsat= 0.15768991340439362 \n",
      "acc for Psat= 0.173431205507115 \n",
      "acc for optim= 0.16752155444271802\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.005524185951799154\n",
      "Loss on test= 0.006105438340455294\n",
      "acc for Lsat= 0.15110462055213322 \n",
      "acc for Psat= 0.17147305991596515 \n",
      "acc for optim= 0.1666984240866083\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.0054149567149579525\n",
      "Loss on test= 0.00613759970292449\n",
      "acc for Lsat= 0.14721236374347516 \n",
      "acc for Psat= 0.17700895813873924 \n",
      "acc for optim= 0.16183110510579266\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.005556767340749502\n",
      "Loss on test= 0.005904139019548893\n",
      "acc for Lsat= 0.1594740504330238 \n",
      "acc for Psat= 0.18386859801124597 \n",
      "acc for optim= 0.1612948875750232\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.0056015546433627605\n",
      "Loss on test= 0.0059776813723146915\n",
      "acc for Lsat= 0.15190801693400421 \n",
      "acc for Psat= 0.16840145111171773 \n",
      "acc for optim= 0.16510333751199946\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.006047147326171398\n",
      "Loss on test= 0.006064365617930889\n",
      "acc for Lsat= 0.1486790348802403 \n",
      "acc for Psat= 0.17471675897956077 \n",
      "acc for optim= 0.16304275201839685\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.0067228758707642555\n",
      "Loss on test= 0.0058761900290846825\n",
      "acc for Lsat= 0.1569941813443963 \n",
      "acc for Psat= 0.1898370757317323 \n",
      "acc for optim= 0.16249988679268368\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.00548258563503623\n",
      "Loss on test= 0.0062048048712313175\n",
      "acc for Lsat= 0.1481551079988407 \n",
      "acc for Psat= 0.17815064712757717 \n",
      "acc for optim= 0.17452362031441135\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.005744042806327343\n",
      "Loss on test= 0.0060455151833593845\n",
      "acc for Lsat= 0.159883689049576 \n",
      "acc for Psat= 0.18918999280469476 \n",
      "acc for optim= 0.1606586731028014\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.005622345954179764\n",
      "Loss on test= 0.006288983393460512\n",
      "acc for Lsat= 0.15731955801258932 \n",
      "acc for Psat= 0.18188246825374052 \n",
      "acc for optim= 0.16001509132844655\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.005726034753024578\n",
      "Loss on test= 0.005879739299416542\n",
      "acc for Lsat= 0.1697958124743309 \n",
      "acc for Psat= 0.18759526856812328 \n",
      "acc for optim= 0.16140397688317623\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.005345209967344999\n",
      "Loss on test= 0.006236092187464237\n",
      "acc for Lsat= 0.15252588218274438 \n",
      "acc for Psat= 0.18057383462933624 \n",
      "acc for optim= 0.1689595288639033\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.00529864989221096\n",
      "Loss on test= 0.006110373418778181\n",
      "acc for Lsat= 0.1526687879562874 \n",
      "acc for Psat= 0.18582028849126742 \n",
      "acc for optim= 0.16273988650331167\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.005443176720291376\n",
      "Loss on test= 0.00673918891698122\n",
      "acc for Lsat= 0.15407137214481095 \n",
      "acc for Psat= 0.177771235743278 \n",
      "acc for optim= 0.16162609735124012\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.005618567578494549\n",
      "Loss on test= 0.006446540355682373\n",
      "acc for Lsat= 0.14788199989432124 \n",
      "acc for Psat= 0.17943440975399963 \n",
      "acc for optim= 0.1681550878529498\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.00574190029874444\n",
      "Loss on test= 0.006225024815648794\n",
      "acc for Lsat= 0.14748213099769972 \n",
      "acc for Psat= 0.166626992898413 \n",
      "acc for optim= 0.16516174630473796\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.00557300029322505\n",
      "Loss on test= 0.006167984567582607\n",
      "acc for Lsat= 0.15375515954086144 \n",
      "acc for Psat= 0.1719913848916252 \n",
      "acc for optim= 0.15871431266213384\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.005443859845399857\n",
      "Loss on test= 0.006041476037353277\n",
      "acc for Lsat= 0.14475127606114493 \n",
      "acc for Psat= 0.1934511847347479 \n",
      "acc for optim= 0.1745907459072158\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.0057863155379891396\n",
      "Loss on test= 0.006278501357883215\n",
      "acc for Lsat= 0.1443769471038545 \n",
      "acc for Psat= 0.1696449880463407 \n",
      "acc for optim= 0.1614000528667229\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.005697871092706919\n",
      "Loss on test= 0.006540225353091955\n",
      "acc for Lsat= 0.15832153160915113 \n",
      "acc for Psat= 0.18371988003062023 \n",
      "acc for optim= 0.15689225124746758\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.005496638361364603\n",
      "Loss on test= 0.006463370285928249\n",
      "acc for Lsat= 0.14994571941187146 \n",
      "acc for Psat= 0.1896768656612725 \n",
      "acc for optim= 0.16566786540359196\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.0054994006641209126\n",
      "Loss on test= 0.005913838744163513\n",
      "acc for Lsat= 0.15671143606219243 \n",
      "acc for Psat= 0.17448224855670857 \n",
      "acc for optim= 0.16079719764043074\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.0056693279184401035\n",
      "Loss on test= 0.006264199502766132\n",
      "acc for Lsat= 0.14627597027355194 \n",
      "acc for Psat= 0.17764370359115866 \n",
      "acc for optim= 0.1642769902394932\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.0053841653279960155\n",
      "Loss on test= 0.005854023154824972\n",
      "acc for Lsat= 0.13809382342160909 \n",
      "acc for Psat= 0.17408966690275177 \n",
      "acc for optim= 0.16380206309144432\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.006205177400261164\n",
      "Loss on test= 0.0061764223501086235\n",
      "acc for Lsat= 0.14707682325645946 \n",
      "acc for Psat= 0.1725404124094133 \n",
      "acc for optim= 0.1616349243362373\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.005354173947125673\n",
      "Loss on test= 0.0060273874551057816\n",
      "acc for Lsat= 0.15277804157488645 \n",
      "acc for Psat= 0.17399446185626716 \n",
      "acc for optim= 0.16426961707813878\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.005270850379019976\n",
      "Loss on test= 0.006280793342739344\n",
      "acc for Lsat= 0.15286703014242478 \n",
      "acc for Psat= 0.17870015755246133 \n",
      "acc for optim= 0.15992044468141223\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.00537091214209795\n",
      "Loss on test= 0.006247362121939659\n",
      "acc for Lsat= 0.1457513356672936 \n",
      "acc for Psat= 0.1655621949203511 \n",
      "acc for optim= 0.1644405713102582\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.005496572237461805\n",
      "Loss on test= 0.0059608533047139645\n",
      "acc for Lsat= 0.14833961298048007 \n",
      "acc for Psat= 0.17634700678563753 \n",
      "acc for optim= 0.16617983276436923\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.00551477400586009\n",
      "Loss on test= 0.005990148521959782\n",
      "acc for Lsat= 0.1534860100609548 \n",
      "acc for Psat= 0.17380168156499867 \n",
      "acc for optim= 0.1672460017313839\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.005819026380777359\n",
      "Loss on test= 0.006035507656633854\n",
      "acc for Lsat= 0.14764334601731818 \n",
      "acc for Psat= 0.18033639913211102 \n",
      "acc for optim= 0.16200640174673803\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.005518623627722263\n",
      "Loss on test= 0.006268090568482876\n",
      "acc for Lsat= 0.1593477834494792 \n",
      "acc for Psat= 0.1895695029093777 \n",
      "acc for optim= 0.159822327328739\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.0055914465337991714\n",
      "Loss on test= 0.006234117317944765\n",
      "acc for Lsat= 0.15307158841331658 \n",
      "acc for Psat= 0.17708096464668385 \n",
      "acc for optim= 0.16539720869012423\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.005478185601532459\n",
      "Loss on test= 0.005705731920897961\n",
      "acc for Lsat= 0.15050723660531165 \n",
      "acc for Psat= 0.17881926051169236 \n",
      "acc for optim= 0.15660083873834857\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.005501731764525175\n",
      "Loss on test= 0.005913706496357918\n",
      "acc for Lsat= 0.1621152960437686 \n",
      "acc for Psat= 0.18436629834640236 \n",
      "acc for optim= 0.16393950891597045\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.005338955670595169\n",
      "Loss on test= 0.005943975877016783\n",
      "acc for Lsat= 0.16525689858721845 \n",
      "acc for Psat= 0.1753984258701017 \n",
      "acc for optim= 0.1638691357020136\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.005728335119783878\n",
      "Loss on test= 0.0062647052109241486\n",
      "acc for Lsat= 0.14545057400933192 \n",
      "acc for Psat= 0.1806347160264239 \n",
      "acc for optim= 0.16550805761562812\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.005613910965621471\n",
      "Loss on test= 0.005811155773699284\n",
      "acc for Lsat= 0.14529730300080282 \n",
      "acc for Psat= 0.18691186844943794 \n",
      "acc for optim= 0.16226923112179245\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.005574909038841724\n",
      "Loss on test= 0.006214906461536884\n",
      "acc for Lsat= 0.1466213643428732 \n",
      "acc for Psat= 0.18277776327247056 \n",
      "acc for optim= 0.16423003357858015\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.005537013523280621\n",
      "Loss on test= 0.006067825946956873\n",
      "acc for Lsat= 0.14230227459670086 \n",
      "acc for Psat= 0.17856054899552798 \n",
      "acc for optim= 0.1663308195723984\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.005662496201694012\n",
      "Loss on test= 0.005942079704254866\n",
      "acc for Lsat= 0.1467577194333168 \n",
      "acc for Psat= 0.1848669539398483 \n",
      "acc for optim= 0.1655784839924547\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.005513434298336506\n",
      "Loss on test= 0.006169454660266638\n",
      "acc for Lsat= 0.15505776195786894 \n",
      "acc for Psat= 0.16763049473395125 \n",
      "acc for optim= 0.15549645639036244\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.005427578464150429\n",
      "Loss on test= 0.006017501465976238\n",
      "acc for Lsat= 0.14371608696700472 \n",
      "acc for Psat= 0.16685929163817134 \n",
      "acc for optim= 0.16340280874960553\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.005322194658219814\n",
      "Loss on test= 0.006288721226155758\n",
      "acc for Lsat= 0.16879455752598124 \n",
      "acc for Psat= 0.17675205658911108 \n",
      "acc for optim= 0.16381320657139858\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.005423261784017086\n",
      "Loss on test= 0.005815391894429922\n",
      "acc for Lsat= 0.15634746040049635 \n",
      "acc for Psat= 0.18305079189590065 \n",
      "acc for optim= 0.16722433312064167\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.005654964596033096\n",
      "Loss on test= 0.00614000391215086\n",
      "acc for Lsat= 0.16876836416662716 \n",
      "acc for Psat= 0.18662813903943284 \n",
      "acc for optim= 0.16477569926718105\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.005802066996693611\n",
      "Loss on test= 0.005517951212823391\n",
      "acc for Lsat= 0.1494583179971936 \n",
      "acc for Psat= 0.18402779717208267 \n",
      "acc for optim= 0.16909707415539801\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.005488187540322542\n",
      "Loss on test= 0.006057462189346552\n",
      "acc for Lsat= 0.15214164893822285 \n",
      "acc for Psat= 0.17464764217493509 \n",
      "acc for optim= 0.1608012234271107\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.005428306758403778\n",
      "Loss on test= 0.006294363643974066\n",
      "acc for Lsat= 0.16234400278323743 \n",
      "acc for Psat= 0.1792432238145533 \n",
      "acc for optim= 0.16513261289200287\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.005384141579270363\n",
      "Loss on test= 0.00631638802587986\n",
      "acc for Lsat= 0.14746589332582338 \n",
      "acc for Psat= 0.15585688134067555 \n",
      "acc for optim= 0.15509473563131487\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.005688437260687351\n",
      "Loss on test= 0.006233668886125088\n",
      "acc for Lsat= 0.15907213167040743 \n",
      "acc for Psat= 0.1767242104983049 \n",
      "acc for optim= 0.16717607607458124\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.005288138519972563\n",
      "Loss on test= 0.006424956023693085\n",
      "acc for Lsat= 0.14205612295157405 \n",
      "acc for Psat= 0.1765007330850375 \n",
      "acc for optim= 0.16032284927815885\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.005435875616967678\n",
      "Loss on test= 0.006458714138716459\n",
      "acc for Lsat= 0.14300964432825777 \n",
      "acc for Psat= 0.17480225441977382 \n",
      "acc for optim= 0.16824927540442555\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.006082802079617977\n",
      "Loss on test= 0.005685398820787668\n",
      "acc for Lsat= 0.15186469060690647 \n",
      "acc for Psat= 0.17117460652590408 \n",
      "acc for optim= 0.16295770399108314\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.005588560365140438\n",
      "Loss on test= 0.00620038527995348\n",
      "acc for Lsat= 0.14875515243000367 \n",
      "acc for Psat= 0.18270921274126492 \n",
      "acc for optim= 0.16217263331369602\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.005979550536721945\n",
      "Loss on test= 0.006173830945044756\n",
      "acc for Lsat= 0.14832299490589038 \n",
      "acc for Psat= 0.1760267563794022 \n",
      "acc for optim= 0.1690502292720816\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.005577050149440765\n",
      "Loss on test= 0.005895518697798252\n",
      "acc for Lsat= 0.14687873760055078 \n",
      "acc for Psat= 0.17960255260552568 \n",
      "acc for optim= 0.16578751685132165\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.005505430046468973\n",
      "Loss on test= 0.0063035329803824425\n",
      "acc for Lsat= 0.15276270526352523 \n",
      "acc for Psat= 0.17933113126157685 \n",
      "acc for optim= 0.16248293642649336\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.005373498424887657\n",
      "Loss on test= 0.005916818045079708\n",
      "acc for Lsat= 0.14713154430462994 \n",
      "acc for Psat= 0.16878961060142725 \n",
      "acc for optim= 0.16206917801421503\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.005641131661832333\n",
      "Loss on test= 0.0060692098923027515\n",
      "acc for Lsat= 0.15195592480509343 \n",
      "acc for Psat= 0.18837963409886932 \n",
      "acc for optim= 0.1593012300871511\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.005473003722727299\n",
      "Loss on test= 0.006111576687544584\n",
      "acc for Lsat= 0.1538553133828052 \n",
      "acc for Psat= 0.18856822062619163 \n",
      "acc for optim= 0.16463073921565455\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.005519673228263855\n",
      "Loss on test= 0.006213851738721132\n",
      "acc for Lsat= 0.16169676041062617 \n",
      "acc for Psat= 0.19383444539462139 \n",
      "acc for optim= 0.16344514580092348\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.005366124212741852\n",
      "Loss on test= 0.006152410991489887\n",
      "acc for Lsat= 0.15776114332190044 \n",
      "acc for Psat= 0.1884067746990009 \n",
      "acc for optim= 0.15909362184475406\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.005694993771612644\n",
      "Loss on test= 0.006222494877874851\n",
      "acc for Lsat= 0.1460856211466665 \n",
      "acc for Psat= 0.19050582534534338 \n",
      "acc for optim= 0.1610004462675787\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.005372584331780672\n",
      "Loss on test= 0.00620105117559433\n",
      "acc for Lsat= 0.14906098005938206 \n",
      "acc for Psat= 0.17790232233824324 \n",
      "acc for optim= 0.1643824201653574\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.005632700398564339\n",
      "Loss on test= 0.0062785339541733265\n",
      "acc for Lsat= 0.15471134600496744 \n",
      "acc for Psat= 0.18624476478291965 \n",
      "acc for optim= 0.16096971415137856\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.005307493731379509\n",
      "Loss on test= 0.006041225511580706\n",
      "acc for Lsat= 0.1441761507316813 \n",
      "acc for Psat= 0.17675441817025517 \n",
      "acc for optim= 0.1591787346633968\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.005546305328607559\n",
      "Loss on test= 0.006144625134766102\n",
      "acc for Lsat= 0.15524619070385567 \n",
      "acc for Psat= 0.16352959574883916 \n",
      "acc for optim= 0.16291660236454278\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.0056495522148907185\n",
      "Loss on test= 0.006381619721651077\n",
      "acc for Lsat= 0.14879544076021212 \n",
      "acc for Psat= 0.1701954502977343 \n",
      "acc for optim= 0.16284152946213534\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.005422917194664478\n",
      "Loss on test= 0.005841326899826527\n",
      "acc for Lsat= 0.1503954036730021 \n",
      "acc for Psat= 0.17748602299920482 \n",
      "acc for optim= 0.1678780830285863\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.0054999785497784615\n",
      "Loss on test= 0.006046375725418329\n",
      "acc for Lsat= 0.14487442490625668 \n",
      "acc for Psat= 0.17864955860556517 \n",
      "acc for optim= 0.1648573180827833\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.005268626846373081\n",
      "Loss on test= 0.00593112176284194\n",
      "acc for Lsat= 0.1499114991768767 \n",
      "acc for Psat= 0.18094777117762906 \n",
      "acc for optim= 0.16300548524328615\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.0055645788088440895\n",
      "Loss on test= 0.00601357314735651\n",
      "acc for Lsat= 0.15096814752495313 \n",
      "acc for Psat= 0.17395851210591795 \n",
      "acc for optim= 0.16084489050191506\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.005505109205842018\n",
      "Loss on test= 0.0060177952982485294\n",
      "acc for Lsat= 0.152361979855026 \n",
      "acc for Psat= 0.174688869969634 \n",
      "acc for optim= 0.16323055618916843\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.005457444116473198\n",
      "Loss on test= 0.006351204589009285\n",
      "acc for Lsat= 0.16050848147763153 \n",
      "acc for Psat= 0.19607943020633148 \n",
      "acc for optim= 0.1641616031829054\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.005325396079570055\n",
      "Loss on test= 0.006335705518722534\n",
      "acc for Lsat= 0.1455171384779473 \n",
      "acc for Psat= 0.16615776715029154 \n",
      "acc for optim= 0.16643916253844032\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.005717802792787552\n",
      "Loss on test= 0.0060188439674675465\n",
      "acc for Lsat= 0.145538669143666 \n",
      "acc for Psat= 0.17851148188041646 \n",
      "acc for optim= 0.16088874681526413\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.005573548376560211\n",
      "Loss on test= 0.006038757041096687\n",
      "acc for Lsat= 0.14876994173706615 \n",
      "acc for Psat= 0.17162792982837016 \n",
      "acc for optim= 0.16255575368814476\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.005829622503370047\n",
      "Loss on test= 0.006084525026381016\n",
      "acc for Lsat= 0.1560956725511952 \n",
      "acc for Psat= 0.18908469090295468 \n",
      "acc for optim= 0.16607166541501503\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.005469150375574827\n",
      "Loss on test= 0.0057909926399588585\n",
      "acc for Lsat= 0.15575854181117363 \n",
      "acc for Psat= 0.1661291473655824 \n",
      "acc for optim= 0.16145377945084294\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.005483713932335377\n",
      "Loss on test= 0.006285587791353464\n",
      "acc for Lsat= 0.15001992586232935 \n",
      "acc for Psat= 0.17256962611935422 \n",
      "acc for optim= 0.16382529168765703\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.005724580958485603\n",
      "Loss on test= 0.006165251601487398\n",
      "acc for Lsat= 0.1452102547519092 \n",
      "acc for Psat= 0.17265643607401604 \n",
      "acc for optim= 0.1679396859395936\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.005397218279540539\n",
      "Loss on test= 0.00574521254748106\n",
      "acc for Lsat= 0.15920837705947274 \n",
      "acc for Psat= 0.19222164559535887 \n",
      "acc for optim= 0.16674947418696767\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.005553909577429295\n",
      "Loss on test= 0.005624119658023119\n",
      "acc for Lsat= 0.15931816128450904 \n",
      "acc for Psat= 0.18324216809429106 \n",
      "acc for optim= 0.15434087428615476\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.005475650541484356\n",
      "Loss on test= 0.005818716250360012\n",
      "acc for Lsat= 0.14540768185493033 \n",
      "acc for Psat= 0.18038192051825433 \n",
      "acc for optim= 0.16109452172441094\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.005373700987547636\n",
      "Loss on test= 0.006116700358688831\n",
      "acc for Lsat= 0.1505397686173712 \n",
      "acc for Psat= 0.18634839277746934 \n",
      "acc for optim= 0.16387057179760675\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.005477425642311573\n",
      "Loss on test= 0.005792816169559956\n",
      "acc for Lsat= 0.14692139241159283 \n",
      "acc for Psat= 0.1757202449239424 \n",
      "acc for optim= 0.161041953617642\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.005626055411994457\n",
      "Loss on test= 0.006328708026558161\n",
      "acc for Lsat= 0.14815067536880827 \n",
      "acc for Psat= 0.1711389801388637 \n",
      "acc for optim= 0.1643669186295468\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.005457371007651091\n",
      "Loss on test= 0.005813349038362503\n",
      "acc for Lsat= 0.15219231967267496 \n",
      "acc for Psat= 0.18262445964911556 \n",
      "acc for optim= 0.16702657184471972\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.005752998869866133\n",
      "Loss on test= 0.0061795515939593315\n",
      "acc for Lsat= 0.1410870864746909 \n",
      "acc for Psat= 0.17499824343191947 \n",
      "acc for optim= 0.1637509047418268\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.005474742967635393\n",
      "Loss on test= 0.006226728670299053\n",
      "acc for Lsat= 0.1481902786219 \n",
      "acc for Psat= 0.17004861135363053 \n",
      "acc for optim= 0.16441188794866082\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.005273579619824886\n",
      "Loss on test= 0.006102462764829397\n",
      "acc for Lsat= 0.139473335039716 \n",
      "acc for Psat= 0.16400800996849343 \n",
      "acc for optim= 0.16693178703435926\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.005311444401741028\n",
      "Loss on test= 0.006288912147283554\n",
      "acc for Lsat= 0.14319352570226507 \n",
      "acc for Psat= 0.18320609305710456 \n",
      "acc for optim= 0.16566420877991686\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.00551691884174943\n",
      "Loss on test= 0.005906541366130114\n",
      "acc for Lsat= 0.14146927568018908 \n",
      "acc for Psat= 0.17306937210214826 \n",
      "acc for optim= 0.16049036934903105\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.005554118659347296\n",
      "Loss on test= 0.006280496716499329\n",
      "acc for Lsat= 0.14885380717612742 \n",
      "acc for Psat= 0.17579207769213398 \n",
      "acc for optim= 0.16401132377872213\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.005393352825194597\n",
      "Loss on test= 0.006227122154086828\n",
      "acc for Lsat= 0.1564249373121248 \n",
      "acc for Psat= 0.1769197946215873 \n",
      "acc for optim= 0.15862383152493972\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.005598049610853195\n",
      "Loss on test= 0.00587956327944994\n",
      "acc for Lsat= 0.14625825829289618 \n",
      "acc for Psat= 0.18799049429381726 \n",
      "acc for optim= 0.16663727245492035\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.005479071754962206\n",
      "Loss on test= 0.006376521196216345\n",
      "acc for Lsat= 0.15011627193326588 \n",
      "acc for Psat= 0.16886066158214338 \n",
      "acc for optim= 0.16555720574764504\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.005467803683131933\n",
      "Loss on test= 0.006164832506328821\n",
      "acc for Lsat= 0.15925584583806607 \n",
      "acc for Psat= 0.17822980259833324 \n",
      "acc for optim= 0.160912569085533\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.005252172239124775\n",
      "Loss on test= 0.005982812028378248\n",
      "acc for Lsat= 0.15042029901753087 \n",
      "acc for Psat= 0.18145226429344907 \n",
      "acc for optim= 0.15802139898372783\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.005436158739030361\n",
      "Loss on test= 0.006176437251269817\n",
      "acc for Lsat= 0.15417971183435197 \n",
      "acc for Psat= 0.16750611939570545 \n",
      "acc for optim= 0.15560796801268018\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.005400172434747219\n",
      "Loss on test= 0.006296197883784771\n",
      "acc for Lsat= 0.1546076946618936 \n",
      "acc for Psat= 0.17604589087537445 \n",
      "acc for optim= 0.1631256718924708\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.005377839785069227\n",
      "Loss on test= 0.005952116567641497\n",
      "acc for Lsat= 0.14532715717649525 \n",
      "acc for Psat= 0.1721332418885021 \n",
      "acc for optim= 0.1604346626410528\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.005300515331327915\n",
      "Loss on test= 0.00610880833119154\n",
      "acc for Lsat= 0.16039722281604524 \n",
      "acc for Psat= 0.173739486980084 \n",
      "acc for optim= 0.17329447088900526\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.00541240768507123\n",
      "Loss on test= 0.006030423566699028\n",
      "acc for Lsat= 0.1591056825754855 \n",
      "acc for Psat= 0.17876546733376197 \n",
      "acc for optim= 0.1630595520930985\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.005176613572984934\n",
      "Loss on test= 0.006509869825094938\n",
      "acc for Lsat= 0.15536967312180452 \n",
      "acc for Psat= 0.17750788772341292 \n",
      "acc for optim= 0.16415879880192644\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.0053336783312261105\n",
      "Loss on test= 0.005783812142908573\n",
      "acc for Lsat= 0.15213930937537892 \n",
      "acc for Psat= 0.17959295800986289 \n",
      "acc for optim= 0.16795145723735913\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.005453623831272125\n",
      "Loss on test= 0.0060127414762973785\n",
      "acc for Lsat= 0.15516348515767708 \n",
      "acc for Psat= 0.18046616890933365 \n",
      "acc for optim= 0.16231146613097766\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.0056966328993439674\n",
      "Loss on test= 0.005939300637692213\n",
      "acc for Lsat= 0.15528483517872566 \n",
      "acc for Psat= 0.18694537896033162 \n",
      "acc for optim= 0.1588962043263042\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.005538368131965399\n",
      "Loss on test= 0.006118918303400278\n",
      "acc for Lsat= 0.15195631133053927 \n",
      "acc for Psat= 0.18201365690472246 \n",
      "acc for optim= 0.16211740572051314\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.005400725640356541\n",
      "Loss on test= 0.005952354986220598\n",
      "acc for Lsat= 0.1425318429200742 \n",
      "acc for Psat= 0.17403739431351004 \n",
      "acc for optim= 0.16597908109848267\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.005685270298272371\n",
      "Loss on test= 0.005869640503078699\n",
      "acc for Lsat= 0.14524427360557324 \n",
      "acc for Psat= 0.1751415782970697 \n",
      "acc for optim= 0.15823296867330086\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.0054500168189406395\n",
      "Loss on test= 0.006382975727319717\n",
      "acc for Lsat= 0.16242004674296354 \n",
      "acc for Psat= 0.1671534825103514 \n",
      "acc for optim= 0.16453636972205385\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.0055702864192426205\n",
      "Loss on test= 0.005949169863015413\n",
      "acc for Lsat= 0.1512910450054867 \n",
      "acc for Psat= 0.18023127181656834 \n",
      "acc for optim= 0.16837910381489296\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.005491012241691351\n",
      "Loss on test= 0.006070124916732311\n",
      "acc for Lsat= 0.157270323520824 \n",
      "acc for Psat= 0.17968587544031028 \n",
      "acc for optim= 0.15971790620652562\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.005627087317407131\n",
      "Loss on test= 0.006336777471005917\n",
      "acc for Lsat= 0.15001886956494867 \n",
      "acc for Psat= 0.19419912292896846 \n",
      "acc for optim= 0.16335366787446173\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.005628672428429127\n",
      "Loss on test= 0.005926402751356363\n",
      "acc for Lsat= 0.15520053190106647 \n",
      "acc for Psat= 0.16333692439079864 \n",
      "acc for optim= 0.16679946199960274\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.005595833528786898\n",
      "Loss on test= 0.006141607649624348\n",
      "acc for Lsat= 0.1559503108425711 \n",
      "acc for Psat= 0.1781792146928578 \n",
      "acc for optim= 0.1583539657123944\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.005486343987286091\n",
      "Loss on test= 0.006050880998373032\n",
      "acc for Lsat= 0.15423876449168034 \n",
      "acc for Psat= 0.1752369665941529 \n",
      "acc for optim= 0.15901619635682676\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.005312901921570301\n",
      "Loss on test= 0.006295303348451853\n",
      "acc for Lsat= 0.15727524198820722 \n",
      "acc for Psat= 0.18004345044311895 \n",
      "acc for optim= 0.16614646553195495\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.005285869352519512\n",
      "Loss on test= 0.005955989472568035\n",
      "acc for Lsat= 0.15120294838504422 \n",
      "acc for Psat= 0.17376042728800875 \n",
      "acc for optim= 0.1615937182259914\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.0056902035139501095\n",
      "Loss on test= 0.005767120514065027\n",
      "acc for Lsat= 0.14994142101190175 \n",
      "acc for Psat= 0.18444720705160986 \n",
      "acc for optim= 0.16548399396763627\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.005807011853903532\n",
      "Loss on test= 0.005952372681349516\n",
      "acc for Lsat= 0.1624528020918064 \n",
      "acc for Psat= 0.1895226958692532 \n",
      "acc for optim= 0.16412647659737678\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.005344277713447809\n",
      "Loss on test= 0.006150625646114349\n",
      "acc for Lsat= 0.14658385661247447 \n",
      "acc for Psat= 0.18305787633509055 \n",
      "acc for optim= 0.16274641580788082\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.005311314016580582\n",
      "Loss on test= 0.0062902383506298065\n",
      "acc for Lsat= 0.1464621329134269 \n",
      "acc for Psat= 0.17907750624628951 \n",
      "acc for optim= 0.1618970216397429\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.005312549415975809\n",
      "Loss on test= 0.006071298383176327\n",
      "acc for Lsat= 0.15213381969904313 \n",
      "acc for Psat= 0.18390457831956752 \n",
      "acc for optim= 0.1632165579132919\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.005505030043423176\n",
      "Loss on test= 0.0060744937509298325\n",
      "acc for Lsat= 0.14669325758758398 \n",
      "acc for Psat= 0.1782041182218608 \n",
      "acc for optim= 0.16314210463257994\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.005578588228672743\n",
      "Loss on test= 0.0062577384524047375\n",
      "acc for Lsat= 0.14509234945957747 \n",
      "acc for Psat= 0.19184502372327336 \n",
      "acc for optim= 0.16363519754224518\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.005420939065515995\n",
      "Loss on test= 0.006085144821554422\n",
      "acc for Lsat= 0.15033613518548397 \n",
      "acc for Psat= 0.17320761944770385 \n",
      "acc for optim= 0.15979560835904358\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.0052721742540597916\n",
      "Loss on test= 0.00646247947588563\n",
      "acc for Lsat= 0.15314166938263893 \n",
      "acc for Psat= 0.17565217071964756 \n",
      "acc for optim= 0.16292268191884104\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.00539748277515173\n",
      "Loss on test= 0.006196208763867617\n",
      "acc for Lsat= 0.15241914407014237 \n",
      "acc for Psat= 0.17373525095592085 \n",
      "acc for optim= 0.1642230704629061\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.005649595521390438\n",
      "Loss on test= 0.006165045779198408\n",
      "acc for Lsat= 0.15287756722770654 \n",
      "acc for Psat= 0.17583632997683724 \n",
      "acc for optim= 0.1625600419617945\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.0054101282730698586\n",
      "Loss on test= 0.006033220794051886\n",
      "acc for Lsat= 0.14896806322427497 \n",
      "acc for Psat= 0.17121970498081313 \n",
      "acc for optim= 0.16568300828860585\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.005304121412336826\n",
      "Loss on test= 0.0065729813650250435\n",
      "acc for Lsat= 0.1526296069078361 \n",
      "acc for Psat= 0.1839233942681038 \n",
      "acc for optim= 0.16506669510410693\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.005499189253896475\n",
      "Loss on test= 0.006019446067512035\n",
      "acc for Lsat= 0.15248687220393817 \n",
      "acc for Psat= 0.17115297762860285 \n",
      "acc for optim= 0.1567449840232272\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.005413412116467953\n",
      "Loss on test= 0.005986548028886318\n",
      "acc for Lsat= 0.1513627411858713 \n",
      "acc for Psat= 0.1775374273771466 \n",
      "acc for optim= 0.16360604077285718\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.0054970188066363335\n",
      "Loss on test= 0.006025079172104597\n",
      "acc for Lsat= 0.15650344226417728 \n",
      "acc for Psat= 0.18058363274121506 \n",
      "acc for optim= 0.16197670179965035\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.005564906634390354\n",
      "Loss on test= 0.0063354503363370895\n",
      "acc for Lsat= 0.15040541844023583 \n",
      "acc for Psat= 0.16665967746549973 \n",
      "acc for optim= 0.15889431658910863\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.005471854470670223\n",
      "Loss on test= 0.005895151291042566\n",
      "acc for Lsat= 0.13936889664132576 \n",
      "acc for Psat= 0.18043124744147715 \n",
      "acc for optim= 0.16530586044288806\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.005862924735993147\n",
      "Loss on test= 0.005971570033580065\n",
      "acc for Lsat= 0.15230430667593953 \n",
      "acc for Psat= 0.16257247813260678 \n",
      "acc for optim= 0.16867614867238206\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.005234123207628727\n",
      "Loss on test= 0.0061113182455301285\n",
      "acc for Lsat= 0.14117047028858443 \n",
      "acc for Psat= 0.17997547701457048 \n",
      "acc for optim= 0.15746420841877823\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.005368199665099382\n",
      "Loss on test= 0.006108094472438097\n",
      "acc for Lsat= 0.15263689797510943 \n",
      "acc for Psat= 0.17530865989087271 \n",
      "acc for optim= 0.16739643979321434\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.005378178786486387\n",
      "Loss on test= 0.006314876489341259\n",
      "acc for Lsat= 0.15657245769231298 \n",
      "acc for Psat= 0.19633506662145517 \n",
      "acc for optim= 0.16029613282527683\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.005403108429163694\n",
      "Loss on test= 0.0059675308875739574\n",
      "acc for Lsat= 0.15551524073478087 \n",
      "acc for Psat= 0.1856238437902858 \n",
      "acc for optim= 0.16260008760866304\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.0058573950082063675\n",
      "Loss on test= 0.006069418042898178\n",
      "acc for Lsat= 0.14275595272507624 \n",
      "acc for Psat= 0.16925723105654708 \n",
      "acc for optim= 0.15627957272999843\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.005344700068235397\n",
      "Loss on test= 0.006139513570815325\n",
      "acc for Lsat= 0.1441150937779028 \n",
      "acc for Psat= 0.17623945484434056 \n",
      "acc for optim= 0.1603661813194955\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.005457775667309761\n",
      "Loss on test= 0.006334392353892326\n",
      "acc for Lsat= 0.14570957619690175 \n",
      "acc for Psat= 0.1830788965718668 \n",
      "acc for optim= 0.1607262000376664\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.0053987521678209305\n",
      "Loss on test= 0.006357955746352673\n",
      "acc for Lsat= 0.14679982432538308 \n",
      "acc for Psat= 0.1679025586374337 \n",
      "acc for optim= 0.1595147369671842\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.005401819013059139\n",
      "Loss on test= 0.006345190107822418\n",
      "acc for Lsat= 0.14513082352474516 \n",
      "acc for Psat= 0.18034849929775743 \n",
      "acc for optim= 0.16090182393491573\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.0056605590507388115\n",
      "Loss on test= 0.005937486421316862\n",
      "acc for Lsat= 0.1483116105385888 \n",
      "acc for Psat= 0.17713113402197286 \n",
      "acc for optim= 0.16373692330595135\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.005414030514657497\n",
      "Loss on test= 0.006110794842243195\n",
      "acc for Lsat= 0.14437004305414194 \n",
      "acc for Psat= 0.18284491501208472 \n",
      "acc for optim= 0.1599589042838846\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.005681263282895088\n",
      "Loss on test= 0.006281926762312651\n",
      "acc for Lsat= 0.14616820563180047 \n",
      "acc for Psat= 0.18560781198263657 \n",
      "acc for optim= 0.16409478364894015\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.005505560897290707\n",
      "Loss on test= 0.006198227405548096\n",
      "acc for Lsat= 0.1516343596191947 \n",
      "acc for Psat= 0.1823962077750351 \n",
      "acc for optim= 0.16352823509674397\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.005370945669710636\n",
      "Loss on test= 0.006198118440806866\n",
      "acc for Lsat= 0.15777611699524016 \n",
      "acc for Psat= 0.16840824501619475 \n",
      "acc for optim= 0.16251114451605064\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.005378336645662785\n",
      "Loss on test= 0.0061392346397042274\n",
      "acc for Lsat= 0.15042448710482262 \n",
      "acc for Psat= 0.18216449844452445 \n",
      "acc for optim= 0.16148959707380958\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.005640893243253231\n",
      "Loss on test= 0.006053431890904903\n",
      "acc for Lsat= 0.15890072517471052 \n",
      "acc for Psat= 0.18325363081044013 \n",
      "acc for optim= 0.15815769689382803\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.005314755253493786\n",
      "Loss on test= 0.006118452176451683\n",
      "acc for Lsat= 0.1573136103154374 \n",
      "acc for Psat= 0.18426256049787612 \n",
      "acc for optim= 0.16041988110393177\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.005622340831905603\n",
      "Loss on test= 0.0059277708642184734\n",
      "acc for Lsat= 0.14942404819599 \n",
      "acc for Psat= 0.1861103203157192 \n",
      "acc for optim= 0.16526136160522822\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.0053207953460514545\n",
      "Loss on test= 0.006158726755529642\n",
      "acc for Lsat= 0.14992209457530883 \n",
      "acc for Psat= 0.1746344347847015 \n",
      "acc for optim= 0.1644179591714628\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.0052487608045339584\n",
      "Loss on test= 0.00595833919942379\n",
      "acc for Lsat= 0.15542408725505383 \n",
      "acc for Psat= 0.16781722421177708 \n",
      "acc for optim= 0.16919202153727442\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.005400862544775009\n",
      "Loss on test= 0.006313677877187729\n",
      "acc for Lsat= 0.14748603538533703 \n",
      "acc for Psat= 0.1765005882233992 \n",
      "acc for optim= 0.16147357468563894\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.005419487599283457\n",
      "Loss on test= 0.006158274598419666\n",
      "acc for Lsat= 0.15220072565292062 \n",
      "acc for Psat= 0.1643570626853034 \n",
      "acc for optim= 0.15974203290462638\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.005621637217700481\n",
      "Loss on test= 0.005892647895962\n",
      "acc for Lsat= 0.1426956238368236 \n",
      "acc for Psat= 0.1885857575943266 \n",
      "acc for optim= 0.16424329744672905\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.005202559754252434\n",
      "Loss on test= 0.005959648173302412\n",
      "acc for Lsat= 0.1505784763629428 \n",
      "acc for Psat= 0.183504486361091 \n",
      "acc for optim= 0.16119453676663278\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.005632874555885792\n",
      "Loss on test= 0.00632526446133852\n",
      "acc for Lsat= 0.16086748347953572 \n",
      "acc for Psat= 0.20089065373615653 \n",
      "acc for optim= 0.16438824524854875\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.005579343531280756\n",
      "Loss on test= 0.0059127965942025185\n",
      "acc for Lsat= 0.15246401049509706 \n",
      "acc for Psat= 0.1722223669317261 \n",
      "acc for optim= 0.1692501131268638\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.005360052455216646\n",
      "Loss on test= 0.005981653928756714\n",
      "acc for Lsat= 0.14917363921890311 \n",
      "acc for Psat= 0.1838605981125481 \n",
      "acc for optim= 0.1611673421844779\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.005705895833671093\n",
      "Loss on test= 0.006150222849100828\n",
      "acc for Lsat= 0.14823750449529635 \n",
      "acc for Psat= 0.18358791661229304 \n",
      "acc for optim= 0.1581243374304785\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.005794824566692114\n",
      "Loss on test= 0.006193565204739571\n",
      "acc for Lsat= 0.1447648189179208 \n",
      "acc for Psat= 0.18814625538519172 \n",
      "acc for optim= 0.1660466490356828\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.005976141896098852\n",
      "Loss on test= 0.006312038283795118\n",
      "acc for Lsat= 0.14548189421756896 \n",
      "acc for Psat= 0.18757340626306374 \n",
      "acc for optim= 0.1692995650788004\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.005510901100933552\n",
      "Loss on test= 0.005970272701233625\n",
      "acc for Lsat= 0.14456012541147667 \n",
      "acc for Psat= 0.16947357422447015 \n",
      "acc for optim= 0.1697219882282566\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.005392842460423708\n",
      "Loss on test= 0.006024838425219059\n",
      "acc for Lsat= 0.15202497300113643 \n",
      "acc for Psat= 0.16724875513731396 \n",
      "acc for optim= 0.16589399411659841\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.005500972270965576\n",
      "Loss on test= 0.005997870583087206\n",
      "acc for Lsat= 0.159070063460061 \n",
      "acc for Psat= 0.17182604913966212 \n",
      "acc for optim= 0.1644838617033455\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.005430974066257477\n",
      "Loss on test= 0.006491345353424549\n",
      "acc for Lsat= 0.14791564145392633 \n",
      "acc for Psat= 0.17841091777052975 \n",
      "acc for optim= 0.16772651750304293\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.005438340362161398\n",
      "Loss on test= 0.0059386915527284145\n",
      "acc for Lsat= 0.1577631408521394 \n",
      "acc for Psat= 0.18575813143025535 \n",
      "acc for optim= 0.1634388490923543\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.005467004608362913\n",
      "Loss on test= 0.006358932703733444\n",
      "acc for Lsat= 0.1542733683407337 \n",
      "acc for Psat= 0.1813439370180694 \n",
      "acc for optim= 0.16691162288112596\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.005534552503377199\n",
      "Loss on test= 0.006284745410084724\n",
      "acc for Lsat= 0.14444300544526442 \n",
      "acc for Psat= 0.171594663631442 \n",
      "acc for optim= 0.1657821001832089\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.005304289981722832\n",
      "Loss on test= 0.0058680688962340355\n",
      "acc for Lsat= 0.15063716593022783 \n",
      "acc for Psat= 0.17812374618990331 \n",
      "acc for optim= 0.16643781140523\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.005540578160434961\n",
      "Loss on test= 0.006133093032985926\n",
      "acc for Lsat= 0.15739277831162327 \n",
      "acc for Psat= 0.17335655096437416 \n",
      "acc for optim= 0.1714302863654696\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.005258697085082531\n",
      "Loss on test= 0.006003518123179674\n",
      "acc for Lsat= 0.1562096598195523 \n",
      "acc for Psat= 0.17694020076715922 \n",
      "acc for optim= 0.16168097374745125\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.005394249223172665\n",
      "Loss on test= 0.00591015862300992\n",
      "acc for Lsat= 0.14388125890896458 \n",
      "acc for Psat= 0.17411081539204565 \n",
      "acc for optim= 0.16908841851075776\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.005371590610593557\n",
      "Loss on test= 0.0058977981097996235\n",
      "acc for Lsat= 0.15753060021746873 \n",
      "acc for Psat= 0.18342405449137184 \n",
      "acc for optim= 0.16566698435891025\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.005533263087272644\n",
      "Loss on test= 0.006041926331818104\n",
      "acc for Lsat= 0.1502172943326782 \n",
      "acc for Psat= 0.15867648917707408 \n",
      "acc for optim= 0.16113330557194278\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.005503206048160791\n",
      "Loss on test= 0.0061600543558597565\n",
      "acc for Lsat= 0.14518277209068908 \n",
      "acc for Psat= 0.18161462285500077 \n",
      "acc for optim= 0.1625860473041835\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.0056508746929466724\n",
      "Loss on test= 0.006425247993320227\n",
      "acc for Lsat= 0.14615993550482403 \n",
      "acc for Psat= 0.1682426670860102 \n",
      "acc for optim= 0.16933452714994152\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.005649548955261707\n",
      "Loss on test= 0.006059179548174143\n",
      "acc for Lsat= 0.14806378285980737 \n",
      "acc for Psat= 0.17540725833396656 \n",
      "acc for optim= 0.16663575982379147\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.005399602930992842\n",
      "Loss on test= 0.00590644683688879\n",
      "acc for Lsat= 0.14258830158830024 \n",
      "acc for Psat= 0.1789366159790394 \n",
      "acc for optim= 0.1607599732623489\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.005379175301641226\n",
      "Loss on test= 0.006298965774476528\n",
      "acc for Lsat= 0.14445596564271043 \n",
      "acc for Psat= 0.1767676774563161 \n",
      "acc for optim= 0.17238728333470701\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.005582742393016815\n",
      "Loss on test= 0.0061280736699700356\n",
      "acc for Lsat= 0.14327193905602278 \n",
      "acc for Psat= 0.1738233580662426 \n",
      "acc for optim= 0.16906524705939133\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.005456036422401667\n",
      "Loss on test= 0.006208112929016352\n",
      "acc for Lsat= 0.16110276460349865 \n",
      "acc for Psat= 0.19391712152731191 \n",
      "acc for optim= 0.16916317666750058\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.005300172604620457\n",
      "Loss on test= 0.006016545929014683\n",
      "acc for Lsat= 0.1466656586315605 \n",
      "acc for Psat= 0.17391349702613565 \n",
      "acc for optim= 0.1624600677504815\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.0054902974516153336\n",
      "Loss on test= 0.006239624693989754\n",
      "acc for Lsat= 0.14966290369124122 \n",
      "acc for Psat= 0.1791680446917527 \n",
      "acc for optim= 0.1639052000353838\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.0052941967733204365\n",
      "Loss on test= 0.006147264037281275\n",
      "acc for Lsat= 0.15110645833936687 \n",
      "acc for Psat= 0.17622805510353695 \n",
      "acc for optim= 0.171029684760562\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.005724117625504732\n",
      "Loss on test= 0.006018234416842461\n",
      "acc for Lsat= 0.1535419783600774 \n",
      "acc for Psat= 0.1710849200863941 \n",
      "acc for optim= 0.16438937814196297\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.005332991946488619\n",
      "Loss on test= 0.006145897321403027\n",
      "acc for Lsat= 0.14536857597747452 \n",
      "acc for Psat= 0.182616271299394 \n",
      "acc for optim= 0.15799072599334887\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.0054100980050861835\n",
      "Loss on test= 0.006153549533337355\n",
      "acc for Lsat= 0.15353130967944068 \n",
      "acc for Psat= 0.17653960827127343 \n",
      "acc for optim= 0.16205853025827816\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.006097261793911457\n",
      "Loss on test= 0.006021494045853615\n",
      "acc for Lsat= 0.14794442283684295 \n",
      "acc for Psat= 0.17023013528841013 \n",
      "acc for optim= 0.1631338466334798\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.00544917955994606\n",
      "Loss on test= 0.005993280094116926\n",
      "acc for Lsat= 0.14790152150061225 \n",
      "acc for Psat= 0.18353607989618648 \n",
      "acc for optim= 0.16707411894038487\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.0054161082953214645\n",
      "Loss on test= 0.006561079062521458\n",
      "acc for Lsat= 0.15850926621065123 \n",
      "acc for Psat= 0.18122402463150286 \n",
      "acc for optim= 0.16422471671411004\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.005477597936987877\n",
      "Loss on test= 0.006282919552177191\n",
      "acc for Lsat= 0.1553224073589367 \n",
      "acc for Psat= 0.1751127305131436 \n",
      "acc for optim= 0.16109428474313167\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.005826647859066725\n",
      "Loss on test= 0.006494056899100542\n",
      "acc for Lsat= 0.15020165513703776 \n",
      "acc for Psat= 0.18904809033036324 \n",
      "acc for optim= 0.16396936026791142\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.0054255141876637936\n",
      "Loss on test= 0.005905955098569393\n",
      "acc for Lsat= 0.14822656577667717 \n",
      "acc for Psat= 0.1815701730838167 \n",
      "acc for optim= 0.16670617201054452\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.005401007365435362\n",
      "Loss on test= 0.005869230721145868\n",
      "acc for Lsat= 0.14918096622520843 \n",
      "acc for Psat= 0.183897420251742 \n",
      "acc for optim= 0.17008339372662956\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.005507900845259428\n",
      "Loss on test= 0.006232866086065769\n",
      "acc for Lsat= 0.13943977873022362 \n",
      "acc for Psat= 0.1703784780372621 \n",
      "acc for optim= 0.1653436421419324\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.005388667806982994\n",
      "Loss on test= 0.005815307609736919\n",
      "acc for Lsat= 0.14850219903174086 \n",
      "acc for Psat= 0.17803633616083553 \n",
      "acc for optim= 0.16306250589941704\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.005765825975686312\n",
      "Loss on test= 0.0059130871668457985\n",
      "acc for Lsat= 0.14981170312203773 \n",
      "acc for Psat= 0.17650097081117208 \n",
      "acc for optim= 0.16728444766161626\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.005585488863289356\n",
      "Loss on test= 0.006191227585077286\n",
      "acc for Lsat= 0.1548786796532098 \n",
      "acc for Psat= 0.1845257447124077 \n",
      "acc for optim= 0.16413815019911795\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.0056733014062047005\n",
      "Loss on test= 0.00569494441151619\n",
      "acc for Lsat= 0.1390503809424728 \n",
      "acc for Psat= 0.18404277221311158 \n",
      "acc for optim= 0.16406897213481764\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.005527551751583815\n",
      "Loss on test= 0.006331205368041992\n",
      "acc for Lsat= 0.15393948847328726 \n",
      "acc for Psat= 0.19005726950498847 \n",
      "acc for optim= 0.16948091874550839\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.005463168025016785\n",
      "Loss on test= 0.0061605554074049\n",
      "acc for Lsat= 0.14341474582200686 \n",
      "acc for Psat= 0.18066818500930046 \n",
      "acc for optim= 0.17753896904970565\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.005338202230632305\n",
      "Loss on test= 0.006316434126347303\n",
      "acc for Lsat= 0.13850832153751028 \n",
      "acc for Psat= 0.18021872830443603 \n",
      "acc for optim= 0.1604752967031062\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.00567705649882555\n",
      "Loss on test= 0.006325168069452047\n",
      "acc for Lsat= 0.14681174069085753 \n",
      "acc for Psat= 0.1808801369527813 \n",
      "acc for optim= 0.1580230712326142\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.005465800873935223\n",
      "Loss on test= 0.006035570986568928\n",
      "acc for Lsat= 0.15250650119908596 \n",
      "acc for Psat= 0.1756102704721671 \n",
      "acc for optim= 0.16131483158540386\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.005363622214645147\n",
      "Loss on test= 0.0058215283788740635\n",
      "acc for Lsat= 0.1470864764040672 \n",
      "acc for Psat= 0.16669389993166092 \n",
      "acc for optim= 0.1644893246209039\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.005205577239394188\n",
      "Loss on test= 0.006224200129508972\n",
      "acc for Lsat= 0.1508777211339129 \n",
      "acc for Psat= 0.18543990587798467 \n",
      "acc for optim= 0.1635070568885746\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.005406365729868412\n",
      "Loss on test= 0.006133602000772953\n",
      "acc for Lsat= 0.14691227999295225 \n",
      "acc for Psat= 0.16856345400695125 \n",
      "acc for optim= 0.1685075229862094\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.00552536454051733\n",
      "Loss on test= 0.0060868836008012295\n",
      "acc for Lsat= 0.15575123776826763 \n",
      "acc for Psat= 0.1883512715177351 \n",
      "acc for optim= 0.16365570909378013\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.005348567385226488\n",
      "Loss on test= 0.006427855230867863\n",
      "acc for Lsat= 0.15131978961528417 \n",
      "acc for Psat= 0.18546993513973278 \n",
      "acc for optim= 0.15959253763650225\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.005676449276506901\n",
      "Loss on test= 0.005990469828248024\n",
      "acc for Lsat= 0.1469487125088354 \n",
      "acc for Psat= 0.18890398377266363 \n",
      "acc for optim= 0.1623458067868401\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.005253972020000219\n",
      "Loss on test= 0.0060089342296123505\n",
      "acc for Lsat= 0.1468959755248955 \n",
      "acc for Psat= 0.17874303185171067 \n",
      "acc for optim= 0.16722185417139507\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.00531154777854681\n",
      "Loss on test= 0.006087735295295715\n",
      "acc for Lsat= 0.15246376249496443 \n",
      "acc for Psat= 0.18472407911751482 \n",
      "acc for optim= 0.1686225604478243\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.00519754970446229\n",
      "Loss on test= 0.006402761209756136\n",
      "acc for Lsat= 0.14104456820975622 \n",
      "acc for Psat= 0.17526170540154676 \n",
      "acc for optim= 0.161455936548844\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.005547280423343182\n",
      "Loss on test= 0.006577993743121624\n",
      "acc for Lsat= 0.14944568299001357 \n",
      "acc for Psat= 0.17763283325167903 \n",
      "acc for optim= 0.16521239266043805\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.005245002917945385\n",
      "Loss on test= 0.006104081403464079\n",
      "acc for Lsat= 0.15131879653027816 \n",
      "acc for Psat= 0.18550049648190786 \n",
      "acc for optim= 0.16861833637794021\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.005507917143404484\n",
      "Loss on test= 0.006236306391656399\n",
      "acc for Lsat= 0.14427137563394413 \n",
      "acc for Psat= 0.18638188729929112 \n",
      "acc for optim= 0.16469228479211584\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.005772066302597523\n",
      "Loss on test= 0.006372776348143816\n",
      "acc for Lsat= 0.14968574188046585 \n",
      "acc for Psat= 0.17999364836866677 \n",
      "acc for optim= 0.16576052295219643\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.005461400840431452\n",
      "Loss on test= 0.006065514869987965\n",
      "acc for Lsat= 0.15157730981233325 \n",
      "acc for Psat= 0.16958324782956835 \n",
      "acc for optim= 0.16184613179266605\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.005553294904530048\n",
      "Loss on test= 0.006185538601130247\n",
      "acc for Lsat= 0.15084490615974244 \n",
      "acc for Psat= 0.1786267673482233 \n",
      "acc for optim= 0.168273112680534\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.005773352924734354\n",
      "Loss on test= 0.006546270567923784\n",
      "acc for Lsat= 0.1399490317208578 \n",
      "acc for Psat= 0.18142092683119698 \n",
      "acc for optim= 0.16419315215459734\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.005446514114737511\n",
      "Loss on test= 0.006001113448292017\n",
      "acc for Lsat= 0.1517850354073386 \n",
      "acc for Psat= 0.182312836934669 \n",
      "acc for optim= 0.16581594944057498\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.005398948676884174\n",
      "Loss on test= 0.005928075406700373\n",
      "acc for Lsat= 0.14992245941295967 \n",
      "acc for Psat= 0.16779528827851134 \n",
      "acc for optim= 0.1581532800363541\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.005299363750964403\n",
      "Loss on test= 0.006014729849994183\n",
      "acc for Lsat= 0.14885741320408147 \n",
      "acc for Psat= 0.1892214476008762 \n",
      "acc for optim= 0.16778630141329143\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.005575123243033886\n",
      "Loss on test= 0.0061851791106164455\n",
      "acc for Lsat= 0.1449369468569725 \n",
      "acc for Psat= 0.18093765958548202 \n",
      "acc for optim= 0.15884820496831395\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.005381929688155651\n",
      "Loss on test= 0.005753329489380121\n",
      "acc for Lsat= 0.14974471042619744 \n",
      "acc for Psat= 0.18865565527640818 \n",
      "acc for optim= 0.15638129666455272\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.005215250886976719\n",
      "Loss on test= 0.0058744377456605434\n",
      "acc for Lsat= 0.1510202411024022 \n",
      "acc for Psat= 0.1807652845493991 \n",
      "acc for optim= 0.16587378408141495\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.005427292548120022\n",
      "Loss on test= 0.0060270121321082115\n",
      "acc for Lsat= 0.14630864593200385 \n",
      "acc for Psat= 0.19230804146858138 \n",
      "acc for optim= 0.16673052650074796\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.005166688933968544\n",
      "Loss on test= 0.0061035118997097015\n",
      "acc for Lsat= 0.1560343539346101 \n",
      "acc for Psat= 0.1922241172470824 \n",
      "acc for optim= 0.16740819569047327\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.0054109664633870125\n",
      "Loss on test= 0.006085360422730446\n",
      "acc for Lsat= 0.15192344499965194 \n",
      "acc for Psat= 0.17853971337823227 \n",
      "acc for optim= 0.16606193911913997\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.005865888670086861\n",
      "Loss on test= 0.0061157699674367905\n",
      "acc for Lsat= 0.15519153902700292 \n",
      "acc for Psat= 0.1743977097821132 \n",
      "acc for optim= 0.1679286748926598\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.005431594327092171\n",
      "Loss on test= 0.006369246635586023\n",
      "acc for Lsat= 0.14077486200887923 \n",
      "acc for Psat= 0.18035577959304705 \n",
      "acc for optim= 0.16010835771525248\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.005292469169944525\n",
      "Loss on test= 0.0061365654692053795\n",
      "acc for Lsat= 0.14972656917348923 \n",
      "acc for Psat= 0.1841771251470238 \n",
      "acc for optim= 0.16050158588208074\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.005577425472438335\n",
      "Loss on test= 0.006244755815714598\n",
      "acc for Lsat= 0.14471860861522146 \n",
      "acc for Psat= 0.16670078508094044 \n",
      "acc for optim= 0.1673228490771344\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.005697214975953102\n",
      "Loss on test= 0.005932364147156477\n",
      "acc for Lsat= 0.14469056645270864 \n",
      "acc for Psat= 0.17585448333669118 \n",
      "acc for optim= 0.16276164780243024\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.005380734335631132\n",
      "Loss on test= 0.006288466509431601\n",
      "acc for Lsat= 0.15802352515461504 \n",
      "acc for Psat= 0.19319033797266874 \n",
      "acc for optim= 0.16653857714006082\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.0057333349250257015\n",
      "Loss on test= 0.006013176869601011\n",
      "acc for Lsat= 0.1442614959173103 \n",
      "acc for Psat= 0.18145278224561243 \n",
      "acc for optim= 0.1595737631620217\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.005207947455346584\n",
      "Loss on test= 0.006389194168150425\n",
      "acc for Lsat= 0.1472974401318514 \n",
      "acc for Psat= 0.1741692592382248 \n",
      "acc for optim= 0.16390581169837445\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.005505542270839214\n",
      "Loss on test= 0.005942747928202152\n",
      "acc for Lsat= 0.15335716720380377 \n",
      "acc for Psat= 0.17684406505107544 \n",
      "acc for optim= 0.16406648587075862\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.0053110201843082905\n",
      "Loss on test= 0.006226868834346533\n",
      "acc for Lsat= 0.1414398252437288 \n",
      "acc for Psat= 0.1718390890667177 \n",
      "acc for optim= 0.16265022743843519\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.005714546889066696\n",
      "Loss on test= 0.005856008268892765\n",
      "acc for Lsat= 0.1572101172773534 \n",
      "acc for Psat= 0.18217035054294087 \n",
      "acc for optim= 0.1637727421000371\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.005397746805101633\n",
      "Loss on test= 0.006180459633469582\n",
      "acc for Lsat= 0.14203655419739528 \n",
      "acc for Psat= 0.17793771020417315 \n",
      "acc for optim= 0.16961588591344837\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.0061026280745863914\n",
      "Loss on test= 0.006287750322371721\n",
      "acc for Lsat= 0.15301524629234872 \n",
      "acc for Psat= 0.17410614580082034 \n",
      "acc for optim= 0.16035967597589526\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.005993625149130821\n",
      "Loss on test= 0.00604282459244132\n",
      "acc for Lsat= 0.1537697593746163 \n",
      "acc for Psat= 0.1735488665580261 \n",
      "acc for optim= 0.16618290480539263\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.005472315941005945\n",
      "Loss on test= 0.006039049942046404\n",
      "acc for Lsat= 0.16078410595750864 \n",
      "acc for Psat= 0.1753813823514244 \n",
      "acc for optim= 0.17023481782010497\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.005403544753789902\n",
      "Loss on test= 0.0059592206962406635\n",
      "acc for Lsat= 0.14824149641022277 \n",
      "acc for Psat= 0.1772052662302053 \n",
      "acc for optim= 0.16310317959812026\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.00535401189699769\n",
      "Loss on test= 0.006162357982248068\n",
      "acc for Lsat= 0.14919271943125764 \n",
      "acc for Psat= 0.16938459370208936 \n",
      "acc for optim= 0.1680277158469954\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.0052085998468101025\n",
      "Loss on test= 0.005772923585027456\n",
      "acc for Lsat= 0.14722066851243087 \n",
      "acc for Psat= 0.18666646511085927 \n",
      "acc for optim= 0.16196068409986825\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.006031894590705633\n",
      "Loss on test= 0.006069449707865715\n",
      "acc for Lsat= 0.156088155246584 \n",
      "acc for Psat= 0.19572809136417296 \n",
      "acc for optim= 0.16308168869057182\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.005529673304408789\n",
      "Loss on test= 0.006520622409880161\n",
      "acc for Lsat= 0.14538938009979768 \n",
      "acc for Psat= 0.17873957093938247 \n",
      "acc for optim= 0.16134077258423338\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.005527647212147713\n",
      "Loss on test= 0.005822063889354467\n",
      "acc for Lsat= 0.1554914437347 \n",
      "acc for Psat= 0.1789426978757666 \n",
      "acc for optim= 0.1665620758125442\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.00532283540815115\n",
      "Loss on test= 0.005947082303464413\n",
      "acc for Lsat= 0.15205781085886153 \n",
      "acc for Psat= 0.1873321685999189 \n",
      "acc for optim= 0.16387604718192214\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.005281255580484867\n",
      "Loss on test= 0.005997516680508852\n",
      "acc for Lsat= 0.14936126628251303 \n",
      "acc for Psat= 0.18459429195585858 \n",
      "acc for optim= 0.16140592819448088\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.0055386461317539215\n",
      "Loss on test= 0.005903023295104504\n",
      "acc for Lsat= 0.15637234035177064 \n",
      "acc for Psat= 0.1861836533023991 \n",
      "acc for optim= 0.16561956336439326\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.005250120535492897\n",
      "Loss on test= 0.006206556223332882\n",
      "acc for Lsat= 0.15043627627155282 \n",
      "acc for Psat= 0.18590251273201486 \n",
      "acc for optim= 0.1647808635676066\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.0053874421864748\n",
      "Loss on test= 0.006171868648380041\n",
      "acc for Lsat= 0.1537181743315696 \n",
      "acc for Psat= 0.1890599945506661 \n",
      "acc for optim= 0.16254866528488193\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.005364042706787586\n",
      "Loss on test= 0.005898098926991224\n",
      "acc for Lsat= 0.13195425041218395 \n",
      "acc for Psat= 0.17152015711562554 \n",
      "acc for optim= 0.16368283268157774\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.0054761264473199844\n",
      "Loss on test= 0.006289409939199686\n",
      "acc for Lsat= 0.16532083715762577 \n",
      "acc for Psat= 0.1670578039499366 \n",
      "acc for optim= 0.16129289356672938\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.005361937917768955\n",
      "Loss on test= 0.006021016743034124\n",
      "acc for Lsat= 0.16511624150233892 \n",
      "acc for Psat= 0.17652524288239904 \n",
      "acc for optim= 0.16135207324796433\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.005313480272889137\n",
      "Loss on test= 0.006432943046092987\n",
      "acc for Lsat= 0.15005774034767366 \n",
      "acc for Psat= 0.17914587794824552 \n",
      "acc for optim= 0.1652869026137508\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.0055298274382948875\n",
      "Loss on test= 0.005655841436237097\n",
      "acc for Lsat= 0.1497025848702207 \n",
      "acc for Psat= 0.17261306329011977 \n",
      "acc for optim= 0.16674484346638296\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.0054588294588029385\n",
      "Loss on test= 0.006368010770529509\n",
      "acc for Lsat= 0.15922298332643847 \n",
      "acc for Psat= 0.1761246530054763 \n",
      "acc for optim= 0.16777860458146354\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.005783057305961847\n",
      "Loss on test= 0.006167228799313307\n",
      "acc for Lsat= 0.15757803827230524 \n",
      "acc for Psat= 0.1853560313329074 \n",
      "acc for optim= 0.16098206621732136\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.005529933143407106\n",
      "Loss on test= 0.006113829091191292\n",
      "acc for Lsat= 0.15291284767251948 \n",
      "acc for Psat= 0.16803259053878242 \n",
      "acc for optim= 0.16762826008355763\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.005528009496629238\n",
      "Loss on test= 0.0058042556047439575\n",
      "acc for Lsat= 0.14568383250458045 \n",
      "acc for Psat= 0.16547700639348478 \n",
      "acc for optim= 0.16607307339048274\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.005621927324682474\n",
      "Loss on test= 0.005841601639986038\n",
      "acc for Lsat= 0.16026936502131006 \n",
      "acc for Psat= 0.1768576288601521 \n",
      "acc for optim= 0.16314182242781275\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.005618738941848278\n",
      "Loss on test= 0.00671786954626441\n",
      "acc for Lsat= 0.14760462487341652 \n",
      "acc for Psat= 0.19026383866566604 \n",
      "acc for optim= 0.16619875231260609\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.006602397654205561\n",
      "Loss on test= 0.005968961399048567\n",
      "acc for Lsat= 0.15368498226620073 \n",
      "acc for Psat= 0.17648848986756974 \n",
      "acc for optim= 0.16921452130133774\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.005385146476328373\n",
      "Loss on test= 0.006218921393156052\n",
      "acc for Lsat= 0.142399050680764 \n",
      "acc for Psat= 0.1867168948912161 \n",
      "acc for optim= 0.16693483054863106\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.00515101058408618\n",
      "Loss on test= 0.005851257126778364\n",
      "acc for Lsat= 0.1459415291579627 \n",
      "acc for Psat= 0.1696904759367424 \n",
      "acc for optim= 0.16821863048358773\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.005401145666837692\n",
      "Loss on test= 0.006012058351188898\n",
      "acc for Lsat= 0.1525010857654766 \n",
      "acc for Psat= 0.1793642600196794 \n",
      "acc for optim= 0.15534472538188832\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.0053492276929318905\n",
      "Loss on test= 0.006174906622618437\n",
      "acc for Lsat= 0.1531440412969191 \n",
      "acc for Psat= 0.1859578536632547 \n",
      "acc for optim= 0.17287455441804267\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.005616962444037199\n",
      "Loss on test= 0.005915969144552946\n",
      "acc for Lsat= 0.14186622074411107 \n",
      "acc for Psat= 0.1842342739649972 \n",
      "acc for optim= 0.16765894774747364\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.005648134741932154\n",
      "Loss on test= 0.006134796887636185\n",
      "acc for Lsat= 0.14953098407665985 \n",
      "acc for Psat= 0.19013152195762872 \n",
      "acc for optim= 0.16754797273525418\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.005624736193567514\n",
      "Loss on test= 0.00613795593380928\n",
      "acc for Lsat= 0.15502772827815936 \n",
      "acc for Psat= 0.18261970491577934 \n",
      "acc for optim= 0.16150961841912712\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.005516120232641697\n",
      "Loss on test= 0.0060670580714941025\n",
      "acc for Lsat= 0.15278958308999044 \n",
      "acc for Psat= 0.17683218028057618 \n",
      "acc for optim= 0.16916570921092614\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.005312315188348293\n",
      "Loss on test= 0.006247284356504679\n",
      "acc for Lsat= 0.14619874692785356 \n",
      "acc for Psat= 0.17333208804255443 \n",
      "acc for optim= 0.15832454127824452\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.005365915130823851\n",
      "Loss on test= 0.006314682774245739\n",
      "acc for Lsat= 0.14705140346978013 \n",
      "acc for Psat= 0.17781334831761045 \n",
      "acc for optim= 0.16163967457546502\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.0055601634085178375\n",
      "Loss on test= 0.006515695713460445\n",
      "acc for Lsat= 0.14125201374723684 \n",
      "acc for Psat= 0.17377772664662725 \n",
      "acc for optim= 0.1660445258368692\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.005469679366797209\n",
      "Loss on test= 0.006255685817450285\n",
      "acc for Lsat= 0.1503609302217049 \n",
      "acc for Psat= 0.17286274936455723 \n",
      "acc for optim= 0.1646440332083673\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.005753976758569479\n",
      "Loss on test= 0.005739710759371519\n",
      "acc for Lsat= 0.15437290689509103 \n",
      "acc for Psat= 0.18612252325067663 \n",
      "acc for optim= 0.1651313794302548\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.005646384321153164\n",
      "Loss on test= 0.005682019982486963\n",
      "acc for Lsat= 0.1621386986595128 \n",
      "acc for Psat= 0.17742897842287422 \n",
      "acc for optim= 0.1611859042262353\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.0054268077947199345\n",
      "Loss on test= 0.00616797711700201\n",
      "acc for Lsat= 0.14872396351143596 \n",
      "acc for Psat= 0.17219637478472757 \n",
      "acc for optim= 0.16418073209447281\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.005867398343980312\n",
      "Loss on test= 0.006155201233923435\n",
      "acc for Lsat= 0.15673146940353633 \n",
      "acc for Psat= 0.18554889692879115 \n",
      "acc for optim= 0.15777404249567523\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.00533266318961978\n",
      "Loss on test= 0.006583285052329302\n",
      "acc for Lsat= 0.1538961193830607 \n",
      "acc for Psat= 0.17052119189289353 \n",
      "acc for optim= 0.16340813631913242\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.005336611531674862\n",
      "Loss on test= 0.005765953566879034\n",
      "acc for Lsat= 0.14839264414298012 \n",
      "acc for Psat= 0.18201794338199792 \n",
      "acc for optim= 0.16669280317757035\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.005561894737184048\n",
      "Loss on test= 0.0061516351997852325\n",
      "acc for Lsat= 0.14888684905580718 \n",
      "acc for Psat= 0.17016212707309084 \n",
      "acc for optim= 0.15648569764214432\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.005263968370854855\n",
      "Loss on test= 0.006022483576089144\n",
      "acc for Lsat= 0.1455242748961967 \n",
      "acc for Psat= 0.17058843779186794 \n",
      "acc for optim= 0.16749503428047738\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.005490100476890802\n",
      "Loss on test= 0.006547433789819479\n",
      "acc for Lsat= 0.14321433253372545 \n",
      "acc for Psat= 0.17316816161027881 \n",
      "acc for optim= 0.15928936153125461\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.005480605643242598\n",
      "Loss on test= 0.006130398251116276\n",
      "acc for Lsat= 0.1364488634300899 \n",
      "acc for Psat= 0.16506724941322856 \n",
      "acc for optim= 0.16344444676349248\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.005344458855688572\n",
      "Loss on test= 0.006120508536696434\n",
      "acc for Lsat= 0.15500862062040366 \n",
      "acc for Psat= 0.18021124410450165 \n",
      "acc for optim= 0.17014837182817796\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.005501388106495142\n",
      "Loss on test= 0.005963051691651344\n",
      "acc for Lsat= 0.15785620913260662 \n",
      "acc for Psat= 0.1849577380069455 \n",
      "acc for optim= 0.1605476493236311\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.005291918758302927\n",
      "Loss on test= 0.006182434502989054\n",
      "acc for Lsat= 0.1554875304882384 \n",
      "acc for Psat= 0.1834937058551405 \n",
      "acc for optim= 0.1676819385883406\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.005986544769257307\n",
      "Loss on test= 0.006347803398966789\n",
      "acc for Lsat= 0.1567638518882259 \n",
      "acc for Psat= 0.1760796389794435 \n",
      "acc for optim= 0.15855755819595557\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.005444739945232868\n",
      "Loss on test= 0.006183905992656946\n",
      "acc for Lsat= 0.15084093812563013 \n",
      "acc for Psat= 0.18111647877376527 \n",
      "acc for optim= 0.16734483122833257\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.005592316389083862\n",
      "Loss on test= 0.005806466564536095\n",
      "acc for Lsat= 0.16213902968772093 \n",
      "acc for Psat= 0.18249826331195407 \n",
      "acc for optim= 0.15906809087438112\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.00615745410323143\n",
      "Loss on test= 0.006153319496661425\n",
      "acc for Lsat= 0.1401700656349603 \n",
      "acc for Psat= 0.1889625112901606 \n",
      "acc for optim= 0.16229672249340735\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.005347659811377525\n",
      "Loss on test= 0.006159990560263395\n",
      "acc for Lsat= 0.14658892569093981 \n",
      "acc for Psat= 0.1913738099377236 \n",
      "acc for optim= 0.1657056770987616\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.005927370395511389\n",
      "Loss on test= 0.005950211547315121\n",
      "acc for Lsat= 0.14265233896993346 \n",
      "acc for Psat= 0.1784539511950198 \n",
      "acc for optim= 0.1681152835350434\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.00540654081851244\n",
      "Loss on test= 0.006253543309867382\n",
      "acc for Lsat= 0.14495248812666833 \n",
      "acc for Psat= 0.1670247663165534 \n",
      "acc for optim= 0.1667565925878885\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.005377132445573807\n",
      "Loss on test= 0.006069590337574482\n",
      "acc for Lsat= 0.14858707096809368 \n",
      "acc for Psat= 0.1729046312592099 \n",
      "acc for optim= 0.16207028167282558\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.005561579950153828\n",
      "Loss on test= 0.006304803304374218\n",
      "acc for Lsat= 0.156577725142439 \n",
      "acc for Psat= 0.16819684631229362 \n",
      "acc for optim= 0.1640976615780659\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.005368552170693874\n",
      "Loss on test= 0.006266742944717407\n",
      "acc for Lsat= 0.1508574691777629 \n",
      "acc for Psat= 0.17954833384357072 \n",
      "acc for optim= 0.1622547146659077\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.0052338214591145515\n",
      "Loss on test= 0.0061638024635612965\n",
      "acc for Lsat= 0.14411927029246188 \n",
      "acc for Psat= 0.17283453091336834 \n",
      "acc for optim= 0.161521043912145\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.0054887509904801846\n",
      "Loss on test= 0.006357417441904545\n",
      "acc for Lsat= 0.14326326738676576 \n",
      "acc for Psat= 0.1860912793354116 \n",
      "acc for optim= 0.16716837328782336\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.005628748796880245\n",
      "Loss on test= 0.005981657188385725\n",
      "acc for Lsat= 0.15432705051956516 \n",
      "acc for Psat= 0.1882535295496069 \n",
      "acc for optim= 0.1584506775414739\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.005402275361120701\n",
      "Loss on test= 0.0063822828233242035\n",
      "acc for Lsat= 0.14611830871549128 \n",
      "acc for Psat= 0.17881198575124754 \n",
      "acc for optim= 0.16510585928717475\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.005570315755903721\n",
      "Loss on test= 0.006285565439611673\n",
      "acc for Lsat= 0.1525796131624031 \n",
      "acc for Psat= 0.16996697289182147 \n",
      "acc for optim= 0.1537411581264946\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.005971649661660194\n",
      "Loss on test= 0.005865263752639294\n",
      "acc for Lsat= 0.14418900135301482 \n",
      "acc for Psat= 0.17704387311060288 \n",
      "acc for optim= 0.16078227536216547\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.005303294397890568\n",
      "Loss on test= 0.006020640954375267\n",
      "acc for Lsat= 0.15705637953656373 \n",
      "acc for Psat= 0.18061719672166604 \n",
      "acc for optim= 0.1604330032571509\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005178073421120644\n",
      "Loss on test= 0.006712097208946943\n",
      "acc for Lsat= 0.15880136203066614 \n",
      "acc for Psat= 0.17085966660057147 \n",
      "acc for optim= 0.1634386528873068\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.005457725375890732\n",
      "Loss on test= 0.006028247997164726\n",
      "acc for Lsat= 0.15247663768756464 \n",
      "acc for Psat= 0.1810994644023356 \n",
      "acc for optim= 0.168304600412423\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.005559024401009083\n",
      "Loss on test= 0.00612151063978672\n",
      "acc for Lsat= 0.1368306687183785 \n",
      "acc for Psat= 0.1709400470780789 \n",
      "acc for optim= 0.1668918512212914\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.005591476336121559\n",
      "Loss on test= 0.005991166923195124\n",
      "acc for Lsat= 0.14346371678569636 \n",
      "acc for Psat= 0.17749980476390967 \n",
      "acc for optim= 0.15992847653315784\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.005253002978861332\n",
      "Loss on test= 0.006164366379380226\n",
      "acc for Lsat= 0.14367892820422432 \n",
      "acc for Psat= 0.17997468782447615 \n",
      "acc for optim= 0.1574187812298063\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.005243013612926006\n",
      "Loss on test= 0.006013625767081976\n",
      "acc for Lsat= 0.14905995847580986 \n",
      "acc for Psat= 0.16963778515346348 \n",
      "acc for optim= 0.16268403573480786\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.005283630918711424\n",
      "Loss on test= 0.006479786243289709\n",
      "acc for Lsat= 0.14146590253613034 \n",
      "acc for Psat= 0.1926460007274906 \n",
      "acc for optim= 0.16812056944804307\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.005516808945685625\n",
      "Loss on test= 0.006044860929250717\n",
      "acc for Lsat= 0.14931823686833998 \n",
      "acc for Psat= 0.18449851446136162 \n",
      "acc for optim= 0.15998413189942065\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.0054267942905426025\n",
      "Loss on test= 0.005768459290266037\n",
      "acc for Lsat= 0.14354204188518943 \n",
      "acc for Psat= 0.17404366202893873 \n",
      "acc for optim= 0.16508940179206308\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.005263631697744131\n",
      "Loss on test= 0.005689286161214113\n",
      "acc for Lsat= 0.1552392373513001 \n",
      "acc for Psat= 0.17696966785082563 \n",
      "acc for optim= 0.16159421485451766\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.005408161785453558\n",
      "Loss on test= 0.006300800479948521\n",
      "acc for Lsat= 0.14631332969922786 \n",
      "acc for Psat= 0.17805861523976077 \n",
      "acc for optim= 0.16036721758728611\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.0056034172885119915\n",
      "Loss on test= 0.006070558913052082\n",
      "acc for Lsat= 0.1484015060050535 \n",
      "acc for Psat= 0.17018466485534475 \n",
      "acc for optim= 0.1692112328074338\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.005636173766106367\n",
      "Loss on test= 0.006113845854997635\n",
      "acc for Lsat= 0.13944160369927155 \n",
      "acc for Psat= 0.17861001287123235 \n",
      "acc for optim= 0.16273111478019062\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.005752488039433956\n",
      "Loss on test= 0.005703988019376993\n",
      "acc for Lsat= 0.14572207599718 \n",
      "acc for Psat= 0.19264405480105062 \n",
      "acc for optim= 0.16413569402123313\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.005413894075900316\n",
      "Loss on test= 0.005927184596657753\n",
      "acc for Lsat= 0.15238137811259653 \n",
      "acc for Psat= 0.17187624126405562 \n",
      "acc for optim= 0.1664879393386922\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.00618103938177228\n",
      "Loss on test= 0.006314245983958244\n",
      "acc for Lsat= 0.14834590231388814 \n",
      "acc for Psat= 0.16991235874682717 \n",
      "acc for optim= 0.1580338249551743\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.005719183944165707\n",
      "Loss on test= 0.006255042739212513\n",
      "acc for Lsat= 0.15296785369005864 \n",
      "acc for Psat= 0.16876883757649921 \n",
      "acc for optim= 0.15802896794515708\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005373550113290548\n",
      "Loss on test= 0.006101409904658794\n",
      "acc for Lsat= 0.15639396088434476 \n",
      "acc for Psat= 0.1822964302668745 \n",
      "acc for optim= 0.16345707646563465\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.0054740700870752335\n",
      "Loss on test= 0.006287151016294956\n",
      "acc for Lsat= 0.14400258832572974 \n",
      "acc for Psat= 0.15766223493107542 \n",
      "acc for optim= 0.1670994384256268\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.00534868985414505\n",
      "Loss on test= 0.006376265548169613\n",
      "acc for Lsat= 0.15263578931831556 \n",
      "acc for Psat= 0.1705509386288735 \n",
      "acc for optim= 0.17043071640087634\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.005576916038990021\n",
      "Loss on test= 0.00601533567532897\n",
      "acc for Lsat= 0.13703709258912627 \n",
      "acc for Psat= 0.174628359718691 \n",
      "acc for optim= 0.15602453309030187\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.005692452657967806\n",
      "Loss on test= 0.006003858987241983\n",
      "acc for Lsat= 0.16663293741551824 \n",
      "acc for Psat= 0.17519347536135235 \n",
      "acc for optim= 0.1672708792167288\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.005373896565288305\n",
      "Loss on test= 0.005938705988228321\n",
      "acc for Lsat= 0.16102840083796285 \n",
      "acc for Psat= 0.1874161014089086 \n",
      "acc for optim= 0.1656923163395478\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.005502729676663876\n",
      "Loss on test= 0.006012728903442621\n",
      "acc for Lsat= 0.14591717212389368 \n",
      "acc for Psat= 0.16770059151302746 \n",
      "acc for optim= 0.15871348513017616\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.005463344044983387\n",
      "Loss on test= 0.006116786506026983\n",
      "acc for Lsat= 0.14819848820129142 \n",
      "acc for Psat= 0.18037605737259643 \n",
      "acc for optim= 0.16390626399270183\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.005308317951858044\n",
      "Loss on test= 0.0058417534455657005\n",
      "acc for Lsat= 0.15171348262410306 \n",
      "acc for Psat= 0.17714150097358544 \n",
      "acc for optim= 0.16181886652092112\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.005840434692800045\n",
      "Loss on test= 0.0063251410610973835\n",
      "acc for Lsat= 0.13582081705542687 \n",
      "acc for Psat= 0.17047425526171373 \n",
      "acc for optim= 0.16486682531301727\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.005709459073841572\n",
      "Loss on test= 0.005986903328448534\n",
      "acc for Lsat= 0.14616061132172214 \n",
      "acc for Psat= 0.16839107368625084 \n",
      "acc for optim= 0.1642071257433167\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.0054657901637256145\n",
      "Loss on test= 0.0060319239273667336\n",
      "acc for Lsat= 0.15163525721176574 \n",
      "acc for Psat= 0.17658101046461705 \n",
      "acc for optim= 0.16561134151873927\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.006074998062103987\n",
      "Loss on test= 0.0061508771032094955\n",
      "acc for Lsat= 0.15417892799338662 \n",
      "acc for Psat= 0.18112888807797287 \n",
      "acc for optim= 0.16829922597275163\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.005540760233998299\n",
      "Loss on test= 0.006173484493046999\n",
      "acc for Lsat= 0.15362348777993934 \n",
      "acc for Psat= 0.16249624711469 \n",
      "acc for optim= 0.17017762973641243\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.005382188595831394\n",
      "Loss on test= 0.00594447972252965\n",
      "acc for Lsat= 0.15402687307901405 \n",
      "acc for Psat= 0.18631689101801116 \n",
      "acc for optim= 0.16385255591047426\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.005380160175263882\n",
      "Loss on test= 0.006040087901055813\n",
      "acc for Lsat= 0.15420563953211072 \n",
      "acc for Psat= 0.17344207923065444 \n",
      "acc for optim= 0.1699317719449087\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.005532091949135065\n",
      "Loss on test= 0.006143833044916391\n",
      "acc for Lsat= 0.15229490379283786 \n",
      "acc for Psat= 0.17529100401930084 \n",
      "acc for optim= 0.16583852300985305\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.005416209809482098\n",
      "Loss on test= 0.006369662471115589\n",
      "acc for Lsat= 0.13906881238914048 \n",
      "acc for Psat= 0.17540227677291412 \n",
      "acc for optim= 0.16422540951769735\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.005346666555851698\n",
      "Loss on test= 0.00609866576269269\n",
      "acc for Lsat= 0.1481140705586037 \n",
      "acc for Psat= 0.18044002542871462 \n",
      "acc for optim= 0.16400907744699325\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.005310039035975933\n",
      "Loss on test= 0.006357257254421711\n",
      "acc for Lsat= 0.14942770648459508 \n",
      "acc for Psat= 0.17229061380055444 \n",
      "acc for optim= 0.1626411785083426\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.005459086503833532\n",
      "Loss on test= 0.006062514614313841\n",
      "acc for Lsat= 0.15753127087277863 \n",
      "acc for Psat= 0.16944899554431178 \n",
      "acc for optim= 0.16687765221004602\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.00551203079521656\n",
      "Loss on test= 0.005767079070210457\n",
      "acc for Lsat= 0.15881411095496198 \n",
      "acc for Psat= 0.18661944810377404 \n",
      "acc for optim= 0.17161814773008685\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.005485144443809986\n",
      "Loss on test= 0.006057252176105976\n",
      "acc for Lsat= 0.15375138738223154 \n",
      "acc for Psat= 0.16974235477515678 \n",
      "acc for optim= 0.16774386422975573\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.005509971175342798\n",
      "Loss on test= 0.006001444533467293\n",
      "acc for Lsat= 0.14389871870979598 \n",
      "acc for Psat= 0.1775706078761761 \n",
      "acc for optim= 0.16552064348850495\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005395920015871525\n",
      "Loss on test= 0.006450654473155737\n",
      "acc for Lsat= 0.1542517466047401 \n",
      "acc for Psat= 0.18708969268816156 \n",
      "acc for optim= 0.1647245218521213\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.005599190481007099\n",
      "Loss on test= 0.005712512414902449\n",
      "acc for Lsat= 0.14169031901563686 \n",
      "acc for Psat= 0.18175176524196476 \n",
      "acc for optim= 0.16613180044233097\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.005534379743039608\n",
      "Loss on test= 0.0059952386654913425\n",
      "acc for Lsat= 0.14436647934823862 \n",
      "acc for Psat= 0.17429457526333386 \n",
      "acc for optim= 0.16422897424256871\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.005285775288939476\n",
      "Loss on test= 0.006009543314576149\n",
      "acc for Lsat= 0.14684898491651124 \n",
      "acc for Psat= 0.177387865630864 \n",
      "acc for optim= 0.16089477855158726\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.005483669228851795\n",
      "Loss on test= 0.005945668090134859\n",
      "acc for Lsat= 0.1474853699742511 \n",
      "acc for Psat= 0.18847854703040479 \n",
      "acc for optim= 0.16043197623011274\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.005495046731084585\n",
      "Loss on test= 0.00614184932783246\n",
      "acc for Lsat= 0.14022007572639267 \n",
      "acc for Psat= 0.18326623415160298 \n",
      "acc for optim= 0.16220440027212388\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.005551230162382126\n",
      "Loss on test= 0.005600418895483017\n",
      "acc for Lsat= 0.15842193062493548 \n",
      "acc for Psat= 0.1880833501795156 \n",
      "acc for optim= 0.16512136241825695\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.005363968200981617\n",
      "Loss on test= 0.005913188681006432\n",
      "acc for Lsat= 0.15319043208103528 \n",
      "acc for Psat= 0.18339263442297826 \n",
      "acc for optim= 0.16147335174099994\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.005192692391574383\n",
      "Loss on test= 0.006353617645800114\n",
      "acc for Lsat= 0.14881912201612454 \n",
      "acc for Psat= 0.17490535168374172 \n",
      "acc for optim= 0.15449690990661438\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.005742237437516451\n",
      "Loss on test= 0.005799487233161926\n",
      "acc for Lsat= 0.14570561182574507 \n",
      "acc for Psat= 0.16390332811718164 \n",
      "acc for optim= 0.16422019710050528\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.005428534001111984\n",
      "Loss on test= 0.006287242751568556\n",
      "acc for Lsat= 0.15153910968587303 \n",
      "acc for Psat= 0.17154939767053412 \n",
      "acc for optim= 0.1640710863695083\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.005390895996242762\n",
      "Loss on test= 0.006230365950614214\n",
      "acc for Lsat= 0.15649118195917672 \n",
      "acc for Psat= 0.19489103577297265 \n",
      "acc for optim= 0.16504781690257272\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.0056532202288508415\n",
      "Loss on test= 0.005901740863919258\n",
      "acc for Lsat= 0.15622407373787117 \n",
      "acc for Psat= 0.18068690861414996 \n",
      "acc for optim= 0.16403698485037388\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.005409492179751396\n",
      "Loss on test= 0.006134002935141325\n",
      "acc for Lsat= 0.15476091663414215 \n",
      "acc for Psat= 0.1769422136868358 \n",
      "acc for optim= 0.16563177605571805\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.005730469711124897\n",
      "Loss on test= 0.006397280376404524\n",
      "acc for Lsat= 0.143242002519329 \n",
      "acc for Psat= 0.17625321408306233 \n",
      "acc for optim= 0.16104997867206874\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.0054822051897645\n",
      "Loss on test= 0.0059106540866196156\n",
      "acc for Lsat= 0.15266046187397642 \n",
      "acc for Psat= 0.1738290275236664 \n",
      "acc for optim= 0.16694038877107173\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.006125836633145809\n",
      "Loss on test= 0.006005752831697464\n",
      "acc for Lsat= 0.1437874676197859 \n",
      "acc for Psat= 0.177603924067044 \n",
      "acc for optim= 0.15372507231082844\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.005780159495770931\n",
      "Loss on test= 0.006182259414345026\n",
      "acc for Lsat= 0.15445871739533776 \n",
      "acc for Psat= 0.18858978350309952 \n",
      "acc for optim= 0.16721399765591458\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.005417304113507271\n",
      "Loss on test= 0.006393889896571636\n",
      "acc for Lsat= 0.15270380482524176 \n",
      "acc for Psat= 0.18318197341818557 \n",
      "acc for optim= 0.16684750584335845\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.005413239821791649\n",
      "Loss on test= 0.006050359923392534\n",
      "acc for Lsat= 0.13696125079057042 \n",
      "acc for Psat= 0.1797019256775069 \n",
      "acc for optim= 0.16293575099944213\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.00540625024586916\n",
      "Loss on test= 0.00590467220172286\n",
      "acc for Lsat= 0.14924755334151818 \n",
      "acc for Psat= 0.1653116668868413 \n",
      "acc for optim= 0.1549690086716122\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.005389729514718056\n",
      "Loss on test= 0.006147862412035465\n",
      "acc for Lsat= 0.13829211391123072 \n",
      "acc for Psat= 0.18731748333475629 \n",
      "acc for optim= 0.1704517986386877\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.005537098739296198\n",
      "Loss on test= 0.006411726586520672\n",
      "acc for Lsat= 0.15201681450574248 \n",
      "acc for Psat= 0.1834147701238389 \n",
      "acc for optim= 0.16341192078410235\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.0052547818049788475\n",
      "Loss on test= 0.005876694340258837\n",
      "acc for Lsat= 0.15020228707151426 \n",
      "acc for Psat= 0.17234631340118645 \n",
      "acc for optim= 0.1536866057037708\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.005468382500112057\n",
      "Loss on test= 0.006406974978744984\n",
      "acc for Lsat= 0.15696466627881908 \n",
      "acc for Psat= 0.17949981237532664 \n",
      "acc for optim= 0.15925307133670163\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.005828919820487499\n",
      "Loss on test= 0.00612961919978261\n",
      "acc for Lsat= 0.14180820040160516 \n",
      "acc for Psat= 0.17232433330767682 \n",
      "acc for optim= 0.163707073760738\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.005351354368031025\n",
      "Loss on test= 0.006127091124653816\n",
      "acc for Lsat= 0.14180372398112043 \n",
      "acc for Psat= 0.16887415170704861 \n",
      "acc for optim= 0.1664869639861968\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.005512543488293886\n",
      "Loss on test= 0.006191948428750038\n",
      "acc for Lsat= 0.15009450653976317 \n",
      "acc for Psat= 0.17577380339470006 \n",
      "acc for optim= 0.15602324736709172\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.005267071072012186\n",
      "Loss on test= 0.0061272624880075455\n",
      "acc for Lsat= 0.14775956403800442 \n",
      "acc for Psat= 0.1828060064791152 \n",
      "acc for optim= 0.1634919893233197\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.005581563804298639\n",
      "Loss on test= 0.0060479408130049706\n",
      "acc for Lsat= 0.1377038861716502 \n",
      "acc for Psat= 0.18020916700966227 \n",
      "acc for optim= 0.1579158143176636\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.005435234867036343\n",
      "Loss on test= 0.00617605447769165\n",
      "acc for Lsat= 0.15422542501836403 \n",
      "acc for Psat= 0.16717455186423097 \n",
      "acc for optim= 0.16127223708055202\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005218152888119221\n",
      "Loss on test= 0.006137036718428135\n",
      "acc for Lsat= 0.1424662538284062 \n",
      "acc for Psat= 0.1844551633604512 \n",
      "acc for optim= 0.1624719905745492\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.00536722969263792\n",
      "Loss on test= 0.006139783188700676\n",
      "acc for Lsat= 0.1498811021328858 \n",
      "acc for Psat= 0.17693225077852476 \n",
      "acc for optim= 0.16538613774416755\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005638832226395607\n",
      "Loss on test= 0.006064942106604576\n",
      "acc for Lsat= 0.14850305745084236 \n",
      "acc for Psat= 0.1683301015262617 \n",
      "acc for optim= 0.16078944132199557\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.0053579253144562244\n",
      "Loss on test= 0.006036248058080673\n",
      "acc for Lsat= 0.1399608967249419 \n",
      "acc for Psat= 0.18332486657089875 \n",
      "acc for optim= 0.16437457621314175\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.005275341682136059\n",
      "Loss on test= 0.005840823519974947\n",
      "acc for Lsat= 0.15087469798192138 \n",
      "acc for Psat= 0.18533692984738231 \n",
      "acc for optim= 0.16025914365185243\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.005691113881766796\n",
      "Loss on test= 0.0060212197713553905\n",
      "acc for Lsat= 0.14805276626415673 \n",
      "acc for Psat= 0.18125391843677194 \n",
      "acc for optim= 0.17086751051304375\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.00557548925280571\n",
      "Loss on test= 0.006105317734181881\n",
      "acc for Lsat= 0.15178379558139388 \n",
      "acc for Psat= 0.18522798361459014 \n",
      "acc for optim= 0.1587259646555214\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.005301032681018114\n",
      "Loss on test= 0.006225975230336189\n",
      "acc for Lsat= 0.1577208679803021 \n",
      "acc for Psat= 0.16983640512993528 \n",
      "acc for optim= 0.15886552927397252\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.00551608856767416\n",
      "Loss on test= 0.006212600972503424\n",
      "acc for Lsat= 0.1455051514816272 \n",
      "acc for Psat= 0.17075119150008577 \n",
      "acc for optim= 0.1606710500638566\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005919171031564474\n",
      "Loss on test= 0.005946233868598938\n",
      "acc for Lsat= 0.14324611994136338 \n",
      "acc for Psat= 0.17203336193733926 \n",
      "acc for optim= 0.1683123498859235\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.00521502923220396\n",
      "Loss on test= 0.0058955042622983456\n",
      "acc for Lsat= 0.15933446325380812 \n",
      "acc for Psat= 0.19031578066842783 \n",
      "acc for optim= 0.1721562670127748\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.005840531550347805\n",
      "Loss on test= 0.006318802013993263\n",
      "acc for Lsat= 0.147008673964616 \n",
      "acc for Psat= 0.17609416995747168 \n",
      "acc for optim= 0.1663219134933048\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.005322092678397894\n",
      "Loss on test= 0.006004020571708679\n",
      "acc for Lsat= 0.164909437109075 \n",
      "acc for Psat= 0.19002273525755478 \n",
      "acc for optim= 0.16039793095274707\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.00529430340975523\n",
      "Loss on test= 0.006039140745997429\n",
      "acc for Lsat= 0.15930743522514573 \n",
      "acc for Psat= 0.1825608773210437 \n",
      "acc for optim= 0.15943265685085953\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.005287486128509045\n",
      "Loss on test= 0.005953214596956968\n",
      "acc for Lsat= 0.1399417957019769 \n",
      "acc for Psat= 0.16989158172614596 \n",
      "acc for optim= 0.16228588060475885\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.005422790069133043\n",
      "Loss on test= 0.006220824550837278\n",
      "acc for Lsat= 0.1574314329971666 \n",
      "acc for Psat= 0.18088853276872885 \n",
      "acc for optim= 0.165450264886785\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.0055104452185332775\n",
      "Loss on test= 0.006541210692375898\n",
      "acc for Lsat= 0.15651937306889135 \n",
      "acc for Psat= 0.1958073555484231 \n",
      "acc for optim= 0.16142687214477386\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.00612903805449605\n",
      "Loss on test= 0.00626938184723258\n",
      "acc for Lsat= 0.14788131789909295 \n",
      "acc for Psat= 0.1830720217127475 \n",
      "acc for optim= 0.16792600452403736\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005363657139241695\n",
      "Loss on test= 0.006102162413299084\n",
      "acc for Lsat= 0.14651712311286724 \n",
      "acc for Psat= 0.1764663554067 \n",
      "acc for optim= 0.16480358640651874\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.005377269349992275\n",
      "Loss on test= 0.006303731352090836\n",
      "acc for Lsat= 0.15236694389824434 \n",
      "acc for Psat= 0.18022844235338348 \n",
      "acc for optim= 0.159690137211325\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.0051979986019432545\n",
      "Loss on test= 0.0062522259540855885\n",
      "acc for Lsat= 0.15333826070657136 \n",
      "acc for Psat= 0.18244420919571164 \n",
      "acc for optim= 0.16612918749146285\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.005277223419398069\n",
      "Loss on test= 0.006049904506653547\n",
      "acc for Lsat= 0.14524565921026686 \n",
      "acc for Psat= 0.16818293091024225 \n",
      "acc for optim= 0.1649238385992949\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.0053145429119467735\n",
      "Loss on test= 0.006348338443785906\n",
      "acc for Lsat= 0.14889574540906264 \n",
      "acc for Psat= 0.17742727863579438 \n",
      "acc for optim= 0.1606478735195763\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.005542200990021229\n",
      "Loss on test= 0.0063125514425337315\n",
      "acc for Lsat= 0.15494101262015872 \n",
      "acc for Psat= 0.1704698516437631 \n",
      "acc for optim= 0.16617571177747345\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.005333501845598221\n",
      "Loss on test= 0.006003460381180048\n",
      "acc for Lsat= 0.1561725005805187 \n",
      "acc for Psat= 0.18183327635108937 \n",
      "acc for optim= 0.1631169558793772\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.00527002289891243\n",
      "Loss on test= 0.006152641493827105\n",
      "acc for Lsat= 0.14521549057814706 \n",
      "acc for Psat= 0.18102030800617316 \n",
      "acc for optim= 0.1628450702494163\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.005538367200642824\n",
      "Loss on test= 0.005916019901633263\n",
      "acc for Lsat= 0.14716415875018804 \n",
      "acc for Psat= 0.16977411911166349 \n",
      "acc for optim= 0.16724965497603272\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.005286876577883959\n",
      "Loss on test= 0.00626435037702322\n",
      "acc for Lsat= 0.15204313129194263 \n",
      "acc for Psat= 0.18219325294876548 \n",
      "acc for optim= 0.1690741231296685\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.005698684137314558\n",
      "Loss on test= 0.0062707397155463696\n",
      "acc for Lsat= 0.15210003599644714 \n",
      "acc for Psat= 0.19185781198941157 \n",
      "acc for optim= 0.16641923006610623\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.005973748862743378\n",
      "Loss on test= 0.005919365677982569\n",
      "acc for Lsat= 0.15377197672696938 \n",
      "acc for Psat= 0.16371273634857242 \n",
      "acc for optim= 0.1638724438504499\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.005245039705187082\n",
      "Loss on test= 0.006219509057700634\n",
      "acc for Lsat= 0.15834992281843518 \n",
      "acc for Psat= 0.18991888669304183 \n",
      "acc for optim= 0.16680486189911417\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.005429795943200588\n",
      "Loss on test= 0.0059141372330486774\n",
      "acc for Lsat= 0.1503700367746742 \n",
      "acc for Psat= 0.17091989913405697 \n",
      "acc for optim= 0.16481570631654963\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.005382544361054897\n",
      "Loss on test= 0.0059166233986616135\n",
      "acc for Lsat= 0.14670370134375188 \n",
      "acc for Psat= 0.18245994029857684 \n",
      "acc for optim= 0.16477119407299753\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.0054478719830513\n",
      "Loss on test= 0.006054465658962727\n",
      "acc for Lsat= 0.14213675416005989 \n",
      "acc for Psat= 0.1692354226881852 \n",
      "acc for optim= 0.16001248670986198\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.0055729905143380165\n",
      "Loss on test= 0.006277302745729685\n",
      "acc for Lsat= 0.1360018323200419 \n",
      "acc for Psat= 0.16589145573031647 \n",
      "acc for optim= 0.16389360623968552\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.005166737828403711\n",
      "Loss on test= 0.005995077546685934\n",
      "acc for Lsat= 0.1528120840098098 \n",
      "acc for Psat= 0.17578436468582845 \n",
      "acc for optim= 0.17383603636560901\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.005498786456882954\n",
      "Loss on test= 0.006315557286143303\n",
      "acc for Lsat= 0.1463813961605679 \n",
      "acc for Psat= 0.17533900979295616 \n",
      "acc for optim= 0.16650335946035397\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005486697889864445\n",
      "Loss on test= 0.006364812143146992\n",
      "acc for Lsat= 0.14608468271560057 \n",
      "acc for Psat= 0.18412046678379546 \n",
      "acc for optim= 0.16851051687797317\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.0054778349585831165\n",
      "Loss on test= 0.006107057444751263\n",
      "acc for Lsat= 0.1533132092058697 \n",
      "acc for Psat= 0.18926327053698916 \n",
      "acc for optim= 0.16217446056116835\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.005869845859706402\n",
      "Loss on test= 0.006384273990988731\n",
      "acc for Lsat= 0.15580578392016564 \n",
      "acc for Psat= 0.17858769808834815 \n",
      "acc for optim= 0.16190596924957315\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.0053779869340360165\n",
      "Loss on test= 0.006413627881556749\n",
      "acc for Lsat= 0.14824095493235975 \n",
      "acc for Psat= 0.17682919010832968 \n",
      "acc for optim= 0.16482455211130476\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.005612294189631939\n",
      "Loss on test= 0.006268984172493219\n",
      "acc for Lsat= 0.15248009049150898 \n",
      "acc for Psat= 0.1709749859539204 \n",
      "acc for optim= 0.15960901059901159\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.00532465660944581\n",
      "Loss on test= 0.005825013387948275\n",
      "acc for Lsat= 0.15545643780735457 \n",
      "acc for Psat= 0.1540969237666119 \n",
      "acc for optim= 0.16676647360970984\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.005321240518242121\n",
      "Loss on test= 0.006266333628445864\n",
      "acc for Lsat= 0.1451836514466091 \n",
      "acc for Psat= 0.18243787810244583 \n",
      "acc for optim= 0.16211069104582315\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.005752301309257746\n",
      "Loss on test= 0.006449293345212936\n",
      "acc for Lsat= 0.1584371818502464 \n",
      "acc for Psat= 0.17814689350083515 \n",
      "acc for optim= 0.16256103115068027\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.005287581123411655\n",
      "Loss on test= 0.006116362288594246\n",
      "acc for Lsat= 0.1527079776381753 \n",
      "acc for Psat= 0.1834088480838605 \n",
      "acc for optim= 0.1631588779758666\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.005473500583320856\n",
      "Loss on test= 0.006299618165940046\n",
      "acc for Lsat= 0.14860192625897892 \n",
      "acc for Psat= 0.17860988390051805 \n",
      "acc for optim= 0.16833614941999378\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.005800365004688501\n",
      "Loss on test= 0.005970877129584551\n",
      "acc for Lsat= 0.1464998090463179 \n",
      "acc for Psat= 0.18265008366099925 \n",
      "acc for optim= 0.17133409364614635\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.0056591578759253025\n",
      "Loss on test= 0.0060996972024440765\n",
      "acc for Lsat= 0.1656758610369088 \n",
      "acc for Psat= 0.17318547104254411 \n",
      "acc for optim= 0.16888960271455408\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.005687280558049679\n",
      "Loss on test= 0.006052025128155947\n",
      "acc for Lsat= 0.15569903165451252 \n",
      "acc for Psat= 0.1742642183309339 \n",
      "acc for optim= 0.16872392328089622\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005241082515567541\n",
      "Loss on test= 0.006144626997411251\n",
      "acc for Lsat= 0.15204202566061123 \n",
      "acc for Psat= 0.1868362540713145 \n",
      "acc for optim= 0.16430671953817555\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.005408020224422216\n",
      "Loss on test= 0.005795649718493223\n",
      "acc for Lsat= 0.14342076473193793 \n",
      "acc for Psat= 0.1781526380165129 \n",
      "acc for optim= 0.1677858995136301\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.005500706844031811\n",
      "Loss on test= 0.00603764271363616\n",
      "acc for Lsat= 0.1482279889594733 \n",
      "acc for Psat= 0.19346819549850733 \n",
      "acc for optim= 0.15759933749003885\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.005408517550677061\n",
      "Loss on test= 0.005880035925656557\n",
      "acc for Lsat= 0.14688503714077952 \n",
      "acc for Psat= 0.18168568895246115 \n",
      "acc for optim= 0.1594635257421092\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.005724240560084581\n",
      "Loss on test= 0.0060738190077245235\n",
      "acc for Lsat= 0.14888411939571627 \n",
      "acc for Psat= 0.16646705880890206 \n",
      "acc for optim= 0.1711220869534939\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.005557692144066095\n",
      "Loss on test= 0.006253927946090698\n",
      "acc for Lsat= 0.1430655278414335 \n",
      "acc for Psat= 0.17853375007780117 \n",
      "acc for optim= 0.15759215376260652\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.005450277589261532\n",
      "Loss on test= 0.006222971715033054\n",
      "acc for Lsat= 0.1431398196848201 \n",
      "acc for Psat= 0.1781072059241658 \n",
      "acc for optim= 0.1646392043647509\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.005244974512606859\n",
      "Loss on test= 0.006144626997411251\n",
      "acc for Lsat= 0.15644565617654196 \n",
      "acc for Psat= 0.18072125273374992 \n",
      "acc for optim= 0.16197573162680187\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.005496928934007883\n",
      "Loss on test= 0.006029049400240183\n",
      "acc for Lsat= 0.15736379976172982 \n",
      "acc for Psat= 0.16799178889687325 \n",
      "acc for optim= 0.16565654689711365\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.005243540275841951\n",
      "Loss on test= 0.006017705425620079\n",
      "acc for Lsat= 0.16096944405094216 \n",
      "acc for Psat= 0.17995526962073854 \n",
      "acc for optim= 0.16177409857828323\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.005680843256413937\n",
      "Loss on test= 0.0059682209976017475\n",
      "acc for Lsat= 0.1575459851088006 \n",
      "acc for Psat= 0.1743847833161021 \n",
      "acc for optim= 0.16218988772817566\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.005437380634248257\n",
      "Loss on test= 0.006188225466758013\n",
      "acc for Lsat= 0.14344277550794612 \n",
      "acc for Psat= 0.17112529118522452 \n",
      "acc for optim= 0.16158391426214339\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.005480861756950617\n",
      "Loss on test= 0.00646183593198657\n",
      "acc for Lsat= 0.15402206891640013 \n",
      "acc for Psat= 0.17229426213555404 \n",
      "acc for optim= 0.1656310190762523\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.005358278285712004\n",
      "Loss on test= 0.006107169669121504\n",
      "acc for Lsat= 0.15135751135230302 \n",
      "acc for Psat= 0.1869642552996978 \n",
      "acc for optim= 0.17167941904359604\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005380935501307249\n",
      "Loss on test= 0.005785346496850252\n",
      "acc for Lsat= 0.15642228715873674 \n",
      "acc for Psat= 0.1829835494536502 \n",
      "acc for optim= 0.16449495503434636\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.005690006073564291\n",
      "Loss on test= 0.005920545198023319\n",
      "acc for Lsat= 0.15402445713073382 \n",
      "acc for Psat= 0.177421244981004 \n",
      "acc for optim= 0.1640740203755129\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.005321468226611614\n",
      "Loss on test= 0.0062329755164682865\n",
      "acc for Lsat= 0.15255881063778481 \n",
      "acc for Psat= 0.1832927743384479 \n",
      "acc for optim= 0.16265780399801577\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005358506925404072\n",
      "Loss on test= 0.006003034301102161\n",
      "acc for Lsat= 0.14992016215644563 \n",
      "acc for Psat= 0.18321059962436861 \n",
      "acc for optim= 0.1710088782218575\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005485947243869305\n",
      "Loss on test= 0.005945947952568531\n",
      "acc for Lsat= 0.13387932525661422 \n",
      "acc for Psat= 0.18323714487124845 \n",
      "acc for optim= 0.16298682199062048\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.005661816336214542\n",
      "Loss on test= 0.006130036432296038\n",
      "acc for Lsat= 0.1567851200290444 \n",
      "acc for Psat= 0.1808493109868427 \n",
      "acc for optim= 0.16610200117708596\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.005308843217790127\n",
      "Loss on test= 0.006371231749653816\n",
      "acc for Lsat= 0.13610678581486563 \n",
      "acc for Psat= 0.17371877097719365 \n",
      "acc for optim= 0.16463208369544294\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.00530963484197855\n",
      "Loss on test= 0.006028896663337946\n",
      "acc for Lsat= 0.15598097414591303 \n",
      "acc for Psat= 0.17857723274214773 \n",
      "acc for optim= 0.16266909983709502\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.005313252564519644\n",
      "Loss on test= 0.006138339638710022\n",
      "acc for Lsat= 0.14818331711430802 \n",
      "acc for Psat= 0.1759258701053799 \n",
      "acc for optim= 0.15710682147459248\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.005748762749135494\n",
      "Loss on test= 0.006011133082211018\n",
      "acc for Lsat= 0.13334296963418085 \n",
      "acc for Psat= 0.16718029713479526 \n",
      "acc for optim= 0.16629646854822477\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005649439059197903\n",
      "Loss on test= 0.006216414272785187\n",
      "acc for Lsat= 0.1488733433174603 \n",
      "acc for Psat= 0.18038530354025453 \n",
      "acc for optim= 0.16024772211943647\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.00575875211507082\n",
      "Loss on test= 0.006102902349084616\n",
      "acc for Lsat= 0.15298883494638102 \n",
      "acc for Psat= 0.1829278302661403 \n",
      "acc for optim= 0.16308827913854343\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.005497452802956104\n",
      "Loss on test= 0.00645022327080369\n",
      "acc for Lsat= 0.15078622387148646 \n",
      "acc for Psat= 0.1763147444560643 \n",
      "acc for optim= 0.15854359565457313\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.0052933478727936745\n",
      "Loss on test= 0.005988528020679951\n",
      "acc for Lsat= 0.16476868430131542 \n",
      "acc for Psat= 0.179303229853633 \n",
      "acc for optim= 0.16176681282861372\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.005243453662842512\n",
      "Loss on test= 0.006290777586400509\n",
      "acc for Lsat= 0.1462620876182718 \n",
      "acc for Psat= 0.1800835254592592 \n",
      "acc for optim= 0.15992761814785972\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.005842737853527069\n",
      "Loss on test= 0.006371625233441591\n",
      "acc for Lsat= 0.16536995934152623 \n",
      "acc for Psat= 0.17991021966683815 \n",
      "acc for optim= 0.1552348688050158\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.005624765995889902\n",
      "Loss on test= 0.005803784355521202\n",
      "acc for Lsat= 0.1419129384067062 \n",
      "acc for Psat= 0.18693249602367926 \n",
      "acc for optim= 0.15602703529775533\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.005224596709012985\n",
      "Loss on test= 0.00592578062787652\n",
      "acc for Lsat= 0.15306034619658976 \n",
      "acc for Psat= 0.17478104072659215 \n",
      "acc for optim= 0.1678515677182166\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.005377642810344696\n",
      "Loss on test= 0.006159897893667221\n",
      "acc for Lsat= 0.15268623226513198 \n",
      "acc for Psat= 0.18175054723077233 \n",
      "acc for optim= 0.1730341584197929\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.005255230702459812\n",
      "Loss on test= 0.006201598327606916\n",
      "acc for Lsat= 0.14678526571808673 \n",
      "acc for Psat= 0.17335770051395827 \n",
      "acc for optim= 0.1612060209803978\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.005381764844059944\n",
      "Loss on test= 0.0063295913860201836\n",
      "acc for Lsat= 0.1454568364842581 \n",
      "acc for Psat= 0.1726835976223095 \n",
      "acc for optim= 0.1660172685969346\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.005335630849003792\n",
      "Loss on test= 0.006043615285307169\n",
      "acc for Lsat= 0.14622399254781232 \n",
      "acc for Psat= 0.18510560118593275 \n",
      "acc for optim= 0.1581875454293293\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.005480026360601187\n",
      "Loss on test= 0.006158938631415367\n",
      "acc for Lsat= 0.14465271646324374 \n",
      "acc for Psat= 0.2003565286362513 \n",
      "acc for optim= 0.16306183830096355\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.005404378287494183\n",
      "Loss on test= 0.006213185843080282\n",
      "acc for Lsat= 0.15110826596756538 \n",
      "acc for Psat= 0.18026979447220315 \n",
      "acc for optim= 0.1677643204996263\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.005936279892921448\n",
      "Loss on test= 0.006127341650426388\n",
      "acc for Lsat= 0.15785869817253295 \n",
      "acc for Psat= 0.18085523673608045 \n",
      "acc for optim= 0.16076950775841098\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.005491944961249828\n",
      "Loss on test= 0.0063194637186825275\n",
      "acc for Lsat= 0.14750359903860716 \n",
      "acc for Psat= 0.17600446801778638 \n",
      "acc for optim= 0.15910524353961383\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005519428290426731\n",
      "Loss on test= 0.006198685150593519\n",
      "acc for Lsat= 0.15829578834293853 \n",
      "acc for Psat= 0.1694510140941005 \n",
      "acc for optim= 0.16414379292286047\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.005498815793544054\n",
      "Loss on test= 0.006104545202106237\n",
      "acc for Lsat= 0.15724124607160594 \n",
      "acc for Psat= 0.177232097615068 \n",
      "acc for optim= 0.17013235918673703\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.005352905951440334\n",
      "Loss on test= 0.0058999876491725445\n",
      "acc for Lsat= 0.13101837783021333 \n",
      "acc for Psat= 0.17253087709970832 \n",
      "acc for optim= 0.1733767613007107\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.005379049573093653\n",
      "Loss on test= 0.006414202973246574\n",
      "acc for Lsat= 0.154991210879258 \n",
      "acc for Psat= 0.19400336470099006 \n",
      "acc for optim= 0.16059008496831367\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.005376891233026981\n",
      "Loss on test= 0.006055026780813932\n",
      "acc for Lsat= 0.15862277015560824 \n",
      "acc for Psat= 0.17915252568429244 \n",
      "acc for optim= 0.16112866558718542\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.005304940510541201\n",
      "Loss on test= 0.006321032531559467\n",
      "acc for Lsat= 0.14631113623587136 \n",
      "acc for Psat= 0.17266446001041436 \n",
      "acc for optim= 0.16569922972016313\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.005519901402294636\n",
      "Loss on test= 0.006502372212707996\n",
      "acc for Lsat= 0.14559784692790376 \n",
      "acc for Psat= 0.17878860430791974 \n",
      "acc for optim= 0.16484752309710918\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.005376082845032215\n",
      "Loss on test= 0.0060049546882510185\n",
      "acc for Lsat= 0.1475346163770453 \n",
      "acc for Psat= 0.18166637595010096 \n",
      "acc for optim= 0.16440324396940834\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.005444730632007122\n",
      "Loss on test= 0.006453216075897217\n",
      "acc for Lsat= 0.14978297703525387 \n",
      "acc for Psat= 0.1748652720559564 \n",
      "acc for optim= 0.16818551748922309\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.005549202207475901\n",
      "Loss on test= 0.006183244753628969\n",
      "acc for Lsat= 0.15794546972868628 \n",
      "acc for Psat= 0.1811424416571008 \n",
      "acc for optim= 0.1674613332277599\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.005363729782402515\n",
      "Loss on test= 0.006194395944476128\n",
      "acc for Lsat= 0.1442429764952022 \n",
      "acc for Psat= 0.1809659782497472 \n",
      "acc for optim= 0.15953388383754455\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.005317172966897488\n",
      "Loss on test= 0.005940172355622053\n",
      "acc for Lsat= 0.16482848333133782 \n",
      "acc for Psat= 0.17846777562269575 \n",
      "acc for optim= 0.16098905813586364\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.005337197333574295\n",
      "Loss on test= 0.006251975428313017\n",
      "acc for Lsat= 0.15398986216894062 \n",
      "acc for Psat= 0.17923466833346507 \n",
      "acc for optim= 0.1667853276952376\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.0054413373582065105\n",
      "Loss on test= 0.0061128027737140656\n",
      "acc for Lsat= 0.14463173889967262 \n",
      "acc for Psat= 0.19433956615642078 \n",
      "acc for optim= 0.17034056382082005\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.0060202935710549355\n",
      "Loss on test= 0.006159628741443157\n",
      "acc for Lsat= 0.1523228175232779 \n",
      "acc for Psat= 0.17876143146565826 \n",
      "acc for optim= 0.17155795228887863\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.005378834903240204\n",
      "Loss on test= 0.005870904307812452\n",
      "acc for Lsat= 0.1481026424637034 \n",
      "acc for Psat= 0.1820691491347417 \n",
      "acc for optim= 0.16448756177436377\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.005477129947394133\n",
      "Loss on test= 0.006337928120046854\n",
      "acc for Lsat= 0.14444030591393592 \n",
      "acc for Psat= 0.17805426643677552 \n",
      "acc for optim= 0.16492415869600888\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.005543939303606749\n",
      "Loss on test= 0.006302754394710064\n",
      "acc for Lsat= 0.14877637339866584 \n",
      "acc for Psat= 0.17304441729888748 \n",
      "acc for optim= 0.16857752058904077\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.005181916989386082\n",
      "Loss on test= 0.0061602164059877396\n",
      "acc for Lsat= 0.14431023427588696 \n",
      "acc for Psat= 0.1719065186876773 \n",
      "acc for optim= 0.16707770687844756\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.005520060658454895\n",
      "Loss on test= 0.006182421930134296\n",
      "acc for Lsat= 0.14380720090808072 \n",
      "acc for Psat= 0.18276323325126662 \n",
      "acc for optim= 0.16954221558980415\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.005305274855345488\n",
      "Loss on test= 0.006027859635651112\n",
      "acc for Lsat= 0.15325606066369085 \n",
      "acc for Psat= 0.18636693577266625 \n",
      "acc for optim= 0.1615173435875894\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.005283770617097616\n",
      "Loss on test= 0.00632863724604249\n",
      "acc for Lsat= 0.14992892373473476 \n",
      "acc for Psat= 0.1778039769908379 \n",
      "acc for optim= 0.17233533735189502\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005423909984529018\n",
      "Loss on test= 0.006206389982253313\n",
      "acc for Lsat= 0.1381313996156439 \n",
      "acc for Psat= 0.17430192758205162 \n",
      "acc for optim= 0.16869781568262832\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.005423297174274921\n",
      "Loss on test= 0.006145821418613195\n",
      "acc for Lsat= 0.15002062054251733 \n",
      "acc for Psat= 0.16562761019802744 \n",
      "acc for optim= 0.16981150195819372\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.005240324884653091\n",
      "Loss on test= 0.005784463137388229\n",
      "acc for Lsat= 0.1529642212822018 \n",
      "acc for Psat= 0.18568882524402294 \n",
      "acc for optim= 0.16454731184954863\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.005486371926963329\n",
      "Loss on test= 0.005959417670965195\n",
      "acc for Lsat= 0.1521591101099878 \n",
      "acc for Psat= 0.1894305360930987 \n",
      "acc for optim= 0.15946768840214764\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.005434122867882252\n",
      "Loss on test= 0.0061974297277629375\n",
      "acc for Lsat= 0.1457804090847246 \n",
      "acc for Psat= 0.17149402092413243 \n",
      "acc for optim= 0.1625497989145873\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.005357051268219948\n",
      "Loss on test= 0.006124948617070913\n",
      "acc for Lsat= 0.15787322495073522 \n",
      "acc for Psat= 0.19127215834746716 \n",
      "acc for optim= 0.16128027429315167\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.005529796704649925\n",
      "Loss on test= 0.006413465831428766\n",
      "acc for Lsat= 0.14657409819163628 \n",
      "acc for Psat= 0.1845827856200335 \n",
      "acc for optim= 0.16186618506388364\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.005478518549352884\n",
      "Loss on test= 0.0057669091038405895\n",
      "acc for Lsat= 0.147169431558043 \n",
      "acc for Psat= 0.16948482382290644 \n",
      "acc for optim= 0.15971150130709083\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.005118964239954948\n",
      "Loss on test= 0.006148067768663168\n",
      "acc for Lsat= 0.1472678564971725 \n",
      "acc for Psat= 0.17941491146358188 \n",
      "acc for optim= 0.15932248233909124\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.005416926462203264\n",
      "Loss on test= 0.0057542757131159306\n",
      "acc for Lsat= 0.14529304361337278 \n",
      "acc for Psat= 0.1825635281708244 \n",
      "acc for optim= 0.16302429275800948\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.005448946263641119\n",
      "Loss on test= 0.0062124645337462425\n",
      "acc for Lsat= 0.14584230216311628 \n",
      "acc for Psat= 0.1816826501853581 \n",
      "acc for optim= 0.1640455658112454\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.005449445452541113\n",
      "Loss on test= 0.006076174788177013\n",
      "acc for Lsat= 0.1383410418483421 \n",
      "acc for Psat= 0.1755617167240416 \n",
      "acc for optim= 0.16411520814958228\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.0052757118828594685\n",
      "Loss on test= 0.005961722694337368\n",
      "acc for Lsat= 0.1566494393544119 \n",
      "acc for Psat= 0.19403604781465056 \n",
      "acc for optim= 0.16247115555433098\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005343467928469181\n",
      "Loss on test= 0.006044155452400446\n",
      "acc for Lsat= 0.14448879152940983 \n",
      "acc for Psat= 0.16845220004859165 \n",
      "acc for optim= 0.16273816118558837\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005185937508940697\n",
      "Loss on test= 0.006422301754355431\n",
      "acc for Lsat= 0.1539943403404084 \n",
      "acc for Psat= 0.17198412032439145 \n",
      "acc for optim= 0.16599924462106933\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.005420762114226818\n",
      "Loss on test= 0.0060291108675301075\n",
      "acc for Lsat= 0.14896587996188262 \n",
      "acc for Psat= 0.18587890413711916 \n",
      "acc for optim= 0.16489051016463638\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.00543421832844615\n",
      "Loss on test= 0.00642921170219779\n",
      "acc for Lsat= 0.15795482146881948 \n",
      "acc for Psat= 0.18317910275559446 \n",
      "acc for optim= 0.16460455345318148\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.006060535088181496\n",
      "Loss on test= 0.006284416653215885\n",
      "acc for Lsat= 0.1532937742846056 \n",
      "acc for Psat= 0.1925778502657567 \n",
      "acc for optim= 0.16090224438764872\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.005224389955401421\n",
      "Loss on test= 0.00613747164607048\n",
      "acc for Lsat= 0.1549087717503664 \n",
      "acc for Psat= 0.17938403891996846 \n",
      "acc for optim= 0.17142263832616575\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.00530045572668314\n",
      "Loss on test= 0.006514520384371281\n",
      "acc for Lsat= 0.1516712389378732 \n",
      "acc for Psat= 0.178649578952387 \n",
      "acc for optim= 0.16287188142567652\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.005573251750320196\n",
      "Loss on test= 0.006281645502895117\n",
      "acc for Lsat= 0.1546543801898045 \n",
      "acc for Psat= 0.17453231702751448 \n",
      "acc for optim= 0.17010021365121708\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.005777117796242237\n",
      "Loss on test= 0.006003168877214193\n",
      "acc for Lsat= 0.15233753389248542 \n",
      "acc for Psat= 0.1718038299212568 \n",
      "acc for optim= 0.1578571069209844\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.005281378515064716\n",
      "Loss on test= 0.006113503593951464\n",
      "acc for Lsat= 0.15487110305073687 \n",
      "acc for Psat= 0.1815693484833006 \n",
      "acc for optim= 0.15807276458847316\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005272681824862957\n",
      "Loss on test= 0.005949938669800758\n",
      "acc for Lsat= 0.1404781594754151 \n",
      "acc for Psat= 0.1799517826936742 \n",
      "acc for optim= 0.16561027696634334\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.005522856023162603\n",
      "Loss on test= 0.006113991141319275\n",
      "acc for Lsat= 0.14509594930544856 \n",
      "acc for Psat= 0.1670278024411241 \n",
      "acc for optim= 0.16903411732293802\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.005857863929122686\n",
      "Loss on test= 0.005951553117483854\n",
      "acc for Lsat= 0.13944588425409643 \n",
      "acc for Psat= 0.15738173589972992 \n",
      "acc for optim= 0.1671052348422131\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.005416862200945616\n",
      "Loss on test= 0.006156362593173981\n",
      "acc for Lsat= 0.14988294134802016 \n",
      "acc for Psat= 0.1729049237296138 \n",
      "acc for optim= 0.163983201620085\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.0055459472350776196\n",
      "Loss on test= 0.006450601853430271\n",
      "acc for Lsat= 0.14857046144067876 \n",
      "acc for Psat= 0.16999322154414154 \n",
      "acc for optim= 0.16816251618886885\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.005430570803582668\n",
      "Loss on test= 0.005859872326254845\n",
      "acc for Lsat= 0.14457250500220012 \n",
      "acc for Psat= 0.17795947454068198 \n",
      "acc for optim= 0.17018136005632992\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.005716654472053051\n",
      "Loss on test= 0.005931758787482977\n",
      "acc for Lsat= 0.15631569536296902 \n",
      "acc for Psat= 0.17904472345449068 \n",
      "acc for optim= 0.1678524425484194\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.005755469668656588\n",
      "Loss on test= 0.006217451766133308\n",
      "acc for Lsat= 0.1497285515732193 \n",
      "acc for Psat= 0.18658086425237372 \n",
      "acc for optim= 0.16425821936830542\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.005691299214959145\n",
      "Loss on test= 0.006447989493608475\n",
      "acc for Lsat= 0.15842425051893366 \n",
      "acc for Psat= 0.18468480355178576 \n",
      "acc for optim= 0.17246545247960698\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.005461362190544605\n",
      "Loss on test= 0.006011246237903833\n",
      "acc for Lsat= 0.15143870162304307 \n",
      "acc for Psat= 0.18396657507505923 \n",
      "acc for optim= 0.15826091087407998\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.005309650674462318\n",
      "Loss on test= 0.0063328868709504604\n",
      "acc for Lsat= 0.14956813458368548 \n",
      "acc for Psat= 0.19149062461296065 \n",
      "acc for optim= 0.16557136328516864\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.005341500509530306\n",
      "Loss on test= 0.006226323079317808\n",
      "acc for Lsat= 0.14989496896417476 \n",
      "acc for Psat= 0.18670014797298493 \n",
      "acc for optim= 0.16009925338432487\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.0055889892391860485\n",
      "Loss on test= 0.005703907925635576\n",
      "acc for Lsat= 0.1427477718915859 \n",
      "acc for Psat= 0.18687647575069768 \n",
      "acc for optim= 0.16213613990393705\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.005327305756509304\n",
      "Loss on test= 0.006099071819335222\n",
      "acc for Lsat= 0.1578953217642504 \n",
      "acc for Psat= 0.18710947714433013 \n",
      "acc for optim= 0.17019843724668388\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.00526741286739707\n",
      "Loss on test= 0.006124355364590883\n",
      "acc for Lsat= 0.15109294766835013 \n",
      "acc for Psat= 0.18689520986255478 \n",
      "acc for optim= 0.16805243179942558\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.005415494553744793\n",
      "Loss on test= 0.006158197298645973\n",
      "acc for Lsat= 0.15522014353086516 \n",
      "acc for Psat= 0.17439812342947603 \n",
      "acc for optim= 0.16378089710502297\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.005402152892202139\n",
      "Loss on test= 0.005973375868052244\n",
      "acc for Lsat= 0.14766055229539815 \n",
      "acc for Psat= 0.1783193235480719 \n",
      "acc for optim= 0.16342112742799533\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.00528298644348979\n",
      "Loss on test= 0.005926451180130243\n",
      "acc for Lsat= 0.15327895606455744 \n",
      "acc for Psat= 0.17605623736649323 \n",
      "acc for optim= 0.16445386977207876\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.005320011638104916\n",
      "Loss on test= 0.006287934724241495\n",
      "acc for Lsat= 0.1531162102070263 \n",
      "acc for Psat= 0.17914628656981818 \n",
      "acc for optim= 0.16325622888312477\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.00549360690638423\n",
      "Loss on test= 0.0061246538534760475\n",
      "acc for Lsat= 0.14836679568321476 \n",
      "acc for Psat= 0.18040102777647649 \n",
      "acc for optim= 0.1626092826411296\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.005225096829235554\n",
      "Loss on test= 0.006352516822516918\n",
      "acc for Lsat= 0.14769868166872957 \n",
      "acc for Psat= 0.18161708356041584 \n",
      "acc for optim= 0.16239317623425092\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.005267196334898472\n",
      "Loss on test= 0.005967059172689915\n",
      "acc for Lsat= 0.14226746747735888 \n",
      "acc for Psat= 0.16536016932585598 \n",
      "acc for optim= 0.1612539448703307\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.005372035317122936\n",
      "Loss on test= 0.005878740455955267\n",
      "acc for Lsat= 0.1544837458405575 \n",
      "acc for Psat= 0.1993038194379044 \n",
      "acc for optim= 0.1668439410067236\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.005298036616295576\n",
      "Loss on test= 0.005859267897903919\n",
      "acc for Lsat= 0.15754873407088588 \n",
      "acc for Psat= 0.16785694938095774 \n",
      "acc for optim= 0.17160781448684084\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.0053964280523359776\n",
      "Loss on test= 0.006265018600970507\n",
      "acc for Lsat= 0.148937591978303 \n",
      "acc for Psat= 0.17732455822204757 \n",
      "acc for optim= 0.16811948269548382\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005355433095246553\n",
      "Loss on test= 0.006216937676072121\n",
      "acc for Lsat= 0.1438121588314792 \n",
      "acc for Psat= 0.17155199881078156 \n",
      "acc for optim= 0.16477550193285723\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.00550538394600153\n",
      "Loss on test= 0.006289346609264612\n",
      "acc for Lsat= 0.15018473934934695 \n",
      "acc for Psat= 0.17643024266743268 \n",
      "acc for optim= 0.15517013722784498\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.0056093605235219\n",
      "Loss on test= 0.006143718492239714\n",
      "acc for Lsat= 0.1523723175111761 \n",
      "acc for Psat= 0.17632874084830277 \n",
      "acc for optim= 0.16762866413702168\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.005848459899425507\n",
      "Loss on test= 0.006096025463193655\n",
      "acc for Lsat= 0.1576266317887396 \n",
      "acc for Psat= 0.17743370698785912 \n",
      "acc for optim= 0.16640890584876913\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.005673610605299473\n",
      "Loss on test= 0.005808129906654358\n",
      "acc for Lsat= 0.15901046676301686 \n",
      "acc for Psat= 0.18286191181997297 \n",
      "acc for optim= 0.1666673471208387\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.005324637982994318\n",
      "Loss on test= 0.00639319745823741\n",
      "acc for Lsat= 0.1465682903968836 \n",
      "acc for Psat= 0.1709167286440669 \n",
      "acc for optim= 0.16789715736689328\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.00537471566349268\n",
      "Loss on test= 0.005994732491672039\n",
      "acc for Lsat= 0.146291242344887 \n",
      "acc for Psat= 0.17644319929961177 \n",
      "acc for optim= 0.1642202971090914\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.005910701118409634\n",
      "Loss on test= 0.006201498676091433\n",
      "acc for Lsat= 0.14676632875439208 \n",
      "acc for Psat= 0.17735934697958014 \n",
      "acc for optim= 0.16527380396165411\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.0053819408640265465\n",
      "Loss on test= 0.005820429418236017\n",
      "acc for Lsat= 0.14757129508643183 \n",
      "acc for Psat= 0.19243982071209637 \n",
      "acc for optim= 0.16696808777680835\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.005316448863595724\n",
      "Loss on test= 0.006086229812353849\n",
      "acc for Lsat= 0.15546535079054474 \n",
      "acc for Psat= 0.18164462287620198 \n",
      "acc for optim= 0.16434264232186968\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.006442985497415066\n",
      "Loss on test= 0.006177164148539305\n",
      "acc for Lsat= 0.14582447197658513 \n",
      "acc for Psat= 0.1883564271730348 \n",
      "acc for optim= 0.17130066733091656\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.005338566843420267\n",
      "Loss on test= 0.006148100830614567\n",
      "acc for Lsat= 0.14370552735655095 \n",
      "acc for Psat= 0.17756070265981566 \n",
      "acc for optim= 0.1634430005942227\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.005728804972022772\n",
      "Loss on test= 0.006427975371479988\n",
      "acc for Lsat= 0.1540722571675032 \n",
      "acc for Psat= 0.17908199928800164 \n",
      "acc for optim= 0.16536614982479014\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.005317773204296827\n",
      "Loss on test= 0.0060300566256046295\n",
      "acc for Lsat= 0.13791361830004523 \n",
      "acc for Psat= 0.16821332706413308 \n",
      "acc for optim= 0.15743796247378236\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005408891476690769\n",
      "Loss on test= 0.00616452656686306\n",
      "acc for Lsat= 0.15280250863508002 \n",
      "acc for Psat= 0.1711836929174453 \n",
      "acc for optim= 0.1699665778463508\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.005449892487376928\n",
      "Loss on test= 0.006334402598440647\n",
      "acc for Lsat= 0.14250452843519523 \n",
      "acc for Psat= 0.19000582838140917 \n",
      "acc for optim= 0.16252702490529655\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.005558994598686695\n",
      "Loss on test= 0.006070369388908148\n",
      "acc for Lsat= 0.1573261643130834 \n",
      "acc for Psat= 0.18748048894473765 \n",
      "acc for optim= 0.1690133640009215\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.0053411866538226604\n",
      "Loss on test= 0.006499077193439007\n",
      "acc for Lsat= 0.1467167911199914 \n",
      "acc for Psat= 0.17908614297229491 \n",
      "acc for optim= 0.16164289007953855\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.005481020547449589\n",
      "Loss on test= 0.0059117660857737064\n",
      "acc for Lsat= 0.15191598844673432 \n",
      "acc for Psat= 0.17341721988451042 \n",
      "acc for optim= 0.16071353755036338\n"
     ]
    }
   ],
   "source": [
    "history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc1':[], 'test_acc2':[], \n",
    "          'test_acc3':[]}\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(df1)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    \n",
    "    X_train = df1.iloc[train_idx]\n",
    "    X_test = df1.iloc[val_idx]\n",
    "    y_train = df2.iloc[train_idx]\n",
    "    y_test = df2.iloc[val_idx]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    scaler2 = MinMaxScaler()\n",
    "    scaler2.fit(y_train)\n",
    "\n",
    "    y_train = scaler2.transform(y_train)\n",
    "    y_test = scaler2.transform(y_test)\n",
    "    \n",
    "    \n",
    "    X_train = torch.Tensor(X_train) \n",
    "    y_train = torch.Tensor(y_train)\n",
    "\n",
    "    X_test = torch.Tensor(X_test)\n",
    "    y_test = torch.Tensor(y_test)\n",
    "\n",
    "    train_set = TensorDataset(X_train, y_train) \n",
    "    test_set = TensorDataset(X_test, y_test) \n",
    "\n",
    "\n",
    "    # Create Dataloader to read the data within batch sizes and put into memory. \n",
    "    train_loader = DataLoader(train_set, batch_size = 64, shuffle = True) \n",
    "    test_loader = DataLoader(test_set, batch_size = 1)\n",
    "\n",
    "    \n",
    "    model = Network(input_size,output_size).to(device) \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1, last_epoch = -1)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_on_train = train_epoch(model, optimizer, criterion, train_loader)\n",
    "        train_loss = float(np.mean(loss_on_train))\n",
    "        _, loss_on_test = validate(model, criterion, test_loader)\n",
    "        test_loss = float(np.mean(loss_on_test))\n",
    "        train_acc = test(model, train_loader)\n",
    "        test_acc = test(model, test_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(\"Epoch:{}/{}\".format(epoch + 1, num_epochs))\n",
    "        print('Loss on train=', train_loss)\n",
    "        print('Loss on test=', test_loss)\n",
    "        print('acc for Lsat=', test_acc[0],'\\n' 'acc for Psat=', test_acc[1], '\\n' 'acc for optim=', test_acc[2])\n",
    "        \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    #history['train_acc'].append(train_acc)\n",
    "    history['test_acc1'].append(test_acc[0])  \n",
    "    history['test_acc2'].append(test_acc[1])  \n",
    "    history['test_acc3'].append(test_acc[2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "1cd2aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of 5 fold cross validation\n",
      "Average Training Loss: 0.0053 \t Average Test Loss: 0.0071 \t Average Lsat Acc: 0.151 \t Average Psat Acc: 0.186 \t Average Loptim Acc: 0.171\n"
     ]
    }
   ],
   "source": [
    "avg_train_loss = np.mean(history['train_loss'])\n",
    "avg_test_loss = np.mean(history['test_loss'])\n",
    "avg_test_acc1 = np.mean(history['test_acc1'])\n",
    "avg_test_acc2 = np.mean(history['test_acc2'])\n",
    "avg_test_acc3 = np.mean(history['test_acc3'])\n",
    "\n",
    "print('Performance of {} fold cross validation'.format(k))\n",
    "print(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f} \\t Average Lsat Acc: {:.3f} \\t Average Psat Acc: {:.3f} \\t Average Loptim Acc: {:.3f}\".format(avg_train_loss,avg_test_loss,avg_test_acc1,avg_test_acc2,\n",
    "avg_test_acc3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6341f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
