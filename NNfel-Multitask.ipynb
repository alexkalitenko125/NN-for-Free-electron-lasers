{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d4cf661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import torch.optim as optim \n",
    "from torch.optim import AdamW\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21fc117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Данные.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c142df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>lu</th>\n",
       "      <th>P0</th>\n",
       "      <th>I</th>\n",
       "      <th>gamma</th>\n",
       "      <th>sgamma</th>\n",
       "      <th>r</th>\n",
       "      <th>Psat</th>\n",
       "      <th>Lsat</th>\n",
       "      <th>loptim</th>\n",
       "      <th>lres</th>\n",
       "      <th>loptim/lres</th>\n",
       "      <th>Psat/Pall</th>\n",
       "      <th>Lsat/lu</th>\n",
       "      <th>f</th>\n",
       "      <th>rho</th>\n",
       "      <th>P0/Pall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>12800000.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.430000e+08</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2.261250e-08</td>\n",
       "      <td>2.257770e-08</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>1.180000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.800000e+07</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1.585280e-07</td>\n",
       "      <td>1.580440e-07</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>3.130000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.130000e+09</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2.061380e-08</td>\n",
       "      <td>2.057220e-08</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>2.070000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.100000e+09</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.648760e-08</td>\n",
       "      <td>1.645770e-08</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.00136</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>1.850000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.180000e+09</td>\n",
       "      <td>19.4</td>\n",
       "      <td>2.356200e-08</td>\n",
       "      <td>2.351110e-08</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>2.210000e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k    lu          P0      I   gamma  sgamma       r          Psat  Lsat  \\\n",
       "0  3.89  3.69  12800000.0   80.0  2650.0     0.0  0.0001  1.430000e+08  18.5   \n",
       "1  3.89  3.69     12800.0   80.0  1000.0     0.0  0.0001  9.800000e+07  16.7   \n",
       "2  3.98  3.69    150000.0  500.0  2830.0     0.0  0.0001  1.130000e+09  20.3   \n",
       "3  3.98  3.69   1500000.0  500.0  3160.0     0.0  0.0001  1.100000e+09  18.3   \n",
       "4  3.98  3.69    150000.0  500.0  2650.0     0.0  0.0001  1.180000e+09  19.4   \n",
       "\n",
       "         loptim          lres  loptim/lres  Psat/Pall  Lsat/lu      f  \\\n",
       "0  2.261250e-08  2.257770e-08     0.001542    0.00132     5.01  0.736   \n",
       "1  1.585280e-07  1.580440e-07     0.003065    0.00240     4.52  0.736   \n",
       "2  2.061380e-08  2.057220e-08     0.002024    0.00156     5.49  0.735   \n",
       "3  1.648760e-08  1.645770e-08     0.001814    0.00136     4.96  0.735   \n",
       "4  2.356200e-08  2.351110e-08     0.002164    0.00175     5.25  0.735   \n",
       "\n",
       "        rho       P0/Pall  \n",
       "0  0.000965  1.180000e-04  \n",
       "1  0.002550  3.130000e-07  \n",
       "2  0.001690  2.070000e-07  \n",
       "3  0.001510  1.850000e-06  \n",
       "4  0.001800  2.210000e-07  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "140b811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e1ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "243cc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Psat/Pall']<0.008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6103f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log'] = np.log(df[['Psat/Pall']])\n",
    "df['log0'] = np.log(df['P0']/df['I']/df['gamma']/511000)\n",
    "df['optim'] = df['loptim/lres']/df['Psat/Pall']\n",
    "df['Lsat/lu'] = np.log(df['Lsat/lu'])\n",
    "df['sqgamma'] = np.log(df['gamma'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee8f0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['optim']<=2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294bf40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9070138150903294"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)/l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "611d767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['optim'] = df['loptim/lres']/df['rho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf41df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['optim'] = (df['optim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f418fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(columns=['gamma', 'P0', 'optim', 'P0/Pall', 'Psat', 'Lsat', 'loptim','lres', 'loptim/lres', 'Psat/Pall', 'Lsat/lu', 'f', 'rho', 'log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3642dca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>lu</th>\n",
       "      <th>I</th>\n",
       "      <th>sgamma</th>\n",
       "      <th>r</th>\n",
       "      <th>log0</th>\n",
       "      <th>sqgamma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>-9.043511</td>\n",
       "      <td>7.882315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>-14.976706</td>\n",
       "      <td>6.907755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>-15.388374</td>\n",
       "      <td>7.948032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>-13.196085</td>\n",
       "      <td>8.058327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>500.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>-15.322657</td>\n",
       "      <td>7.882315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>1.72</td>\n",
       "      <td>1.99</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-16.247034</td>\n",
       "      <td>10.275051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>1.72</td>\n",
       "      <td>1.99</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-11.532665</td>\n",
       "      <td>10.165852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>3.29</td>\n",
       "      <td>1.99</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-11.512708</td>\n",
       "      <td>10.404263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>3.29</td>\n",
       "      <td>1.99</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-11.653787</td>\n",
       "      <td>10.545341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>3.29</td>\n",
       "      <td>1.99</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0.00005</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-15.988667</td>\n",
       "      <td>10.275051</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1707 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         k    lu       I   sgamma        r       log0    sqgamma\n",
       "0     3.89  3.69    80.0  0.00000  0.00010  -9.043511   7.882315\n",
       "1     3.89  3.69    80.0  0.00000  0.00010 -14.976706   6.907755\n",
       "2     3.98  3.69   500.0  0.00000  0.00010 -15.388374   7.948032\n",
       "3     3.98  3.69   500.0  0.00000  0.00010 -13.196085   8.058327\n",
       "4     3.98  3.69   500.0  0.00000  0.00010 -15.322657   7.882315\n",
       "...    ...   ...     ...      ...      ...        ...        ...\n",
       "1877  1.72  1.99  7600.0  0.00005  0.00001 -16.247034  10.275051\n",
       "1878  1.72  1.99  7600.0  0.00005  0.00001 -11.532665  10.165852\n",
       "1879  3.29  1.99  4500.0  0.00005  0.00001 -11.512708  10.404263\n",
       "1880  3.29  1.99  4500.0  0.00005  0.00001 -11.653787  10.545341\n",
       "1881  3.29  1.99  4500.0  0.00005  0.00001 -15.988667  10.275051\n",
       "\n",
       "[1707 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17404835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(columns=['sqgamma', 'k', 'lu', 'I', 'gamma', 'sgamma', 'r', 'log0', 'P0', 'P0/Pall', 'loptim','lres', 'loptim/lres', 'Psat/Pall', 'Lsat', 'f', 'rho', 'Psat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01cfb8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lsat/lu</th>\n",
       "      <th>log</th>\n",
       "      <th>optim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.611436</td>\n",
       "      <td>-6.630124</td>\n",
       "      <td>1.598041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.508512</td>\n",
       "      <td>-6.032287</td>\n",
       "      <td>1.201894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.702928</td>\n",
       "      <td>-6.463069</td>\n",
       "      <td>1.197420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.601406</td>\n",
       "      <td>-6.600271</td>\n",
       "      <td>1.201364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.658228</td>\n",
       "      <td>-6.348139</td>\n",
       "      <td>1.202222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1877</th>\n",
       "      <td>2.360854</td>\n",
       "      <td>-7.606921</td>\n",
       "      <td>0.798766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1878</th>\n",
       "      <td>1.829376</td>\n",
       "      <td>-7.086882</td>\n",
       "      <td>1.198454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1879</th>\n",
       "      <td>1.906575</td>\n",
       "      <td>-7.127156</td>\n",
       "      <td>1.200737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>2.034706</td>\n",
       "      <td>-7.268725</td>\n",
       "      <td>1.197812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1881</th>\n",
       "      <td>2.202765</td>\n",
       "      <td>-7.360312</td>\n",
       "      <td>0.799514</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1707 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lsat/lu       log     optim\n",
       "0     1.611436 -6.630124  1.598041\n",
       "1     1.508512 -6.032287  1.201894\n",
       "2     1.702928 -6.463069  1.197420\n",
       "3     1.601406 -6.600271  1.201364\n",
       "4     1.658228 -6.348139  1.202222\n",
       "...        ...       ...       ...\n",
       "1877  2.360854 -7.606921  0.798766\n",
       "1878  1.829376 -7.086882  1.198454\n",
       "1879  1.906575 -7.127156  1.200737\n",
       "1880  2.034706 -7.268725  1.197812\n",
       "1881  2.202765 -7.360312  0.799514\n",
       "\n",
       "[1707 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a77acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "515fa4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler2.fit(y_train)\n",
    "\n",
    "y_train = scaler2.transform(y_train)\n",
    "y_test = scaler2.transform(y_test)\n",
    "y_val = scaler2.transform(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dcc3a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = torch.Tensor(X_train) \n",
    "y_train = torch.Tensor(y_train)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(y_val)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "train_set = TensorDataset(X_train, y_train) \n",
    "validate_set = TensorDataset(X_val, y_val) \n",
    "test_set = TensorDataset(X_test, y_test) \n",
    "\n",
    "\n",
    "# Create Dataloader to read the data within batch sizes and put into memory. \n",
    "train_loader = DataLoader(train_set, batch_size = 64, shuffle = True) \n",
    "validate_loader = DataLoader(validate_set, batch_size = 20) \n",
    "test_loader = DataLoader(test_set, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "541c3e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.03344481, 0.46488294, 0.07614213, 0.        , 0.11594203,\n",
       "        0.38745704, 0.47627386],\n",
       "       [0.2541806 , 0.6688963 , 0.5025381 , 0.        , 0.42028984,\n",
       "        0.51257414, 0.6090432 ],\n",
       "       [0.22408026, 0.50167227, 0.6040609 , 0.5       , 0.02898551,\n",
       "        0.4730055 , 0.56033206],\n",
       "       [0.4916388 , 0.34448162, 0.70558375, 0.        , 0.42028984,\n",
       "        0.64954364, 0.6932179 ],\n",
       "       [0.66220737, 0.89966553, 0.70558375, 0.        , 0.07246377,\n",
       "        0.64118177, 0.6090432 ],\n",
       "       [0.4347826 , 0.8561873 , 0.42131978, 0.2       , 0.04347826,\n",
       "        0.15162516, 0.84266347],\n",
       "       [0.04682274, 0.729097  , 0.6040609 , 0.1       , 0.71014494,\n",
       "        0.37730882, 0.45869353],\n",
       "       [0.22408026, 0.8929766 , 0.06598984, 0.5       , 0.05797102,\n",
       "        0.650167  , 0.4479199 ],\n",
       "       [0.36789298, 0.3043478 , 0.8071066 , 0.1       , 0.1594203 ,\n",
       "        0.29905614, 0.7573984 ],\n",
       "       [0.77591974, 0.0735786 , 0.70558375, 0.5       , 0.2753623 ,\n",
       "        0.5440797 , 0.58063394],\n",
       "       [0.44816053, 0.04682274, 0.8071066 , 0.1       , 0.2753623 ,\n",
       "        0.34906256, 0.58063394],\n",
       "       [0.7692308 , 0.13377926, 0.        , 0.5       , 0.11594203,\n",
       "        0.43840206, 0.30689391],\n",
       "       [0.30769232, 0.9498328 , 0.5025381 , 1.        , 0.13043478,\n",
       "        0.49756306, 0.77025384],\n",
       "       [0.26755852, 0.8327759 , 0.04568528, 0.        , 0.5652174 ,\n",
       "        0.18219887, 0.4479199 ],\n",
       "       [0.99331105, 0.5083612 , 0.07614213, 0.1       , 0.02898551,\n",
       "        0.33989152, 0.79025006],\n",
       "       [0.8060201 , 0.99331105, 0.0964467 , 0.2       , 0.04347826,\n",
       "        0.6423463 , 0.89578736],\n",
       "       [0.6220736 , 0.85953176, 0.6040609 , 0.        , 0.07246377,\n",
       "        0.64043224, 0.59649855],\n",
       "       [0.3478261 , 0.01672241, 0.00304569, 1.        , 0.20289855,\n",
       "        0.6417748 , 0.16126782],\n",
       "       [0.19397993, 0.5518395 , 0.        , 0.1       , 0.02753623,\n",
       "        0.51802075, 0.58063394],\n",
       "       [0.9765886 , 0.8528428 , 0.5025381 , 0.        , 0.10144927,\n",
       "        0.64553803, 0.58063394],\n",
       "       [0.10033445, 0.89966553, 0.04568528, 0.5       , 0.14492753,\n",
       "        0.42720407, 0.4193661 ],\n",
       "       [0.8862876 , 0.29431438, 0.70558375, 0.        , 0.11594203,\n",
       "        0.8461086 , 0.47627386],\n",
       "       [0.84949833, 0.19063546, 0.6040609 , 0.        , 0.01449275,\n",
       "        0.9969816 , 0.6373941 ],\n",
       "       [0.76254183, 0.23411371, 0.05583756, 0.2       , 0.5652174 ,\n",
       "        0.8158032 , 0.2583    ],\n",
       "       [0.9230769 , 0.7056856 , 0.6040609 , 0.        , 0.42028984,\n",
       "        0.64650935, 0.77025384],\n",
       "       [0.57859534, 0.72240806, 0.14720812, 0.05      , 0.        ,\n",
       "        0.47904363, 0.9772493 ],\n",
       "       [0.1638796 , 0.75250834, 0.5025381 , 0.        , 0.05797102,\n",
       "        0.32843727, 0.78102744],\n",
       "       [0.62541807, 0.05016723, 0.00304569, 0.        , 0.10144927,\n",
       "        0.5190487 , 0.48360172],\n",
       "       [0.29765886, 0.05016723, 0.8071066 , 0.        , 0.07246377,\n",
       "        0.7453331 , 0.59649855],\n",
       "       [0.9665552 , 0.89966553, 0.00304569, 0.        , 0.13043478,\n",
       "        0.40602633, 0.48360172],\n",
       "       [0.31772575, 0.39130434, 0.05583756, 0.        , 0.01449275,\n",
       "        0.32002383, 0.77025384],\n",
       "       [0.06020067, 0.12374582, 0.        , 0.        , 0.5652174 ,\n",
       "        0.29960006, 0.3223339 ],\n",
       "       [0.8729097 , 0.35451505, 0.8071066 , 0.        , 0.01449275,\n",
       "        0.39576337, 0.8059356 ],\n",
       "       [0.54180604, 0.3645485 , 0.06598984, 0.2       , 0.42028984,\n",
       "        0.38256568, 0.43508568],\n",
       "       [0.9230769 , 0.9632107 , 0.01522843, 0.1       , 0.0173913 ,\n",
       "        0.3166289 , 0.83145845],\n",
       "       [0.5652174 , 0.12374582, 0.8071066 , 0.        , 0.10144927,\n",
       "        0.46591264, 0.8059356 ],\n",
       "       [0.24749164, 0.6220736 , 0.07614213, 0.        , 0.85507244,\n",
       "        0.45374528, 0.23799816],\n",
       "       [0.35117057, 0.10702341, 0.8071066 , 0.        , 0.10144927,\n",
       "        0.36162916, 0.6446678 ],\n",
       "       [0.17725752, 0.89966553, 0.6040609 , 0.1       , 0.08695652,\n",
       "        0.6681877 , 0.47627386],\n",
       "       [0.5518395 , 0.46153846, 0.00304569, 0.1       , 0.13043478,\n",
       "        0.5408829 , 0.48360172],\n",
       "       [0.5852843 , 0.84615386, 0.5025381 , 0.5       , 0.05797102,\n",
       "        0.61991835, 0.6373941 ],\n",
       "       [0.71571904, 0.44481605, 0.05583756, 0.1       , 0.01449275,\n",
       "        0.7288685 , 0.7217358 ],\n",
       "       [0.57859534, 0.72240806, 0.14720812, 0.05      , 0.        ,\n",
       "        0.36000496, 0.87173045],\n",
       "       [0.05016723, 0.61204016, 0.5025381 , 0.1       , 0.04637681,\n",
       "        0.15290499, 0.7573984 ],\n",
       "       [0.2909699 , 0.16722408, 0.00101523, 0.        , 0.13043478,\n",
       "        0.31507617, 0.48360172],\n",
       "       [0.61538464, 0.11371238, 0.00101523, 0.5       , 0.5652174 ,\n",
       "        0.8042735 , 0.13635962],\n",
       "       [0.4347826 , 0.3979933 , 0.        , 0.        , 0.85507244,\n",
       "        0.5139899 , 0.3223339 ],\n",
       "       [0.1638796 , 0.32441473, 0.5025381 , 0.        , 0.07246377,\n",
       "        0.46547198, 0.79025006],\n",
       "       [0.00668896, 0.13377926, 0.8071066 , 0.        , 0.04347826,\n",
       "        0.37276822, 0.6292278 ],\n",
       "       [0.9498328 , 0.99331105, 0.8071066 , 0.        , 0.11594203,\n",
       "        0.45753542, 0.62002826],\n",
       "       [0.35785952, 0.05685619, 0.00304569, 0.        , 0.13043478,\n",
       "        0.5114424 , 0.4479199 ],\n",
       "       [0.4381271 , 0.55518395, 0.06598984, 0.        , 0.13043478,\n",
       "        0.39166224, 0.53170013],\n",
       "       [0.9230769 , 0.9264214 , 0.06598984, 0.1       , 0.11014493,\n",
       "        0.29168513, 0.8059356 ],\n",
       "       [0.9799331 , 0.21070234, 0.5025381 , 0.        , 0.71014494,\n",
       "        0.49022138, 0.62002826],\n",
       "       [0.8729097 , 0.43143812, 0.42131978, 0.        , 0.00724638,\n",
       "        0.33217672, 0.92849064],\n",
       "       [0.09030101, 0.71237457, 0.06598984, 0.1       , 0.04347826,\n",
       "        0.63948053, 0.4479199 ],\n",
       "       [0.13043478, 0.4381271 , 0.5025381 , 0.        , 0.10144927,\n",
       "        0.7258507 , 0.62002826],\n",
       "       [0.9130435 , 0.81270903, 0.04568528, 0.1       , 0.07246377,\n",
       "        0.6543084 , 0.47627386],\n",
       "       [0.5652174 , 0.10367893, 0.04568528, 1.        , 0.42028984,\n",
       "        0.59877867, 0.30689391],\n",
       "       [0.30100334, 0.5250836 , 0.8071066 , 0.        , 0.85507244,\n",
       "        0.81945115, 0.3223339 ],\n",
       "       [0.76254183, 0.9799331 , 0.04568528, 0.        , 0.07246377,\n",
       "        0.8362683 , 0.46791616],\n",
       "       [0.10033445, 0.67558527, 0.        , 0.        , 0.5652174 ,\n",
       "        0.52578217, 0.31506017],\n",
       "       [0.59197325, 0.78595316, 0.06598984, 0.1       , 0.02753623,\n",
       "        0.34532076, 0.77025384],\n",
       "       [0.5585284 , 0.26755852, 0.04568528, 0.5       , 0.02898551,\n",
       "        0.4628416 , 0.47627386]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_array = next(iter(train_loader))[0].numpy()\n",
    "train_dataset_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "db94f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters \n",
    "input_size = list(X_train.shape)[1]   \n",
    "output_size = list(y_train.shape)[1]  \n",
    "\n",
    "\n",
    "\n",
    "# Define neural network \n",
    "class Network(nn.Module): \n",
    "    def __init__(self, input_size, output_size, init_form=\"normal\"): \n",
    "        super().__init__() \n",
    "        self.conv_stack = nn.Sequential(\n",
    "        nn.Linear(input_size, 100), \n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(100, 100),\n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(100, 100),\n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.1))\n",
    "        \n",
    "        self.conv_stack1 = nn.Sequential(\n",
    "        nn.Linear(100, 100), \n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(100, 30),\n",
    "        nn.Tanh(), \n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(30, 1))\n",
    "                \n",
    "        self.conv_stack2 = nn.Sequential(\n",
    "        nn.Linear(100, 100), \n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(100, 30),\n",
    "        nn.Tanh(), \n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(30, 1))\n",
    "        \n",
    "        self.conv_stack3 = nn.Sequential(\n",
    "        nn.Linear(100, 100), \n",
    "        nn.Tanh(),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(100, 30),\n",
    "        nn.Tanh(), \n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Linear(30, 1))\n",
    "            \n",
    "        \n",
    "        self.init_form = init_form\n",
    "        if self.init_form is not None:\n",
    "            self.init()\n",
    "\n",
    "    def forward(self, x): \n",
    "        s = self.conv_stack(x)\n",
    "        out1 = self.conv_stack1(s)\n",
    "        out2 = self.conv_stack2(s)\n",
    "        out3 = self.conv_stack3(s)\n",
    "        return out1, out2, out3\n",
    "    \n",
    "    \n",
    "        # xavier weight initialization\n",
    "    def init(self):\n",
    "        sigmoid_gain = torch.nn.init.calculate_gain(\"tanh\")\n",
    "        for child in self.conv_stack.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                if self.init_form == \"normal\":\n",
    "                    torch.nn.init.xavier_normal_(child.weight,\n",
    "                                                 gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                elif self.init_form == \"uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(child.weight,\n",
    "                                                  gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                else:\n",
    "                    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a50d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_epoch(model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                train_loader):\n",
    "    loss_history = []\n",
    "    for batch in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        x_train, y_train = batch # parse data\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "        y1, y2, y3 = model(x_train) # get predictions\n",
    "        loss = criterion(y1, y_train[:, 0:1]) + criterion(y2, y_train[:,1:2]) + criterion(y3, y_train[:,2:]) # compute loss\n",
    "        loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a6c7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,\n",
    "             criterion,\n",
    "             val_loader):\n",
    "    cumloss = 0\n",
    "    loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_train, y_train = batch # parse data\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "            y1, y2, y3 = model(x_train) # get predictions\n",
    "            loss = criterion(y1, y_train[:, 0:1]) + criterion(y2, y_train[:,1:2]) + criterion(y3, y_train[:,2:]) # compute loss\n",
    "            loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
    "            cumloss += loss\n",
    "    return cumloss / len(val_loader), loss_history # mean loss and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3fed850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, optimizer, model_name=None, n_epochs=5):\n",
    "  \n",
    "    criterion = nn.MSELoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history['model_name'] = model_name\n",
    "    train_history['loss_on_train'] = []\n",
    "    train_history['loss_on_test'] = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        loss_on_train = train_epoch(model,\n",
    "                                    optimizer,\n",
    "                                    criterion,\n",
    "                                    train_loader)\n",
    "        _, loss_on_test = validate(model,\n",
    "                                   criterion,\n",
    "                                   validate_loader)\n",
    "        train_history['loss_on_train'].append(np.mean(loss_on_train))\n",
    "        train_history['loss_on_test'].append(np.mean(loss_on_test))\n",
    "        scheduler.step()\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2e8bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(scalars, weight):  \n",
    "    last = scalars[0]  \n",
    "    smoothed = []\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  \n",
    "        smoothed.append(smoothed_val)                        \n",
    "        last = smoothed_val                                 \n",
    "\n",
    "    return smoothed\n",
    "\n",
    "\n",
    "def plot_history(history, n_epochs=5, smooth_val=0.9):\n",
    "    fig, ax =  plt.subplots(3, 1, figsize=(12, 14))\n",
    "    for stage_idx, (stage_lbl, stage_title) in enumerate(\n",
    "        zip(['loss_on_train', 'loss_on_test'],\n",
    "            ['train loss', 'test loss'])):\n",
    "        # plot history on each learning step\n",
    "        epoch_len = len(history[stage_lbl])//n_epochs\n",
    "        full_stage_len = len(history[stage_lbl])\n",
    "        ax[stage_idx].plot(exponential_smoothing(history[stage_lbl], smooth_val),\n",
    "                           label='smoothed',\n",
    "                           color='m')\n",
    "        ax[stage_idx].plot(history[stage_lbl],\n",
    "                           label='raw',\n",
    "                           alpha=0.2,\n",
    "                           color='c')\n",
    "        ax[stage_idx].set_title(stage_title)\n",
    "        ax[stage_idx].set_xlabel('epochs')\n",
    "        ax[stage_idx].set_ylabel('loss')\n",
    "        epochs_ticks_positions = np.arange(stop=full_stage_len+1,\n",
    "                                           step=epoch_len)\n",
    "        ax[stage_idx].set_xticks(np.arange(0,1000,100))\n",
    "        ax[stage_idx].set_xticklabels(np.arange(0,1000,100))\n",
    "        ax[stage_idx].legend()\n",
    "\n",
    "        # plot mean train and test loss combined\n",
    "        mean_loss_on_epoch = [np.mean(history[stage_lbl][i:i+epoch_len]) \\\n",
    "                              for i in range(0, full_stage_len, epoch_len)]\n",
    "        std_loss_on_epoch = [np.std(history[stage_lbl][i:i+epoch_len]) \\\n",
    "                              for i in range(0, full_stage_len, epoch_len)]\n",
    "\n",
    "        ax[2].set_title('\\nAverage loss per epoch')\n",
    "        ax[2].errorbar(np.arange(n_epochs) + stage_idx / 30.,\n",
    "                       mean_loss_on_epoch,\n",
    "                       yerr=std_loss_on_epoch,\n",
    "                       capsize=5,\n",
    "                       fmt=\"X--\",\n",
    "                       label=stage_title)\n",
    "        ax[2].set_xticks(np.arange(0,1000,100))\n",
    "        ax[2].set_xticklabels(np.arange(0,1000,100))\n",
    "        ax[2].set_xlabel('epochs')\n",
    "        ax[2].set_ylabel('loss')\n",
    "        ax[2].legend()\n",
    "\n",
    "    fig.suptitle(history['model_name'], fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f030e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [01:37<00:00, 10.27it/s]\n"
     ]
    }
   ],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "model = Network(input_size,output_size).to(device) \n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "lambda1 = lambda epoch: 0.998 ** epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1, last_epoch = -1)\n",
    "\n",
    "n_epochs = 1000\n",
    "history = train_model(model, optimizer, model_name='model', n_epochs=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6971052a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x1008 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history, n_epochs=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc83567c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x26807586d90>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,n_epochs+1), (history['loss_on_train']), label='train')\n",
    "plt.plot(range(1,n_epochs+1), (history['loss_on_test']), label='test')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6986b941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv_stack): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=100, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (7): Tanh()\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (conv_stack1): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=30, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       "  (conv_stack2): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=30, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       "  (conv_stack3): Sequential(\n",
       "    (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): Linear(in_features=100, out_features=30, bias=True)\n",
       "    (4): Tanh()\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Linear(in_features=30, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7685f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc for Lsat= 0.055333974958419234 \n",
      "acc for Psat= 0.09806225094175795 \n",
      "acc for optim= 0.151078057970451\n"
     ]
    }
   ],
   "source": [
    "def relative_abs_error(true, pred):\n",
    "    num = np.sum(np.abs(true - pred))\n",
    "    den = np.sum(np.abs(true))\n",
    "    squared_error = num/den\n",
    "    rrmse_loss = (squared_error)\n",
    "    return rrmse_loss\n",
    "\n",
    "\n",
    "def test(model, val_loader):\n",
    "    cumloss1 = 0\n",
    "    cumloss2 = 0\n",
    "    cumloss3 = 0\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    l3 = []\n",
    "    l4 = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_train, y_train = batch # parse data\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "            y_pred = torch.cat(model(x_train),1) # get predictions\n",
    "            y_pred = scaler2.inverse_transform(y_pred.cpu().detach().numpy())\n",
    "            y_train = scaler2.inverse_transform(y_train.cpu().detach().numpy())\n",
    "            loss1 = relative_abs_error(np.exp(y_pred[0][0]), \n",
    "                                                    np.exp(y_train[0][0])) # compute loss\n",
    "            loss2 = relative_abs_error(np.exp(y_pred[0][1]), \n",
    "                                                    np.exp(y_train[0][1]))\n",
    "            loss3 = relative_abs_error((y_pred[0][2]), \n",
    "                                                    (y_train[0][2]))\n",
    "            cumloss1 += loss1\n",
    "            cumloss2 += loss2\n",
    "            cumloss3 += loss3\n",
    "            l1.append(loss1)\n",
    "            l2.append(loss2)\n",
    "            l3.append(loss3)\n",
    "            l4.append(x_train.cpu().detach().numpy())\n",
    "    return cumloss1 / len(val_loader), cumloss2 / len(val_loader), cumloss3 / len(val_loader), l1, l2, l3, l4\n",
    "\n",
    "\n",
    "l = test(model, test_loader)\n",
    "print('acc for Lsat=', l[0],'\\n' 'acc for Psat=', l[1], '\\n' 'acc for optim=', l[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "39faae6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Lsat error')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(l[3])\n",
    "plt.title(\"Lsat error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fe589d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Power error')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(l[4])\n",
    "plt.title(\"Power error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4214a0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143    0.220020\n",
       "43     0.225928\n",
       "46     0.227741\n",
       "22     0.237590\n",
       "35     0.242115\n",
       "11     0.254136\n",
       "146    0.255378\n",
       "135    0.256404\n",
       "111    0.261256\n",
       "33     0.269618\n",
       "86     0.272049\n",
       "129    0.277935\n",
       "34     0.285919\n",
       "102    0.288295\n",
       "78     0.298147\n",
       "64     0.328062\n",
       "159    0.332591\n",
       "47     0.380434\n",
       "169    0.473399\n",
       "96     0.632012\n",
       "dtype: float32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(l[4]).sort_values().tail(20)\n",
    "#scaler.inverse_transform(np.array([X_test[103].cpu().detach().numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "948af4b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.43000007e+00,  2.86000013e+00,  7.00000000e+03,\n",
       "         1.00000005e-04,  9.00000014e-05, -1.02147408e+01,\n",
       "         8.05832767e+00]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(l[6][18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c55302e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'optim error')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(l[5])\n",
    "plt.title(\"optim error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6404a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import jv\n",
    "\n",
    "X = pd.DataFrame({'k':[2.13], 'lu':[2.8], 'I':[53],  'sgamma':[0.0002], \n",
    "                  'r':[0.00012], 'log0':[10], 'sqgamma': [np.log(300)]})\n",
    "\n",
    "ksi = X['k']**2/(1+X['k']**2/2)/4\n",
    "f = jv(0,ksi)-jv(1,ksi)\n",
    "rho = 1/2/(np.exp(X['sqgamma']))*(X['I']/X['r']**2/np.pi/4/np.pi/17000*(X['lu']/100*X['k']*f)**2)**(1/3)\n",
    "\n",
    "\n",
    "X['log0'] = np.log(X['log0']/X['I']/np.exp(X['sqgamma'])/511000)\n",
    "\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f47cf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.Tensor(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fba5bf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6327567, -6.043516 ,  1.0047495]], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (torch.cat(model(input1.to(device)),1)).cpu().detach().numpy()\n",
    "a= scaler2.inverse_transform(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64901883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lsat= 14.330298614501952 Psat= 19282011.948153373 loptim= 5.103993424225048e-07\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X = pd.DataFrame({'k':[2.13], 'lu':[2.8], 'I':[53],  'sgamma':[0.0002], \n",
    "                  'r':[0.00012], 'log0':[10], 'sqgamma': [np.log(300)]})\n",
    "\n",
    "P_0 = X['log0']\n",
    "\n",
    "ksi = X['k']**2/(1+X['k']**2/2)/4\n",
    "f = jv(0,ksi)-jv(1,ksi)\n",
    "\n",
    "rho = 1/2/(np.exp(X['sqgamma']))*(X['I']/X['r']**2/np.pi/4/np.pi/17000*(X['lu']/100*X['k']*f)**2)**(1/3)\n",
    "X['log0'] = np.log(X['log0']/X['I']/np.exp(X['sqgamma'])/511000)\n",
    "\n",
    "\n",
    "L_sat = np.exp(a[0][0])*X['lu'][0]\n",
    "P_sat = (np.exp(a[0][1])*np.exp(X['sqgamma'])*511000*X['I'])[0]\n",
    "\n",
    "print('Lsat=', np.exp(a[0][0])*X['lu'][0], 'Psat=', (np.exp(a[0][1])*np.exp(X['sqgamma'])*511000*X['I'])[0], \n",
    "'loptim=',(((a[0][2])*rho+1)*X['lu']/100/2/np.exp(X['sqgamma'])/np.exp(X['sqgamma'])*(1+X['k']*X['k']/2))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9992987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1707"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "38dd6206",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    2.047438e+07\n",
      "Name: log0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2680bd97610>]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def P(z,P_0,P_sat,L_sat):\n",
    "    def A(z,L):\n",
    "        return 1/9*(3+2*np.cosh(z/L)+4*np.cos(3**(0.5)/2*z/L)*np.cosh(z/(2*L)))\n",
    "    L = L_sat/1.1/np.log(9*P_sat/P_0)\n",
    "    if z<L_sat:\n",
    "        return P_0*(A(z,L)*np.exp(0.233*z/L_sat))/(1+P_0/P_sat*(A(z,L)-1))\n",
    "    else: \n",
    "        return P_0*(A(L_sat,L)*np.exp(0.233*L_sat/L_sat))/(1+P_0/P_sat*(A(L_sat,L)-1))\n",
    "\n",
    "print(P(L_sat,P_0,P_sat,L_sat))\n",
    "\n",
    " \n",
    "# exponential function y = 10^x\n",
    "data = [P(i,P_0,P_sat,L_sat) for i in np.arange(0, int(1.3*L_sat), 0.1)]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "# convert y-axis to Logarithmic scale\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel('z, m')\n",
    "plt.ylabel('Psat, W')\n",
    "plt.title('FEL power evolution')\n",
    "\n",
    " \n",
    "plt.plot(np.arange(0, int(1.3*L_sat), 0.1), data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "57c36cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, SubsetRandomSampler, ConcatDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "0a148458",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "set_random_seed(42)\n",
    "\n",
    "num_epochs=1000\n",
    "batch_size=64\n",
    "k=5\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "id": "a1a8b1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.08542811870574951\n",
      "Loss on test= 0.036827389150857925\n",
      "acc for Lsat= 0.6435098354187276 \n",
      "acc for Psat= 0.6896814983338118 \n",
      "acc for optim= 0.19622140445022118\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.02992241270840168\n",
      "Loss on test= 0.02722686529159546\n",
      "acc for Lsat= 0.3688102663598127 \n",
      "acc for Psat= 0.5031620230939653 \n",
      "acc for optim= 0.15890241243566075\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.0239699799567461\n",
      "Loss on test= 0.027174176648259163\n",
      "acc for Lsat= 0.5277412767625518 \n",
      "acc for Psat= 0.43931180104199385 \n",
      "acc for optim= 0.2555303463919295\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.021186212077736855\n",
      "Loss on test= 0.021732905879616737\n",
      "acc for Lsat= 0.4702269856093658 \n",
      "acc for Psat= 0.4093520034932428 \n",
      "acc for optim= 0.2641823978887664\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.02076485939323902\n",
      "Loss on test= 0.022011402994394302\n",
      "acc for Lsat= 0.5610672754442526 \n",
      "acc for Psat= 0.44310582677523297 \n",
      "acc for optim= 0.19653205630472964\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.020430821925401688\n",
      "Loss on test= 0.0203569196164608\n",
      "acc for Lsat= 0.481948959072017 \n",
      "acc for Psat= 0.3644602898922231 \n",
      "acc for optim= 0.21909841532922453\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.01925273984670639\n",
      "Loss on test= 0.020326195284724236\n",
      "acc for Lsat= 0.5116328504971333 \n",
      "acc for Psat= 0.3352239111231433 \n",
      "acc for optim= 0.21757314906183942\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.018745915964245796\n",
      "Loss on test= 0.020755551755428314\n",
      "acc for Lsat= 0.5362478765762515 \n",
      "acc for Psat= 0.371390660552101 \n",
      "acc for optim= 0.30614475947287345\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.019146747887134552\n",
      "Loss on test= 0.019128696992993355\n",
      "acc for Lsat= 0.410191706329998 \n",
      "acc for Psat= 0.5380409972664589 \n",
      "acc for optim= 0.18543449427104658\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.017722783610224724\n",
      "Loss on test= 0.02006690949201584\n",
      "acc for Lsat= 0.6535961392025152 \n",
      "acc for Psat= 0.3625148307118151 \n",
      "acc for optim= 0.20331478654406965\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.0177301038056612\n",
      "Loss on test= 0.01911197416484356\n",
      "acc for Lsat= 0.4995122506386704 \n",
      "acc for Psat= 0.5665448948533999 \n",
      "acc for optim= 0.24038749167488682\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.017435863614082336\n",
      "Loss on test= 0.020251715555787086\n",
      "acc for Lsat= 0.3291473339001338 \n",
      "acc for Psat= 0.6769170029502776 \n",
      "acc for optim= 0.17513626443946528\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.017678434029221535\n",
      "Loss on test= 0.01816796138882637\n",
      "acc for Lsat= 0.45323044692890513 \n",
      "acc for Psat= 0.3263673363770876 \n",
      "acc for optim= 0.18025580928143528\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.016520004719495773\n",
      "Loss on test= 0.019613517448306084\n",
      "acc for Lsat= 0.5315072586139044 \n",
      "acc for Psat= 0.46918742710517514 \n",
      "acc for optim= 0.20897727092314097\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.016337696462869644\n",
      "Loss on test= 0.018812384456396103\n",
      "acc for Lsat= 0.5048572252401047 \n",
      "acc for Psat= 0.4659746889438894 \n",
      "acc for optim= 0.21228786656219098\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.015568900853395462\n",
      "Loss on test= 0.018858494237065315\n",
      "acc for Lsat= 0.31355769207908046 \n",
      "acc for Psat= 0.35605687503185535 \n",
      "acc for optim= 0.2065900263066093\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.015261557884514332\n",
      "Loss on test= 0.016473693773150444\n",
      "acc for Lsat= 0.4153401408758428 \n",
      "acc for Psat= 0.3251378123855425 \n",
      "acc for optim= 0.16709489850715423\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.014909546822309494\n",
      "Loss on test= 0.016985008493065834\n",
      "acc for Lsat= 0.27817435790267253 \n",
      "acc for Psat= 0.295230485783476 \n",
      "acc for optim= 0.2602599977205197\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.015218496322631836\n",
      "Loss on test= 0.019866134971380234\n",
      "acc for Lsat= 0.33844301803037524 \n",
      "acc for Psat= 0.4786316187431415 \n",
      "acc for optim= 0.2240608414867893\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.014927658252418041\n",
      "Loss on test= 0.015550155192613602\n",
      "acc for Lsat= 0.43949538386530346 \n",
      "acc for Psat= 0.36437378875497317 \n",
      "acc for optim= 0.2286081850114796\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.014899779111146927\n",
      "Loss on test= 0.017735522240400314\n",
      "acc for Lsat= 0.34563960911085206 \n",
      "acc for Psat= 0.5200704650487751 \n",
      "acc for optim= 0.204941575622393\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.014981681481003761\n",
      "Loss on test= 0.017897361889481544\n",
      "acc for Lsat= 0.34371305676177144 \n",
      "acc for Psat= 0.36278515888584983 \n",
      "acc for optim= 0.22705943220191532\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.014628976583480835\n",
      "Loss on test= 0.016506504267454147\n",
      "acc for Lsat= 0.16197175511883366 \n",
      "acc for Psat= 0.37325202994462514 \n",
      "acc for optim= 0.19584002169883913\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.01423676311969757\n",
      "Loss on test= 0.015557574108242989\n",
      "acc for Lsat= 0.3227115856587059 \n",
      "acc for Psat= 0.35064982102873427 \n",
      "acc for optim= 0.1643798530050036\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.014571810141205788\n",
      "Loss on test= 0.016570894047617912\n",
      "acc for Lsat= 0.4212066325255566 \n",
      "acc for Psat= 0.2817256518950065 \n",
      "acc for optim= 0.187455018294309\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.013843346387147903\n",
      "Loss on test= 0.01489256788045168\n",
      "acc for Lsat= 0.5359530573089918 \n",
      "acc for Psat= 0.3679132783630242 \n",
      "acc for optim= 0.19052390765864402\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.013545065186917782\n",
      "Loss on test= 0.01589060015976429\n",
      "acc for Lsat= 0.2349131795991626 \n",
      "acc for Psat= 0.29389810463827515 \n",
      "acc for optim= 0.17488559138857657\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.013987627811729908\n",
      "Loss on test= 0.016208086162805557\n",
      "acc for Lsat= 0.3454574645212334 \n",
      "acc for Psat= 0.3496819871167342 \n",
      "acc for optim= 0.1737844394519925\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.014168200083076954\n",
      "Loss on test= 0.0151846744120121\n",
      "acc for Lsat= 0.41027408879664207 \n",
      "acc for Psat= 0.3424482361103098 \n",
      "acc for optim= 0.20060436531073517\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.013767831958830357\n",
      "Loss on test= 0.016036204993724823\n",
      "acc for Lsat= 0.36876519654308343 \n",
      "acc for Psat= 0.3664589213828246 \n",
      "acc for optim= 0.15403713644870246\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.013456703163683414\n",
      "Loss on test= 0.014887775294482708\n",
      "acc for Lsat= 0.31713678936163586 \n",
      "acc for Psat= 0.3148572284521328 \n",
      "acc for optim= 0.19623156207510167\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.013333993963897228\n",
      "Loss on test= 0.01610223762691021\n",
      "acc for Lsat= 0.26791406019280356 \n",
      "acc for Psat= 0.33126743800110287 \n",
      "acc for optim= 0.20048446979166734\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.013018334284424782\n",
      "Loss on test= 0.015293268486857414\n",
      "acc for Lsat= 0.36042211970521343 \n",
      "acc for Psat= 0.28379322096912396 \n",
      "acc for optim= 0.16921764477673504\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.013166061602532864\n",
      "Loss on test= 0.014708825387060642\n",
      "acc for Lsat= 0.26767348441191846 \n",
      "acc for Psat= 0.20569995244861478 \n",
      "acc for optim= 0.1923497538599703\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.012987431138753891\n",
      "Loss on test= 0.015625208616256714\n",
      "acc for Lsat= 0.486094965495997 \n",
      "acc for Psat= 0.28633928174773854 \n",
      "acc for optim= 0.2093192045059469\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.013295008800923824\n",
      "Loss on test= 0.014863114804029465\n",
      "acc for Lsat= 0.3179033204085297 \n",
      "acc for Psat= 0.37351736881666714 \n",
      "acc for optim= 0.19750553359174067\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.012872666120529175\n",
      "Loss on test= 0.01473715528845787\n",
      "acc for Lsat= 0.38421429817875224 \n",
      "acc for Psat= 0.23078095147179234 \n",
      "acc for optim= 0.15220420490853334\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.012707247398793697\n",
      "Loss on test= 0.014967312105000019\n",
      "acc for Lsat= 0.34172168494680794 \n",
      "acc for Psat= 0.416909428830776 \n",
      "acc for optim= 0.2297406161410941\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.012333299964666367\n",
      "Loss on test= 0.014322100207209587\n",
      "acc for Lsat= 0.27832171721901333 \n",
      "acc for Psat= 0.3604278193993701 \n",
      "acc for optim= 0.18829362808416286\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.012392834760248661\n",
      "Loss on test= 0.013658424839377403\n",
      "acc for Lsat= 0.3048588093887601 \n",
      "acc for Psat= 0.3165610858187493 \n",
      "acc for optim= 0.2019965816806588\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.012831887230277061\n",
      "Loss on test= 0.013805847615003586\n",
      "acc for Lsat= 0.3617367495575713 \n",
      "acc for Psat= 0.2419758267286751 \n",
      "acc for optim= 0.20881618192005488\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.013131179846823215\n",
      "Loss on test= 0.015077190473675728\n",
      "acc for Lsat= 0.2994739891340335 \n",
      "acc for Psat= 0.37864624915851486 \n",
      "acc for optim= 0.24521618945679316\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.012668429873883724\n",
      "Loss on test= 0.0157938189804554\n",
      "acc for Lsat= 0.3342263135645125 \n",
      "acc for Psat= 0.2887619308393268 \n",
      "acc for optim= 0.1794417964346293\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.012555975466966629\n",
      "Loss on test= 0.014635155908763409\n",
      "acc for Lsat= 0.34229055987412316 \n",
      "acc for Psat= 0.27883373469942146 \n",
      "acc for optim= 0.2003900838187999\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.01259277667850256\n",
      "Loss on test= 0.014895664528012276\n",
      "acc for Lsat= 0.28524516833325225 \n",
      "acc for Psat= 0.3089064974337816 \n",
      "acc for optim= 0.16541408333513472\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.0126527464017272\n",
      "Loss on test= 0.014521758072078228\n",
      "acc for Lsat= 0.3547165371063683 \n",
      "acc for Psat= 0.31070280851175386 \n",
      "acc for optim= 0.22575715794745418\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.01188412681221962\n",
      "Loss on test= 0.014513739384710789\n",
      "acc for Lsat= 0.36721021433671314 \n",
      "acc for Psat= 0.41021812583009404 \n",
      "acc for optim= 0.17766269258896095\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.012637096457183361\n",
      "Loss on test= 0.013354312628507614\n",
      "acc for Lsat= 0.28921349926127327 \n",
      "acc for Psat= 0.3339222613722086 \n",
      "acc for optim= 0.1764493064256385\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.011469892226159573\n",
      "Loss on test= 0.015091638080775738\n",
      "acc for Lsat= 0.4866766615046395 \n",
      "acc for Psat= 0.2672302619450622 \n",
      "acc for optim= 0.21147935102797216\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.011622542515397072\n",
      "Loss on test= 0.013018399477005005\n",
      "acc for Lsat= 0.4425166564502029 \n",
      "acc for Psat= 0.27535114877132905 \n",
      "acc for optim= 0.1311636518027323\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.011617559008300304\n",
      "Loss on test= 0.014054890722036362\n",
      "acc for Lsat= 0.2579688432936867 \n",
      "acc for Psat= 0.23460314091708925 \n",
      "acc for optim= 0.19341856142919925\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.01169551257044077\n",
      "Loss on test= 0.013765616342425346\n",
      "acc for Lsat= 0.2497106303150455 \n",
      "acc for Psat= 0.28091159850979847 \n",
      "acc for optim= 0.16897732350561354\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.011355829425156116\n",
      "Loss on test= 0.013375062495470047\n",
      "acc for Lsat= 0.4140156432468858 \n",
      "acc for Psat= 0.26872556904951733 \n",
      "acc for optim= 0.16899027308035228\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.011938572861254215\n",
      "Loss on test= 0.013247531838715076\n",
      "acc for Lsat= 0.2880965683531637 \n",
      "acc for Psat= 0.3295488879084587 \n",
      "acc for optim= 0.17716219356387025\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.011592536233365536\n",
      "Loss on test= 0.013263951055705547\n",
      "acc for Lsat= 0.3285859694911374 \n",
      "acc for Psat= 0.24632452552517256 \n",
      "acc for optim= 0.166559138490508\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.011509277857840061\n",
      "Loss on test= 0.01320877019315958\n",
      "acc for Lsat= 0.28272687312629485 \n",
      "acc for Psat= 0.23006827544627917 \n",
      "acc for optim= 0.2244382021534774\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.01128182653337717\n",
      "Loss on test= 0.014362300746142864\n",
      "acc for Lsat= 0.23377378864420784 \n",
      "acc for Psat= 0.26175442669126725 \n",
      "acc for optim= 0.2121162587362859\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.011660981923341751\n",
      "Loss on test= 0.013439284637570381\n",
      "acc for Lsat= 0.3584594051871035 \n",
      "acc for Psat= 0.28586893901228905 \n",
      "acc for optim= 0.19283807732992703\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.01130176242440939\n",
      "Loss on test= 0.012955663725733757\n",
      "acc for Lsat= 0.32611931218869156 \n",
      "acc for Psat= 0.31989454043408233 \n",
      "acc for optim= 0.14296782319433987\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.01110647339373827\n",
      "Loss on test= 0.013399327173829079\n",
      "acc for Lsat= 0.2879864859504677 \n",
      "acc for Psat= 0.22649257531803516 \n",
      "acc for optim= 0.21799527015537024\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.011376628652215004\n",
      "Loss on test= 0.013292941264808178\n",
      "acc for Lsat= 0.34788156021386385 \n",
      "acc for Psat= 0.2471344374741117 \n",
      "acc for optim= 0.19391302239253289\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.011184273287653923\n",
      "Loss on test= 0.013385591097176075\n",
      "acc for Lsat= 0.3838126104738977 \n",
      "acc for Psat= 0.32294179347809404 \n",
      "acc for optim= 0.19438398939867815\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.010993940755724907\n",
      "Loss on test= 0.013000886887311935\n",
      "acc for Lsat= 0.2678276346867076 \n",
      "acc for Psat= 0.36793093828277457 \n",
      "acc for optim= 0.14879521699104872\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.011162170208990574\n",
      "Loss on test= 0.01265639252960682\n",
      "acc for Lsat= 0.3746479540649388 \n",
      "acc for Psat= 0.35636068590813214 \n",
      "acc for optim= 0.17757679925610623\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.011090085841715336\n",
      "Loss on test= 0.013917422853410244\n",
      "acc for Lsat= 0.38162150922127897 \n",
      "acc for Psat= 0.31085175153096617 \n",
      "acc for optim= 0.17464744630787107\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.01129144337028265\n",
      "Loss on test= 0.013052619993686676\n",
      "acc for Lsat= 0.3912863793747319 \n",
      "acc for Psat= 0.2435292945139938 \n",
      "acc for optim= 0.20651504356000158\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.011107943020761013\n",
      "Loss on test= 0.013210768811404705\n",
      "acc for Lsat= 0.4303561347640223 \n",
      "acc for Psat= 0.2630913708255523 \n",
      "acc for optim= 0.20885911573552424\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.01071077585220337\n",
      "Loss on test= 0.012510576285421848\n",
      "acc for Lsat= 0.39460315327677464 \n",
      "acc for Psat= 0.35047002255709636 \n",
      "acc for optim= 0.14993831031541857\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.01092805340886116\n",
      "Loss on test= 0.012649036012589931\n",
      "acc for Lsat= 0.2843665182153422 \n",
      "acc for Psat= 0.3070683228757439 \n",
      "acc for optim= 0.16063546340188217\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.010953603312373161\n",
      "Loss on test= 0.01310678105801344\n",
      "acc for Lsat= 0.32464251874221695 \n",
      "acc for Psat= 0.24961481605552965 \n",
      "acc for optim= 0.19201280150769484\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.010718075558543205\n",
      "Loss on test= 0.013596737757325172\n",
      "acc for Lsat= 0.20650639027977982 \n",
      "acc for Psat= 0.26804389618337154 \n",
      "acc for optim= 0.17089509405195713\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.010264633223414421\n",
      "Loss on test= 0.012119974941015244\n",
      "acc for Lsat= 0.322680682150854 \n",
      "acc for Psat= 0.3411674640244908 \n",
      "acc for optim= 0.19599252173470127\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.010699387639760971\n",
      "Loss on test= 0.012326296418905258\n",
      "acc for Lsat= 0.29778906509616515 \n",
      "acc for Psat= 0.24358546966686845 \n",
      "acc for optim= 0.185576474501027\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.010800203308463097\n",
      "Loss on test= 0.011553090065717697\n",
      "acc for Lsat= 0.21880930232711965 \n",
      "acc for Psat= 0.2363330608802951 \n",
      "acc for optim= 0.19572388799861073\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.010292521677911282\n",
      "Loss on test= 0.01304730772972107\n",
      "acc for Lsat= 0.40567001410656506 \n",
      "acc for Psat= 0.24569098677279222 \n",
      "acc for optim= 0.23924154662139094\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.010809087194502354\n",
      "Loss on test= 0.012184008955955505\n",
      "acc for Lsat= 0.3173644825971375 \n",
      "acc for Psat= 0.3341441849867503 \n",
      "acc for optim= 0.16816955405132225\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.01002515759319067\n",
      "Loss on test= 0.012737337499856949\n",
      "acc for Lsat= 0.21881525131822047 \n",
      "acc for Psat= 0.3166013621828622 \n",
      "acc for optim= 0.19002689860968125\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.010425316169857979\n",
      "Loss on test= 0.012607317417860031\n",
      "acc for Lsat= 0.37377447272754377 \n",
      "acc for Psat= 0.31932368765895564 \n",
      "acc for optim= 0.20758989680972365\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.010771235451102257\n",
      "Loss on test= 0.01255134679377079\n",
      "acc for Lsat= 0.3452959315230449 \n",
      "acc for Psat= 0.26664519558350247 \n",
      "acc for optim= 0.18258432598991525\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.010455506853759289\n",
      "Loss on test= 0.013044251129031181\n",
      "acc for Lsat= 0.24721769931622678 \n",
      "acc for Psat= 0.3558118626889255 \n",
      "acc for optim= 0.19152290446476805\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.010224896483123302\n",
      "Loss on test= 0.012106395326554775\n",
      "acc for Lsat= 0.3348883319025238 \n",
      "acc for Psat= 0.2525454782363441 \n",
      "acc for optim= 0.14981778545512092\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.010242980904877186\n",
      "Loss on test= 0.012355371378362179\n",
      "acc for Lsat= 0.29154538611570996 \n",
      "acc for Psat= 0.2264684984046552 \n",
      "acc for optim= 0.15155334470586646\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.01022395957261324\n",
      "Loss on test= 0.011391173116862774\n",
      "acc for Lsat= 0.32557040005404914 \n",
      "acc for Psat= 0.24185673359574544 \n",
      "acc for optim= 0.17946923656078675\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.010369616560637951\n",
      "Loss on test= 0.012401878833770752\n",
      "acc for Lsat= 0.2325486602882544 \n",
      "acc for Psat= 0.2727110349159274 \n",
      "acc for optim= 0.18024988948471016\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.01028437539935112\n",
      "Loss on test= 0.012335157953202724\n",
      "acc for Lsat= 0.26055410338772667 \n",
      "acc for Psat= 0.20108570867321557 \n",
      "acc for optim= 0.16294650278157657\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.009841139428317547\n",
      "Loss on test= 0.012169421650469303\n",
      "acc for Lsat= 0.2731815658820172 \n",
      "acc for Psat= 0.22207566526614958 \n",
      "acc for optim= 0.17464350650293958\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.010182938538491726\n",
      "Loss on test= 0.011377105489373207\n",
      "acc for Lsat= 0.3373931110319164 \n",
      "acc for Psat= 0.21186212015648684 \n",
      "acc for optim= 0.17459739454918438\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.00999591313302517\n",
      "Loss on test= 0.011306635104119778\n",
      "acc for Lsat= 0.2905385153264635 \n",
      "acc for Psat= 0.3106277564333545 \n",
      "acc for optim= 0.18840903140759716\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.010044651105999947\n",
      "Loss on test= 0.01185450330376625\n",
      "acc for Lsat= 0.28121379059222007 \n",
      "acc for Psat= 0.26468643649584717 \n",
      "acc for optim= 0.17359988179264796\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.00997934490442276\n",
      "Loss on test= 0.011421076953411102\n",
      "acc for Lsat= 0.29044097211832803 \n",
      "acc for Psat= 0.39167794005738366 \n",
      "acc for optim= 0.20514771337103513\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.009968952275812626\n",
      "Loss on test= 0.012155858799815178\n",
      "acc for Lsat= 0.33201615548589164 \n",
      "acc for Psat= 0.2641670473644303 \n",
      "acc for optim= 0.21049561698196662\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.010343837551772594\n",
      "Loss on test= 0.010961203835904598\n",
      "acc for Lsat= 0.21966041324453223 \n",
      "acc for Psat= 0.3036391205645891 \n",
      "acc for optim= 0.202850544721716\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.010007387958467007\n",
      "Loss on test= 0.011448731645941734\n",
      "acc for Lsat= 0.2130149095836613 \n",
      "acc for Psat= 0.3105363609114041 \n",
      "acc for optim= 0.1776492287301355\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.00991324707865715\n",
      "Loss on test= 0.012785542756319046\n",
      "acc for Lsat= 0.20471687612330747 \n",
      "acc for Psat= 0.22964862749601403 \n",
      "acc for optim= 0.20665331213321123\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.009921443648636341\n",
      "Loss on test= 0.01132938638329506\n",
      "acc for Lsat= 0.2518632480253776 \n",
      "acc for Psat= 0.22735254836475682 \n",
      "acc for optim= 0.15806541444423297\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.009777030907571316\n",
      "Loss on test= 0.011258500628173351\n",
      "acc for Lsat= 0.3263784142004119 \n",
      "acc for Psat= 0.23833121214475897 \n",
      "acc for optim= 0.19972134210790196\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.009517399594187737\n",
      "Loss on test= 0.01133655197918415\n",
      "acc for Lsat= 0.1985853004993664 \n",
      "acc for Psat= 0.1912773675091254 \n",
      "acc for optim= 0.1793961452009777\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.009336888790130615\n",
      "Loss on test= 0.01164432242512703\n",
      "acc for Lsat= 0.19131733735816348 \n",
      "acc for Psat= 0.23371716229464962 \n",
      "acc for optim= 0.19266413550616968\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.009627001360058784\n",
      "Loss on test= 0.011696972884237766\n",
      "acc for Lsat= 0.27007887662491864 \n",
      "acc for Psat= 0.31026226377839017 \n",
      "acc for optim= 0.20718353567644954\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.009693687781691551\n",
      "Loss on test= 0.0111292265355587\n",
      "acc for Lsat= 0.1679910849262443 \n",
      "acc for Psat= 0.23009556286140448 \n",
      "acc for optim= 0.1444905325770378\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.009304613806307316\n",
      "Loss on test= 0.011220794171094894\n",
      "acc for Lsat= 0.5153681830399566 \n",
      "acc for Psat= 0.22878636026548016 \n",
      "acc for optim= 0.17032636132919127\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.009583557024598122\n",
      "Loss on test= 0.012127143330872059\n",
      "acc for Lsat= 0.24530833933709395 \n",
      "acc for Psat= 0.2762110782269802 \n",
      "acc for optim= 0.176187724502395\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.009265840984880924\n",
      "Loss on test= 0.011776376515626907\n",
      "acc for Lsat= 0.2720861350082689 \n",
      "acc for Psat= 0.19695175594339767 \n",
      "acc for optim= 0.17262074858364132\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.009585737250745296\n",
      "Loss on test= 0.011236739344894886\n",
      "acc for Lsat= 0.16662778653618363 \n",
      "acc for Psat= 0.19959291732973522 \n",
      "acc for optim= 0.16544953513787025\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.009565881453454494\n",
      "Loss on test= 0.011242935433983803\n",
      "acc for Lsat= 0.2923098026723083 \n",
      "acc for Psat= 0.25122840692185694 \n",
      "acc for optim= 0.16040166526929373\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.009671551175415516\n",
      "Loss on test= 0.01202482357621193\n",
      "acc for Lsat= 0.39879920706152916 \n",
      "acc for Psat= 0.2908628907882505 \n",
      "acc for optim= 0.1880507126657499\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.009782793931663036\n",
      "Loss on test= 0.012356780469417572\n",
      "acc for Lsat= 0.4272696404821343 \n",
      "acc for Psat= 0.23984914945645464 \n",
      "acc for optim= 0.19919565138924453\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.009792182594537735\n",
      "Loss on test= 0.010727187618613243\n",
      "acc for Lsat= 0.34879516458345783 \n",
      "acc for Psat= 0.16244940909867486 \n",
      "acc for optim= 0.1999756493088272\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.009171507321298122\n",
      "Loss on test= 0.010805686935782433\n",
      "acc for Lsat= 0.2432374432682991 \n",
      "acc for Psat= 0.19716413833925295 \n",
      "acc for optim= 0.1962253914421631\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.009524091146886349\n",
      "Loss on test= 0.011069768108427525\n",
      "acc for Lsat= 0.18510167812928557 \n",
      "acc for Psat= 0.1764843939907021 \n",
      "acc for optim= 0.18162305896273917\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.009216210804879665\n",
      "Loss on test= 0.010792377404868603\n",
      "acc for Lsat= 0.3618828664637274 \n",
      "acc for Psat= 0.23990490331521463 \n",
      "acc for optim= 0.19999499044691524\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.008835327811539173\n",
      "Loss on test= 0.010691960342228413\n",
      "acc for Lsat= 0.2059855525278383 \n",
      "acc for Psat= 0.33668297591308755 \n",
      "acc for optim= 0.1827019796603256\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.008967697620391846\n",
      "Loss on test= 0.010618549771606922\n",
      "acc for Lsat= 0.27832400395224494 \n",
      "acc for Psat= 0.24852355502338874 \n",
      "acc for optim= 0.15184253043925208\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.008883005939424038\n",
      "Loss on test= 0.010450787842273712\n",
      "acc for Lsat= 0.2608847887151771 \n",
      "acc for Psat= 0.32781724135080975 \n",
      "acc for optim= 0.18646644505982599\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.008891426026821136\n",
      "Loss on test= 0.01049796026200056\n",
      "acc for Lsat= 0.3146548186454715 \n",
      "acc for Psat= 0.21485047525170053 \n",
      "acc for optim= 0.19051177273245734\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.008775911293923855\n",
      "Loss on test= 0.011025124229490757\n",
      "acc for Lsat= 0.2217654601877762 \n",
      "acc for Psat= 0.2392480383730597 \n",
      "acc for optim= 0.19322098366036597\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.00866897776722908\n",
      "Loss on test= 0.010697316378355026\n",
      "acc for Lsat= 0.22255086122701564 \n",
      "acc for Psat= 0.2082583371116521 \n",
      "acc for optim= 0.16144386513365638\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.009044677019119263\n",
      "Loss on test= 0.010320503264665604\n",
      "acc for Lsat= 0.25331608415581286 \n",
      "acc for Psat= 0.20403838757839468 \n",
      "acc for optim= 0.16627666416267553\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.008908675983548164\n",
      "Loss on test= 0.010695272125303745\n",
      "acc for Lsat= 0.24547930744787058 \n",
      "acc for Psat= 0.19397900957200262 \n",
      "acc for optim= 0.17117461282759905\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.008719739504158497\n",
      "Loss on test= 0.011334367096424103\n",
      "acc for Lsat= 0.3371352204897751 \n",
      "acc for Psat= 0.2024014513525698 \n",
      "acc for optim= 0.17307884184022745\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.008862629532814026\n",
      "Loss on test= 0.010838259011507034\n",
      "acc for Lsat= 0.3035249799593455 \n",
      "acc for Psat= 0.2686039199017816 \n",
      "acc for optim= 0.1935023105599814\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.008678681217133999\n",
      "Loss on test= 0.010563565418124199\n",
      "acc for Lsat= 0.2907566223293543 \n",
      "acc for Psat= 0.2419522286185788 \n",
      "acc for optim= 0.1955886003949369\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.008326486684381962\n",
      "Loss on test= 0.010746631771326065\n",
      "acc for Lsat= 0.3222765603309704 \n",
      "acc for Psat= 0.25031651960064966 \n",
      "acc for optim= 0.1916279864963144\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.00862356647849083\n",
      "Loss on test= 0.011042073369026184\n",
      "acc for Lsat= 0.315526887257066 \n",
      "acc for Psat= 0.16210512247764403 \n",
      "acc for optim= 0.15462720316524306\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.008521095849573612\n",
      "Loss on test= 0.010467075742781162\n",
      "acc for Lsat= 0.20157791579711354 \n",
      "acc for Psat= 0.2615857691400581 \n",
      "acc for optim= 0.19244434141243497\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.008047878742218018\n",
      "Loss on test= 0.010266287252306938\n",
      "acc for Lsat= 0.26657506316486335 \n",
      "acc for Psat= 0.22636003549754 \n",
      "acc for optim= 0.18317952814201513\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.007956466637551785\n",
      "Loss on test= 0.00980209931731224\n",
      "acc for Lsat= 0.35513569838884806 \n",
      "acc for Psat= 0.20342535696302852 \n",
      "acc for optim= 0.19228818208729434\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.008389916270971298\n",
      "Loss on test= 0.009740938432514668\n",
      "acc for Lsat= 0.2771125305444002 \n",
      "acc for Psat= 0.21175544320916137 \n",
      "acc for optim= 0.18095362020863426\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.008300310000777245\n",
      "Loss on test= 0.01030869409441948\n",
      "acc for Lsat= 0.22750071705215508 \n",
      "acc for Psat= 0.27403911544630927 \n",
      "acc for optim= 0.18187798691603044\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.00814334861934185\n",
      "Loss on test= 0.010297458618879318\n",
      "acc for Lsat= 0.24428180998398197 \n",
      "acc for Psat= 0.1813063303836518 \n",
      "acc for optim= 0.16024514261355055\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.00796916987746954\n",
      "Loss on test= 0.00969453901052475\n",
      "acc for Lsat= 0.2394605270690388 \n",
      "acc for Psat= 0.24808779715870818 \n",
      "acc for optim= 0.18086636366529596\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.008167502470314503\n",
      "Loss on test= 0.009737951681017876\n",
      "acc for Lsat= 0.2900770878833201 \n",
      "acc for Psat= 0.18896500445488426 \n",
      "acc for optim= 0.20379969984706905\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.00838794931769371\n",
      "Loss on test= 0.009819320403039455\n",
      "acc for Lsat= 0.2724423354698552 \n",
      "acc for Psat= 0.19714790013515288 \n",
      "acc for optim= 0.18785994831058714\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.008270304650068283\n",
      "Loss on test= 0.009273219853639603\n",
      "acc for Lsat= 0.19196577590062386 \n",
      "acc for Psat= 0.21255260049494812 \n",
      "acc for optim= 0.20317503126959005\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.008251690305769444\n",
      "Loss on test= 0.00959179550409317\n",
      "acc for Lsat= 0.1738327835013883 \n",
      "acc for Psat= 0.2104761710183488 \n",
      "acc for optim= 0.18696119276703232\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.007934806868433952\n",
      "Loss on test= 0.009345929138362408\n",
      "acc for Lsat= 0.3058060933318403 \n",
      "acc for Psat= 0.2469334476110008 \n",
      "acc for optim= 0.18315203156736162\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.007763591129332781\n",
      "Loss on test= 0.010218000039458275\n",
      "acc for Lsat= 0.21402792662330386 \n",
      "acc for Psat= 0.23468711780798104 \n",
      "acc for optim= 0.18381888584958184\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.007970345206558704\n",
      "Loss on test= 0.0098575409501791\n",
      "acc for Lsat= 0.17692187273253998 \n",
      "acc for Psat= 0.2685351102716393 \n",
      "acc for optim= 0.1877933417239951\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.00809413380920887\n",
      "Loss on test= 0.010496160015463829\n",
      "acc for Lsat= 0.207948401880761 \n",
      "acc for Psat= 0.22573673787216345 \n",
      "acc for optim= 0.2005269154906273\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.0077638644725084305\n",
      "Loss on test= 0.010147851891815662\n",
      "acc for Lsat= 0.20443760474315947 \n",
      "acc for Psat= 0.2227160800765786 \n",
      "acc for optim= 0.1941646778335174\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.00776618393138051\n",
      "Loss on test= 0.009682062081992626\n",
      "acc for Lsat= 0.16802694065134144 \n",
      "acc for Psat= 0.24568170650551716 \n",
      "acc for optim= 0.17725596441111216\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.007768265437334776\n",
      "Loss on test= 0.00912008062005043\n",
      "acc for Lsat= 0.20087575705515015 \n",
      "acc for Psat= 0.1877302575028605 \n",
      "acc for optim= 0.17174000939768222\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.007868829183280468\n",
      "Loss on test= 0.00990215688943863\n",
      "acc for Lsat= 0.22860927196032005 \n",
      "acc for Psat= 0.21963125255165827 \n",
      "acc for optim= 0.18742342717531654\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.007701462134718895\n",
      "Loss on test= 0.009111437946557999\n",
      "acc for Lsat= 0.20267131461554933 \n",
      "acc for Psat= 0.12378563015307817 \n",
      "acc for optim= 0.18339599586195415\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.007869227789342403\n",
      "Loss on test= 0.009405560791492462\n",
      "acc for Lsat= 0.2587743657123711 \n",
      "acc for Psat= 0.2588993425791462 \n",
      "acc for optim= 0.17684742311636606\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.007449171040207148\n",
      "Loss on test= 0.009494001045823097\n",
      "acc for Lsat= 0.21645512297335598 \n",
      "acc for Psat= 0.2276219831676119 \n",
      "acc for optim= 0.1648327246722248\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.007834652438759804\n",
      "Loss on test= 0.009343489073216915\n",
      "acc for Lsat= 0.21478310325700375 \n",
      "acc for Psat= 0.14138286974694994 \n",
      "acc for optim= 0.16711097381388149\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.007354688830673695\n",
      "Loss on test= 0.009138904511928558\n",
      "acc for Lsat= 0.22486532914141813 \n",
      "acc for Psat= 0.2541324600266914 \n",
      "acc for optim= 0.17895580522923005\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.007364420220255852\n",
      "Loss on test= 0.009495225735008717\n",
      "acc for Lsat= 0.19571717083454132 \n",
      "acc for Psat= 0.3558071048723327 \n",
      "acc for optim= 0.19050243734899494\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.007524383254349232\n",
      "Loss on test= 0.010580611415207386\n",
      "acc for Lsat= 0.1678971990994695 \n",
      "acc for Psat= 0.2835251550293631 \n",
      "acc for optim= 0.18349530785861942\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.007563016843050718\n",
      "Loss on test= 0.008823972195386887\n",
      "acc for Lsat= 0.25314280251041055 \n",
      "acc for Psat= 0.21028264229244087 \n",
      "acc for optim= 0.20158912800252438\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.007633438799530268\n",
      "Loss on test= 0.00934560876339674\n",
      "acc for Lsat= 0.22648823281957042 \n",
      "acc for Psat= 0.16390818724822667 \n",
      "acc for optim= 0.16330838265518346\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.007312295958399773\n",
      "Loss on test= 0.009156506508588791\n",
      "acc for Lsat= 0.24197881441149446 \n",
      "acc for Psat= 0.17922481076998842 \n",
      "acc for optim= 0.1725674600650867\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.0073971436358988285\n",
      "Loss on test= 0.009572985582053661\n",
      "acc for Lsat= 0.15608153792305124 \n",
      "acc for Psat= 0.15533766046994263 \n",
      "acc for optim= 0.17614495423105028\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.007267640437930822\n",
      "Loss on test= 0.009173962287604809\n",
      "acc for Lsat= 0.18495208490639925 \n",
      "acc for Psat= 0.24520728894923297 \n",
      "acc for optim= 0.16648024486170876\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.0074025471694767475\n",
      "Loss on test= 0.00920945405960083\n",
      "acc for Lsat= 0.22886477674668035 \n",
      "acc for Psat= 0.22761459847808713 \n",
      "acc for optim= 0.19509816676792172\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.007389978040009737\n",
      "Loss on test= 0.008975295349955559\n",
      "acc for Lsat= 0.20763670280575752 \n",
      "acc for Psat= 0.25335818860265946 \n",
      "acc for optim= 0.1850110757061177\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.0071954806335270405\n",
      "Loss on test= 0.008875265717506409\n",
      "acc for Lsat= 0.2092843938411938 \n",
      "acc for Psat= 0.20571143542312914 \n",
      "acc for optim= 0.19575872779306439\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.007438525557518005\n",
      "Loss on test= 0.00878627598285675\n",
      "acc for Lsat= 0.17083358826736608 \n",
      "acc for Psat= 0.19837165142719945 \n",
      "acc for optim= 0.19332444784231484\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.007228098809719086\n",
      "Loss on test= 0.009161558002233505\n",
      "acc for Lsat= 0.15187717798269457 \n",
      "acc for Psat= 0.23946552195896706 \n",
      "acc for optim= 0.2043305459535784\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.0071247294545173645\n",
      "Loss on test= 0.009536255151033401\n",
      "acc for Lsat= 0.1634043655746306 \n",
      "acc for Psat= 0.23656530160870817 \n",
      "acc for optim= 0.20336815394047233\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.0070257652550935745\n",
      "Loss on test= 0.009255778044462204\n",
      "acc for Lsat= 0.16665936530464226 \n",
      "acc for Psat= 0.18749710876080725 \n",
      "acc for optim= 0.19887538619029024\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.00704571045935154\n",
      "Loss on test= 0.008855498395860195\n",
      "acc for Lsat= 0.2153614710809456 \n",
      "acc for Psat= 0.21063428604975343 \n",
      "acc for optim= 0.18258596853249603\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.007135679945349693\n",
      "Loss on test= 0.009126691147685051\n",
      "acc for Lsat= 0.24280034212602508 \n",
      "acc for Psat= 0.18900358200901085 \n",
      "acc for optim= 0.15412338036629888\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.0070489137433469296\n",
      "Loss on test= 0.00940518919378519\n",
      "acc for Lsat= 0.12296598172462028 \n",
      "acc for Psat= 0.1536622997890744 \n",
      "acc for optim= 0.19039633419985572\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.006943396758288145\n",
      "Loss on test= 0.00861017033457756\n",
      "acc for Lsat= 0.17650221565013957 \n",
      "acc for Psat= 0.17627543066110876 \n",
      "acc for optim= 0.18149102665483952\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.006988415028899908\n",
      "Loss on test= 0.008549924939870834\n",
      "acc for Lsat= 0.21322677688052258 \n",
      "acc for Psat= 0.13460868758071834 \n",
      "acc for optim= 0.18304249846066037\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.0070113809779286385\n",
      "Loss on test= 0.008248926140367985\n",
      "acc for Lsat= 0.16859699082043436 \n",
      "acc for Psat= 0.2025952080471648 \n",
      "acc for optim= 0.17847675742167565\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.007246780209243298\n",
      "Loss on test= 0.008278985507786274\n",
      "acc for Lsat= 0.16369104297417733 \n",
      "acc for Psat= 0.20949145495251287 \n",
      "acc for optim= 0.16220102769633135\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.0071715000085532665\n",
      "Loss on test= 0.008343067951500416\n",
      "acc for Lsat= 0.22542682973047098 \n",
      "acc for Psat= 0.17178842487434545 \n",
      "acc for optim= 0.1956324346570505\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.00700724683701992\n",
      "Loss on test= 0.008960123173892498\n",
      "acc for Lsat= 0.14494193779925504 \n",
      "acc for Psat= 0.26198185266306 \n",
      "acc for optim= 0.18964047812753254\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.006925538182258606\n",
      "Loss on test= 0.008733388967812061\n",
      "acc for Lsat= 0.16772002649183074 \n",
      "acc for Psat= 0.21047169686709014 \n",
      "acc for optim= 0.1894388356142574\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.007144323084503412\n",
      "Loss on test= 0.008921314962208271\n",
      "acc for Lsat= 0.18492650830497345 \n",
      "acc for Psat= 0.2185510205001467 \n",
      "acc for optim= 0.17742892657487472\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.006879718974232674\n",
      "Loss on test= 0.008654329925775528\n",
      "acc for Lsat= 0.19231266357625523 \n",
      "acc for Psat= 0.2775642012970315 \n",
      "acc for optim= 0.18696200682057273\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.006681664381176233\n",
      "Loss on test= 0.0086356271058321\n",
      "acc for Lsat= 0.14675161382183433 \n",
      "acc for Psat= 0.2348347290729483 \n",
      "acc for optim= 0.16787460384269556\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.006761645898222923\n",
      "Loss on test= 0.008271971717476845\n",
      "acc for Lsat= 0.16085229519133767 \n",
      "acc for Psat= 0.1539374219201919 \n",
      "acc for optim= 0.1836964963003993\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.0068917484022676945\n",
      "Loss on test= 0.008293231017887592\n",
      "acc for Lsat= 0.1885545284797748 \n",
      "acc for Psat= 0.2014897707849741 \n",
      "acc for optim= 0.1689952935040411\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.006601531989872456\n",
      "Loss on test= 0.00892531219869852\n",
      "acc for Lsat= 0.14761320372215575 \n",
      "acc for Psat= 0.18513646804624134 \n",
      "acc for optim= 0.18001855423467028\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.007028898224234581\n",
      "Loss on test= 0.008786095306277275\n",
      "acc for Lsat= 0.2835433083689875 \n",
      "acc for Psat= 0.24328086773554483 \n",
      "acc for optim= 0.18033998107744587\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.006756245624274015\n",
      "Loss on test= 0.008779531344771385\n",
      "acc for Lsat= 0.13130428188014776 \n",
      "acc for Psat= 0.17028812619133127 \n",
      "acc for optim= 0.15207827060172954\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.006965769454836845\n",
      "Loss on test= 0.00849002692848444\n",
      "acc for Lsat= 0.23515210818085405 \n",
      "acc for Psat= 0.15472048345125383 \n",
      "acc for optim= 0.19458095980290738\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.006671395618468523\n",
      "Loss on test= 0.008886394090950489\n",
      "acc for Lsat= 0.1813337372408973 \n",
      "acc for Psat= 0.17036973255582982 \n",
      "acc for optim= 0.16773733853672942\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.006555257830768824\n",
      "Loss on test= 0.008510980755090714\n",
      "acc for Lsat= 0.16494545067123706 \n",
      "acc for Psat= 0.25888457770148915 \n",
      "acc for optim= 0.180973539646301\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.00691842008382082\n",
      "Loss on test= 0.009109972044825554\n",
      "acc for Lsat= 0.1775915737056898 \n",
      "acc for Psat= 0.184181118151173 \n",
      "acc for optim= 0.18223528465670016\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.0065435487776994705\n",
      "Loss on test= 0.008278376422822475\n",
      "acc for Lsat= 0.2033794254788922 \n",
      "acc for Psat= 0.15809192842183015 \n",
      "acc for optim= 0.15772422414738685\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.006655069068074226\n",
      "Loss on test= 0.008282658644020557\n",
      "acc for Lsat= 0.22713414297646117 \n",
      "acc for Psat= 0.1391793036212524 \n",
      "acc for optim= 0.22516050284159267\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.0068884980864822865\n",
      "Loss on test= 0.008465285412967205\n",
      "acc for Lsat= 0.24354094207390314 \n",
      "acc for Psat= 0.11585952501950993 \n",
      "acc for optim= 0.18577932481033108\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.006726600229740143\n",
      "Loss on test= 0.008472626097500324\n",
      "acc for Lsat= 0.13708400250309044 \n",
      "acc for Psat= 0.11036260591612922 \n",
      "acc for optim= 0.1803916207411223\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.006598226260393858\n",
      "Loss on test= 0.008436450734734535\n",
      "acc for Lsat= 0.17392686751878095 \n",
      "acc for Psat= 0.2624110892001126 \n",
      "acc for optim= 0.18391092421693933\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.006410236936062574\n",
      "Loss on test= 0.008379343897104263\n",
      "acc for Lsat= 0.1938504204671416 \n",
      "acc for Psat= 0.17897874598080912 \n",
      "acc for optim= 0.16914743097085091\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.0064149899408221245\n",
      "Loss on test= 0.007794419303536415\n",
      "acc for Lsat= 0.19170236287431586 \n",
      "acc for Psat= 0.1706476252002176 \n",
      "acc for optim= 0.179425077047199\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.0064927623607218266\n",
      "Loss on test= 0.008143030107021332\n",
      "acc for Lsat= 0.20462107554905945 \n",
      "acc for Psat= 0.2347570245878564 \n",
      "acc for optim= 0.17793513110114467\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.006412214133888483\n",
      "Loss on test= 0.007978253997862339\n",
      "acc for Lsat= 0.23504599794331524 \n",
      "acc for Psat= 0.1464480249107712 \n",
      "acc for optim= 0.15401451641486752\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.006453999783843756\n",
      "Loss on test= 0.008656702935695648\n",
      "acc for Lsat= 0.21053295916256806 \n",
      "acc for Psat= 0.25031169435098694 \n",
      "acc for optim= 0.17808039031094974\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.00644819438457489\n",
      "Loss on test= 0.008748572319746017\n",
      "acc for Lsat= 0.21503467588788933 \n",
      "acc for Psat= 0.25881929964654976 \n",
      "acc for optim= 0.20195828209398314\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.006397168152034283\n",
      "Loss on test= 0.008093067444860935\n",
      "acc for Lsat= 0.20123739093024698 \n",
      "acc for Psat= 0.20032842845345536 \n",
      "acc for optim= 0.15890894623266327\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.006429336499422789\n",
      "Loss on test= 0.007974263280630112\n",
      "acc for Lsat= 0.1332088196132746 \n",
      "acc for Psat= 0.2042201514252358 \n",
      "acc for optim= 0.1692113366184963\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.006375720724463463\n",
      "Loss on test= 0.008481087163090706\n",
      "acc for Lsat= 0.16261067469086912 \n",
      "acc for Psat= 0.15761300581248683 \n",
      "acc for optim= 0.16296794663907754\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.006328532472252846\n",
      "Loss on test= 0.008143317885696888\n",
      "acc for Lsat= 0.19564367225393653 \n",
      "acc for Psat= 0.21912881007624996 \n",
      "acc for optim= 0.1735915003551377\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.006391135975718498\n",
      "Loss on test= 0.007947256788611412\n",
      "acc for Lsat= 0.14575618779700664 \n",
      "acc for Psat= 0.14205522323027253 \n",
      "acc for optim= 0.1840361893797914\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.006208151113241911\n",
      "Loss on test= 0.00806375127285719\n",
      "acc for Lsat= 0.15631173442428312 \n",
      "acc for Psat= 0.17896934339983595 \n",
      "acc for optim= 0.17267088850753176\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.006309213116765022\n",
      "Loss on test= 0.007434841711074114\n",
      "acc for Lsat= 0.2274562581959698 \n",
      "acc for Psat= 0.2271877850095431 \n",
      "acc for optim= 0.17514333610112467\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.006238177418708801\n",
      "Loss on test= 0.008158138021826744\n",
      "acc for Lsat= 0.12966498678886434 \n",
      "acc for Psat= 0.17771063125999514 \n",
      "acc for optim= 0.1860141323154999\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.006446048151701689\n",
      "Loss on test= 0.007182458881288767\n",
      "acc for Lsat= 0.20375220115400022 \n",
      "acc for Psat= 0.17292787002710006 \n",
      "acc for optim= 0.1767137414879269\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.0061419191770255566\n",
      "Loss on test= 0.00808374211192131\n",
      "acc for Lsat= 0.1461943673590819 \n",
      "acc for Psat= 0.15219533733195728 \n",
      "acc for optim= 0.17121803977837166\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.006115807220339775\n",
      "Loss on test= 0.00783570483326912\n",
      "acc for Lsat= 0.17319241466207635 \n",
      "acc for Psat= 0.18422888974762625 \n",
      "acc for optim= 0.17181002245181137\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.006390710361301899\n",
      "Loss on test= 0.008479943498969078\n",
      "acc for Lsat= 0.13746284941832224 \n",
      "acc for Psat= 0.1953941055883964 \n",
      "acc for optim= 0.1622304525743756\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.0063974857330322266\n",
      "Loss on test= 0.008232759311795235\n",
      "acc for Lsat= 0.16838192929410273 \n",
      "acc for Psat= 0.2257638397730059 \n",
      "acc for optim= 0.17435943612104488\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.006291468162089586\n",
      "Loss on test= 0.008273957297205925\n",
      "acc for Lsat= 0.18715250305831432 \n",
      "acc for Psat= 0.13860832859710273 \n",
      "acc for optim= 0.16405266042177877\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.006209361832588911\n",
      "Loss on test= 0.008565918542444706\n",
      "acc for Lsat= 0.12909338675025436 \n",
      "acc for Psat= 0.1744476032909006 \n",
      "acc for optim= 0.16699853477378687\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.006396233569830656\n",
      "Loss on test= 0.007372891064733267\n",
      "acc for Lsat= 0.14477476943284273 \n",
      "acc for Psat= 0.14719059729638198 \n",
      "acc for optim= 0.1589653908740729\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.005995242390781641\n",
      "Loss on test= 0.007719745859503746\n",
      "acc for Lsat= 0.23817907431576815 \n",
      "acc for Psat= 0.1831743550590343 \n",
      "acc for optim= 0.17999134031641814\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.006114402320235968\n",
      "Loss on test= 0.007464232388883829\n",
      "acc for Lsat= 0.1831007878192597 \n",
      "acc for Psat= 0.14314576000389126 \n",
      "acc for optim= 0.16864264937531617\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.006264817900955677\n",
      "Loss on test= 0.0077126165851950645\n",
      "acc for Lsat= 0.11043147659964031 \n",
      "acc for Psat= 0.11863650218583643 \n",
      "acc for optim= 0.15015144920390514\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.005977941676974297\n",
      "Loss on test= 0.0074480026960372925\n",
      "acc for Lsat= 0.1737093149115228 \n",
      "acc for Psat= 0.17188004047299424 \n",
      "acc for optim= 0.1901270545915597\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.005974051542580128\n",
      "Loss on test= 0.007849174551665783\n",
      "acc for Lsat= 0.17409578421049648 \n",
      "acc for Psat= 0.1677736977322234 \n",
      "acc for optim= 0.17654604454421335\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.00584886409342289\n",
      "Loss on test= 0.0076067172922194\n",
      "acc for Lsat= 0.15235345034549633 \n",
      "acc for Psat= 0.1973363778864344 \n",
      "acc for optim= 0.13585982858462053\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.006163035519421101\n",
      "Loss on test= 0.007798376958817244\n",
      "acc for Lsat= 0.14310264465813008 \n",
      "acc for Psat= 0.21975520504121152 \n",
      "acc for optim= 0.16349146119318902\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.006098026409745216\n",
      "Loss on test= 0.007572811562567949\n",
      "acc for Lsat= 0.17983619009868967 \n",
      "acc for Psat= 0.1835796151491296 \n",
      "acc for optim= 0.18313204238398206\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.0060408636927604675\n",
      "Loss on test= 0.007643930613994598\n",
      "acc for Lsat= 0.14564795216493723 \n",
      "acc for Psat= 0.1388612512188653 \n",
      "acc for optim= 0.17245508435492715\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.0058236983604729176\n",
      "Loss on test= 0.007152635138481855\n",
      "acc for Lsat= 0.16524373926222324 \n",
      "acc for Psat= 0.20047837951117092 \n",
      "acc for optim= 0.1707500723294086\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.0060486700385808945\n",
      "Loss on test= 0.007780750747770071\n",
      "acc for Lsat= 0.17237240081239077 \n",
      "acc for Psat= 0.1447839369583461 \n",
      "acc for optim= 0.1579136004179923\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.005961982533335686\n",
      "Loss on test= 0.007081233896315098\n",
      "acc for Lsat= 0.13101525580148315 \n",
      "acc for Psat= 0.14383308092753092 \n",
      "acc for optim= 0.16369493137527671\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.006007324438542128\n",
      "Loss on test= 0.007366098463535309\n",
      "acc for Lsat= 0.1457001098121206 \n",
      "acc for Psat= 0.1411009891760639 \n",
      "acc for optim= 0.17583178935779464\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.006278457120060921\n",
      "Loss on test= 0.007854833267629147\n",
      "acc for Lsat= 0.17028222967767054 \n",
      "acc for Psat= 0.26539935678657556 \n",
      "acc for optim= 0.19439442155675757\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.0060571059584617615\n",
      "Loss on test= 0.007928200997412205\n",
      "acc for Lsat= 0.17643945824561846 \n",
      "acc for Psat= 0.15754978907191092 \n",
      "acc for optim= 0.16393973083338803\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.00597405293956399\n",
      "Loss on test= 0.008129175752401352\n",
      "acc for Lsat= 0.19825593351076046 \n",
      "acc for Psat= 0.19614642372147906 \n",
      "acc for optim= 0.18322126171551645\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.005908092483878136\n",
      "Loss on test= 0.007822823710739613\n",
      "acc for Lsat= 0.17716037383716968 \n",
      "acc for Psat= 0.13226777698016828 \n",
      "acc for optim= 0.15954533560822406\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.006193757522851229\n",
      "Loss on test= 0.008585349656641483\n",
      "acc for Lsat= 0.24008424911234114 \n",
      "acc for Psat= 0.19168238724685377 \n",
      "acc for optim= 0.16201452507327\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.005729221273213625\n",
      "Loss on test= 0.007720621768385172\n",
      "acc for Lsat= 0.2016457673162222 \n",
      "acc for Psat= 0.19471844730691779 \n",
      "acc for optim= 0.15639269227782884\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.0058735441416502\n",
      "Loss on test= 0.007361563388258219\n",
      "acc for Lsat= 0.13987493825455508 \n",
      "acc for Psat= 0.17183549288246366 \n",
      "acc for optim= 0.17791576000551382\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.005755902733653784\n",
      "Loss on test= 0.007214764133095741\n",
      "acc for Lsat= 0.1378071748962005 \n",
      "acc for Psat= 0.1960871421938969 \n",
      "acc for optim= 0.16757395387523705\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.006086986977607012\n",
      "Loss on test= 0.007647981867194176\n",
      "acc for Lsat= 0.2050501255111562 \n",
      "acc for Psat= 0.16068152736665475 \n",
      "acc for optim= 0.1618410765659064\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.006021449342370033\n",
      "Loss on test= 0.008095990866422653\n",
      "acc for Lsat= 0.14850715909981066 \n",
      "acc for Psat= 0.1871915300273233 \n",
      "acc for optim= 0.1699155647980256\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.005800384096801281\n",
      "Loss on test= 0.007920484989881516\n",
      "acc for Lsat= 0.1281469918580519 \n",
      "acc for Psat= 0.21972758964531952 \n",
      "acc for optim= 0.16690341812661952\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.005752119235694408\n",
      "Loss on test= 0.007513228338211775\n",
      "acc for Lsat= 0.13678415353772128 \n",
      "acc for Psat= 0.20488570304587483 \n",
      "acc for optim= 0.14093177388551542\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.005740778520703316\n",
      "Loss on test= 0.0076315198093652725\n",
      "acc for Lsat= 0.1635079140154024 \n",
      "acc for Psat= 0.2129512159153819 \n",
      "acc for optim= 0.1816064642690536\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.00576549069955945\n",
      "Loss on test= 0.007681124843657017\n",
      "acc for Lsat= 0.14843652987231812 \n",
      "acc for Psat= 0.19860264498533475 \n",
      "acc for optim= 0.16231422995527586\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.005922989919781685\n",
      "Loss on test= 0.008004611358046532\n",
      "acc for Lsat= 0.15048294943860835 \n",
      "acc for Psat= 0.26437092806574786 \n",
      "acc for optim= 0.15811954888825616\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.00546425674110651\n",
      "Loss on test= 0.007328776642680168\n",
      "acc for Lsat= 0.1286498742798964 \n",
      "acc for Psat= 0.1363331276224926 \n",
      "acc for optim= 0.15471982133264342\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.005740786902606487\n",
      "Loss on test= 0.007158834952861071\n",
      "acc for Lsat= 0.13116509513929486 \n",
      "acc for Psat= 0.16212521666764385 \n",
      "acc for optim= 0.16307897079322073\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.005800560116767883\n",
      "Loss on test= 0.007421708665788174\n",
      "acc for Lsat= 0.1307714254491859 \n",
      "acc for Psat= 0.24369053351175454 \n",
      "acc for optim= 0.17945891921408474\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.005914910230785608\n",
      "Loss on test= 0.007511546835303307\n",
      "acc for Lsat= 0.1429002382275131 \n",
      "acc for Psat= 0.1725620207273298 \n",
      "acc for optim= 0.16710504392782846\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.005791765172034502\n",
      "Loss on test= 0.007146117743104696\n",
      "acc for Lsat= 0.19689975741008917 \n",
      "acc for Psat= 0.1378061253991392 \n",
      "acc for optim= 0.1688382646275891\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.0057615311816334724\n",
      "Loss on test= 0.006858854554593563\n",
      "acc for Lsat= 0.16354924323645215 \n",
      "acc for Psat= 0.16738936377482283 \n",
      "acc for optim= 0.16373604386010104\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.005551491864025593\n",
      "Loss on test= 0.0069636511616408825\n",
      "acc for Lsat= 0.15683008222064623 \n",
      "acc for Psat= 0.20933748647156689 \n",
      "acc for optim= 0.15531884940961996\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.005606565158814192\n",
      "Loss on test= 0.007211291231215\n",
      "acc for Lsat= 0.16367421568267876 \n",
      "acc for Psat= 0.13496410057673025 \n",
      "acc for optim= 0.14977517962041828\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.005778432358056307\n",
      "Loss on test= 0.007184539455920458\n",
      "acc for Lsat= 0.15131863661291492 \n",
      "acc for Psat= 0.19606082369056013 \n",
      "acc for optim= 0.173765549953613\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.005629794672131538\n",
      "Loss on test= 0.007079582195729017\n",
      "acc for Lsat= 0.11673820435599838 \n",
      "acc for Psat= 0.16573739267833945 \n",
      "acc for optim= 0.15878764229516187\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.005721458699554205\n",
      "Loss on test= 0.0076962728053331375\n",
      "acc for Lsat= 0.12814059430578104 \n",
      "acc for Psat= 0.16623690988247594 \n",
      "acc for optim= 0.17270341189578176\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.0057573202066123486\n",
      "Loss on test= 0.006995188072323799\n",
      "acc for Lsat= 0.12943743210699823 \n",
      "acc for Psat= 0.1507335411410572 \n",
      "acc for optim= 0.15023459848533902\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.005532382987439632\n",
      "Loss on test= 0.00722616259008646\n",
      "acc for Lsat= 0.19208056637499896 \n",
      "acc for Psat= 0.19843629160378543 \n",
      "acc for optim= 0.14986436845113835\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.005661408882588148\n",
      "Loss on test= 0.007247664965689182\n",
      "acc for Lsat= 0.22341526890846175 \n",
      "acc for Psat= 0.15638376927624145 \n",
      "acc for optim= 0.17833957034680578\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.005593054462224245\n",
      "Loss on test= 0.0072715748101472855\n",
      "acc for Lsat= 0.14541752003586023 \n",
      "acc for Psat= 0.1991166377750536 \n",
      "acc for optim= 0.1693992155422974\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.005563583690673113\n",
      "Loss on test= 0.007229481358081102\n",
      "acc for Lsat= 0.1058137800751461 \n",
      "acc for Psat= 0.12671456784786037 \n",
      "acc for optim= 0.15951765099695572\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.005576584488153458\n",
      "Loss on test= 0.007138320244848728\n",
      "acc for Lsat= 0.13500192290585902 \n",
      "acc for Psat= 0.16285206455116472 \n",
      "acc for optim= 0.1607350679114461\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.005491382908076048\n",
      "Loss on test= 0.007155237719416618\n",
      "acc for Lsat= 0.17245089997433954 \n",
      "acc for Psat= 0.15210373107240432 \n",
      "acc for optim= 0.16787092056539324\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.005543097387999296\n",
      "Loss on test= 0.006901030894368887\n",
      "acc for Lsat= 0.16704594545687237 \n",
      "acc for Psat= 0.1256196025836592 \n",
      "acc for optim= 0.2130575031042099\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.005554040428251028\n",
      "Loss on test= 0.007027441635727882\n",
      "acc for Lsat= 0.16728526850541434 \n",
      "acc for Psat= 0.21382537520387107 \n",
      "acc for optim= 0.16311113205220965\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.00552788283675909\n",
      "Loss on test= 0.007321154698729515\n",
      "acc for Lsat= 0.11028627192394601 \n",
      "acc for Psat= 0.16201135847303602 \n",
      "acc for optim= 0.16605706722475588\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.005572174210101366\n",
      "Loss on test= 0.00738099729642272\n",
      "acc for Lsat= 0.15534381665444622 \n",
      "acc for Psat= 0.1656477565993555 \n",
      "acc for optim= 0.14194452465097937\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.005458954256027937\n",
      "Loss on test= 0.006909409072250128\n",
      "acc for Lsat= 0.17734097779935432 \n",
      "acc for Psat= 0.1614294886175129 \n",
      "acc for optim= 0.17542713306223354\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.005620575975626707\n",
      "Loss on test= 0.007116541266441345\n",
      "acc for Lsat= 0.14140535120127928 \n",
      "acc for Psat= 0.11464408971369267 \n",
      "acc for optim= 0.13853071896462804\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.0054389433935284615\n",
      "Loss on test= 0.007409123238176107\n",
      "acc for Lsat= 0.1464604709504379 \n",
      "acc for Psat= 0.14942731128798592 \n",
      "acc for optim= 0.18556016876310524\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.005561394616961479\n",
      "Loss on test= 0.007096284069120884\n",
      "acc for Lsat= 0.139528455109232 \n",
      "acc for Psat= 0.16147710548506844 \n",
      "acc for optim= 0.16426492751472527\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.005443606059998274\n",
      "Loss on test= 0.006985184270888567\n",
      "acc for Lsat= 0.17834122334089544 \n",
      "acc for Psat= 0.14407005664219874 \n",
      "acc for optim= 0.16358680226322678\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.005306081846356392\n",
      "Loss on test= 0.007538361009210348\n",
      "acc for Lsat= 0.21908775634235805 \n",
      "acc for Psat= 0.24853716252578628 \n",
      "acc for optim= 0.1764397719461057\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.00571153499186039\n",
      "Loss on test= 0.0075859185308218\n",
      "acc for Lsat= 0.1886212042429381 \n",
      "acc for Psat= 0.2331338388224443 \n",
      "acc for optim= 0.12425198768162066\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.005452780053019524\n",
      "Loss on test= 0.0070162247866392136\n",
      "acc for Lsat= 0.13584169869621596 \n",
      "acc for Psat= 0.149981295896901 \n",
      "acc for optim= 0.13636727233986473\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.005501816980540752\n",
      "Loss on test= 0.007136817555874586\n",
      "acc for Lsat= 0.19060509093105793 \n",
      "acc for Psat= 0.1372870169321282 \n",
      "acc for optim= 0.17730032549136215\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.0053955367766320705\n",
      "Loss on test= 0.006853701546788216\n",
      "acc for Lsat= 0.19528871464232603 \n",
      "acc for Psat= 0.19223714302966577 \n",
      "acc for optim= 0.1536132108627094\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.005374166648834944\n",
      "Loss on test= 0.007616768125444651\n",
      "acc for Lsat= 0.18700745049864054 \n",
      "acc for Psat= 0.14497021885795724 \n",
      "acc for optim= 0.19809446127773198\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.005224545486271381\n",
      "Loss on test= 0.0067557524889707565\n",
      "acc for Lsat= 0.12794022417316833 \n",
      "acc for Psat= 0.21798001923080948 \n",
      "acc for optim= 0.18196289453448522\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.005527742672711611\n",
      "Loss on test= 0.00728603033348918\n",
      "acc for Lsat= 0.2052065007802513 \n",
      "acc for Psat= 0.16303736589745516 \n",
      "acc for optim= 0.17476665638645905\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.005516960751265287\n",
      "Loss on test= 0.0070664118975400925\n",
      "acc for Lsat= 0.15802806119124094 \n",
      "acc for Psat= 0.133345319216864 \n",
      "acc for optim= 0.19166951062571672\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.005304447840899229\n",
      "Loss on test= 0.007335712667554617\n",
      "acc for Lsat= 0.08848909736197028 \n",
      "acc for Psat= 0.12477658570019735 \n",
      "acc for optim= 0.13965802466393346\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.005364050157368183\n",
      "Loss on test= 0.007092502433806658\n",
      "acc for Lsat= 0.12963649210157907 \n",
      "acc for Psat= 0.28653154853317475 \n",
      "acc for optim= 0.1647262790162737\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.0054293605498969555\n",
      "Loss on test= 0.007502482272684574\n",
      "acc for Lsat= 0.11291604106211 \n",
      "acc for Psat= 0.1728537374486526 \n",
      "acc for optim= 0.14863684783146405\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.005303379613906145\n",
      "Loss on test= 0.007015745621174574\n",
      "acc for Lsat= 0.14295395541315278 \n",
      "acc for Psat= 0.1479998216446903 \n",
      "acc for optim= 0.14083047412956753\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.005214654374867678\n",
      "Loss on test= 0.006891947239637375\n",
      "acc for Lsat= 0.16182985154834265 \n",
      "acc for Psat= 0.11953251311529635 \n",
      "acc for optim= 0.16552780726407137\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.005163125693798065\n",
      "Loss on test= 0.006822388619184494\n",
      "acc for Lsat= 0.16055482668646923 \n",
      "acc for Psat= 0.18815010961973005 \n",
      "acc for optim= 0.1801205573655251\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.005220423918217421\n",
      "Loss on test= 0.00685439957305789\n",
      "acc for Lsat= 0.13754886109381914 \n",
      "acc for Psat= 0.1311326197658976 \n",
      "acc for optim= 0.1567015819794809\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.005344494711607695\n",
      "Loss on test= 0.007230783347040415\n",
      "acc for Lsat= 0.15101942241502306 \n",
      "acc for Psat= 0.14301321146679888 \n",
      "acc for optim= 0.16044243000861672\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.0052566323429346085\n",
      "Loss on test= 0.0068977102637290955\n",
      "acc for Lsat= 0.15482245970310438 \n",
      "acc for Psat= 0.12991323534192312 \n",
      "acc for optim= 0.15119466519293687\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.005302671808749437\n",
      "Loss on test= 0.0081184646114707\n",
      "acc for Lsat= 0.158600986107356 \n",
      "acc for Psat= 0.22730220541901267 \n",
      "acc for optim= 0.15019161476650172\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.005285417195409536\n",
      "Loss on test= 0.007025856990367174\n",
      "acc for Lsat= 0.19096421864297655 \n",
      "acc for Psat= 0.13860045138022137 \n",
      "acc for optim= 0.15768986371242338\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.005419716238975525\n",
      "Loss on test= 0.0070896935649216175\n",
      "acc for Lsat= 0.13381039009739956 \n",
      "acc for Psat= 0.14527850626553926 \n",
      "acc for optim= 0.15372287114668223\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.00532497838139534\n",
      "Loss on test= 0.006849775556474924\n",
      "acc for Lsat= 0.1705924842454907 \n",
      "acc for Psat= 0.15351988478667206 \n",
      "acc for optim= 0.1683875745576289\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.00517180236056447\n",
      "Loss on test= 0.006892850622534752\n",
      "acc for Lsat= 0.1333049794452058 \n",
      "acc for Psat= 0.1359549444168806 \n",
      "acc for optim= 0.14709512645883174\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.005302928388118744\n",
      "Loss on test= 0.007441642228513956\n",
      "acc for Lsat= 0.11626772980930077 \n",
      "acc for Psat= 0.14820570240004194 \n",
      "acc for optim= 0.16853700226379764\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.005208936054259539\n",
      "Loss on test= 0.007058890536427498\n",
      "acc for Lsat= 0.1383503730693418 \n",
      "acc for Psat= 0.07636224147346285 \n",
      "acc for optim= 0.16340950084850192\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.005382183473557234\n",
      "Loss on test= 0.007311186753213406\n",
      "acc for Lsat= 0.15822042390290234 \n",
      "acc for Psat= 0.16446975944563746 \n",
      "acc for optim= 0.15781563512670496\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.005268843844532967\n",
      "Loss on test= 0.007037091534584761\n",
      "acc for Lsat= 0.11857827421691683 \n",
      "acc for Psat= 0.22010719465712705 \n",
      "acc for optim= 0.16778760413742727\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.005103248171508312\n",
      "Loss on test= 0.007130580488592386\n",
      "acc for Lsat= 0.1421067456378498 \n",
      "acc for Psat= 0.19624198471299475 \n",
      "acc for optim= 0.18123989645391703\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.00518525717779994\n",
      "Loss on test= 0.007158500608056784\n",
      "acc for Lsat= 0.134065547815731 \n",
      "acc for Psat= 0.19204029089046848 \n",
      "acc for optim= 0.1812019520956609\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.005243736784905195\n",
      "Loss on test= 0.007478207349777222\n",
      "acc for Lsat= 0.12459843647148874 \n",
      "acc for Psat= 0.18242731731798914 \n",
      "acc for optim= 0.1768571538850665\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.005042677279561758\n",
      "Loss on test= 0.006933932192623615\n",
      "acc for Lsat= 0.1401873551949393 \n",
      "acc for Psat= 0.17457487691556 \n",
      "acc for optim= 0.1631089466649832\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.005223301239311695\n",
      "Loss on test= 0.0069155446253716946\n",
      "acc for Lsat= 0.1207959505263716 \n",
      "acc for Psat= 0.139639670546684 \n",
      "acc for optim= 0.15195952049380898\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.00518723763525486\n",
      "Loss on test= 0.006326206028461456\n",
      "acc for Lsat= 0.12526063491370426 \n",
      "acc for Psat= 0.18791780858818027 \n",
      "acc for optim= 0.14585883730453336\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.00494930287823081\n",
      "Loss on test= 0.006810779683291912\n",
      "acc for Lsat= 0.1223562608485938 \n",
      "acc for Psat= 0.18540421966463327 \n",
      "acc for optim= 0.16482340741074747\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.005055483430624008\n",
      "Loss on test= 0.0068512121215462685\n",
      "acc for Lsat= 0.1447252199674646 \n",
      "acc for Psat= 0.14137777344634136 \n",
      "acc for optim= 0.17358555534802791\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.005035727750509977\n",
      "Loss on test= 0.0067996857687830925\n",
      "acc for Lsat= 0.11756277327529258 \n",
      "acc for Psat= 0.09695136813550359 \n",
      "acc for optim= 0.15431655561001711\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.004945436026901007\n",
      "Loss on test= 0.006447708699852228\n",
      "acc for Lsat= 0.11422656735198365 \n",
      "acc for Psat= 0.1692657677663697 \n",
      "acc for optim= 0.1613901379621691\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.005113556049764156\n",
      "Loss on test= 0.00654100626707077\n",
      "acc for Lsat= 0.11860120325076827 \n",
      "acc for Psat= 0.14826316725359195 \n",
      "acc for optim= 0.1723537180158827\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.004966890439391136\n",
      "Loss on test= 0.006736988201737404\n",
      "acc for Lsat= 0.13766731070871982 \n",
      "acc for Psat= 0.1346242794663542 \n",
      "acc for optim= 0.1858941790026923\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.005048656836152077\n",
      "Loss on test= 0.00735645554959774\n",
      "acc for Lsat= 0.1358248862541384 \n",
      "acc for Psat= 0.14447072396675745 \n",
      "acc for optim= 0.1526297041046847\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.005015142727643251\n",
      "Loss on test= 0.006886184215545654\n",
      "acc for Lsat= 0.1468354971665475 \n",
      "acc for Psat= 0.16681344196614292 \n",
      "acc for optim= 0.17026365879509184\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.005019315052777529\n",
      "Loss on test= 0.007134464103728533\n",
      "acc for Lsat= 0.10589499957859516 \n",
      "acc for Psat= 0.12267851312127379 \n",
      "acc for optim= 0.1686278946387271\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.00503626698628068\n",
      "Loss on test= 0.006796359084546566\n",
      "acc for Lsat= 0.1655374974426296 \n",
      "acc for Psat= 0.1684513252435459 \n",
      "acc for optim= 0.1599979717672492\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.00496521545574069\n",
      "Loss on test= 0.007225215435028076\n",
      "acc for Lsat= 0.1744865243219667 \n",
      "acc for Psat= 0.12151470661370291 \n",
      "acc for optim= 0.15762647578958422\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.005166301503777504\n",
      "Loss on test= 0.006643139291554689\n",
      "acc for Lsat= 0.1377235595136881 \n",
      "acc for Psat= 0.2047010835311893 \n",
      "acc for optim= 0.16397522585207802\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.005064757540822029\n",
      "Loss on test= 0.006533730309456587\n",
      "acc for Lsat= 0.1078837165195081 \n",
      "acc for Psat= 0.1730103474110365 \n",
      "acc for optim= 0.159147847793065\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.004987584892660379\n",
      "Loss on test= 0.007136906031519175\n",
      "acc for Lsat= 0.11597422963111764 \n",
      "acc for Psat= 0.20331510218481222 \n",
      "acc for optim= 0.1790218438125319\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.005080127622932196\n",
      "Loss on test= 0.00699606304988265\n",
      "acc for Lsat= 0.10575282545242873 \n",
      "acc for Psat= 0.13980615542580685 \n",
      "acc for optim= 0.1665381233000921\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.005078764632344246\n",
      "Loss on test= 0.006453931797295809\n",
      "acc for Lsat= 0.172834486183193 \n",
      "acc for Psat= 0.14489365162120926 \n",
      "acc for optim= 0.15368272837561867\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.0050908601842820644\n",
      "Loss on test= 0.006465691141784191\n",
      "acc for Lsat= 0.1233499828312132 \n",
      "acc for Psat= 0.15929845332478484 \n",
      "acc for optim= 0.16889563037289512\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.005069779697805643\n",
      "Loss on test= 0.006396274548023939\n",
      "acc for Lsat= 0.14688707034414014 \n",
      "acc for Psat= 0.17469914422448105 \n",
      "acc for optim= 0.16513075689888662\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.00496903108432889\n",
      "Loss on test= 0.006627501919865608\n",
      "acc for Lsat= 0.12015338601647979 \n",
      "acc for Psat= 0.13747550340162384 \n",
      "acc for optim= 0.1461832578190499\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.004974351264536381\n",
      "Loss on test= 0.006509068422019482\n",
      "acc for Lsat= 0.13367911394582027 \n",
      "acc for Psat= 0.11471467313822359 \n",
      "acc for optim= 0.16938024420394665\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.004948195535689592\n",
      "Loss on test= 0.0065944311209023\n",
      "acc for Lsat= 0.12859567741139066 \n",
      "acc for Psat= 0.10318352444462814 \n",
      "acc for optim= 0.166693100033121\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.004799963906407356\n",
      "Loss on test= 0.006465706042945385\n",
      "acc for Lsat= 0.19424887063602606 \n",
      "acc for Psat= 0.16634523811646634 \n",
      "acc for optim= 0.17241820418793294\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.005033399444073439\n",
      "Loss on test= 0.006698788143694401\n",
      "acc for Lsat= 0.10031122083051337 \n",
      "acc for Psat= 0.1423456956528955 \n",
      "acc for optim= 0.15691089412818351\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.005011295899748802\n",
      "Loss on test= 0.006627173162996769\n",
      "acc for Lsat= 0.17844987898651096 \n",
      "acc for Psat= 0.22885471396148205 \n",
      "acc for optim= 0.1441072936480244\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.004791720770299435\n",
      "Loss on test= 0.006464303005486727\n",
      "acc for Lsat= 0.12251550881289101 \n",
      "acc for Psat= 0.09651335597866112 \n",
      "acc for optim= 0.16460288517797986\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.004880707710981369\n",
      "Loss on test= 0.006880395580083132\n",
      "acc for Lsat= 0.16374782886770037 \n",
      "acc for Psat= 0.16863158492681882 \n",
      "acc for optim= 0.1718217844867872\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.0048383260145783424\n",
      "Loss on test= 0.006706534884870052\n",
      "acc for Lsat= 0.1304361381335184 \n",
      "acc for Psat= 0.10607795538898143 \n",
      "acc for optim= 0.15701700157822213\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.004848644603043795\n",
      "Loss on test= 0.006505013443529606\n",
      "acc for Lsat= 0.10843271322341429 \n",
      "acc for Psat= 0.13964163977652788 \n",
      "acc for optim= 0.1532281607699891\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.004825158976018429\n",
      "Loss on test= 0.0067190066911280155\n",
      "acc for Lsat= 0.13592982023126549 \n",
      "acc for Psat= 0.19328929939203793 \n",
      "acc for optim= 0.16850595986761618\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.004967324901372194\n",
      "Loss on test= 0.006790020503103733\n",
      "acc for Lsat= 0.10457645345013589 \n",
      "acc for Psat= 0.14586496635133195 \n",
      "acc for optim= 0.1575994216836989\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.00500122644007206\n",
      "Loss on test= 0.006947396323084831\n",
      "acc for Lsat= 0.1300965795914332 \n",
      "acc for Psat= 0.1655429793625242 \n",
      "acc for optim= 0.16649109046556987\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.004995014518499374\n",
      "Loss on test= 0.007695779204368591\n",
      "acc for Lsat= 0.19005141823759508 \n",
      "acc for Psat= 0.16385370992874312 \n",
      "acc for optim= 0.14041184965107176\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.004843008238822222\n",
      "Loss on test= 0.006435256917029619\n",
      "acc for Lsat= 0.1419400534618439 \n",
      "acc for Psat= 0.15967153455130756 \n",
      "acc for optim= 0.17144487123005092\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.004876915831118822\n",
      "Loss on test= 0.006915092933923006\n",
      "acc for Lsat= 0.12369536022500445 \n",
      "acc for Psat= 0.0866396615229961 \n",
      "acc for optim= 0.16260019092199704\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.004800453316420317\n",
      "Loss on test= 0.0062363771721720695\n",
      "acc for Lsat= 0.1706398002182444 \n",
      "acc for Psat= 0.17747690989118484 \n",
      "acc for optim= 0.17443476284905854\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.004950679372996092\n",
      "Loss on test= 0.0066396314650774\n",
      "acc for Lsat= 0.11794208775326195 \n",
      "acc for Psat= 0.1510678171956291 \n",
      "acc for optim= 0.15279348003160623\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.004859844222664833\n",
      "Loss on test= 0.006717820186167955\n",
      "acc for Lsat= 0.12848978380983075 \n",
      "acc for Psat= 0.12543912852803865 \n",
      "acc for optim= 0.1627445013469292\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.00490369088947773\n",
      "Loss on test= 0.006500599905848503\n",
      "acc for Lsat= 0.12942713752595914 \n",
      "acc for Psat= 0.15071372020368776 \n",
      "acc for optim= 0.15973329316410753\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.004810314159840345\n",
      "Loss on test= 0.006647690199315548\n",
      "acc for Lsat= 0.09305496348275079 \n",
      "acc for Psat= 0.12460040906444192 \n",
      "acc for optim= 0.16784146247017714\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.004800861701369286\n",
      "Loss on test= 0.0068807899951934814\n",
      "acc for Lsat= 0.13758731078511724 \n",
      "acc for Psat= 0.15873182037224373 \n",
      "acc for optim= 0.12506391018784294\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.004775763489305973\n",
      "Loss on test= 0.007020832039415836\n",
      "acc for Lsat= 0.11977285508894259 \n",
      "acc for Psat= 0.0931739837073514 \n",
      "acc for optim= 0.15319633016608553\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.004723076708614826\n",
      "Loss on test= 0.006851464509963989\n",
      "acc for Lsat= 0.12054679449647665 \n",
      "acc for Psat= 0.12570735804426172 \n",
      "acc for optim= 0.18433632691287333\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.004812337923794985\n",
      "Loss on test= 0.00620895903557539\n",
      "acc for Lsat= 0.11310650339065534 \n",
      "acc for Psat= 0.1180055966704256 \n",
      "acc for optim= 0.1858146300332414\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.004799668677151203\n",
      "Loss on test= 0.0069437711499631405\n",
      "acc for Lsat= 0.13035100789016318 \n",
      "acc for Psat= 0.09907197408999006 \n",
      "acc for optim= 0.19693859371667108\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.00478108087554574\n",
      "Loss on test= 0.006757642608135939\n",
      "acc for Lsat= 0.1699234359095701 \n",
      "acc for Psat= 0.13667811561996737 \n",
      "acc for optim= 0.16117280054216584\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.004647636786103249\n",
      "Loss on test= 0.006770450156182051\n",
      "acc for Lsat= 0.11084749684151676 \n",
      "acc for Psat= 0.15284650896986327 \n",
      "acc for optim= 0.18476954797127595\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.004640255589038134\n",
      "Loss on test= 0.006615214049816132\n",
      "acc for Lsat= 0.17847558385175136 \n",
      "acc for Psat= 0.15591261365140477 \n",
      "acc for optim= 0.14849869767203927\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.004736090078949928\n",
      "Loss on test= 0.006443979684263468\n",
      "acc for Lsat= 0.14322258428566986 \n",
      "acc for Psat= 0.1568342018355098 \n",
      "acc for optim= 0.1704776586136884\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.0048369900323450565\n",
      "Loss on test= 0.007090990897268057\n",
      "acc for Lsat= 0.15546945016184407 \n",
      "acc for Psat= 0.13842596537950966 \n",
      "acc for optim= 0.1398582513599346\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.004986086394637823\n",
      "Loss on test= 0.0072705927304923534\n",
      "acc for Lsat= 0.12176645808439288 \n",
      "acc for Psat= 0.1665792527815534 \n",
      "acc for optim= 0.1669176335174901\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.004772788845002651\n",
      "Loss on test= 0.006601214874535799\n",
      "acc for Lsat= 0.1335492536632551 \n",
      "acc for Psat= 0.1270467836746118 \n",
      "acc for optim= 0.14189408266813391\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.004825417883694172\n",
      "Loss on test= 0.006909084971994162\n",
      "acc for Lsat= 0.13273171718335813 \n",
      "acc for Psat= 0.16465427136669555 \n",
      "acc for optim= 0.16593931504111323\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.00481078028678894\n",
      "Loss on test= 0.0064276657067239285\n",
      "acc for Lsat= 0.15210205595940351 \n",
      "acc for Psat= 0.1013318683900353 \n",
      "acc for optim= 0.14740350832127863\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.004813803359866142\n",
      "Loss on test= 0.0065279328264296055\n",
      "acc for Lsat= 0.17642491714408 \n",
      "acc for Psat= 0.16441344700029326 \n",
      "acc for optim= 0.170384252211079\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.004766479600220919\n",
      "Loss on test= 0.006202319636940956\n",
      "acc for Lsat= 0.16367386819587815 \n",
      "acc for Psat= 0.13236052664514217 \n",
      "acc for optim= 0.15902774579202136\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.004610980395227671\n",
      "Loss on test= 0.006351216696202755\n",
      "acc for Lsat= 0.14833975973952976 \n",
      "acc for Psat= 0.13827807730477717 \n",
      "acc for optim= 0.1464982113490502\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.004624407738447189\n",
      "Loss on test= 0.006724925711750984\n",
      "acc for Lsat= 0.11997838023429115 \n",
      "acc for Psat= 0.11652559944842425 \n",
      "acc for optim= 0.17103149198616543\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.00469254981726408\n",
      "Loss on test= 0.006227564997971058\n",
      "acc for Lsat= 0.21152781798607773 \n",
      "acc for Psat= 0.20590865198108885 \n",
      "acc for optim= 0.154903089420663\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.004732908681035042\n",
      "Loss on test= 0.006586783565580845\n",
      "acc for Lsat= 0.15594547086705765 \n",
      "acc for Psat= 0.1640392801620894 \n",
      "acc for optim= 0.13483214853719497\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.004726893734186888\n",
      "Loss on test= 0.007234071847051382\n",
      "acc for Lsat= 0.07447822423030932 \n",
      "acc for Psat= 0.12194737711171103 \n",
      "acc for optim= 0.143876444755329\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.004601989407092333\n",
      "Loss on test= 0.006506820674985647\n",
      "acc for Lsat= 0.15363069631469747 \n",
      "acc for Psat= 0.1915521113615897 \n",
      "acc for optim= 0.17476951263638008\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.004629900678992271\n",
      "Loss on test= 0.006229015067219734\n",
      "acc for Lsat= 0.09933516921268569 \n",
      "acc for Psat= 0.12762446918835244 \n",
      "acc for optim= 0.1502494848229819\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.004644058644771576\n",
      "Loss on test= 0.006978956982493401\n",
      "acc for Lsat= 0.13934954348951578 \n",
      "acc for Psat= 0.1605159279683398 \n",
      "acc for optim= 0.15998193549199236\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.004560478497296572\n",
      "Loss on test= 0.006408951245248318\n",
      "acc for Lsat= 0.14528541892973912 \n",
      "acc for Psat= 0.1421959192569678 \n",
      "acc for optim= 0.16671589565359884\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.004535588435828686\n",
      "Loss on test= 0.006534656044095755\n",
      "acc for Lsat= 0.14025731664150953 \n",
      "acc for Psat= 0.10483733019241805 \n",
      "acc for optim= 0.16594279104740256\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.004744185134768486\n",
      "Loss on test= 0.00653822859749198\n",
      "acc for Lsat= 0.12673068714017668 \n",
      "acc for Psat= 0.11178784807109171 \n",
      "acc for optim= 0.15760211030849153\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.004626251291483641\n",
      "Loss on test= 0.0066389357671141624\n",
      "acc for Lsat= 0.12461955312432514 \n",
      "acc for Psat= 0.15657191226879755 \n",
      "acc for optim= 0.15426302046722007\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.004694279283285141\n",
      "Loss on test= 0.006678951904177666\n",
      "acc for Lsat= 0.1338562855703963 \n",
      "acc for Psat= 0.19284466449688706 \n",
      "acc for optim= 0.15873386855754587\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.004617428872734308\n",
      "Loss on test= 0.0064201559871435165\n",
      "acc for Lsat= 0.12292379673777355 \n",
      "acc for Psat= 0.1524628095729794 \n",
      "acc for optim= 0.17424672345320383\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.004455003421753645\n",
      "Loss on test= 0.006409528665244579\n",
      "acc for Lsat= 0.16076469224774176 \n",
      "acc for Psat= 0.14189821947366 \n",
      "acc for optim= 0.16237168023104054\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.004739366937428713\n",
      "Loss on test= 0.006712109316140413\n",
      "acc for Lsat= 0.07666964634942512 \n",
      "acc for Psat= 0.1106983791752201 \n",
      "acc for optim= 0.15027726426099738\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.004657039884477854\n",
      "Loss on test= 0.006763094570487738\n",
      "acc for Lsat= 0.11396830893742542 \n",
      "acc for Psat= 0.12267692738937007 \n",
      "acc for optim= 0.13203642103407118\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.004528578836470842\n",
      "Loss on test= 0.006446640472859144\n",
      "acc for Lsat= 0.14887329397930038 \n",
      "acc for Psat= 0.1235034085241043 \n",
      "acc for optim= 0.1570803199817116\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.004630608484148979\n",
      "Loss on test= 0.006501743569970131\n",
      "acc for Lsat= 0.14042804136665332 \n",
      "acc for Psat= 0.13460193027276546 \n",
      "acc for optim= 0.14852384395069546\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.0045523447915911674\n",
      "Loss on test= 0.006959444843232632\n",
      "acc for Lsat= 0.164753184889883 \n",
      "acc for Psat= 0.14075611664965335 \n",
      "acc for optim= 0.16440823500872487\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.004594156984239817\n",
      "Loss on test= 0.006445472594350576\n",
      "acc for Lsat= 0.11582145229395893 \n",
      "acc for Psat= 0.14692062017921773 \n",
      "acc for optim= 0.16249552592893857\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.004582477267831564\n",
      "Loss on test= 0.006382120307534933\n",
      "acc for Lsat= 0.16620098716682857 \n",
      "acc for Psat= 0.14877894497274408 \n",
      "acc for optim= 0.15492588425210366\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.004532971419394016\n",
      "Loss on test= 0.006370084825903177\n",
      "acc for Lsat= 0.10471386511603163 \n",
      "acc for Psat= 0.15611941936529344 \n",
      "acc for optim= 0.16733233289172253\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.0045242272317409515\n",
      "Loss on test= 0.006355771794915199\n",
      "acc for Lsat= 0.10840512750049432 \n",
      "acc for Psat= 0.10113297389923698 \n",
      "acc for optim= 0.1717284475194497\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.00445283530279994\n",
      "Loss on test= 0.006843514274805784\n",
      "acc for Lsat= 0.11686397399494632 \n",
      "acc for Psat= 0.15006130499144396 \n",
      "acc for optim= 0.17498760618683365\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.004425606690347195\n",
      "Loss on test= 0.006617192644625902\n",
      "acc for Lsat= 0.14014593180682924 \n",
      "acc for Psat= 0.1521572226451503 \n",
      "acc for optim= 0.1464721545473569\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.004532139282673597\n",
      "Loss on test= 0.006783687509596348\n",
      "acc for Lsat= 0.12769790366292 \n",
      "acc for Psat= 0.10824069673092002 \n",
      "acc for optim= 0.15375328441667888\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.0044959066435694695\n",
      "Loss on test= 0.0060839299112558365\n",
      "acc for Lsat= 0.11733680034780668 \n",
      "acc for Psat= 0.1589164000728892 \n",
      "acc for optim= 0.1657682722466739\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.004396459553390741\n",
      "Loss on test= 0.00643868837505579\n",
      "acc for Lsat= 0.15073357129262555 \n",
      "acc for Psat= 0.16565927480243975 \n",
      "acc for optim= 0.1883986328288706\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.004441671539098024\n",
      "Loss on test= 0.0067679388448596\n",
      "acc for Lsat= 0.10947891573111217 \n",
      "acc for Psat= 0.14559833982881779 \n",
      "acc for optim= 0.15474781937276325\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.004572932608425617\n",
      "Loss on test= 0.006554977968335152\n",
      "acc for Lsat= 0.14455556952291065 \n",
      "acc for Psat= 0.17210970342987114 \n",
      "acc for optim= 0.14789759537880956\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.004486494231969118\n",
      "Loss on test= 0.006259918212890625\n",
      "acc for Lsat= 0.1265177650946296 \n",
      "acc for Psat= 0.17581720929592848 \n",
      "acc for optim= 0.16099262485901514\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.004535872954875231\n",
      "Loss on test= 0.006602552253752947\n",
      "acc for Lsat= 0.10049047022281836 \n",
      "acc for Psat= 0.1263158735819161 \n",
      "acc for optim= 0.16163467926283678\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.004448676481842995\n",
      "Loss on test= 0.006733381655067205\n",
      "acc for Lsat= 0.1272555840615597 \n",
      "acc for Psat= 0.13547772127721044 \n",
      "acc for optim= 0.15953743659580746\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.004627916496247053\n",
      "Loss on test= 0.006393034476786852\n",
      "acc for Lsat= 0.11647356857752635 \n",
      "acc for Psat= 0.1360148487923046 \n",
      "acc for optim= 0.19099409319460392\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.004474877845495939\n",
      "Loss on test= 0.006574525032192469\n",
      "acc for Lsat= 0.14701408872173893 \n",
      "acc for Psat= 0.15585950834469664 \n",
      "acc for optim= 0.14829680820306143\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.00448423670604825\n",
      "Loss on test= 0.00633520632982254\n",
      "acc for Lsat= 0.09734158388649423 \n",
      "acc for Psat= 0.13452091895871693 \n",
      "acc for optim= 0.1646904485921065\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.00446375273168087\n",
      "Loss on test= 0.00721711153164506\n",
      "acc for Lsat= 0.13770226378821665 \n",
      "acc for Psat= 0.17658338131796983 \n",
      "acc for optim= 0.16626516150103676\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.004514317028224468\n",
      "Loss on test= 0.006376542150974274\n",
      "acc for Lsat= 0.13282287852942115 \n",
      "acc for Psat= 0.22485780141626796 \n",
      "acc for optim= 0.15707770983378092\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.004533565603196621\n",
      "Loss on test= 0.006395327392965555\n",
      "acc for Lsat= 0.12081892684929901 \n",
      "acc for Psat= 0.13521781728033805 \n",
      "acc for optim= 0.16004986440141997\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.0046279896050691605\n",
      "Loss on test= 0.006386430934071541\n",
      "acc for Lsat= 0.11522923265066412 \n",
      "acc for Psat= 0.16915292385965586 \n",
      "acc for optim= 0.1333035905069361\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.004534236621111631\n",
      "Loss on test= 0.006537357810884714\n",
      "acc for Lsat= 0.08932271725239439 \n",
      "acc for Psat= 0.09526207272170319 \n",
      "acc for optim= 0.18975128091470753\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.004451726097613573\n",
      "Loss on test= 0.006211433093994856\n",
      "acc for Lsat= 0.14673128413657346 \n",
      "acc for Psat= 0.18424839337563348 \n",
      "acc for optim= 0.16904045394363088\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.004382659215480089\n",
      "Loss on test= 0.006261602975428104\n",
      "acc for Lsat= 0.1028034068747527 \n",
      "acc for Psat= 0.10740185787694322 \n",
      "acc for optim= 0.14878175102381241\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.004393051844090223\n",
      "Loss on test= 0.006178268697112799\n",
      "acc for Lsat= 0.14810093766492274 \n",
      "acc for Psat= 0.14419406424793932 \n",
      "acc for optim= 0.15719031708108056\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.004476753994822502\n",
      "Loss on test= 0.006628410425037146\n",
      "acc for Lsat= 0.10690954218929012 \n",
      "acc for Psat= 0.13502104050065908 \n",
      "acc for optim= 0.14956116774636838\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.004514400381594896\n",
      "Loss on test= 0.006381064187735319\n",
      "acc for Lsat= 0.12389753992384714 \n",
      "acc for Psat= 0.13139510967044365 \n",
      "acc for optim= 0.1873349185205168\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.004486451856791973\n",
      "Loss on test= 0.00621558353304863\n",
      "acc for Lsat= 0.14481911631042343 \n",
      "acc for Psat= 0.15363239608187643 \n",
      "acc for optim= 0.13621544781037503\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.00438639335334301\n",
      "Loss on test= 0.006399573292583227\n",
      "acc for Lsat= 0.1283764916782578 \n",
      "acc for Psat= 0.137336030188534 \n",
      "acc for optim= 0.15842315976301002\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.00452322605997324\n",
      "Loss on test= 0.00627534557133913\n",
      "acc for Lsat= 0.11599574362238248 \n",
      "acc for Psat= 0.11373782116505834 \n",
      "acc for optim= 0.1297740055144661\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.0046522594057023525\n",
      "Loss on test= 0.006580087821930647\n",
      "acc for Lsat= 0.12451374949887395 \n",
      "acc for Psat= 0.15318091329471725 \n",
      "acc for optim= 0.16914101752627175\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.004480387084186077\n",
      "Loss on test= 0.006379281170666218\n",
      "acc for Lsat= 0.1293515171855688 \n",
      "acc for Psat= 0.11330999847915438 \n",
      "acc for optim= 0.15596273225835627\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.004501247778534889\n",
      "Loss on test= 0.006412298418581486\n",
      "acc for Lsat= 0.14419549817426336 \n",
      "acc for Psat= 0.1471455067706605 \n",
      "acc for optim= 0.1445054394296474\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.004331882111728191\n",
      "Loss on test= 0.006663288455456495\n",
      "acc for Lsat= 0.13048857605705658 \n",
      "acc for Psat= 0.16301124509320492 \n",
      "acc for optim= 0.16755981163846123\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.004522019997239113\n",
      "Loss on test= 0.0069435639306902885\n",
      "acc for Lsat= 0.09633719952156146 \n",
      "acc for Psat= 0.11589904170897272 \n",
      "acc for optim= 0.15105449579035243\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.004422200843691826\n",
      "Loss on test= 0.006469449494034052\n",
      "acc for Lsat= 0.12486857744968599 \n",
      "acc for Psat= 0.14127143710437748 \n",
      "acc for optim= 0.15596727316086698\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.0043993447907269\n",
      "Loss on test= 0.006266201846301556\n",
      "acc for Lsat= 0.10409377406661709 \n",
      "acc for Psat= 0.11436682582522432 \n",
      "acc for optim= 0.16356817125213435\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.004332170356065035\n",
      "Loss on test= 0.006382201798260212\n",
      "acc for Lsat= 0.12293929389367501 \n",
      "acc for Psat= 0.14166116300556394 \n",
      "acc for optim= 0.15680654548729459\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.004318753257393837\n",
      "Loss on test= 0.006479564588516951\n",
      "acc for Lsat= 0.12727756808615392 \n",
      "acc for Psat= 0.18274888675659895 \n",
      "acc for optim= 0.17191338960805702\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.004301406443119049\n",
      "Loss on test= 0.006237117573618889\n",
      "acc for Lsat= 0.10576182202849951 \n",
      "acc for Psat= 0.14533603851062557 \n",
      "acc for optim= 0.14744763070484623\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.004403548315167427\n",
      "Loss on test= 0.006758348550647497\n",
      "acc for Lsat= 0.10859530005190107 \n",
      "acc for Psat= 0.15541105200019148 \n",
      "acc for optim= 0.16157281641951865\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.004474553745239973\n",
      "Loss on test= 0.006472514942288399\n",
      "acc for Lsat= 0.1198325846150207 \n",
      "acc for Psat= 0.18070540581053743 \n",
      "acc for optim= 0.16518042678944767\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.0044104126282036304\n",
      "Loss on test= 0.006878132466226816\n",
      "acc for Lsat= 0.1317147376636664 \n",
      "acc for Psat= 0.19597870577126741 \n",
      "acc for optim= 0.16860223623613516\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.004371626302599907\n",
      "Loss on test= 0.006080294493585825\n",
      "acc for Lsat= 0.11433261803661783 \n",
      "acc for Psat= 0.12529620631701416 \n",
      "acc for optim= 0.12601455165228495\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.004433367867022753\n",
      "Loss on test= 0.006617758423089981\n",
      "acc for Lsat= 0.09036230104458001 \n",
      "acc for Psat= 0.0993649826462691 \n",
      "acc for optim= 0.15872222330007288\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.004428744316101074\n",
      "Loss on test= 0.0066571603529155254\n",
      "acc for Lsat= 0.09068703237507078 \n",
      "acc for Psat= 0.11183152860030532 \n",
      "acc for optim= 0.17017855681478977\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.004394134506583214\n",
      "Loss on test= 0.006147321313619614\n",
      "acc for Lsat= 0.13389324457643348 \n",
      "acc for Psat= 0.12817592856784663 \n",
      "acc for optim= 0.1545529911915461\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.004196287598460913\n",
      "Loss on test= 0.006250075530260801\n",
      "acc for Lsat= 0.10710937597064508 \n",
      "acc for Psat= 0.17779795408973265 \n",
      "acc for optim= 0.1373300690352658\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.004407821223139763\n",
      "Loss on test= 0.0063822316005826\n",
      "acc for Lsat= 0.10311707072348024 \n",
      "acc for Psat= 0.1176913716416392 \n",
      "acc for optim= 0.1553915911871526\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.004365132190287113\n",
      "Loss on test= 0.0063170213252305984\n",
      "acc for Lsat= 0.09755198145285249 \n",
      "acc for Psat= 0.14113665579093826 \n",
      "acc for optim= 0.15922051837616083\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.004148813430219889\n",
      "Loss on test= 0.006400974467396736\n",
      "acc for Lsat= 0.12451357629874514 \n",
      "acc for Psat= 0.158294297185623 \n",
      "acc for optim= 0.14819590804270572\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.004332870244979858\n",
      "Loss on test= 0.006311553530395031\n",
      "acc for Lsat= 0.11970956807231738 \n",
      "acc for Psat= 0.18380666255123085 \n",
      "acc for optim= 0.16798311502983174\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.0043957969173789024\n",
      "Loss on test= 0.006142373196780682\n",
      "acc for Lsat= 0.14646279646290672 \n",
      "acc for Psat= 0.18118132319715288 \n",
      "acc for optim= 0.17403454255933562\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.004466078709810972\n",
      "Loss on test= 0.006859111599624157\n",
      "acc for Lsat= 0.10285612381994724 \n",
      "acc for Psat= 0.11451559853351985 \n",
      "acc for optim= 0.16667305077943537\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.004333870019763708\n",
      "Loss on test= 0.006372806616127491\n",
      "acc for Lsat= 0.10468467022292316 \n",
      "acc for Psat= 0.1231021850512156 \n",
      "acc for optim= 0.179261836119824\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.004243754781782627\n",
      "Loss on test= 0.0064430939964950085\n",
      "acc for Lsat= 0.13313405414939755 \n",
      "acc for Psat= 0.09150071727991518 \n",
      "acc for optim= 0.1877209580399924\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.0041866181418299675\n",
      "Loss on test= 0.006435272749513388\n",
      "acc for Lsat= 0.10566502426324102 \n",
      "acc for Psat= 0.13404324805984894 \n",
      "acc for optim= 0.1316996884221832\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.004357786849141121\n",
      "Loss on test= 0.006009572651237249\n",
      "acc for Lsat= 0.10662382243511577 \n",
      "acc for Psat= 0.14036793523054156 \n",
      "acc for optim= 0.18494510108656767\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.00428206380456686\n",
      "Loss on test= 0.0062419576570391655\n",
      "acc for Lsat= 0.08043691805667347 \n",
      "acc for Psat= 0.1134645674093109 \n",
      "acc for optim= 0.1554478162433952\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.004259572830051184\n",
      "Loss on test= 0.006214366294443607\n",
      "acc for Lsat= 0.10622450849041343 \n",
      "acc for Psat= 0.14118779233346382 \n",
      "acc for optim= 0.16319917866753209\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.004250433761626482\n",
      "Loss on test= 0.00664504012092948\n",
      "acc for Lsat= 0.1471374538830585 \n",
      "acc for Psat= 0.14708495046943426 \n",
      "acc for optim= 0.17813393644367656\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.004393140785396099\n",
      "Loss on test= 0.006175199523568153\n",
      "acc for Lsat= 0.125700495348105 \n",
      "acc for Psat= 0.1237015873969843 \n",
      "acc for optim= 0.17101982655003667\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.004226959776133299\n",
      "Loss on test= 0.005959749687463045\n",
      "acc for Lsat= 0.14691505870885319 \n",
      "acc for Psat= 0.1399038089439273 \n",
      "acc for optim= 0.139727299929493\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.004258044995367527\n",
      "Loss on test= 0.006611364893615246\n",
      "acc for Lsat= 0.13625003330202567 \n",
      "acc for Psat= 0.1470073763695028 \n",
      "acc for optim= 0.15742903081182805\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.004177965223789215\n",
      "Loss on test= 0.006376616656780243\n",
      "acc for Lsat= 0.15700882474063999 \n",
      "acc for Psat= 0.19019448674387401 \n",
      "acc for optim= 0.1610037919340862\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.0043381331488490105\n",
      "Loss on test= 0.006279432214796543\n",
      "acc for Lsat= 0.11911301071652108 \n",
      "acc for Psat= 0.13829371651324132 \n",
      "acc for optim= 0.15619096309981412\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.004248467739671469\n",
      "Loss on test= 0.006398045923560858\n",
      "acc for Lsat= 0.09118828663809432 \n",
      "acc for Psat= 0.08844156161831052 \n",
      "acc for optim= 0.15035354851150057\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.004174873698502779\n",
      "Loss on test= 0.006279763765633106\n",
      "acc for Lsat= 0.12617784649288902 \n",
      "acc for Psat= 0.19056471038816702 \n",
      "acc for optim= 0.14307116525661615\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.004378198646008968\n",
      "Loss on test= 0.006678048055619001\n",
      "acc for Lsat= 0.12267740321759549 \n",
      "acc for Psat= 0.12946553052299553 \n",
      "acc for optim= 0.1548376146496998\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.004204172175377607\n",
      "Loss on test= 0.006253362167626619\n",
      "acc for Lsat= 0.12727574614756224 \n",
      "acc for Psat= 0.13170340517535806 \n",
      "acc for optim= 0.17011789263536534\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.004171479027718306\n",
      "Loss on test= 0.006025698035955429\n",
      "acc for Lsat= 0.12397475970081157 \n",
      "acc for Psat= 0.1466801892966032 \n",
      "acc for optim= 0.17733452771790326\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.004313953686505556\n",
      "Loss on test= 0.006374510936439037\n",
      "acc for Lsat= 0.1319466326903138 \n",
      "acc for Psat= 0.13979116040799353 \n",
      "acc for optim= 0.15235275516493452\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.004232755862176418\n",
      "Loss on test= 0.006255892105400562\n",
      "acc for Lsat= 0.11784672416332695 \n",
      "acc for Psat= 0.1576936092848579 \n",
      "acc for optim= 0.14855730725038382\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.004144931212067604\n",
      "Loss on test= 0.006256147287786007\n",
      "acc for Lsat= 0.10497225319138831 \n",
      "acc for Psat= 0.14091336114021638 \n",
      "acc for optim= 0.1584336319550251\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.004185047000646591\n",
      "Loss on test= 0.006455693859606981\n",
      "acc for Lsat= 0.09556561872725272 \n",
      "acc for Psat= 0.1236308203741727 \n",
      "acc for optim= 0.17168000288721588\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.004209321923553944\n",
      "Loss on test= 0.0062116095796227455\n",
      "acc for Lsat= 0.13359972027440867 \n",
      "acc for Psat= 0.17018649879739517 \n",
      "acc for optim= 0.15479852601937535\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.004210864193737507\n",
      "Loss on test= 0.00720573216676712\n",
      "acc for Lsat= 0.09459496361927854 \n",
      "acc for Psat= 0.14242948796082702 \n",
      "acc for optim= 0.13964486701620948\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.004233282525092363\n",
      "Loss on test= 0.006369572598487139\n",
      "acc for Lsat= 0.13288289277503887 \n",
      "acc for Psat= 0.12872008164413273 \n",
      "acc for optim= 0.1758423777193659\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.004207014571875334\n",
      "Loss on test= 0.00609931955114007\n",
      "acc for Lsat= 0.13764854365338883 \n",
      "acc for Psat= 0.11467348414266275 \n",
      "acc for optim= 0.16647181753069162\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.0041768611408770084\n",
      "Loss on test= 0.006526859011501074\n",
      "acc for Lsat= 0.10872210191559538 \n",
      "acc for Psat= 0.1630253985317217 \n",
      "acc for optim= 0.1469597799781089\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.0043405694887042046\n",
      "Loss on test= 0.006057162769138813\n",
      "acc for Lsat= 0.14882448005179563 \n",
      "acc for Psat= 0.10656534921791819 \n",
      "acc for optim= 0.15256352660556635\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.0041364626958966255\n",
      "Loss on test= 0.006601504050195217\n",
      "acc for Lsat= 0.12270674342289567 \n",
      "acc for Psat= 0.14879649836156103 \n",
      "acc for optim= 0.1572163864556286\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.004343957640230656\n",
      "Loss on test= 0.006357240490615368\n",
      "acc for Lsat= 0.09314946158944319 \n",
      "acc for Psat= 0.16265981333951154 \n",
      "acc for optim= 0.19099388982997173\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.00418922258540988\n",
      "Loss on test= 0.006214392837136984\n",
      "acc for Lsat= 0.12668948004850084 \n",
      "acc for Psat= 0.1147475380760928 \n",
      "acc for optim= 0.13281923731685513\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.004218043759465218\n",
      "Loss on test= 0.006287160329520702\n",
      "acc for Lsat= 0.11837939628296429 \n",
      "acc for Psat= 0.11707609858583762 \n",
      "acc for optim= 0.1488726658022238\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.004155303351581097\n",
      "Loss on test= 0.006198554299771786\n",
      "acc for Lsat= 0.1405093841927333 \n",
      "acc for Psat= 0.10672689575908913 \n",
      "acc for optim= 0.15375505729267994\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.0042692567221820354\n",
      "Loss on test= 0.0065706996247172356\n",
      "acc for Lsat= 0.14269825306999134 \n",
      "acc for Psat= 0.13751957830714268 \n",
      "acc for optim= 0.1698100883513689\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.004170247353613377\n",
      "Loss on test= 0.0067271338775753975\n",
      "acc for Lsat= 0.1395715947987305 \n",
      "acc for Psat= 0.16502103778637117 \n",
      "acc for optim= 0.144998259708599\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.0042002578265964985\n",
      "Loss on test= 0.006686813198029995\n",
      "acc for Lsat= 0.15111123708387217 \n",
      "acc for Psat= 0.16615181607711646 \n",
      "acc for optim= 0.1496786730001784\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.004030978307127953\n",
      "Loss on test= 0.006297004874795675\n",
      "acc for Lsat= 0.11052307760756877 \n",
      "acc for Psat= 0.13961622232778204 \n",
      "acc for optim= 0.15547922522657448\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.004159772768616676\n",
      "Loss on test= 0.0063961283303797245\n",
      "acc for Lsat= 0.11795795755460858 \n",
      "acc for Psat= 0.15662019534243476 \n",
      "acc for optim= 0.15615420582212713\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.0041671437211334705\n",
      "Loss on test= 0.006288789212703705\n",
      "acc for Lsat= 0.13645456693807823 \n",
      "acc for Psat= 0.15665112808346748 \n",
      "acc for optim= 0.17530315038230684\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.004083773121237755\n",
      "Loss on test= 0.006335054058581591\n",
      "acc for Lsat= 0.1128810610389337 \n",
      "acc for Psat= 0.16622765871903133 \n",
      "acc for optim= 0.1481574024591181\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.00423977617174387\n",
      "Loss on test= 0.006235158536583185\n",
      "acc for Lsat= 0.06995722258256541 \n",
      "acc for Psat= 0.10602038881431024 \n",
      "acc for optim= 0.13571332653777468\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.004076825920492411\n",
      "Loss on test= 0.0061706784181296825\n",
      "acc for Lsat= 0.17671150362326038 \n",
      "acc for Psat= 0.12872616584516233 \n",
      "acc for optim= 0.15956166614988535\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.004054481163620949\n",
      "Loss on test= 0.00619852589443326\n",
      "acc for Lsat= 0.130419972048306 \n",
      "acc for Psat= 0.13426762689939803 \n",
      "acc for optim= 0.1709834915689296\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.004105949774384499\n",
      "Loss on test= 0.006483093369752169\n",
      "acc for Lsat= 0.11466040213902791 \n",
      "acc for Psat= 0.123188898122559 \n",
      "acc for optim= 0.16017357949426192\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.004015791695564985\n",
      "Loss on test= 0.006646939553320408\n",
      "acc for Lsat= 0.09954264004611307 \n",
      "acc for Psat= 0.1268454952159017 \n",
      "acc for optim= 0.14632255097644198\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.0041099172085523605\n",
      "Loss on test= 0.006178381387144327\n",
      "acc for Lsat= 0.07931852376916343 \n",
      "acc for Psat= 0.14500391317738426 \n",
      "acc for optim= 0.1819784836584909\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.004115141462534666\n",
      "Loss on test= 0.006378293037414551\n",
      "acc for Lsat= 0.10971474596428582 \n",
      "acc for Psat= 0.10011999063297278 \n",
      "acc for optim= 0.14897412612238745\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.004032645840197802\n",
      "Loss on test= 0.006172767840325832\n",
      "acc for Lsat= 0.14690718882613713 \n",
      "acc for Psat= 0.11703551912473308 \n",
      "acc for optim= 0.16915899328887463\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.004216632340103388\n",
      "Loss on test= 0.006584764923900366\n",
      "acc for Lsat= 0.15061046879660958 \n",
      "acc for Psat= 0.11997705660501702 \n",
      "acc for optim= 0.149607980520361\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.004033687524497509\n",
      "Loss on test= 0.0061087217181921005\n",
      "acc for Lsat= 0.12479460016927785 \n",
      "acc for Psat= 0.13701759775479636 \n",
      "acc for optim= 0.15228201862838533\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.004167016129940748\n",
      "Loss on test= 0.00636727549135685\n",
      "acc for Lsat= 0.16819390586008215 \n",
      "acc for Psat= 0.1406270276962055 \n",
      "acc for optim= 0.1440087902204444\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.004159623757004738\n",
      "Loss on test= 0.006526648532599211\n",
      "acc for Lsat= 0.09702961527768315 \n",
      "acc for Psat= 0.17046932014636695 \n",
      "acc for optim= 0.17220838233414623\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.003970335703343153\n",
      "Loss on test= 0.005987761542201042\n",
      "acc for Lsat= 0.09372397967510754 \n",
      "acc for Psat= 0.11969691173483928 \n",
      "acc for optim= 0.16918382027910817\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.004025478381663561\n",
      "Loss on test= 0.0061110216192901134\n",
      "acc for Lsat= 0.10270113499265993 \n",
      "acc for Psat= 0.12723485524636796 \n",
      "acc for optim= 0.18095306013452095\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.004078587982803583\n",
      "Loss on test= 0.006096904166042805\n",
      "acc for Lsat= 0.13801699017898905 \n",
      "acc for Psat= 0.15466515180499604 \n",
      "acc for optim= 0.14852289154401255\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.004031108692288399\n",
      "Loss on test= 0.00626375200226903\n",
      "acc for Lsat= 0.14385725226667193 \n",
      "acc for Psat= 0.10379609276747538 \n",
      "acc for optim= 0.16102710076504284\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.003947942517697811\n",
      "Loss on test= 0.006261294707655907\n",
      "acc for Lsat= 0.1160255977883935 \n",
      "acc for Psat= 0.10611724951821896 \n",
      "acc for optim= 0.161027809824898\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.004247136879712343\n",
      "Loss on test= 0.0062440247274935246\n",
      "acc for Lsat= 0.12519605566437045 \n",
      "acc for Psat= 0.09450237277067369 \n",
      "acc for optim= 0.16983098992043072\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.004080064129084349\n",
      "Loss on test= 0.006172529421746731\n",
      "acc for Lsat= 0.10654986900691357 \n",
      "acc for Psat= 0.12319840325249566 \n",
      "acc for optim= 0.1671296810834772\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.004181041847914457\n",
      "Loss on test= 0.0064109195955097675\n",
      "acc for Lsat= 0.1444411889856888 \n",
      "acc for Psat= 0.18009404972609547 \n",
      "acc for optim= 0.16401250358709754\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.004034662619233131\n",
      "Loss on test= 0.006170893087983131\n",
      "acc for Lsat= 0.1165653576867448 \n",
      "acc for Psat= 0.13724203749249378 \n",
      "acc for optim= 0.16019796900865105\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.004044836852699518\n",
      "Loss on test= 0.006527327466756105\n",
      "acc for Lsat= 0.1569614780859815 \n",
      "acc for Psat= 0.16741877049207687 \n",
      "acc for optim= 0.15761800770026943\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.003916803281754255\n",
      "Loss on test= 0.006731456145644188\n",
      "acc for Lsat= 0.11791210616421369 \n",
      "acc for Psat= 0.12052145424402422 \n",
      "acc for optim= 0.15498771806920153\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.004178880248218775\n",
      "Loss on test= 0.006323153153061867\n",
      "acc for Lsat= 0.14050383560566437 \n",
      "acc for Psat= 0.11306085072768231 \n",
      "acc for optim= 0.14416229345887485\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.004039805848151445\n",
      "Loss on test= 0.006093621253967285\n",
      "acc for Lsat= 0.12347516567549771 \n",
      "acc for Psat= 0.16468843093348873 \n",
      "acc for optim= 0.17070452863764432\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.003983387723565102\n",
      "Loss on test= 0.006066083908081055\n",
      "acc for Lsat= 0.10435169070842676 \n",
      "acc for Psat= 0.13037156657729712 \n",
      "acc for optim= 0.15885474124095506\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.004046253394335508\n",
      "Loss on test= 0.006242597941309214\n",
      "acc for Lsat= 0.140871975894293 \n",
      "acc for Psat= 0.09174319480856259 \n",
      "acc for optim= 0.13520639665269604\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.004078388679772615\n",
      "Loss on test= 0.0062681566923856735\n",
      "acc for Lsat= 0.11215703934431076 \n",
      "acc for Psat= 0.11991988176790376 \n",
      "acc for optim= 0.17113027897559935\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.003982131835073233\n",
      "Loss on test= 0.006940688006579876\n",
      "acc for Lsat= 0.11461520245130588 \n",
      "acc for Psat= 0.1734570542143451 \n",
      "acc for optim= 0.16646502477427325\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.004091192036867142\n",
      "Loss on test= 0.00644497387111187\n",
      "acc for Lsat= 0.14027366494863397 \n",
      "acc for Psat= 0.10967572980249922 \n",
      "acc for optim= 0.15932301468112403\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.004052144940942526\n",
      "Loss on test= 0.006292382255196571\n",
      "acc for Lsat= 0.14516670039544502 \n",
      "acc for Psat= 0.12764666467491123 \n",
      "acc for optim= 0.142129963884751\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.004185415338724852\n",
      "Loss on test= 0.0060272300615906715\n",
      "acc for Lsat= 0.101020260170723 \n",
      "acc for Psat= 0.12519610318769184 \n",
      "acc for optim= 0.15363360359980208\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.004050479736179113\n",
      "Loss on test= 0.006330777425318956\n",
      "acc for Lsat= 0.15018837847229508 \n",
      "acc for Psat= 0.12574708803246418 \n",
      "acc for optim= 0.15374828318858313\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.00395547691732645\n",
      "Loss on test= 0.0063431644812226295\n",
      "acc for Lsat= 0.13603299960959703 \n",
      "acc for Psat= 0.12760039827682906 \n",
      "acc for optim= 0.15009467414994207\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.003964049741625786\n",
      "Loss on test= 0.006119965575635433\n",
      "acc for Lsat= 0.15441022060622345 \n",
      "acc for Psat= 0.08056434419833952 \n",
      "acc for optim= 0.16955189916512203\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.0040345084853470325\n",
      "Loss on test= 0.006443716585636139\n",
      "acc for Lsat= 0.13578488755350313 \n",
      "acc for Psat= 0.14847917223556173 \n",
      "acc for optim= 0.14828547716347706\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.003986048977822065\n",
      "Loss on test= 0.006140807177871466\n",
      "acc for Lsat= 0.10021219976867239 \n",
      "acc for Psat= 0.10683561954647303 \n",
      "acc for optim= 0.14778939789781967\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.004064662382006645\n",
      "Loss on test= 0.0067206257954239845\n",
      "acc for Lsat= 0.11815773530138864 \n",
      "acc for Psat= 0.12459489610046148 \n",
      "acc for optim= 0.1739154381211847\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.004185647238045931\n",
      "Loss on test= 0.005636580288410187\n",
      "acc for Lsat= 0.10298988550332272 \n",
      "acc for Psat= 0.14256726927770716 \n",
      "acc for optim= 0.15741506926133297\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.0039057687390595675\n",
      "Loss on test= 0.0062140715308487415\n",
      "acc for Lsat= 0.1188384444038901 \n",
      "acc for Psat= 0.13446686204729807 \n",
      "acc for optim= 0.18006334267556667\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.003967862576246262\n",
      "Loss on test= 0.006791501771658659\n",
      "acc for Lsat= 0.15179371021481025 \n",
      "acc for Psat= 0.12922203574433094 \n",
      "acc for optim= 0.1624440279039037\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.004098555538803339\n",
      "Loss on test= 0.00610247952863574\n",
      "acc for Lsat= 0.09806857796178924 \n",
      "acc for Psat= 0.11260915252690513 \n",
      "acc for optim= 0.1476720785204735\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.0040357112884521484\n",
      "Loss on test= 0.006546748802065849\n",
      "acc for Lsat= 0.13207804894126537 \n",
      "acc for Psat= 0.11591958818543288 \n",
      "acc for optim= 0.1625602375877659\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.003908663522452116\n",
      "Loss on test= 0.005916424095630646\n",
      "acc for Lsat= 0.121645732556418 \n",
      "acc for Psat= 0.12133781808531946 \n",
      "acc for optim= 0.17095678522148067\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.003975939471274614\n",
      "Loss on test= 0.006361403036862612\n",
      "acc for Lsat= 0.13010373344230983 \n",
      "acc for Psat= 0.14067224320024252 \n",
      "acc for optim= 0.16424392727721068\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.004053306765854359\n",
      "Loss on test= 0.006264973897486925\n",
      "acc for Lsat= 0.10927460849699047 \n",
      "acc for Psat= 0.09775183184279336 \n",
      "acc for optim= 0.14291395936419982\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.004012755583971739\n",
      "Loss on test= 0.006586396135389805\n",
      "acc for Lsat= 0.1375150094843573 \n",
      "acc for Psat= 0.1481175683826829 \n",
      "acc for optim= 0.16092098993249238\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.003930505830794573\n",
      "Loss on test= 0.0064058322459459305\n",
      "acc for Lsat= 0.09938236077626546 \n",
      "acc for Psat= 0.12712751797193456 \n",
      "acc for optim= 0.15648520928031454\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.003965463489294052\n",
      "Loss on test= 0.006136767100542784\n",
      "acc for Lsat= 0.09330858563124719 \n",
      "acc for Psat= 0.1353441420942545 \n",
      "acc for optim= 0.15170266489601797\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.004035661928355694\n",
      "Loss on test= 0.006303099915385246\n",
      "acc for Lsat= 0.11257951288846219 \n",
      "acc for Psat= 0.13717282935976982 \n",
      "acc for optim= 0.13126436015591025\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.003941201139241457\n",
      "Loss on test= 0.006335856858640909\n",
      "acc for Lsat= 0.08931866272663076 \n",
      "acc for Psat= 0.14056931394669744 \n",
      "acc for optim= 0.15796448017742173\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.003933199215680361\n",
      "Loss on test= 0.005844814702868462\n",
      "acc for Lsat= 0.0934532772258131 \n",
      "acc for Psat= 0.17345899384882715 \n",
      "acc for optim= 0.17669534089509398\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.004002445377409458\n",
      "Loss on test= 0.006697882432490587\n",
      "acc for Lsat= 0.09691557288169861 \n",
      "acc for Psat= 0.15681923501607445 \n",
      "acc for optim= 0.16560107982190353\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.003954527899622917\n",
      "Loss on test= 0.0068784598261117935\n",
      "acc for Lsat= 0.14929662052438492 \n",
      "acc for Psat= 0.1553397175286793 \n",
      "acc for optim= 0.16802776263082503\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.003985064569860697\n",
      "Loss on test= 0.00649701151996851\n",
      "acc for Lsat= 0.07735154889006582 \n",
      "acc for Psat= 0.10510338591929111 \n",
      "acc for optim= 0.1633282634558984\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.003970546182245016\n",
      "Loss on test= 0.006223939824849367\n",
      "acc for Lsat= 0.11423391507317622 \n",
      "acc for Psat= 0.1351671445493897 \n",
      "acc for optim= 0.15489451825851575\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.003922365605831146\n",
      "Loss on test= 0.006209591869264841\n",
      "acc for Lsat= 0.09835463063791394 \n",
      "acc for Psat= 0.13042958123454204 \n",
      "acc for optim= 0.15090065787080675\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.003891042433679104\n",
      "Loss on test= 0.006376415491104126\n",
      "acc for Lsat= 0.13890197474716437 \n",
      "acc for Psat= 0.15102240562878755 \n",
      "acc for optim= 0.17221257848561639\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.003831073408946395\n",
      "Loss on test= 0.005982473026961088\n",
      "acc for Lsat= 0.0822730164638617 \n",
      "acc for Psat= 0.16402750951237977 \n",
      "acc for optim= 0.17439854258878362\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.003887919243425131\n",
      "Loss on test= 0.006331642623990774\n",
      "acc for Lsat= 0.1225111083024078 \n",
      "acc for Psat= 0.08275798211495082 \n",
      "acc for optim= 0.1494294073846605\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.0038921611849218607\n",
      "Loss on test= 0.006488542538136244\n",
      "acc for Lsat= 0.09561691904026601 \n",
      "acc for Psat= 0.11506426681040062 \n",
      "acc for optim= 0.14729284070846108\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.003857287112623453\n",
      "Loss on test= 0.006358145270496607\n",
      "acc for Lsat= 0.09641900772435798 \n",
      "acc for Psat= 0.12928265853164098 \n",
      "acc for optim= 0.14056270600607\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.004094602540135384\n",
      "Loss on test= 0.00580858439207077\n",
      "acc for Lsat= 0.15400724123335546 \n",
      "acc for Psat= 0.09037532499577436 \n",
      "acc for optim= 0.15534402237325493\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.003912557847797871\n",
      "Loss on test= 0.005926620680838823\n",
      "acc for Lsat= 0.09700064697987425 \n",
      "acc for Psat= 0.11748449594920708 \n",
      "acc for optim= 0.16093534542273524\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.00395677937194705\n",
      "Loss on test= 0.006429347209632397\n",
      "acc for Lsat= 0.1352233913106223 \n",
      "acc for Psat= 0.10427822550344798 \n",
      "acc for optim= 0.18083228615836966\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.003770472016185522\n",
      "Loss on test= 0.006204997189342976\n",
      "acc for Lsat= 0.15441953075221843 \n",
      "acc for Psat= 0.08883604986800088 \n",
      "acc for optim= 0.17425138547292185\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.0040333946235477924\n",
      "Loss on test= 0.006158484145998955\n",
      "acc for Lsat= 0.12654188345186412 \n",
      "acc for Psat= 0.14215281357367834 \n",
      "acc for optim= 0.1550080664973292\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.003850142005831003\n",
      "Loss on test= 0.006553777027875185\n",
      "acc for Lsat= 0.11147946098612414 \n",
      "acc for Psat= 0.11314215943113798 \n",
      "acc for optim= 0.16986588649969134\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.00385811529122293\n",
      "Loss on test= 0.006430599372833967\n",
      "acc for Lsat= 0.14102527250846228 \n",
      "acc for Psat= 0.1120827490877774 \n",
      "acc for optim= 0.15320135122682485\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.0038124399725347757\n",
      "Loss on test= 0.006087909918278456\n",
      "acc for Lsat= 0.11626228364184499 \n",
      "acc for Psat= 0.11998566752299666 \n",
      "acc for optim= 0.15519284094787306\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.0038554100319743156\n",
      "Loss on test= 0.006464606616646051\n",
      "acc for Lsat= 0.12582297129685888 \n",
      "acc for Psat= 0.09224481327045295 \n",
      "acc for optim= 0.18096283078193665\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.0038161149714142084\n",
      "Loss on test= 0.006287117023020983\n",
      "acc for Lsat= 0.12315055306276514 \n",
      "acc for Psat= 0.1013325478674637 \n",
      "acc for optim= 0.12147132990260918\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.003959312569350004\n",
      "Loss on test= 0.005848632659763098\n",
      "acc for Lsat= 0.1265903072586904 \n",
      "acc for Psat= 0.12103476299671456 \n",
      "acc for optim= 0.15299902277507094\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.003892789827659726\n",
      "Loss on test= 0.006934245582669973\n",
      "acc for Lsat= 0.11666579860159093 \n",
      "acc for Psat= 0.13315195829555806 \n",
      "acc for optim= 0.18478603003960517\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.0037874693516641855\n",
      "Loss on test= 0.006365604232996702\n",
      "acc for Lsat= 0.10410034873833258 \n",
      "acc for Psat= 0.11364168265006608 \n",
      "acc for optim= 0.14759954087074018\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.003892146982252598\n",
      "Loss on test= 0.0062247514724731445\n",
      "acc for Lsat= 0.08185345356145667 \n",
      "acc for Psat= 0.1395383232868173 \n",
      "acc for optim= 0.16572092659771442\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.003926578909158707\n",
      "Loss on test= 0.006033794023096561\n",
      "acc for Lsat= 0.10610858175075716 \n",
      "acc for Psat= 0.14773232945137554 \n",
      "acc for optim= 0.18199430799318683\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.00376025284640491\n",
      "Loss on test= 0.006273380946367979\n",
      "acc for Lsat= 0.12196211020151775 \n",
      "acc for Psat= 0.12271960074495938 \n",
      "acc for optim= 0.15607093417202123\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.003931116778403521\n",
      "Loss on test= 0.006037597544491291\n",
      "acc for Lsat= 0.09079324911969404 \n",
      "acc for Psat= 0.12608632086711521 \n",
      "acc for optim= 0.17669904957680652\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.003778425045311451\n",
      "Loss on test= 0.006754949223250151\n",
      "acc for Lsat= 0.07857448879965684 \n",
      "acc for Psat= 0.12224856401897138 \n",
      "acc for optim= 0.1733676724963718\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.0039452421478927135\n",
      "Loss on test= 0.006652880925685167\n",
      "acc for Lsat= 0.12597507794594598 \n",
      "acc for Psat= 0.13306710610373151 \n",
      "acc for optim= 0.14845740008685324\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.003868298837915063\n",
      "Loss on test= 0.006244413089007139\n",
      "acc for Lsat= 0.0781177409614126 \n",
      "acc for Psat= 0.12117400012599926 \n",
      "acc for optim= 0.1556828969106492\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.0037776895333081484\n",
      "Loss on test= 0.006029460579156876\n",
      "acc for Lsat= 0.14006764377053413 \n",
      "acc for Psat= 0.0867096403607219 \n",
      "acc for optim= 0.15066804739439654\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.003844129852950573\n",
      "Loss on test= 0.0059015778824687\n",
      "acc for Lsat= 0.12748437762881318 \n",
      "acc for Psat= 0.11379572886249258 \n",
      "acc for optim= 0.13175085176610285\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.003897348651662469\n",
      "Loss on test= 0.005939943250268698\n",
      "acc for Lsat= 0.11984716506817171 \n",
      "acc for Psat= 0.1608930695284572 \n",
      "acc for optim= 0.15755544577000868\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.003733136458322406\n",
      "Loss on test= 0.006038764491677284\n",
      "acc for Lsat= 0.13433328984926143 \n",
      "acc for Psat= 0.2258945086763965 \n",
      "acc for optim= 0.14397931675840583\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.0037617117632180452\n",
      "Loss on test= 0.00610705791041255\n",
      "acc for Lsat= 0.15174076219813692 \n",
      "acc for Psat= 0.13772257727881274 \n",
      "acc for optim= 0.13981950617663744\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.0038505150005221367\n",
      "Loss on test= 0.006164726801216602\n",
      "acc for Lsat= 0.08706384141825968 \n",
      "acc for Psat= 0.10427356112955345 \n",
      "acc for optim= 0.19450630351073211\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.0038500928785651922\n",
      "Loss on test= 0.005986335221678019\n",
      "acc for Lsat= 0.10873580118641257 \n",
      "acc for Psat= 0.12686655616077283 \n",
      "acc for optim= 0.1602705590840843\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.0036678402684628963\n",
      "Loss on test= 0.006245132070034742\n",
      "acc for Lsat= 0.11035190739979346 \n",
      "acc for Psat= 0.14316431963298884 \n",
      "acc for optim= 0.16158631415520278\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.0038961118552833796\n",
      "Loss on test= 0.006415168754756451\n",
      "acc for Lsat= 0.10328521662288243 \n",
      "acc for Psat= 0.15939066662556595 \n",
      "acc for optim= 0.15162219805642962\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.0038613954093307257\n",
      "Loss on test= 0.006198612041771412\n",
      "acc for Lsat= 0.1248453943990171 \n",
      "acc for Psat= 0.1186523716379371 \n",
      "acc for optim= 0.1685010587486128\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.0038791263941675425\n",
      "Loss on test= 0.006020667031407356\n",
      "acc for Lsat= 0.1328219892974529 \n",
      "acc for Psat= 0.1016607113286025 \n",
      "acc for optim= 0.16116753053696206\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.0038355106953531504\n",
      "Loss on test= 0.005951561965048313\n",
      "acc for Lsat= 0.09677591961291102 \n",
      "acc for Psat= 0.09975910869737466 \n",
      "acc for optim= 0.17121042352583674\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.003867120947688818\n",
      "Loss on test= 0.006115050055086613\n",
      "acc for Lsat= 0.12223059787518448 \n",
      "acc for Psat= 0.12876292359497812 \n",
      "acc for optim= 0.15616783441510051\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.0036656202282756567\n",
      "Loss on test= 0.006354925688356161\n",
      "acc for Lsat= 0.1217333504723178 \n",
      "acc for Psat= 0.09751156251877546 \n",
      "acc for optim= 0.129887051285348\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.0038527490105479956\n",
      "Loss on test= 0.006276450119912624\n",
      "acc for Lsat= 0.12998393141768044 \n",
      "acc for Psat= 0.12629230726613766 \n",
      "acc for optim= 0.1584709440357983\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.003993598278611898\n",
      "Loss on test= 0.005797711666673422\n",
      "acc for Lsat= 0.10182665961070193 \n",
      "acc for Psat= 0.09633603371265861 \n",
      "acc for optim= 0.14147634183367094\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.0037814860697835684\n",
      "Loss on test= 0.006072415038943291\n",
      "acc for Lsat= 0.1371613528786434 \n",
      "acc for Psat= 0.11911464417223921 \n",
      "acc for optim= 0.16846435610204935\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.0038205250166356564\n",
      "Loss on test= 0.006361851934343576\n",
      "acc for Lsat= 0.14681059489440587 \n",
      "acc for Psat= 0.1136249248455796 \n",
      "acc for optim= 0.16680193132358706\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.0037399926222860813\n",
      "Loss on test= 0.006494319532066584\n",
      "acc for Lsat= 0.1233348918483696 \n",
      "acc for Psat= 0.13874755685942042 \n",
      "acc for optim= 0.17092860831568638\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.003736721584573388\n",
      "Loss on test= 0.006233633495867252\n",
      "acc for Lsat= 0.12326067603296703 \n",
      "acc for Psat= 0.15955259816514122 \n",
      "acc for optim= 0.1754043105368813\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.003917386755347252\n",
      "Loss on test= 0.005834624171257019\n",
      "acc for Lsat= 0.10467675355418275 \n",
      "acc for Psat= 0.1190583080622471 \n",
      "acc for optim= 0.17640573986702496\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.003708399599418044\n",
      "Loss on test= 0.006692793220281601\n",
      "acc for Lsat= 0.09826018022269839 \n",
      "acc for Psat= 0.1471669290525218 \n",
      "acc for optim= 0.14681222439847058\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.003654077649116516\n",
      "Loss on test= 0.006253283470869064\n",
      "acc for Lsat= 0.1135469821229991 \n",
      "acc for Psat= 0.10478033205597764 \n",
      "acc for optim= 0.1529591687851482\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.003733971854671836\n",
      "Loss on test= 0.0063356757164001465\n",
      "acc for Lsat= 0.10900873201980074 \n",
      "acc for Psat= 0.10978167972320484 \n",
      "acc for optim= 0.1796798166922397\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.0038101980462670326\n",
      "Loss on test= 0.005755158606916666\n",
      "acc for Lsat= 0.10377341825773732 \n",
      "acc for Psat= 0.10558557929471135 \n",
      "acc for optim= 0.13926514993525213\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.003823660546913743\n",
      "Loss on test= 0.006235678214579821\n",
      "acc for Lsat= 0.11021141055971384 \n",
      "acc for Psat= 0.09821763075888157 \n",
      "acc for optim= 0.145582643415158\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.003760102903470397\n",
      "Loss on test= 0.006404371000826359\n",
      "acc for Lsat= 0.1018611249100003 \n",
      "acc for Psat= 0.11223119255414025 \n",
      "acc for optim= 0.19952456497897705\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.0038473778404295444\n",
      "Loss on test= 0.006402744445949793\n",
      "acc for Lsat= 0.09821729082614183 \n",
      "acc for Psat= 0.14710437033014992 \n",
      "acc for optim= 0.17135928912709156\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.003960960544645786\n",
      "Loss on test= 0.006178879179060459\n",
      "acc for Lsat= 0.08213584476228182 \n",
      "acc for Psat= 0.08940833108499646 \n",
      "acc for optim= 0.18620337825268507\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.0037646754644811153\n",
      "Loss on test= 0.006515121553093195\n",
      "acc for Lsat= 0.11767168860468599 \n",
      "acc for Psat= 0.13402308534002966 \n",
      "acc for optim= 0.14387058227374735\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.003795199329033494\n",
      "Loss on test= 0.006211013533174992\n",
      "acc for Lsat= 0.16031833820872837 \n",
      "acc for Psat= 0.08719433171467648 \n",
      "acc for optim= 0.16259968798193666\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.0038979051169008017\n",
      "Loss on test= 0.006644053850322962\n",
      "acc for Lsat= 0.12107029013956587 \n",
      "acc for Psat= 0.11686973522106807 \n",
      "acc for optim= 0.1817895243358281\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.0038029253482818604\n",
      "Loss on test= 0.006421978119760752\n",
      "acc for Lsat= 0.13975969194951984 \n",
      "acc for Psat= 0.14955574576742947 \n",
      "acc for optim= 0.13335270279397568\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.0037341585848480463\n",
      "Loss on test= 0.006039308849722147\n",
      "acc for Lsat= 0.10996071621775627 \n",
      "acc for Psat= 0.155098809601946 \n",
      "acc for optim= 0.17829529216719997\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.0037624267861247063\n",
      "Loss on test= 0.005997062660753727\n",
      "acc for Lsat= 0.1297002831965478 \n",
      "acc for Psat= 0.15147103928029537 \n",
      "acc for optim= 0.17390899163567358\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.0037539065815508366\n",
      "Loss on test= 0.006283849012106657\n",
      "acc for Lsat= 0.10332505024659137 \n",
      "acc for Psat= 0.1300273939139313 \n",
      "acc for optim= 0.14925001478857464\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.003774363314732909\n",
      "Loss on test= 0.006266316398978233\n",
      "acc for Lsat= 0.09270199702748666 \n",
      "acc for Psat= 0.13167415948636416 \n",
      "acc for optim= 0.18815829118506777\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.0037753237411379814\n",
      "Loss on test= 0.006673032883554697\n",
      "acc for Lsat= 0.11553593730140063 \n",
      "acc for Psat= 0.13145174944980276 \n",
      "acc for optim= 0.15920642158016562\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.00372431892901659\n",
      "Loss on test= 0.006171997636556625\n",
      "acc for Lsat= 0.11668661847296688 \n",
      "acc for Psat= 0.11592015884040545 \n",
      "acc for optim= 0.1692357616395586\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.0037465353962033987\n",
      "Loss on test= 0.006295689847320318\n",
      "acc for Lsat= 0.10956762938035859 \n",
      "acc for Psat= 0.15839241072535515 \n",
      "acc for optim= 0.1562554868352082\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.0036906523164361715\n",
      "Loss on test= 0.006121125537902117\n",
      "acc for Lsat= 0.11536824753663193 \n",
      "acc for Psat= 0.15180287696421146 \n",
      "acc for optim= 0.15870619151327345\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.003648096928372979\n",
      "Loss on test= 0.006591899786144495\n",
      "acc for Lsat= 0.09358706480513017 \n",
      "acc for Psat= 0.10474198187390964 \n",
      "acc for optim= 0.1761844044344293\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.0037314884830266237\n",
      "Loss on test= 0.006289004348218441\n",
      "acc for Lsat= 0.09737684215522474 \n",
      "acc for Psat= 0.11386456899344921 \n",
      "acc for optim= 0.16245763252178827\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.0038661977741867304\n",
      "Loss on test= 0.0062769148498773575\n",
      "acc for Lsat= 0.07454096655904625 \n",
      "acc for Psat= 0.15635810057736105 \n",
      "acc for optim= 0.16207787378354827\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.0037060407921671867\n",
      "Loss on test= 0.0058584753423929214\n",
      "acc for Lsat= 0.11568675294984132 \n",
      "acc for Psat= 0.10364757003359652 \n",
      "acc for optim= 0.14996201583805183\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.0037620277144014835\n",
      "Loss on test= 0.0062104263342916965\n",
      "acc for Lsat= 0.07927097645329519 \n",
      "acc for Psat= 0.12008239535821809 \n",
      "acc for optim= 0.13952511360144448\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.003692604834213853\n",
      "Loss on test= 0.006455952301621437\n",
      "acc for Lsat= 0.10693614722953902 \n",
      "acc for Psat= 0.09919778956100345 \n",
      "acc for optim= 0.15296080234919726\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.0036568031646311283\n",
      "Loss on test= 0.0061858841218054295\n",
      "acc for Lsat= 0.09107166652878125 \n",
      "acc for Psat= 0.12998981846289503 \n",
      "acc for optim= 0.14527189645903288\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.003737359307706356\n",
      "Loss on test= 0.00606427900493145\n",
      "acc for Lsat= 0.09887607227493492 \n",
      "acc for Psat= 0.13053779780036873 \n",
      "acc for optim= 0.13953934798741507\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.003746688598766923\n",
      "Loss on test= 0.006272186990827322\n",
      "acc for Lsat= 0.07705206325691608 \n",
      "acc for Psat= 0.09993418705158143 \n",
      "acc for optim= 0.15974923960554102\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.0037005634512752295\n",
      "Loss on test= 0.00608713598921895\n",
      "acc for Lsat= 0.11506500296915571 \n",
      "acc for Psat= 0.137423261932175 \n",
      "acc for optim= 0.1595837687038713\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.0038160199765115976\n",
      "Loss on test= 0.006063718348741531\n",
      "acc for Lsat= 0.11159349326044321 \n",
      "acc for Psat= 0.10663290292723104 \n",
      "acc for optim= 0.14911445362182954\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.0036726943217217922\n",
      "Loss on test= 0.006659498438239098\n",
      "acc for Lsat= 0.0995033136762989 \n",
      "acc for Psat= 0.10990796276989083 \n",
      "acc for optim= 0.15563773472644649\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.0037759041879326105\n",
      "Loss on test= 0.005898378323763609\n",
      "acc for Lsat= 0.10170626498034431 \n",
      "acc for Psat= 0.09325198508385155 \n",
      "acc for optim= 0.14910807628701958\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.0036121816374361515\n",
      "Loss on test= 0.005922860465943813\n",
      "acc for Lsat= 0.12037110452850659 \n",
      "acc for Psat= 0.15512678898974425 \n",
      "acc for optim= 0.140808670134801\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.0037055506836622953\n",
      "Loss on test= 0.005936605855822563\n",
      "acc for Lsat= 0.09311594466109657 \n",
      "acc for Psat= 0.13649621797311637 \n",
      "acc for optim= 0.15421310594926277\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.0037001026794314384\n",
      "Loss on test= 0.006163473706692457\n",
      "acc for Lsat= 0.08778490545228124 \n",
      "acc for Psat= 0.13313132401607516 \n",
      "acc for optim= 0.1541086564021599\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.0037655255291610956\n",
      "Loss on test= 0.006367461755871773\n",
      "acc for Lsat= 0.12969289634687206 \n",
      "acc for Psat= 0.10704376315698028 \n",
      "acc for optim= 0.17006298123548427\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.003581457072868943\n",
      "Loss on test= 0.00633198069408536\n",
      "acc for Lsat= 0.10312826445119248 \n",
      "acc for Psat= 0.11709326303874452 \n",
      "acc for optim= 0.1801162204808659\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.0037632635794579983\n",
      "Loss on test= 0.006216141860932112\n",
      "acc for Lsat= 0.12154320360989207 \n",
      "acc for Psat= 0.10403406578310144 \n",
      "acc for optim= 0.16714255296149835\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.0036305366083979607\n",
      "Loss on test= 0.0061537292785942554\n",
      "acc for Lsat= 0.08994671310453366 \n",
      "acc for Psat= 0.11926465378039414 \n",
      "acc for optim= 0.1611083574179146\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.003725011833012104\n",
      "Loss on test= 0.006337017752230167\n",
      "acc for Lsat= 0.09232448626102673 \n",
      "acc for Psat= 0.11449231921384732 \n",
      "acc for optim= 0.1619664780381653\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.003631799016147852\n",
      "Loss on test= 0.0065475329756736755\n",
      "acc for Lsat= 0.10993277835142282 \n",
      "acc for Psat= 0.14154701344927567 \n",
      "acc for optim= 0.17647519567981362\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.003617925336584449\n",
      "Loss on test= 0.00587732158601284\n",
      "acc for Lsat= 0.13912673760205507 \n",
      "acc for Psat= 0.12101591492278709 \n",
      "acc for optim= 0.1713823423617416\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.003589698811993003\n",
      "Loss on test= 0.006069364491850138\n",
      "acc for Lsat= 0.14636624335414833 \n",
      "acc for Psat= 0.12487460799618727 \n",
      "acc for optim= 0.1566940907181965\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.003630747552961111\n",
      "Loss on test= 0.00634988397359848\n",
      "acc for Lsat= 0.09653090313076973 \n",
      "acc for Psat= 0.1122646083175722 \n",
      "acc for optim= 0.13955645615028012\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.00376992323435843\n",
      "Loss on test= 0.005995975807309151\n",
      "acc for Lsat= 0.10933749765778582 \n",
      "acc for Psat= 0.09828778930629294 \n",
      "acc for optim= 0.13511745023748112\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.0037380224093794823\n",
      "Loss on test= 0.006292911246418953\n",
      "acc for Lsat= 0.09733525507100341 \n",
      "acc for Psat= 0.09176884022437864 \n",
      "acc for optim= 0.1389700777751083\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.0036482475697994232\n",
      "Loss on test= 0.005943043157458305\n",
      "acc for Lsat= 0.10885320063163009 \n",
      "acc for Psat= 0.1361556113180187 \n",
      "acc for optim= 0.1501853721953618\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.003646248020231724\n",
      "Loss on test= 0.006408241111785173\n",
      "acc for Lsat= 0.1269154433232163 \n",
      "acc for Psat= 0.11442554496332175 \n",
      "acc for optim= 0.16446248576458958\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.0037337096873670816\n",
      "Loss on test= 0.006349622737616301\n",
      "acc for Lsat= 0.0904463865639021 \n",
      "acc for Psat= 0.14185195933613512 \n",
      "acc for optim= 0.1795504221485721\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.003557651536539197\n",
      "Loss on test= 0.006388680078089237\n",
      "acc for Lsat= 0.10998366540297866 \n",
      "acc for Psat= 0.20770040464897951 \n",
      "acc for optim= 0.1590358106057263\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.003681688103824854\n",
      "Loss on test= 0.006375140510499477\n",
      "acc for Lsat= 0.1183642331096861 \n",
      "acc for Psat= 0.12522222753614187 \n",
      "acc for optim= 0.1610200106062823\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.003684043185785413\n",
      "Loss on test= 0.006166784092783928\n",
      "acc for Lsat= 0.1042631957679987 \n",
      "acc for Psat= 0.14247891296529108 \n",
      "acc for optim= 0.15072109260492855\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.003559954697266221\n",
      "Loss on test= 0.006346626207232475\n",
      "acc for Lsat= 0.09362269550911151 \n",
      "acc for Psat= 0.1209236571772231 \n",
      "acc for optim= 0.1574194128625095\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.0035931465681642294\n",
      "Loss on test= 0.006166676990687847\n",
      "acc for Lsat= 0.112397951229165 \n",
      "acc for Psat= 0.1035081397017671 \n",
      "acc for optim= 0.17408760968181822\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.003544249339029193\n",
      "Loss on test= 0.006166340317577124\n",
      "acc for Lsat= 0.10565517232235935 \n",
      "acc for Psat= 0.1380269403089187 \n",
      "acc for optim= 0.16792899139949846\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.003683418035507202\n",
      "Loss on test= 0.00603444455191493\n",
      "acc for Lsat= 0.1255608979716069 \n",
      "acc for Psat= 0.11833088700142172 \n",
      "acc for optim= 0.13639870886173514\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.003711450845003128\n",
      "Loss on test= 0.005751549266278744\n",
      "acc for Lsat= 0.15270663632286918 \n",
      "acc for Psat= 0.16661779499716228 \n",
      "acc for optim= 0.16539511695090267\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.003636231180280447\n",
      "Loss on test= 0.0060353665612638\n",
      "acc for Lsat= 0.11958456681006485 \n",
      "acc for Psat= 0.0996229026414868 \n",
      "acc for optim= 0.16522929496649238\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.0037315115332603455\n",
      "Loss on test= 0.005967886187136173\n",
      "acc for Lsat= 0.13132320841153464 \n",
      "acc for Psat= 0.10423364587283383 \n",
      "acc for optim= 0.1486827533485161\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.003578269388526678\n",
      "Loss on test= 0.006146321538835764\n",
      "acc for Lsat= 0.09500699298870233 \n",
      "acc for Psat= 0.09205994043602711 \n",
      "acc for optim= 0.16703402789102662\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.0036263829097151756\n",
      "Loss on test= 0.006259771529585123\n",
      "acc for Lsat= 0.12477002864600056 \n",
      "acc for Psat= 0.1261790582227857 \n",
      "acc for optim= 0.17092111629123488\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.0037312142085283995\n",
      "Loss on test= 0.006722656078636646\n",
      "acc for Lsat= 0.10704598260215586 \n",
      "acc for Psat= 0.13726829199327362 \n",
      "acc for optim= 0.18586225169969517\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.003606789745390415\n",
      "Loss on test= 0.0062553053721785545\n",
      "acc for Lsat= 0.10343464743345976 \n",
      "acc for Psat= 0.11089586476898855 \n",
      "acc for optim= 0.20011419938722005\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.0035804861690849066\n",
      "Loss on test= 0.006493799854069948\n",
      "acc for Lsat= 0.13308888011508518 \n",
      "acc for Psat= 0.13702497750313747 \n",
      "acc for optim= 0.19210476578316754\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.0034718038514256477\n",
      "Loss on test= 0.006168018095195293\n",
      "acc for Lsat= 0.1169742508015285 \n",
      "acc for Psat= 0.09901942562363628 \n",
      "acc for optim= 0.14358711670825464\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.0037367448676377535\n",
      "Loss on test= 0.006167372688651085\n",
      "acc for Lsat= 0.11246350534363753 \n",
      "acc for Psat= 0.11040733278625542 \n",
      "acc for optim= 0.15760882469961265\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.0036535896360874176\n",
      "Loss on test= 0.0063051930628716946\n",
      "acc for Lsat= 0.08662400305183837 \n",
      "acc for Psat= 0.1365742968240132 \n",
      "acc for optim= 0.15231666333662966\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.003709889017045498\n",
      "Loss on test= 0.00625075725838542\n",
      "acc for Lsat= 0.12527825217694044 \n",
      "acc for Psat= 0.1428559178279506 \n",
      "acc for optim= 0.18187166028656065\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.003641612594947219\n",
      "Loss on test= 0.006671587936580181\n",
      "acc for Lsat= 0.08650057342472589 \n",
      "acc for Psat= 0.18216435621596044 \n",
      "acc for optim= 0.17077808692637417\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.003708187723532319\n",
      "Loss on test= 0.006023535504937172\n",
      "acc for Lsat= 0.06695944795178042 \n",
      "acc for Psat= 0.10709504517985301 \n",
      "acc for optim= 0.16141225728723738\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.0036024258006364107\n",
      "Loss on test= 0.005900783464312553\n",
      "acc for Lsat= 0.11534839940981732 \n",
      "acc for Psat= 0.1490890429251724 \n",
      "acc for optim= 0.17358587433894476\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.003560429671779275\n",
      "Loss on test= 0.0066327862441539764\n",
      "acc for Lsat= 0.09690600405964586 \n",
      "acc for Psat= 0.09570614628804226 \n",
      "acc for optim= 0.1588660455826256\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.0036370479501783848\n",
      "Loss on test= 0.00601358525454998\n",
      "acc for Lsat= 0.12024327822857434 \n",
      "acc for Psat= 0.13212137834893334 \n",
      "acc for optim= 0.17358562310174522\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.003566688857972622\n",
      "Loss on test= 0.0058939955197274685\n",
      "acc for Lsat= 0.15131530952122477 \n",
      "acc for Psat= 0.137383457324985 \n",
      "acc for optim= 0.15359087754040956\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.00361460680142045\n",
      "Loss on test= 0.006165885832160711\n",
      "acc for Lsat= 0.10659423152295251 \n",
      "acc for Psat= 0.13144701926244629 \n",
      "acc for optim= 0.17456347813681028\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.0035105450078845024\n",
      "Loss on test= 0.005899982526898384\n",
      "acc for Lsat= 0.11811123312347466 \n",
      "acc for Psat= 0.09623775232790245 \n",
      "acc for optim= 0.1511251280931497\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.0036327550187706947\n",
      "Loss on test= 0.005933178588747978\n",
      "acc for Lsat= 0.14177750847819778 \n",
      "acc for Psat= 0.07862808442829798 \n",
      "acc for optim= 0.18362059257924557\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.0036445443984121084\n",
      "Loss on test= 0.0061353356577456\n",
      "acc for Lsat= 0.11467944723942007 \n",
      "acc for Psat= 0.12262798871638046 \n",
      "acc for optim= 0.16650871598782638\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.0036109702195972204\n",
      "Loss on test= 0.0064711072482168674\n",
      "acc for Lsat= 0.13243401298920313 \n",
      "acc for Psat= 0.12214096387227376 \n",
      "acc for optim= 0.16665005420024195\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.003683122107759118\n",
      "Loss on test= 0.006422149017453194\n",
      "acc for Lsat= 0.11802613911115462 \n",
      "acc for Psat= 0.12978288122556275 \n",
      "acc for optim= 0.163100512801773\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.0036521018482744694\n",
      "Loss on test= 0.006029762793332338\n",
      "acc for Lsat= 0.10305111317170991 \n",
      "acc for Psat= 0.09212027750779977 \n",
      "acc for optim= 0.1541301137217993\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.0035390094853937626\n",
      "Loss on test= 0.006602639798074961\n",
      "acc for Lsat= 0.10504425917234686 \n",
      "acc for Psat= 0.11774057687984572 \n",
      "acc for optim= 0.14784764508820242\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.003575463779270649\n",
      "Loss on test= 0.0058750612661242485\n",
      "acc for Lsat= 0.1134606918009619 \n",
      "acc for Psat= 0.1198708405200806 \n",
      "acc for optim= 0.13631540438574222\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.003547405358403921\n",
      "Loss on test= 0.006210679654031992\n",
      "acc for Lsat= 0.0876719891352372 \n",
      "acc for Psat= 0.10234438806138416 \n",
      "acc for optim= 0.17875678922670582\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.003469684859737754\n",
      "Loss on test= 0.006475631147623062\n",
      "acc for Lsat= 0.1208513856658505 \n",
      "acc for Psat= 0.0992308138197081 \n",
      "acc for optim= 0.14956107601109478\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.003574895206838846\n",
      "Loss on test= 0.006265267264097929\n",
      "acc for Lsat= 0.11912726727314293 \n",
      "acc for Psat= 0.13532422141482434 \n",
      "acc for optim= 0.15532078055871856\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.003717910498380661\n",
      "Loss on test= 0.006073973141610622\n",
      "acc for Lsat= 0.07849071385701084 \n",
      "acc for Psat= 0.16601253156032827 \n",
      "acc for optim= 0.15494027444057995\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.003554191207513213\n",
      "Loss on test= 0.006501395720988512\n",
      "acc for Lsat= 0.0900109449091057 \n",
      "acc for Psat= 0.09589390089321467 \n",
      "acc for optim= 0.14742700790045798\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.003689677221700549\n",
      "Loss on test= 0.006260784808546305\n",
      "acc for Lsat= 0.1290040846603612 \n",
      "acc for Psat= 0.1432532101817843 \n",
      "acc for optim= 0.1847292434734603\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.0035265202168375254\n",
      "Loss on test= 0.006144838407635689\n",
      "acc for Lsat= 0.10282769988730757 \n",
      "acc for Psat= 0.15454887816061577 \n",
      "acc for optim= 0.153967183510152\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.0036851889453828335\n",
      "Loss on test= 0.006202777847647667\n",
      "acc for Lsat= 0.07822117776413506 \n",
      "acc for Psat= 0.13753170921053323 \n",
      "acc for optim= 0.16613646927807066\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.003446354530751705\n",
      "Loss on test= 0.0061073447577655315\n",
      "acc for Lsat= 0.09695765921949512 \n",
      "acc for Psat= 0.1262851362828062 \n",
      "acc for optim= 0.16437302223251513\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.0035784842912107706\n",
      "Loss on test= 0.006455674301832914\n",
      "acc for Lsat= 0.12567396772404513 \n",
      "acc for Psat= 0.15735844067401356 \n",
      "acc for optim= 0.16429304207364717\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.0033777912613004446\n",
      "Loss on test= 0.006101580336689949\n",
      "acc for Lsat= 0.11479922063234779 \n",
      "acc for Psat= 0.1301727133007565 \n",
      "acc for optim= 0.18077607618437874\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.0034512768033891916\n",
      "Loss on test= 0.0058999499306082726\n",
      "acc for Lsat= 0.1295544551168051 \n",
      "acc for Psat= 0.15750690632396275 \n",
      "acc for optim= 0.15846644202247262\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.003598635084927082\n",
      "Loss on test= 0.006073357071727514\n",
      "acc for Lsat= 0.11784421875038081 \n",
      "acc for Psat= 0.14143088361662295 \n",
      "acc for optim= 0.17411256954073906\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.003616445465013385\n",
      "Loss on test= 0.006157460156828165\n",
      "acc for Lsat= 0.13956683341206777 \n",
      "acc for Psat= 0.1645100996312168 \n",
      "acc for optim= 0.13173645056991112\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.00361770112067461\n",
      "Loss on test= 0.006186133716255426\n",
      "acc for Lsat= 0.09565907614564316 \n",
      "acc for Psat= 0.11637268820777535 \n",
      "acc for optim= 0.1753231124021113\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.003609051462262869\n",
      "Loss on test= 0.006032422184944153\n",
      "acc for Lsat= 0.11441667403818832 \n",
      "acc for Psat= 0.1215144521298094 \n",
      "acc for optim= 0.1743993800547388\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.0034363160375505686\n",
      "Loss on test= 0.006384692154824734\n",
      "acc for Lsat= 0.08653444870530318 \n",
      "acc for Psat= 0.13281981305529675 \n",
      "acc for optim= 0.18408715373112094\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.0035500330850481987\n",
      "Loss on test= 0.006027556024491787\n",
      "acc for Lsat= 0.10257703040002121 \n",
      "acc for Psat= 0.11789197795506981 \n",
      "acc for optim= 0.168412159403993\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.0034127002581954002\n",
      "Loss on test= 0.007110279519110918\n",
      "acc for Lsat= 0.13762074382652323 \n",
      "acc for Psat= 0.1371328441115717 \n",
      "acc for optim= 0.16701147806209823\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.003599253948777914\n",
      "Loss on test= 0.006134134717285633\n",
      "acc for Lsat= 0.11584733312742578 \n",
      "acc for Psat= 0.11302428257962067 \n",
      "acc for optim= 0.1360465172264311\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.00348724820651114\n",
      "Loss on test= 0.006031893193721771\n",
      "acc for Lsat= 0.14005689405732685 \n",
      "acc for Psat= 0.13034657379871029 \n",
      "acc for optim= 0.15913085686042905\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.003653643187135458\n",
      "Loss on test= 0.006439263001084328\n",
      "acc for Lsat= 0.13474173137607673 \n",
      "acc for Psat= 0.09409566777240899 \n",
      "acc for optim= 0.15893043942439058\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.003514021635055542\n",
      "Loss on test= 0.006031205877661705\n",
      "acc for Lsat= 0.08257010330756505 \n",
      "acc for Psat= 0.09811551888318111 \n",
      "acc for optim= 0.14308374169437835\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.0034502632915973663\n",
      "Loss on test= 0.006161753088235855\n",
      "acc for Lsat= 0.09460377605218026 \n",
      "acc for Psat= 0.12726968004264766 \n",
      "acc for optim= 0.17366802940766016\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.003456095000728965\n",
      "Loss on test= 0.006475385744124651\n",
      "acc for Lsat= 0.11427012080740598 \n",
      "acc for Psat= 0.1257131279303899 \n",
      "acc for optim= 0.1721504407727884\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.0035204968880861998\n",
      "Loss on test= 0.005965725984424353\n",
      "acc for Lsat= 0.0989341162559059 \n",
      "acc for Psat= 0.11362575470573372 \n",
      "acc for optim= 0.16418107730957368\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.003601226257160306\n",
      "Loss on test= 0.006072745192795992\n",
      "acc for Lsat= 0.08181278741297622 \n",
      "acc for Psat= 0.0934180064262667 \n",
      "acc for optim= 0.14985656099290484\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.003523442894220352\n",
      "Loss on test= 0.006448149215430021\n",
      "acc for Lsat= 0.10886937674755852 \n",
      "acc for Psat= 0.12630281910403734 \n",
      "acc for optim= 0.13926195544708106\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.0033826364669948816\n",
      "Loss on test= 0.006341995671391487\n",
      "acc for Lsat= 0.09349752401208712 \n",
      "acc for Psat= 0.14527287929215366 \n",
      "acc for optim= 0.16278806186488104\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.0035615349188447\n",
      "Loss on test= 0.005937560461461544\n",
      "acc for Lsat= 0.11959872581711453 \n",
      "acc for Psat= 0.15952595116363633 \n",
      "acc for optim= 0.14341310389702105\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.003547624684870243\n",
      "Loss on test= 0.006267196964472532\n",
      "acc for Lsat= 0.1043690815826671 \n",
      "acc for Psat= 0.10510414719788565 \n",
      "acc for optim= 0.17072589312576586\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.003418564796447754\n",
      "Loss on test= 0.006110521033406258\n",
      "acc for Lsat= 0.12461551167588267 \n",
      "acc for Psat= 0.10249072890211311 \n",
      "acc for optim= 0.15220174260644448\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.003341534873470664\n",
      "Loss on test= 0.006039352621883154\n",
      "acc for Lsat= 0.1083047228296184 \n",
      "acc for Psat= 0.1157343623538812 \n",
      "acc for optim= 0.16424934211600986\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.0034729682374745607\n",
      "Loss on test= 0.005981906782835722\n",
      "acc for Lsat= 0.12296847797309358 \n",
      "acc for Psat= 0.0931185595772048 \n",
      "acc for optim= 0.1481134163008796\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.0035307796206325293\n",
      "Loss on test= 0.006249791011214256\n",
      "acc for Lsat= 0.10164417878129622 \n",
      "acc for Psat= 0.13649293718238673 \n",
      "acc for optim= 0.14843531286654374\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.0035729208029806614\n",
      "Loss on test= 0.006267246324568987\n",
      "acc for Lsat= 0.10052028857171535 \n",
      "acc for Psat= 0.14376981326171923 \n",
      "acc for optim= 0.15195790228123465\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.0035767422523349524\n",
      "Loss on test= 0.006306807044893503\n",
      "acc for Lsat= 0.10602176934480667 \n",
      "acc for Psat= 0.13995605109569928 \n",
      "acc for optim= 0.1620972370090183\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.00344333634711802\n",
      "Loss on test= 0.0060304817743599415\n",
      "acc for Lsat= 0.07676052333166201 \n",
      "acc for Psat= 0.08731889864429832 \n",
      "acc for optim= 0.15286714969099396\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.003507912391796708\n",
      "Loss on test= 0.006118305958807468\n",
      "acc for Lsat= 0.10953116548868518 \n",
      "acc for Psat= 0.12433100300323632 \n",
      "acc for optim= 0.14892840252206144\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.003494815668091178\n",
      "Loss on test= 0.006361176259815693\n",
      "acc for Lsat= 0.10407476644549105 \n",
      "acc for Psat= 0.08563811350904871 \n",
      "acc for optim= 0.14518223682373194\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.0035686343908309937\n",
      "Loss on test= 0.006224173586815596\n",
      "acc for Lsat= 0.11665931644125117 \n",
      "acc for Psat= 0.1251760703097615 \n",
      "acc for optim= 0.15248274360460023\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.0035524701233953238\n",
      "Loss on test= 0.005966245196759701\n",
      "acc for Lsat= 0.11534901232355171 \n",
      "acc for Psat= 0.12375986953783366 \n",
      "acc for optim= 0.13885480677708983\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.003404101822525263\n",
      "Loss on test= 0.006117097567766905\n",
      "acc for Lsat= 0.12047092895954847 \n",
      "acc for Psat= 0.11373316715212746 \n",
      "acc for optim= 0.16775345507388315\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.003484950168058276\n",
      "Loss on test= 0.005917397793382406\n",
      "acc for Lsat= 0.07510885267725421 \n",
      "acc for Psat= 0.12669146288600233 \n",
      "acc for optim= 0.1335478431234757\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.003570424159988761\n",
      "Loss on test= 0.006215061992406845\n",
      "acc for Lsat= 0.1403092091722 \n",
      "acc for Psat= 0.08701598263966541 \n",
      "acc for optim= 0.15764808437476555\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.0034637528005987406\n",
      "Loss on test= 0.006171799264848232\n",
      "acc for Lsat= 0.10207215866022226 \n",
      "acc for Psat= 0.11539911941832139 \n",
      "acc for optim= 0.1680769757885072\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.003395993262529373\n",
      "Loss on test= 0.006205187179148197\n",
      "acc for Lsat= 0.10281722284465407 \n",
      "acc for Psat= 0.0805072487435407 \n",
      "acc for optim= 0.19467066171475583\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.003492075717076659\n",
      "Loss on test= 0.005933098495006561\n",
      "acc for Lsat= 0.09670974628534168 \n",
      "acc for Psat= 0.15292505899237263 \n",
      "acc for optim= 0.15687097898787922\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.003455806290730834\n",
      "Loss on test= 0.005811390001326799\n",
      "acc for Lsat= 0.10637885042362744 \n",
      "acc for Psat= 0.09087230366033812 \n",
      "acc for optim= 0.18658999876222676\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.0033195994328707457\n",
      "Loss on test= 0.006490049418061972\n",
      "acc for Lsat= 0.105698005684341 \n",
      "acc for Psat= 0.10153868913443552 \n",
      "acc for optim= 0.15626978118800455\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.0034107898827642202\n",
      "Loss on test= 0.006566720083355904\n",
      "acc for Lsat= 0.11136677480923633 \n",
      "acc for Psat= 0.15119842160493135 \n",
      "acc for optim= 0.1479478898820364\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.0033774639014154673\n",
      "Loss on test= 0.006322858855128288\n",
      "acc for Lsat= 0.07636680412623617 \n",
      "acc for Psat= 0.09082102016287132 \n",
      "acc for optim= 0.15737880135162008\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.0035223430022597313\n",
      "Loss on test= 0.005946730263531208\n",
      "acc for Lsat= 0.12087569810036156 \n",
      "acc for Psat= 0.13784922447262538 \n",
      "acc for optim= 0.16417694060752788\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.003437305800616741\n",
      "Loss on test= 0.006243349984288216\n",
      "acc for Lsat= 0.09982051206235257 \n",
      "acc for Psat= 0.10088114979185371 \n",
      "acc for optim= 0.1580424128850508\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.0034734478686004877\n",
      "Loss on test= 0.006521800998598337\n",
      "acc for Lsat= 0.10898839666818579 \n",
      "acc for Psat= 0.13303987371424833 \n",
      "acc for optim= 0.15884938639485174\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.0033596379216760397\n",
      "Loss on test= 0.006109841167926788\n",
      "acc for Lsat= 0.0825046667855026 \n",
      "acc for Psat= 0.13613213567684093 \n",
      "acc for optim= 0.16715406559200752\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.0033374724444001913\n",
      "Loss on test= 0.006180787459015846\n",
      "acc for Lsat= 0.15872636975513565 \n",
      "acc for Psat= 0.1234310335583157 \n",
      "acc for optim= 0.15442678497897255\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.0033899315167218447\n",
      "Loss on test= 0.006230682600289583\n",
      "acc for Lsat= 0.12565034503738085 \n",
      "acc for Psat= 0.16344821391006312 \n",
      "acc for optim= 0.13271561378820074\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.00351037853397429\n",
      "Loss on test= 0.006647142581641674\n",
      "acc for Lsat= 0.09142702041814725 \n",
      "acc for Psat= 0.11754262312832806 \n",
      "acc for optim= 0.16447365695623578\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.0035125783178955317\n",
      "Loss on test= 0.0066552418284118176\n",
      "acc for Lsat= 0.14745354812799227 \n",
      "acc for Psat= 0.14620540347985095 \n",
      "acc for optim= 0.16581107859706712\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.0033408922608941793\n",
      "Loss on test= 0.006398929748684168\n",
      "acc for Lsat= 0.13646724804614982 \n",
      "acc for Psat= 0.16037838054924375 \n",
      "acc for optim= 0.1742592498453127\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.0035953412298113108\n",
      "Loss on test= 0.00629012193530798\n",
      "acc for Lsat= 0.12373898126598862 \n",
      "acc for Psat= 0.09794900945336041 \n",
      "acc for optim= 0.15457394482574374\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.0034227038267999887\n",
      "Loss on test= 0.006364984903484583\n",
      "acc for Lsat= 0.1176667769646479 \n",
      "acc for Psat= 0.10093925065464443 \n",
      "acc for optim= 0.14081575095446575\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.0034487044904381037\n",
      "Loss on test= 0.006152583751827478\n",
      "acc for Lsat= 0.08607151499018073 \n",
      "acc for Psat= 0.08480076471136676 \n",
      "acc for optim= 0.16633157138454002\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.0034270731266587973\n",
      "Loss on test= 0.006257223896682262\n",
      "acc for Lsat= 0.11470602967569397 \n",
      "acc for Psat= 0.13587491162535217 \n",
      "acc for optim= 0.18009888388526937\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.003411184996366501\n",
      "Loss on test= 0.005834057927131653\n",
      "acc for Lsat= 0.06512907910574642 \n",
      "acc for Psat= 0.10332857199116713 \n",
      "acc for optim= 0.14902935430614483\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.0033157370053231716\n",
      "Loss on test= 0.006425352767109871\n",
      "acc for Lsat= 0.13802684476185176 \n",
      "acc for Psat= 0.12580596402080524 \n",
      "acc for optim= 0.15862933900724682\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.0034667698200792074\n",
      "Loss on test= 0.00602769386023283\n",
      "acc for Lsat= 0.08452783990651369 \n",
      "acc for Psat= 0.1424241883376251 \n",
      "acc for optim= 0.1712791899012195\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.003539455821737647\n",
      "Loss on test= 0.00603372510522604\n",
      "acc for Lsat= 0.09767036931831778 \n",
      "acc for Psat= 0.1250983608398302 \n",
      "acc for optim= 0.12900473296435344\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.0033451966010034084\n",
      "Loss on test= 0.006163274869322777\n",
      "acc for Lsat= 0.12083082291711536 \n",
      "acc for Psat= 0.09796651190360232 \n",
      "acc for optim= 0.13066772741472554\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.0035256429109722376\n",
      "Loss on test= 0.006400578655302525\n",
      "acc for Lsat= 0.0779988547696525 \n",
      "acc for Psat= 0.11887072739450054 \n",
      "acc for optim= 0.17864374164491892\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.0035053237807005644\n",
      "Loss on test= 0.006264263764023781\n",
      "acc for Lsat= 0.10933868737063474 \n",
      "acc for Psat= 0.10052121409939395 \n",
      "acc for optim= 0.18871669698920515\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.003476957092061639\n",
      "Loss on test= 0.006260939408093691\n",
      "acc for Lsat= 0.09359895210299227 \n",
      "acc for Psat= 0.11903085562193559 \n",
      "acc for optim= 0.15968582010181206\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.003446221351623535\n",
      "Loss on test= 0.006174155976623297\n",
      "acc for Lsat= 0.10022532557033831 \n",
      "acc for Psat= 0.11564038349832925 \n",
      "acc for optim= 0.19232471080289948\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.003436972154304385\n",
      "Loss on test= 0.00623156176880002\n",
      "acc for Lsat= 0.1212558345675158 \n",
      "acc for Psat= 0.1456413647910166 \n",
      "acc for optim= 0.17773072690599495\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.00342261022888124\n",
      "Loss on test= 0.006414863746613264\n",
      "acc for Lsat= 0.10492528463914318 \n",
      "acc for Psat= 0.16418770907653701 \n",
      "acc for optim= 0.13636553846299648\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.0033796904608607292\n",
      "Loss on test= 0.005825781263411045\n",
      "acc for Lsat= 0.14359871359839518 \n",
      "acc for Psat= 0.10538413414097805 \n",
      "acc for optim= 0.1335303814460834\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.003505367087200284\n",
      "Loss on test= 0.006096766795963049\n",
      "acc for Lsat= 0.09051848660844068 \n",
      "acc for Psat= 0.10753860100845082 \n",
      "acc for optim= 0.1290405466635194\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.0034548426046967506\n",
      "Loss on test= 0.006118195131421089\n",
      "acc for Lsat= 0.12179403089814717 \n",
      "acc for Psat= 0.11628858194712342 \n",
      "acc for optim= 0.12570599538998473\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.003306589787825942\n",
      "Loss on test= 0.00664131436496973\n",
      "acc for Lsat= 0.1339812988622321 \n",
      "acc for Psat= 0.15905654668394062 \n",
      "acc for optim= 0.1678843977343705\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.0036018958780914545\n",
      "Loss on test= 0.006521483417600393\n",
      "acc for Lsat= 0.10296610727285345 \n",
      "acc for Psat= 0.12280678022135463 \n",
      "acc for optim= 0.17002230429918402\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.003459785832092166\n",
      "Loss on test= 0.0060765501111745834\n",
      "acc for Lsat= 0.11527193558868021 \n",
      "acc for Psat= 0.11652630984058811 \n",
      "acc for optim= 0.1888923164482953\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.0034993102308362722\n",
      "Loss on test= 0.006005742121487856\n",
      "acc for Lsat= 0.13132020559472343 \n",
      "acc for Psat= 0.11637171347875766 \n",
      "acc for optim= 0.1767761483295342\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.0036323985550552607\n",
      "Loss on test= 0.006213439628481865\n",
      "acc for Lsat= 0.10252012840161721 \n",
      "acc for Psat= 0.10830092404244675 \n",
      "acc for optim= 0.1733725639577541\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.003316818969324231\n",
      "Loss on test= 0.006330216769129038\n",
      "acc for Lsat= 0.1154705264295141 \n",
      "acc for Psat= 0.11573696687507133 \n",
      "acc for optim= 0.12123260274529457\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.0033791298046708107\n",
      "Loss on test= 0.006077336147427559\n",
      "acc for Lsat= 0.109526688621069 \n",
      "acc for Psat= 0.09149109153077006 \n",
      "acc for optim= 0.14965603025242066\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.0034145796671509743\n",
      "Loss on test= 0.006149708293378353\n",
      "acc for Lsat= 0.12144995584256119 \n",
      "acc for Psat= 0.13388120217455757 \n",
      "acc for optim= 0.15866788998472556\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.003480716608464718\n",
      "Loss on test= 0.0065062930807471275\n",
      "acc for Lsat= 0.11213484810246478 \n",
      "acc for Psat= 0.10257820629178444 \n",
      "acc for optim= 0.14553512757023176\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.003505345433950424\n",
      "Loss on test= 0.006265309639275074\n",
      "acc for Lsat= 0.09657533870389064 \n",
      "acc for Psat= 0.15318489388381648 \n",
      "acc for optim= 0.16085342586544962\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.0035207427572458982\n",
      "Loss on test= 0.006487803068011999\n",
      "acc for Lsat= 0.08392688127545019 \n",
      "acc for Psat= 0.09622481049478261 \n",
      "acc for optim= 0.14599134845452177\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.003530112560838461\n",
      "Loss on test= 0.00622904859483242\n",
      "acc for Lsat= 0.11884411952147882 \n",
      "acc for Psat= 0.10255708410922024 \n",
      "acc for optim= 0.15743639369935003\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.00340320379473269\n",
      "Loss on test= 0.006310622673481703\n",
      "acc for Lsat= 0.10560658656888539 \n",
      "acc for Psat= 0.10890137311071157 \n",
      "acc for optim= 0.17061031004413962\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.0033215864095836878\n",
      "Loss on test= 0.00630525778979063\n",
      "acc for Lsat= 0.10767021464804809 \n",
      "acc for Psat= 0.14616262447088957 \n",
      "acc for optim= 0.1516706534829508\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.003320695599541068\n",
      "Loss on test= 0.005930997896939516\n",
      "acc for Lsat= 0.11645486703006706 \n",
      "acc for Psat= 0.1103269166002671 \n",
      "acc for optim= 0.1571209202003148\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.00329661276191473\n",
      "Loss on test= 0.006210275925695896\n",
      "acc for Lsat= 0.10808524479054743 \n",
      "acc for Psat= 0.17279683609700036 \n",
      "acc for optim= 0.13680578305179047\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.0033670009579509497\n",
      "Loss on test= 0.005882130935788155\n",
      "acc for Lsat= 0.07418994482658389 \n",
      "acc for Psat= 0.13647728744480345 \n",
      "acc for optim= 0.14908506527232626\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.003492414252832532\n",
      "Loss on test= 0.006335204932838678\n",
      "acc for Lsat= 0.08513794095940991 \n",
      "acc for Psat= 0.12431730392078559 \n",
      "acc for optim= 0.15186102046734756\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.003415432060137391\n",
      "Loss on test= 0.005863305646926165\n",
      "acc for Lsat= 0.09640380623750389 \n",
      "acc for Psat= 0.1218654809191422 \n",
      "acc for optim= 0.1679726033988926\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.003382278373464942\n",
      "Loss on test= 0.006061851978302002\n",
      "acc for Lsat= 0.08301928820502427 \n",
      "acc for Psat= 0.1164000363399585 \n",
      "acc for optim= 0.15679566262082922\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.0034158646594733\n",
      "Loss on test= 0.0063606929033994675\n",
      "acc for Lsat= 0.08596963352627224 \n",
      "acc for Psat= 0.10309489728468987 \n",
      "acc for optim= 0.15429508983571497\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.0033258639741688967\n",
      "Loss on test= 0.006468741223216057\n",
      "acc for Lsat= 0.08886011535974427 \n",
      "acc for Psat= 0.17073688914792406 \n",
      "acc for optim= 0.13109118398278952\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.0034060319885611534\n",
      "Loss on test= 0.006264377385377884\n",
      "acc for Lsat= 0.1015578802778489 \n",
      "acc for Psat= 0.0978509440448963 \n",
      "acc for optim= 0.1349207418324012\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.0033293599262833595\n",
      "Loss on test= 0.00599973788484931\n",
      "acc for Lsat= 0.10946186207648781 \n",
      "acc for Psat= 0.10125716030996854 \n",
      "acc for optim= 0.1589907657665511\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.003402029164135456\n",
      "Loss on test= 0.006263758987188339\n",
      "acc for Lsat= 0.10512224292486078 \n",
      "acc for Psat= 0.09104368064759506 \n",
      "acc for optim= 0.18510092360277972\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.003321065567433834\n",
      "Loss on test= 0.005904856603592634\n",
      "acc for Lsat= 0.14855790960912904 \n",
      "acc for Psat= 0.15555801095130542 \n",
      "acc for optim= 0.1586850840701825\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.003352052764967084\n",
      "Loss on test= 0.006082936655730009\n",
      "acc for Lsat= 0.0962792220654794 \n",
      "acc for Psat= 0.10502426646417007 \n",
      "acc for optim= 0.1317751170653436\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.0033080563880503178\n",
      "Loss on test= 0.0062773325480520725\n",
      "acc for Lsat= 0.08950693341385987 \n",
      "acc for Psat= 0.10540612730094129 \n",
      "acc for optim= 0.16347194173269802\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.0035078017972409725\n",
      "Loss on test= 0.0065221176482737064\n",
      "acc for Lsat= 0.11607304238714278 \n",
      "acc for Psat= 0.13379514714082083 \n",
      "acc for optim= 0.14317410545320147\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.003518638899549842\n",
      "Loss on test= 0.005875658709555864\n",
      "acc for Lsat= 0.08827213285904792 \n",
      "acc for Psat= 0.12651452504926258 \n",
      "acc for optim= 0.19552224884844488\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.003367510624229908\n",
      "Loss on test= 0.006248035933822393\n",
      "acc for Lsat= 0.12346589213444127 \n",
      "acc for Psat= 0.11609347736359471 \n",
      "acc for optim= 0.1695930574060185\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.003518136451020837\n",
      "Loss on test= 0.006097284145653248\n",
      "acc for Lsat= 0.1266581474079026 \n",
      "acc for Psat= 0.15611018085231385 \n",
      "acc for optim= 0.1356127578506453\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.0034095102455466986\n",
      "Loss on test= 0.005955260246992111\n",
      "acc for Lsat= 0.11823664491789208 \n",
      "acc for Psat= 0.11130428862654501 \n",
      "acc for optim= 0.15344504293494132\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.003501935862004757\n",
      "Loss on test= 0.006195700261741877\n",
      "acc for Lsat= 0.08549945682494177 \n",
      "acc for Psat= 0.13100938354101446 \n",
      "acc for optim= 0.1419408492381788\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.0033272705040872097\n",
      "Loss on test= 0.006144974380731583\n",
      "acc for Lsat= 0.094293095688853 \n",
      "acc for Psat= 0.11916183199112614 \n",
      "acc for optim= 0.15137778002665275\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.003377624088898301\n",
      "Loss on test= 0.0061512719839811325\n",
      "acc for Lsat= 0.07396190103867815 \n",
      "acc for Psat= 0.09216804028902617 \n",
      "acc for optim= 0.1539335156687432\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.003442796878516674\n",
      "Loss on test= 0.006356260739266872\n",
      "acc for Lsat= 0.08716344236422123 \n",
      "acc for Psat= 0.10573227923466927 \n",
      "acc for optim= 0.16250130171991056\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.0033891811035573483\n",
      "Loss on test= 0.006225242279469967\n",
      "acc for Lsat= 0.11784860141859907 \n",
      "acc for Psat= 0.10303888878681594 \n",
      "acc for optim= 0.15786544096449184\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.0031813473906368017\n",
      "Loss on test= 0.005850482266396284\n",
      "acc for Lsat= 0.09734037358106838 \n",
      "acc for Psat= 0.1381955426445024 \n",
      "acc for optim= 0.16716161644500163\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.0033681667409837246\n",
      "Loss on test= 0.0060965013690292835\n",
      "acc for Lsat= 0.09847621845741135 \n",
      "acc for Psat= 0.10476203374047247 \n",
      "acc for optim= 0.14905896291586235\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.003316372400149703\n",
      "Loss on test= 0.0064548105001449585\n",
      "acc for Lsat= 0.09837965967340602 \n",
      "acc for Psat= 0.13321185029215282 \n",
      "acc for optim= 0.2155360381002538\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.003347544465214014\n",
      "Loss on test= 0.0059455763548612595\n",
      "acc for Lsat= 0.112937091733329 \n",
      "acc for Psat= 0.0814334882339204 \n",
      "acc for optim= 0.1604389219234387\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.003300064941868186\n",
      "Loss on test= 0.006555112544447184\n",
      "acc for Lsat= 0.0991726048070834 \n",
      "acc for Psat= 0.093374599786734 \n",
      "acc for optim= 0.15275070992194945\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.0033596805296838284\n",
      "Loss on test= 0.00618832977488637\n",
      "acc for Lsat= 0.14021143896712196 \n",
      "acc for Psat= 0.1455358009164532 \n",
      "acc for optim= 0.17274904592583576\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.0033491752110421658\n",
      "Loss on test= 0.0060641951858997345\n",
      "acc for Lsat= 0.14425286205692422 \n",
      "acc for Psat= 0.1345995665113959 \n",
      "acc for optim= 0.16771017263333002\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.0034672566689550877\n",
      "Loss on test= 0.006440380122512579\n",
      "acc for Lsat= 0.1172353561139769 \n",
      "acc for Psat= 0.09974182591152687 \n",
      "acc for optim= 0.1386590675942393\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.003420740133151412\n",
      "Loss on test= 0.00585679616779089\n",
      "acc for Lsat= 0.12144178329941092 \n",
      "acc for Psat= 0.09723603678867221 \n",
      "acc for optim= 0.1445519429528051\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.0033719108905643225\n",
      "Loss on test= 0.00629847077652812\n",
      "acc for Lsat= 0.09099667638333307 \n",
      "acc for Psat= 0.13088219824971425 \n",
      "acc for optim= 0.18208832945674658\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.0033165328204631805\n",
      "Loss on test= 0.0063260626047849655\n",
      "acc for Lsat= 0.09474574215710163 \n",
      "acc for Psat= 0.10868799965828657 \n",
      "acc for optim= 0.15131084284641677\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.003306739963591099\n",
      "Loss on test= 0.006179459393024445\n",
      "acc for Lsat= 0.08753934717646593 \n",
      "acc for Psat= 0.11649250254655878 \n",
      "acc for optim= 0.1550061140830318\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.0033516110852360725\n",
      "Loss on test= 0.006328664720058441\n",
      "acc for Lsat= 0.11577726227955686 \n",
      "acc for Psat= 0.12282053841206814 \n",
      "acc for optim= 0.15004114981275052\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.0034858770668506622\n",
      "Loss on test= 0.006342190317809582\n",
      "acc for Lsat= 0.10864841017044252 \n",
      "acc for Psat= 0.1047060046500216 \n",
      "acc for optim= 0.1601859200972184\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.003288692096248269\n",
      "Loss on test= 0.0062250797636806965\n",
      "acc for Lsat= 0.12804389263813695 \n",
      "acc for Psat= 0.14807931685613263 \n",
      "acc for optim= 0.19538277987804678\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.0033715993631631136\n",
      "Loss on test= 0.0058188848197460175\n",
      "acc for Lsat= 0.11083419595120682 \n",
      "acc for Psat= 0.1273213235092246 \n",
      "acc for optim= 0.18175239700617063\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.003341879928484559\n",
      "Loss on test= 0.005811058450490236\n",
      "acc for Lsat= 0.09409820505728324 \n",
      "acc for Psat= 0.100917773159583 \n",
      "acc for optim= 0.17421010488437283\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.0033452631905674934\n",
      "Loss on test= 0.006202110089361668\n",
      "acc for Lsat= 0.0974660659622815 \n",
      "acc for Psat= 0.10097837468816175 \n",
      "acc for optim= 0.15419824162705076\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.003377869725227356\n",
      "Loss on test= 0.0063406238332390785\n",
      "acc for Lsat= 0.15769312613540226 \n",
      "acc for Psat= 0.11975224781781435 \n",
      "acc for optim= 0.14482680648668772\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.0034042128827422857\n",
      "Loss on test= 0.006264671217650175\n",
      "acc for Lsat= 0.10412823765849073 \n",
      "acc for Psat= 0.11702998408711413 \n",
      "acc for optim= 0.17832638757924238\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.0034260342363268137\n",
      "Loss on test= 0.006111377850174904\n",
      "acc for Lsat= 0.10186319296351737 \n",
      "acc for Psat= 0.13321499831767547 \n",
      "acc for optim= 0.13270225631681065\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.003337470581755042\n",
      "Loss on test= 0.005970085971057415\n",
      "acc for Lsat= 0.10329266664080529 \n",
      "acc for Psat= 0.12854679704954228 \n",
      "acc for optim= 0.1664067723063959\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.003402191447094083\n",
      "Loss on test= 0.006269306875765324\n",
      "acc for Lsat= 0.106883160252538 \n",
      "acc for Psat= 0.12969887290253407 \n",
      "acc for optim= 0.16882942942902446\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.0032989128958433867\n",
      "Loss on test= 0.006321779452264309\n",
      "acc for Lsat= 0.10527731126381291 \n",
      "acc for Psat= 0.12171964271369183 \n",
      "acc for optim= 0.13245599846252137\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.0032585018780082464\n",
      "Loss on test= 0.006208149716258049\n",
      "acc for Lsat= 0.10846900081055032 \n",
      "acc for Psat= 0.13678233051258656 \n",
      "acc for optim= 0.15769336335749054\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.003430779092013836\n",
      "Loss on test= 0.006190179381519556\n",
      "acc for Lsat= 0.10408952741676734 \n",
      "acc for Psat= 0.10854837042279541 \n",
      "acc for optim= 0.13353797542448673\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.0032710672821849585\n",
      "Loss on test= 0.006112167611718178\n",
      "acc for Lsat= 0.14521264171020853 \n",
      "acc for Psat= 0.15530941653479305 \n",
      "acc for optim= 0.16792028630152345\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.003357566660270095\n",
      "Loss on test= 0.006513142958283424\n",
      "acc for Lsat= 0.10775563715853625 \n",
      "acc for Psat= 0.12074652860327559 \n",
      "acc for optim= 0.15386698281185496\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.0032159886322915554\n",
      "Loss on test= 0.005850069224834442\n",
      "acc for Lsat= 0.11239141484515534 \n",
      "acc for Psat= 0.11451085346440475 \n",
      "acc for optim= 0.17739921347755525\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.0032922110985964537\n",
      "Loss on test= 0.0060409787110984325\n",
      "acc for Lsat= 0.10025110748958671 \n",
      "acc for Psat= 0.13548941227296987 \n",
      "acc for optim= 0.17860432403783003\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.003343147225677967\n",
      "Loss on test= 0.0060377223417162895\n",
      "acc for Lsat= 0.08705391755534543 \n",
      "acc for Psat= 0.14711862595544922 \n",
      "acc for optim= 0.16353234948797357\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.0031130879651755095\n",
      "Loss on test= 0.0058445711620152\n",
      "acc for Lsat= 0.11707446682784292 \n",
      "acc for Psat= 0.1088883331265404 \n",
      "acc for optim= 0.15389900989571792\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.003328542923554778\n",
      "Loss on test= 0.005774488672614098\n",
      "acc for Lsat= 0.11547524916628997 \n",
      "acc for Psat= 0.10888399670107497 \n",
      "acc for optim= 0.15780749505696198\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.0032749243546277285\n",
      "Loss on test= 0.006031596567481756\n",
      "acc for Lsat= 0.08609309823562701 \n",
      "acc for Psat= 0.12131287074751324 \n",
      "acc for optim= 0.15694395379008105\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.003248620545491576\n",
      "Loss on test= 0.006141240242868662\n",
      "acc for Lsat= 0.06873765670590931 \n",
      "acc for Psat= 0.11757425389563043 \n",
      "acc for optim= 0.133610675473594\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.003441744949668646\n",
      "Loss on test= 0.006106468848884106\n",
      "acc for Lsat= 0.10165512682093929 \n",
      "acc for Psat= 0.08959699018547933 \n",
      "acc for optim= 0.18902836740016937\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.0031664976850152016\n",
      "Loss on test= 0.00639685895293951\n",
      "acc for Lsat= 0.12612798530608416 \n",
      "acc for Psat= 0.11888317898329762 \n",
      "acc for optim= 0.197331874527865\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.0032178706023842096\n",
      "Loss on test= 0.006108875852078199\n",
      "acc for Lsat= 0.1204611082535444 \n",
      "acc for Psat= 0.13303273375560012 \n",
      "acc for optim= 0.1750292799487296\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.0033243612851947546\n",
      "Loss on test= 0.00650604534894228\n",
      "acc for Lsat= 0.0982713479639238 \n",
      "acc for Psat= 0.12834449986823732 \n",
      "acc for optim= 0.1658644573763013\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.0032982046250253916\n",
      "Loss on test= 0.006451238878071308\n",
      "acc for Lsat= 0.12177235114621807 \n",
      "acc for Psat= 0.12362489926939209 \n",
      "acc for optim= 0.18121797788060373\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.0033450813498347998\n",
      "Loss on test= 0.006173641420900822\n",
      "acc for Lsat= 0.10488978129190703 \n",
      "acc for Psat= 0.11836956048177348 \n",
      "acc for optim= 0.1658575707115233\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.0033086484763771296\n",
      "Loss on test= 0.006100793834775686\n",
      "acc for Lsat= 0.10402484163124529 \n",
      "acc for Psat= 0.06275399000797835 \n",
      "acc for optim= 0.156208491897107\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.0033126682974398136\n",
      "Loss on test= 0.0060441819950938225\n",
      "acc for Lsat= 0.12120744503206676 \n",
      "acc for Psat= 0.12560994959332877 \n",
      "acc for optim= 0.16009517262379327\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.0032879477366805077\n",
      "Loss on test= 0.006398836616426706\n",
      "acc for Lsat= 0.09278606419037613 \n",
      "acc for Psat= 0.12632537162345317 \n",
      "acc for optim= 0.1483605376496497\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.003314793109893799\n",
      "Loss on test= 0.006292425096035004\n",
      "acc for Lsat= 0.13106954097747803 \n",
      "acc for Psat= 0.10102089942019019 \n",
      "acc for optim= 0.15156012708838615\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.003343791700899601\n",
      "Loss on test= 0.006030792370438576\n",
      "acc for Lsat= 0.10387235462096417 \n",
      "acc for Psat= 0.13704013058708775 \n",
      "acc for optim= 0.15332610281701717\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.0031712306663393974\n",
      "Loss on test= 0.006131754256784916\n",
      "acc for Lsat= 0.08490837618915571 \n",
      "acc for Psat= 0.11246115491828984 \n",
      "acc for optim= 0.11206572125148442\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.003251307411119342\n",
      "Loss on test= 0.006028912961483002\n",
      "acc for Lsat= 0.13154998680369723 \n",
      "acc for Psat= 0.116074337106612 \n",
      "acc for optim= 0.16520778462290764\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.003445696784183383\n",
      "Loss on test= 0.006156688090413809\n",
      "acc for Lsat= 0.09965032452924384 \n",
      "acc for Psat= 0.09992146501705672 \n",
      "acc for optim= 0.15474802824772066\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.0032835796009749174\n",
      "Loss on test= 0.006198654882609844\n",
      "acc for Lsat= 0.1265853269206774 \n",
      "acc for Psat= 0.08451301471925238 \n",
      "acc for optim= 0.15900280497347316\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.0032229649368673563\n",
      "Loss on test= 0.006406104192137718\n",
      "acc for Lsat= 0.11267304451515277 \n",
      "acc for Psat= 0.13028091864867342 \n",
      "acc for optim= 0.12866749042748576\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.0032963945996016264\n",
      "Loss on test= 0.005966618657112122\n",
      "acc for Lsat= 0.09718508304407199 \n",
      "acc for Psat= 0.09439447392813033 \n",
      "acc for optim= 0.13371424317463404\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.0032687755301594734\n",
      "Loss on test= 0.006229122169315815\n",
      "acc for Lsat= 0.10870398405111498 \n",
      "acc for Psat= 0.09186253500067526 \n",
      "acc for optim= 0.15998909959226795\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.0031664238777011633\n",
      "Loss on test= 0.005665435455739498\n",
      "acc for Lsat= 0.1307420806131429 \n",
      "acc for Psat= 0.14619875068051946 \n",
      "acc for optim= 0.18336366365353265\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.0034345181193202734\n",
      "Loss on test= 0.006110533606261015\n",
      "acc for Lsat= 0.11248123768018559 \n",
      "acc for Psat= 0.14703087543603033 \n",
      "acc for optim= 0.19769383097688356\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.003328475868329406\n",
      "Loss on test= 0.00605163536965847\n",
      "acc for Lsat= 0.10278005903172824 \n",
      "acc for Psat= 0.11986148776486516 \n",
      "acc for optim= 0.15063167084008455\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.0032988658640533686\n",
      "Loss on test= 0.006103829015046358\n",
      "acc for Lsat= 0.08581733791571525 \n",
      "acc for Psat= 0.15231118822056386 \n",
      "acc for optim= 0.17077483723147047\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.0034663116093724966\n",
      "Loss on test= 0.0059736343100667\n",
      "acc for Lsat= 0.08638378206847443 \n",
      "acc for Psat= 0.1077418453415804 \n",
      "acc for optim= 0.1488523974807726\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.0033360281959176064\n",
      "Loss on test= 0.0060404459945857525\n",
      "acc for Lsat= 0.09789961408306327 \n",
      "acc for Psat= 0.09169709299587542 \n",
      "acc for optim= 0.16515841904199785\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.003301753895357251\n",
      "Loss on test= 0.006013956852257252\n",
      "acc for Lsat= 0.07443321661816703 \n",
      "acc for Psat= 0.12166995513770315 \n",
      "acc for optim= 0.16597962211300102\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.0031599171925336123\n",
      "Loss on test= 0.0057856193743646145\n",
      "acc for Lsat= 0.14281947794370353 \n",
      "acc for Psat= 0.1293535915772534 \n",
      "acc for optim= 0.15781845649083456\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.0032847619149833918\n",
      "Loss on test= 0.006361143197864294\n",
      "acc for Lsat= 0.12264357729711467 \n",
      "acc for Psat= 0.10934186005033553 \n",
      "acc for optim= 0.16597660718899634\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.003312618937343359\n",
      "Loss on test= 0.0062655373476445675\n",
      "acc for Lsat= 0.09422393385062201 \n",
      "acc for Psat= 0.11141204679410698 \n",
      "acc for optim= 0.15484008754219125\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.003314403584226966\n",
      "Loss on test= 0.005919458344578743\n",
      "acc for Lsat= 0.07805188906301434 \n",
      "acc for Psat= 0.15115577085978454 \n",
      "acc for optim= 0.14236627012077305\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.0032118679955601692\n",
      "Loss on test= 0.00677547138184309\n",
      "acc for Lsat= 0.11094813731809457 \n",
      "acc for Psat= 0.10548635168621938 \n",
      "acc for optim= 0.15720176924433973\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.0032640614081174135\n",
      "Loss on test= 0.006266506854444742\n",
      "acc for Lsat= 0.10426016964225306 \n",
      "acc for Psat= 0.1653960564484199 \n",
      "acc for optim= 0.15193541658421358\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.003196808509528637\n",
      "Loss on test= 0.006278663408011198\n",
      "acc for Lsat= 0.08465208105432491 \n",
      "acc for Psat= 0.13148737566856047 \n",
      "acc for optim= 0.18986259763025576\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.00324192619882524\n",
      "Loss on test= 0.005925310309976339\n",
      "acc for Lsat= 0.1183889839060915 \n",
      "acc for Psat= 0.13458445196738467 \n",
      "acc for optim= 0.16099140317075783\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.003181284759193659\n",
      "Loss on test= 0.005879905074834824\n",
      "acc for Lsat= 0.11093137930664751 \n",
      "acc for Psat= 0.15891805705096987 \n",
      "acc for optim= 0.16732308020194372\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.0034002335742115974\n",
      "Loss on test= 0.005766723304986954\n",
      "acc for Lsat= 0.13299017356217113 \n",
      "acc for Psat= 0.13103506072527832 \n",
      "acc for optim= 0.1936568951027261\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.003266192739829421\n",
      "Loss on test= 0.005924013443291187\n",
      "acc for Lsat= 0.08763837242602474 \n",
      "acc for Psat= 0.10257043990875697 \n",
      "acc for optim= 0.1404295617636914\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.003256698604673147\n",
      "Loss on test= 0.00639904523268342\n",
      "acc for Lsat= 0.08744837012555864 \n",
      "acc for Psat= 0.1611004765662882 \n",
      "acc for optim= 0.15920192975964811\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.0032176568638533354\n",
      "Loss on test= 0.005803486332297325\n",
      "acc for Lsat= 0.10367355226642555 \n",
      "acc for Psat= 0.12549952731933445 \n",
      "acc for optim= 0.1763484668659253\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.0032379732001572847\n",
      "Loss on test= 0.0063318852335214615\n",
      "acc for Lsat= 0.12367355518250002 \n",
      "acc for Psat= 0.1053482875124448 \n",
      "acc for optim= 0.18405311950482428\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.003221372375264764\n",
      "Loss on test= 0.006281697656959295\n",
      "acc for Lsat= 0.07844560476951301 \n",
      "acc for Psat= 0.11254979049166043 \n",
      "acc for optim= 0.19269749690364632\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.0032425150275230408\n",
      "Loss on test= 0.0056976801715791225\n",
      "acc for Lsat= 0.1247544630120198 \n",
      "acc for Psat= 0.13461259932955727 \n",
      "acc for optim= 0.16307659478237232\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.0032793974969536066\n",
      "Loss on test= 0.005924167111515999\n",
      "acc for Lsat= 0.13875944467468393 \n",
      "acc for Psat= 0.12871824546406666 \n",
      "acc for optim= 0.16320617452988195\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.0032233623787760735\n",
      "Loss on test= 0.006551884114742279\n",
      "acc for Lsat= 0.08407844569430584 \n",
      "acc for Psat= 0.09542799947990312 \n",
      "acc for optim= 0.16569514852017164\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.003479291684925556\n",
      "Loss on test= 0.00601799413561821\n",
      "acc for Lsat= 0.17581411492493418 \n",
      "acc for Psat= 0.1211807362916362 \n",
      "acc for optim= 0.15945449141630283\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.0032120721880346537\n",
      "Loss on test= 0.005921283736824989\n",
      "acc for Lsat= 0.10030323749459866 \n",
      "acc for Psat= 0.12576071599808833 \n",
      "acc for optim= 0.15426537736008564\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.0032554075587540865\n",
      "Loss on test= 0.0062010823749005795\n",
      "acc for Lsat= 0.07586410382969512 \n",
      "acc for Psat= 0.10916270119034582 \n",
      "acc for optim= 0.178083342862212\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.003345760051161051\n",
      "Loss on test= 0.0060565960593521595\n",
      "acc for Lsat= 0.1225168010763203 \n",
      "acc for Psat= 0.15480052715995246 \n",
      "acc for optim= 0.1819869559775624\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.003248061751946807\n",
      "Loss on test= 0.00639757327735424\n",
      "acc for Lsat= 0.09937851821693282 \n",
      "acc for Psat= 0.14405579513145816 \n",
      "acc for optim= 0.2020465211632351\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.00332582532428205\n",
      "Loss on test= 0.005913313012570143\n",
      "acc for Lsat= 0.09657961487149198 \n",
      "acc for Psat= 0.13488255880980027 \n",
      "acc for optim= 0.12045768726642968\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.0033614032436162233\n",
      "Loss on test= 0.005996469408273697\n",
      "acc for Lsat= 0.1522674416191876 \n",
      "acc for Psat= 0.12695134522962487 \n",
      "acc for optim= 0.1178690129891038\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.0032861223444342613\n",
      "Loss on test= 0.006110860034823418\n",
      "acc for Lsat= 0.10728023594452275 \n",
      "acc for Psat= 0.11449454761006767 \n",
      "acc for optim= 0.1548275512436198\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.0033044551964849234\n",
      "Loss on test= 0.006017464213073254\n",
      "acc for Lsat= 0.1195536061293549 \n",
      "acc for Psat= 0.14185997512605455 \n",
      "acc for optim= 0.19838434897570145\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.0032560236286371946\n",
      "Loss on test= 0.0061544510535895824\n",
      "acc for Lsat= 0.10485961705368634 \n",
      "acc for Psat= 0.08937927106550585 \n",
      "acc for optim= 0.14632851633036303\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.0032715999986976385\n",
      "Loss on test= 0.006370359566062689\n",
      "acc for Lsat= 0.08195436218132575 \n",
      "acc for Psat= 0.11497310693893167 \n",
      "acc for optim= 0.1339891845256918\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.003259614109992981\n",
      "Loss on test= 0.005747174844145775\n",
      "acc for Lsat= 0.0984808977227658 \n",
      "acc for Psat= 0.15909561721815002 \n",
      "acc for optim= 0.17498809557097653\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.003174356184899807\n",
      "Loss on test= 0.006223403848707676\n",
      "acc for Lsat= 0.11176018435637364 \n",
      "acc for Psat= 0.1221016460719208 \n",
      "acc for optim= 0.13733771533912253\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.003260573837906122\n",
      "Loss on test= 0.006324695888906717\n",
      "acc for Lsat= 0.10994059693378706 \n",
      "acc for Psat= 0.10256418085191399 \n",
      "acc for optim= 0.2022627687288655\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.0032668947242200375\n",
      "Loss on test= 0.0058019463904201984\n",
      "acc for Lsat= 0.11786297832926114 \n",
      "acc for Psat= 0.16230689188361996 \n",
      "acc for optim= 0.18133655132260174\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.0032403087243437767\n",
      "Loss on test= 0.005990247242152691\n",
      "acc for Lsat= 0.11352448411182398 \n",
      "acc for Psat= 0.1301511399861839 \n",
      "acc for optim= 0.16377799688941902\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.0031853122636675835\n",
      "Loss on test= 0.006010383367538452\n",
      "acc for Lsat= 0.13198118594785532 \n",
      "acc for Psat= 0.14626532071876377 \n",
      "acc for optim= 0.17385342656376046\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.0032801618799567223\n",
      "Loss on test= 0.005926009267568588\n",
      "acc for Lsat= 0.09877689150420742 \n",
      "acc for Psat= 0.127408735635173 \n",
      "acc for optim= 0.13533912195513645\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.003243918064981699\n",
      "Loss on test= 0.006118730176240206\n",
      "acc for Lsat= 0.12039428887267907 \n",
      "acc for Psat= 0.11402968896759881 \n",
      "acc for optim= 0.15157911165927848\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.0032263381872326136\n",
      "Loss on test= 0.006322573870420456\n",
      "acc for Lsat= 0.11874724433033003 \n",
      "acc for Psat= 0.09423390568958388 \n",
      "acc for optim= 0.1751120825841402\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.0033078568521887064\n",
      "Loss on test= 0.005900260526686907\n",
      "acc for Lsat= 0.05894239232616706 \n",
      "acc for Psat= 0.13571818002189198 \n",
      "acc for optim= 0.15536787847263944\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.0031618436332792044\n",
      "Loss on test= 0.006164472550153732\n",
      "acc for Lsat= 0.11859309393912554 \n",
      "acc for Psat= 0.14185131962100664 \n",
      "acc for optim= 0.14842371067950605\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.0033047357574105263\n",
      "Loss on test= 0.006164834834635258\n",
      "acc for Lsat= 0.08831300824466679 \n",
      "acc for Psat= 0.12609448863400352 \n",
      "acc for optim= 0.16726695083909565\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.003245738334953785\n",
      "Loss on test= 0.006083279848098755\n",
      "acc for Lsat= 0.12787718988127178 \n",
      "acc for Psat= 0.10714377566344208 \n",
      "acc for optim= 0.15450134666429627\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.0032306730281561613\n",
      "Loss on test= 0.005722734611481428\n",
      "acc for Lsat= 0.11841795056696153 \n",
      "acc for Psat= 0.1316076401207182 \n",
      "acc for optim= 0.14887603010154432\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.0031824226025491953\n",
      "Loss on test= 0.006391194183379412\n",
      "acc for Lsat= 0.13523087029655775 \n",
      "acc for Psat= 0.1075247108625869 \n",
      "acc for optim= 0.12147362721670005\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.0031817241106182337\n",
      "Loss on test= 0.0059377350844442844\n",
      "acc for Lsat= 0.13001376535329554 \n",
      "acc for Psat= 0.11414602643667927 \n",
      "acc for optim= 0.184698064915008\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.0033205358777195215\n",
      "Loss on test= 0.0064061712473630905\n",
      "acc for Lsat= 0.0967796989910615 \n",
      "acc for Psat= 0.12312967193105982 \n",
      "acc for optim= 0.18360170017695054\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.0031137997284531593\n",
      "Loss on test= 0.006185593083500862\n",
      "acc for Lsat= 0.11488137980146955 \n",
      "acc for Psat= 0.08909782314569586 \n",
      "acc for optim= 0.15269477672861992\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.003265674924477935\n",
      "Loss on test= 0.006524065975099802\n",
      "acc for Lsat= 0.10267392188931505 \n",
      "acc for Psat= 0.10390725469268444 \n",
      "acc for optim= 0.1784656261572511\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.0031950687989592552\n",
      "Loss on test= 0.005928443279117346\n",
      "acc for Lsat= 0.11386668920103046 \n",
      "acc for Psat= 0.16717951613100013 \n",
      "acc for optim= 0.15724139044889146\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.0030932240188121796\n",
      "Loss on test= 0.006513119209557772\n",
      "acc for Lsat= 0.12740393024351862 \n",
      "acc for Psat= 0.10228885001399451 \n",
      "acc for optim= 0.16359469682599106\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.003254939569160342\n",
      "Loss on test= 0.00620765658095479\n",
      "acc for Lsat= 0.09277946524606603 \n",
      "acc for Psat= 0.13936697996945846 \n",
      "acc for optim= 0.17450850405212906\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.0032048590946942568\n",
      "Loss on test= 0.005998418666422367\n",
      "acc for Lsat= 0.10133350115696278 \n",
      "acc for Psat= 0.13707190777899492 \n",
      "acc for optim= 0.17479908130028182\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.003060495015233755\n",
      "Loss on test= 0.006380307488143444\n",
      "acc for Lsat= 0.06931231019552797 \n",
      "acc for Psat= 0.156240526586771 \n",
      "acc for optim= 0.15686823771749106\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.0031472593545913696\n",
      "Loss on test= 0.006025192327797413\n",
      "acc for Lsat= 0.12612884579640296 \n",
      "acc for Psat= 0.16591924553116164 \n",
      "acc for optim= 0.121650969544943\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.003192167729139328\n",
      "Loss on test= 0.006087375804781914\n",
      "acc for Lsat= 0.12045371356523699 \n",
      "acc for Psat= 0.12193349583281411 \n",
      "acc for optim= 0.18610633321804926\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.003378929104655981\n",
      "Loss on test= 0.005930251907557249\n",
      "acc for Lsat= 0.10069961907962958 \n",
      "acc for Psat= 0.1178024410425375 \n",
      "acc for optim= 0.12539092844559085\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.003133992664515972\n",
      "Loss on test= 0.0060252598486840725\n",
      "acc for Lsat= 0.08784835307031041 \n",
      "acc for Psat= 0.10891065515008652 \n",
      "acc for optim= 0.16989677285568583\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.0031487762462347746\n",
      "Loss on test= 0.005991121754050255\n",
      "acc for Lsat= 0.0901108933871405 \n",
      "acc for Psat= 0.0881641624469517 \n",
      "acc for optim= 0.1776512823998928\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.0030285613611340523\n",
      "Loss on test= 0.006272312253713608\n",
      "acc for Lsat= 0.10828411962009138 \n",
      "acc for Psat= 0.0859936520897059 \n",
      "acc for optim= 0.15593604846960968\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.0031708364840596914\n",
      "Loss on test= 0.006147475913167\n",
      "acc for Lsat= 0.09783101978892875 \n",
      "acc for Psat= 0.06714134114897913 \n",
      "acc for optim= 0.16326474951994088\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.0031416253186762333\n",
      "Loss on test= 0.006108826957643032\n",
      "acc for Lsat= 0.11565722892474797 \n",
      "acc for Psat= 0.11584068657571657 \n",
      "acc for optim= 0.17372356934679878\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.003158153034746647\n",
      "Loss on test= 0.00614168168976903\n",
      "acc for Lsat= 0.08919159633417924 \n",
      "acc for Psat= 0.13637528604724342 \n",
      "acc for optim= 0.15965845063328743\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.003260899567976594\n",
      "Loss on test= 0.006611826829612255\n",
      "acc for Lsat= 0.09282378014177084 \n",
      "acc for Psat= 0.10243598118864207 \n",
      "acc for optim= 0.14266334318866333\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.003202898893505335\n",
      "Loss on test= 0.006242020055651665\n",
      "acc for Lsat= 0.13225035752273268 \n",
      "acc for Psat= 0.16362197136428827 \n",
      "acc for optim= 0.1581143828936749\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.0031306406017392874\n",
      "Loss on test= 0.005957114975899458\n",
      "acc for Lsat= 0.10115009604487568 \n",
      "acc for Psat= 0.11590689027474986 \n",
      "acc for optim= 0.2021298680661453\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.0030610577668994665\n",
      "Loss on test= 0.006094562821090221\n",
      "acc for Lsat= 0.12097735074348748 \n",
      "acc for Psat= 0.15144539158791304 \n",
      "acc for optim= 0.15539150270504049\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.0031364946626126766\n",
      "Loss on test= 0.0055504753254354\n",
      "acc for Lsat= 0.11785795498872176 \n",
      "acc for Psat= 0.11629440819120242 \n",
      "acc for optim= 0.1663420805707574\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.0031821473967283964\n",
      "Loss on test= 0.006284632254391909\n",
      "acc for Lsat= 0.09336172624817765 \n",
      "acc for Psat= 0.13410773381797803 \n",
      "acc for optim= 0.16102667756947792\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.003225988242775202\n",
      "Loss on test= 0.006269896402955055\n",
      "acc for Lsat= 0.08194534298187743 \n",
      "acc for Psat= 0.11419236683286726 \n",
      "acc for optim= 0.1373298608808303\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.003259135177358985\n",
      "Loss on test= 0.006279958412051201\n",
      "acc for Lsat= 0.10491982821582092 \n",
      "acc for Psat= 0.14635524076099196 \n",
      "acc for optim= 0.1404370651062992\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.003216489451006055\n",
      "Loss on test= 0.006123856641352177\n",
      "acc for Lsat= 0.08173383165720022 \n",
      "acc for Psat= 0.10844143088777652 \n",
      "acc for optim= 0.1313482698880964\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.003146313363686204\n",
      "Loss on test= 0.006172292400151491\n",
      "acc for Lsat= 0.09916499524842948 \n",
      "acc for Psat= 0.13268418387613362 \n",
      "acc for optim= 0.15776938592896134\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.003172097960487008\n",
      "Loss on test= 0.006377506069839001\n",
      "acc for Lsat= 0.11690150304800934 \n",
      "acc for Psat= 0.10718067362904549 \n",
      "acc for optim= 0.15606370040849368\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.003132413374260068\n",
      "Loss on test= 0.00604655034840107\n",
      "acc for Lsat= 0.13045829405180281 \n",
      "acc for Psat= 0.12013662120120393 \n",
      "acc for optim= 0.14592443075444964\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.0033413043711334467\n",
      "Loss on test= 0.005674298852682114\n",
      "acc for Lsat= 0.11669113554590796 \n",
      "acc for Psat= 0.10436808695602748 \n",
      "acc for optim= 0.18429749769469103\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.0032043056562542915\n",
      "Loss on test= 0.006099021527916193\n",
      "acc for Lsat= 0.11889598508261973 \n",
      "acc for Psat= 0.14835907545218813 \n",
      "acc for optim= 0.14181130764902466\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.003208358073607087\n",
      "Loss on test= 0.006247227545827627\n",
      "acc for Lsat= 0.09059205801329678 \n",
      "acc for Psat= 0.10545548161543492 \n",
      "acc for optim= 0.15767250510139597\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.0031316177919507027\n",
      "Loss on test= 0.00620841421186924\n",
      "acc for Lsat= 0.05485034973308858 \n",
      "acc for Psat= 0.06928966361899963 \n",
      "acc for optim= 0.15601030061871926\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.0030541354790329933\n",
      "Loss on test= 0.005966296419501305\n",
      "acc for Lsat= 0.11781792420273025 \n",
      "acc for Psat= 0.13807249979840386 \n",
      "acc for optim= 0.1601827550265524\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.0032272336538881063\n",
      "Loss on test= 0.006196778733283281\n",
      "acc for Lsat= 0.11842930420405334 \n",
      "acc for Psat= 0.09983246887309684 \n",
      "acc for optim= 0.1811081160687738\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.0031398904975503683\n",
      "Loss on test= 0.006094792392104864\n",
      "acc for Lsat= 0.06545492656166768 \n",
      "acc for Psat= 0.1187457021118866 \n",
      "acc for optim= 0.15686919995480114\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.0032249740324914455\n",
      "Loss on test= 0.006692053750157356\n",
      "acc for Lsat= 0.0683317377180275 \n",
      "acc for Psat= 0.14780350557217994 \n",
      "acc for optim= 0.16900762708650696\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.0032561577390879393\n",
      "Loss on test= 0.006197783630341291\n",
      "acc for Lsat= 0.0793001184033023 \n",
      "acc for Psat= 0.10449265574829446 \n",
      "acc for optim= 0.164259178770913\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.0031228484585881233\n",
      "Loss on test= 0.0061050718650221825\n",
      "acc for Lsat= 0.09472973668016493 \n",
      "acc for Psat= 0.12678465423070723 \n",
      "acc for optim= 0.1425623962034782\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.002954755211248994\n",
      "Loss on test= 0.0060508460737764835\n",
      "acc for Lsat= 0.11263954028901127 \n",
      "acc for Psat= 0.12569495331909922 \n",
      "acc for optim= 0.13255585993950567\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.00312925036996603\n",
      "Loss on test= 0.006148486863821745\n",
      "acc for Lsat= 0.10691449981338035 \n",
      "acc for Psat= 0.10390300853436606 \n",
      "acc for optim= 0.15642306469898257\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.0031151107978075743\n",
      "Loss on test= 0.006369646172970533\n",
      "acc for Lsat= 0.11359552988627304 \n",
      "acc for Psat= 0.09246225820647345 \n",
      "acc for optim= 0.16187017266282863\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.0031547644175589085\n",
      "Loss on test= 0.006199172232300043\n",
      "acc for Lsat= 0.07158153949098454 \n",
      "acc for Psat= 0.12728213353289497 \n",
      "acc for optim= 0.15773017269869646\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.003167664399370551\n",
      "Loss on test= 0.00626299437135458\n",
      "acc for Lsat= 0.11114250682294369 \n",
      "acc for Psat= 0.11240085783518022 \n",
      "acc for optim= 0.16498217853303584\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.0031567250844091177\n",
      "Loss on test= 0.0063740843906998634\n",
      "acc for Lsat= 0.10407080897130072 \n",
      "acc for Psat= 0.10763713934769233 \n",
      "acc for optim= 0.15510068026681742\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.003076439956203103\n",
      "Loss on test= 0.006252995226532221\n",
      "acc for Lsat= 0.14603230388214192 \n",
      "acc for Psat= 0.09680341391099824 \n",
      "acc for optim= 0.16924371953225797\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.0032254583202302456\n",
      "Loss on test= 0.006163299083709717\n",
      "acc for Lsat= 0.11616008123382926 \n",
      "acc for Psat= 0.12482266562680404 \n",
      "acc for optim= 0.17725158848851505\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.003046197583898902\n",
      "Loss on test= 0.005904337391257286\n",
      "acc for Lsat= 0.12045526604116377 \n",
      "acc for Psat= 0.09739189173301889 \n",
      "acc for optim= 0.1303260711590863\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.003234732896089554\n",
      "Loss on test= 0.006312748417258263\n",
      "acc for Lsat= 0.10863681354870398 \n",
      "acc for Psat= 0.09826855812247635 \n",
      "acc for optim= 0.13730080736180147\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.0030912442598491907\n",
      "Loss on test= 0.006150797940790653\n",
      "acc for Lsat= 0.08261771352651219 \n",
      "acc for Psat= 0.09447053799198733 \n",
      "acc for optim= 0.17130708994550836\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.0030601760372519493\n",
      "Loss on test= 0.006271371617913246\n",
      "acc for Lsat= 0.13111014301992124 \n",
      "acc for Psat= 0.09772531708909406 \n",
      "acc for optim= 0.12408455471611685\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.0032388910185545683\n",
      "Loss on test= 0.005840632598847151\n",
      "acc for Lsat= 0.0961538190022111 \n",
      "acc for Psat= 0.11188910197880533 \n",
      "acc for optim= 0.17768355184105328\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.0031510284170508385\n",
      "Loss on test= 0.006249165162444115\n",
      "acc for Lsat= 0.08377300407543468 \n",
      "acc for Psat= 0.09849430602561268 \n",
      "acc for optim= 0.17351571511891153\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.0031250284519046545\n",
      "Loss on test= 0.005897619761526585\n",
      "acc for Lsat= 0.1167340764093549 \n",
      "acc for Psat= 0.12089232096655501 \n",
      "acc for optim= 0.15288700614797157\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.0031353652011603117\n",
      "Loss on test= 0.006349855102598667\n",
      "acc for Lsat= 0.10012008126876834 \n",
      "acc for Psat= 0.1198503189953044 \n",
      "acc for optim= 0.1386214674760898\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.0031346797477453947\n",
      "Loss on test= 0.006166224367916584\n",
      "acc for Lsat= 0.08950767115068932 \n",
      "acc for Psat= 0.12875163244704405 \n",
      "acc for optim= 0.1581556275422271\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.003178277751430869\n",
      "Loss on test= 0.00627492368221283\n",
      "acc for Lsat= 0.11397181016703446 \n",
      "acc for Psat= 0.16376559394929144 \n",
      "acc for optim= 0.17816175101324916\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.003123081522062421\n",
      "Loss on test= 0.006493838503956795\n",
      "acc for Lsat= 0.12250527364408804 \n",
      "acc for Psat= 0.13152663792586988 \n",
      "acc for optim= 0.14349267763706544\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.0031302159186452627\n",
      "Loss on test= 0.006283079739660025\n",
      "acc for Lsat= 0.11918402287281221 \n",
      "acc for Psat= 0.16211732021636432 \n",
      "acc for optim= 0.18939957715984848\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.0031470865942537785\n",
      "Loss on test= 0.0056811063550412655\n",
      "acc for Lsat= 0.13049402532892096 \n",
      "acc for Psat= 0.12714883855854472 \n",
      "acc for optim= 0.1629970705188397\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.003105937037616968\n",
      "Loss on test= 0.006110748276114464\n",
      "acc for Lsat= 0.08790481178503898 \n",
      "acc for Psat= 0.11472069919626746 \n",
      "acc for optim= 0.16977017667765418\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.0031597011256963015\n",
      "Loss on test= 0.006202218122780323\n",
      "acc for Lsat= 0.1025089355130654 \n",
      "acc for Psat= 0.12603522092103958 \n",
      "acc for optim= 0.1442389138456848\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.003135445062071085\n",
      "Loss on test= 0.006118269637227058\n",
      "acc for Lsat= 0.08598744178501268 \n",
      "acc for Psat= 0.1546206900642978 \n",
      "acc for optim= 0.18642131973885828\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.0030944133177399635\n",
      "Loss on test= 0.006040563341230154\n",
      "acc for Lsat= 0.13059063969053064 \n",
      "acc for Psat= 0.11860393117078477 \n",
      "acc for optim= 0.17936655568579832\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.0031759559642523527\n",
      "Loss on test= 0.006373933982104063\n",
      "acc for Lsat= 0.08950583719544941 \n",
      "acc for Psat= 0.13057127967476845 \n",
      "acc for optim= 0.15779450364385006\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.00314177293330431\n",
      "Loss on test= 0.006230233237147331\n",
      "acc for Lsat= 0.11021936311024344 \n",
      "acc for Psat= 0.11745158401835296 \n",
      "acc for optim= 0.16054375037654406\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.003123458242043853\n",
      "Loss on test= 0.005912108812481165\n",
      "acc for Lsat= 0.12920341902524038 \n",
      "acc for Psat= 0.14457358761380115 \n",
      "acc for optim= 0.14963207833675873\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.0030483179725706577\n",
      "Loss on test= 0.0060739293694496155\n",
      "acc for Lsat= 0.1036929550787641 \n",
      "acc for Psat= 0.11648362468824619 \n",
      "acc for optim= 0.15127426124591795\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.0031497462186962366\n",
      "Loss on test= 0.006084911525249481\n",
      "acc for Lsat= 0.07764799000384907 \n",
      "acc for Psat= 0.09660439484731695 \n",
      "acc for optim= 0.16864508452514806\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.003186203306540847\n",
      "Loss on test= 0.0059910970740020275\n",
      "acc for Lsat= 0.0931745402307974 \n",
      "acc for Psat= 0.1410517043227123 \n",
      "acc for optim= 0.17418212133149305\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.0031374944373965263\n",
      "Loss on test= 0.006167612504214048\n",
      "acc for Lsat= 0.11254315718542784 \n",
      "acc for Psat= 0.138326726310576 \n",
      "acc for optim= 0.17347923759371042\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.0031255052890628576\n",
      "Loss on test= 0.005950184538960457\n",
      "acc for Lsat= 0.10680847268344627 \n",
      "acc for Psat= 0.11011848753939073 \n",
      "acc for optim= 0.15591352744700593\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.0031811760272830725\n",
      "Loss on test= 0.006442522630095482\n",
      "acc for Lsat= 0.0885491169238877 \n",
      "acc for Psat= 0.13534249880144167 \n",
      "acc for optim= 0.1333893119202306\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.0031354257371276617\n",
      "Loss on test= 0.005955604836344719\n",
      "acc for Lsat= 0.09999784884146518 \n",
      "acc for Psat= 0.12669876999118262 \n",
      "acc for optim= 0.14627609748923634\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.0030740140937268734\n",
      "Loss on test= 0.0063262805342674255\n",
      "acc for Lsat= 0.1387380248763495 \n",
      "acc for Psat= 0.11694400498850478 \n",
      "acc for optim= 0.15693339943471882\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.0030472970101982355\n",
      "Loss on test= 0.0060240160673856735\n",
      "acc for Lsat= 0.1321989715927177 \n",
      "acc for Psat= 0.12874032562184665 \n",
      "acc for optim= 0.17476055800863025\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.0032172827050089836\n",
      "Loss on test= 0.006639725528657436\n",
      "acc for Lsat= 0.08641899899683064 \n",
      "acc for Psat= 0.13598430684457222 \n",
      "acc for optim= 0.15927605599992806\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.003039898816496134\n",
      "Loss on test= 0.00586121017113328\n",
      "acc for Lsat= 0.09591133908058207 \n",
      "acc for Psat= 0.1654048575502303 \n",
      "acc for optim= 0.16292832367536095\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.003103659488260746\n",
      "Loss on test= 0.00630939332768321\n",
      "acc for Lsat= 0.11849658320554429 \n",
      "acc for Psat= 0.13241794674346843 \n",
      "acc for optim= 0.17806960569901598\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.0031605816911906004\n",
      "Loss on test= 0.006267703603953123\n",
      "acc for Lsat= 0.14367492290006745 \n",
      "acc for Psat= 0.12855813522926635 \n",
      "acc for optim= 0.15763087498231065\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.0030977840069681406\n",
      "Loss on test= 0.0057688429951667786\n",
      "acc for Lsat= 0.08111795486507213 \n",
      "acc for Psat= 0.1317299311566684 \n",
      "acc for optim= 0.14124310041686133\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.003146917326375842\n",
      "Loss on test= 0.005882869474589825\n",
      "acc for Lsat= 0.08629157171688145 \n",
      "acc for Psat= 0.07724927217026965 \n",
      "acc for optim= 0.18033587746322155\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.003094979329034686\n",
      "Loss on test= 0.005922209471464157\n",
      "acc for Lsat= 0.12906084613253674 \n",
      "acc for Psat= 0.1451912659427358 \n",
      "acc for optim= 0.19252374385380083\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.003164716763421893\n",
      "Loss on test= 0.006255756597965956\n",
      "acc for Lsat= 0.0969745110358215 \n",
      "acc for Psat= 0.11252129023584227 \n",
      "acc for optim= 0.14372394369759908\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.003126513911411166\n",
      "Loss on test= 0.006055823527276516\n",
      "acc for Lsat= 0.090031730541442 \n",
      "acc for Psat= 0.08028000748405854 \n",
      "acc for optim= 0.13722491526924488\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.003201557556167245\n",
      "Loss on test= 0.006492028012871742\n",
      "acc for Lsat= 0.08589833355896796 \n",
      "acc for Psat= 0.11133266010114716 \n",
      "acc for optim= 0.15251586410320467\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.0030949031934142113\n",
      "Loss on test= 0.005919761024415493\n",
      "acc for Lsat= 0.08685580661727323 \n",
      "acc for Psat= 0.12610953440889716 \n",
      "acc for optim= 0.13278294308111072\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.0030649243853986263\n",
      "Loss on test= 0.006511943880468607\n",
      "acc for Lsat= 0.12341454475730036 \n",
      "acc for Psat= 0.11962185562070873 \n",
      "acc for optim= 0.16960820462554693\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.003073343774303794\n",
      "Loss on test= 0.006622048560529947\n",
      "acc for Lsat= 0.07391749595181965 \n",
      "acc for Psat= 0.10537158408098751 \n",
      "acc for optim= 0.14747743706943262\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.003100837115198374\n",
      "Loss on test= 0.006299189291894436\n",
      "acc for Lsat= 0.08532370238875349 \n",
      "acc for Psat= 0.12750817832743955 \n",
      "acc for optim= 0.17496970699479183\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.003190021263435483\n",
      "Loss on test= 0.006116925738751888\n",
      "acc for Lsat= 0.10418722157030263 \n",
      "acc for Psat= 0.14951824945294195 \n",
      "acc for optim= 0.18231294428308806\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.003088685218244791\n",
      "Loss on test= 0.006220969371497631\n",
      "acc for Lsat= 0.1119620297564931 \n",
      "acc for Psat= 0.11602535424754024 \n",
      "acc for optim= 0.1729111356867684\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.003231646725907922\n",
      "Loss on test= 0.006394568830728531\n",
      "acc for Lsat= 0.10810937136152966 \n",
      "acc for Psat= 0.12616691337380972 \n",
      "acc for optim= 0.14811169325063625\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.0030623101629316807\n",
      "Loss on test= 0.006630034185945988\n",
      "acc for Lsat= 0.11633690234480633 \n",
      "acc for Psat= 0.10320074196594457 \n",
      "acc for optim= 0.1277469309667746\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.003209449118003249\n",
      "Loss on test= 0.005958294961601496\n",
      "acc for Lsat= 0.09849520312208268 \n",
      "acc for Psat= 0.1203410849492583 \n",
      "acc for optim= 0.17769396305084229\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.0032567097805440426\n",
      "Loss on test= 0.006316399201750755\n",
      "acc for Lsat= 0.1037511784169409 \n",
      "acc for Psat= 0.13394846223915616 \n",
      "acc for optim= 0.1812269571237266\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.0031969191040843725\n",
      "Loss on test= 0.006348761729896069\n",
      "acc for Lsat= 0.12083762467470176 \n",
      "acc for Psat= 0.1066885885472099 \n",
      "acc for optim= 0.1641644364119404\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.003186298068612814\n",
      "Loss on test= 0.006200801115483046\n",
      "acc for Lsat= 0.12415421692033608 \n",
      "acc for Psat= 0.10254088535697924 \n",
      "acc for optim= 0.14554969164439374\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.0031525813974440098\n",
      "Loss on test= 0.006212201900780201\n",
      "acc for Lsat= 0.11352597099418442 \n",
      "acc for Psat= 0.17028812256952128 \n",
      "acc for optim= 0.2155272639873955\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.003147403709590435\n",
      "Loss on test= 0.0061280266381800175\n",
      "acc for Lsat= 0.11339411473212142 \n",
      "acc for Psat= 0.14677217106024423 \n",
      "acc for optim= 0.17213686669452322\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.0030545303598046303\n",
      "Loss on test= 0.006465644109994173\n",
      "acc for Lsat= 0.13368486812234753 \n",
      "acc for Psat= 0.16429607636200672 \n",
      "acc for optim= 0.16394623322412372\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.0030285464599728584\n",
      "Loss on test= 0.006010657642036676\n",
      "acc for Lsat= 0.08211273551245944 \n",
      "acc for Psat= 0.14157081573891142 \n",
      "acc for optim= 0.18248944362211558\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.003154550679028034\n",
      "Loss on test= 0.006433332338929176\n",
      "acc for Lsat= 0.08704812846715665 \n",
      "acc for Psat= 0.1339334967908346 \n",
      "acc for optim= 0.1562346815286825\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.0031951183918863535\n",
      "Loss on test= 0.006033272948116064\n",
      "acc for Lsat= 0.09208683238183665 \n",
      "acc for Psat= 0.13144720821744865 \n",
      "acc for optim= 0.13775464530206388\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.0031060867477208376\n",
      "Loss on test= 0.0059900712221860886\n",
      "acc for Lsat= 0.10704341530799866 \n",
      "acc for Psat= 0.16519342467007744 \n",
      "acc for optim= 0.17513506963021225\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.003096274333074689\n",
      "Loss on test= 0.006098374258726835\n",
      "acc for Lsat= 0.09593987330380413 \n",
      "acc for Psat= 0.1362327446954118 \n",
      "acc for optim= 0.145381151077648\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.003152421908453107\n",
      "Loss on test= 0.006349215283989906\n",
      "acc for Lsat= 0.10497485799714923 \n",
      "acc for Psat= 0.14996969565335247 \n",
      "acc for optim= 0.1666981749262454\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.003028369741514325\n",
      "Loss on test= 0.006244327407330275\n",
      "acc for Lsat= 0.12481492695709069 \n",
      "acc for Psat= 0.11427760206990772 \n",
      "acc for optim= 0.1604821087870126\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.003091739723458886\n",
      "Loss on test= 0.006370191462337971\n",
      "acc for Lsat= 0.08060956961061391 \n",
      "acc for Psat= 0.10124590992927551 \n",
      "acc for optim= 0.17733208638512427\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.0030439330730587244\n",
      "Loss on test= 0.0059324344620108604\n",
      "acc for Lsat= 0.07581522307979564 \n",
      "acc for Psat= 0.13620343669835064 \n",
      "acc for optim= 0.14194109942764044\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.003031069878488779\n",
      "Loss on test= 0.006378529127687216\n",
      "acc for Lsat= 0.12194833441430496 \n",
      "acc for Psat= 0.1321303602308035 \n",
      "acc for optim= 0.1400911831838635\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.0030570297967642546\n",
      "Loss on test= 0.005636746529489756\n",
      "acc for Lsat= 0.12206023093312979 \n",
      "acc for Psat= 0.13264959326220882 \n",
      "acc for optim= 0.15940131611811617\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.003036223351955414\n",
      "Loss on test= 0.006614117883145809\n",
      "acc for Lsat= 0.10601940701922609 \n",
      "acc for Psat= 0.1186474893345601 \n",
      "acc for optim= 0.14712650460811952\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.003071483224630356\n",
      "Loss on test= 0.005785746965557337\n",
      "acc for Lsat= 0.113836953157766 \n",
      "acc for Psat= 0.12035964863995711 \n",
      "acc for optim= 0.13774841734104687\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.003114561550319195\n",
      "Loss on test= 0.0060004922561347485\n",
      "acc for Lsat= 0.14243649484382737 \n",
      "acc for Psat= 0.12370783163027631 \n",
      "acc for optim= 0.1491861449321732\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.0030100869480520487\n",
      "Loss on test= 0.006163282319903374\n",
      "acc for Lsat= 0.08370116063290173 \n",
      "acc for Psat= 0.12285559464039074 \n",
      "acc for optim= 0.13022902662244937\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.003189592156559229\n",
      "Loss on test= 0.005914846435189247\n",
      "acc for Lsat= 0.08672425551857385 \n",
      "acc for Psat= 0.10644456811456217 \n",
      "acc for optim= 0.13212915934481215\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.0030649476684629917\n",
      "Loss on test= 0.006207635160535574\n",
      "acc for Lsat= 0.130617992952466 \n",
      "acc for Psat= 0.13931450806558132 \n",
      "acc for optim= 0.1527337433071807\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.0031274117063730955\n",
      "Loss on test= 0.0060897935181856155\n",
      "acc for Lsat= 0.12099958878631394 \n",
      "acc for Psat= 0.1710104658268392 \n",
      "acc for optim= 0.1432950841780338\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.0029403644148260355\n",
      "Loss on test= 0.005977638531476259\n",
      "acc for Lsat= 0.07774282418864055 \n",
      "acc for Psat= 0.11025663563567731 \n",
      "acc for optim= 0.16845952681938392\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.0030792623292654753\n",
      "Loss on test= 0.006147498730570078\n",
      "acc for Lsat= 0.1354228916267554 \n",
      "acc for Psat= 0.1877187912662824 \n",
      "acc for optim= 0.16517146490514278\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.0030307990964502096\n",
      "Loss on test= 0.00563229713588953\n",
      "acc for Lsat= 0.08200597346553372 \n",
      "acc for Psat= 0.12846756073284066 \n",
      "acc for optim= 0.1466538951628738\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.0030687316320836544\n",
      "Loss on test= 0.006476132199168205\n",
      "acc for Lsat= 0.09743006299767229 \n",
      "acc for Psat= 0.12438960192311141 \n",
      "acc for optim= 0.13866776985944146\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.003147880081087351\n",
      "Loss on test= 0.006123322993516922\n",
      "acc for Lsat= 0.10219985412226783 \n",
      "acc for Psat= 0.11191630063371526 \n",
      "acc for optim= 0.18391692514220873\n",
      "Fold 2\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.06917422264814377\n",
      "Loss on test= 0.03669927269220352\n",
      "acc for Lsat= 0.503255614441716 \n",
      "acc for Psat= 0.7267044188532358 \n",
      "acc for optim= 0.20895937624542663\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.03033825010061264\n",
      "Loss on test= 0.025695282965898514\n",
      "acc for Lsat= 0.4209515377879143 \n",
      "acc for Psat= 0.8567926845409803 \n",
      "acc for optim= 0.18821324824562502\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.025097476318478584\n",
      "Loss on test= 0.022366659715771675\n",
      "acc for Lsat= 0.39785903402500683 \n",
      "acc for Psat= 0.597268066679438 \n",
      "acc for optim= 0.21947829756471846\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.02315855771303177\n",
      "Loss on test= 0.022424589842557907\n",
      "acc for Lsat= 0.39615482662985513 \n",
      "acc for Psat= 0.5570999922023879 \n",
      "acc for optim= 0.18168715480715036\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.021350238472223282\n",
      "Loss on test= 0.02119304984807968\n",
      "acc for Lsat= 0.2773422638161315 \n",
      "acc for Psat= 0.8894607262271974 \n",
      "acc for optim= 0.3322420378939973\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.021695591509342194\n",
      "Loss on test= 0.018352439627051353\n",
      "acc for Lsat= 0.34836014069151133 \n",
      "acc for Psat= 0.45784709364589715 \n",
      "acc for optim= 0.23568400145611829\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.019809527322649956\n",
      "Loss on test= 0.017531536519527435\n",
      "acc for Lsat= 0.2595630528198348 \n",
      "acc for Psat= 0.44970268497450483 \n",
      "acc for optim= 0.19631929506754708\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.018950413912534714\n",
      "Loss on test= 0.018803516402840614\n",
      "acc for Lsat= 0.32801216199166244 \n",
      "acc for Psat= 0.5511467578924365 \n",
      "acc for optim= 0.1521172078533305\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.01892486959695816\n",
      "Loss on test= 0.01702844351530075\n",
      "acc for Lsat= 0.24480710791734359 \n",
      "acc for Psat= 0.39220173770768774 \n",
      "acc for optim= 0.2017112715790669\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.01873955875635147\n",
      "Loss on test= 0.01661832630634308\n",
      "acc for Lsat= 0.26192014529887175 \n",
      "acc for Psat= 0.5415986888110638 \n",
      "acc for optim= 0.16563196958870524\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.017037170007824898\n",
      "Loss on test= 0.016954518854618073\n",
      "acc for Lsat= 0.2847175669028527 \n",
      "acc for Psat= 0.48752570690380204 \n",
      "acc for optim= 0.19173094412932792\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.01695721410214901\n",
      "Loss on test= 0.015336347743868828\n",
      "acc for Lsat= 0.27555369016610914 \n",
      "acc for Psat= 0.4483261252236035 \n",
      "acc for optim= 0.18456651125517157\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.01693645305931568\n",
      "Loss on test= 0.016568535938858986\n",
      "acc for Lsat= 0.3793223823110263 \n",
      "acc for Psat= 0.53680585143027 \n",
      "acc for optim= 0.20451383240934876\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.01718629151582718\n",
      "Loss on test= 0.015744145959615707\n",
      "acc for Lsat= 0.24801141706605753 \n",
      "acc for Psat= 0.46104712618721855 \n",
      "acc for optim= 0.17842758444991583\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.015799574553966522\n",
      "Loss on test= 0.01488302182406187\n",
      "acc for Lsat= 0.26434306443358463 \n",
      "acc for Psat= 0.34956239616925205 \n",
      "acc for optim= 0.1729927157672743\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.015772897750139236\n",
      "Loss on test= 0.015876486897468567\n",
      "acc for Lsat= 0.253604205014805 \n",
      "acc for Psat= 0.43416235968470573 \n",
      "acc for optim= 0.20810895495944554\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.015998413786292076\n",
      "Loss on test= 0.014848058111965656\n",
      "acc for Lsat= 0.28380273520532584 \n",
      "acc for Psat= 0.521073605451319 \n",
      "acc for optim= 0.17093761327366033\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.01576533168554306\n",
      "Loss on test= 0.01475084014236927\n",
      "acc for Lsat= 0.39914473415248924 \n",
      "acc for Psat= 0.34298143453068203 \n",
      "acc for optim= 0.14432442974713114\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.015450786799192429\n",
      "Loss on test= 0.013376063667237759\n",
      "acc for Lsat= 0.18000442071610856 \n",
      "acc for Psat= 0.32248765664796036 \n",
      "acc for optim= 0.1820763521310356\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.01502953376621008\n",
      "Loss on test= 0.013727867044508457\n",
      "acc for Lsat= 0.23718364350497723 \n",
      "acc for Psat= 0.3872636506954829 \n",
      "acc for optim= 0.19106402123967806\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.01525843795388937\n",
      "Loss on test= 0.015743380412459373\n",
      "acc for Lsat= 0.2450931598432362 \n",
      "acc for Psat= 0.4203961483306355 \n",
      "acc for optim= 0.18449631188478735\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.015312201343476772\n",
      "Loss on test= 0.014351293444633484\n",
      "acc for Lsat= 0.22787527305384478 \n",
      "acc for Psat= 0.37623249077134663 \n",
      "acc for optim= 0.15940744920064592\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.014058688655495644\n",
      "Loss on test= 0.014036517590284348\n",
      "acc for Lsat= 0.25655326681832474 \n",
      "acc for Psat= 0.4852929843796624 \n",
      "acc for optim= 0.17654533735993835\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.01479430217295885\n",
      "Loss on test= 0.01444914098829031\n",
      "acc for Lsat= 0.32384108669228023 \n",
      "acc for Psat= 0.44148168837030727 \n",
      "acc for optim= 0.23729536516798866\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.014244426041841507\n",
      "Loss on test= 0.013617200776934624\n",
      "acc for Lsat= 0.29085487582617336 \n",
      "acc for Psat= 0.41200775681580937 \n",
      "acc for optim= 0.1964865579114606\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.014181310310959816\n",
      "Loss on test= 0.013544324785470963\n",
      "acc for Lsat= 0.2939140705081324 \n",
      "acc for Psat= 0.4138232117725743 \n",
      "acc for optim= 0.18538505428781113\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.014122859574854374\n",
      "Loss on test= 0.012577405199408531\n",
      "acc for Lsat= 0.2673162541145252 \n",
      "acc for Psat= 0.3598002088773582 \n",
      "acc for optim= 0.16003014926940928\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.014108088798820972\n",
      "Loss on test= 0.01358844805508852\n",
      "acc for Lsat= 0.3018347937096324 \n",
      "acc for Psat= 0.39888626652666265 \n",
      "acc for optim= 0.18476488451576895\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.013864969834685326\n",
      "Loss on test= 0.013095010071992874\n",
      "acc for Lsat= 0.3325219953225719 \n",
      "acc for Psat= 0.5000409231029658 \n",
      "acc for optim= 0.1779006652377575\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.013638301752507687\n",
      "Loss on test= 0.014122117310762405\n",
      "acc for Lsat= 0.218842885353499 \n",
      "acc for Psat= 0.295590958558023 \n",
      "acc for optim= 0.1767094022490912\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.013853916898369789\n",
      "Loss on test= 0.014008160680532455\n",
      "acc for Lsat= 0.25356263424166375 \n",
      "acc for Psat= 0.31545525445188916 \n",
      "acc for optim= 0.19261332078733379\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.013984435237944126\n",
      "Loss on test= 0.013013379648327827\n",
      "acc for Lsat= 0.22930059923479953 \n",
      "acc for Psat= 0.3460387895659854 \n",
      "acc for optim= 0.17855649935599002\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.012937826104462147\n",
      "Loss on test= 0.013049710541963577\n",
      "acc for Lsat= 0.23898819668425453 \n",
      "acc for Psat= 0.3557921605081194 \n",
      "acc for optim= 0.17198654279733697\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.013465005904436111\n",
      "Loss on test= 0.012542828917503357\n",
      "acc for Lsat= 0.22204461983508533 \n",
      "acc for Psat= 0.3312122207134962 \n",
      "acc for optim= 0.17363953047121564\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.012793690897524357\n",
      "Loss on test= 0.013052668422460556\n",
      "acc for Lsat= 0.26374042546376586 \n",
      "acc for Psat= 0.3654895206499431 \n",
      "acc for optim= 0.13809719945614538\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.013245770707726479\n",
      "Loss on test= 0.013082053512334824\n",
      "acc for Lsat= 0.2737708017230034 \n",
      "acc for Psat= 0.27819483778956866 \n",
      "acc for optim= 0.1593013330259257\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.012892973609268665\n",
      "Loss on test= 0.012575052678585052\n",
      "acc for Lsat= 0.17869016476389435 \n",
      "acc for Psat= 0.23211269453167915 \n",
      "acc for optim= 0.1384116349120935\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.01299481000751257\n",
      "Loss on test= 0.012191268615424633\n",
      "acc for Lsat= 0.18862375244498253 \n",
      "acc for Psat= 0.23092107267843354 \n",
      "acc for optim= 0.12220330303534865\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.012333407998085022\n",
      "Loss on test= 0.011559057980775833\n",
      "acc for Lsat= 0.22868652403768566 \n",
      "acc for Psat= 0.3796106393759449 \n",
      "acc for optim= 0.15005865010122457\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.012478618882596493\n",
      "Loss on test= 0.01156145241111517\n",
      "acc for Lsat= 0.2068384269045459 \n",
      "acc for Psat= 0.29382248129695654 \n",
      "acc for optim= 0.14434180475978386\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.01272779330611229\n",
      "Loss on test= 0.01381603255867958\n",
      "acc for Lsat= 0.3310494164082532 \n",
      "acc for Psat= 0.4986439094775253 \n",
      "acc for optim= 0.18702641688287258\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.012607160024344921\n",
      "Loss on test= 0.011754073202610016\n",
      "acc for Lsat= 0.2602125462144613 \n",
      "acc for Psat= 0.3099121117653946 \n",
      "acc for optim= 0.14582100117372143\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.012122207321226597\n",
      "Loss on test= 0.01090286299586296\n",
      "acc for Lsat= 0.2312831281322158 \n",
      "acc for Psat= 0.42013923006339204 \n",
      "acc for optim= 0.14951754006971088\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.012423022650182247\n",
      "Loss on test= 0.012182977050542831\n",
      "acc for Lsat= 0.2947344233592351 \n",
      "acc for Psat= 0.2746660178527236 \n",
      "acc for optim= 0.16123558818880054\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.012244919314980507\n",
      "Loss on test= 0.011826460249722004\n",
      "acc for Lsat= 0.29077850095927715 \n",
      "acc for Psat= 0.3615481174654431 \n",
      "acc for optim= 0.18085868366890484\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.012509855441749096\n",
      "Loss on test= 0.011475170031189919\n",
      "acc for Lsat= 0.23856640136283305 \n",
      "acc for Psat= 0.31977111225326854 \n",
      "acc for optim= 0.17747977862341535\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.012031874619424343\n",
      "Loss on test= 0.011075405403971672\n",
      "acc for Lsat= 0.2935366176275743 \n",
      "acc for Psat= 0.304726539645344 \n",
      "acc for optim= 0.16541145503934887\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.01235189102590084\n",
      "Loss on test= 0.011661404743790627\n",
      "acc for Lsat= 0.2232130883494392 \n",
      "acc for Psat= 0.24229318959017596 \n",
      "acc for optim= 0.1442872218063308\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.012282892130315304\n",
      "Loss on test= 0.01109582744538784\n",
      "acc for Lsat= 0.17646182499205074 \n",
      "acc for Psat= 0.4098044243227277 \n",
      "acc for optim= 0.17251240596589115\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.011834423989057541\n",
      "Loss on test= 0.011317634023725986\n",
      "acc for Lsat= 0.22629276564758685 \n",
      "acc for Psat= 0.3664222076121304 \n",
      "acc for optim= 0.1593325677741733\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.012032289057970047\n",
      "Loss on test= 0.010956698097288609\n",
      "acc for Lsat= 0.24916251904020706 \n",
      "acc for Psat= 0.31662617010685307 \n",
      "acc for optim= 0.14815198868099186\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.012018292210996151\n",
      "Loss on test= 0.010492482222616673\n",
      "acc for Lsat= 0.22995753997626403 \n",
      "acc for Psat= 0.3664609188110464 \n",
      "acc for optim= 0.19168758019804955\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.011958719231188297\n",
      "Loss on test= 0.010879229754209518\n",
      "acc for Lsat= 0.2719229157600138 \n",
      "acc for Psat= 0.28489735950198436 \n",
      "acc for optim= 0.15425818247927559\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.011766824871301651\n",
      "Loss on test= 0.011108224280178547\n",
      "acc for Lsat= 0.21421168151492667 \n",
      "acc for Psat= 0.3869590326729748 \n",
      "acc for optim= 0.13793442792828298\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.011897814460098743\n",
      "Loss on test= 0.010833635926246643\n",
      "acc for Lsat= 0.2258820366114378 \n",
      "acc for Psat= 0.34995522763994 \n",
      "acc for optim= 0.15094002005126742\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.01184436958283186\n",
      "Loss on test= 0.01102940272539854\n",
      "acc for Lsat= 0.1909874448966649 \n",
      "acc for Psat= 0.2814903650432825 \n",
      "acc for optim= 0.1680252713461717\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.011250441893935204\n",
      "Loss on test= 0.010702012106776237\n",
      "acc for Lsat= 0.2125814645551145 \n",
      "acc for Psat= 0.30315111732731265 \n",
      "acc for optim= 0.17450262440575492\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.01159866712987423\n",
      "Loss on test= 0.011082733049988747\n",
      "acc for Lsat= 0.2705900188949373 \n",
      "acc for Psat= 0.37853195518255234 \n",
      "acc for optim= 0.16674467714296448\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.011086946353316307\n",
      "Loss on test= 0.01039536576718092\n",
      "acc for Lsat= 0.261588376843267 \n",
      "acc for Psat= 0.27253352457450497 \n",
      "acc for optim= 0.17575729079544544\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.011622991412878036\n",
      "Loss on test= 0.009963175281882286\n",
      "acc for Lsat= 0.20031897977201474 \n",
      "acc for Psat= 0.3218455852733718 \n",
      "acc for optim= 0.15882295817654166\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.011345445178449154\n",
      "Loss on test= 0.010509731248021126\n",
      "acc for Lsat= 0.24020662914133734 \n",
      "acc for Psat= 0.30385375529941583 \n",
      "acc for optim= 0.1587677707753351\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.011296173557639122\n",
      "Loss on test= 0.010229062288999557\n",
      "acc for Lsat= 0.16299567943335408 \n",
      "acc for Psat= 0.22108962635199228 \n",
      "acc for optim= 0.13450688751052237\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.01132206805050373\n",
      "Loss on test= 0.009747599251568317\n",
      "acc for Lsat= 0.1883403601952725 \n",
      "acc for Psat= 0.35018949231339824 \n",
      "acc for optim= 0.13563638007811582\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.011440611444413662\n",
      "Loss on test= 0.010341671295464039\n",
      "acc for Lsat= 0.22702861111611128 \n",
      "acc for Psat= 0.33148720974309576 \n",
      "acc for optim= 0.12965633880553973\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.011625365354120731\n",
      "Loss on test= 0.009709279984235764\n",
      "acc for Lsat= 0.2575252902590566 \n",
      "acc for Psat= 0.4067163572957118 \n",
      "acc for optim= 0.1705436628932754\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.010852974839508533\n",
      "Loss on test= 0.01031773816794157\n",
      "acc for Lsat= 0.2536659712592761 \n",
      "acc for Psat= 0.29981733786149156 \n",
      "acc for optim= 0.15426955475575393\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.010684275068342686\n",
      "Loss on test= 0.010632915422320366\n",
      "acc for Lsat= 0.19381318370708162 \n",
      "acc for Psat= 0.28932542726397514 \n",
      "acc for optim= 0.13684634119272232\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.011456042528152466\n",
      "Loss on test= 0.010671376250684261\n",
      "acc for Lsat= 0.19868438007930914 \n",
      "acc for Psat= 0.27630709887792665 \n",
      "acc for optim= 0.13909629934156933\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.01075746864080429\n",
      "Loss on test= 0.010552415624260902\n",
      "acc for Lsat= 0.23126713783454356 \n",
      "acc for Psat= 0.44076468091872 \n",
      "acc for optim= 0.1251907143741846\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.010908113792538643\n",
      "Loss on test= 0.010194179601967335\n",
      "acc for Lsat= 0.24971474210421243 \n",
      "acc for Psat= 0.4618324960788919 \n",
      "acc for optim= 0.1853104189245237\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.01034864503890276\n",
      "Loss on test= 0.010044918395578861\n",
      "acc for Lsat= 0.18949995852178997 \n",
      "acc for Psat= 0.31641832961597377 \n",
      "acc for optim= 0.15723647218611506\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.010833265259861946\n",
      "Loss on test= 0.01012472528964281\n",
      "acc for Lsat= 0.15982662017146745 \n",
      "acc for Psat= 0.3565783676587873 \n",
      "acc for optim= 0.1334244171804231\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.010777447372674942\n",
      "Loss on test= 0.010256224311888218\n",
      "acc for Lsat= 0.2690350144273705 \n",
      "acc for Psat= 0.3040721273670594 \n",
      "acc for optim= 0.14235470650924575\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.01061875931918621\n",
      "Loss on test= 0.009731153957545757\n",
      "acc for Lsat= 0.23417706415057182 \n",
      "acc for Psat= 0.2872775325215318 \n",
      "acc for optim= 0.13726386241614819\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.010166492313146591\n",
      "Loss on test= 0.010019750334322453\n",
      "acc for Lsat= 0.16921026973674694 \n",
      "acc for Psat= 0.31621426261133617 \n",
      "acc for optim= 0.1579457661913087\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.010880778543651104\n",
      "Loss on test= 0.009772416204214096\n",
      "acc for Lsat= 0.22685659076119513 \n",
      "acc for Psat= 0.30280965857673436 \n",
      "acc for optim= 0.1578946684797605\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.010169854387640953\n",
      "Loss on test= 0.009806104004383087\n",
      "acc for Lsat= 0.1796530003969868 \n",
      "acc for Psat= 0.3534831152194076 \n",
      "acc for optim= 0.1551891305587358\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.0105190584436059\n",
      "Loss on test= 0.009716574102640152\n",
      "acc for Lsat= 0.20602081974761355 \n",
      "acc for Psat= 0.3694707688668536 \n",
      "acc for optim= 0.14839562070038584\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.01064310036599636\n",
      "Loss on test= 0.010128066875040531\n",
      "acc for Lsat= 0.23335257979730764 \n",
      "acc for Psat= 0.3481247503724363 \n",
      "acc for optim= 0.13031991307313243\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.01023812685161829\n",
      "Loss on test= 0.009321067482233047\n",
      "acc for Lsat= 0.26901269352270496 \n",
      "acc for Psat= 0.23122371153699028 \n",
      "acc for optim= 0.14501484235127768\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.010129425674676895\n",
      "Loss on test= 0.010090581141412258\n",
      "acc for Lsat= 0.21558983525675204 \n",
      "acc for Psat= 0.31506359742747414 \n",
      "acc for optim= 0.14384758394832411\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.009846041910350323\n",
      "Loss on test= 0.009279431775212288\n",
      "acc for Lsat= 0.2149364962759945 \n",
      "acc for Psat= 0.2874919884941644 \n",
      "acc for optim= 0.1502128883989321\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.01007059309631586\n",
      "Loss on test= 0.008532820269465446\n",
      "acc for Lsat= 0.16694722697138786 \n",
      "acc for Psat= 0.26955346307820743 \n",
      "acc for optim= 0.1443229630175564\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.009733300656080246\n",
      "Loss on test= 0.009834902361035347\n",
      "acc for Lsat= 0.24661173278258908 \n",
      "acc for Psat= 0.19294941164035764 \n",
      "acc for optim= 0.16450585254157582\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.00996557530015707\n",
      "Loss on test= 0.009315650910139084\n",
      "acc for Lsat= 0.18849888099874887 \n",
      "acc for Psat= 0.22665225486788484 \n",
      "acc for optim= 0.1275463017453957\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.00998099334537983\n",
      "Loss on test= 0.009198558516800404\n",
      "acc for Lsat= 0.257124496002992 \n",
      "acc for Psat= 0.27017523053412634 \n",
      "acc for optim= 0.13589719589799643\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.009636488743126392\n",
      "Loss on test= 0.009092501364648342\n",
      "acc for Lsat= 0.22296368410914308 \n",
      "acc for Psat= 0.3224985845800903 \n",
      "acc for optim= 0.15173894208338526\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.0097081009298563\n",
      "Loss on test= 0.009363175369799137\n",
      "acc for Lsat= 0.23143190083404383 \n",
      "acc for Psat= 0.3814951736066077 \n",
      "acc for optim= 0.1300807472370151\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.01000303402543068\n",
      "Loss on test= 0.009308841079473495\n",
      "acc for Lsat= 0.22573890845847522 \n",
      "acc for Psat= 0.3914919608893494 \n",
      "acc for optim= 0.13691142762804198\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.009824090637266636\n",
      "Loss on test= 0.008724519982933998\n",
      "acc for Lsat= 0.2273690480635398 \n",
      "acc for Psat= 0.35446981630391544 \n",
      "acc for optim= 0.16223447925100723\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.009522362612187862\n",
      "Loss on test= 0.007970904931426048\n",
      "acc for Lsat= 0.17184809759621406 \n",
      "acc for Psat= 0.23515064991402646 \n",
      "acc for optim= 0.13560639166583618\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.009235077537596226\n",
      "Loss on test= 0.008621550165116787\n",
      "acc for Lsat= 0.15420813287750612 \n",
      "acc for Psat= 0.24149019855798948 \n",
      "acc for optim= 0.14246752651201355\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.009595674462616444\n",
      "Loss on test= 0.008089769631624222\n",
      "acc for Lsat= 0.19566450076591638 \n",
      "acc for Psat= 0.2898121574479673 \n",
      "acc for optim= 0.14959268282271093\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.009386376477777958\n",
      "Loss on test= 0.008763340301811695\n",
      "acc for Lsat= 0.23412995575927198 \n",
      "acc for Psat= 0.26927718525338507 \n",
      "acc for optim= 0.17001146649838322\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.009516855701804161\n",
      "Loss on test= 0.008591101504862309\n",
      "acc for Lsat= 0.1556961092994445 \n",
      "acc for Psat= 0.2360416484168834 \n",
      "acc for optim= 0.14229575203110775\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.009273476898670197\n",
      "Loss on test= 0.008235287852585316\n",
      "acc for Lsat= 0.17950182236058432 \n",
      "acc for Psat= 0.26003256482848275 \n",
      "acc for optim= 0.13178647899379334\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.00950712338089943\n",
      "Loss on test= 0.008684460073709488\n",
      "acc for Lsat= 0.165216412084798 \n",
      "acc for Psat= 0.22716325997478432 \n",
      "acc for optim= 0.13680775142792198\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.009208506904542446\n",
      "Loss on test= 0.00877280905842781\n",
      "acc for Lsat= 0.14949154507161844 \n",
      "acc for Psat= 0.21598581760190427 \n",
      "acc for optim= 0.14364115692054233\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.009051285684108734\n",
      "Loss on test= 0.008568715304136276\n",
      "acc for Lsat= 0.18142900657322672 \n",
      "acc for Psat= 0.21168667393633062 \n",
      "acc for optim= 0.15615222204683554\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.008793894201517105\n",
      "Loss on test= 0.00839991495013237\n",
      "acc for Lsat= 0.23410083922661012 \n",
      "acc for Psat= 0.24694843874830338 \n",
      "acc for optim= 0.14568840650220713\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.008994205854833126\n",
      "Loss on test= 0.008345569483935833\n",
      "acc for Lsat= 0.20189572208457524 \n",
      "acc for Psat= 0.2493314519007173 \n",
      "acc for optim= 0.11024537103043662\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.009145350195467472\n",
      "Loss on test= 0.008530865423381329\n",
      "acc for Lsat= 0.2487904561890496 \n",
      "acc for Psat= 0.3345406132025851 \n",
      "acc for optim= 0.15545012046479517\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.008861773647367954\n",
      "Loss on test= 0.008285200223326683\n",
      "acc for Lsat= 0.16739047109149396 \n",
      "acc for Psat= 0.20171754245529883 \n",
      "acc for optim= 0.13435154234159402\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.008614514023065567\n",
      "Loss on test= 0.007955587469041348\n",
      "acc for Lsat= 0.15965771457801262 \n",
      "acc for Psat= 0.2559915091842413 \n",
      "acc for optim= 0.14573468081653118\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.008826624602079391\n",
      "Loss on test= 0.008747068233788013\n",
      "acc for Lsat= 0.16765730882090996 \n",
      "acc for Psat= 0.2957927688387119 \n",
      "acc for optim= 0.14616589036045802\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.0085378997027874\n",
      "Loss on test= 0.00849185697734356\n",
      "acc for Lsat= 0.23486338555812836 \n",
      "acc for Psat= 0.23028896562755108 \n",
      "acc for optim= 0.13556572287860844\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.008861418813467026\n",
      "Loss on test= 0.00798849854618311\n",
      "acc for Lsat= 0.17270888949537444 \n",
      "acc for Psat= 0.29940383198360604 \n",
      "acc for optim= 0.1560068503022194\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.008502236567437649\n",
      "Loss on test= 0.007639216259121895\n",
      "acc for Lsat= 0.11981784276819478 \n",
      "acc for Psat= 0.19172542340432605 \n",
      "acc for optim= 0.14370335602305\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.008529642596840858\n",
      "Loss on test= 0.008633025921881199\n",
      "acc for Lsat= 0.18524377767203581 \n",
      "acc for Psat= 0.24435666001712283 \n",
      "acc for optim= 0.13273133544458282\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.008666873909533024\n",
      "Loss on test= 0.007884126156568527\n",
      "acc for Lsat= 0.19779817229654226 \n",
      "acc for Psat= 0.2725771487587028 \n",
      "acc for optim= 0.1388908483980534\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.008481155149638653\n",
      "Loss on test= 0.008770450949668884\n",
      "acc for Lsat= 0.21779656782746315 \n",
      "acc for Psat= 0.25066605810489917 \n",
      "acc for optim= 0.14277510908949706\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.008446979336440563\n",
      "Loss on test= 0.008331491611897945\n",
      "acc for Lsat= 0.18731423513963819 \n",
      "acc for Psat= 0.2688706212987502 \n",
      "acc for optim= 0.15441678267800146\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.008526957593858242\n",
      "Loss on test= 0.007630030158907175\n",
      "acc for Lsat= 0.1818213981265823 \n",
      "acc for Psat= 0.24058167243169415 \n",
      "acc for optim= 0.11188035266887811\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.008177142590284348\n",
      "Loss on test= 0.007919768802821636\n",
      "acc for Lsat= 0.14776931599610382 \n",
      "acc for Psat= 0.2808165018343263 \n",
      "acc for optim= 0.1514177368953824\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.008503003977239132\n",
      "Loss on test= 0.007870731875300407\n",
      "acc for Lsat= 0.14436723540226618 \n",
      "acc for Psat= 0.2636333814718657 \n",
      "acc for optim= 0.1543469329416338\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.0081780469045043\n",
      "Loss on test= 0.007788111921399832\n",
      "acc for Lsat= 0.23165525992711386 \n",
      "acc for Psat= 0.23811482886473337 \n",
      "acc for optim= 0.14759949058578867\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.008356877602636814\n",
      "Loss on test= 0.008342272602021694\n",
      "acc for Lsat= 0.19185952045437363 \n",
      "acc for Psat= 0.31394841418498093 \n",
      "acc for optim= 0.1351938813717829\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.008252318948507309\n",
      "Loss on test= 0.007667139172554016\n",
      "acc for Lsat= 0.159013111403005 \n",
      "acc for Psat= 0.2383657010893027 \n",
      "acc for optim= 0.14038682516871226\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.008319574408233166\n",
      "Loss on test= 0.007733066100627184\n",
      "acc for Lsat= 0.16284462651755247 \n",
      "acc for Psat= 0.2520174439996481 \n",
      "acc for optim= 0.13812532433722582\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.008315231651067734\n",
      "Loss on test= 0.007278772536665201\n",
      "acc for Lsat= 0.1644615482331978 \n",
      "acc for Psat= 0.1853605201985273 \n",
      "acc for optim= 0.1610379916512304\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.008055204525589943\n",
      "Loss on test= 0.007720911875367165\n",
      "acc for Lsat= 0.17373084269153574 \n",
      "acc for Psat= 0.24728224323027664 \n",
      "acc for optim= 0.14944604660073915\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.00794311985373497\n",
      "Loss on test= 0.008036831393837929\n",
      "acc for Lsat= 0.13916502793371263 \n",
      "acc for Psat= 0.24674693758909902 \n",
      "acc for optim= 0.12787234930632016\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.008111509494483471\n",
      "Loss on test= 0.007729334756731987\n",
      "acc for Lsat= 0.15402603283938435 \n",
      "acc for Psat= 0.1573037434136495 \n",
      "acc for optim= 0.1535968662550052\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.007994746789336205\n",
      "Loss on test= 0.0076022944413125515\n",
      "acc for Lsat= 0.18486585923367077 \n",
      "acc for Psat= 0.24107801601187223 \n",
      "acc for optim= 0.15579337906092405\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.008077302947640419\n",
      "Loss on test= 0.0073442840948700905\n",
      "acc for Lsat= 0.19364852525500786 \n",
      "acc for Psat= 0.21120375581085682 \n",
      "acc for optim= 0.1210445375699136\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.007812004070729017\n",
      "Loss on test= 0.007217162288725376\n",
      "acc for Lsat= 0.21224010859926543 \n",
      "acc for Psat= 0.29770059749070144 \n",
      "acc for optim= 0.12537655640496975\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.007952800020575523\n",
      "Loss on test= 0.007182613015174866\n",
      "acc for Lsat= 0.14733851382819316 \n",
      "acc for Psat= 0.1793571702308125 \n",
      "acc for optim= 0.12626445623269925\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.007987601682543755\n",
      "Loss on test= 0.007121148984879255\n",
      "acc for Lsat= 0.1713729908482896 \n",
      "acc for Psat= 0.2220717491582036 \n",
      "acc for optim= 0.13104612272905392\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.007905548438429832\n",
      "Loss on test= 0.00732904439792037\n",
      "acc for Lsat= 0.1401245773045553 \n",
      "acc for Psat= 0.20198489208188322 \n",
      "acc for optim= 0.11563142683977883\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.007457150612026453\n",
      "Loss on test= 0.007501001004129648\n",
      "acc for Lsat= 0.16802684164657775 \n",
      "acc for Psat= 0.27234135050740504 \n",
      "acc for optim= 0.12688664108928707\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.007853107526898384\n",
      "Loss on test= 0.007678048685193062\n",
      "acc for Lsat= 0.20195825729105207 \n",
      "acc for Psat= 0.2507926477636728 \n",
      "acc for optim= 0.12136692303789055\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.007600617129355669\n",
      "Loss on test= 0.007464479189366102\n",
      "acc for Lsat= 0.14335529257853827 \n",
      "acc for Psat= 0.18874053426811266 \n",
      "acc for optim= 0.13904900409074294\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.007558839395642281\n",
      "Loss on test= 0.0070204585790634155\n",
      "acc for Lsat= 0.12403776107304212 \n",
      "acc for Psat= 0.20186215452849865 \n",
      "acc for optim= 0.1246347048630317\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.007569244131445885\n",
      "Loss on test= 0.007149986922740936\n",
      "acc for Lsat= 0.15207960927445027 \n",
      "acc for Psat= 0.20425228654898497 \n",
      "acc for optim= 0.10018238184663157\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.007323509082198143\n",
      "Loss on test= 0.007143358234316111\n",
      "acc for Lsat= 0.16159727240705657 \n",
      "acc for Psat= 0.21329125296324492 \n",
      "acc for optim= 0.13243757985118362\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.007394623942673206\n",
      "Loss on test= 0.007655758876353502\n",
      "acc for Lsat= 0.2036212392979198 \n",
      "acc for Psat= 0.26188642549742425 \n",
      "acc for optim= 0.14399603857762283\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.007752467878162861\n",
      "Loss on test= 0.007553348783403635\n",
      "acc for Lsat= 0.19698545647164187 \n",
      "acc for Psat= 0.29949426506128574 \n",
      "acc for optim= 0.13033423598648775\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.007864104583859444\n",
      "Loss on test= 0.0071751996874809265\n",
      "acc for Lsat= 0.141822733711807 \n",
      "acc for Psat= 0.23827994974433547 \n",
      "acc for optim= 0.10947229123363893\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.007712656166404486\n",
      "Loss on test= 0.007764482870697975\n",
      "acc for Lsat= 0.1960706813260913 \n",
      "acc for Psat= 0.21984937589796674 \n",
      "acc for optim= 0.14245686090240875\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.007741846144199371\n",
      "Loss on test= 0.00730309309437871\n",
      "acc for Lsat= 0.1581847726677855 \n",
      "acc for Psat= 0.22404623221114484 \n",
      "acc for optim= 0.1374750285823312\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.007359364535659552\n",
      "Loss on test= 0.0071078091859817505\n",
      "acc for Lsat= 0.1323260443492068 \n",
      "acc for Psat= 0.226492737678604 \n",
      "acc for optim= 0.1358058580921756\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.007341685704886913\n",
      "Loss on test= 0.007360073272138834\n",
      "acc for Lsat= 0.21258777933609155 \n",
      "acc for Psat= 0.1873927800398734 \n",
      "acc for optim= 0.12786113967498144\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.00752479862421751\n",
      "Loss on test= 0.007518041413277388\n",
      "acc for Lsat= 0.14485332442240584 \n",
      "acc for Psat= 0.2587830511232217 \n",
      "acc for optim= 0.13032793615841204\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.007298653945326805\n",
      "Loss on test= 0.007169247604906559\n",
      "acc for Lsat= 0.18010709811318926 \n",
      "acc for Psat= 0.19532016230126223 \n",
      "acc for optim= 0.12588709903260073\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.0074882046319544315\n",
      "Loss on test= 0.00668169604614377\n",
      "acc for Lsat= 0.17019520989722675 \n",
      "acc for Psat= 0.19291520356718037 \n",
      "acc for optim= 0.13721595646994603\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.007343185134232044\n",
      "Loss on test= 0.006975613534450531\n",
      "acc for Lsat= 0.15708330959831882 \n",
      "acc for Psat= 0.20200203907572561 \n",
      "acc for optim= 0.14099274368749726\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.007149622309952974\n",
      "Loss on test= 0.007126169744879007\n",
      "acc for Lsat= 0.18714515505255097 \n",
      "acc for Psat= 0.19259218669806918 \n",
      "acc for optim= 0.12034957726589507\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.007332982495427132\n",
      "Loss on test= 0.00714165810495615\n",
      "acc for Lsat= 0.1398169513170918 \n",
      "acc for Psat= 0.27210844464813516 \n",
      "acc for optim= 0.14214591247340044\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.007193941157311201\n",
      "Loss on test= 0.006744518876075745\n",
      "acc for Lsat= 0.15205827160065788 \n",
      "acc for Psat= 0.2741235166581141 \n",
      "acc for optim= 0.12556389240651494\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.007583389058709145\n",
      "Loss on test= 0.006682433187961578\n",
      "acc for Lsat= 0.20857297132412592 \n",
      "acc for Psat= 0.22197162986008656 \n",
      "acc for optim= 0.14793010857991046\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.007412216160446405\n",
      "Loss on test= 0.006496882997453213\n",
      "acc for Lsat= 0.13609003430853286 \n",
      "acc for Psat= 0.25299443811592126 \n",
      "acc for optim= 0.11502076488816076\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.007278257980942726\n",
      "Loss on test= 0.0069380165077745914\n",
      "acc for Lsat= 0.16395179979089233 \n",
      "acc for Psat= 0.24707614609764683 \n",
      "acc for optim= 0.11670863024159593\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.007072357926517725\n",
      "Loss on test= 0.00741978082805872\n",
      "acc for Lsat= 0.15851719537749887 \n",
      "acc for Psat= 0.2539106946852472 \n",
      "acc for optim= 0.13049246282834145\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.007085558492690325\n",
      "Loss on test= 0.006497031543403864\n",
      "acc for Lsat= 0.20069489483204153 \n",
      "acc for Psat= 0.25150455477544004 \n",
      "acc for optim= 0.11625544708739552\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.007229112088680267\n",
      "Loss on test= 0.007221583742648363\n",
      "acc for Lsat= 0.1528089264821675 \n",
      "acc for Psat= 0.2087533807175027 \n",
      "acc for optim= 0.1331527028232813\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.007086269091814756\n",
      "Loss on test= 0.007130391895771027\n",
      "acc for Lsat= 0.1546756476163864 \n",
      "acc for Psat= 0.23754825608597863 \n",
      "acc for optim= 0.10281923563646463\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.007224639877676964\n",
      "Loss on test= 0.006528048310428858\n",
      "acc for Lsat= 0.1469989966394173 \n",
      "acc for Psat= 0.25413749035861755 \n",
      "acc for optim= 0.1437856600775073\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.0068091438151896\n",
      "Loss on test= 0.006715497002005577\n",
      "acc for Lsat= 0.1261994117198305 \n",
      "acc for Psat= 0.14463757265669605 \n",
      "acc for optim= 0.11053339993425955\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.007223011460155249\n",
      "Loss on test= 0.006934046745300293\n",
      "acc for Lsat= 0.12675944338035253 \n",
      "acc for Psat= 0.20089091308828858 \n",
      "acc for optim= 0.1314048068662588\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.0069156731478869915\n",
      "Loss on test= 0.00642986036837101\n",
      "acc for Lsat= 0.10337411891669035 \n",
      "acc for Psat= 0.23216409334498975 \n",
      "acc for optim= 0.11508746238218413\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.007075146306306124\n",
      "Loss on test= 0.0063911802135407925\n",
      "acc for Lsat= 0.17128079425957468 \n",
      "acc for Psat= 0.12557674990966916 \n",
      "acc for optim= 0.12758279586624768\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.0070627485401928425\n",
      "Loss on test= 0.006874175276607275\n",
      "acc for Lsat= 0.15568346973870778 \n",
      "acc for Psat= 0.2768769713325633 \n",
      "acc for optim= 0.13887639198866156\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.006961390376091003\n",
      "Loss on test= 0.007540534716099501\n",
      "acc for Lsat= 0.13902268439738286 \n",
      "acc for Psat= 0.24224135734968716 \n",
      "acc for optim= 0.1348875136528578\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.007228955160826445\n",
      "Loss on test= 0.007074008230119944\n",
      "acc for Lsat= 0.17048177417988578 \n",
      "acc for Psat= 0.2858718276774097 \n",
      "acc for optim= 0.10732252988964319\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.0068972972221672535\n",
      "Loss on test= 0.007102149073034525\n",
      "acc for Lsat= 0.1694135299573342 \n",
      "acc for Psat= 0.18704408045030302 \n",
      "acc for optim= 0.1021937307022098\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.007001240737736225\n",
      "Loss on test= 0.006692013703286648\n",
      "acc for Lsat= 0.15582945733654519 \n",
      "acc for Psat= 0.22170933693026504 \n",
      "acc for optim= 0.1291636223387387\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.007065607700496912\n",
      "Loss on test= 0.007338628172874451\n",
      "acc for Lsat= 0.14365467398116985 \n",
      "acc for Psat= 0.20898861883001196 \n",
      "acc for optim= 0.12380389446884187\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.006976480595767498\n",
      "Loss on test= 0.007072129286825657\n",
      "acc for Lsat= 0.13030832048712504 \n",
      "acc for Psat= 0.1996779647241864 \n",
      "acc for optim= 0.11342578950441545\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.006798942107707262\n",
      "Loss on test= 0.006728393957018852\n",
      "acc for Lsat= 0.07280278374997175 \n",
      "acc for Psat= 0.18198901026820144 \n",
      "acc for optim= 0.13903686113189906\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.006820640992373228\n",
      "Loss on test= 0.006790807470679283\n",
      "acc for Lsat= 0.1551681955655416 \n",
      "acc for Psat= 0.1823007606694268 \n",
      "acc for optim= 0.12543494013112244\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.006887226831167936\n",
      "Loss on test= 0.006636602804064751\n",
      "acc for Lsat= 0.1364537529233429 \n",
      "acc for Psat= 0.18005394262986052 \n",
      "acc for optim= 0.11858227003055315\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.006762547418475151\n",
      "Loss on test= 0.006402030121535063\n",
      "acc for Lsat= 0.12526704381323522 \n",
      "acc for Psat= 0.22079608216881752 \n",
      "acc for optim= 0.14540107217099932\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.006700034718960524\n",
      "Loss on test= 0.006317255552858114\n",
      "acc for Lsat= 0.15245899040665892 \n",
      "acc for Psat= 0.24974028456704722 \n",
      "acc for optim= 0.12467502135162552\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.006804875563830137\n",
      "Loss on test= 0.006392247974872589\n",
      "acc for Lsat= 0.17338013007409042 \n",
      "acc for Psat= 0.19095305076593327 \n",
      "acc for optim= 0.14734896355205113\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.007066401652991772\n",
      "Loss on test= 0.0062458994798362255\n",
      "acc for Lsat= 0.152351535934334 \n",
      "acc for Psat= 0.2510190384669436 \n",
      "acc for optim= 0.13087569813554487\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.006821198854595423\n",
      "Loss on test= 0.006846910808235407\n",
      "acc for Lsat= 0.15954588684770796 \n",
      "acc for Psat= 0.18199336727977627 \n",
      "acc for optim= 0.14728649265857208\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.00675992202013731\n",
      "Loss on test= 0.006728174164891243\n",
      "acc for Lsat= 0.12675283774216142 \n",
      "acc for Psat= 0.20646625343296263 \n",
      "acc for optim= 0.15510392245940036\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.006696636788547039\n",
      "Loss on test= 0.0063279252499341965\n",
      "acc for Lsat= 0.1534090508875023 \n",
      "acc for Psat= 0.1993304771474666 \n",
      "acc for optim= 0.11967868875298235\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.006707102060317993\n",
      "Loss on test= 0.006425983272492886\n",
      "acc for Lsat= 0.13691696162439054 \n",
      "acc for Psat= 0.15983864401156703 \n",
      "acc for optim= 0.12089383105436961\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.006745584309101105\n",
      "Loss on test= 0.006049254443496466\n",
      "acc for Lsat= 0.148292757001602 \n",
      "acc for Psat= 0.24785883631557226 \n",
      "acc for optim= 0.10920898073042433\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.006659801118075848\n",
      "Loss on test= 0.006803271360695362\n",
      "acc for Lsat= 0.14115845556888315 \n",
      "acc for Psat= 0.13825547570983568 \n",
      "acc for optim= 0.12182349057143761\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.0065425680950284\n",
      "Loss on test= 0.007051635999232531\n",
      "acc for Lsat= 0.13961066874778932 \n",
      "acc for Psat= 0.17686857986781332 \n",
      "acc for optim= 0.10888892257611991\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.006758511066436768\n",
      "Loss on test= 0.006672120187431574\n",
      "acc for Lsat= 0.21386143368565375 \n",
      "acc for Psat= 0.2683204531462656 \n",
      "acc for optim= 0.10679063231994708\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.00651985127478838\n",
      "Loss on test= 0.006214482709765434\n",
      "acc for Lsat= 0.16693569947771417 \n",
      "acc for Psat= 0.19151658926986986 \n",
      "acc for optim= 0.10042760325854437\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.00651134829968214\n",
      "Loss on test= 0.006789885461330414\n",
      "acc for Lsat= 0.11875284783956078 \n",
      "acc for Psat= 0.18774244151750785 \n",
      "acc for optim= 0.10502591540312602\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.00680683134123683\n",
      "Loss on test= 0.006198215764015913\n",
      "acc for Lsat= 0.19890696607116196 \n",
      "acc for Psat= 0.173424802824027 \n",
      "acc for optim= 0.14476052806195286\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.006622785702347755\n",
      "Loss on test= 0.006193891167640686\n",
      "acc for Lsat= 0.18686862414081892 \n",
      "acc for Psat= 0.2769961382986771 \n",
      "acc for optim= 0.12623217654052293\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.006624799687415361\n",
      "Loss on test= 0.006128739099949598\n",
      "acc for Lsat= 0.18270724618600476 \n",
      "acc for Psat= 0.21121111367311743 \n",
      "acc for optim= 0.12497312660949926\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.006478721275925636\n",
      "Loss on test= 0.006473468616604805\n",
      "acc for Lsat= 0.09900186688173562 \n",
      "acc for Psat= 0.18890826605881253 \n",
      "acc for optim= 0.12258236187820633\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.0065972390584647655\n",
      "Loss on test= 0.007157440762966871\n",
      "acc for Lsat= 0.15268679925551018 \n",
      "acc for Psat= 0.27317692309022984 \n",
      "acc for optim= 0.142582946172398\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.00672121811658144\n",
      "Loss on test= 0.00641653873026371\n",
      "acc for Lsat= 0.1630619369292011 \n",
      "acc for Psat= 0.181433499764858 \n",
      "acc for optim= 0.1273452928289771\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.006612441036850214\n",
      "Loss on test= 0.00636838236823678\n",
      "acc for Lsat= 0.13695635098136133 \n",
      "acc for Psat= 0.20323866749337563 \n",
      "acc for optim= 0.11921089714936291\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.006566828116774559\n",
      "Loss on test= 0.006192661821842194\n",
      "acc for Lsat= 0.1714710712225901 \n",
      "acc for Psat= 0.18385800170815653 \n",
      "acc for optim= 0.11676578146095078\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.006469466257840395\n",
      "Loss on test= 0.0065382905304431915\n",
      "acc for Lsat= 0.14913082914426923 \n",
      "acc for Psat= 0.20125012399835718 \n",
      "acc for optim= 0.0977228448803847\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.006360969040542841\n",
      "Loss on test= 0.006000177934765816\n",
      "acc for Lsat= 0.16672319921457934 \n",
      "acc for Psat= 0.1920749163772497 \n",
      "acc for optim= 0.11451733314930203\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.00676870159804821\n",
      "Loss on test= 0.006339272018522024\n",
      "acc for Lsat= 0.12987828574033403 \n",
      "acc for Psat= 0.1462212364292807 \n",
      "acc for optim= 0.12774196944923866\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.0063596321269869804\n",
      "Loss on test= 0.0066308011300861835\n",
      "acc for Lsat= 0.14602087614023024 \n",
      "acc for Psat= 0.19271157613386297 \n",
      "acc for optim= 0.12091150001570997\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.006473055109381676\n",
      "Loss on test= 0.0064535667188465595\n",
      "acc for Lsat= 0.15661644792029014 \n",
      "acc for Psat= 0.2157671946576253 \n",
      "acc for optim= 0.12476504508716364\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.006573058199137449\n",
      "Loss on test= 0.005992295686155558\n",
      "acc for Lsat= 0.12174965897186969 \n",
      "acc for Psat= 0.1488968850818411 \n",
      "acc for optim= 0.11621665111225513\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.0063407402485609055\n",
      "Loss on test= 0.006700214929878712\n",
      "acc for Lsat= 0.09018566081714299 \n",
      "acc for Psat= 0.13690056448750612 \n",
      "acc for optim= 0.09888760383344358\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.006426776759326458\n",
      "Loss on test= 0.006214425899088383\n",
      "acc for Lsat= 0.10862307925708592 \n",
      "acc for Psat= 0.10379089953170882 \n",
      "acc for optim= 0.11998743563890457\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.006420907098799944\n",
      "Loss on test= 0.006411842070519924\n",
      "acc for Lsat= 0.13768477680989438 \n",
      "acc for Psat= 0.12778123799297544 \n",
      "acc for optim= 0.12864010341258514\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.006378228776156902\n",
      "Loss on test= 0.006294577848166227\n",
      "acc for Lsat= 0.19711781700445702 \n",
      "acc for Psat= 0.24248968965063492 \n",
      "acc for optim= 0.12478005100274459\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.006230928003787994\n",
      "Loss on test= 0.0063805230893194675\n",
      "acc for Lsat= 0.13518347508377498 \n",
      "acc for Psat= 0.2637247569445107 \n",
      "acc for optim= 0.1430435169442919\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.006263297516852617\n",
      "Loss on test= 0.006065619643777609\n",
      "acc for Lsat= 0.1212800122383568 \n",
      "acc for Psat= 0.20855598679433265 \n",
      "acc for optim= 0.12624425704901418\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.006285538896918297\n",
      "Loss on test= 0.006162507459521294\n",
      "acc for Lsat= 0.12504164952163896 \n",
      "acc for Psat= 0.1724088503461745 \n",
      "acc for optim= 0.12364932335913181\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.006345778703689575\n",
      "Loss on test= 0.005774195771664381\n",
      "acc for Lsat= 0.12764587211940023 \n",
      "acc for Psat= 0.15852861685885322 \n",
      "acc for optim= 0.10162630366782348\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.006289349868893623\n",
      "Loss on test= 0.0065872990526258945\n",
      "acc for Lsat= 0.12367397443287903 \n",
      "acc for Psat= 0.18415667013161713 \n",
      "acc for optim= 0.13712471206155089\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.006293600890785456\n",
      "Loss on test= 0.006218933500349522\n",
      "acc for Lsat= 0.11434400262725022 \n",
      "acc for Psat= 0.1893134323052234 \n",
      "acc for optim= 0.11533515258795685\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.006214983761310577\n",
      "Loss on test= 0.0060691554099321365\n",
      "acc for Lsat= 0.15980067724982897 \n",
      "acc for Psat= 0.1935363000827945 \n",
      "acc for optim= 0.10658259213798577\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.006293092854321003\n",
      "Loss on test= 0.0066734240390360355\n",
      "acc for Lsat= 0.17963995825913218 \n",
      "acc for Psat= 0.2424729593977746 \n",
      "acc for optim= 0.11329878050471759\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.006170426029711962\n",
      "Loss on test= 0.005732630379498005\n",
      "acc for Lsat= 0.1224669184949663 \n",
      "acc for Psat= 0.1795680464969741 \n",
      "acc for optim= 0.10241026767633027\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.0063341096974909306\n",
      "Loss on test= 0.006684374529868364\n",
      "acc for Lsat= 0.14684956727756393 \n",
      "acc for Psat= 0.22759211930840845 \n",
      "acc for optim= 0.12405347689572307\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.00621898053213954\n",
      "Loss on test= 0.006177933886647224\n",
      "acc for Lsat= 0.1370727557481991 \n",
      "acc for Psat= 0.18753327829633942 \n",
      "acc for optim= 0.1151907433134814\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.0064241900108754635\n",
      "Loss on test= 0.006693693343549967\n",
      "acc for Lsat= 0.15677386028174725 \n",
      "acc for Psat= 0.1549337903270498 \n",
      "acc for optim= 0.11565045271224032\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.006505886092782021\n",
      "Loss on test= 0.006441851612180471\n",
      "acc for Lsat= 0.17068316906483638 \n",
      "acc for Psat= 0.1739484690543678 \n",
      "acc for optim= 0.12309564277529716\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.006099466700106859\n",
      "Loss on test= 0.00587585661560297\n",
      "acc for Lsat= 0.12365963069411616 \n",
      "acc for Psat= 0.21000613753373423 \n",
      "acc for optim= 0.09524651328360455\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.006128195207566023\n",
      "Loss on test= 0.006038468796759844\n",
      "acc for Lsat= 0.12864613212231132 \n",
      "acc for Psat= 0.22627974767237902 \n",
      "acc for optim= 0.10131608498179251\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.006169741041958332\n",
      "Loss on test= 0.006197619251906872\n",
      "acc for Lsat= 0.16442722185618347 \n",
      "acc for Psat= 0.19949800179650387 \n",
      "acc for optim= 0.14074693765077326\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.00611001206561923\n",
      "Loss on test= 0.006026733200997114\n",
      "acc for Lsat= 0.1693499233159754 \n",
      "acc for Psat= 0.18849973132212958 \n",
      "acc for optim= 0.1141060977242887\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.005716843996196985\n",
      "Loss on test= 0.0059388079680502415\n",
      "acc for Lsat= 0.10653060710885459 \n",
      "acc for Psat= 0.1816374604176316 \n",
      "acc for optim= 0.1259519528183672\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.006007069256156683\n",
      "Loss on test= 0.005951729603111744\n",
      "acc for Lsat= 0.11584913665946159 \n",
      "acc for Psat= 0.1726861318780316 \n",
      "acc for optim= 0.10332471672962937\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.006027344148606062\n",
      "Loss on test= 0.006093282252550125\n",
      "acc for Lsat= 0.17563693939397731 \n",
      "acc for Psat= 0.2514819875359535 \n",
      "acc for optim= 0.13128059449243462\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.006183389108628035\n",
      "Loss on test= 0.005995164625346661\n",
      "acc for Lsat= 0.1651203379345437 \n",
      "acc for Psat= 0.14746347148805702 \n",
      "acc for optim= 0.11067746344229414\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.006212455220520496\n",
      "Loss on test= 0.006164524704217911\n",
      "acc for Lsat= 0.14869759474984473 \n",
      "acc for Psat= 0.1778127610579961 \n",
      "acc for optim= 0.13118729878786123\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.005963523406535387\n",
      "Loss on test= 0.005818688310682774\n",
      "acc for Lsat= 0.152283096841226 \n",
      "acc for Psat= 0.1650736716045584 \n",
      "acc for optim= 0.1379350297421398\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.006127342116087675\n",
      "Loss on test= 0.0058402325958013535\n",
      "acc for Lsat= 0.1313066954931451 \n",
      "acc for Psat= 0.1623441106122401 \n",
      "acc for optim= 0.10889786980139131\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.0060589308850467205\n",
      "Loss on test= 0.005840913392603397\n",
      "acc for Lsat= 0.1350586218242016 \n",
      "acc for Psat= 0.18783775427275234 \n",
      "acc for optim= 0.12099714701374371\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.0058929589577019215\n",
      "Loss on test= 0.0059919897466897964\n",
      "acc for Lsat= 0.11324299401086238 \n",
      "acc for Psat= 0.17220162652018997 \n",
      "acc for optim= 0.10106066418100251\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.005805624648928642\n",
      "Loss on test= 0.005913427099585533\n",
      "acc for Lsat= 0.11410848258270158 \n",
      "acc for Psat= 0.20363882354771098 \n",
      "acc for optim= 0.11373363707571116\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.00592769356444478\n",
      "Loss on test= 0.005939158610999584\n",
      "acc for Lsat= 0.15436730332051715 \n",
      "acc for Psat= 0.16390532022342086 \n",
      "acc for optim= 0.11995665873918268\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.005847443826496601\n",
      "Loss on test= 0.006216378416866064\n",
      "acc for Lsat= 0.15155729086190048 \n",
      "acc for Psat= 0.1933309643322395 \n",
      "acc for optim= 0.108196152244798\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.006000463385134935\n",
      "Loss on test= 0.005944238975644112\n",
      "acc for Lsat= 0.09987202022845547 \n",
      "acc for Psat= 0.17332432812286747 \n",
      "acc for optim= 0.13580837530187434\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.005971459671854973\n",
      "Loss on test= 0.006122145336121321\n",
      "acc for Lsat= 0.12294756672862503 \n",
      "acc for Psat= 0.1541611785069108 \n",
      "acc for optim= 0.11941350934406121\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.006054614204913378\n",
      "Loss on test= 0.005878553260117769\n",
      "acc for Lsat= 0.15077361555045676 \n",
      "acc for Psat= 0.26159852078287965 \n",
      "acc for optim= 0.14081265772175458\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.005753694102168083\n",
      "Loss on test= 0.006117855664342642\n",
      "acc for Lsat= 0.16255740858873147 \n",
      "acc for Psat= 0.17049823246068424 \n",
      "acc for optim= 0.12294793491148287\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.006026920396834612\n",
      "Loss on test= 0.005848412401974201\n",
      "acc for Lsat= 0.13928012228441528 \n",
      "acc for Psat= 0.193597611790109 \n",
      "acc for optim= 0.10263646158596708\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.005979081615805626\n",
      "Loss on test= 0.005729335360229015\n",
      "acc for Lsat= 0.140704072597954 \n",
      "acc for Psat= 0.22572444213761222 \n",
      "acc for optim= 0.09542781869984335\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.006042006425559521\n",
      "Loss on test= 0.0059798043221235275\n",
      "acc for Lsat= 0.15046851781921255 \n",
      "acc for Psat= 0.16525933177520832 \n",
      "acc for optim= 0.12209788184716469\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.005803328938782215\n",
      "Loss on test= 0.006007697898894548\n",
      "acc for Lsat= 0.12115185718155569 \n",
      "acc for Psat= 0.18912979770296565 \n",
      "acc for optim= 0.1164645782749479\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.005938880145549774\n",
      "Loss on test= 0.005907758604735136\n",
      "acc for Lsat= 0.1328101022582915 \n",
      "acc for Psat= 0.17033288886563647 \n",
      "acc for optim= 0.11397313512861729\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.005894504953175783\n",
      "Loss on test= 0.005683365743607283\n",
      "acc for Lsat= 0.15194847941812542 \n",
      "acc for Psat= 0.17452652654093173 \n",
      "acc for optim= 0.13372416328638792\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.005886377766728401\n",
      "Loss on test= 0.005974495783448219\n",
      "acc for Lsat= 0.13444974415728617 \n",
      "acc for Psat= 0.16872362166436183 \n",
      "acc for optim= 0.1164987055817619\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.005886767525225878\n",
      "Loss on test= 0.006195451132953167\n",
      "acc for Lsat= 0.19675447791814804 \n",
      "acc for Psat= 0.2646706056127894 \n",
      "acc for optim= 0.12484358514969547\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.0061178687028586864\n",
      "Loss on test= 0.00593058206140995\n",
      "acc for Lsat= 0.11454837267390555 \n",
      "acc for Psat= 0.16868092750923502 \n",
      "acc for optim= 0.11162987713598543\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.005651971325278282\n",
      "Loss on test= 0.005919535644352436\n",
      "acc for Lsat= 0.1463854595915311 \n",
      "acc for Psat= 0.2223162635539969 \n",
      "acc for optim= 0.10637483293087119\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.005749152973294258\n",
      "Loss on test= 0.005916410591453314\n",
      "acc for Lsat= 0.15751142562496373 \n",
      "acc for Psat= 0.14613410333792368 \n",
      "acc for optim= 0.0926910999438001\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.005927361082285643\n",
      "Loss on test= 0.005532080307602882\n",
      "acc for Lsat= 0.10472048518972264 \n",
      "acc for Psat= 0.13660177257325914 \n",
      "acc for optim= 0.11429889038360368\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.005763957276940346\n",
      "Loss on test= 0.0055906022898852825\n",
      "acc for Lsat= 0.14118244447227982 \n",
      "acc for Psat= 0.18228036364436978 \n",
      "acc for optim= 0.10157911999461551\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.0059341611340641975\n",
      "Loss on test= 0.005566606763750315\n",
      "acc for Lsat= 0.1477962432222234 \n",
      "acc for Psat= 0.14367427829226168 \n",
      "acc for optim= 0.11417129154627521\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.005649483297020197\n",
      "Loss on test= 0.005801469087600708\n",
      "acc for Lsat= 0.14166134119861656 \n",
      "acc for Psat= 0.1701131743223717 \n",
      "acc for optim= 0.11359733437550151\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.005905873607844114\n",
      "Loss on test= 0.00625575240701437\n",
      "acc for Lsat= 0.10940097815667589 \n",
      "acc for Psat= 0.17468711826950312 \n",
      "acc for optim= 0.10948077304702666\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.005901148542761803\n",
      "Loss on test= 0.006022045388817787\n",
      "acc for Lsat= 0.10657280881423503 \n",
      "acc for Psat= 0.14444116590958503 \n",
      "acc for optim= 0.10945357823382235\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.005878225434571505\n",
      "Loss on test= 0.005890197586268187\n",
      "acc for Lsat= 0.18443763007720312 \n",
      "acc for Psat= 0.2519926242530346 \n",
      "acc for optim= 0.10026328962218638\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.0059702773578464985\n",
      "Loss on test= 0.005735611077398062\n",
      "acc for Lsat= 0.12960045179352164 \n",
      "acc for Psat= 0.14773305515862173 \n",
      "acc for optim= 0.10341798990137047\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.005699177272617817\n",
      "Loss on test= 0.00571367796510458\n",
      "acc for Lsat= 0.1418313370603654 \n",
      "acc for Psat= 0.17715325692875517 \n",
      "acc for optim= 0.10791403313891755\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.005885138642042875\n",
      "Loss on test= 0.005810702219605446\n",
      "acc for Lsat= 0.12746878589193025 \n",
      "acc for Psat= 0.14495791556934515 \n",
      "acc for optim= 0.09945903884039985\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.005618553142994642\n",
      "Loss on test= 0.005730864126235247\n",
      "acc for Lsat= 0.10102310481791694 \n",
      "acc for Psat= 0.16287679163118204 \n",
      "acc for optim= 0.09184013524403174\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.005745648872107267\n",
      "Loss on test= 0.0059304991737008095\n",
      "acc for Lsat= 0.12438751125915183 \n",
      "acc for Psat= 0.21189662664093906 \n",
      "acc for optim= 0.1187904874742445\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.005843576975166798\n",
      "Loss on test= 0.005680187605321407\n",
      "acc for Lsat= 0.12070243101980951 \n",
      "acc for Psat= 0.15321412889493835 \n",
      "acc for optim= 0.10017570594532622\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.005923195276409388\n",
      "Loss on test= 0.005735018290579319\n",
      "acc for Lsat= 0.11174997296701702 \n",
      "acc for Psat= 0.1942369351680908 \n",
      "acc for optim= 0.09652676906747122\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.005846369080245495\n",
      "Loss on test= 0.005523480009287596\n",
      "acc for Lsat= 0.1198410243830747 \n",
      "acc for Psat= 0.12377050327551034 \n",
      "acc for optim= 0.11858202426487373\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.005780231673270464\n",
      "Loss on test= 0.005939500406384468\n",
      "acc for Lsat= 0.10176186378036316 \n",
      "acc for Psat= 0.1480144552834746 \n",
      "acc for optim= 0.12428870494477451\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.005789898801594973\n",
      "Loss on test= 0.006010676268488169\n",
      "acc for Lsat= 0.11921949337960945 \n",
      "acc for Psat= 0.15293811758359274 \n",
      "acc for optim= 0.10271007089047796\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.005796326790004969\n",
      "Loss on test= 0.005977371707558632\n",
      "acc for Lsat= 0.12217156744251649 \n",
      "acc for Psat= 0.16702439912801814 \n",
      "acc for optim= 0.10910935565415356\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.0057095796801149845\n",
      "Loss on test= 0.0057229772210121155\n",
      "acc for Lsat= 0.15264964900496933 \n",
      "acc for Psat= 0.16663563503405182 \n",
      "acc for optim= 0.11380236523432864\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.005744487512856722\n",
      "Loss on test= 0.005974577274173498\n",
      "acc for Lsat= 0.1506767154173253 \n",
      "acc for Psat= 0.17043282034703428 \n",
      "acc for optim= 0.11578267507462038\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.005666106473654509\n",
      "Loss on test= 0.005564453080296516\n",
      "acc for Lsat= 0.10967223087532653 \n",
      "acc for Psat= 0.16521423066862756 \n",
      "acc for optim= 0.1100528484934734\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.005667027086019516\n",
      "Loss on test= 0.0056152199395000935\n",
      "acc for Lsat= 0.12231004750356078 \n",
      "acc for Psat= 0.2239230630091495 \n",
      "acc for optim= 0.08928240954668985\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.0056231324560940266\n",
      "Loss on test= 0.005577787756919861\n",
      "acc for Lsat= 0.1330254710175925 \n",
      "acc for Psat= 0.12339417812310988 \n",
      "acc for optim= 0.11253976154451568\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.005774803925305605\n",
      "Loss on test= 0.005509926006197929\n",
      "acc for Lsat= 0.09252077372123797 \n",
      "acc for Psat= 0.12747550247392306 \n",
      "acc for optim= 0.10055246578607087\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.005822450388222933\n",
      "Loss on test= 0.005569141823798418\n",
      "acc for Lsat= 0.16097801509830686 \n",
      "acc for Psat= 0.14320161447135937 \n",
      "acc for optim= 0.09741655957703996\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.005822606850415468\n",
      "Loss on test= 0.005585827399045229\n",
      "acc for Lsat= 0.10023694444033834 \n",
      "acc for Psat= 0.18948057511200508 \n",
      "acc for optim= 0.11777539354857759\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.00558454729616642\n",
      "Loss on test= 0.005728990770876408\n",
      "acc for Lsat= 0.10752335565889047 \n",
      "acc for Psat= 0.20087525732297865 \n",
      "acc for optim= 0.10519390610150164\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.00557266129180789\n",
      "Loss on test= 0.005692655220627785\n",
      "acc for Lsat= 0.15181605812783042 \n",
      "acc for Psat= 0.11904139293538821 \n",
      "acc for optim= 0.09665455052810204\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.005632609128952026\n",
      "Loss on test= 0.005904886405915022\n",
      "acc for Lsat= 0.14156627877754444 \n",
      "acc for Psat= 0.18601216957904398 \n",
      "acc for optim= 0.11283849263822453\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.005468946881592274\n",
      "Loss on test= 0.005603244062513113\n",
      "acc for Lsat= 0.1728411494857735 \n",
      "acc for Psat= 0.19462198696823585 \n",
      "acc for optim= 0.10262831885160671\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.00564718060195446\n",
      "Loss on test= 0.005576365161687136\n",
      "acc for Lsat= 0.1645132527143384 \n",
      "acc for Psat= 0.18300936836749315 \n",
      "acc for optim= 0.12473827253820167\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.005607897415757179\n",
      "Loss on test= 0.005635321140289307\n",
      "acc for Lsat= 0.1334569011297491 \n",
      "acc for Psat= 0.12725275785972676 \n",
      "acc for optim= 0.09724061557143512\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.005557291675359011\n",
      "Loss on test= 0.005443457048386335\n",
      "acc for Lsat= 0.12869214930105954 \n",
      "acc for Psat= 0.1489198213029239 \n",
      "acc for optim= 0.08593940116568571\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.005532302428036928\n",
      "Loss on test= 0.005774432327598333\n",
      "acc for Lsat= 0.1427054052732678 \n",
      "acc for Psat= 0.16475580811190108 \n",
      "acc for optim= 0.10480936687801862\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.0055137802846729755\n",
      "Loss on test= 0.005566976964473724\n",
      "acc for Lsat= 0.13042779753191602 \n",
      "acc for Psat= 0.1671793356912935 \n",
      "acc for optim= 0.10455978889432219\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.005545337218791246\n",
      "Loss on test= 0.00551963783800602\n",
      "acc for Lsat= 0.13177670709167918 \n",
      "acc for Psat= 0.1823352622644355 \n",
      "acc for optim= 0.11306509541140662\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.005542959552258253\n",
      "Loss on test= 0.0053984057158231735\n",
      "acc for Lsat= 0.13736454325003755 \n",
      "acc for Psat= 0.16398454173597404 \n",
      "acc for optim= 0.12040946589938055\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.005446452647447586\n",
      "Loss on test= 0.005447266157716513\n",
      "acc for Lsat= 0.12353180700706111 \n",
      "acc for Psat= 0.12177684409026471 \n",
      "acc for optim= 0.10631496562725967\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.005598841235041618\n",
      "Loss on test= 0.0056144073605537415\n",
      "acc for Lsat= 0.12234761476025192 \n",
      "acc for Psat= 0.20277305759696496 \n",
      "acc for optim= 0.10456349250550072\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.005546850152313709\n",
      "Loss on test= 0.0055456911213696\n",
      "acc for Lsat= 0.12176297488622367 \n",
      "acc for Psat= 0.16916699231498772 \n",
      "acc for optim= 0.0808985168631706\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.005488478112965822\n",
      "Loss on test= 0.005707032047212124\n",
      "acc for Lsat= 0.11400413202742736 \n",
      "acc for Psat= 0.18230805934096375 \n",
      "acc for optim= 0.11137233890541312\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.005722412373870611\n",
      "Loss on test= 0.00581982359290123\n",
      "acc for Lsat= 0.14620459641769734 \n",
      "acc for Psat= 0.14110593787497944 \n",
      "acc for optim= 0.11808021987801315\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.0055083357729017735\n",
      "Loss on test= 0.005679700523614883\n",
      "acc for Lsat= 0.08911719877182299 \n",
      "acc for Psat= 0.1596140953608685 \n",
      "acc for optim= 0.10280409548431635\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.005611587315797806\n",
      "Loss on test= 0.005763767287135124\n",
      "acc for Lsat= 0.14482982363551855 \n",
      "acc for Psat= 0.1775761228766189 \n",
      "acc for optim= 0.09277170751657751\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.00537311052903533\n",
      "Loss on test= 0.00575120747089386\n",
      "acc for Lsat= 0.14562157311269808 \n",
      "acc for Psat= 0.22502998531692558 \n",
      "acc for optim= 0.11733076355368313\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.005470490548759699\n",
      "Loss on test= 0.005491172429174185\n",
      "acc for Lsat= 0.13973281460089815 \n",
      "acc for Psat= 0.16462749211738506 \n",
      "acc for optim= 0.13294750886658827\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.005526572000235319\n",
      "Loss on test= 0.005646702833473682\n",
      "acc for Lsat= 0.13209400988287395 \n",
      "acc for Psat= 0.20075607030755943 \n",
      "acc for optim= 0.08583011136700709\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.005383574869483709\n",
      "Loss on test= 0.005511630326509476\n",
      "acc for Lsat= 0.1361294889744992 \n",
      "acc for Psat= 0.1511291851897517 \n",
      "acc for optim= 0.13545532198622823\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.0056059653870761395\n",
      "Loss on test= 0.005744650959968567\n",
      "acc for Lsat= 0.12834373652003706 \n",
      "acc for Psat= 0.2133057152128054 \n",
      "acc for optim= 0.0891744701916145\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.005417969077825546\n",
      "Loss on test= 0.005788007285445929\n",
      "acc for Lsat= 0.10315445127586524 \n",
      "acc for Psat= 0.16194190240154663 \n",
      "acc for optim= 0.12210665943308009\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.00544442655518651\n",
      "Loss on test= 0.005447451490908861\n",
      "acc for Lsat= 0.14568967423919174 \n",
      "acc for Psat= 0.19847113680508402 \n",
      "acc for optim= 0.117291057559972\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.005490882322192192\n",
      "Loss on test= 0.0055314633063972\n",
      "acc for Lsat= 0.10808073072823593 \n",
      "acc for Psat= 0.0961573122897082 \n",
      "acc for optim= 0.1161434818059206\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.005566710140556097\n",
      "Loss on test= 0.005732448305934668\n",
      "acc for Lsat= 0.17107118769652313 \n",
      "acc for Psat= 0.17609060912703475 \n",
      "acc for optim= 0.11182189846618308\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.005427106283605099\n",
      "Loss on test= 0.005854996386915445\n",
      "acc for Lsat= 0.12497890995453215 \n",
      "acc for Psat= 0.19807175640016794 \n",
      "acc for optim= 0.10487549041863531\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.00559584517031908\n",
      "Loss on test= 0.005495644640177488\n",
      "acc for Lsat= 0.10877415788773862 \n",
      "acc for Psat= 0.1812697470239881 \n",
      "acc for optim= 0.102850249192367\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.005456987768411636\n",
      "Loss on test= 0.005795873235911131\n",
      "acc for Lsat= 0.11737026201768054 \n",
      "acc for Psat= 0.13079866321964395 \n",
      "acc for optim= 0.11022809490613225\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.0056636459194123745\n",
      "Loss on test= 0.005868999287486076\n",
      "acc for Lsat= 0.13244398103819954 \n",
      "acc for Psat= 0.1365550112289687 \n",
      "acc for optim= 0.10931301680910918\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.005598369054496288\n",
      "Loss on test= 0.005777011625468731\n",
      "acc for Lsat= 0.19250392292936644 \n",
      "acc for Psat= 0.18343350580996937 \n",
      "acc for optim= 0.10709257789939228\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.005370286758989096\n",
      "Loss on test= 0.005383444484323263\n",
      "acc for Lsat= 0.13333714984926498 \n",
      "acc for Psat= 0.1771797949137787 \n",
      "acc for optim= 0.10718330456357864\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.005431749392300844\n",
      "Loss on test= 0.005504841450601816\n",
      "acc for Lsat= 0.14104276781694758 \n",
      "acc for Psat= 0.18847060169921154 \n",
      "acc for optim= 0.11759863254944018\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.00551673723384738\n",
      "Loss on test= 0.005446554161608219\n",
      "acc for Lsat= 0.11933227890727317 \n",
      "acc for Psat= 0.20586398243904114 \n",
      "acc for optim= 0.11236864848372836\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.005273969378322363\n",
      "Loss on test= 0.005746189970523119\n",
      "acc for Lsat= 0.1482061141068698 \n",
      "acc for Psat= 0.17619118104792303 \n",
      "acc for optim= 0.10042326545549764\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.005613512825220823\n",
      "Loss on test= 0.005514516029506922\n",
      "acc for Lsat= 0.16897016587770647 \n",
      "acc for Psat= 0.1750326197490924 \n",
      "acc for optim= 0.10211157100275159\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.005467086564749479\n",
      "Loss on test= 0.005475582554936409\n",
      "acc for Lsat= 0.13395815195751007 \n",
      "acc for Psat= 0.18799169899688828 \n",
      "acc for optim= 0.10442604716970688\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.005515957251191139\n",
      "Loss on test= 0.005708929616957903\n",
      "acc for Lsat= 0.09348327204093544 \n",
      "acc for Psat= 0.10464945901185274 \n",
      "acc for optim= 0.1180051970295608\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.005370564758777618\n",
      "Loss on test= 0.005615662783384323\n",
      "acc for Lsat= 0.14967641865627634 \n",
      "acc for Psat= 0.2274119637699591 \n",
      "acc for optim= 0.13903687325202757\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.005410443060100079\n",
      "Loss on test= 0.005744018126279116\n",
      "acc for Lsat= 0.14509280512316358 \n",
      "acc for Psat= 0.16362535332640013 \n",
      "acc for optim= 0.12667844496253464\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.005293865222483873\n",
      "Loss on test= 0.005804657470434904\n",
      "acc for Lsat= 0.16116290761985713 \n",
      "acc for Psat= 0.23105930681857798 \n",
      "acc for optim= 0.11315159158160289\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.0055381543934345245\n",
      "Loss on test= 0.005402187816798687\n",
      "acc for Lsat= 0.12350829380253951 \n",
      "acc for Psat= 0.18970434346960652 \n",
      "acc for optim= 0.10482744583957053\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.005431038793176413\n",
      "Loss on test= 0.005533107556402683\n",
      "acc for Lsat= 0.1063954902605878 \n",
      "acc for Psat= 0.12350433925166726 \n",
      "acc for optim= 0.09913237227333917\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.005366670899093151\n",
      "Loss on test= 0.005551072768867016\n",
      "acc for Lsat= 0.12495565636911327 \n",
      "acc for Psat= 0.14837434774057734 \n",
      "acc for optim= 0.09863469904909532\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.0055251047015190125\n",
      "Loss on test= 0.0052358792163431644\n",
      "acc for Lsat= 0.11331626014887458 \n",
      "acc for Psat= 0.1540080607131434 \n",
      "acc for optim= 0.08634343024136291\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.005439113825559616\n",
      "Loss on test= 0.005277229472994804\n",
      "acc for Lsat= 0.13069467168922225 \n",
      "acc for Psat= 0.1875987770035863 \n",
      "acc for optim= 0.1040807109998746\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.005309184547513723\n",
      "Loss on test= 0.005597690120339394\n",
      "acc for Lsat= 0.13394652130146925 \n",
      "acc for Psat= 0.14384183815370002 \n",
      "acc for optim= 0.10890059876773092\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.00532024959102273\n",
      "Loss on test= 0.005261889658868313\n",
      "acc for Lsat= 0.10174192565803726 \n",
      "acc for Psat= 0.1498286279125346 \n",
      "acc for optim= 0.10380956095953782\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.005266840569674969\n",
      "Loss on test= 0.0053773680701851845\n",
      "acc for Lsat= 0.1395616557242142 \n",
      "acc for Psat= 0.17000110124030876 \n",
      "acc for optim= 0.11636299370891517\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.005426663439720869\n",
      "Loss on test= 0.005802272818982601\n",
      "acc for Lsat= 0.09878014400601387 \n",
      "acc for Psat= 0.12959559026381207 \n",
      "acc for optim= 0.10030264402222303\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.005334306042641401\n",
      "Loss on test= 0.005571544636040926\n",
      "acc for Lsat= 0.13787592903989004 \n",
      "acc for Psat= 0.16237389927523005 \n",
      "acc for optim= 0.11928619840182364\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.00526798702776432\n",
      "Loss on test= 0.005405638366937637\n",
      "acc for Lsat= 0.10216913180920528 \n",
      "acc for Psat= 0.21454241395824486 \n",
      "acc for optim= 0.10276062021795143\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.005206957925111055\n",
      "Loss on test= 0.0055819423869252205\n",
      "acc for Lsat= 0.1324612401270618 \n",
      "acc for Psat= 0.1672978895302448 \n",
      "acc for optim= 0.10301095961282651\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.005347102880477905\n",
      "Loss on test= 0.00547544751316309\n",
      "acc for Lsat= 0.1166692489059642 \n",
      "acc for Psat= 0.12817383799443227 \n",
      "acc for optim= 0.09080800289909045\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.005315952468663454\n",
      "Loss on test= 0.00545794190838933\n",
      "acc for Lsat= 0.14356540722979438 \n",
      "acc for Psat= 0.1957266198264228 \n",
      "acc for optim= 0.09605627780547366\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.005327129270881414\n",
      "Loss on test= 0.005349421873688698\n",
      "acc for Lsat= 0.10817477303660578 \n",
      "acc for Psat= 0.2176731467867891 \n",
      "acc for optim= 0.11799670270799349\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.005240653641521931\n",
      "Loss on test= 0.005332367494702339\n",
      "acc for Lsat= 0.15670299819774097 \n",
      "acc for Psat= 0.16331279875400165 \n",
      "acc for optim= 0.09210108199881183\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.005351046100258827\n",
      "Loss on test= 0.005639535374939442\n",
      "acc for Lsat= 0.12855759067719597 \n",
      "acc for Psat= 0.17314893317719302 \n",
      "acc for optim= 0.11369238028095828\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.005221449304372072\n",
      "Loss on test= 0.005438324064016342\n",
      "acc for Lsat= 0.09952402497745222 \n",
      "acc for Psat= 0.1340988894096679 \n",
      "acc for optim= 0.1157660674976392\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.0053577427752316\n",
      "Loss on test= 0.005491900257766247\n",
      "acc for Lsat= 0.11696157894200748 \n",
      "acc for Psat= 0.13538185807151926 \n",
      "acc for optim= 0.14705574528003731\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.005218368489295244\n",
      "Loss on test= 0.005709207151085138\n",
      "acc for Lsat= 0.12016131516752972 \n",
      "acc for Psat= 0.14035819114198805 \n",
      "acc for optim= 0.11849226435232493\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.005241963546723127\n",
      "Loss on test= 0.005361797288060188\n",
      "acc for Lsat= 0.15131478880842528 \n",
      "acc for Psat= 0.16078478749841452 \n",
      "acc for optim= 0.10083544892000242\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.005226174369454384\n",
      "Loss on test= 0.0054236967116594315\n",
      "acc for Lsat= 0.12222402576460606 \n",
      "acc for Psat= 0.1119014138304111 \n",
      "acc for optim= 0.11594476964738634\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.005251750815659761\n",
      "Loss on test= 0.005152171477675438\n",
      "acc for Lsat= 0.12945087005694708 \n",
      "acc for Psat= 0.1318167976440034 \n",
      "acc for optim= 0.09620308405202296\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.005245984066277742\n",
      "Loss on test= 0.005571588408201933\n",
      "acc for Lsat= 0.12356007968386014 \n",
      "acc for Psat= 0.15923428199150497 \n",
      "acc for optim= 0.11143254509402646\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.005226849112659693\n",
      "Loss on test= 0.0053961873054504395\n",
      "acc for Lsat= 0.11187797532572101 \n",
      "acc for Psat= 0.18792551341984007 \n",
      "acc for optim= 0.1240609808171737\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.005530800670385361\n",
      "Loss on test= 0.005534991156309843\n",
      "acc for Lsat= 0.11563914793077856 \n",
      "acc for Psat= 0.20470494471697342 \n",
      "acc for optim= 0.11509454167551464\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.0052341572009027\n",
      "Loss on test= 0.005348599050194025\n",
      "acc for Lsat= 0.12581080850213766 \n",
      "acc for Psat= 0.18940310645848513 \n",
      "acc for optim= 0.10723711296709047\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.005188960116356611\n",
      "Loss on test= 0.005366183817386627\n",
      "acc for Lsat= 0.12178607150498363 \n",
      "acc for Psat= 0.1402528738706476 \n",
      "acc for optim= 0.1085229886488782\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.005292769055813551\n",
      "Loss on test= 0.005235868040472269\n",
      "acc for Lsat= 0.13890221083743703 \n",
      "acc for Psat= 0.17356962229435643 \n",
      "acc for optim= 0.11531567661505607\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.005266076885163784\n",
      "Loss on test= 0.0052480269223451614\n",
      "acc for Lsat= 0.10494434316125181 \n",
      "acc for Psat= 0.0782472572949094 \n",
      "acc for optim= 0.08144113677553833\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.005334305111318827\n",
      "Loss on test= 0.005228700581938028\n",
      "acc for Lsat= 0.12724058330059052 \n",
      "acc for Psat= 0.14405285644655427 \n",
      "acc for optim= 0.10953512705034679\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.005120404530316591\n",
      "Loss on test= 0.005436224862933159\n",
      "acc for Lsat= 0.12579845135203666 \n",
      "acc for Psat= 0.19362702903648218 \n",
      "acc for optim= 0.12215199342204465\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.005207579117268324\n",
      "Loss on test= 0.00545056676492095\n",
      "acc for Lsat= 0.10559993863312735 \n",
      "acc for Psat= 0.11240880875589533 \n",
      "acc for optim= 0.09941879432234499\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.005144360475242138\n",
      "Loss on test= 0.005451719276607037\n",
      "acc for Lsat= 0.09035690066715081 \n",
      "acc for Psat= 0.16555512603372335 \n",
      "acc for optim= 0.10340559860277507\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.005095514468848705\n",
      "Loss on test= 0.0055167884565889835\n",
      "acc for Lsat= 0.1104108679573983 \n",
      "acc for Psat= 0.14200061238888237 \n",
      "acc for optim= 0.12456953194406298\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.005205226130783558\n",
      "Loss on test= 0.00529163982719183\n",
      "acc for Lsat= 0.12772857087353864 \n",
      "acc for Psat= 0.10479715839028358 \n",
      "acc for optim= 0.11295550563631372\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.005131642334163189\n",
      "Loss on test= 0.005405663046985865\n",
      "acc for Lsat= 0.12689355315847528 \n",
      "acc for Psat= 0.16037372479008305 \n",
      "acc for optim= 0.09384684663058983\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.005170573014765978\n",
      "Loss on test= 0.005449336487799883\n",
      "acc for Lsat= 0.09614962208757384 \n",
      "acc for Psat= 0.17307311896648672 \n",
      "acc for optim= 0.10725712517483367\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.005074342247098684\n",
      "Loss on test= 0.005347517319023609\n",
      "acc for Lsat= 0.09621391569574674 \n",
      "acc for Psat= 0.13839859437818328 \n",
      "acc for optim= 0.09242555491315822\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.005115358158946037\n",
      "Loss on test= 0.005430202465504408\n",
      "acc for Lsat= 0.11214006495558554 \n",
      "acc for Psat= 0.171493753635635 \n",
      "acc for optim= 0.10647246536488335\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.005118468310683966\n",
      "Loss on test= 0.00540968170389533\n",
      "acc for Lsat= 0.08407518353002767 \n",
      "acc for Psat= 0.14550533414714867 \n",
      "acc for optim= 0.08822021191008389\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.0050796582363545895\n",
      "Loss on test= 0.00567219965159893\n",
      "acc for Lsat= 0.11639365963613575 \n",
      "acc for Psat= 0.1073542781588104 \n",
      "acc for optim= 0.11143525524271859\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.00525700906291604\n",
      "Loss on test= 0.00503111444413662\n",
      "acc for Lsat= 0.1245758884275953 \n",
      "acc for Psat= 0.11846833779580063 \n",
      "acc for optim= 0.08505114729309247\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.005311245564371347\n",
      "Loss on test= 0.005582045763731003\n",
      "acc for Lsat= 0.15093039845426878 \n",
      "acc for Psat= 0.13895535670841733 \n",
      "acc for optim= 0.12997427872485584\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.00515895476564765\n",
      "Loss on test= 0.005392152350395918\n",
      "acc for Lsat= 0.14672852638694975 \n",
      "acc for Psat= 0.19048929835359255 \n",
      "acc for optim= 0.09721915692918831\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.005083999130874872\n",
      "Loss on test= 0.005291994195431471\n",
      "acc for Lsat= 0.1036273951952656 \n",
      "acc for Psat= 0.16659573402204034 \n",
      "acc for optim= 0.11004543522398712\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.005197278223931789\n",
      "Loss on test= 0.005305703729391098\n",
      "acc for Lsat= 0.07547560572210285 \n",
      "acc for Psat= 0.13634471776377824 \n",
      "acc for optim= 0.10598948257069828\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.0052559878677129745\n",
      "Loss on test= 0.005205875262618065\n",
      "acc for Lsat= 0.09583197275383605 \n",
      "acc for Psat= 0.15224554570805696 \n",
      "acc for optim= 0.10987711697816849\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.005170270800590515\n",
      "Loss on test= 0.005271287634968758\n",
      "acc for Lsat= 0.12420515845426255 \n",
      "acc for Psat= 0.1677288654156857 \n",
      "acc for optim= 0.10316062500027733\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.005100283771753311\n",
      "Loss on test= 0.005227996036410332\n",
      "acc for Lsat= 0.12319069544577764 \n",
      "acc for Psat= 0.14177347859367728 \n",
      "acc for optim= 0.09709129575639963\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.005003224592655897\n",
      "Loss on test= 0.005477421917021275\n",
      "acc for Lsat= 0.12436353785263539 \n",
      "acc for Psat= 0.17332609515223238 \n",
      "acc for optim= 0.12545453720829552\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.00508100725710392\n",
      "Loss on test= 0.005108920857310295\n",
      "acc for Lsat= 0.10798263760645771 \n",
      "acc for Psat= 0.17004447476938367 \n",
      "acc for optim= 0.08925473194621089\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.005008337553590536\n",
      "Loss on test= 0.00566046591848135\n",
      "acc for Lsat= 0.11082254487296773 \n",
      "acc for Psat= 0.20934691435347 \n",
      "acc for optim= 0.1044271058247735\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.005121133755892515\n",
      "Loss on test= 0.005117990542203188\n",
      "acc for Lsat= 0.1545658042240474 \n",
      "acc for Psat= 0.13910255586314532 \n",
      "acc for optim= 0.0886992192051063\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.005152131896466017\n",
      "Loss on test= 0.005323649384081364\n",
      "acc for Lsat= 0.14114090060401294 \n",
      "acc for Psat= 0.16129561212276006 \n",
      "acc for optim= 0.11750017630401999\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.005177403334528208\n",
      "Loss on test= 0.005147601943463087\n",
      "acc for Lsat= 0.1553663674535023 \n",
      "acc for Psat= 0.18679227884341446 \n",
      "acc for optim= 0.11178712169122365\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.005013672634959221\n",
      "Loss on test= 0.005115141160786152\n",
      "acc for Lsat= 0.1128801261947956 \n",
      "acc for Psat= 0.1338825623711778 \n",
      "acc for optim= 0.0965032982122567\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.005051599815487862\n",
      "Loss on test= 0.0050294846296310425\n",
      "acc for Lsat= 0.12483742672743069 \n",
      "acc for Psat= 0.14426099688151023 \n",
      "acc for optim= 0.08391430170740932\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.0050573693588376045\n",
      "Loss on test= 0.005452875047922134\n",
      "acc for Lsat= 0.1077122476676272 \n",
      "acc for Psat= 0.1342495399456109 \n",
      "acc for optim= 0.09615895380031564\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.005137666594237089\n",
      "Loss on test= 0.005261231679469347\n",
      "acc for Lsat= 0.11100797727704048 \n",
      "acc for Psat= 0.17734936055623823 \n",
      "acc for optim= 0.10183042835301927\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.005203820765018463\n",
      "Loss on test= 0.0053475298918783665\n",
      "acc for Lsat= 0.11798523653609057 \n",
      "acc for Psat= 0.19526365554581085 \n",
      "acc for optim= 0.10577697431047757\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.005053068045526743\n",
      "Loss on test= 0.005454251542687416\n",
      "acc for Lsat= 0.11943221614799565 \n",
      "acc for Psat= 0.14156796030389765 \n",
      "acc for optim= 0.1194306622362799\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.004851046483963728\n",
      "Loss on test= 0.00513329915702343\n",
      "acc for Lsat= 0.12909132945868704 \n",
      "acc for Psat= 0.18702169073124728 \n",
      "acc for optim= 0.11272612480388489\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.005021422635763884\n",
      "Loss on test= 0.005305162630975246\n",
      "acc for Lsat= 0.11097480809419519 \n",
      "acc for Psat= 0.13713508337322208 \n",
      "acc for optim= 0.0821303400690441\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.004952933173626661\n",
      "Loss on test= 0.005447248462587595\n",
      "acc for Lsat= 0.08573761722072959 \n",
      "acc for Psat= 0.1602592322871917 \n",
      "acc for optim= 0.08987517724744976\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.004885101690888405\n",
      "Loss on test= 0.005623108707368374\n",
      "acc for Lsat= 0.13744413164547747 \n",
      "acc for Psat= 0.1651695522790154 \n",
      "acc for optim= 0.1318872635666695\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.005056345369666815\n",
      "Loss on test= 0.005113523453474045\n",
      "acc for Lsat= 0.11536369580102877 \n",
      "acc for Psat= 0.1411513079914989 \n",
      "acc for optim= 0.10680295492056757\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.00497795082628727\n",
      "Loss on test= 0.005169295240193605\n",
      "acc for Lsat= 0.12965116918914849 \n",
      "acc for Psat= 0.1729691126642542 \n",
      "acc for optim= 0.1116267916901658\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.004957443103194237\n",
      "Loss on test= 0.0051382784731686115\n",
      "acc for Lsat= 0.11750534532539961 \n",
      "acc for Psat= 0.1681556437526726 \n",
      "acc for optim= 0.11348260794248846\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.005154149141162634\n",
      "Loss on test= 0.005171331111341715\n",
      "acc for Lsat= 0.1536312708631158 \n",
      "acc for Psat= 0.266859113652673 \n",
      "acc for optim= 0.12666492722928524\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.004974867682904005\n",
      "Loss on test= 0.00480478722602129\n",
      "acc for Lsat= 0.13094091175783737 \n",
      "acc for Psat= 0.15692493029766613 \n",
      "acc for optim= 0.09326569521282282\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.005080087576061487\n",
      "Loss on test= 0.0053741540759801865\n",
      "acc for Lsat= 0.14731521143888435 \n",
      "acc for Psat= 0.23858757296370137 \n",
      "acc for optim= 0.09701656631659716\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.005161670967936516\n",
      "Loss on test= 0.005367730278521776\n",
      "acc for Lsat= 0.11301260388508025 \n",
      "acc for Psat= 0.15105637250882056 \n",
      "acc for optim= 0.09123677786232696\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.005124513525515795\n",
      "Loss on test= 0.005404566414654255\n",
      "acc for Lsat= 0.13621811051658975 \n",
      "acc for Psat= 0.16292424593120813 \n",
      "acc for optim= 0.09774340575353967\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.004984332248568535\n",
      "Loss on test= 0.0053825294598937035\n",
      "acc for Lsat= 0.12264665505952305 \n",
      "acc for Psat= 0.14698257038576734 \n",
      "acc for optim= 0.1161678336146805\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.004773691762238741\n",
      "Loss on test= 0.004802271723747253\n",
      "acc for Lsat= 0.08436865155171189 \n",
      "acc for Psat= 0.15432066615256998 \n",
      "acc for optim= 0.11975098319170582\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.005029128864407539\n",
      "Loss on test= 0.0051710838451981544\n",
      "acc for Lsat= 0.09264417479021682 \n",
      "acc for Psat= 0.13978680903609428 \n",
      "acc for optim= 0.13622759365373188\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.005143758375197649\n",
      "Loss on test= 0.005161600653082132\n",
      "acc for Lsat= 0.13106775138941076 \n",
      "acc for Psat= 0.17835442035640073 \n",
      "acc for optim= 0.10455703031685618\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.0050071547739207745\n",
      "Loss on test= 0.0052271876484155655\n",
      "acc for Lsat= 0.11501545686688688 \n",
      "acc for Psat= 0.15301451595344892 \n",
      "acc for optim= 0.09313133635765149\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.004890846088528633\n",
      "Loss on test= 0.0052100359462201595\n",
      "acc for Lsat= 0.1098755404042701 \n",
      "acc for Psat= 0.15965573375837672 \n",
      "acc for optim= 0.10589466978692347\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.004927649628371\n",
      "Loss on test= 0.005010528489947319\n",
      "acc for Lsat= 0.15544080700621837 \n",
      "acc for Psat= 0.15493903539350462 \n",
      "acc for optim= 0.11507243073234956\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.004865091294050217\n",
      "Loss on test= 0.005355527624487877\n",
      "acc for Lsat= 0.11651758083866702 \n",
      "acc for Psat= 0.16635057979470325 \n",
      "acc for optim= 0.10966686508618295\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.0049940743483603\n",
      "Loss on test= 0.005458394531160593\n",
      "acc for Lsat= 0.12010005328597294 \n",
      "acc for Psat= 0.12863440666761664 \n",
      "acc for optim= 0.09358856749410431\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.005013419780880213\n",
      "Loss on test= 0.005619540810585022\n",
      "acc for Lsat= 0.1676409134844208 \n",
      "acc for Psat= 0.1462744211183033 \n",
      "acc for optim= 0.09990587117823048\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.0051294295117259026\n",
      "Loss on test= 0.005345876328647137\n",
      "acc for Lsat= 0.12413887366549009 \n",
      "acc for Psat= 0.12554887665383932 \n",
      "acc for optim= 0.10148305425213443\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.004907475784420967\n",
      "Loss on test= 0.005189872346818447\n",
      "acc for Lsat= 0.12370690426582263 \n",
      "acc for Psat= 0.1596892236524986 \n",
      "acc for optim= 0.10480030021992409\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.004880200140178204\n",
      "Loss on test= 0.005324238445609808\n",
      "acc for Lsat= 0.12268187209135956 \n",
      "acc for Psat= 0.2339994739741087 \n",
      "acc for optim= 0.10897965392925674\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.004889901261776686\n",
      "Loss on test= 0.005337337031960487\n",
      "acc for Lsat= 0.13914062848521602 \n",
      "acc for Psat= 0.13385289762583044 \n",
      "acc for optim= 0.11126755756009112\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.00484418123960495\n",
      "Loss on test= 0.005269668065011501\n",
      "acc for Lsat= 0.11083266920953368 \n",
      "acc for Psat= 0.18546097787717977 \n",
      "acc for optim= 0.12723392118803328\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.004984689876437187\n",
      "Loss on test= 0.0053607202135026455\n",
      "acc for Lsat= 0.10316293694389363 \n",
      "acc for Psat= 0.10621387094983624 \n",
      "acc for optim= 0.10173346992168161\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.005010173190385103\n",
      "Loss on test= 0.0054814014583826065\n",
      "acc for Lsat= 0.11946915682508713 \n",
      "acc for Psat= 0.18678918995687532 \n",
      "acc for optim= 0.11951235795034638\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.0051076640374958515\n",
      "Loss on test= 0.005072318948805332\n",
      "acc for Lsat= 0.11122355901170522 \n",
      "acc for Psat= 0.13584675826132298 \n",
      "acc for optim= 0.10366074081199865\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.005144832655787468\n",
      "Loss on test= 0.005140798166394234\n",
      "acc for Lsat= 0.14573551126522943 \n",
      "acc for Psat= 0.17496962969501814 \n",
      "acc for optim= 0.11312923378621538\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.004945345688611269\n",
      "Loss on test= 0.00517268106341362\n",
      "acc for Lsat= 0.10330457775853574 \n",
      "acc for Psat= 0.13032067148014903 \n",
      "acc for optim= 0.11190279159280989\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.004917884711176157\n",
      "Loss on test= 0.005182294640690088\n",
      "acc for Lsat= 0.11826180863297647 \n",
      "acc for Psat= 0.14235805740625235 \n",
      "acc for optim= 0.10232263110164139\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.0049943034537136555\n",
      "Loss on test= 0.005101323593407869\n",
      "acc for Lsat= 0.09559354429236716 \n",
      "acc for Psat= 0.13492990016109413 \n",
      "acc for optim= 0.08440944379092091\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.004932853858917952\n",
      "Loss on test= 0.005176937207579613\n",
      "acc for Lsat= 0.13007460493180487 \n",
      "acc for Psat= 0.16993427762968671 \n",
      "acc for optim= 0.09776626508553615\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.004874976817518473\n",
      "Loss on test= 0.005285227671265602\n",
      "acc for Lsat= 0.07837499165907502 \n",
      "acc for Psat= 0.13462079466424054 \n",
      "acc for optim= 0.11630650475207302\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.004904686938971281\n",
      "Loss on test= 0.005369950085878372\n",
      "acc for Lsat= 0.1109559125163489 \n",
      "acc for Psat= 0.17185148687955612 \n",
      "acc for optim= 0.10831246149933173\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.004980070050805807\n",
      "Loss on test= 0.005203769076615572\n",
      "acc for Lsat= 0.11666519756221937 \n",
      "acc for Psat= 0.11103067937720981 \n",
      "acc for optim= 0.1167122371132589\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.004990152548998594\n",
      "Loss on test= 0.0053862459026277065\n",
      "acc for Lsat= 0.12267753487038943 \n",
      "acc for Psat= 0.12369331914103693 \n",
      "acc for optim= 0.11279492199213968\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.004869580268859863\n",
      "Loss on test= 0.005276658106595278\n",
      "acc for Lsat= 0.1466984544854818 \n",
      "acc for Psat= 0.1619911953392956 \n",
      "acc for optim= 0.0820868924816346\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.004923945292830467\n",
      "Loss on test= 0.005123605486005545\n",
      "acc for Lsat= 0.16322316943357387 \n",
      "acc for Psat= 0.2080720590117077 \n",
      "acc for optim= 0.08760039129992947\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.005051996558904648\n",
      "Loss on test= 0.005342839751392603\n",
      "acc for Lsat= 0.0999984794891336 \n",
      "acc for Psat= 0.1825310266059306 \n",
      "acc for optim= 0.11623970170815785\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.004855888895690441\n",
      "Loss on test= 0.0051748561672866344\n",
      "acc for Lsat= 0.1698914154743155 \n",
      "acc for Psat= 0.14599280442214674 \n",
      "acc for optim= 0.08508287266077888\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.004787275567650795\n",
      "Loss on test= 0.004975549876689911\n",
      "acc for Lsat= 0.11441862986733516 \n",
      "acc for Psat= 0.1380170895879726 \n",
      "acc for optim= 0.11298790755164292\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.0048926942981779575\n",
      "Loss on test= 0.005177358631044626\n",
      "acc for Lsat= 0.12062218164404233 \n",
      "acc for Psat= 0.17610605037124413 \n",
      "acc for optim= 0.1007076844826871\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.004917732905596495\n",
      "Loss on test= 0.005339962430298328\n",
      "acc for Lsat= 0.12333717931889826 \n",
      "acc for Psat= 0.17318886844441295 \n",
      "acc for optim= 0.09376185439113113\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.004929442424327135\n",
      "Loss on test= 0.005084694363176823\n",
      "acc for Lsat= 0.11944977605404954 \n",
      "acc for Psat= 0.12220670407017072 \n",
      "acc for optim= 0.10684224541829382\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.004868645686656237\n",
      "Loss on test= 0.00527404947206378\n",
      "acc for Lsat= 0.13487706972389585 \n",
      "acc for Psat= 0.18121703235535985 \n",
      "acc for optim= 0.118247930581371\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.004814848769456148\n",
      "Loss on test= 0.00519140250980854\n",
      "acc for Lsat= 0.11483874032273889 \n",
      "acc for Psat= 0.14446089062322345 \n",
      "acc for optim= 0.12122992121536906\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.004833857994526625\n",
      "Loss on test= 0.005233041942119598\n",
      "acc for Lsat= 0.14061933124644888 \n",
      "acc for Psat= 0.15745720970961782 \n",
      "acc for optim= 0.12025900236848328\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.004853201098740101\n",
      "Loss on test= 0.0053550247102975845\n",
      "acc for Lsat= 0.15196573237578073 \n",
      "acc for Psat= 0.14564697651399505 \n",
      "acc for optim= 0.12180212802357143\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.00470335129648447\n",
      "Loss on test= 0.004970732145011425\n",
      "acc for Lsat= 0.11875466904085544 \n",
      "acc for Psat= 0.1216332116164267 \n",
      "acc for optim= 0.11818876277862324\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.0048724072985351086\n",
      "Loss on test= 0.005501945037394762\n",
      "acc for Lsat= 0.12495063317732678 \n",
      "acc for Psat= 0.13386305649247435 \n",
      "acc for optim= 0.09273098632628615\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.004825043026357889\n",
      "Loss on test= 0.005368790589272976\n",
      "acc for Lsat= 0.10208729991993298 \n",
      "acc for Psat= 0.10555406758147809 \n",
      "acc for optim= 0.11683628074307409\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.004860482178628445\n",
      "Loss on test= 0.005191930569708347\n",
      "acc for Lsat= 0.1481651487863726 \n",
      "acc for Psat= 0.14355930691171023 \n",
      "acc for optim= 0.10385353109126703\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.004851684905588627\n",
      "Loss on test= 0.005439092870801687\n",
      "acc for Lsat= 0.16471559712145892 \n",
      "acc for Psat= 0.11754042779405911 \n",
      "acc for optim= 0.09180024301167578\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.00473698228597641\n",
      "Loss on test= 0.005476141348481178\n",
      "acc for Lsat= 0.1233401055344277 \n",
      "acc for Psat= 0.18707305167077315 \n",
      "acc for optim= 0.08773035103351706\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.004810001235455275\n",
      "Loss on test= 0.004812731873244047\n",
      "acc for Lsat= 0.12096629478037357 \n",
      "acc for Psat= 0.19013631378523618 \n",
      "acc for optim= 0.12312028789892793\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.0047943140380084515\n",
      "Loss on test= 0.005028681363910437\n",
      "acc for Lsat= 0.0911596179810456 \n",
      "acc for Psat= 0.16004519164562225 \n",
      "acc for optim= 0.10972765771051247\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.0047992835752666\n",
      "Loss on test= 0.0053260172717273235\n",
      "acc for Lsat= 0.11462429874680108 \n",
      "acc for Psat= 0.20648290185878673 \n",
      "acc for optim= 0.09908953776013935\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.004861621651798487\n",
      "Loss on test= 0.005088215693831444\n",
      "acc for Lsat= 0.11738017480820417 \n",
      "acc for Psat= 0.1523848066313399 \n",
      "acc for optim= 0.1052749751187447\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.004802742041647434\n",
      "Loss on test= 0.005128620192408562\n",
      "acc for Lsat= 0.1586602138251894 \n",
      "acc for Psat= 0.10250327992253006 \n",
      "acc for optim= 0.11189704353455454\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.0047094328328967094\n",
      "Loss on test= 0.00520327826961875\n",
      "acc for Lsat= 0.10481449979771343 \n",
      "acc for Psat= 0.10995743387482232 \n",
      "acc for optim= 0.11933478071457809\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.004902792163193226\n",
      "Loss on test= 0.0050142970867455006\n",
      "acc for Lsat= 0.13020290537355728 \n",
      "acc for Psat= 0.12946499001959133 \n",
      "acc for optim= 0.09654727192699081\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.004815395921468735\n",
      "Loss on test= 0.005513220559805632\n",
      "acc for Lsat= 0.12083441422631343 \n",
      "acc for Psat= 0.15834576729685068 \n",
      "acc for optim= 0.11946398826936881\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.004741545766592026\n",
      "Loss on test= 0.005589577369391918\n",
      "acc for Lsat= 0.11877487423933214 \n",
      "acc for Psat= 0.19943882731927765 \n",
      "acc for optim= 0.09485665748878899\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.004954559728503227\n",
      "Loss on test= 0.005513245239853859\n",
      "acc for Lsat= 0.14462093150682953 \n",
      "acc for Psat= 0.1408594397879723 \n",
      "acc for optim= 0.09083669216165112\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.004849461372941732\n",
      "Loss on test= 0.005518611986190081\n",
      "acc for Lsat= 0.1295033003617492 \n",
      "acc for Psat= 0.1291810477143574 \n",
      "acc for optim= 0.09440827480931249\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.004728046245872974\n",
      "Loss on test= 0.005203248467296362\n",
      "acc for Lsat= 0.14544091082643718 \n",
      "acc for Psat= 0.16642995547348013 \n",
      "acc for optim= 0.12814146150938338\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.004782075993716717\n",
      "Loss on test= 0.005279602948576212\n",
      "acc for Lsat= 0.11955704600808935 \n",
      "acc for Psat= 0.1356605506605572 \n",
      "acc for optim= 0.08197835174440923\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.004859971813857555\n",
      "Loss on test= 0.005423947237432003\n",
      "acc for Lsat= 0.12233933889203602 \n",
      "acc for Psat= 0.1781372662840618 \n",
      "acc for optim= 0.105650936305109\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.004759862553328276\n",
      "Loss on test= 0.005250612273812294\n",
      "acc for Lsat= 0.13742230460047722 \n",
      "acc for Psat= 0.18395192646938893 \n",
      "acc for optim= 0.0973547722484606\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.004717077594250441\n",
      "Loss on test= 0.005345355719327927\n",
      "acc for Lsat= 0.11490081858614253 \n",
      "acc for Psat= 0.15590335035489666 \n",
      "acc for optim= 0.10181861216875\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.004615336656570435\n",
      "Loss on test= 0.00533183803781867\n",
      "acc for Lsat= 0.11785712217291196 \n",
      "acc for Psat= 0.12664967614950406 \n",
      "acc for optim= 0.11891657652126418\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.004842114169150591\n",
      "Loss on test= 0.0053732553496956825\n",
      "acc for Lsat= 0.14456621071116793 \n",
      "acc for Psat= 0.15362723242206913 \n",
      "acc for optim= 0.09261273182669862\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.004767990205436945\n",
      "Loss on test= 0.005575595423579216\n",
      "acc for Lsat= 0.13252722684087026 \n",
      "acc for Psat= 0.1542396131489012 \n",
      "acc for optim= 0.10087521102589865\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.004697347059845924\n",
      "Loss on test= 0.004852595739066601\n",
      "acc for Lsat= 0.1217715469150183 \n",
      "acc for Psat= 0.14201258133269018 \n",
      "acc for optim= 0.1082865454049574\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.00484653003513813\n",
      "Loss on test= 0.0055177719332277775\n",
      "acc for Lsat= 0.129212219785485 \n",
      "acc for Psat= 0.1677242366390096 \n",
      "acc for optim= 0.12262776155128247\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.004684563260525465\n",
      "Loss on test= 0.005206632427871227\n",
      "acc for Lsat= 0.11699950808866157 \n",
      "acc for Psat= 0.18356710566311246 \n",
      "acc for optim= 0.11314966462345587\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.004873399157077074\n",
      "Loss on test= 0.00521835358813405\n",
      "acc for Lsat= 0.11309587593293852 \n",
      "acc for Psat= 0.15784773820390305 \n",
      "acc for optim= 0.10983693692833185\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.004846310708671808\n",
      "Loss on test= 0.0051648435182869434\n",
      "acc for Lsat= 0.13289736627808046 \n",
      "acc for Psat= 0.17535089711762136 \n",
      "acc for optim= 0.11040499770186013\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.0047915312461555\n",
      "Loss on test= 0.0050669219344854355\n",
      "acc for Lsat= 0.13346671631249288 \n",
      "acc for Psat= 0.15075118246022612 \n",
      "acc for optim= 0.11191671062260866\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.004719582851976156\n",
      "Loss on test= 0.0053581069223582745\n",
      "acc for Lsat= 0.11934684532591039 \n",
      "acc for Psat= 0.11759483172661728 \n",
      "acc for optim= 0.12046975921839476\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.004930015653371811\n",
      "Loss on test= 0.0050961608067154884\n",
      "acc for Lsat= 0.13711045821966966 \n",
      "acc for Psat= 0.16688724317484432 \n",
      "acc for optim= 0.09325392862794818\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.004683233331888914\n",
      "Loss on test= 0.0050589824095368385\n",
      "acc for Lsat= 0.14434219860575265 \n",
      "acc for Psat= 0.14453185034087962 \n",
      "acc for optim= 0.11317295995023516\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.004643305670469999\n",
      "Loss on test= 0.005065955221652985\n",
      "acc for Lsat= 0.1202474749562599 \n",
      "acc for Psat= 0.15422470671021277 \n",
      "acc for optim= 0.10734847664005226\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.004572177305817604\n",
      "Loss on test= 0.0051750484853982925\n",
      "acc for Lsat= 0.13316597577391398 \n",
      "acc for Psat= 0.11891187633025563 \n",
      "acc for optim= 0.12775310594588518\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.004613181576132774\n",
      "Loss on test= 0.005008898209780455\n",
      "acc for Lsat= 0.09101448231376708 \n",
      "acc for Psat= 0.19100970464448133 \n",
      "acc for optim= 0.10202264273539186\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.004684917163103819\n",
      "Loss on test= 0.0050703235901892185\n",
      "acc for Lsat= 0.07771060168710796 \n",
      "acc for Psat= 0.12723304284736514 \n",
      "acc for optim= 0.10551772022154182\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.004786266945302486\n",
      "Loss on test= 0.00497791962698102\n",
      "acc for Lsat= 0.10081007797271013 \n",
      "acc for Psat= 0.13053510648508868 \n",
      "acc for optim= 0.09551133727654815\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.004746643360704184\n",
      "Loss on test= 0.004939660429954529\n",
      "acc for Lsat= 0.11759664880163553 \n",
      "acc for Psat= 0.15442497832959312 \n",
      "acc for optim= 0.10722759873331394\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.004668887238949537\n",
      "Loss on test= 0.005390415899455547\n",
      "acc for Lsat= 0.14884181801850596 \n",
      "acc for Psat= 0.19366212111587325 \n",
      "acc for optim= 0.112245551802011\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.004678139463067055\n",
      "Loss on test= 0.005394058767706156\n",
      "acc for Lsat= 0.09328046272922721 \n",
      "acc for Psat= 0.10960810310724708 \n",
      "acc for optim= 0.09601496651561724\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.00468294695019722\n",
      "Loss on test= 0.0049957698211073875\n",
      "acc for Lsat= 0.10050859650234795 \n",
      "acc for Psat= 0.1398064006611498 \n",
      "acc for optim= 0.12016764394421545\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.00455471733585\n",
      "Loss on test= 0.005117347463965416\n",
      "acc for Lsat= 0.12968625449058083 \n",
      "acc for Psat= 0.1447534844175809 \n",
      "acc for optim= 0.07071640235113187\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.0047244299203157425\n",
      "Loss on test= 0.005279430653899908\n",
      "acc for Lsat= 0.09554431841307734 \n",
      "acc for Psat= 0.12473246656979124 \n",
      "acc for optim= 0.0930190279872881\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.004864606074988842\n",
      "Loss on test= 0.004986949265003204\n",
      "acc for Lsat= 0.12990892512930763 \n",
      "acc for Psat= 0.13981629221881223 \n",
      "acc for optim= 0.09407588899315063\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.00471700681373477\n",
      "Loss on test= 0.004941204562783241\n",
      "acc for Lsat= 0.1043030373338196 \n",
      "acc for Psat= 0.13251766986731026 \n",
      "acc for optim= 0.0869505658111949\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.004743048921227455\n",
      "Loss on test= 0.005179135128855705\n",
      "acc for Lsat= 0.15020984100798765 \n",
      "acc for Psat= 0.12635349239119226 \n",
      "acc for optim= 0.10699229190746944\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.004723250400274992\n",
      "Loss on test= 0.005192366428673267\n",
      "acc for Lsat= 0.10929214606747134 \n",
      "acc for Psat= 0.12244791659112605 \n",
      "acc for optim= 0.11280443498657809\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.004583440255373716\n",
      "Loss on test= 0.005705821793526411\n",
      "acc for Lsat= 0.09657100489776996 \n",
      "acc for Psat= 0.14936392252436942 \n",
      "acc for optim= 0.10742975792123212\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.004741148091852665\n",
      "Loss on test= 0.005198673810809851\n",
      "acc for Lsat= 0.12002865271642804 \n",
      "acc for Psat= 0.14524192839033073 \n",
      "acc for optim= 0.11299685463826689\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.004718332085758448\n",
      "Loss on test= 0.005343741271644831\n",
      "acc for Lsat= 0.10584515963758652 \n",
      "acc for Psat= 0.1597234349594348 \n",
      "acc for optim= 0.10884066224874307\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.004602700937539339\n",
      "Loss on test= 0.005474759265780449\n",
      "acc for Lsat= 0.15523888325939575 \n",
      "acc for Psat= 0.1671165217541986 \n",
      "acc for optim= 0.10629489826452401\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.004773161839693785\n",
      "Loss on test= 0.005120462272316217\n",
      "acc for Lsat= 0.10064657441236907 \n",
      "acc for Psat= 0.10852105973107326 \n",
      "acc for optim= 0.10172532299636966\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.004711809102445841\n",
      "Loss on test= 0.005224158056080341\n",
      "acc for Lsat= 0.13580927501122156 \n",
      "acc for Psat= 0.1895160044853886 \n",
      "acc for optim= 0.12363437731336388\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.0044823032803833485\n",
      "Loss on test= 0.005047406069934368\n",
      "acc for Lsat= 0.10517917718324396 \n",
      "acc for Psat= 0.127878292112857 \n",
      "acc for optim= 0.11717576388683584\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.004806938115507364\n",
      "Loss on test= 0.0051873065531253815\n",
      "acc for Lsat= 0.11809194325986835 \n",
      "acc for Psat= 0.17718147305357787 \n",
      "acc for optim= 0.1077977122477023\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.0044874707236886024\n",
      "Loss on test= 0.005447957199066877\n",
      "acc for Lsat= 0.11905040379820599 \n",
      "acc for Psat= 0.12881378453069678 \n",
      "acc for optim= 0.11000816935362916\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.004607632756233215\n",
      "Loss on test= 0.005013412330299616\n",
      "acc for Lsat= 0.1271485213138577 \n",
      "acc for Psat= 0.13622739657552707 \n",
      "acc for optim= 0.1006659568584938\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.004547715187072754\n",
      "Loss on test= 0.005216915626078844\n",
      "acc for Lsat= 0.10609774506236944 \n",
      "acc for Psat= 0.11020408922599421 \n",
      "acc for optim= 0.11010513977251118\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.004401720594614744\n",
      "Loss on test= 0.005556077230721712\n",
      "acc for Lsat= 0.08366165206664139 \n",
      "acc for Psat= 0.1434904895334815 \n",
      "acc for optim= 0.1127142073172662\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.004714665934443474\n",
      "Loss on test= 0.005463471636176109\n",
      "acc for Lsat= 0.1259628820634033 \n",
      "acc for Psat= 0.1438742301478568 \n",
      "acc for optim= 0.11307827949834366\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.004601617809385061\n",
      "Loss on test= 0.005128410179167986\n",
      "acc for Lsat= 0.08739862880773014 \n",
      "acc for Psat= 0.20112612412776798 \n",
      "acc for optim= 0.11904886937958913\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.004722421523183584\n",
      "Loss on test= 0.005086510442197323\n",
      "acc for Lsat= 0.1575390589940879 \n",
      "acc for Psat= 0.16903530143705817 \n",
      "acc for optim= 0.13768265975846183\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.004462013021111488\n",
      "Loss on test= 0.0053607202135026455\n",
      "acc for Lsat= 0.11370663262075847 \n",
      "acc for Psat= 0.1070872842748132 \n",
      "acc for optim= 0.10585505091067818\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.004597686696797609\n",
      "Loss on test= 0.005115256179124117\n",
      "acc for Lsat= 0.14694431786321932 \n",
      "acc for Psat= 0.20371924858126375 \n",
      "acc for optim= 0.08846078182493027\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.004672459792345762\n",
      "Loss on test= 0.005330672487616539\n",
      "acc for Lsat= 0.10626765945926309 \n",
      "acc for Psat= 0.13912156353601152 \n",
      "acc for optim= 0.10545112415113383\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.004639871884137392\n",
      "Loss on test= 0.005390556063503027\n",
      "acc for Lsat= 0.10764862772905165 \n",
      "acc for Psat= 0.14234775265989205 \n",
      "acc for optim= 0.0789828895423044\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.004658461082726717\n",
      "Loss on test= 0.0052125719375908375\n",
      "acc for Lsat= 0.12345221887032191 \n",
      "acc for Psat= 0.13026271276693377 \n",
      "acc for optim= 0.11314341467287806\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.0045041367411613464\n",
      "Loss on test= 0.0051983376033604145\n",
      "acc for Lsat= 0.08954781842314535 \n",
      "acc for Psat= 0.14177003000966376 \n",
      "acc for optim= 0.08602593627033962\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.004516746383160353\n",
      "Loss on test= 0.005336021538823843\n",
      "acc for Lsat= 0.10197727770234148 \n",
      "acc for Psat= 0.17748570473243794 \n",
      "acc for optim= 0.10782615213085794\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.004476022906601429\n",
      "Loss on test= 0.0055955504067242146\n",
      "acc for Lsat= 0.1310680218998136 \n",
      "acc for Psat= 0.11802978260675445 \n",
      "acc for optim= 0.12043688380314659\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.00474720261991024\n",
      "Loss on test= 0.005262244027107954\n",
      "acc for Lsat= 0.1004493121161229 \n",
      "acc for Psat= 0.12177729342753689 \n",
      "acc for optim= 0.10342750857428958\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.004620809573680162\n",
      "Loss on test= 0.0054542566649615765\n",
      "acc for Lsat= 0.13466720963414344 \n",
      "acc for Psat= 0.12262932280363101 \n",
      "acc for optim= 0.1172878731869989\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.004486197140067816\n",
      "Loss on test= 0.005279337987303734\n",
      "acc for Lsat= 0.13400953032800722 \n",
      "acc for Psat= 0.14748859882173646 \n",
      "acc for optim= 0.10522680463165873\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.004673158284276724\n",
      "Loss on test= 0.00510447146371007\n",
      "acc for Lsat= 0.12368582644396359 \n",
      "acc for Psat= 0.17344479935450685 \n",
      "acc for optim= 0.1015923015980257\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.004727668594568968\n",
      "Loss on test= 0.0054914276115596294\n",
      "acc for Lsat= 0.1045315571116387 \n",
      "acc for Psat= 0.17037412873469293 \n",
      "acc for optim= 0.10679908491308904\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.0046956175938248634\n",
      "Loss on test= 0.005321702919900417\n",
      "acc for Lsat= 0.0953946213897628 \n",
      "acc for Psat= 0.14782597847645068 \n",
      "acc for optim= 0.1021767374024623\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.004551511723548174\n",
      "Loss on test= 0.005122666712850332\n",
      "acc for Lsat= 0.09372213087044656 \n",
      "acc for Psat= 0.12889963921366465 \n",
      "acc for optim= 0.08067435253825453\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.004612566903233528\n",
      "Loss on test= 0.00519393477588892\n",
      "acc for Lsat= 0.11331941239121887 \n",
      "acc for Psat= 0.16688743823518357 \n",
      "acc for optim= 0.10459633647567695\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.004666532855480909\n",
      "Loss on test= 0.005066073965281248\n",
      "acc for Lsat= 0.12708622411527257 \n",
      "acc for Psat= 0.15856582403648645 \n",
      "acc for optim= 0.11930661043152213\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.004586915019899607\n",
      "Loss on test= 0.005483890883624554\n",
      "acc for Lsat= 0.10363069218066004 \n",
      "acc for Psat= 0.20930310559601317 \n",
      "acc for optim= 0.0979125676676631\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.004590946715325117\n",
      "Loss on test= 0.005095177795737982\n",
      "acc for Lsat= 0.1035613247529707 \n",
      "acc for Psat= 0.1624291025929981 \n",
      "acc for optim= 0.11501595711322604\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.0044253673404455185\n",
      "Loss on test= 0.005839275196194649\n",
      "acc for Lsat= 0.12816788382931715 \n",
      "acc for Psat= 0.15222272514883015 \n",
      "acc for optim= 0.11622159330484767\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.0046226042322814465\n",
      "Loss on test= 0.005115109495818615\n",
      "acc for Lsat= 0.1582757629868057 \n",
      "acc for Psat= 0.17577255041235024 \n",
      "acc for optim= 0.08808342346714602\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.004483264405280352\n",
      "Loss on test= 0.005281939171254635\n",
      "acc for Lsat= 0.11325888772423948 \n",
      "acc for Psat= 0.1682660322112497 \n",
      "acc for optim= 0.11407479800335649\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.004516286309808493\n",
      "Loss on test= 0.005324134137481451\n",
      "acc for Lsat= 0.16259063464692897 \n",
      "acc for Psat= 0.15584800406617838 \n",
      "acc for optim= 0.09897839464247227\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.0046791196800768375\n",
      "Loss on test= 0.005340016447007656\n",
      "acc for Lsat= 0.12924503897213274 \n",
      "acc for Psat= 0.15193565148446295 \n",
      "acc for optim= 0.10706614206234615\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.004423107486218214\n",
      "Loss on test= 0.005111668258905411\n",
      "acc for Lsat= 0.1399911724858814 \n",
      "acc for Psat= 0.10340727071484758 \n",
      "acc for optim= 0.10030847402716365\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.00460813008248806\n",
      "Loss on test= 0.005273981019854546\n",
      "acc for Lsat= 0.15480386072562802 \n",
      "acc for Psat= 0.1545400501215934 \n",
      "acc for optim= 0.09896198326411347\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.004505590535700321\n",
      "Loss on test= 0.00550532341003418\n",
      "acc for Lsat= 0.10178124834783375 \n",
      "acc for Psat= 0.17620792347265202 \n",
      "acc for optim= 0.10159160070017809\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.004466287326067686\n",
      "Loss on test= 0.005282556638121605\n",
      "acc for Lsat= 0.09416837290175156 \n",
      "acc for Psat= 0.13423767781609464 \n",
      "acc for optim= 0.10415450333514148\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.004636100027710199\n",
      "Loss on test= 0.005376138724386692\n",
      "acc for Lsat= 0.15282644538415802 \n",
      "acc for Psat= 0.2015476869419217 \n",
      "acc for optim= 0.11924195192599048\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.0045236144214868546\n",
      "Loss on test= 0.005191040690988302\n",
      "acc for Lsat= 0.09384152026743525 \n",
      "acc for Psat= 0.1567459332032336 \n",
      "acc for optim= 0.11085604364052415\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.004421968013048172\n",
      "Loss on test= 0.0052613322623074055\n",
      "acc for Lsat= 0.09765787615389046 \n",
      "acc for Psat= 0.15496858126587337 \n",
      "acc for optim= 0.08845161325815651\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.0045180488377809525\n",
      "Loss on test= 0.00509802857413888\n",
      "acc for Lsat= 0.10528172475622138 \n",
      "acc for Psat= 0.13052251786252278 \n",
      "acc for optim= 0.11342731418295039\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.00440678047016263\n",
      "Loss on test= 0.0049721128307282925\n",
      "acc for Lsat= 0.09590430377930817 \n",
      "acc for Psat= 0.15271841124114063 \n",
      "acc for optim= 0.10617884820223683\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.004531923681497574\n",
      "Loss on test= 0.005160969216376543\n",
      "acc for Lsat= 0.10931808156116556 \n",
      "acc for Psat= 0.16067378781735897 \n",
      "acc for optim= 0.10077143089276636\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.00458582304418087\n",
      "Loss on test= 0.0049384403973817825\n",
      "acc for Lsat= 0.10439256739078297 \n",
      "acc for Psat= 0.1667899941611621 \n",
      "acc for optim= 0.1177822123022957\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.0046987817622721195\n",
      "Loss on test= 0.005174359772354364\n",
      "acc for Lsat= 0.09626245229608482 \n",
      "acc for Psat= 0.15546369875988197 \n",
      "acc for optim= 0.08687168137273854\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.004468131810426712\n",
      "Loss on test= 0.0049671451561152935\n",
      "acc for Lsat= 0.11946416713504328 \n",
      "acc for Psat= 0.16595835511301024 \n",
      "acc for optim= 0.10312129360520178\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.00434931181371212\n",
      "Loss on test= 0.00497475964948535\n",
      "acc for Lsat= 0.10684472953693734 \n",
      "acc for Psat= 0.17408361492238733 \n",
      "acc for optim= 0.09708016138109896\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.004530647769570351\n",
      "Loss on test= 0.00512376893311739\n",
      "acc for Lsat= 0.10778494562125868 \n",
      "acc for Psat= 0.14398440599648488 \n",
      "acc for optim= 0.10196433099918067\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.004493359941989183\n",
      "Loss on test= 0.005285988561809063\n",
      "acc for Lsat= 0.0977176037720508 \n",
      "acc for Psat= 0.15404222284754118 \n",
      "acc for optim= 0.10760622321524554\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.004299450200051069\n",
      "Loss on test= 0.005000612232834101\n",
      "acc for Lsat= 0.11347270560347372 \n",
      "acc for Psat= 0.11932129471097142 \n",
      "acc for optim= 0.11190080135646793\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.004594831727445126\n",
      "Loss on test= 0.005001814570277929\n",
      "acc for Lsat= 0.1198352456299795 \n",
      "acc for Psat= 0.19159540627151728 \n",
      "acc for optim= 0.11290555545646283\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.0044108303263783455\n",
      "Loss on test= 0.005150860175490379\n",
      "acc for Lsat= 0.09042723373406464 \n",
      "acc for Psat= 0.13756034373202258 \n",
      "acc for optim= 0.08376481898853348\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.004514810163527727\n",
      "Loss on test= 0.005036801099777222\n",
      "acc for Lsat= 0.07481553227019806 \n",
      "acc for Psat= 0.07812537776125181 \n",
      "acc for optim= 0.09483683230872783\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.00430589122697711\n",
      "Loss on test= 0.0050347428768873215\n",
      "acc for Lsat= 0.09019330149102542 \n",
      "acc for Psat= 0.15636389681862461 \n",
      "acc for optim= 0.08102015389724532\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.004334933590143919\n",
      "Loss on test= 0.005225955508649349\n",
      "acc for Lsat= 0.1315997998851041 \n",
      "acc for Psat= 0.1288994914955563 \n",
      "acc for optim= 0.12661856504726327\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.004346373025327921\n",
      "Loss on test= 0.005467565730214119\n",
      "acc for Lsat= 0.12634797083834806 \n",
      "acc for Psat= 0.16026400174531671 \n",
      "acc for optim= 0.08414712272739659\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.0043372586369514465\n",
      "Loss on test= 0.005366046912968159\n",
      "acc for Lsat= 0.09884153810950617 \n",
      "acc for Psat= 0.17016114874018562 \n",
      "acc for optim= 0.12370129156624898\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.004379602149128914\n",
      "Loss on test= 0.005089399870485067\n",
      "acc for Lsat= 0.14913777163666156 \n",
      "acc for Psat= 0.1859290306456387 \n",
      "acc for optim= 0.10037664368024303\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.00456351088359952\n",
      "Loss on test= 0.005121450871229172\n",
      "acc for Lsat= 0.13387313681758112 \n",
      "acc for Psat= 0.12735308272143206 \n",
      "acc for optim= 0.11459765263781366\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.004511736799031496\n",
      "Loss on test= 0.0056537059135735035\n",
      "acc for Lsat= 0.1377006795567771 \n",
      "acc for Psat= 0.13867859225784843 \n",
      "acc for optim= 0.09701288905408648\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.0043966565281152725\n",
      "Loss on test= 0.00482490099966526\n",
      "acc for Lsat= 0.10795484281455477 \n",
      "acc for Psat= 0.13155959721188992 \n",
      "acc for optim= 0.08681487021062316\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.004499419126659632\n",
      "Loss on test= 0.005350695922970772\n",
      "acc for Lsat= 0.09685709604269101 \n",
      "acc for Psat= 0.12850027779738107 \n",
      "acc for optim= 0.12759357711507213\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.004455835558474064\n",
      "Loss on test= 0.005356743466109037\n",
      "acc for Lsat= 0.1541110858735111 \n",
      "acc for Psat= 0.16636216630124384 \n",
      "acc for optim= 0.10093800076800916\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.004375547636300325\n",
      "Loss on test= 0.0054128291085362434\n",
      "acc for Lsat= 0.08283366304304865 \n",
      "acc for Psat= 0.1082002366375592 \n",
      "acc for optim= 0.10471362566264968\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.004287340212613344\n",
      "Loss on test= 0.005058262497186661\n",
      "acc for Lsat= 0.10121238749060366 \n",
      "acc for Psat= 0.10663868270866159 \n",
      "acc for optim= 0.11247355199884623\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.004454962909221649\n",
      "Loss on test= 0.005415354389697313\n",
      "acc for Lsat= 0.11650560879045063 \n",
      "acc for Psat= 0.11495873125063048 \n",
      "acc for optim= 0.11974708901511298\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.004559847991913557\n",
      "Loss on test= 0.004946952685713768\n",
      "acc for Lsat= 0.11446879048728281 \n",
      "acc for Psat= 0.12411317423296471 \n",
      "acc for optim= 0.0945366837291254\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.004546583630144596\n",
      "Loss on test= 0.005402377340942621\n",
      "acc for Lsat= 0.09075694166757683 \n",
      "acc for Psat= 0.18523659691628483 \n",
      "acc for optim= 0.10907822877116916\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.004297586157917976\n",
      "Loss on test= 0.005260216537863016\n",
      "acc for Lsat= 0.11564495719762312 \n",
      "acc for Psat= 0.15920936691367793 \n",
      "acc for optim= 0.11947469157166779\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.004358101636171341\n",
      "Loss on test= 0.005030051805078983\n",
      "acc for Lsat= 0.11847313017480904 \n",
      "acc for Psat= 0.12553448600616926 \n",
      "acc for optim= 0.10487095121708181\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.004442636389285326\n",
      "Loss on test= 0.005427483934909105\n",
      "acc for Lsat= 0.09224436389437567 \n",
      "acc for Psat= 0.1391654343654712 \n",
      "acc for optim= 0.10413407213571998\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.0043794745579361916\n",
      "Loss on test= 0.0051068514585494995\n",
      "acc for Lsat= 0.11957820321226285 \n",
      "acc for Psat= 0.12448861512045066 \n",
      "acc for optim= 0.08800701404106803\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.004624711349606514\n",
      "Loss on test= 0.005221217405050993\n",
      "acc for Lsat= 0.12994118624677262 \n",
      "acc for Psat= 0.0967990623418397 \n",
      "acc for optim= 0.10373594543083679\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.0043271249160170555\n",
      "Loss on test= 0.005375513806939125\n",
      "acc for Lsat= 0.08316910412880436 \n",
      "acc for Psat= 0.14582337325231898 \n",
      "acc for optim= 0.08558680287872751\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.004377576522529125\n",
      "Loss on test= 0.005082791671156883\n",
      "acc for Lsat= 0.11911791744124559 \n",
      "acc for Psat= 0.11782182670140173 \n",
      "acc for optim= 0.09741071870343553\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.004594635684043169\n",
      "Loss on test= 0.004872838966548443\n",
      "acc for Lsat= 0.1414030914505323 \n",
      "acc for Psat= 0.11347451451648441 \n",
      "acc for optim= 0.1040224246810087\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.004274612758308649\n",
      "Loss on test= 0.005332957487553358\n",
      "acc for Lsat= 0.10795876589448501 \n",
      "acc for Psat= 0.17307225802910076 \n",
      "acc for optim= 0.10063728207670566\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.004439300391823053\n",
      "Loss on test= 0.00538363354280591\n",
      "acc for Lsat= 0.1337409074832168 \n",
      "acc for Psat= 0.15595409338776436 \n",
      "acc for optim= 0.0894257514608196\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.004343262407928705\n",
      "Loss on test= 0.005202942062169313\n",
      "acc for Lsat= 0.10605001306006064 \n",
      "acc for Psat= 0.13837719253367847 \n",
      "acc for optim= 0.09932678165690352\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.00445900671184063\n",
      "Loss on test= 0.0053086900152266026\n",
      "acc for Lsat= 0.09761929669831362 \n",
      "acc for Psat= 0.11193284868366188 \n",
      "acc for optim= 0.09157333545671362\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.004454286303371191\n",
      "Loss on test= 0.00487336702644825\n",
      "acc for Lsat= 0.09244363594593273 \n",
      "acc for Psat= 0.17555985568712154 \n",
      "acc for optim= 0.07768528815358877\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.004397266544401646\n",
      "Loss on test= 0.0053557138890028\n",
      "acc for Lsat= 0.09405889496621159 \n",
      "acc for Psat= 0.20271285359437266 \n",
      "acc for optim= 0.10572043133692609\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.004466330632567406\n",
      "Loss on test= 0.005407677497714758\n",
      "acc for Lsat= 0.11916188484368224 \n",
      "acc for Psat= 0.12961822893056604 \n",
      "acc for optim= 0.10948098617761086\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.004355346783995628\n",
      "Loss on test= 0.004922677297145128\n",
      "acc for Lsat= 0.12188768479973078 \n",
      "acc for Psat= 0.20187564152810308 \n",
      "acc for optim= 0.10828831610787246\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.004323414992541075\n",
      "Loss on test= 0.004974147770553827\n",
      "acc for Lsat= 0.16375034198992783 \n",
      "acc for Psat= 0.21033593970868322 \n",
      "acc for optim= 0.10581394320534956\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.004352115560323\n",
      "Loss on test= 0.0056381369940936565\n",
      "acc for Lsat= 0.10773784473227958 \n",
      "acc for Psat= 0.14202375871051723 \n",
      "acc for optim= 0.09866525062049429\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.004454365465790033\n",
      "Loss on test= 0.005291460081934929\n",
      "acc for Lsat= 0.09687525560406761 \n",
      "acc for Psat= 0.13614156040259534 \n",
      "acc for optim= 0.08241790066111004\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.004331714939326048\n",
      "Loss on test= 0.005079691298305988\n",
      "acc for Lsat= 0.09957232440097465 \n",
      "acc for Psat= 0.14489350193697545 \n",
      "acc for optim= 0.13383084763255385\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.004318790975958109\n",
      "Loss on test= 0.005009068176150322\n",
      "acc for Lsat= 0.10214838371353431 \n",
      "acc for Psat= 0.12793365327848327 \n",
      "acc for optim= 0.12802826965020764\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.004397602751851082\n",
      "Loss on test= 0.005301734898239374\n",
      "acc for Lsat= 0.10770910555341591 \n",
      "acc for Psat= 0.09447644886353777 \n",
      "acc for optim= 0.11289772937177783\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.004280557855963707\n",
      "Loss on test= 0.005209139548242092\n",
      "acc for Lsat= 0.11094663757830858 \n",
      "acc for Psat= 0.12816206955661377 \n",
      "acc for optim= 0.10829747261272536\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.004358123522251844\n",
      "Loss on test= 0.00516304187476635\n",
      "acc for Lsat= 0.15953851408428615 \n",
      "acc for Psat= 0.17282075714319944 \n",
      "acc for optim= 0.13222376650406253\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.0043267072178423405\n",
      "Loss on test= 0.00530104897916317\n",
      "acc for Lsat= 0.12921956114264 \n",
      "acc for Psat= 0.13509885216545728 \n",
      "acc for optim= 0.11115552552251352\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.004334479104727507\n",
      "Loss on test= 0.005652125924825668\n",
      "acc for Lsat= 0.11931030205192251 \n",
      "acc for Psat= 0.13983694193302654 \n",
      "acc for optim= 0.08820716343406174\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.004308919422328472\n",
      "Loss on test= 0.005203973967581987\n",
      "acc for Lsat= 0.13836136242995659 \n",
      "acc for Psat= 0.15704608315394986 \n",
      "acc for optim= 0.11933793355193403\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.004324789624661207\n",
      "Loss on test= 0.004897833336144686\n",
      "acc for Lsat= 0.11378685447076957 \n",
      "acc for Psat= 0.11934559574971597 \n",
      "acc for optim= 0.13040106158910525\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.004363285377621651\n",
      "Loss on test= 0.005224261898547411\n",
      "acc for Lsat= 0.10146582748792651 \n",
      "acc for Psat= 0.12343718421955903 \n",
      "acc for optim= 0.10784532429857387\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.004303552210330963\n",
      "Loss on test= 0.0048609208315610886\n",
      "acc for Lsat= 0.11811653271110521 \n",
      "acc for Psat= 0.13964131257186332 \n",
      "acc for optim= 0.10403539674977462\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.004271958488970995\n",
      "Loss on test= 0.005026012193411589\n",
      "acc for Lsat= 0.12022457579668197 \n",
      "acc for Psat= 0.154599958875527 \n",
      "acc for optim= 0.10633614535133044\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.004266807809472084\n",
      "Loss on test= 0.005246806424111128\n",
      "acc for Lsat= 0.10990890759017526 \n",
      "acc for Psat= 0.11305434261966082 \n",
      "acc for optim= 0.11543003464531568\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.004331781063228846\n",
      "Loss on test= 0.005385470576584339\n",
      "acc for Lsat= 0.08751461235806346 \n",
      "acc for Psat= 0.11970552063495335 \n",
      "acc for optim= 0.08783419898019121\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.004315132275223732\n",
      "Loss on test= 0.004775767680257559\n",
      "acc for Lsat= 0.13026218850993448 \n",
      "acc for Psat= 0.1644501414977842 \n",
      "acc for optim= 0.132499795846848\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.004367456771433353\n",
      "Loss on test= 0.005198580212891102\n",
      "acc for Lsat= 0.10703358201620479 \n",
      "acc for Psat= 0.13321379028396527 \n",
      "acc for optim= 0.08678918613845275\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.004450179170817137\n",
      "Loss on test= 0.004987453110516071\n",
      "acc for Lsat= 0.12977355594436327 \n",
      "acc for Psat= 0.14381055099268755 \n",
      "acc for optim= 0.09948136545184146\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.004282580688595772\n",
      "Loss on test= 0.0052430834621191025\n",
      "acc for Lsat= 0.13343469048332837 \n",
      "acc for Psat= 0.1787722752843466 \n",
      "acc for optim= 0.10222797271692091\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.0044380915351212025\n",
      "Loss on test= 0.00481156911700964\n",
      "acc for Lsat= 0.11233581885850678 \n",
      "acc for Psat= 0.14275512865020168 \n",
      "acc for optim= 0.09052244996807228\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.00431114761158824\n",
      "Loss on test= 0.005266609136015177\n",
      "acc for Lsat= 0.11250705590161185 \n",
      "acc for Psat= 0.14219767000112268 \n",
      "acc for optim= 0.10648737925415237\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.00437025586143136\n",
      "Loss on test= 0.0049910093657672405\n",
      "acc for Lsat= 0.12095567273596923 \n",
      "acc for Psat= 0.1492435713039918 \n",
      "acc for optim= 0.09256015128145616\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.004152629524469376\n",
      "Loss on test= 0.005267640575766563\n",
      "acc for Lsat= 0.11767120640272172 \n",
      "acc for Psat= 0.1330152986985114 \n",
      "acc for optim= 0.09649620326753292\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.004231616389006376\n",
      "Loss on test= 0.005088308826088905\n",
      "acc for Lsat= 0.1494750871012608 \n",
      "acc for Psat= 0.14016519667994645 \n",
      "acc for optim= 0.11608391353022146\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.004219964146614075\n",
      "Loss on test= 0.005280901677906513\n",
      "acc for Lsat= 0.11879861447960138 \n",
      "acc for Psat= 0.171998619619343 \n",
      "acc for optim= 0.10109760689859588\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.004370730835944414\n",
      "Loss on test= 0.005394293460994959\n",
      "acc for Lsat= 0.10740658728819755 \n",
      "acc for Psat= 0.11626297732194264 \n",
      "acc for optim= 0.1075682217746766\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.004158606752753258\n",
      "Loss on test= 0.005405854899436235\n",
      "acc for Lsat= 0.13227867122946513 \n",
      "acc for Psat= 0.11981863399139708 \n",
      "acc for optim= 0.12891471127255094\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.004361320752650499\n",
      "Loss on test= 0.005206209607422352\n",
      "acc for Lsat= 0.1415997821216782 \n",
      "acc for Psat= 0.13412479725148943 \n",
      "acc for optim= 0.10003605355612105\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.004481631331145763\n",
      "Loss on test= 0.005057349801063538\n",
      "acc for Lsat= 0.06801828880432165 \n",
      "acc for Psat= 0.15550638652510113 \n",
      "acc for optim= 0.11714621181858496\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.0042618014849722385\n",
      "Loss on test= 0.005147184245288372\n",
      "acc for Lsat= 0.10064247330754167 \n",
      "acc for Psat= 0.11677837612417837 \n",
      "acc for optim= 0.1009219420245952\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.004292195662856102\n",
      "Loss on test= 0.0055043925531208515\n",
      "acc for Lsat= 0.09411133248876366 \n",
      "acc for Psat= 0.15831409346881425 \n",
      "acc for optim= 0.11491686612781551\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.004315442871302366\n",
      "Loss on test= 0.005352682434022427\n",
      "acc for Lsat= 0.1267980579804215 \n",
      "acc for Psat= 0.13048422910893956 \n",
      "acc for optim= 0.1349624657175607\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.004076267126947641\n",
      "Loss on test= 0.005328462924808264\n",
      "acc for Lsat= 0.12276746954820636 \n",
      "acc for Psat= 0.17685201370881665 \n",
      "acc for optim= 0.09700170111480272\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.004385827574878931\n",
      "Loss on test= 0.00511096091940999\n",
      "acc for Lsat= 0.11025405173293418 \n",
      "acc for Psat= 0.13116165570035163 \n",
      "acc for optim= 0.10233380606708427\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.004236171953380108\n",
      "Loss on test= 0.005256664007902145\n",
      "acc for Lsat= 0.13177675138124162 \n",
      "acc for Psat= 0.09802219910731462 \n",
      "acc for optim= 0.12867617944721133\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.004206548444926739\n",
      "Loss on test= 0.00508513068780303\n",
      "acc for Lsat= 0.12346559178291096 \n",
      "acc for Psat= 0.11682185595337716 \n",
      "acc for optim= 0.10351826278363457\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.004289066884666681\n",
      "Loss on test= 0.005355667322874069\n",
      "acc for Lsat= 0.1309083838843637 \n",
      "acc for Psat= 0.12044761785525931 \n",
      "acc for optim= 0.10672172692526753\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.004251290112733841\n",
      "Loss on test= 0.005361237563192844\n",
      "acc for Lsat= 0.1353959473910638 \n",
      "acc for Psat= 0.14109502737927768 \n",
      "acc for optim= 0.10950681062725683\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.0045087020844221115\n",
      "Loss on test= 0.005102267488837242\n",
      "acc for Lsat= 0.13186902490754923 \n",
      "acc for Psat= 0.14203609010049453 \n",
      "acc for optim= 0.0828422895218763\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.004146328195929527\n",
      "Loss on test= 0.0049270931631326675\n",
      "acc for Lsat= 0.11558934526207547 \n",
      "acc for Psat= 0.12297342024329636 \n",
      "acc for optim= 0.09306553761254893\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.004240989685058594\n",
      "Loss on test= 0.0052286311984062195\n",
      "acc for Lsat= 0.10542715625423524 \n",
      "acc for Psat= 0.16755651571373972 \n",
      "acc for optim= 0.1185792435426265\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.004223195370286703\n",
      "Loss on test= 0.005004672333598137\n",
      "acc for Lsat= 0.12457418396499836 \n",
      "acc for Psat= 0.16196730994205508 \n",
      "acc for optim= 0.11784289735886785\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.004251205828040838\n",
      "Loss on test= 0.005478908307850361\n",
      "acc for Lsat= 0.1532902918342087 \n",
      "acc for Psat= 0.1413139393294437 \n",
      "acc for optim= 0.0995789367136442\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.004218760412186384\n",
      "Loss on test= 0.0053001996129751205\n",
      "acc for Lsat= 0.11955776221455178 \n",
      "acc for Psat= 0.154040590640054 \n",
      "acc for optim= 0.11470532318991092\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.004169147461652756\n",
      "Loss on test= 0.005047297105193138\n",
      "acc for Lsat= 0.1043038677631153 \n",
      "acc for Psat= 0.1706017013671549 \n",
      "acc for optim= 0.1361337259101371\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.004204307217150927\n",
      "Loss on test= 0.004963668994605541\n",
      "acc for Lsat= 0.10808707450309561 \n",
      "acc for Psat= 0.09610102982777688 \n",
      "acc for optim= 0.0970768057482524\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.004197522532194853\n",
      "Loss on test= 0.005174087826162577\n",
      "acc for Lsat= 0.14012486999854445 \n",
      "acc for Psat= 0.1589254406798217 \n",
      "acc for optim= 0.11235735781439063\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.004302352201193571\n",
      "Loss on test= 0.005237794015556574\n",
      "acc for Lsat= 0.12057386449952093 \n",
      "acc for Psat= 0.14295054599642754 \n",
      "acc for optim= 0.10041691788177963\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.004142139572650194\n",
      "Loss on test= 0.005116445478051901\n",
      "acc for Lsat= 0.0997800423970653 \n",
      "acc for Psat= 0.06883947908257444 \n",
      "acc for optim= 0.09861595752752489\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.004304880276322365\n",
      "Loss on test= 0.00517614372074604\n",
      "acc for Lsat= 0.10565221697712938 \n",
      "acc for Psat= 0.15821906800071397 \n",
      "acc for optim= 0.11107602404485482\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.00428721634671092\n",
      "Loss on test= 0.004944096319377422\n",
      "acc for Lsat= 0.14700553647708148 \n",
      "acc for Psat= 0.17087992996675894 \n",
      "acc for optim= 0.14014625799285974\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.004046154208481312\n",
      "Loss on test= 0.005411139223724604\n",
      "acc for Lsat= 0.12511853139019674 \n",
      "acc for Psat= 0.1572162224135051 \n",
      "acc for optim= 0.12000197415343589\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.004206986632198095\n",
      "Loss on test= 0.0051256525330245495\n",
      "acc for Lsat= 0.1037515951870268 \n",
      "acc for Psat= 0.16923692646539873 \n",
      "acc for optim= 0.09693744747589032\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.004127172287553549\n",
      "Loss on test= 0.005118736997246742\n",
      "acc for Lsat= 0.07520845065462506 \n",
      "acc for Psat= 0.100506239829378 \n",
      "acc for optim= 0.11607151970060335\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.004181901924312115\n",
      "Loss on test= 0.0053054336458444595\n",
      "acc for Lsat= 0.10755469838881658 \n",
      "acc for Psat= 0.17193932148317495 \n",
      "acc for optim= 0.07238387797648708\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.0042959884740412235\n",
      "Loss on test= 0.0052819084376096725\n",
      "acc for Lsat= 0.13320568876547945 \n",
      "acc for Psat= 0.09688826277852058 \n",
      "acc for optim= 0.09184566183345548\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.004204380325973034\n",
      "Loss on test= 0.00542652839794755\n",
      "acc for Lsat= 0.10521633091169254 \n",
      "acc for Psat= 0.21029753237962723 \n",
      "acc for optim= 0.08295077781399919\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.004299348220229149\n",
      "Loss on test= 0.005449543707072735\n",
      "acc for Lsat= 0.11837459068434934 \n",
      "acc for Psat= 0.1035662188142952 \n",
      "acc for optim= 0.09711443825573143\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.004291310906410217\n",
      "Loss on test= 0.005113648716360331\n",
      "acc for Lsat= 0.1280253743300111 \n",
      "acc for Psat= 0.15728238897605074 \n",
      "acc for optim= 0.0870358017531948\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.0041695814579725266\n",
      "Loss on test= 0.005468660965561867\n",
      "acc for Lsat= 0.1358342296961281 \n",
      "acc for Psat= 0.14749707933676998 \n",
      "acc for optim= 0.11159431339345044\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.004267972428351641\n",
      "Loss on test= 0.00528803002089262\n",
      "acc for Lsat= 0.12318690699369957 \n",
      "acc for Psat= 0.15161140418301025 \n",
      "acc for optim= 0.10350850485782656\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.00412764074280858\n",
      "Loss on test= 0.00508795166388154\n",
      "acc for Lsat= 0.14835266241182885 \n",
      "acc for Psat= 0.1301807656677233 \n",
      "acc for optim= 0.09360827778517786\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.0041215489618480206\n",
      "Loss on test= 0.005344839300960302\n",
      "acc for Lsat= 0.12220970288682212 \n",
      "acc for Psat= 0.13683453442192534 \n",
      "acc for optim= 0.08970710066043669\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.0040015000849962234\n",
      "Loss on test= 0.0053392681293189526\n",
      "acc for Lsat= 0.1419115997850895 \n",
      "acc for Psat= 0.12007282463794884 \n",
      "acc for optim= 0.10416579453481568\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.004108783323317766\n",
      "Loss on test= 0.00502430647611618\n",
      "acc for Lsat= 0.11479615213142501 \n",
      "acc for Psat= 0.1320439782511029 \n",
      "acc for optim= 0.09186354390759435\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.0040689450688660145\n",
      "Loss on test= 0.005308007355779409\n",
      "acc for Lsat= 0.11955245951604512 \n",
      "acc for Psat= 0.1274676052853465 \n",
      "acc for optim= 0.10455546678147382\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.0041214097291231155\n",
      "Loss on test= 0.005189711228013039\n",
      "acc for Lsat= 0.0927872187522654 \n",
      "acc for Psat= 0.14385995941443575 \n",
      "acc for optim= 0.09807137560306324\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.004246383905410767\n",
      "Loss on test= 0.005421271547675133\n",
      "acc for Lsat= 0.1283013381374379 \n",
      "acc for Psat= 0.13024499003464976 \n",
      "acc for optim= 0.10147170952728225\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.004193076863884926\n",
      "Loss on test= 0.005159981083124876\n",
      "acc for Lsat= 0.0690151597890589 \n",
      "acc for Psat= 0.11137642535484499 \n",
      "acc for optim= 0.10684669118685027\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.004093623720109463\n",
      "Loss on test= 0.00521993450820446\n",
      "acc for Lsat= 0.10210173194193178 \n",
      "acc for Psat= 0.14326549042016268 \n",
      "acc for optim= 0.09997282192731897\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.004189442377537489\n",
      "Loss on test= 0.005288903601467609\n",
      "acc for Lsat= 0.10926351931670474 \n",
      "acc for Psat= 0.12044637495030959 \n",
      "acc for optim= 0.10636135792204489\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.0042367237620055676\n",
      "Loss on test= 0.005262489430606365\n",
      "acc for Lsat= 0.11141744819987151 \n",
      "acc for Psat= 0.13805288241969216 \n",
      "acc for optim= 0.10388144040997657\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.004378938116133213\n",
      "Loss on test= 0.005391005426645279\n",
      "acc for Lsat= 0.10479928496190244 \n",
      "acc for Psat= 0.1347878842562851 \n",
      "acc for optim= 0.102749731275253\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.004248509183526039\n",
      "Loss on test= 0.005315457936376333\n",
      "acc for Lsat= 0.0966356091408266 \n",
      "acc for Psat= 0.15357805933389398 \n",
      "acc for optim= 0.10450207923228542\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.003996159415692091\n",
      "Loss on test= 0.005415237974375486\n",
      "acc for Lsat= 0.17597790424608523 \n",
      "acc for Psat= 0.1362018500868645 \n",
      "acc for optim= 0.10833364333181332\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.0040326546877622604\n",
      "Loss on test= 0.0054776836186647415\n",
      "acc for Lsat= 0.09452512880994214 \n",
      "acc for Psat= 0.13393964623618457 \n",
      "acc for optim= 0.09841529731380029\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.004101160913705826\n",
      "Loss on test= 0.005188102833926678\n",
      "acc for Lsat= 0.107481441887406 \n",
      "acc for Psat= 0.15288624607233536 \n",
      "acc for optim= 0.09949073204511984\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.00411747582256794\n",
      "Loss on test= 0.005352767184376717\n",
      "acc for Lsat= 0.11542849304775397 \n",
      "acc for Psat= 0.13785027204236636 \n",
      "acc for optim= 0.10959035365117921\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.003921197727322578\n",
      "Loss on test= 0.005136839114129543\n",
      "acc for Lsat= 0.09622754642946853 \n",
      "acc for Psat= 0.10411703278077766 \n",
      "acc for optim= 0.10839517291040263\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.004141038283705711\n",
      "Loss on test= 0.005466174799948931\n",
      "acc for Lsat= 0.1291122409618563 \n",
      "acc for Psat= 0.166757534038172 \n",
      "acc for optim= 0.0896047900379118\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.0041620125994086266\n",
      "Loss on test= 0.004940610378980637\n",
      "acc for Lsat= 0.11327680598090713 \n",
      "acc for Psat= 0.1202370980495794 \n",
      "acc for optim= 0.10003029971590473\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.00412007188424468\n",
      "Loss on test= 0.005355438683182001\n",
      "acc for Lsat= 0.1199913097338544 \n",
      "acc for Psat= 0.15633803016327066 \n",
      "acc for optim= 0.0861435078873506\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.004110102541744709\n",
      "Loss on test= 0.005447840318083763\n",
      "acc for Lsat= 0.1347025676655499 \n",
      "acc for Psat= 0.11823143558770728 \n",
      "acc for optim= 0.11165726292205767\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.004075018689036369\n",
      "Loss on test= 0.005314881447702646\n",
      "acc for Lsat= 0.1093358161031372 \n",
      "acc for Psat= 0.11365159176703957 \n",
      "acc for optim= 0.08860705016155003\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.004145200829952955\n",
      "Loss on test= 0.00529359420761466\n",
      "acc for Lsat= 0.10794609821298057 \n",
      "acc for Psat= 0.1271793702746638 \n",
      "acc for optim= 0.11239229523602666\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.004174933303147554\n",
      "Loss on test= 0.005106367636471987\n",
      "acc for Lsat= 0.09564224656464325 \n",
      "acc for Psat= 0.1255286837824517 \n",
      "acc for optim= 0.08312009766490923\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.004065131768584251\n",
      "Loss on test= 0.005376819521188736\n",
      "acc for Lsat= 0.12983391744395098 \n",
      "acc for Psat= 0.15307684284117487 \n",
      "acc for optim= 0.09679100901768026\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.003904511220753193\n",
      "Loss on test= 0.005202221218496561\n",
      "acc for Lsat= 0.09152880109549086 \n",
      "acc for Psat= 0.09464824026347035 \n",
      "acc for optim= 0.09696652613476747\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.004053078126162291\n",
      "Loss on test= 0.005075099412351847\n",
      "acc for Lsat= 0.12368315101290743 \n",
      "acc for Psat= 0.10024815497712956 \n",
      "acc for optim= 0.12415099495814906\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.00414735684171319\n",
      "Loss on test= 0.005238108336925507\n",
      "acc for Lsat= 0.09784542660539348 \n",
      "acc for Psat= 0.08498432823560303 \n",
      "acc for optim= 0.1161481847262217\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.004135848488658667\n",
      "Loss on test= 0.005112063605338335\n",
      "acc for Lsat= 0.14254114342232546 \n",
      "acc for Psat= 0.21170593430805537 \n",
      "acc for optim= 0.11448486775366797\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.00398943992331624\n",
      "Loss on test= 0.005220445804297924\n",
      "acc for Lsat= 0.08475889535394446 \n",
      "acc for Psat= 0.14395374524044907 \n",
      "acc for optim= 0.10700683832530761\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.004251117818057537\n",
      "Loss on test= 0.005123500246554613\n",
      "acc for Lsat= 0.11873740557995108 \n",
      "acc for Psat= 0.16336919765712488 \n",
      "acc for optim= 0.10729983690867408\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.004089985508471727\n",
      "Loss on test= 0.005186819937080145\n",
      "acc for Lsat= 0.09410584149494146 \n",
      "acc for Psat= 0.13502643875674242 \n",
      "acc for optim= 0.09366376558318734\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.004259773064404726\n",
      "Loss on test= 0.005187263246625662\n",
      "acc for Lsat= 0.15094360212484995 \n",
      "acc for Psat= 0.12852483879153928 \n",
      "acc for optim= 0.0999562259659999\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.0041895415633916855\n",
      "Loss on test= 0.005079034250229597\n",
      "acc for Lsat= 0.11824332565690081 \n",
      "acc for Psat= 0.13077484128168887 \n",
      "acc for optim= 0.08139316740238832\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.0041670529171824455\n",
      "Loss on test= 0.005057602189481258\n",
      "acc for Lsat= 0.08301713265892532 \n",
      "acc for Psat= 0.10810361802577972 \n",
      "acc for optim= 0.12692486158468658\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.003953912761062384\n",
      "Loss on test= 0.005093701649457216\n",
      "acc for Lsat= 0.1324165695760813 \n",
      "acc for Psat= 0.1169383630880879 \n",
      "acc for optim= 0.09705773257236514\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.003993846941739321\n",
      "Loss on test= 0.0059305885806679726\n",
      "acc for Lsat= 0.13081962946388456 \n",
      "acc for Psat= 0.147537606018078 \n",
      "acc for optim= 0.08600909381897913\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.004038963466882706\n",
      "Loss on test= 0.005352177657186985\n",
      "acc for Lsat= 0.13330005305922693 \n",
      "acc for Psat= 0.11492181103676558 \n",
      "acc for optim= 0.10040842157064213\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.003976719453930855\n",
      "Loss on test= 0.005513954907655716\n",
      "acc for Lsat= 0.1459285012549824 \n",
      "acc for Psat= 0.1709822880414625 \n",
      "acc for optim= 0.09764740187933461\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.0041385372169315815\n",
      "Loss on test= 0.0052736434154212475\n",
      "acc for Lsat= 0.11815030690437804 \n",
      "acc for Psat= 0.14502490467081466 \n",
      "acc for optim= 0.13170585186324185\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.004071929957717657\n",
      "Loss on test= 0.005367577541619539\n",
      "acc for Lsat= 0.10443111011085825 \n",
      "acc for Psat= 0.14372066925797197 \n",
      "acc for optim= 0.13336862872044244\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.004102664068341255\n",
      "Loss on test= 0.0050994157791137695\n",
      "acc for Lsat= 0.10768504929728806 \n",
      "acc for Psat= 0.1355426923190761 \n",
      "acc for optim= 0.12149781702707212\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.004077521152794361\n",
      "Loss on test= 0.0051367017440497875\n",
      "acc for Lsat= 0.12709588601460886 \n",
      "acc for Psat= 0.1917297422640129 \n",
      "acc for optim= 0.13659947826009658\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.004032884258776903\n",
      "Loss on test= 0.005275747273117304\n",
      "acc for Lsat= 0.12200765704943074 \n",
      "acc for Psat= 0.14286776518242228 \n",
      "acc for optim= 0.07644356194780105\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.004114171024411917\n",
      "Loss on test= 0.005385119933634996\n",
      "acc for Lsat= 0.10147602777255492 \n",
      "acc for Psat= 0.15885168853371093 \n",
      "acc for optim= 0.09624866036918117\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.003934465814381838\n",
      "Loss on test= 0.00539681501686573\n",
      "acc for Lsat= 0.08477176073938608 \n",
      "acc for Psat= 0.1074756518420246 \n",
      "acc for optim= 0.10111483512446284\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.003976703155785799\n",
      "Loss on test= 0.0052574388682842255\n",
      "acc for Lsat= 0.10848514238993327 \n",
      "acc for Psat= 0.1256393189024594 \n",
      "acc for optim= 0.09736711806100276\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.004014648962765932\n",
      "Loss on test= 0.005772592965513468\n",
      "acc for Lsat= 0.107796435089161 \n",
      "acc for Psat= 0.13845600042906073 \n",
      "acc for optim= 0.12385794494508041\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.004095024894922972\n",
      "Loss on test= 0.005093821324408054\n",
      "acc for Lsat= 0.12512485541487373 \n",
      "acc for Psat= 0.1673262567104151 \n",
      "acc for optim= 0.1337710899921755\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.003930936101824045\n",
      "Loss on test= 0.005253558978438377\n",
      "acc for Lsat= 0.11863413372904891 \n",
      "acc for Psat= 0.17161722322149822 \n",
      "acc for optim= 0.11184621579660517\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.0040031070820987225\n",
      "Loss on test= 0.005576530005782843\n",
      "acc for Lsat= 0.1243864200077951 \n",
      "acc for Psat= 0.16582641657441854 \n",
      "acc for optim= 0.1307709926428894\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.004170060157775879\n",
      "Loss on test= 0.005308532156050205\n",
      "acc for Lsat= 0.16237466145280954 \n",
      "acc for Psat= 0.1928673153322759 \n",
      "acc for optim= 0.10318365186038944\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.0040700314566493034\n",
      "Loss on test= 0.005299142096191645\n",
      "acc for Lsat= 0.1369348092121072 \n",
      "acc for Psat= 0.18073775453699958 \n",
      "acc for optim= 0.12330843730726176\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.003973727114498615\n",
      "Loss on test= 0.005429454613476992\n",
      "acc for Lsat= 0.11377428209460858 \n",
      "acc for Psat= 0.16013983730226755 \n",
      "acc for optim= 0.10975060842206909\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.00405374588444829\n",
      "Loss on test= 0.00506674824282527\n",
      "acc for Lsat= 0.08928151128606664 \n",
      "acc for Psat= 0.10609564891395469 \n",
      "acc for optim= 0.09144124106710984\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.003911187872290611\n",
      "Loss on test= 0.005435049068182707\n",
      "acc for Lsat= 0.0924315649188227 \n",
      "acc for Psat= 0.12049619289528993 \n",
      "acc for optim= 0.11763719610300744\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.004002096131443977\n",
      "Loss on test= 0.005562016274780035\n",
      "acc for Lsat= 0.11305646660427253 \n",
      "acc for Psat= 0.1051156794742888 \n",
      "acc for optim= 0.12783603271883395\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.00401768134906888\n",
      "Loss on test= 0.005300056654959917\n",
      "acc for Lsat= 0.11611050884756777 \n",
      "acc for Psat= 0.13786144363176492 \n",
      "acc for optim= 0.10745615356912215\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.004194739740341902\n",
      "Loss on test= 0.005209890194237232\n",
      "acc for Lsat= 0.10329581341809696 \n",
      "acc for Psat= 0.1525363993520538 \n",
      "acc for optim= 0.08475841261032555\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.004056654404848814\n",
      "Loss on test= 0.005533779971301556\n",
      "acc for Lsat= 0.09877327964123753 \n",
      "acc for Psat= 0.1309023432355995 \n",
      "acc for optim= 0.1062296507621391\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.0039474437944591045\n",
      "Loss on test= 0.004990612156689167\n",
      "acc for Lsat= 0.12109687101716797 \n",
      "acc for Psat= 0.14149492629803717 \n",
      "acc for optim= 0.1310601595064832\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.003964673262089491\n",
      "Loss on test= 0.005560506600886583\n",
      "acc for Lsat= 0.10295668575498793 \n",
      "acc for Psat= 0.13994685498376688 \n",
      "acc for optim= 0.09715585961627464\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.0039894492365419865\n",
      "Loss on test= 0.005432568956166506\n",
      "acc for Lsat= 0.12648600766745707 \n",
      "acc for Psat= 0.19358207861013296 \n",
      "acc for optim= 0.12663060509496266\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.004164717625826597\n",
      "Loss on test= 0.005263332277536392\n",
      "acc for Lsat= 0.11617357907299367 \n",
      "acc for Psat= 0.15043131611309946 \n",
      "acc for optim= 0.11126761111275603\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.004009846597909927\n",
      "Loss on test= 0.005383709445595741\n",
      "acc for Lsat= 0.12466088237447871 \n",
      "acc for Psat= 0.15651595265889126 \n",
      "acc for optim= 0.11175374918012596\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.004027512390166521\n",
      "Loss on test= 0.005273016169667244\n",
      "acc for Lsat= 0.10735340054250425 \n",
      "acc for Psat= 0.15120256470820298 \n",
      "acc for optim= 0.09734851266774866\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.0038603649009019136\n",
      "Loss on test= 0.005121531430631876\n",
      "acc for Lsat= 0.10164465205485208 \n",
      "acc for Psat= 0.15069082425907254 \n",
      "acc for optim= 0.11408916115760803\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.003999772481620312\n",
      "Loss on test= 0.005260383244603872\n",
      "acc for Lsat= 0.0821898753023965 \n",
      "acc for Psat= 0.13905907470163786 \n",
      "acc for optim= 0.08553690111471547\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.0040423148311674595\n",
      "Loss on test= 0.00536371162161231\n",
      "acc for Lsat= 0.10217052736940484 \n",
      "acc for Psat= 0.12407376221381128 \n",
      "acc for optim= 0.10237506467900756\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.004064138047397137\n",
      "Loss on test= 0.005016888026148081\n",
      "acc for Lsat= 0.1302375130665799 \n",
      "acc for Psat= 0.11533448436400956 \n",
      "acc for optim= 0.1044469373818073\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.004171237349510193\n",
      "Loss on test= 0.005198571365326643\n",
      "acc for Lsat= 0.08479041228484777 \n",
      "acc for Psat= 0.1566708712424669 \n",
      "acc for optim= 0.0801696959824767\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.00410910788923502\n",
      "Loss on test= 0.00497835036367178\n",
      "acc for Lsat= 0.10516279258040918 \n",
      "acc for Psat= 0.14131073609718847 \n",
      "acc for optim= 0.11730423970665368\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.003965753596276045\n",
      "Loss on test= 0.005139091983437538\n",
      "acc for Lsat= 0.13391087700923285 \n",
      "acc for Psat= 0.17482879613008764 \n",
      "acc for optim= 0.12786589326747666\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.0040049124509096146\n",
      "Loss on test= 0.0050513469614088535\n",
      "acc for Lsat= 0.11292947119929725 \n",
      "acc for Psat= 0.10370461919551922 \n",
      "acc for optim= 0.10075564886533862\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.004096302203834057\n",
      "Loss on test= 0.005211788695305586\n",
      "acc for Lsat= 0.13917908941706023 \n",
      "acc for Psat= 0.10666054104351336 \n",
      "acc for optim= 0.11202533160232836\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.003931691870093346\n",
      "Loss on test= 0.005168675445020199\n",
      "acc for Lsat= 0.09726259603889452 \n",
      "acc for Psat= 0.1629871043842286 \n",
      "acc for optim= 0.11250410042703152\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.0040004500187933445\n",
      "Loss on test= 0.005007700063288212\n",
      "acc for Lsat= 0.1404568388954633 \n",
      "acc for Psat= 0.1272681627047455 \n",
      "acc for optim= 0.0963979109478209\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.003956311848014593\n",
      "Loss on test= 0.005100449081510305\n",
      "acc for Lsat= 0.1274168954955207 \n",
      "acc for Psat= 0.1737607617574718 \n",
      "acc for optim= 0.12179893920094603\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.00404741195961833\n",
      "Loss on test= 0.005337648093700409\n",
      "acc for Lsat= 0.0944583482171058 \n",
      "acc for Psat= 0.11170054791081283 \n",
      "acc for optim= 0.10603416359259023\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.003814171999692917\n",
      "Loss on test= 0.0050801243633031845\n",
      "acc for Lsat= 0.14468076628529364 \n",
      "acc for Psat= 0.16515582502405676 \n",
      "acc for optim= 0.12493507522675726\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.003943810239434242\n",
      "Loss on test= 0.005544282961636782\n",
      "acc for Lsat= 0.11275196176332732 \n",
      "acc for Psat= 0.1507486102992617 \n",
      "acc for optim= 0.10638663183069891\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.004250126425176859\n",
      "Loss on test= 0.0053632683120667934\n",
      "acc for Lsat= 0.12638510703335568 \n",
      "acc for Psat= 0.14617490478687817 \n",
      "acc for optim= 0.09109969553537667\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.003915809094905853\n",
      "Loss on test= 0.005319326650351286\n",
      "acc for Lsat= 0.11896811104896995 \n",
      "acc for Psat= 0.13742246551232207 \n",
      "acc for optim= 0.10576517114208804\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.003992124926298857\n",
      "Loss on test= 0.005460512358695269\n",
      "acc for Lsat= 0.10621705175273949 \n",
      "acc for Psat= 0.1478856425318453 \n",
      "acc for optim= 0.08713453843827462\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.004047033376991749\n",
      "Loss on test= 0.005255636293441057\n",
      "acc for Lsat= 0.09449651982221338 \n",
      "acc for Psat= 0.11860074116460358 \n",
      "acc for optim= 0.11339466664422718\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.0041549187153577805\n",
      "Loss on test= 0.005191868171095848\n",
      "acc for Lsat= 0.09700762599499689 \n",
      "acc for Psat= 0.15091598665134776 \n",
      "acc for optim= 0.11298230273597357\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.004049044102430344\n",
      "Loss on test= 0.0051265498623251915\n",
      "acc for Lsat= 0.12873015257840356 \n",
      "acc for Psat= 0.09591476735658944 \n",
      "acc for optim= 0.10228650895361271\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.00391740258783102\n",
      "Loss on test= 0.005570430774241686\n",
      "acc for Lsat= 0.12046395718223518 \n",
      "acc for Psat= 0.1468435792873303 \n",
      "acc for optim= 0.10908131059517877\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.003917013760656118\n",
      "Loss on test= 0.0051862201653420925\n",
      "acc for Lsat= 0.1259187553498325 \n",
      "acc for Psat= 0.12644156689445177 \n",
      "acc for optim= 0.11517715309229162\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.004071780014783144\n",
      "Loss on test= 0.005462749395519495\n",
      "acc for Lsat= 0.12879126399113577 \n",
      "acc for Psat= 0.1658677174192336 \n",
      "acc for optim= 0.11360357329249382\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.003993436228483915\n",
      "Loss on test= 0.005293022375553846\n",
      "acc for Lsat= 0.11195460800081491 \n",
      "acc for Psat= 0.14462584986661872 \n",
      "acc for optim= 0.0796461019716743\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.0038711533416062593\n",
      "Loss on test= 0.005504031665623188\n",
      "acc for Lsat= 0.17142151792844137 \n",
      "acc for Psat= 0.1585560655221343 \n",
      "acc for optim= 0.09926325515455876\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.003902248339727521\n",
      "Loss on test= 0.005467560607939959\n",
      "acc for Lsat= 0.1096563141586052 \n",
      "acc for Psat= 0.1219720113505092 \n",
      "acc for optim= 0.09718502204244335\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.0039389850571751595\n",
      "Loss on test= 0.005056049674749374\n",
      "acc for Lsat= 0.10543521836128396 \n",
      "acc for Psat= 0.1324519043814184 \n",
      "acc for optim= 0.12695992254076474\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.004051490221172571\n",
      "Loss on test= 0.005211689509451389\n",
      "acc for Lsat= 0.10103031809234785 \n",
      "acc for Psat= 0.12944064954192275 \n",
      "acc for optim= 0.10961393160848981\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.00389529368840158\n",
      "Loss on test= 0.005129562225192785\n",
      "acc for Lsat= 0.12368808500468731 \n",
      "acc for Psat= 0.1311575963627547 \n",
      "acc for optim= 0.11959267813169087\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.0039764647372066975\n",
      "Loss on test= 0.005200250539928675\n",
      "acc for Lsat= 0.11025991927211483 \n",
      "acc for Psat= 0.19041216870148978 \n",
      "acc for optim= 0.0978421944730346\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.003806376364082098\n",
      "Loss on test= 0.005383730866014957\n",
      "acc for Lsat= 0.1356155270089706 \n",
      "acc for Psat= 0.1373661220487621 \n",
      "acc for optim= 0.10551616513273782\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.003960412461310625\n",
      "Loss on test= 0.005117296706885099\n",
      "acc for Lsat= 0.11457697245188886 \n",
      "acc for Psat= 0.13079981764571535 \n",
      "acc for optim= 0.09706071383940677\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.003947855904698372\n",
      "Loss on test= 0.00551918800920248\n",
      "acc for Lsat= 0.1603552266024053 \n",
      "acc for Psat= 0.1349269208472429 \n",
      "acc for optim= 0.09930600778251472\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.0038841278292238712\n",
      "Loss on test= 0.0053436653688549995\n",
      "acc for Lsat= 0.12265650054905564 \n",
      "acc for Psat= 0.16383613894383112 \n",
      "acc for optim= 0.11790539701986644\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.0039684465155005455\n",
      "Loss on test= 0.005255936179310083\n",
      "acc for Lsat= 0.12763147273411354 \n",
      "acc for Psat= 0.166898000985384 \n",
      "acc for optim= 0.1022652745143407\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.003969735931605101\n",
      "Loss on test= 0.005305476486682892\n",
      "acc for Lsat= 0.10673654642111312 \n",
      "acc for Psat= 0.16435778306590187 \n",
      "acc for optim= 0.1491492324663947\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.0039027640596032143\n",
      "Loss on test= 0.00501756276935339\n",
      "acc for Lsat= 0.10595462466719457 \n",
      "acc for Psat= 0.1417604281515297 \n",
      "acc for optim= 0.1232836428615782\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.003916420042514801\n",
      "Loss on test= 0.005040689371526241\n",
      "acc for Lsat= 0.11101893811590141 \n",
      "acc for Psat= 0.16018443947864902 \n",
      "acc for optim= 0.10193281258559889\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.0039712004363536835\n",
      "Loss on test= 0.0055535039864480495\n",
      "acc for Lsat= 0.1305416607913988 \n",
      "acc for Psat= 0.1256522017841538 \n",
      "acc for optim= 0.09981305974846084\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.004108789376914501\n",
      "Loss on test= 0.005351193714886904\n",
      "acc for Lsat= 0.08245042179866384 \n",
      "acc for Psat= 0.12406445749931866 \n",
      "acc for optim= 0.13711722195148468\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.0038550205063074827\n",
      "Loss on test= 0.00539964297786355\n",
      "acc for Lsat= 0.13142403354868293 \n",
      "acc for Psat= 0.16539026776121724 \n",
      "acc for optim= 0.11207310663950112\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.003833451773971319\n",
      "Loss on test= 0.0051564425230026245\n",
      "acc for Lsat= 0.1360663946511017 \n",
      "acc for Psat= 0.16120143327862024 \n",
      "acc for optim= 0.11671530750269692\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.003983435221016407\n",
      "Loss on test= 0.0054300762712955475\n",
      "acc for Lsat= 0.09258587999890248 \n",
      "acc for Psat= 0.12504253720787042 \n",
      "acc for optim= 0.08694739782044457\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.0038262978196144104\n",
      "Loss on test= 0.005398103967308998\n",
      "acc for Lsat= 0.11841922046409713 \n",
      "acc for Psat= 0.14871834045334253 \n",
      "acc for optim= 0.12372549933691819\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.003959998954087496\n",
      "Loss on test= 0.005011663772165775\n",
      "acc for Lsat= 0.12223562298135625 \n",
      "acc for Psat= 0.13900526543147862 \n",
      "acc for optim= 0.10475743639593323\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.0037715190555900335\n",
      "Loss on test= 0.004908246453851461\n",
      "acc for Lsat= 0.12155361087449516 \n",
      "acc for Psat= 0.11804194234880722 \n",
      "acc for optim= 0.12140015937620774\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.0037660300731658936\n",
      "Loss on test= 0.005038230214267969\n",
      "acc for Lsat= 0.10844759468454868 \n",
      "acc for Psat= 0.11987974467208712 \n",
      "acc for optim= 0.1185093978727107\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.003833369817584753\n",
      "Loss on test= 0.0052979690954089165\n",
      "acc for Lsat= 0.10133334106972648 \n",
      "acc for Psat= 0.1166666564790325 \n",
      "acc for optim= 0.06847080236507787\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.0038445964455604553\n",
      "Loss on test= 0.005017263814806938\n",
      "acc for Lsat= 0.10887910974108511 \n",
      "acc for Psat= 0.11837998958718446 \n",
      "acc for optim= 0.11689128468020095\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.0038566195871680975\n",
      "Loss on test= 0.004994992632418871\n",
      "acc for Lsat= 0.10817376986637504 \n",
      "acc for Psat= 0.16164451009697384 \n",
      "acc for optim= 0.0984777986175484\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.004013467114418745\n",
      "Loss on test= 0.005203483160585165\n",
      "acc for Lsat= 0.1302669033110659 \n",
      "acc for Psat= 0.1403322122577164 \n",
      "acc for optim= 0.10777692320860094\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.0037968559190630913\n",
      "Loss on test= 0.005746921990066767\n",
      "acc for Lsat= 0.1021210367584394 \n",
      "acc for Psat= 0.18459176262452578 \n",
      "acc for optim= 0.12115011770705071\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.003942335955798626\n",
      "Loss on test= 0.005805435590445995\n",
      "acc for Lsat= 0.12225037776968545 \n",
      "acc for Psat= 0.12317116897449726 \n",
      "acc for optim= 0.10668952949345112\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.003875380614772439\n",
      "Loss on test= 0.005504431668668985\n",
      "acc for Lsat= 0.1373176687500543 \n",
      "acc for Psat= 0.12261173123907712 \n",
      "acc for optim= 0.09896824594276647\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.0039061373099684715\n",
      "Loss on test= 0.005200157407671213\n",
      "acc for Lsat= 0.12574975694426233 \n",
      "acc for Psat= 0.1678907400669737 \n",
      "acc for optim= 0.09813711295525233\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.003943618852645159\n",
      "Loss on test= 0.005049567203968763\n",
      "acc for Lsat= 0.10669194095923255 \n",
      "acc for Psat= 0.12442139893199863 \n",
      "acc for optim= 0.11708846080323888\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.0038009569980204105\n",
      "Loss on test= 0.005833775736391544\n",
      "acc for Lsat= 0.12876572338993558 \n",
      "acc for Psat= 0.11877759740067025 \n",
      "acc for optim= 0.09676301668191122\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.0038391274865716696\n",
      "Loss on test= 0.005060793831944466\n",
      "acc for Lsat= 0.10571596592975159 \n",
      "acc for Psat= 0.14644312584358785 \n",
      "acc for optim= 0.12735630018222663\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.003908641170710325\n",
      "Loss on test= 0.005060216411948204\n",
      "acc for Lsat= 0.11881272174004051 \n",
      "acc for Psat= 0.15302991215139627 \n",
      "acc for optim= 0.1141666251545151\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.003918197937309742\n",
      "Loss on test= 0.00545990327373147\n",
      "acc for Lsat= 0.12366451711083452 \n",
      "acc for Psat= 0.14116224149862924 \n",
      "acc for optim= 0.14945049539932775\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.0038604738656431437\n",
      "Loss on test= 0.005208870861679316\n",
      "acc for Lsat= 0.12273431051936415 \n",
      "acc for Psat= 0.13820636978683373 \n",
      "acc for optim= 0.10567701361206774\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.003907213918864727\n",
      "Loss on test= 0.0056795463897287846\n",
      "acc for Lsat= 0.12232926848527212 \n",
      "acc for Psat= 0.1445468281292253 \n",
      "acc for optim= 0.12463457106302182\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.004033430013805628\n",
      "Loss on test= 0.005272614769637585\n",
      "acc for Lsat= 0.14437044340754962 \n",
      "acc for Psat= 0.16478054727324182 \n",
      "acc for optim= 0.13176545542147425\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.0038555182982236147\n",
      "Loss on test= 0.0053518423810601234\n",
      "acc for Lsat= 0.07831231640496601 \n",
      "acc for Psat= 0.1405280605993337 \n",
      "acc for optim= 0.1226459021446418\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.003869115374982357\n",
      "Loss on test= 0.005174442660063505\n",
      "acc for Lsat= 0.12051301828533825 \n",
      "acc for Psat= 0.1369789138229357 \n",
      "acc for optim= 0.11039632253555788\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.0037395989056676626\n",
      "Loss on test= 0.005510319955646992\n",
      "acc for Lsat= 0.14661165745928884 \n",
      "acc for Psat= 0.1386469568953746 \n",
      "acc for optim= 0.12740961431215206\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.0038754763081669807\n",
      "Loss on test= 0.005333591718226671\n",
      "acc for Lsat= 0.09767170472251666 \n",
      "acc for Psat= 0.0959514746338957 \n",
      "acc for optim= 0.13284400835012397\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.00403534946963191\n",
      "Loss on test= 0.005185452289879322\n",
      "acc for Lsat= 0.09935871956662999 \n",
      "acc for Psat= 0.12481613084673882 \n",
      "acc for optim= 0.13299468109552334\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.003760858438909054\n",
      "Loss on test= 0.0049791494384408\n",
      "acc for Lsat= 0.13741161736349264 \n",
      "acc for Psat= 0.08785100113083091 \n",
      "acc for optim= 0.12425891793746915\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.0037943606730550528\n",
      "Loss on test= 0.00533110648393631\n",
      "acc for Lsat= 0.09160219019071923 \n",
      "acc for Psat= 0.1144182737916708 \n",
      "acc for optim= 0.11336111678327951\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.0037152229342609644\n",
      "Loss on test= 0.005176850128918886\n",
      "acc for Lsat= 0.09865575850320359 \n",
      "acc for Psat= 0.14797916904919678 \n",
      "acc for optim= 0.11616291859536432\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.003864108817651868\n",
      "Loss on test= 0.005551605485379696\n",
      "acc for Lsat= 0.10832346603274345 \n",
      "acc for Psat= 0.16877886297232988 \n",
      "acc for optim= 0.1167734176851809\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.003716892097145319\n",
      "Loss on test= 0.005654596257954836\n",
      "acc for Lsat= 0.09296290095274647 \n",
      "acc for Psat= 0.11360602629267508 \n",
      "acc for optim= 0.09256969171757293\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.0039915358647704124\n",
      "Loss on test= 0.0058130137622356415\n",
      "acc for Lsat= 0.10654560887228905 \n",
      "acc for Psat= 0.11909692069619066 \n",
      "acc for optim= 0.11678820833751363\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.0036822559777647257\n",
      "Loss on test= 0.00514905946329236\n",
      "acc for Lsat= 0.1141927642101008 \n",
      "acc for Psat= 0.13025654303944773 \n",
      "acc for optim= 0.11098266835324466\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.003774522338062525\n",
      "Loss on test= 0.0056084562093019485\n",
      "acc for Lsat= 0.11792059855846067 \n",
      "acc for Psat= 0.12201034112109078 \n",
      "acc for optim= 0.10616326412289506\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.003686722368001938\n",
      "Loss on test= 0.0051482608541846275\n",
      "acc for Lsat= 0.09683977771136495 \n",
      "acc for Psat= 0.12586364238005546 \n",
      "acc for optim= 0.12966880279903611\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.003975065890699625\n",
      "Loss on test= 0.005596572067588568\n",
      "acc for Lsat= 0.15130099757677978 \n",
      "acc for Psat= 0.15957335444788137 \n",
      "acc for optim= 0.13243378864394295\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.003954727202653885\n",
      "Loss on test= 0.005175724159926176\n",
      "acc for Lsat= 0.12748318858858612 \n",
      "acc for Psat= 0.13425391449386048 \n",
      "acc for optim= 0.1173790857816736\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.003810385474935174\n",
      "Loss on test= 0.0056951651349663734\n",
      "acc for Lsat= 0.09239104131443633 \n",
      "acc for Psat= 0.1441110151224873 \n",
      "acc for optim= 0.12229498941451311\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.003718906780704856\n",
      "Loss on test= 0.005461768247187138\n",
      "acc for Lsat= 0.08368729861427306 \n",
      "acc for Psat= 0.08523301583611304 \n",
      "acc for optim= 0.10920743747717804\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.003909720573574305\n",
      "Loss on test= 0.005150137469172478\n",
      "acc for Lsat= 0.10544915514239822 \n",
      "acc for Psat= 0.09470699709426197 \n",
      "acc for optim= 0.121459420149525\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.0037689448799937963\n",
      "Loss on test= 0.005191840697079897\n",
      "acc for Lsat= 0.09169105062675145 \n",
      "acc for Psat= 0.11619499794000553 \n",
      "acc for optim= 0.10795246864048143\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.003800247563049197\n",
      "Loss on test= 0.0054040346294641495\n",
      "acc for Lsat= 0.19326199715336165 \n",
      "acc for Psat= 0.14572205378984412 \n",
      "acc for optim= 0.11337880412530568\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.0037474113050848246\n",
      "Loss on test= 0.00525754876434803\n",
      "acc for Lsat= 0.11016197127497031 \n",
      "acc for Psat= 0.14634258923534718 \n",
      "acc for optim= 0.11872144866113861\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.0037892370019108057\n",
      "Loss on test= 0.005230757407844067\n",
      "acc for Lsat= 0.12641553413252243 \n",
      "acc for Psat= 0.19142406154423952 \n",
      "acc for optim= 0.12329025209570925\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.003911412321031094\n",
      "Loss on test= 0.005605954211205244\n",
      "acc for Lsat= 0.12047946867015627 \n",
      "acc for Psat= 0.1279399604536593 \n",
      "acc for optim= 0.10854346581941678\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.0038987668231129646\n",
      "Loss on test= 0.005134960636496544\n",
      "acc for Lsat= 0.1144028600893863 \n",
      "acc for Psat= 0.18025400877619782 \n",
      "acc for optim= 0.12073545302781793\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.003720881650224328\n",
      "Loss on test= 0.005560789257287979\n",
      "acc for Lsat= 0.11552437643210094 \n",
      "acc for Psat= 0.11196658696927544 \n",
      "acc for optim= 0.11525566003628127\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.0037693411577492952\n",
      "Loss on test= 0.005214916542172432\n",
      "acc for Lsat= 0.10304711466677771 \n",
      "acc for Psat= 0.15201596124097705 \n",
      "acc for optim= 0.12395554418779081\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.0037542751524597406\n",
      "Loss on test= 0.005104246083647013\n",
      "acc for Lsat= 0.12242146260622475 \n",
      "acc for Psat= 0.11913518328219652 \n",
      "acc for optim= 0.10235823438658069\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.003797444747760892\n",
      "Loss on test= 0.005691959522664547\n",
      "acc for Lsat= 0.09234211024724776 \n",
      "acc for Psat= 0.12433537209613456 \n",
      "acc for optim= 0.1139870189751188\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.003909043502062559\n",
      "Loss on test= 0.005161675624549389\n",
      "acc for Lsat= 0.12997849836635092 \n",
      "acc for Psat= 0.1304114123599397 \n",
      "acc for optim= 0.10472618022726642\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.00380100030452013\n",
      "Loss on test= 0.005167766474187374\n",
      "acc for Lsat= 0.10950024689858158 \n",
      "acc for Psat= 0.1278185040379564 \n",
      "acc for optim= 0.08788352137586723\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.003949667327105999\n",
      "Loss on test= 0.005221704952418804\n",
      "acc for Lsat= 0.12427282304916945 \n",
      "acc for Psat= 0.14209429210879737 \n",
      "acc for optim= 0.12636252130485243\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.0038153885398060083\n",
      "Loss on test= 0.00545421801507473\n",
      "acc for Lsat= 0.12655067019578484 \n",
      "acc for Psat= 0.15965187922120094 \n",
      "acc for optim= 0.12019720022282046\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.003797737415879965\n",
      "Loss on test= 0.0051971375942230225\n",
      "acc for Lsat= 0.09625284492762552 \n",
      "acc for Psat= 0.14487820064338544 \n",
      "acc for optim= 0.0995875738768114\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.0037841713055968285\n",
      "Loss on test= 0.005067483987659216\n",
      "acc for Lsat= 0.10479493273629083 \n",
      "acc for Psat= 0.11939072293332881 \n",
      "acc for optim= 0.10487454964054956\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.0038394478615373373\n",
      "Loss on test= 0.005177272483706474\n",
      "acc for Lsat= 0.09844706652479039 \n",
      "acc for Psat= 0.16991133905119365 \n",
      "acc for optim= 0.09701113928005928\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.003710987512022257\n",
      "Loss on test= 0.005237918347120285\n",
      "acc for Lsat= 0.10055308313005501 \n",
      "acc for Psat= 0.14731827549015483 \n",
      "acc for optim= 0.10267945622197455\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.003843325423076749\n",
      "Loss on test= 0.0051488797180354595\n",
      "acc for Lsat= 0.17003062796882457 \n",
      "acc for Psat= 0.1534483644904362 \n",
      "acc for optim= 0.12461839279987746\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.0037634505424648523\n",
      "Loss on test= 0.0055280993692576885\n",
      "acc for Lsat= 0.09503077369623093 \n",
      "acc for Psat= 0.14187461576916072 \n",
      "acc for optim= 0.1527818923867825\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.0037585424724966288\n",
      "Loss on test= 0.005318683572113514\n",
      "acc for Lsat= 0.08510998023363452 \n",
      "acc for Psat= 0.15301872039627698 \n",
      "acc for optim= 0.10624440978345875\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.003805638989433646\n",
      "Loss on test= 0.0052844141609966755\n",
      "acc for Lsat= 0.12084389540056388 \n",
      "acc for Psat= 0.11771095657928123 \n",
      "acc for optim= 0.10852327073613803\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.003754736389964819\n",
      "Loss on test= 0.005254657007753849\n",
      "acc for Lsat= 0.12902336572814319 \n",
      "acc for Psat= 0.09385413128054804 \n",
      "acc for optim= 0.10726807204385598\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.0037495559081435204\n",
      "Loss on test= 0.005262128077447414\n",
      "acc for Lsat= 0.12588588667050418 \n",
      "acc for Psat= 0.14363422679404417 \n",
      "acc for optim= 0.11389611325123244\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.003817519638687372\n",
      "Loss on test= 0.005767827853560448\n",
      "acc for Lsat= 0.1243218037351552 \n",
      "acc for Psat= 0.167313581927576 \n",
      "acc for optim= 0.10418231549879743\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.004042486194521189\n",
      "Loss on test= 0.005105635616928339\n",
      "acc for Lsat= 0.0912981278832174 \n",
      "acc for Psat= 0.13867102356420624 \n",
      "acc for optim= 0.11551226714315514\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.0037984459195286036\n",
      "Loss on test= 0.005061469506472349\n",
      "acc for Lsat= 0.0981862324083017 \n",
      "acc for Psat= 0.13153855487083396 \n",
      "acc for optim= 0.10844140028994945\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.0036922222934663296\n",
      "Loss on test= 0.00496250344440341\n",
      "acc for Lsat= 0.13952267651135722 \n",
      "acc for Psat= 0.17072249576449394 \n",
      "acc for optim= 0.12280691290895145\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.0038584494031965733\n",
      "Loss on test= 0.005597808863967657\n",
      "acc for Lsat= 0.11090966241641177 \n",
      "acc for Psat= 0.1540547768300813 \n",
      "acc for optim= 0.10961413683576716\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.003803240368142724\n",
      "Loss on test= 0.005395433399826288\n",
      "acc for Lsat= 0.10681632005920012 \n",
      "acc for Psat= 0.14598980719327098 \n",
      "acc for optim= 0.11811587848286662\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.0038326962385326624\n",
      "Loss on test= 0.005369415041059256\n",
      "acc for Lsat= 0.11526311406244834 \n",
      "acc for Psat= 0.16240805139144263 \n",
      "acc for optim= 0.10912434223832355\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.0038379954639822245\n",
      "Loss on test= 0.005178650375455618\n",
      "acc for Lsat= 0.12539164908230305 \n",
      "acc for Psat= 0.18873512207452828 \n",
      "acc for optim= 0.12994677909753388\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.0038614654913544655\n",
      "Loss on test= 0.005039337556809187\n",
      "acc for Lsat= 0.11607676992813747 \n",
      "acc for Psat= 0.1833758352117406 \n",
      "acc for optim= 0.1308938053229617\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.0036290602292865515\n",
      "Loss on test= 0.005240533966571093\n",
      "acc for Lsat= 0.1438865318066544 \n",
      "acc for Psat= 0.1542298525908134 \n",
      "acc for optim= 0.11369865460114346\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.0037893911357969046\n",
      "Loss on test= 0.0051919836550951\n",
      "acc for Lsat= 0.14222111822002464 \n",
      "acc for Psat= 0.18679399708182448 \n",
      "acc for optim= 0.09259625299212833\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.0036288199480623007\n",
      "Loss on test= 0.0053140511736273766\n",
      "acc for Lsat= 0.14863118306837148 \n",
      "acc for Psat= 0.16434863271812597 \n",
      "acc for optim= 0.10267978999763727\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.0036980127915740013\n",
      "Loss on test= 0.0052268607541918755\n",
      "acc for Lsat= 0.14371026405650708 \n",
      "acc for Psat= 0.18275199556309316 \n",
      "acc for optim= 0.11511927747374608\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.0038088096771389246\n",
      "Loss on test= 0.005198833532631397\n",
      "acc for Lsat= 0.0972951466941999 \n",
      "acc for Psat= 0.11579031859421068 \n",
      "acc for optim= 0.13170313023470548\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.0037765244487673044\n",
      "Loss on test= 0.005123209673911333\n",
      "acc for Lsat= 0.13063931723849642 \n",
      "acc for Psat= 0.18360560734031928 \n",
      "acc for optim= 0.12910422848330605\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.003730509430170059\n",
      "Loss on test= 0.0050587463192641735\n",
      "acc for Lsat= 0.15105277920762697 \n",
      "acc for Psat= 0.1440586153443696 \n",
      "acc for optim= 0.1147883931795756\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.0036065203603357077\n",
      "Loss on test= 0.005417098291218281\n",
      "acc for Lsat= 0.1023374066895081 \n",
      "acc for Psat= 0.1315654299946295 \n",
      "acc for optim= 0.11322117100159328\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.0040180557407438755\n",
      "Loss on test= 0.005264410749077797\n",
      "acc for Lsat= 0.10868896543979645 \n",
      "acc for Psat= 0.11419456503871414 \n",
      "acc for optim= 0.1228104488303264\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.0037366098258644342\n",
      "Loss on test= 0.0049936105497181416\n",
      "acc for Lsat= 0.08920471142563555 \n",
      "acc for Psat= 0.14285624606741798 \n",
      "acc for optim= 0.10445608847981526\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.0036639717873185873\n",
      "Loss on test= 0.004987609572708607\n",
      "acc for Lsat= 0.1074036102121075 \n",
      "acc for Psat= 0.11421791867663462 \n",
      "acc for optim= 0.10097795921481317\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.0036306804977357388\n",
      "Loss on test= 0.0055959876626729965\n",
      "acc for Lsat= 0.12588441553008226 \n",
      "acc for Psat= 0.15159301796100205 \n",
      "acc for optim= 0.12306092578607301\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.0037733183708041906\n",
      "Loss on test= 0.005373012740164995\n",
      "acc for Lsat= 0.12498456700187591 \n",
      "acc for Psat= 0.15603271023266846 \n",
      "acc for optim= 0.10190183366648853\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.003698830958455801\n",
      "Loss on test= 0.005123441107571125\n",
      "acc for Lsat= 0.10437008435837924 \n",
      "acc for Psat= 0.13886150552166832 \n",
      "acc for optim= 0.11626862369141439\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.003725726855918765\n",
      "Loss on test= 0.005603946279734373\n",
      "acc for Lsat= 0.10825076256231922 \n",
      "acc for Psat= 0.14167192195438677 \n",
      "acc for optim= 0.152732051598529\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.003726955270394683\n",
      "Loss on test= 0.005423964466899633\n",
      "acc for Lsat= 0.14045755030302745 \n",
      "acc for Psat= 0.16969863726343545 \n",
      "acc for optim= 0.12159796529966924\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.0036580467130988836\n",
      "Loss on test= 0.005612652748823166\n",
      "acc for Lsat= 0.12925812457170752 \n",
      "acc for Psat= 0.1500886598498457 \n",
      "acc for optim= 0.0913816834282544\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.003847029060125351\n",
      "Loss on test= 0.005183203145861626\n",
      "acc for Lsat= 0.11704767904140884 \n",
      "acc for Psat= 0.15274563390347692 \n",
      "acc for optim= 0.12808596007784623\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.003767312504351139\n",
      "Loss on test= 0.00504989642649889\n",
      "acc for Lsat= 0.08034937529979895 \n",
      "acc for Psat= 0.15534249439951964 \n",
      "acc for optim= 0.10992141184397042\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.0038141540717333555\n",
      "Loss on test= 0.005380808375775814\n",
      "acc for Lsat= 0.10909877109548284 \n",
      "acc for Psat= 0.16274002111620373 \n",
      "acc for optim= 0.10867516820629437\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.0037947334349155426\n",
      "Loss on test= 0.00529159652069211\n",
      "acc for Lsat= 0.1215468955795384 \n",
      "acc for Psat= 0.12069030488944715 \n",
      "acc for optim= 0.11340644528778891\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.0037399872671812773\n",
      "Loss on test= 0.00523535069078207\n",
      "acc for Lsat= 0.09143364946875307 \n",
      "acc for Psat= 0.12613301698325408 \n",
      "acc for optim= 0.09804143647973736\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.003731935517862439\n",
      "Loss on test= 0.005573580507189035\n",
      "acc for Lsat= 0.15312629537139502 \n",
      "acc for Psat= 0.1241245436702027 \n",
      "acc for optim= 0.12508975867078537\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.0037649990990757942\n",
      "Loss on test= 0.005627491511404514\n",
      "acc for Lsat= 0.11086399180607663 \n",
      "acc for Psat= 0.15627028917272887 \n",
      "acc for optim= 0.111529809422791\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.003808078356087208\n",
      "Loss on test= 0.005322641227394342\n",
      "acc for Lsat= 0.10439207637682557 \n",
      "acc for Psat= 0.15738437159193885 \n",
      "acc for optim= 0.09632666288719823\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.0036826038267463446\n",
      "Loss on test= 0.0052306996658444405\n",
      "acc for Lsat= 0.08629288450012812 \n",
      "acc for Psat= 0.1410319646820426 \n",
      "acc for optim= 0.09684133677122493\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.003614407032728195\n",
      "Loss on test= 0.0053678033873438835\n",
      "acc for Lsat= 0.13955093599441978 \n",
      "acc for Psat= 0.14284526554143262 \n",
      "acc for optim= 0.098289017772509\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.0036134496331214905\n",
      "Loss on test= 0.005135075189173222\n",
      "acc for Lsat= 0.1223471873284628 \n",
      "acc for Psat= 0.11760261004221523 \n",
      "acc for optim= 0.08563983715915431\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.003817915916442871\n",
      "Loss on test= 0.005310745444148779\n",
      "acc for Lsat= 0.10316765717127258 \n",
      "acc for Psat= 0.18714888060155013 \n",
      "acc for optim= 0.10313090733769867\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.0037922055926173925\n",
      "Loss on test= 0.005423272959887981\n",
      "acc for Lsat= 0.11197767250188109 \n",
      "acc for Psat= 0.1511104026576504 \n",
      "acc for optim= 0.09361133287731921\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.003733375808224082\n",
      "Loss on test= 0.005109092220664024\n",
      "acc for Lsat= 0.08972894925520652 \n",
      "acc for Psat= 0.1372852303708593 \n",
      "acc for optim= 0.12224640673957765\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.0038447887636721134\n",
      "Loss on test= 0.005447752308100462\n",
      "acc for Lsat= 0.12812761759333727 \n",
      "acc for Psat= 0.12663324404921797 \n",
      "acc for optim= 0.10115658160712984\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.0036540282890200615\n",
      "Loss on test= 0.005236312747001648\n",
      "acc for Lsat= 0.11451237659073538 \n",
      "acc for Psat= 0.11884133528090185 \n",
      "acc for optim= 0.11055125658296877\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.0036175339482724667\n",
      "Loss on test= 0.0054395729675889015\n",
      "acc for Lsat= 0.08523771746291055 \n",
      "acc for Psat= 0.10340629489574996 \n",
      "acc for optim= 0.101773385812218\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.0037284595891833305\n",
      "Loss on test= 0.0055786557495594025\n",
      "acc for Lsat= 0.11498801943121685 \n",
      "acc for Psat= 0.14064235755035448 \n",
      "acc for optim= 0.12407523104007447\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.003746047616004944\n",
      "Loss on test= 0.005106146447360516\n",
      "acc for Lsat= 0.083954695198271 \n",
      "acc for Psat= 0.08789875310483491 \n",
      "acc for optim= 0.1338818772023337\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.003788948291912675\n",
      "Loss on test= 0.005589640233665705\n",
      "acc for Lsat= 0.11919806710728961 \n",
      "acc for Psat= 0.19898589031719086 \n",
      "acc for optim= 0.12061727398799525\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.003778137033805251\n",
      "Loss on test= 0.005381080321967602\n",
      "acc for Lsat= 0.08997139766708845 \n",
      "acc for Psat= 0.10937714517220026 \n",
      "acc for optim= 0.10245308886644328\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.00366233685053885\n",
      "Loss on test= 0.005173038225620985\n",
      "acc for Lsat= 0.0632004469840063 \n",
      "acc for Psat= 0.13217610441562203 \n",
      "acc for optim= 0.10863069030973646\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.003913960885256529\n",
      "Loss on test= 0.005645161494612694\n",
      "acc for Lsat= 0.1126001979638305 \n",
      "acc for Psat= 0.15313234392346609 \n",
      "acc for optim= 0.10613521602418688\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.003869915148243308\n",
      "Loss on test= 0.005392733495682478\n",
      "acc for Lsat= 0.08929926257890959 \n",
      "acc for Psat= 0.1320075857349568 \n",
      "acc for optim= 0.09200825692257947\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.003830455243587494\n",
      "Loss on test= 0.005321964621543884\n",
      "acc for Lsat= 0.09820738533097836 \n",
      "acc for Psat= 0.13016909805850851 \n",
      "acc for optim= 0.1212889752868149\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.0037676000501960516\n",
      "Loss on test= 0.005465688183903694\n",
      "acc for Lsat= 0.10277453257650551 \n",
      "acc for Psat= 0.1411107610911131 \n",
      "acc for optim= 0.129228252503607\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.0037948156241327524\n",
      "Loss on test= 0.005160200409591198\n",
      "acc for Lsat= 0.12704220740124583 \n",
      "acc for Psat= 0.1401340771610396 \n",
      "acc for optim= 0.0708619991524352\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.003682828741148114\n",
      "Loss on test= 0.005345604848116636\n",
      "acc for Lsat= 0.09926737105059955 \n",
      "acc for Psat= 0.13227702697945964 \n",
      "acc for optim= 0.14704569718903965\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.003845949424430728\n",
      "Loss on test= 0.005385708995163441\n",
      "acc for Lsat= 0.10292394578249918 \n",
      "acc for Psat= 0.11436873173160064 \n",
      "acc for optim= 0.11226009918997686\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.003746036207303405\n",
      "Loss on test= 0.005633639171719551\n",
      "acc for Lsat= 0.1341716908953256 \n",
      "acc for Psat= 0.12277659178814954 \n",
      "acc for optim= 0.14156654280506903\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.003603433258831501\n",
      "Loss on test= 0.005283092614263296\n",
      "acc for Lsat= 0.09727110739590393 \n",
      "acc for Psat= 0.16126846716118357 \n",
      "acc for optim= 0.13995571258581346\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.00376105890609324\n",
      "Loss on test= 0.005340939853340387\n",
      "acc for Lsat= 0.07106462985070215 \n",
      "acc for Psat= 0.11859859950426552 \n",
      "acc for optim= 0.10893447924819258\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.003609022591263056\n",
      "Loss on test= 0.005594956688582897\n",
      "acc for Lsat= 0.11135237811767082 \n",
      "acc for Psat= 0.16452195112489992 \n",
      "acc for optim= 0.1076378510850999\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.003622617805376649\n",
      "Loss on test= 0.005600627511739731\n",
      "acc for Lsat= 0.1041969960141513 \n",
      "acc for Psat= 0.09968545481873055 \n",
      "acc for optim= 0.08667592560717215\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.003585702972486615\n",
      "Loss on test= 0.005322163458913565\n",
      "acc for Lsat= 0.10995371725746533 \n",
      "acc for Psat= 0.1321274257885913 \n",
      "acc for optim= 0.11733141337107453\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.0036981054581701756\n",
      "Loss on test= 0.005457896739244461\n",
      "acc for Lsat= 0.09488865061818312 \n",
      "acc for Psat= 0.12937372762502897 \n",
      "acc for optim= 0.1064229917505549\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.0035769471433013678\n",
      "Loss on test= 0.00536418566480279\n",
      "acc for Lsat= 0.1571902778879222 \n",
      "acc for Psat= 0.1869000370821191 \n",
      "acc for optim= 0.1084329099394381\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.0038027570117264986\n",
      "Loss on test= 0.005421545822173357\n",
      "acc for Lsat= 0.08662011487305993 \n",
      "acc for Psat= 0.14238105120602995 \n",
      "acc for optim= 0.11787636540571435\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.0036052665673196316\n",
      "Loss on test= 0.005691496655344963\n",
      "acc for Lsat= 0.11029359468051957 \n",
      "acc for Psat= 0.15348121536792153 \n",
      "acc for optim= 0.09346120551021563\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.0036554113030433655\n",
      "Loss on test= 0.005325616337358952\n",
      "acc for Lsat= 0.11606611135519213 \n",
      "acc for Psat= 0.14242919641805607 \n",
      "acc for optim= 0.12217941338894889\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.003532782895490527\n",
      "Loss on test= 0.005501204635947943\n",
      "acc for Lsat= 0.13036988579875064 \n",
      "acc for Psat= 0.0965736507722694 \n",
      "acc for optim= 0.10648803865640527\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.003872513771057129\n",
      "Loss on test= 0.005401779431849718\n",
      "acc for Lsat= 0.10773144646858175 \n",
      "acc for Psat= 0.11429636656410164 \n",
      "acc for optim= 0.10486093070358038\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.0038465962279587984\n",
      "Loss on test= 0.005267332307994366\n",
      "acc for Lsat= 0.0986727187409997 \n",
      "acc for Psat= 0.17752550169825554 \n",
      "acc for optim= 0.10394299964213537\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.003636770648881793\n",
      "Loss on test= 0.005693898070603609\n",
      "acc for Lsat= 0.12267457751699516 \n",
      "acc for Psat= 0.14305748048031497 \n",
      "acc for optim= 0.10447584811805023\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.0035595125518739223\n",
      "Loss on test= 0.0054787625558674335\n",
      "acc for Lsat= 0.08481426481416242 \n",
      "acc for Psat= 0.12046803575423029 \n",
      "acc for optim= 0.11981600819854066\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.00367002934217453\n",
      "Loss on test= 0.005590863525867462\n",
      "acc for Lsat= 0.06878103227871987 \n",
      "acc for Psat= 0.13216691324487329 \n",
      "acc for optim= 0.08650375033418338\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.003502762410789728\n",
      "Loss on test= 0.005157072097063065\n",
      "acc for Lsat= 0.13022620681052408 \n",
      "acc for Psat= 0.17347205782102215 \n",
      "acc for optim= 0.14801604411331937\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.0037231571041047573\n",
      "Loss on test= 0.00572052039206028\n",
      "acc for Lsat= 0.09848540920453767 \n",
      "acc for Psat= 0.17047614392100108 \n",
      "acc for optim= 0.11893339108468758\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.003679673420265317\n",
      "Loss on test= 0.005475129000842571\n",
      "acc for Lsat= 0.1330939942660431 \n",
      "acc for Psat= 0.13987032882869244 \n",
      "acc for optim= 0.09895029689909683\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.0036270057316869497\n",
      "Loss on test= 0.005210554227232933\n",
      "acc for Lsat= 0.08818586579420501 \n",
      "acc for Psat= 0.15441844126002657 \n",
      "acc for optim= 0.11720258282083604\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.0036205716896802187\n",
      "Loss on test= 0.005319222807884216\n",
      "acc for Lsat= 0.10105581376895618 \n",
      "acc for Psat= 0.1405124309886661 \n",
      "acc for optim= 0.10734006617632177\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.003587236162275076\n",
      "Loss on test= 0.005461774300783873\n",
      "acc for Lsat= 0.12183974114446351 \n",
      "acc for Psat= 0.13326682706570459 \n",
      "acc for optim= 0.12956277024932206\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.0037013874389231205\n",
      "Loss on test= 0.005455684382468462\n",
      "acc for Lsat= 0.11114733276513612 \n",
      "acc for Psat= 0.1666736662737094 \n",
      "acc for optim= 0.10873136177865995\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.00362856755964458\n",
      "Loss on test= 0.005358915310353041\n",
      "acc for Lsat= 0.13080177396639353 \n",
      "acc for Psat= 0.09466593826396598 \n",
      "acc for optim= 0.11973110800156267\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.0034735267981886864\n",
      "Loss on test= 0.0055500417947769165\n",
      "acc for Lsat= 0.11512006829596227 \n",
      "acc for Psat= 0.17102224498780239 \n",
      "acc for optim= 0.12046946600700419\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.003659452311694622\n",
      "Loss on test= 0.005599355325102806\n",
      "acc for Lsat= 0.09925954116301404 \n",
      "acc for Psat= 0.11243023136760005 \n",
      "acc for optim= 0.1014711170638394\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.0037641883827745914\n",
      "Loss on test= 0.00530509976670146\n",
      "acc for Lsat= 0.09642769861966372 \n",
      "acc for Psat= 0.12731648800480697 \n",
      "acc for optim= 0.12145486794826058\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.0036376214120537043\n",
      "Loss on test= 0.005876947194337845\n",
      "acc for Lsat= 0.10406443626723355 \n",
      "acc for Psat= 0.15229319532712302 \n",
      "acc for optim= 0.1413766040156285\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.0036812149919569492\n",
      "Loss on test= 0.005524092819541693\n",
      "acc for Lsat= 0.12066309386864305 \n",
      "acc for Psat= 0.16444624743113914 \n",
      "acc for optim= 0.1278622441718148\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.0035080546513199806\n",
      "Loss on test= 0.005484650377184153\n",
      "acc for Lsat= 0.11271969373855326 \n",
      "acc for Psat= 0.15016450295742187 \n",
      "acc for optim= 0.12822666458992493\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.0036141714081168175\n",
      "Loss on test= 0.0053588515147566795\n",
      "acc for Lsat= 0.15018188150133938 \n",
      "acc for Psat= 0.10909642738988623 \n",
      "acc for optim= 0.11688599342273341\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.0035495872143656015\n",
      "Loss on test= 0.005378623493015766\n",
      "acc for Lsat= 0.11934337257925007 \n",
      "acc for Psat= 0.16483798780892459 \n",
      "acc for optim= 0.10321739572100341\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.00363723561167717\n",
      "Loss on test= 0.0056694126687943935\n",
      "acc for Lsat= 0.0971813980561112 \n",
      "acc for Psat= 0.16924434507058728 \n",
      "acc for optim= 0.10832639411091805\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.0036174082197248936\n",
      "Loss on test= 0.005429462529718876\n",
      "acc for Lsat= 0.11520922841737047 \n",
      "acc for Psat= 0.13359498200265485 \n",
      "acc for optim= 0.10078044178792173\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.003622984979301691\n",
      "Loss on test= 0.005267898086458445\n",
      "acc for Lsat= 0.09720622438989165 \n",
      "acc for Psat= 0.1250676863322345 \n",
      "acc for optim= 0.126878287203403\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.0035783492494374514\n",
      "Loss on test= 0.005416732747107744\n",
      "acc for Lsat= 0.1318446724552713 \n",
      "acc for Psat= 0.19186024274677038 \n",
      "acc for optim= 0.1065645703735451\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.0037886714562773705\n",
      "Loss on test= 0.005026991944760084\n",
      "acc for Lsat= 0.1335100485270636 \n",
      "acc for Psat= 0.14558128557271427 \n",
      "acc for optim= 0.16520897407705584\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.00340325222350657\n",
      "Loss on test= 0.005229185800999403\n",
      "acc for Lsat= 0.10096195065933797 \n",
      "acc for Psat= 0.16092632757499814 \n",
      "acc for optim= 0.08744052988994452\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.0035695796832442284\n",
      "Loss on test= 0.005761554464697838\n",
      "acc for Lsat= 0.12974250694322917 \n",
      "acc for Psat= 0.15031656472840244 \n",
      "acc for optim= 0.1363753906658126\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.003643079660832882\n",
      "Loss on test= 0.005552529823035002\n",
      "acc for Lsat= 0.12150475992691806 \n",
      "acc for Psat= 0.19284417242225674 \n",
      "acc for optim= 0.1083255937943856\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.0034913262352347374\n",
      "Loss on test= 0.0055524203926324844\n",
      "acc for Lsat= 0.1284759249796884 \n",
      "acc for Psat= 0.13527332567092445 \n",
      "acc for optim= 0.10058235947346678\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.0037048093508929014\n",
      "Loss on test= 0.005834341514855623\n",
      "acc for Lsat= 0.1010496783354837 \n",
      "acc for Psat= 0.15081376339205438 \n",
      "acc for optim= 0.10890301181805423\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.003646434750407934\n",
      "Loss on test= 0.004961597733199596\n",
      "acc for Lsat= 0.08792200754396617 \n",
      "acc for Psat= 0.12525595355934152 \n",
      "acc for optim= 0.09421108431544983\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.0036582923494279385\n",
      "Loss on test= 0.005628677085042\n",
      "acc for Lsat= 0.12600332335568964 \n",
      "acc for Psat= 0.13271675791798365 \n",
      "acc for optim= 0.11221397282659179\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.0035459662321954966\n",
      "Loss on test= 0.004920936189591885\n",
      "acc for Lsat= 0.11226206914418274 \n",
      "acc for Psat= 0.1047549081267789 \n",
      "acc for optim= 0.12677448667171928\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.0035402856301516294\n",
      "Loss on test= 0.005597875453531742\n",
      "acc for Lsat= 0.155579902128213 \n",
      "acc for Psat= 0.12912691017198893 \n",
      "acc for optim= 0.1239076447673142\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.0037309215404093266\n",
      "Loss on test= 0.005524033680558205\n",
      "acc for Lsat= 0.12080812060998546 \n",
      "acc for Psat= 0.13914923168097934 \n",
      "acc for optim= 0.09477326734405425\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.0037828811910003424\n",
      "Loss on test= 0.005257570184767246\n",
      "acc for Lsat= 0.11901875789691177 \n",
      "acc for Psat= 0.12125121129469739 \n",
      "acc for optim= 0.1245708576300078\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.0035796912852674723\n",
      "Loss on test= 0.005835201591253281\n",
      "acc for Lsat= 0.13672023833108446 \n",
      "acc for Psat= 0.1439329257183191 \n",
      "acc for optim= 0.10425623345913158\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.0036441413685679436\n",
      "Loss on test= 0.005236256867647171\n",
      "acc for Lsat= 0.13470170237512016 \n",
      "acc for Psat= 0.11455642794155413 \n",
      "acc for optim= 0.11916577722877264\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.0036265822127461433\n",
      "Loss on test= 0.005062769167125225\n",
      "acc for Lsat= 0.10770633922786349 \n",
      "acc for Psat= 0.2217014608387318 \n",
      "acc for optim= 0.14295244372139373\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.003735376987606287\n",
      "Loss on test= 0.0052245864644646645\n",
      "acc for Lsat= 0.15298766436171718 \n",
      "acc for Psat= 0.13677615558521616 \n",
      "acc for optim= 0.10762757958016461\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.0037673444021493196\n",
      "Loss on test= 0.00557196419686079\n",
      "acc for Lsat= 0.12276336959459716 \n",
      "acc for Psat= 0.1738557623919203 \n",
      "acc for optim= 0.13188102825855216\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.003622693009674549\n",
      "Loss on test= 0.005445460788905621\n",
      "acc for Lsat= 0.12185345160671407 \n",
      "acc for Psat= 0.14139123167842627 \n",
      "acc for optim= 0.12100319476384255\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.0035091249737888575\n",
      "Loss on test= 0.00545420590788126\n",
      "acc for Lsat= 0.1159391692166941 \n",
      "acc for Psat= 0.16471298533239556 \n",
      "acc for optim= 0.10156083440718551\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.003488586749881506\n",
      "Loss on test= 0.0052382852882146835\n",
      "acc for Lsat= 0.09605645186578234 \n",
      "acc for Psat= 0.1479241690831259 \n",
      "acc for optim= 0.0900676208936299\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.00354014802724123\n",
      "Loss on test= 0.005357797257602215\n",
      "acc for Lsat= 0.11231599686046441 \n",
      "acc for Psat= 0.1383946808313744 \n",
      "acc for optim= 0.08727402351279226\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.0035468449350446463\n",
      "Loss on test= 0.005309859290719032\n",
      "acc for Lsat= 0.10316303289598888 \n",
      "acc for Psat= 0.11833923972315258 \n",
      "acc for optim= 0.09860275887573759\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.003608369966968894\n",
      "Loss on test= 0.005223358981311321\n",
      "acc for Lsat= 0.12998483262749183 \n",
      "acc for Psat= 0.14750220140235293 \n",
      "acc for optim= 0.12829809749705923\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.0036586173810064793\n",
      "Loss on test= 0.0052992235869169235\n",
      "acc for Lsat= 0.11571519237218632 \n",
      "acc for Psat= 0.1809020009305742 \n",
      "acc for optim= 0.12394807135893239\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.0035337687004357576\n",
      "Loss on test= 0.005193206947296858\n",
      "acc for Lsat= 0.10655770300784045 \n",
      "acc for Psat= 0.14799880422651768 \n",
      "acc for optim= 0.1015136854774836\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.0035169487819075584\n",
      "Loss on test= 0.005306335631757975\n",
      "acc for Lsat= 0.1470608899059395 \n",
      "acc for Psat= 0.14556220122095612 \n",
      "acc for optim= 0.11288245591438478\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.0035422660876065493\n",
      "Loss on test= 0.005502470303326845\n",
      "acc for Lsat= 0.15770062633479634 \n",
      "acc for Psat= 0.2116095879011684 \n",
      "acc for optim= 0.10988328053564247\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.0036393424961715937\n",
      "Loss on test= 0.005543263629078865\n",
      "acc for Lsat= 0.10885700976683034 \n",
      "acc for Psat= 0.11960711900610477 \n",
      "acc for optim= 0.1161711380765256\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.003472155425697565\n",
      "Loss on test= 0.005644654855132103\n",
      "acc for Lsat= 0.09456820720030616 \n",
      "acc for Psat= 0.12323794171162364 \n",
      "acc for optim= 0.10543079392260148\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.003616337664425373\n",
      "Loss on test= 0.005498848855495453\n",
      "acc for Lsat= 0.09101793552852339 \n",
      "acc for Psat= 0.1646771708296405 \n",
      "acc for optim= 0.1048310736918615\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.003690564539283514\n",
      "Loss on test= 0.005172237753868103\n",
      "acc for Lsat= 0.11682665353226993 \n",
      "acc for Psat= 0.13413904364117318 \n",
      "acc for optim= 0.0770645597949624\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.003518252167850733\n",
      "Loss on test= 0.005437842570245266\n",
      "acc for Lsat= 0.12754483233826855 \n",
      "acc for Psat= 0.14462774495283762 \n",
      "acc for optim= 0.12647248659696844\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.003509010886773467\n",
      "Loss on test= 0.005550237372517586\n",
      "acc for Lsat= 0.13863082214569053 \n",
      "acc for Psat= 0.16558439845943618 \n",
      "acc for optim= 0.12762885010387334\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.0036653929855674505\n",
      "Loss on test= 0.0051691182889044285\n",
      "acc for Lsat= 0.11178414740910132 \n",
      "acc for Psat= 0.09983967503325807 \n",
      "acc for optim= 0.10765787834922473\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.003643548581749201\n",
      "Loss on test= 0.005582986865192652\n",
      "acc for Lsat= 0.07629176130932239 \n",
      "acc for Psat= 0.11779583853462504 \n",
      "acc for optim= 0.12306523721458183\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.003570749657228589\n",
      "Loss on test= 0.005539028439670801\n",
      "acc for Lsat= 0.10104161350884372 \n",
      "acc for Psat= 0.13716681698376001 \n",
      "acc for optim= 0.10355769542770253\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.003512708004564047\n",
      "Loss on test= 0.005492097232490778\n",
      "acc for Lsat= 0.14256038346664152 \n",
      "acc for Psat= 0.1689910515366743 \n",
      "acc for optim= 0.13042790883789873\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.003592283232137561\n",
      "Loss on test= 0.005255395546555519\n",
      "acc for Lsat= 0.08497473773443037 \n",
      "acc for Psat= 0.12578141989393365 \n",
      "acc for optim= 0.13461772605983746\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.003653421765193343\n",
      "Loss on test= 0.005941134877502918\n",
      "acc for Lsat= 0.09353607693790561 \n",
      "acc for Psat= 0.10181968146935105 \n",
      "acc for optim= 0.11736033370511399\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.0035206859465688467\n",
      "Loss on test= 0.005651239305734634\n",
      "acc for Lsat= 0.09704293341686328 \n",
      "acc for Psat= 0.15620838974912962 \n",
      "acc for optim= 0.0942088600455059\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.003487013280391693\n",
      "Loss on test= 0.005526266526430845\n",
      "acc for Lsat= 0.12213112351795037 \n",
      "acc for Psat= 0.12417549220845103 \n",
      "acc for optim= 0.09649647093222787\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.003649242455139756\n",
      "Loss on test= 0.005202208645641804\n",
      "acc for Lsat= 0.10918476228188309 \n",
      "acc for Psat= 0.1600138218038612 \n",
      "acc for optim= 0.12745570132715833\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.0036575605627149343\n",
      "Loss on test= 0.005518006626516581\n",
      "acc for Lsat= 0.10609591250411338 \n",
      "acc for Psat= 0.14698298156468403 \n",
      "acc for optim= 0.11050717171100485\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.0035123229026794434\n",
      "Loss on test= 0.005549036432057619\n",
      "acc for Lsat= 0.1480278777372506 \n",
      "acc for Psat= 0.15847350979068628 \n",
      "acc for optim= 0.10344984956706564\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.003563598031178117\n",
      "Loss on test= 0.005035822745412588\n",
      "acc for Lsat= 0.10362561155084728 \n",
      "acc for Psat= 0.13802241894882172 \n",
      "acc for optim= 0.0965533086952443\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.003606531536206603\n",
      "Loss on test= 0.005353932268917561\n",
      "acc for Lsat= 0.12845779484551814 \n",
      "acc for Psat= 0.1786068285582587 \n",
      "acc for optim= 0.10323049355712202\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.003657009219750762\n",
      "Loss on test= 0.005476862657815218\n",
      "acc for Lsat= 0.12610504062872174 \n",
      "acc for Psat= 0.18340467506398758 \n",
      "acc for optim= 0.13337234818997482\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.0035606310702860355\n",
      "Loss on test= 0.005561721511185169\n",
      "acc for Lsat= 0.11408611656063133 \n",
      "acc for Psat= 0.09564150749550511 \n",
      "acc for optim= 0.08053983388365143\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.0035196205135434866\n",
      "Loss on test= 0.0051157716661691666\n",
      "acc for Lsat= 0.12432402092963457 \n",
      "acc for Psat= 0.11831581747780244 \n",
      "acc for optim= 0.10506447213184503\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.0035195311065763235\n",
      "Loss on test= 0.005523150786757469\n",
      "acc for Lsat= 0.13468583699108827 \n",
      "acc for Psat= 0.14533894748375234 \n",
      "acc for optim= 0.11069117848011148\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.00371441338211298\n",
      "Loss on test= 0.0053994604386389256\n",
      "acc for Lsat= 0.08721649527756704 \n",
      "acc for Psat= 0.11725223256507888 \n",
      "acc for optim= 0.12653324646978742\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.0034543441142886877\n",
      "Loss on test= 0.005567715037614107\n",
      "acc for Lsat= 0.09523179211343329 \n",
      "acc for Psat= 0.1030667713655728 \n",
      "acc for optim= 0.10502316046040505\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.00359679595567286\n",
      "Loss on test= 0.005494576878845692\n",
      "acc for Lsat= 0.09864700841717422 \n",
      "acc for Psat= 0.12042724118348108 \n",
      "acc for optim= 0.08298956645335744\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.0035853153094649315\n",
      "Loss on test= 0.005328285042196512\n",
      "acc for Lsat= 0.12140523393948872 \n",
      "acc for Psat= 0.13074125121865007 \n",
      "acc for optim= 0.13844717065795623\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.0035731217358261347\n",
      "Loss on test= 0.00545080192387104\n",
      "acc for Lsat= 0.10414656789766417 \n",
      "acc for Psat= 0.12705344810254043 \n",
      "acc for optim= 0.11513825527961469\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.003622322343289852\n",
      "Loss on test= 0.00545344315469265\n",
      "acc for Lsat= 0.12645600580920777 \n",
      "acc for Psat= 0.14666928068941665 \n",
      "acc for optim= 0.11821575545602375\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.0035536913201212883\n",
      "Loss on test= 0.005562250968068838\n",
      "acc for Lsat= 0.10297093806891805 \n",
      "acc for Psat= 0.15239100352401794 \n",
      "acc for optim= 0.12410104590364629\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.0035008429549634457\n",
      "Loss on test= 0.0054432000033557415\n",
      "acc for Lsat= 0.144270367299517 \n",
      "acc for Psat= 0.13608646977485883 \n",
      "acc for optim= 0.09658779038323297\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.003512886120006442\n",
      "Loss on test= 0.005612041801214218\n",
      "acc for Lsat= 0.07797729437233 \n",
      "acc for Psat= 0.1499175485999634 \n",
      "acc for optim= 0.08131281620201965\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.0034440679010003805\n",
      "Loss on test= 0.005242183804512024\n",
      "acc for Lsat= 0.1275639900995884 \n",
      "acc for Psat= 0.16046994568831804 \n",
      "acc for optim= 0.1006481670257118\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.0034866132773458958\n",
      "Loss on test= 0.0055761393159627914\n",
      "acc for Lsat= 0.12021855911653903 \n",
      "acc for Psat= 0.1120688203567018 \n",
      "acc for optim= 0.0933902872687516\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.003780191298574209\n",
      "Loss on test= 0.005405034404247999\n",
      "acc for Lsat= 0.13257830548617575 \n",
      "acc for Psat= 0.13835892722838455 \n",
      "acc for optim= 0.0962245280130042\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.003485686844214797\n",
      "Loss on test= 0.00596926175057888\n",
      "acc for Lsat= 0.06993996320913236 \n",
      "acc for Psat= 0.11654445647986399 \n",
      "acc for optim= 0.1274686339828703\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.003586794249713421\n",
      "Loss on test= 0.0056177228689193726\n",
      "acc for Lsat= 0.11467829153924766 \n",
      "acc for Psat= 0.13901265195777845 \n",
      "acc for optim= 0.09913862936405672\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.00351880700327456\n",
      "Loss on test= 0.005401092115789652\n",
      "acc for Lsat= 0.12085020562840833 \n",
      "acc for Psat= 0.17822652377395165 \n",
      "acc for optim= 0.10516504175545076\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.0036463497672230005\n",
      "Loss on test= 0.005409056320786476\n",
      "acc for Lsat= 0.09628562981055842 \n",
      "acc for Psat= 0.14585753271563184 \n",
      "acc for optim= 0.12219461726231708\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.0035426842514425516\n",
      "Loss on test= 0.0054267100058496\n",
      "acc for Lsat= 0.10515615860559693 \n",
      "acc for Psat= 0.1461521600269609 \n",
      "acc for optim= 0.15910767443064186\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.003550321562215686\n",
      "Loss on test= 0.0058336989022791386\n",
      "acc for Lsat= 0.12365520807603995 \n",
      "acc for Psat= 0.17444673377192682 \n",
      "acc for optim= 0.11171258349592487\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.0036742030642926693\n",
      "Loss on test= 0.005305493716150522\n",
      "acc for Lsat= 0.10142803113396642 \n",
      "acc for Psat= 0.1095235384742005 \n",
      "acc for optim= 0.09665777580812573\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.0035584806464612484\n",
      "Loss on test= 0.005336764734238386\n",
      "acc for Lsat= 0.10562199944009383 \n",
      "acc for Psat= 0.14010930682222048 \n",
      "acc for optim= 0.10997248591027325\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.0035519986413419247\n",
      "Loss on test= 0.005319829564541578\n",
      "acc for Lsat= 0.16965270756433407 \n",
      "acc for Psat= 0.16575650855277976 \n",
      "acc for optim= 0.10185955279868925\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.0035613735672086477\n",
      "Loss on test= 0.005521615967154503\n",
      "acc for Lsat= 0.119747347301907 \n",
      "acc for Psat= 0.15698368329968718 \n",
      "acc for optim= 0.09235935741000706\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.003489304566755891\n",
      "Loss on test= 0.005624315235763788\n",
      "acc for Lsat= 0.11417607137829894 \n",
      "acc for Psat= 0.12958170701232222 \n",
      "acc for optim= 0.11752020095526758\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.0035743629559874535\n",
      "Loss on test= 0.0053071435540914536\n",
      "acc for Lsat= 0.08710303359354536 \n",
      "acc for Psat= 0.1570088167467879 \n",
      "acc for optim= 0.12291245472927888\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.003533884882926941\n",
      "Loss on test= 0.005819536745548248\n",
      "acc for Lsat= 0.12500622082087728 \n",
      "acc for Psat= 0.14379707061582142 \n",
      "acc for optim= 0.14248721286033592\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.0037310225889086723\n",
      "Loss on test= 0.0053390031680464745\n",
      "acc for Lsat= 0.1287295795045793 \n",
      "acc for Psat= 0.151533928906752 \n",
      "acc for optim= 0.09888947643857035\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.00359939131885767\n",
      "Loss on test= 0.005254446994513273\n",
      "acc for Lsat= 0.1123955700895749 \n",
      "acc for Psat= 0.12603683931390858 \n",
      "acc for optim= 0.12591289025213984\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.0034348266199231148\n",
      "Loss on test= 0.005516757257282734\n",
      "acc for Lsat= 0.09738683638473351 \n",
      "acc for Psat= 0.16846326466960213 \n",
      "acc for optim= 0.12889197996507087\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.0035990846808999777\n",
      "Loss on test= 0.00558359595015645\n",
      "acc for Lsat= 0.12082657225740452 \n",
      "acc for Psat= 0.1086520585231483 \n",
      "acc for optim= 0.12237683445629147\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.003543341066688299\n",
      "Loss on test= 0.005189566407352686\n",
      "acc for Lsat= 0.11598784179012808 \n",
      "acc for Psat= 0.16261459982747006 \n",
      "acc for optim= 0.11800094991404977\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.00350321177393198\n",
      "Loss on test= 0.005394031759351492\n",
      "acc for Lsat= 0.12463668495830563 \n",
      "acc for Psat= 0.13149110895271102 \n",
      "acc for optim= 0.12884529253157476\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.003387250704690814\n",
      "Loss on test= 0.005453997757285833\n",
      "acc for Lsat= 0.13486826655247974 \n",
      "acc for Psat= 0.13332228502258658 \n",
      "acc for optim= 0.11160533622993778\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.0036705804523080587\n",
      "Loss on test= 0.005209301132708788\n",
      "acc for Lsat= 0.10336288879625499 \n",
      "acc for Psat= 0.1217902777199116 \n",
      "acc for optim= 0.10963107583423455\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.0036884925793856382\n",
      "Loss on test= 0.005646254401654005\n",
      "acc for Lsat= 0.12951986708988747 \n",
      "acc for Psat= 0.16158487647771835 \n",
      "acc for optim= 0.11241209791559312\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.00343800475820899\n",
      "Loss on test= 0.005556856282055378\n",
      "acc for Lsat= 0.11233529852082332 \n",
      "acc for Psat= 0.1306057582842186 \n",
      "acc for optim= 0.14334399899881747\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.0034867918584495783\n",
      "Loss on test= 0.005607709754258394\n",
      "acc for Lsat= 0.08894269204595023 \n",
      "acc for Psat= 0.14656385199891198 \n",
      "acc for optim= 0.13526530589701402\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.003577395575121045\n",
      "Loss on test= 0.005640731193125248\n",
      "acc for Lsat= 0.09793378133326769 \n",
      "acc for Psat= 0.11018091189907864 \n",
      "acc for optim= 0.0787643884929518\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.0033729621209204197\n",
      "Loss on test= 0.00552755780518055\n",
      "acc for Lsat= 0.15200008244978058 \n",
      "acc for Psat= 0.1140434697477354 \n",
      "acc for optim= 0.11349081022975345\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.003493718570098281\n",
      "Loss on test= 0.005319611169397831\n",
      "acc for Lsat= 0.12661489389008945 \n",
      "acc for Psat= 0.14417590480297804 \n",
      "acc for optim= 0.10921551007777452\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.0035397768951952457\n",
      "Loss on test= 0.005503398831933737\n",
      "acc for Lsat= 0.12027686273601527 \n",
      "acc for Psat= 0.13035922037023637 \n",
      "acc for optim= 0.1350565171904034\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.003465983085334301\n",
      "Loss on test= 0.00557556701824069\n",
      "acc for Lsat= 0.08883473108936515 \n",
      "acc for Psat= 0.13219114330584286 \n",
      "acc for optim= 0.14177702563918299\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.003523938124999404\n",
      "Loss on test= 0.005490800831466913\n",
      "acc for Lsat= 0.12673174023317793 \n",
      "acc for Psat= 0.17841565348984054 \n",
      "acc for optim= 0.11659193320924209\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.003499816171824932\n",
      "Loss on test= 0.004990153480321169\n",
      "acc for Lsat= 0.12443465398003657 \n",
      "acc for Psat= 0.13707687819583547 \n",
      "acc for optim= 0.11790701987532277\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.0034818099811673164\n",
      "Loss on test= 0.005249685607850552\n",
      "acc for Lsat= 0.11848415508090208 \n",
      "acc for Psat= 0.12271330552175641 \n",
      "acc for optim= 0.10859401280888253\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.003504189196974039\n",
      "Loss on test= 0.005281401332467794\n",
      "acc for Lsat= 0.09334262237987584 \n",
      "acc for Psat= 0.15742777422484425 \n",
      "acc for optim= 0.09906129286779712\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.003568245330825448\n",
      "Loss on test= 0.005323102697730064\n",
      "acc for Lsat= 0.08990128196698303 \n",
      "acc for Psat= 0.13053210343544683 \n",
      "acc for optim= 0.1122572138103553\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.003546187886968255\n",
      "Loss on test= 0.005467754788696766\n",
      "acc for Lsat= 0.14348551092876327 \n",
      "acc for Psat= 0.1321539015043527 \n",
      "acc for optim= 0.1253050617977149\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.0034695626236498356\n",
      "Loss on test= 0.0055269841104745865\n",
      "acc for Lsat= 0.06941026221546862 \n",
      "acc for Psat= 0.16748848003852698 \n",
      "acc for optim= 0.13529962738458481\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.0035201816353946924\n",
      "Loss on test= 0.00542786531150341\n",
      "acc for Lsat= 0.1418410383711388 \n",
      "acc for Psat= 0.13168290448892447 \n",
      "acc for optim= 0.09743510145280096\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.003423377638682723\n",
      "Loss on test= 0.005469656549394131\n",
      "acc for Lsat= 0.12579245265159342 \n",
      "acc for Psat= 0.13961462834332553 \n",
      "acc for optim= 0.10637872327222592\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.0034673758782446384\n",
      "Loss on test= 0.005585851613432169\n",
      "acc for Lsat= 0.1147650931444433 \n",
      "acc for Psat= 0.16494847859980333 \n",
      "acc for optim= 0.12088425053904454\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.0035431692376732826\n",
      "Loss on test= 0.005437157116830349\n",
      "acc for Lsat= 0.08206095484395821 \n",
      "acc for Psat= 0.1177786862091226 \n",
      "acc for optim= 0.0951896760816453\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.003415326587855816\n",
      "Loss on test= 0.005424053408205509\n",
      "acc for Lsat= 0.09035353813346268 \n",
      "acc for Psat= 0.15517429495230317 \n",
      "acc for optim= 0.13644215914731225\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.0034462353214621544\n",
      "Loss on test= 0.0053077018819749355\n",
      "acc for Lsat= 0.149749794561002 \n",
      "acc for Psat= 0.16835838170825607 \n",
      "acc for optim= 0.0992480130193548\n",
      "Fold 3\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.07478843629360199\n",
      "Loss on test= 0.03306778147816658\n",
      "acc for Lsat= 0.5639131727317969 \n",
      "acc for Psat= 0.6748431151111921 \n",
      "acc for optim= 0.24426707956526014\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.028729164972901344\n",
      "Loss on test= 0.021664494648575783\n",
      "acc for Lsat= 0.38577976709024775 \n",
      "acc for Psat= 0.6165448889757196 \n",
      "acc for optim= 0.24111628801458412\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.022865237668156624\n",
      "Loss on test= 0.02276439219713211\n",
      "acc for Lsat= 0.4177444879379537 \n",
      "acc for Psat= 0.6034474019478593 \n",
      "acc for optim= 0.12001359945861623\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.02260282076895237\n",
      "Loss on test= 0.01972297579050064\n",
      "acc for Lsat= 0.38319269174502957 \n",
      "acc for Psat= 0.31874085230649346 \n",
      "acc for optim= 0.12385714672402376\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.020008286461234093\n",
      "Loss on test= 0.01926891878247261\n",
      "acc for Lsat= 0.38743959305187065 \n",
      "acc for Psat= 0.4687029715213511 \n",
      "acc for optim= 0.15403035678900778\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.01936393417418003\n",
      "Loss on test= 0.018884025514125824\n",
      "acc for Lsat= 0.34030870881138575 \n",
      "acc for Psat= 0.5182025122145811 \n",
      "acc for optim= 0.16048612093759906\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.018355727195739746\n",
      "Loss on test= 0.015568370930850506\n",
      "acc for Lsat= 0.3947518343726794 \n",
      "acc for Psat= 0.34161653868957526 \n",
      "acc for optim= 0.16226444310612148\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.018126970157027245\n",
      "Loss on test= 0.01624385267496109\n",
      "acc for Lsat= 0.3727524696538846 \n",
      "acc for Psat= 0.38125458846075666 \n",
      "acc for optim= 0.13199048173717326\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.016913611441850662\n",
      "Loss on test= 0.015212029218673706\n",
      "acc for Lsat= 0.42200528320649433 \n",
      "acc for Psat= 0.3539918193386661 \n",
      "acc for optim= 0.14331994672668064\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.01655358262360096\n",
      "Loss on test= 0.015035871416330338\n",
      "acc for Lsat= 0.38659408709241283 \n",
      "acc for Psat= 0.44104843338330585 \n",
      "acc for optim= 0.17236740531451586\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.017096223309636116\n",
      "Loss on test= 0.01381668820977211\n",
      "acc for Lsat= 0.19426250654376215 \n",
      "acc for Psat= 0.3042360059916973 \n",
      "acc for optim= 0.14745624653167194\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.015912316739559174\n",
      "Loss on test= 0.014706394635140896\n",
      "acc for Lsat= 0.339170031197783 \n",
      "acc for Psat= 0.4718802178071605 \n",
      "acc for optim= 0.18319856419434977\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.015911217778921127\n",
      "Loss on test= 0.013173645362257957\n",
      "acc for Lsat= 0.3542584980015009 \n",
      "acc for Psat= 0.3582885296653128 \n",
      "acc for optim= 0.15464907398240435\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.01627158932387829\n",
      "Loss on test= 0.013998348265886307\n",
      "acc for Lsat= 0.3065597042441368 \n",
      "acc for Psat= 0.223740021387736 \n",
      "acc for optim= 0.13716879593104953\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.015743030235171318\n",
      "Loss on test= 0.01358127687126398\n",
      "acc for Lsat= 0.31529767262852854 \n",
      "acc for Psat= 0.2943097095315655 \n",
      "acc for optim= 0.14241420316587514\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.015477219596505165\n",
      "Loss on test= 0.013070070184767246\n",
      "acc for Lsat= 0.34608596625427407 \n",
      "acc for Psat= 0.38488544518541956 \n",
      "acc for optim= 0.1226950506421013\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.014851721934974194\n",
      "Loss on test= 0.013180669397115707\n",
      "acc for Lsat= 0.41947446839508806 \n",
      "acc for Psat= 0.34765834361314774 \n",
      "acc for optim= 0.1461165426298976\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.01503019966185093\n",
      "Loss on test= 0.01408998854458332\n",
      "acc for Lsat= 0.3171379533078935 \n",
      "acc for Psat= 0.2515620724039359 \n",
      "acc for optim= 0.15587160074048573\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.015156381763517857\n",
      "Loss on test= 0.014178412035107613\n",
      "acc for Lsat= 0.2727586921213919 \n",
      "acc for Psat= 0.3895318504008982 \n",
      "acc for optim= 0.13972073089906997\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.014554091729223728\n",
      "Loss on test= 0.013440369628369808\n",
      "acc for Lsat= 0.3326176491876443 \n",
      "acc for Psat= 0.2944203032594588 \n",
      "acc for optim= 0.14425499747610754\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.014599844813346863\n",
      "Loss on test= 0.012731784954667091\n",
      "acc for Lsat= 0.32518437173631454 \n",
      "acc for Psat= 0.3489223517891433 \n",
      "acc for optim= 0.14272651580298165\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.015263337641954422\n",
      "Loss on test= 0.012545020319521427\n",
      "acc for Lsat= 0.2815061247027997 \n",
      "acc for Psat= 0.380494133879741 \n",
      "acc for optim= 0.19989270127067962\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.014431774616241455\n",
      "Loss on test= 0.01211610995233059\n",
      "acc for Lsat= 0.25907397440945107 \n",
      "acc for Psat= 0.29398482567113304 \n",
      "acc for optim= 0.16258792087642682\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.013896385207772255\n",
      "Loss on test= 0.01255150604993105\n",
      "acc for Lsat= 0.2576776923896331 \n",
      "acc for Psat= 0.3378644236880872 \n",
      "acc for optim= 0.14429747227889797\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.014109447598457336\n",
      "Loss on test= 0.011903082951903343\n",
      "acc for Lsat= 0.3210552964980404 \n",
      "acc for Psat= 0.2959762557099263 \n",
      "acc for optim= 0.15028684669070774\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.01388067938387394\n",
      "Loss on test= 0.013012636452913284\n",
      "acc for Lsat= 0.28196670327128637 \n",
      "acc for Psat= 0.3622682460894187 \n",
      "acc for optim= 0.17162350601413184\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.013792016543447971\n",
      "Loss on test= 0.012436684221029282\n",
      "acc for Lsat= 0.26714906267200905 \n",
      "acc for Psat= 0.30556379486289287 \n",
      "acc for optim= 0.15715020995574175\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.01357249915599823\n",
      "Loss on test= 0.011663743294775486\n",
      "acc for Lsat= 0.28330865988714826 \n",
      "acc for Psat= 0.36477084463048315 \n",
      "acc for optim= 0.16142766508791181\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.013803503476083279\n",
      "Loss on test= 0.011715521104633808\n",
      "acc for Lsat= 0.36423074785206055 \n",
      "acc for Psat= 0.29802462745768327 \n",
      "acc for optim= 0.1719035943193982\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.013651075772941113\n",
      "Loss on test= 0.012920340523123741\n",
      "acc for Lsat= 0.30325682782050634 \n",
      "acc for Psat= 0.3361119358903832 \n",
      "acc for optim= 0.15524446959089902\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.013693234883248806\n",
      "Loss on test= 0.01168029848486185\n",
      "acc for Lsat= 0.22768572945561674 \n",
      "acc for Psat= 0.39163178991940284 \n",
      "acc for optim= 0.19493023383741578\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.013592502102255821\n",
      "Loss on test= 0.011242032051086426\n",
      "acc for Lsat= 0.2849829861273368 \n",
      "acc for Psat= 0.3215369001651804 \n",
      "acc for optim= 0.16503883551599252\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.013602512888610363\n",
      "Loss on test= 0.012391307391226292\n",
      "acc for Lsat= 0.26772779495351845 \n",
      "acc for Psat= 0.3199267766127984 \n",
      "acc for optim= 0.14495903049181733\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.013543710112571716\n",
      "Loss on test= 0.01097166072577238\n",
      "acc for Lsat= 0.3326997099858191 \n",
      "acc for Psat= 0.37580919286443126 \n",
      "acc for optim= 0.1465771231127696\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.01353254821151495\n",
      "Loss on test= 0.01109040156006813\n",
      "acc for Lsat= 0.3664155381007327 \n",
      "acc for Psat= 0.33092187334679896 \n",
      "acc for optim= 0.15844370859364668\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.01332373358309269\n",
      "Loss on test= 0.012211104854941368\n",
      "acc for Lsat= 0.34268954520424205 \n",
      "acc for Psat= 0.3262079876666475 \n",
      "acc for optim= 0.1446452343241415\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.01347210630774498\n",
      "Loss on test= 0.010962428525090218\n",
      "acc for Lsat= 0.2798967652229799 \n",
      "acc for Psat= 0.3553585869570573 \n",
      "acc for optim= 0.19973801707641947\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.01276771817356348\n",
      "Loss on test= 0.010755643248558044\n",
      "acc for Lsat= 0.23881334834732115 \n",
      "acc for Psat= 0.31224628173125285 \n",
      "acc for optim= 0.17653745681875282\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.012559891678392887\n",
      "Loss on test= 0.011190922930836678\n",
      "acc for Lsat= 0.28568581502056783 \n",
      "acc for Psat= 0.34570664415756863 \n",
      "acc for optim= 0.16575003176694736\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.012735492549836636\n",
      "Loss on test= 0.010544083081185818\n",
      "acc for Lsat= 0.39585566942373085 \n",
      "acc for Psat= 0.2671947316783998 \n",
      "acc for optim= 0.13796825414626962\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.01217923779040575\n",
      "Loss on test= 0.011298181489109993\n",
      "acc for Lsat= 0.29535658347109955 \n",
      "acc for Psat= 0.2618545809139808 \n",
      "acc for optim= 0.17006865619785255\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.012656834907829762\n",
      "Loss on test= 0.009875502437353134\n",
      "acc for Lsat= 0.26085521761948866 \n",
      "acc for Psat= 0.40976489645739395 \n",
      "acc for optim= 0.1461861379082418\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.012710602022707462\n",
      "Loss on test= 0.010750367306172848\n",
      "acc for Lsat= 0.30256375090943444 \n",
      "acc for Psat= 0.27675797130602103 \n",
      "acc for optim= 0.14976166629478233\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.012188103049993515\n",
      "Loss on test= 0.009688496589660645\n",
      "acc for Lsat= 0.26404854588003623 \n",
      "acc for Psat= 0.32519722719573313 \n",
      "acc for optim= 0.14712508086166862\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.011975460685789585\n",
      "Loss on test= 0.010686693713068962\n",
      "acc for Lsat= 0.3487011254377042 \n",
      "acc for Psat= 0.2617666977716403 \n",
      "acc for optim= 0.1517946577094133\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.012111824005842209\n",
      "Loss on test= 0.010179935023188591\n",
      "acc for Lsat= 0.3207311029028561 \n",
      "acc for Psat= 0.2728686135960743 \n",
      "acc for optim= 0.1541896790214297\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.0122122997418046\n",
      "Loss on test= 0.009734400548040867\n",
      "acc for Lsat= 0.25042021667791736 \n",
      "acc for Psat= 0.30728641868982876 \n",
      "acc for optim= 0.13457275125094587\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.011962401680648327\n",
      "Loss on test= 0.01004882249981165\n",
      "acc for Lsat= 0.24996453378763464 \n",
      "acc for Psat= 0.28857493597186273 \n",
      "acc for optim= 0.1470153775687019\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.011716645210981369\n",
      "Loss on test= 0.010184925980865955\n",
      "acc for Lsat= 0.24576631540225613 \n",
      "acc for Psat= 0.29009616111094755 \n",
      "acc for optim= 0.14091027176214588\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.01158398762345314\n",
      "Loss on test= 0.010189885273575783\n",
      "acc for Lsat= 0.2098999380444487 \n",
      "acc for Psat= 0.3022727242463993 \n",
      "acc for optim= 0.15771565187282655\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.011717601679265499\n",
      "Loss on test= 0.012384552508592606\n",
      "acc for Lsat= 0.2738481579451925 \n",
      "acc for Psat= 0.3371851490293112 \n",
      "acc for optim= 0.12370216267623214\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.01236496027559042\n",
      "Loss on test= 0.010486050508916378\n",
      "acc for Lsat= 0.26821280767520267 \n",
      "acc for Psat= 0.3304691681017478 \n",
      "acc for optim= 0.16402881900365981\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.011463419534265995\n",
      "Loss on test= 0.010333019308745861\n",
      "acc for Lsat= 0.29913471618460286 \n",
      "acc for Psat= 0.33979493338200784 \n",
      "acc for optim= 0.13830868535054228\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.011875190772116184\n",
      "Loss on test= 0.009944381192326546\n",
      "acc for Lsat= 0.1848688667329649 \n",
      "acc for Psat= 0.23081062123593357 \n",
      "acc for optim= 0.16089148902230793\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.011243880726397038\n",
      "Loss on test= 0.008832739666104317\n",
      "acc for Lsat= 0.28094456738067997 \n",
      "acc for Psat= 0.3481826184886611 \n",
      "acc for optim= 0.14653922979616457\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.01169640477746725\n",
      "Loss on test= 0.010115108452737331\n",
      "acc for Lsat= 0.26785981344679993 \n",
      "acc for Psat= 0.26879528992705876 \n",
      "acc for optim= 0.1468180068768561\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.011349622160196304\n",
      "Loss on test= 0.00987422838807106\n",
      "acc for Lsat= 0.304810306070269 \n",
      "acc for Psat= 0.2750195429349939 \n",
      "acc for optim= 0.1695501329894695\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.011192364618182182\n",
      "Loss on test= 0.009568456560373306\n",
      "acc for Lsat= 0.3674813397228718 \n",
      "acc for Psat= 0.368255839165714 \n",
      "acc for optim= 0.1391963559565031\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.011369194835424423\n",
      "Loss on test= 0.0095992935821414\n",
      "acc for Lsat= 0.24555459804832935 \n",
      "acc for Psat= 0.3654984194112735 \n",
      "acc for optim= 0.1447598895821203\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.011742223054170609\n",
      "Loss on test= 0.009211346507072449\n",
      "acc for Lsat= 0.27137965046697193 \n",
      "acc for Psat= 0.3070261624331276 \n",
      "acc for optim= 0.13068430001537004\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.01116407010704279\n",
      "Loss on test= 0.01036764681339264\n",
      "acc for Lsat= 0.25348463075028527 \n",
      "acc for Psat= 0.2662634239014652 \n",
      "acc for optim= 0.15567085177948078\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.01135973073542118\n",
      "Loss on test= 0.009662424214184284\n",
      "acc for Lsat= 0.29320796993043685 \n",
      "acc for Psat= 0.245934790543591 \n",
      "acc for optim= 0.1279833895775179\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.010878048837184906\n",
      "Loss on test= 0.009239275939762592\n",
      "acc for Lsat= 0.21438729597462547 \n",
      "acc for Psat= 0.3031959532850629 \n",
      "acc for optim= 0.11170119072711612\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.01112942025065422\n",
      "Loss on test= 0.008980777114629745\n",
      "acc for Lsat= 0.278371883284611 \n",
      "acc for Psat= 0.2715928641458352 \n",
      "acc for optim= 0.161249534951316\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.011327879503369331\n",
      "Loss on test= 0.009357231669127941\n",
      "acc for Lsat= 0.2671149619337585 \n",
      "acc for Psat= 0.30855393244160545 \n",
      "acc for optim= 0.15385641369761693\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.011089947074651718\n",
      "Loss on test= 0.009905153885483742\n",
      "acc for Lsat= 0.26759221715231735 \n",
      "acc for Psat= 0.273622184784876 \n",
      "acc for optim= 0.1543397018685937\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.010903509333729744\n",
      "Loss on test= 0.008766399696469307\n",
      "acc for Lsat= 0.22152791803495753 \n",
      "acc for Psat= 0.26286618416715 \n",
      "acc for optim= 0.15717746855484116\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.010941751301288605\n",
      "Loss on test= 0.008679989725351334\n",
      "acc for Lsat= 0.2430493327168127 \n",
      "acc for Psat= 0.2646717060771253 \n",
      "acc for optim= 0.1532464411834048\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.010912544094026089\n",
      "Loss on test= 0.009322351776063442\n",
      "acc for Lsat= 0.283506356813531 \n",
      "acc for Psat= 0.2756073226401996 \n",
      "acc for optim= 0.13098853510907954\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.010487943887710571\n",
      "Loss on test= 0.009199545718729496\n",
      "acc for Lsat= 0.30108368976248634 \n",
      "acc for Psat= 0.3068128644178311 \n",
      "acc for optim= 0.13623901725643212\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.010733294300734997\n",
      "Loss on test= 0.008705021813511848\n",
      "acc for Lsat= 0.2964538648310635 \n",
      "acc for Psat= 0.24347168072644207 \n",
      "acc for optim= 0.14105656701657507\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.010802265256643295\n",
      "Loss on test= 0.009137780405580997\n",
      "acc for Lsat= 0.27842966420575976 \n",
      "acc for Psat= 0.3685730973051654 \n",
      "acc for optim= 0.15982228985780644\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.010777571238577366\n",
      "Loss on test= 0.008540712296962738\n",
      "acc for Lsat= 0.26899335015979076 \n",
      "acc for Psat= 0.28487791390054756 \n",
      "acc for optim= 0.14129812580843767\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.010354398749768734\n",
      "Loss on test= 0.009112748317420483\n",
      "acc for Lsat= 0.3263556982080142 \n",
      "acc for Psat= 0.31195515725347733 \n",
      "acc for optim= 0.15389525807566112\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.010512529872357845\n",
      "Loss on test= 0.009353180415928364\n",
      "acc for Lsat= 0.22668680207182965 \n",
      "acc for Psat= 0.28827378979056245 \n",
      "acc for optim= 0.17208107022775543\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.010654681362211704\n",
      "Loss on test= 0.008447517640888691\n",
      "acc for Lsat= 0.32458654774624546 \n",
      "acc for Psat= 0.23913603671826422 \n",
      "acc for optim= 0.16242488546089995\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.01040737982839346\n",
      "Loss on test= 0.009163102135062218\n",
      "acc for Lsat= 0.27929215812279534 \n",
      "acc for Psat= 0.20172647485095593 \n",
      "acc for optim= 0.13196703046560287\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.010262200608849525\n",
      "Loss on test= 0.00925034936517477\n",
      "acc for Lsat= 0.2572165941560848 \n",
      "acc for Psat= 0.19354871188342157 \n",
      "acc for optim= 0.12327769522865613\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.010580131784081459\n",
      "Loss on test= 0.010063298046588898\n",
      "acc for Lsat= 0.3372272815969255 \n",
      "acc for Psat= 0.3342758784484532 \n",
      "acc for optim= 0.12984321297456822\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.01057853177189827\n",
      "Loss on test= 0.008395649492740631\n",
      "acc for Lsat= 0.25410753436800504 \n",
      "acc for Psat= 0.30822043865919113 \n",
      "acc for optim= 0.14819161190340915\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.010243586264550686\n",
      "Loss on test= 0.008850841782987118\n",
      "acc for Lsat= 0.23090178064174122 \n",
      "acc for Psat= 0.291598792705271 \n",
      "acc for optim= 0.15312177333463398\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.010234642773866653\n",
      "Loss on test= 0.008716974407434464\n",
      "acc for Lsat= 0.286976866527564 \n",
      "acc for Psat= 0.3160212143427796 \n",
      "acc for optim= 0.1466317078512576\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.009959260001778603\n",
      "Loss on test= 0.008739521726965904\n",
      "acc for Lsat= 0.26437935502164894 \n",
      "acc for Psat= 0.23905452123532692 \n",
      "acc for optim= 0.13511384402712187\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.010217279195785522\n",
      "Loss on test= 0.009040523320436478\n",
      "acc for Lsat= 0.2582440318332778 \n",
      "acc for Psat= 0.2576655359007418 \n",
      "acc for optim= 0.12998620551338214\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.010000805370509624\n",
      "Loss on test= 0.008783871307969093\n",
      "acc for Lsat= 0.23559649914710057 \n",
      "acc for Psat= 0.34726200180335176 \n",
      "acc for optim= 0.16031783984767067\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.010492735542356968\n",
      "Loss on test= 0.009027879685163498\n",
      "acc for Lsat= 0.27259005782090956 \n",
      "acc for Psat= 0.2552736152170433 \n",
      "acc for optim= 0.16784923642666805\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.010027549229562283\n",
      "Loss on test= 0.008652182295918465\n",
      "acc for Lsat= 0.20910118504737815 \n",
      "acc for Psat= 0.24458594661619928 \n",
      "acc for optim= 0.15092239953163597\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.009670277126133442\n",
      "Loss on test= 0.008690825663506985\n",
      "acc for Lsat= 0.27076253336336875 \n",
      "acc for Psat= 0.300643007348602 \n",
      "acc for optim= 0.14789973622343192\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.009751907549798489\n",
      "Loss on test= 0.008273174986243248\n",
      "acc for Lsat= 0.23174211382865906 \n",
      "acc for Psat= 0.2790989987552166 \n",
      "acc for optim= 0.12604075784070623\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.009435621090233326\n",
      "Loss on test= 0.007978912442922592\n",
      "acc for Lsat= 0.2717519113793969 \n",
      "acc for Psat= 0.25679115323712015 \n",
      "acc for optim= 0.1418455876927409\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.009777512401342392\n",
      "Loss on test= 0.008321781642735004\n",
      "acc for Lsat= 0.3151498573521773 \n",
      "acc for Psat= 0.2584671262237761 \n",
      "acc for optim= 0.1369378092802233\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.009460756555199623\n",
      "Loss on test= 0.008547591045498848\n",
      "acc for Lsat= 0.2913677871434225 \n",
      "acc for Psat= 0.3700228115129802 \n",
      "acc for optim= 0.12963073149876436\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.009746500290930271\n",
      "Loss on test= 0.00846725795418024\n",
      "acc for Lsat= 0.24892169858018556 \n",
      "acc for Psat= 0.28707036106950706 \n",
      "acc for optim= 0.12818989074892467\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.009503386914730072\n",
      "Loss on test= 0.008913543075323105\n",
      "acc for Lsat= 0.19744037992010513 \n",
      "acc for Psat= 0.325361476590236 \n",
      "acc for optim= 0.1392663497180264\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.010099410079419613\n",
      "Loss on test= 0.008629737421870232\n",
      "acc for Lsat= 0.2518286891281605 \n",
      "acc for Psat= 0.38503867346379494 \n",
      "acc for optim= 0.12648068748724958\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.009410343132913113\n",
      "Loss on test= 0.00806472823023796\n",
      "acc for Lsat= 0.17637236980307433 \n",
      "acc for Psat= 0.2793852227429549 \n",
      "acc for optim= 0.13531755319693023\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.009424611926078796\n",
      "Loss on test= 0.009264718741178513\n",
      "acc for Lsat= 0.26121899257931447 \n",
      "acc for Psat= 0.25281961179441875 \n",
      "acc for optim= 0.12506211256711847\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.009582724422216415\n",
      "Loss on test= 0.007999159395694733\n",
      "acc for Lsat= 0.2927070488739345 \n",
      "acc for Psat= 0.27176308906766483 \n",
      "acc for optim= 0.17430127375862664\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.0093509741127491\n",
      "Loss on test= 0.007910422049462795\n",
      "acc for Lsat= 0.25382882356643677 \n",
      "acc for Psat= 0.22643648996017873 \n",
      "acc for optim= 0.12632353614187902\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.009463942609727383\n",
      "Loss on test= 0.008021887391805649\n",
      "acc for Lsat= 0.2764007029020124 \n",
      "acc for Psat= 0.27327697579231525 \n",
      "acc for optim= 0.15733391046524048\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.009272160939872265\n",
      "Loss on test= 0.007986810058355331\n",
      "acc for Lsat= 0.1641728246791495 \n",
      "acc for Psat= 0.3242981662252633 \n",
      "acc for optim= 0.1537829734540234\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.009255283512175083\n",
      "Loss on test= 0.007898597046732903\n",
      "acc for Lsat= 0.2782511762860749 \n",
      "acc for Psat= 0.25523013606046635 \n",
      "acc for optim= 0.1479957562405616\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.009056802839040756\n",
      "Loss on test= 0.007907416671514511\n",
      "acc for Lsat= 0.3636323505391677 \n",
      "acc for Psat= 0.22335854817518136 \n",
      "acc for optim= 0.12395579885277483\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.009230751544237137\n",
      "Loss on test= 0.007386838551610708\n",
      "acc for Lsat= 0.2907266868278384 \n",
      "acc for Psat= 0.29541970665256184 \n",
      "acc for optim= 0.1439534776016242\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.009391402825713158\n",
      "Loss on test= 0.008497425355017185\n",
      "acc for Lsat= 0.2646618359722197 \n",
      "acc for Psat= 0.33105947444629336 \n",
      "acc for optim= 0.14669896471120106\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.009226761758327484\n",
      "Loss on test= 0.008260746486485004\n",
      "acc for Lsat= 0.1626551042225199 \n",
      "acc for Psat= 0.2250002043050093 \n",
      "acc for optim= 0.13516379877304038\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.008690868504345417\n",
      "Loss on test= 0.007759204134345055\n",
      "acc for Lsat= 0.28019432268208927 \n",
      "acc for Psat= 0.2574412760635217 \n",
      "acc for optim= 0.132768324835019\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.009172482416033745\n",
      "Loss on test= 0.007260718382894993\n",
      "acc for Lsat= 0.1979292674611012 \n",
      "acc for Psat= 0.2612647172063589 \n",
      "acc for optim= 0.14787663640971813\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.008644569665193558\n",
      "Loss on test= 0.007451993878930807\n",
      "acc for Lsat= 0.26251314156171346 \n",
      "acc for Psat= 0.24859369370258516 \n",
      "acc for optim= 0.11859016927580039\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.008749189786612988\n",
      "Loss on test= 0.007769259158521891\n",
      "acc for Lsat= 0.14195854837695757 \n",
      "acc for Psat= 0.2411437395753132 \n",
      "acc for optim= 0.143351839027471\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.008717835880815983\n",
      "Loss on test= 0.008214671164751053\n",
      "acc for Lsat= 0.20305053336131904 \n",
      "acc for Psat= 0.2997560049924586 \n",
      "acc for optim= 0.1570972210417191\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.008591590449213982\n",
      "Loss on test= 0.007456093095242977\n",
      "acc for Lsat= 0.21236695680353376 \n",
      "acc for Psat= 0.24515470075938436 \n",
      "acc for optim= 0.1323116034683254\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.008483647368848324\n",
      "Loss on test= 0.007278410717844963\n",
      "acc for Lsat= 0.25589601043611765 \n",
      "acc for Psat= 0.2513291271817353 \n",
      "acc for optim= 0.13251910667814729\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.008701988495886326\n",
      "Loss on test= 0.006839896086603403\n",
      "acc for Lsat= 0.21042211105426153 \n",
      "acc for Psat= 0.20250040342863132 \n",
      "acc for optim= 0.15900947214362937\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.008722574450075626\n",
      "Loss on test= 0.00868847593665123\n",
      "acc for Lsat= 0.24719332427614266 \n",
      "acc for Psat= 0.24749538778430885 \n",
      "acc for optim= 0.1413864749645452\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.008328553289175034\n",
      "Loss on test= 0.007404734846204519\n",
      "acc for Lsat= 0.2575524765998125 \n",
      "acc for Psat= 0.24075637343857023 \n",
      "acc for optim= 0.15299201573038268\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.008382073603570461\n",
      "Loss on test= 0.007127061486244202\n",
      "acc for Lsat= 0.1995163280258162 \n",
      "acc for Psat= 0.2504354934725497 \n",
      "acc for optim= 0.14444464789186087\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.008245040662586689\n",
      "Loss on test= 0.007267936132848263\n",
      "acc for Lsat= 0.19148521037358376 \n",
      "acc for Psat= 0.22055373092492422 \n",
      "acc for optim= 0.1117421898783909\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.008120182901620865\n",
      "Loss on test= 0.0069558206014335155\n",
      "acc for Lsat= 0.22935214700798193 \n",
      "acc for Psat= 0.21812105033960608 \n",
      "acc for optim= 0.1303876261226833\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.00811332929879427\n",
      "Loss on test= 0.006959942635148764\n",
      "acc for Lsat= 0.22275321684881216 \n",
      "acc for Psat= 0.1720093434366087 \n",
      "acc for optim= 0.1479406033953031\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.008276105858385563\n",
      "Loss on test= 0.007823175750672817\n",
      "acc for Lsat= 0.22577524309357008 \n",
      "acc for Psat= 0.2661252037828995 \n",
      "acc for optim= 0.1429275259272092\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.008040136657655239\n",
      "Loss on test= 0.007206195034086704\n",
      "acc for Lsat= 0.1950596702647292 \n",
      "acc for Psat= 0.22342423411707082 \n",
      "acc for optim= 0.14991795025869376\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.007983988150954247\n",
      "Loss on test= 0.007366869132965803\n",
      "acc for Lsat= 0.23861963695122135 \n",
      "acc for Psat= 0.26819119074692327 \n",
      "acc for optim= 0.1334258712724679\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.007937620393931866\n",
      "Loss on test= 0.006961273029446602\n",
      "acc for Lsat= 0.15847358811232778 \n",
      "acc for Psat= 0.18372816106097567 \n",
      "acc for optim= 0.1479041275775267\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.008119952864944935\n",
      "Loss on test= 0.006883722264319658\n",
      "acc for Lsat= 0.1788592521722118 \n",
      "acc for Psat= 0.2364344821932415 \n",
      "acc for optim= 0.14791397429588768\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.007941009476780891\n",
      "Loss on test= 0.007101602852344513\n",
      "acc for Lsat= 0.20799879646963543 \n",
      "acc for Psat= 0.24589046318497923 \n",
      "acc for optim= 0.13453805914873052\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.007971295155584812\n",
      "Loss on test= 0.007099389098584652\n",
      "acc for Lsat= 0.19451748706503874 \n",
      "acc for Psat= 0.28417838973432985 \n",
      "acc for optim= 0.14850992476567626\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.0078103020787239075\n",
      "Loss on test= 0.006418655160814524\n",
      "acc for Lsat= 0.16428920409331718 \n",
      "acc for Psat= 0.2872496797806687 \n",
      "acc for optim= 0.1505274565683471\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.007754975464195013\n",
      "Loss on test= 0.006946591194719076\n",
      "acc for Lsat= 0.16320799943059683 \n",
      "acc for Psat= 0.1760109570912189 \n",
      "acc for optim= 0.13968426858385405\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.007404175586998463\n",
      "Loss on test= 0.007109971717000008\n",
      "acc for Lsat= 0.18518978854020438 \n",
      "acc for Psat= 0.18623514354435933 \n",
      "acc for optim= 0.1424476773892012\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.007623341865837574\n",
      "Loss on test= 0.006822112016379833\n",
      "acc for Lsat= 0.20530692806156972 \n",
      "acc for Psat= 0.22862698510289192 \n",
      "acc for optim= 0.1579007942022549\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.007852173410356045\n",
      "Loss on test= 0.00641497690230608\n",
      "acc for Lsat= 0.2063733216168152 \n",
      "acc for Psat= 0.2517742146220472 \n",
      "acc for optim= 0.11884577740703309\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.0075161089189350605\n",
      "Loss on test= 0.006982011720538139\n",
      "acc for Lsat= 0.1328993924996919 \n",
      "acc for Psat= 0.2140372381480928 \n",
      "acc for optim= 0.14280509893109816\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.007525106891989708\n",
      "Loss on test= 0.006189396604895592\n",
      "acc for Lsat= 0.13176519258154762 \n",
      "acc for Psat= 0.20259824705620608 \n",
      "acc for optim= 0.14247536677349773\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.00785911176353693\n",
      "Loss on test= 0.005974067375063896\n",
      "acc for Lsat= 0.1926443586902072 \n",
      "acc for Psat= 0.20293420255701575 \n",
      "acc for optim= 0.13440517149865627\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.007670302875339985\n",
      "Loss on test= 0.00658565666526556\n",
      "acc for Lsat= 0.2159078157403403 \n",
      "acc for Psat= 0.26758615527715945 \n",
      "acc for optim= 0.14546809614532524\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.0075716073624789715\n",
      "Loss on test= 0.006362825632095337\n",
      "acc for Lsat= 0.1839959990595364 \n",
      "acc for Psat= 0.22104267535420755 \n",
      "acc for optim= 0.14233374605990118\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.007571666035801172\n",
      "Loss on test= 0.006685259286314249\n",
      "acc for Lsat= 0.14966924562274167 \n",
      "acc for Psat= 0.28691444132063126 \n",
      "acc for optim= 0.15967321972776619\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.00736596155911684\n",
      "Loss on test= 0.007201595231890678\n",
      "acc for Lsat= 0.248576944693923 \n",
      "acc for Psat= 0.226879029845198 \n",
      "acc for optim= 0.15304702608328727\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.007287116255611181\n",
      "Loss on test= 0.006491918116807938\n",
      "acc for Lsat= 0.14638702126426828 \n",
      "acc for Psat= 0.2104904014947048 \n",
      "acc for optim= 0.12960163448911366\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.007537841331213713\n",
      "Loss on test= 0.0062563554383814335\n",
      "acc for Lsat= 0.15134118589210427 \n",
      "acc for Psat= 0.16363128481639755 \n",
      "acc for optim= 0.14957870812051827\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.00730878533795476\n",
      "Loss on test= 0.0062645538710057735\n",
      "acc for Lsat= 0.21199296373460028 \n",
      "acc for Psat= 0.19999126407007375 \n",
      "acc for optim= 0.14464038237929344\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.007426540832966566\n",
      "Loss on test= 0.00624005775898695\n",
      "acc for Lsat= 0.17979350960296062 \n",
      "acc for Psat= 0.1970832949090335 \n",
      "acc for optim= 0.14878576590369144\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.007294662296772003\n",
      "Loss on test= 0.006495791487395763\n",
      "acc for Lsat= 0.14681297386737746 \n",
      "acc for Psat= 0.22831695568230417 \n",
      "acc for optim= 0.15476642662866247\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.006965988781303167\n",
      "Loss on test= 0.0064221955835819244\n",
      "acc for Lsat= 0.2459626679046778 \n",
      "acc for Psat= 0.20781144310927224 \n",
      "acc for optim= 0.14363907898465791\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.007006174419075251\n",
      "Loss on test= 0.0061918287537992\n",
      "acc for Lsat= 0.2310152573304044 \n",
      "acc for Psat= 0.2021386114259561 \n",
      "acc for optim= 0.1820297290881475\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.007114619016647339\n",
      "Loss on test= 0.0063488115556538105\n",
      "acc for Lsat= 0.2152304013984071 \n",
      "acc for Psat= 0.18588986767766377 \n",
      "acc for optim= 0.1390041676414613\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.007286672480404377\n",
      "Loss on test= 0.00615872535854578\n",
      "acc for Lsat= 0.14736691060372525 \n",
      "acc for Psat= 0.1798022455121908 \n",
      "acc for optim= 0.1671007460811072\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.007248585112392902\n",
      "Loss on test= 0.006028166972100735\n",
      "acc for Lsat= 0.19230739627932458 \n",
      "acc for Psat= 0.18439155586788225 \n",
      "acc for optim= 0.1557515556924045\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.007058650255203247\n",
      "Loss on test= 0.005982043221592903\n",
      "acc for Lsat= 0.15776606971889529 \n",
      "acc for Psat= 0.2336050796115564 \n",
      "acc for optim= 0.13543768806589973\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.0071425605565309525\n",
      "Loss on test= 0.00656199362128973\n",
      "acc for Lsat= 0.14235414316256842 \n",
      "acc for Psat= 0.2479412758515941 \n",
      "acc for optim= 0.14273693267669943\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.007047809194773436\n",
      "Loss on test= 0.00612762663513422\n",
      "acc for Lsat= 0.19047830833329094 \n",
      "acc for Psat= 0.21632002304411596 \n",
      "acc for optim= 0.13921807856402463\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.006994491443037987\n",
      "Loss on test= 0.006099010352045298\n",
      "acc for Lsat= 0.2204425966160165 \n",
      "acc for Psat= 0.1946855020812816 \n",
      "acc for optim= 0.14273218060326245\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.007033122703433037\n",
      "Loss on test= 0.0056958855129778385\n",
      "acc for Lsat= 0.18520379728741115 \n",
      "acc for Psat= 0.25667213627861607 \n",
      "acc for optim= 0.16024254800544846\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.0071073053404688835\n",
      "Loss on test= 0.0056407880038022995\n",
      "acc for Lsat= 0.1882893494847748 \n",
      "acc for Psat= 0.23303812576664817 \n",
      "acc for optim= 0.1575926556510644\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.006941456813365221\n",
      "Loss on test= 0.005902450531721115\n",
      "acc for Lsat= 0.20640918488950571 \n",
      "acc for Psat= 0.23595123797268672 \n",
      "acc for optim= 0.1627356917079952\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.007000495679676533\n",
      "Loss on test= 0.005798636004328728\n",
      "acc for Lsat= 0.2054864381857947 \n",
      "acc for Psat= 0.1879956195803566 \n",
      "acc for optim= 0.1598337327854501\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.007058665156364441\n",
      "Loss on test= 0.0058244322426617146\n",
      "acc for Lsat= 0.17080551696320376 \n",
      "acc for Psat= 0.23127633785932428 \n",
      "acc for optim= 0.14964924193918705\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.007034194655716419\n",
      "Loss on test= 0.005947890225797892\n",
      "acc for Lsat= 0.1401549849866165 \n",
      "acc for Psat= 0.1660408571931637 \n",
      "acc for optim= 0.13585355375996894\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.0068848286755383015\n",
      "Loss on test= 0.00588943948969245\n",
      "acc for Lsat= 0.21173578521443737 \n",
      "acc for Psat= 0.2226054093076123 \n",
      "acc for optim= 0.14488457148480746\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.006979371886700392\n",
      "Loss on test= 0.005967861507087946\n",
      "acc for Lsat= 0.12314087930200104 \n",
      "acc for Psat= 0.21808049889902273 \n",
      "acc for optim= 0.1602805795587806\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.007032093126326799\n",
      "Loss on test= 0.005966293625533581\n",
      "acc for Lsat= 0.148160669952631 \n",
      "acc for Psat= 0.1663007160855664 \n",
      "acc for optim= 0.1480536268629496\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.006745216436684132\n",
      "Loss on test= 0.006130590103566647\n",
      "acc for Lsat= 0.1492603979487386 \n",
      "acc for Psat= 0.21033702785563138 \n",
      "acc for optim= 0.11988669496753977\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.006586243398487568\n",
      "Loss on test= 0.005957803688943386\n",
      "acc for Lsat= 0.16266081942659286 \n",
      "acc for Psat= 0.21186636346909735 \n",
      "acc for optim= 0.18509702239599493\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.00698019890114665\n",
      "Loss on test= 0.005882893688976765\n",
      "acc for Lsat= 0.15319818108239108 \n",
      "acc for Psat= 0.1819592907688477 \n",
      "acc for optim= 0.1553028714325693\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.006636679172515869\n",
      "Loss on test= 0.005847107619047165\n",
      "acc for Lsat= 0.16761905857775775 \n",
      "acc for Psat= 0.1743445007337464 \n",
      "acc for optim= 0.15479516139667895\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.006750354077666998\n",
      "Loss on test= 0.006291738711297512\n",
      "acc for Lsat= 0.17857968041466343 \n",
      "acc for Psat= 0.16866951166755623 \n",
      "acc for optim= 0.1683118316448397\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.0069107357412576675\n",
      "Loss on test= 0.005097794346511364\n",
      "acc for Lsat= 0.1926910405487029 \n",
      "acc for Psat= 0.19044662028965023 \n",
      "acc for optim= 0.16655525230129975\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.006585280876606703\n",
      "Loss on test= 0.006098868325352669\n",
      "acc for Lsat= 0.09741391118667606 \n",
      "acc for Psat= 0.21296418706576029 \n",
      "acc for optim= 0.15472956299264398\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.0065188040025532246\n",
      "Loss on test= 0.005464291200041771\n",
      "acc for Lsat= 0.17622368104962838 \n",
      "acc for Psat= 0.21257665225615105 \n",
      "acc for optim= 0.1267916231105725\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.006579324137419462\n",
      "Loss on test= 0.006163371726870537\n",
      "acc for Lsat= 0.1320948437270191 \n",
      "acc for Psat= 0.1849899608641863 \n",
      "acc for optim= 0.14691802533343434\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.006640791893005371\n",
      "Loss on test= 0.005873700138181448\n",
      "acc for Lsat= 0.18076709368162686 \n",
      "acc for Psat= 0.21140636547675562 \n",
      "acc for optim= 0.15371281084501082\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.006574679631739855\n",
      "Loss on test= 0.0058243488892912865\n",
      "acc for Lsat= 0.14193410785972244 \n",
      "acc for Psat= 0.16416896331227487 \n",
      "acc for optim= 0.13303477058394086\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.0065485164523124695\n",
      "Loss on test= 0.00567860109731555\n",
      "acc for Lsat= 0.24304193471713612 \n",
      "acc for Psat= 0.17809135845163837 \n",
      "acc for optim= 0.10700315768675257\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.006509230937808752\n",
      "Loss on test= 0.0061179776675999165\n",
      "acc for Lsat= 0.16478003333840105 \n",
      "acc for Psat= 0.21395631216000766 \n",
      "acc for optim= 0.14139628213726813\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.006700168829411268\n",
      "Loss on test= 0.005902537144720554\n",
      "acc for Lsat= 0.15018795741101107 \n",
      "acc for Psat= 0.18002450476504034 \n",
      "acc for optim= 0.13480795381797683\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.006607994437217712\n",
      "Loss on test= 0.00551340077072382\n",
      "acc for Lsat= 0.2429420349912511 \n",
      "acc for Psat= 0.2160703059958501 \n",
      "acc for optim= 0.1539295872207731\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.0064471508376300335\n",
      "Loss on test= 0.006030204705893993\n",
      "acc for Lsat= 0.13819662026233143 \n",
      "acc for Psat= 0.15838842187076807 \n",
      "acc for optim= 0.17548641893598768\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.006521312519907951\n",
      "Loss on test= 0.0066130515187978745\n",
      "acc for Lsat= 0.17014350348876583 \n",
      "acc for Psat= 0.17515202497856486 \n",
      "acc for optim= 0.16394398402836588\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.006586948409676552\n",
      "Loss on test= 0.005340387113392353\n",
      "acc for Lsat= 0.15274202963337302 \n",
      "acc for Psat= 0.18182065116060483 \n",
      "acc for optim= 0.15013011089629597\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.0064662545919418335\n",
      "Loss on test= 0.005718528293073177\n",
      "acc for Lsat= 0.1181983206835058 \n",
      "acc for Psat= 0.1386455555136005 \n",
      "acc for optim= 0.14711711985162562\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.006399143021553755\n",
      "Loss on test= 0.005724965129047632\n",
      "acc for Lsat= 0.17950872807866997 \n",
      "acc for Psat= 0.16572605295934612 \n",
      "acc for optim= 0.1385181152468754\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.006408381275832653\n",
      "Loss on test= 0.005657543893903494\n",
      "acc for Lsat= 0.15968418679484683 \n",
      "acc for Psat= 0.18221127334982157 \n",
      "acc for optim= 0.14501532301720646\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.006417043972760439\n",
      "Loss on test= 0.005559021607041359\n",
      "acc for Lsat= 0.10491995616919464 \n",
      "acc for Psat= 0.12290148369114225 \n",
      "acc for optim= 0.16061302036460903\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.006377306301146746\n",
      "Loss on test= 0.005766882095485926\n",
      "acc for Lsat= 0.162810567766428 \n",
      "acc for Psat= 0.14711816339432618 \n",
      "acc for optim= 0.16287461015033639\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.006459773983806372\n",
      "Loss on test= 0.0054246303625404835\n",
      "acc for Lsat= 0.09732893351206763 \n",
      "acc for Psat= 0.13901221731470692 \n",
      "acc for optim= 0.1378631955012679\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.0065283384174108505\n",
      "Loss on test= 0.005529455840587616\n",
      "acc for Lsat= 0.12766942625037497 \n",
      "acc for Psat= 0.179944751441427 \n",
      "acc for optim= 0.1714142273283667\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.0063840788789093494\n",
      "Loss on test= 0.005356332752853632\n",
      "acc for Lsat= 0.14055618390233982 \n",
      "acc for Psat= 0.20119402958597574 \n",
      "acc for optim= 0.14442544099357393\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.006332135293632746\n",
      "Loss on test= 0.005481990519911051\n",
      "acc for Lsat= 0.18860510405566958 \n",
      "acc for Psat= 0.12678911009829286 \n",
      "acc for optim= 0.15104782229496372\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.0063354503363370895\n",
      "Loss on test= 0.005460172425955534\n",
      "acc for Lsat= 0.15969786989606088 \n",
      "acc for Psat= 0.17024893323994345 \n",
      "acc for optim= 0.11880065068706042\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.006182356271892786\n",
      "Loss on test= 0.005221786443144083\n",
      "acc for Lsat= 0.19085592303114632 \n",
      "acc for Psat= 0.19041975046921936 \n",
      "acc for optim= 0.1594254933297634\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.006304746959358454\n",
      "Loss on test= 0.0053463890217244625\n",
      "acc for Lsat= 0.15140712840689552 \n",
      "acc for Psat= 0.2042120473148922 \n",
      "acc for optim= 0.12045243333300783\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.006422663107514381\n",
      "Loss on test= 0.005357927177101374\n",
      "acc for Lsat= 0.14704734676827988 \n",
      "acc for Psat= 0.1587317001281513 \n",
      "acc for optim= 0.15070729992455906\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.006142090540379286\n",
      "Loss on test= 0.005143103189766407\n",
      "acc for Lsat= 0.12589945644140244 \n",
      "acc for Psat= 0.11553908713782828 \n",
      "acc for optim= 0.13019134176688063\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.006036402657628059\n",
      "Loss on test= 0.005254436284303665\n",
      "acc for Lsat= 0.14527517883107066 \n",
      "acc for Psat= 0.19519432820379734 \n",
      "acc for optim= 0.126818489904205\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.006191147956997156\n",
      "Loss on test= 0.0051169972866773605\n",
      "acc for Lsat= 0.18905874921215904 \n",
      "acc for Psat= 0.1753286801589032 \n",
      "acc for optim= 0.13755836544765365\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.006205787882208824\n",
      "Loss on test= 0.00532781844958663\n",
      "acc for Lsat= 0.1187597821570105 \n",
      "acc for Psat= 0.1432161796838045 \n",
      "acc for optim= 0.13709189287490314\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.006239376496523619\n",
      "Loss on test= 0.005442850757390261\n",
      "acc for Lsat= 0.2081008367240429 \n",
      "acc for Psat= 0.16923837343023884 \n",
      "acc for optim= 0.12606780064783785\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.0060533504001796246\n",
      "Loss on test= 0.0053702788427472115\n",
      "acc for Lsat= 0.127842352932526 \n",
      "acc for Psat= 0.11660796227968401 \n",
      "acc for optim= 0.1373033970594406\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.0061884657479822636\n",
      "Loss on test= 0.0053045134991407394\n",
      "acc for Lsat= 0.13278327051860592 \n",
      "acc for Psat= 0.19218137997409535 \n",
      "acc for optim= 0.13829879105711976\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.006105366628617048\n",
      "Loss on test= 0.0050630029290914536\n",
      "acc for Lsat= 0.16615018683175245 \n",
      "acc for Psat= 0.14936865315151712 \n",
      "acc for optim= 0.1396824434115034\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.0060089631006121635\n",
      "Loss on test= 0.005084736738353968\n",
      "acc for Lsat= 0.1767351144614319 \n",
      "acc for Psat= 0.12202601639890215 \n",
      "acc for optim= 0.1599637529709273\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.0061689275316894054\n",
      "Loss on test= 0.005223596002906561\n",
      "acc for Lsat= 0.11579740021584763 \n",
      "acc for Psat= 0.15596805243856376 \n",
      "acc for optim= 0.1402128858284818\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.005923213437199593\n",
      "Loss on test= 0.005316523835062981\n",
      "acc for Lsat= 0.17175487016599314 \n",
      "acc for Psat= 0.2190125467022881 \n",
      "acc for optim= 0.1360697098231564\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.0059436289593577385\n",
      "Loss on test= 0.005009090527892113\n",
      "acc for Lsat= 0.20012932513943976 \n",
      "acc for Psat= 0.2070585172623396 \n",
      "acc for optim= 0.17719656197975078\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.006173558998852968\n",
      "Loss on test= 0.005117250606417656\n",
      "acc for Lsat= 0.1471380962886744 \n",
      "acc for Psat= 0.2636119732633233 \n",
      "acc for optim= 0.1610304676901756\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.00612198980525136\n",
      "Loss on test= 0.00548766041174531\n",
      "acc for Lsat= 0.12522324164294535 \n",
      "acc for Psat= 0.16926837329649264 \n",
      "acc for optim= 0.16141374015973675\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.005947095341980457\n",
      "Loss on test= 0.004731380380690098\n",
      "acc for Lsat= 0.11963499303803676 \n",
      "acc for Psat= 0.1478936455419494 \n",
      "acc for optim= 0.14960020682257083\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.0059878346510231495\n",
      "Loss on test= 0.005101277958601713\n",
      "acc for Lsat= 0.1218961905170646 \n",
      "acc for Psat= 0.12108448975616032 \n",
      "acc for optim= 0.1583688116321961\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.005957652814686298\n",
      "Loss on test= 0.005283793434500694\n",
      "acc for Lsat= 0.17331027037774524 \n",
      "acc for Psat= 0.2296003121882677 \n",
      "acc for optim= 0.15291790012270212\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.005963109899312258\n",
      "Loss on test= 0.0053406464867293835\n",
      "acc for Lsat= 0.15528934712508796 \n",
      "acc for Psat= 0.17898473573020762 \n",
      "acc for optim= 0.13702174576206338\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.006153617519885302\n",
      "Loss on test= 0.005347344558686018\n",
      "acc for Lsat= 0.16548953319175375 \n",
      "acc for Psat= 0.1322821288680037 \n",
      "acc for optim= 0.14142925430658376\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.005878881085664034\n",
      "Loss on test= 0.0054377177730202675\n",
      "acc for Lsat= 0.1563367729799615 \n",
      "acc for Psat= 0.2148416785316335 \n",
      "acc for optim= 0.1389776509669092\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.005980180110782385\n",
      "Loss on test= 0.004998484160751104\n",
      "acc for Lsat= 0.14528347613910833 \n",
      "acc for Psat= 0.15144371916539967 \n",
      "acc for optim= 0.16675713270281753\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.005904276389628649\n",
      "Loss on test= 0.005001893732696772\n",
      "acc for Lsat= 0.14265531968946257 \n",
      "acc for Psat= 0.18135528804244436 \n",
      "acc for optim= 0.15797456653995645\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.005995807237923145\n",
      "Loss on test= 0.005399543792009354\n",
      "acc for Lsat= 0.10774950041539139 \n",
      "acc for Psat= 0.1268442009265224 \n",
      "acc for optim= 0.1508633732802183\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.005881097633391619\n",
      "Loss on test= 0.005071290303021669\n",
      "acc for Lsat= 0.15790804025406638 \n",
      "acc for Psat= 0.27620007532338303 \n",
      "acc for optim= 0.14441548575026295\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.005872385576367378\n",
      "Loss on test= 0.005201720166951418\n",
      "acc for Lsat= 0.13086992462113914 \n",
      "acc for Psat= 0.2290558967118462 \n",
      "acc for optim= 0.13123243757420117\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.00602714391425252\n",
      "Loss on test= 0.004799898713827133\n",
      "acc for Lsat= 0.17589132640407318 \n",
      "acc for Psat= 0.18756453240186804 \n",
      "acc for optim= 0.14117749242319\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.005929372739046812\n",
      "Loss on test= 0.005009717307984829\n",
      "acc for Lsat= 0.14774879229520999 \n",
      "acc for Psat= 0.18286171255426276 \n",
      "acc for optim= 0.14730932159970203\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.005905181169509888\n",
      "Loss on test= 0.0047674053348600864\n",
      "acc for Lsat= 0.11368059348832402 \n",
      "acc for Psat= 0.18895782137082684 \n",
      "acc for optim= 0.15879855553309122\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.005823837127536535\n",
      "Loss on test= 0.00516416085883975\n",
      "acc for Lsat= 0.12777423160150647 \n",
      "acc for Psat= 0.1986034464918905 \n",
      "acc for optim= 0.1362680321973231\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.005889114923775196\n",
      "Loss on test= 0.005056519061326981\n",
      "acc for Lsat= 0.14851903589442372 \n",
      "acc for Psat= 0.17266879085865286 \n",
      "acc for optim= 0.1385174681329065\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.005820704624056816\n",
      "Loss on test= 0.004742434713989496\n",
      "acc for Lsat= 0.06803634893407838 \n",
      "acc for Psat= 0.20338721614744928 \n",
      "acc for optim= 0.14034198458668673\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.005762842483818531\n",
      "Loss on test= 0.004509009420871735\n",
      "acc for Lsat= 0.13149147894647387 \n",
      "acc for Psat= 0.17451908056520754 \n",
      "acc for optim= 0.14636310627813348\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.00575263099744916\n",
      "Loss on test= 0.005243653431534767\n",
      "acc for Lsat= 0.14234210711179507 \n",
      "acc for Psat= 0.19846646932678091 \n",
      "acc for optim= 0.14999367037994993\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.005837407894432545\n",
      "Loss on test= 0.0048873829655349255\n",
      "acc for Lsat= 0.17748878503011334 \n",
      "acc for Psat= 0.22701005679037836 \n",
      "acc for optim= 0.14337065940101942\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.006284764502197504\n",
      "Loss on test= 0.005144218448549509\n",
      "acc for Lsat= 0.16320501847399604 \n",
      "acc for Psat= 0.2108252535884579 \n",
      "acc for optim= 0.12565596732828352\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.0056625185534358025\n",
      "Loss on test= 0.0047532725147902966\n",
      "acc for Lsat= 0.12132987110979027 \n",
      "acc for Psat= 0.15923924257771838 \n",
      "acc for optim= 0.14740658820503288\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.005746196024119854\n",
      "Loss on test= 0.00502115348353982\n",
      "acc for Lsat= 0.1558655707889961 \n",
      "acc for Psat= 0.1991223848114411 \n",
      "acc for optim= 0.1775659036098255\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.006006130948662758\n",
      "Loss on test= 0.005082485731691122\n",
      "acc for Lsat= 0.1253626069260968 \n",
      "acc for Psat= 0.16595222278394633 \n",
      "acc for optim= 0.13323201717705363\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.005853285081684589\n",
      "Loss on test= 0.0051638283766806126\n",
      "acc for Lsat= 0.1315309727538584 \n",
      "acc for Psat= 0.2578982394706044 \n",
      "acc for optim= 0.16010050092720324\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.005749073810875416\n",
      "Loss on test= 0.004808695055544376\n",
      "acc for Lsat= 0.1845790609303448 \n",
      "acc for Psat= 0.19262396740830606 \n",
      "acc for optim= 0.15871333910359275\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.005744416732341051\n",
      "Loss on test= 0.0051338085904717445\n",
      "acc for Lsat= 0.16814013166973987 \n",
      "acc for Psat= 0.28682211476067704 \n",
      "acc for optim= 0.1360416136061152\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.005754963029175997\n",
      "Loss on test= 0.004809524863958359\n",
      "acc for Lsat= 0.15608192866461146 \n",
      "acc for Psat= 0.17440409891747144 \n",
      "acc for optim= 0.17018977345691788\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.005815282929688692\n",
      "Loss on test= 0.004935724660754204\n",
      "acc for Lsat= 0.16863555357688004 \n",
      "acc for Psat= 0.234520280526744 \n",
      "acc for optim= 0.15586247152855826\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.005775113124400377\n",
      "Loss on test= 0.00524616613984108\n",
      "acc for Lsat= 0.10946750066553552 \n",
      "acc for Psat= 0.13489025696698162 \n",
      "acc for optim= 0.14170620621492466\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.005824765656143427\n",
      "Loss on test= 0.004753434099256992\n",
      "acc for Lsat= 0.1840916434302926 \n",
      "acc for Psat= 0.270664821482367 \n",
      "acc for optim= 0.16762925438686377\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.005573289003223181\n",
      "Loss on test= 0.004884028807282448\n",
      "acc for Lsat= 0.08638291309277217 \n",
      "acc for Psat= 0.1666734493854973 \n",
      "acc for optim= 0.12749603472831142\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.005567418877035379\n",
      "Loss on test= 0.004749766550958157\n",
      "acc for Lsat= 0.12277534410047035 \n",
      "acc for Psat= 0.11469950154423714 \n",
      "acc for optim= 0.14018930189518464\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.005614403169602156\n",
      "Loss on test= 0.004582274705171585\n",
      "acc for Lsat= 0.12825544773497516 \n",
      "acc for Psat= 0.14969379635941651 \n",
      "acc for optim= 0.12922656003178823\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.005619499366730452\n",
      "Loss on test= 0.005006067920476198\n",
      "acc for Lsat= 0.10925771875513925 \n",
      "acc for Psat= 0.15637296464087236 \n",
      "acc for optim= 0.1606069728732109\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.005714851431548595\n",
      "Loss on test= 0.0047017429023981094\n",
      "acc for Lsat= 0.12855913494584253 \n",
      "acc for Psat= 0.16053624285591972 \n",
      "acc for optim= 0.14941676944080326\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.005540702026337385\n",
      "Loss on test= 0.004808918572962284\n",
      "acc for Lsat= 0.13005735616510114 \n",
      "acc for Psat= 0.16673727012756798 \n",
      "acc for optim= 0.13551437019163537\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.00585409440100193\n",
      "Loss on test= 0.004835672676563263\n",
      "acc for Lsat= 0.09015602820242445 \n",
      "acc for Psat= 0.13417936408788794 \n",
      "acc for optim= 0.1692904925180806\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.005679627880454063\n",
      "Loss on test= 0.005124643910676241\n",
      "acc for Lsat= 0.14300627305379343 \n",
      "acc for Psat= 0.1700553890485834 \n",
      "acc for optim= 0.12431056714720196\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.005639731418341398\n",
      "Loss on test= 0.004949013702571392\n",
      "acc for Lsat= 0.12759445812035766 \n",
      "acc for Psat= 0.16711902225183117 \n",
      "acc for optim= 0.15547702295912635\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.005532696843147278\n",
      "Loss on test= 0.005056770984083414\n",
      "acc for Lsat= 0.11360403189125161 \n",
      "acc for Psat= 0.13246666681435373 \n",
      "acc for optim= 0.13148822324971357\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.005641092546284199\n",
      "Loss on test= 0.0047285547479987144\n",
      "acc for Lsat= 0.11751990382456118 \n",
      "acc for Psat= 0.16318093623138136 \n",
      "acc for optim= 0.1498127101480754\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.0056577143259346485\n",
      "Loss on test= 0.005025620572268963\n",
      "acc for Lsat= 0.12593848258256912 \n",
      "acc for Psat= 0.13155250332783908 \n",
      "acc for optim= 0.12534344703372982\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.00555259408429265\n",
      "Loss on test= 0.0045370617881417274\n",
      "acc for Lsat= 0.13331504145430195 \n",
      "acc for Psat= 0.1764951185323298 \n",
      "acc for optim= 0.14049854791826671\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.005405748263001442\n",
      "Loss on test= 0.00486286636441946\n",
      "acc for Lsat= 0.1085332126951673 \n",
      "acc for Psat= 0.13721843666603994 \n",
      "acc for optim= 0.13952542003244162\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.0055146608501672745\n",
      "Loss on test= 0.004878221079707146\n",
      "acc for Lsat= 0.11946063488721848 \n",
      "acc for Psat= 0.14937356730095214 \n",
      "acc for optim= 0.12790852182337809\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.00564104039222002\n",
      "Loss on test= 0.004697445314377546\n",
      "acc for Lsat= 0.10219707500396503 \n",
      "acc for Psat= 0.15172609428150785 \n",
      "acc for optim= 0.17377942821217907\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.0055351294577121735\n",
      "Loss on test= 0.004948257468640804\n",
      "acc for Lsat= 0.14578221526203883 \n",
      "acc for Psat= 0.21675813437872826 \n",
      "acc for optim= 0.1734121727446715\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.005680091679096222\n",
      "Loss on test= 0.004658190533518791\n",
      "acc for Lsat= 0.13943608167270818 \n",
      "acc for Psat= 0.16957699971842682 \n",
      "acc for optim= 0.131310291982825\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.005521286278963089\n",
      "Loss on test= 0.005013521295040846\n",
      "acc for Lsat= 0.13340133506183824 \n",
      "acc for Psat= 0.1394812941758169 \n",
      "acc for optim= 0.1527028512985756\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.005517386365681887\n",
      "Loss on test= 0.004604343790560961\n",
      "acc for Lsat= 0.134965243206049 \n",
      "acc for Psat= 0.1432475794831084 \n",
      "acc for optim= 0.14228880622734627\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.005511221010237932\n",
      "Loss on test= 0.004889563657343388\n",
      "acc for Lsat= 0.18990564294573334 \n",
      "acc for Psat= 0.16132387668929166 \n",
      "acc for optim= 0.14470496401190758\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.005447853822261095\n",
      "Loss on test= 0.004748036619275808\n",
      "acc for Lsat= 0.1119640708849248 \n",
      "acc for Psat= 0.19321268093254831 \n",
      "acc for optim= 0.1404886607391139\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.005321830045431852\n",
      "Loss on test= 0.0046043917536735535\n",
      "acc for Lsat= 0.16662748416678774 \n",
      "acc for Psat= 0.19553062081750897 \n",
      "acc for optim= 0.14033052273508576\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.005635825917124748\n",
      "Loss on test= 0.004543773364275694\n",
      "acc for Lsat= 0.11859720495219032 \n",
      "acc for Psat= 0.19786051003676322 \n",
      "acc for optim= 0.12843126746722394\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.005494939163327217\n",
      "Loss on test= 0.004497099667787552\n",
      "acc for Lsat= 0.1676071693137702 \n",
      "acc for Psat= 0.17504099684043062 \n",
      "acc for optim= 0.15593149181869295\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.005480242893099785\n",
      "Loss on test= 0.00489898631349206\n",
      "acc for Lsat= 0.14385731918284567 \n",
      "acc for Psat= 0.1637763552652258 \n",
      "acc for optim= 0.13508839946654108\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.005316504742950201\n",
      "Loss on test= 0.0049222782254219055\n",
      "acc for Lsat= 0.12835943243569797 \n",
      "acc for Psat= 0.1931685614399612 \n",
      "acc for optim= 0.14305827031946844\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.005463884212076664\n",
      "Loss on test= 0.00490547763183713\n",
      "acc for Lsat= 0.119083249488742 \n",
      "acc for Psat= 0.09091095026168558 \n",
      "acc for optim= 0.16566753966940773\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.005516750738024712\n",
      "Loss on test= 0.004669003654271364\n",
      "acc for Lsat= 0.13352257489330238 \n",
      "acc for Psat= 0.11998261913605449 \n",
      "acc for optim= 0.14112249630529228\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.005454379599541426\n",
      "Loss on test= 0.0049311211332678795\n",
      "acc for Lsat= 0.1114769213046303 \n",
      "acc for Psat= 0.1624766355380416 \n",
      "acc for optim= 0.1329583315592673\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.005376765504479408\n",
      "Loss on test= 0.005068579688668251\n",
      "acc for Lsat= 0.08016817892591159 \n",
      "acc for Psat= 0.12684656431277594 \n",
      "acc for optim= 0.1540350733945767\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.005312741734087467\n",
      "Loss on test= 0.004803950898349285\n",
      "acc for Lsat= 0.12371699680160317 \n",
      "acc for Psat= 0.19561742983448008 \n",
      "acc for optim= 0.13844466990687782\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.005412222817540169\n",
      "Loss on test= 0.00459452485665679\n",
      "acc for Lsat= 0.13032366852793428 \n",
      "acc for Psat= 0.1576018438467549 \n",
      "acc for optim= 0.16812324710190296\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.005310010630637407\n",
      "Loss on test= 0.004509977530688047\n",
      "acc for Lsat= 0.08928093490087324 \n",
      "acc for Psat= 0.08880381242165135 \n",
      "acc for optim= 0.127935199584398\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.005432604346424341\n",
      "Loss on test= 0.004627535119652748\n",
      "acc for Lsat= 0.1338041933874289 \n",
      "acc for Psat= 0.15518273884016606 \n",
      "acc for optim= 0.14699183062960705\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.005477264989167452\n",
      "Loss on test= 0.004724908620119095\n",
      "acc for Lsat= 0.11458392958674166 \n",
      "acc for Psat= 0.1279876150527141 \n",
      "acc for optim= 0.13978838646370503\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.005327523220330477\n",
      "Loss on test= 0.004941195715218782\n",
      "acc for Lsat= 0.11461546189255184 \n",
      "acc for Psat= 0.15604680124670267 \n",
      "acc for optim= 0.12954298939762843\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.005390774924308062\n",
      "Loss on test= 0.004561747889965773\n",
      "acc for Lsat= 0.07470028314532505 \n",
      "acc for Psat= 0.15416711693008742 \n",
      "acc for optim= 0.13378418236970901\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.005409473553299904\n",
      "Loss on test= 0.004960345104336739\n",
      "acc for Lsat= 0.13279023106830815 \n",
      "acc for Psat= 0.14206896111783054 \n",
      "acc for optim= 0.12662456153419852\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.005367495585232973\n",
      "Loss on test= 0.004829989280551672\n",
      "acc for Lsat= 0.13803777284920216 \n",
      "acc for Psat= 0.17582009763767323 \n",
      "acc for optim= 0.1493819693310393\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.005156013183295727\n",
      "Loss on test= 0.004855219274759293\n",
      "acc for Lsat= 0.09900431705884533 \n",
      "acc for Psat= 0.1643459536652598 \n",
      "acc for optim= 0.14115371254997122\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.005448874086141586\n",
      "Loss on test= 0.005012519657611847\n",
      "acc for Lsat= 0.1534098231026696 \n",
      "acc for Psat= 0.1662808544933796 \n",
      "acc for optim= 0.13387131825503376\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.005363195203244686\n",
      "Loss on test= 0.0047511267475783825\n",
      "acc for Lsat= 0.12931792735536066 \n",
      "acc for Psat= 0.13384443537021676 \n",
      "acc for optim= 0.1158234296599403\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.005328210536390543\n",
      "Loss on test= 0.004702411592006683\n",
      "acc for Lsat= 0.12244239397760895 \n",
      "acc for Psat= 0.13491094688652083 \n",
      "acc for optim= 0.1409658764799436\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.005285073071718216\n",
      "Loss on test= 0.004894477780908346\n",
      "acc for Lsat= 0.1341958606822623 \n",
      "acc for Psat= 0.17720106690831017 \n",
      "acc for optim= 0.13411228697643512\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.0053346287459135056\n",
      "Loss on test= 0.0045646922662854195\n",
      "acc for Lsat= 0.10056664758465356 \n",
      "acc for Psat= 0.17149004133211243 \n",
      "acc for optim= 0.14591203961107466\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.005155864637345076\n",
      "Loss on test= 0.004594627767801285\n",
      "acc for Lsat= 0.17946069170203474 \n",
      "acc for Psat= 0.13436321885738936 \n",
      "acc for optim= 0.14156937309437329\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.005486005917191505\n",
      "Loss on test= 0.004452643916010857\n",
      "acc for Lsat= 0.10055267836691605 \n",
      "acc for Psat= 0.10812969614441197 \n",
      "acc for optim= 0.12465805446522103\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.005445481743663549\n",
      "Loss on test= 0.0049172136932611465\n",
      "acc for Lsat= 0.12325016983474295 \n",
      "acc for Psat= 0.11614346339936471 \n",
      "acc for optim= 0.12939990198032725\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.005281664896756411\n",
      "Loss on test= 0.004456937778741121\n",
      "acc for Lsat= 0.09052117220643494 \n",
      "acc for Psat= 0.13868113726170528 \n",
      "acc for optim= 0.16319763836347395\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.005261773709207773\n",
      "Loss on test= 0.004809824749827385\n",
      "acc for Lsat= 0.14228313592159086 \n",
      "acc for Psat= 0.19503260709138381 \n",
      "acc for optim= 0.11957174891399013\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.005330287851393223\n",
      "Loss on test= 0.004797040950506926\n",
      "acc for Lsat= 0.13691706907270096 \n",
      "acc for Psat= 0.13487070915935975 \n",
      "acc for optim= 0.15035823649830288\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.005318221170455217\n",
      "Loss on test= 0.004562870599329472\n",
      "acc for Lsat= 0.11254388663089937 \n",
      "acc for Psat= 0.11492583889695299 \n",
      "acc for optim= 0.15387422322399086\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.00524893356487155\n",
      "Loss on test= 0.004410929977893829\n",
      "acc for Lsat= 0.14312894916575816 \n",
      "acc for Psat= 0.14493013633829024 \n",
      "acc for optim= 0.12545938551839855\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.005145467817783356\n",
      "Loss on test= 0.004697653464972973\n",
      "acc for Lsat= 0.14677883074101475 \n",
      "acc for Psat= 0.13280574972223905 \n",
      "acc for optim= 0.16304037189628515\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.0052377586252987385\n",
      "Loss on test= 0.004463339224457741\n",
      "acc for Lsat= 0.13786444052432975 \n",
      "acc for Psat= 0.16514943136523166 \n",
      "acc for optim= 0.13135012042605215\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.005339454859495163\n",
      "Loss on test= 0.0046503557823598385\n",
      "acc for Lsat= 0.13733539229724556 \n",
      "acc for Psat= 0.1339371975304352 \n",
      "acc for optim= 0.12810579081997275\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.005302785895764828\n",
      "Loss on test= 0.004601502791047096\n",
      "acc for Lsat= 0.1373899678647932 \n",
      "acc for Psat= 0.19177610851410362 \n",
      "acc for optim= 0.17215668984378377\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.005388067569583654\n",
      "Loss on test= 0.0047215428203344345\n",
      "acc for Lsat= 0.14702080852455562 \n",
      "acc for Psat= 0.17356575011379188 \n",
      "acc for optim= 0.13600488131244978\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.005134909879416227\n",
      "Loss on test= 0.004772508982568979\n",
      "acc for Lsat= 0.09975684610091978 \n",
      "acc for Psat= 0.15359697180489698 \n",
      "acc for optim= 0.12190171752849387\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.0051868450827896595\n",
      "Loss on test= 0.004708647262305021\n",
      "acc for Lsat= 0.1352680300672849 \n",
      "acc for Psat= 0.2059283676660723 \n",
      "acc for optim= 0.14739461600159606\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.005276872776448727\n",
      "Loss on test= 0.004614341538399458\n",
      "acc for Lsat= 0.15726403002109793 \n",
      "acc for Psat= 0.11705287287218703 \n",
      "acc for optim= 0.13611124724977547\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.005364693701267242\n",
      "Loss on test= 0.004536565858870745\n",
      "acc for Lsat= 0.17623837913076082 \n",
      "acc for Psat= 0.19944134903036886 \n",
      "acc for optim= 0.17257882789191273\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.005239580757915974\n",
      "Loss on test= 0.004588610026985407\n",
      "acc for Lsat= 0.1080283410847187 \n",
      "acc for Psat= 0.16995644093387657 \n",
      "acc for optim= 0.16608735960390833\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.0050987000577151775\n",
      "Loss on test= 0.004608563147485256\n",
      "acc for Lsat= 0.14187425907908213 \n",
      "acc for Psat= 0.1848487255887853 \n",
      "acc for optim= 0.1506173333360089\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.0051517244428396225\n",
      "Loss on test= 0.004437658470124006\n",
      "acc for Lsat= 0.11644974407843417 \n",
      "acc for Psat= 0.16562247121085724 \n",
      "acc for optim= 0.15406768872506088\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.005158519372344017\n",
      "Loss on test= 0.0049430918879806995\n",
      "acc for Lsat= 0.08718045945796701 \n",
      "acc for Psat= 0.15529342026760182 \n",
      "acc for optim= 0.1426343767088838\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.005099637899547815\n",
      "Loss on test= 0.004894575569778681\n",
      "acc for Lsat= 0.10504737374786702 \n",
      "acc for Psat= 0.12608638897331226 \n",
      "acc for optim= 0.13920240942388773\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.005047008860856295\n",
      "Loss on test= 0.004726722836494446\n",
      "acc for Lsat= 0.16929632652964857 \n",
      "acc for Psat= 0.20136097756524882 \n",
      "acc for optim= 0.1498719530387057\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.0053085521794855595\n",
      "Loss on test= 0.004421886522322893\n",
      "acc for Lsat= 0.17537865001294348 \n",
      "acc for Psat= 0.20727276150137186 \n",
      "acc for optim= 0.14419972621706417\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.005325642880052328\n",
      "Loss on test= 0.004669331945478916\n",
      "acc for Lsat= 0.16773449888245928 \n",
      "acc for Psat= 0.19978425367217925 \n",
      "acc for optim= 0.12840462310446632\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.005070853047072887\n",
      "Loss on test= 0.004855222534388304\n",
      "acc for Lsat= 0.1264473128442963 \n",
      "acc for Psat= 0.15821745360477102 \n",
      "acc for optim= 0.1574225321205126\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.005072161555290222\n",
      "Loss on test= 0.005111189093440771\n",
      "acc for Lsat= 0.1121636791051262 \n",
      "acc for Psat= 0.14315253868699074 \n",
      "acc for optim= 0.15961114927712414\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.005270888097584248\n",
      "Loss on test= 0.004272241611033678\n",
      "acc for Lsat= 0.10924893545193805 \n",
      "acc for Psat= 0.19108452916973168 \n",
      "acc for optim= 0.15181301875660816\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.005092736799269915\n",
      "Loss on test= 0.0047355107963085175\n",
      "acc for Lsat= 0.10313791435004936 \n",
      "acc for Psat= 0.14443869557645586 \n",
      "acc for optim= 0.1584607143368986\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.005208960734307766\n",
      "Loss on test= 0.004368288442492485\n",
      "acc for Lsat= 0.186545021728509 \n",
      "acc for Psat= 0.13868743698630068 \n",
      "acc for optim= 0.1534181364501516\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.005262469407171011\n",
      "Loss on test= 0.004390813875943422\n",
      "acc for Lsat= 0.09891419675356398 \n",
      "acc for Psat= 0.1792906702758046 \n",
      "acc for optim= 0.1388329720745484\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.00528613431379199\n",
      "Loss on test= 0.004497427027672529\n",
      "acc for Lsat= 0.12227104935381147 \n",
      "acc for Psat= 0.12199993959317605 \n",
      "acc for optim= 0.16254739390893114\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.005141288973391056\n",
      "Loss on test= 0.0045731086283922195\n",
      "acc for Lsat= 0.16191551989565292 \n",
      "acc for Psat= 0.13495277637977982 \n",
      "acc for optim= 0.1361182467598054\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.005017380230128765\n",
      "Loss on test= 0.004453601315617561\n",
      "acc for Lsat= 0.11706529764665498 \n",
      "acc for Psat= 0.15041703131929454 \n",
      "acc for optim= 0.13572062458842993\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.0050867167301476\n",
      "Loss on test= 0.004684331361204386\n",
      "acc for Lsat= 0.09853827469568285 \n",
      "acc for Psat= 0.16659455311795077 \n",
      "acc for optim= 0.15697808149788114\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.004986266605556011\n",
      "Loss on test= 0.0044315350241959095\n",
      "acc for Lsat= 0.12303129714241044 \n",
      "acc for Psat= 0.1453141196042351 \n",
      "acc for optim= 0.1373570379283693\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.0050485339015722275\n",
      "Loss on test= 0.004560777917504311\n",
      "acc for Lsat= 0.13447819339732328 \n",
      "acc for Psat= 0.1706612136008011 \n",
      "acc for optim= 0.1393110229012867\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.005014270544052124\n",
      "Loss on test= 0.004459695424884558\n",
      "acc for Lsat= 0.11663679087844987 \n",
      "acc for Psat= 0.15291107984052765 \n",
      "acc for optim= 0.14559641170005003\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.004964785650372505\n",
      "Loss on test= 0.00470469705760479\n",
      "acc for Lsat= 0.12576788984653023 \n",
      "acc for Psat= 0.13867299240599903 \n",
      "acc for optim= 0.15249662804934713\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.005023151636123657\n",
      "Loss on test= 0.004217154812067747\n",
      "acc for Lsat= 0.10611460787347621 \n",
      "acc for Psat= 0.20143932746981996 \n",
      "acc for optim= 0.16451696787650386\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.005153609439730644\n",
      "Loss on test= 0.004543905612081289\n",
      "acc for Lsat= 0.07874959517761858 \n",
      "acc for Psat= 0.11591596133075655 \n",
      "acc for optim= 0.16643330144385496\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.005065636709332466\n",
      "Loss on test= 0.004548140335828066\n",
      "acc for Lsat= 0.10113671282306314 \n",
      "acc for Psat= 0.1342703042189694 \n",
      "acc for optim= 0.14789498421467012\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.005099694710224867\n",
      "Loss on test= 0.004524286836385727\n",
      "acc for Lsat= 0.1332865755021986 \n",
      "acc for Psat= 0.16493253958308035 \n",
      "acc for optim= 0.1374362145240108\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.00514204939827323\n",
      "Loss on test= 0.004606889560818672\n",
      "acc for Lsat= 0.11171138038237889 \n",
      "acc for Psat= 0.11938618283279033 \n",
      "acc for optim= 0.13500760806103548\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.004992565140128136\n",
      "Loss on test= 0.004833952523767948\n",
      "acc for Lsat= 0.13211816694173548 \n",
      "acc for Psat= 0.13432376231584284 \n",
      "acc for optim= 0.15573465637862682\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.005012305453419685\n",
      "Loss on test= 0.004427900072187185\n",
      "acc for Lsat= 0.1002506171935238 \n",
      "acc for Psat= 0.13784258920026737 \n",
      "acc for optim= 0.14469617631079423\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.004809215199202299\n",
      "Loss on test= 0.004547267686575651\n",
      "acc for Lsat= 0.1371137463591165 \n",
      "acc for Psat= 0.13945331584869158 \n",
      "acc for optim= 0.11727556394827035\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.004928221460431814\n",
      "Loss on test= 0.004505270626395941\n",
      "acc for Lsat= 0.1103124463180494 \n",
      "acc for Psat= 0.12062932272157115 \n",
      "acc for optim= 0.16277257104714712\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.004915821831673384\n",
      "Loss on test= 0.004859105683863163\n",
      "acc for Lsat= 0.08279318152926862 \n",
      "acc for Psat= 0.1520891880823506 \n",
      "acc for optim= 0.1546539416239183\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.005032010842114687\n",
      "Loss on test= 0.004362786188721657\n",
      "acc for Lsat= 0.14326117539571392 \n",
      "acc for Psat= 0.12707442195258206 \n",
      "acc for optim= 0.13971073594358233\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.005094774067401886\n",
      "Loss on test= 0.004430958069860935\n",
      "acc for Lsat= 0.09626713488250971 \n",
      "acc for Psat= 0.1783357703437408 \n",
      "acc for optim= 0.15817390785863003\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.004893619101494551\n",
      "Loss on test= 0.004696682095527649\n",
      "acc for Lsat= 0.15050973194754785 \n",
      "acc for Psat= 0.14871652827908596 \n",
      "acc for optim= 0.13438909645709726\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.004984365776181221\n",
      "Loss on test= 0.004685749299824238\n",
      "acc for Lsat= 0.13050286026878488 \n",
      "acc for Psat= 0.1496214801316253 \n",
      "acc for optim= 0.12753704943396668\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.00503105204552412\n",
      "Loss on test= 0.004594132769852877\n",
      "acc for Lsat= 0.13341602186361948 \n",
      "acc for Psat= 0.16492156472264063 \n",
      "acc for optim= 0.15611823172205025\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.004941051825881004\n",
      "Loss on test= 0.004602471832185984\n",
      "acc for Lsat= 0.10906037890041868 \n",
      "acc for Psat= 0.13033809285196993 \n",
      "acc for optim= 0.12257614235083263\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.0050177606754004955\n",
      "Loss on test= 0.004631853196769953\n",
      "acc for Lsat= 0.12395086993152897 \n",
      "acc for Psat= 0.19351769662979576 \n",
      "acc for optim= 0.12065502100934584\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.0050309584476053715\n",
      "Loss on test= 0.004358925856649876\n",
      "acc for Lsat= 0.12674023324830663 \n",
      "acc for Psat= 0.15239083179686633 \n",
      "acc for optim= 0.16031924241946804\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.0048803966492414474\n",
      "Loss on test= 0.004411594942212105\n",
      "acc for Lsat= 0.10058037791815069 \n",
      "acc for Psat= 0.13853083411231637 \n",
      "acc for optim= 0.11790052697890335\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.0047645834274590015\n",
      "Loss on test= 0.0042888144962489605\n",
      "acc for Lsat= 0.1493901807245695 \n",
      "acc for Psat= 0.1532051003434592 \n",
      "acc for optim= 0.16668713643836477\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.004793156404048204\n",
      "Loss on test= 0.004427218809723854\n",
      "acc for Lsat= 0.14265286741364333 \n",
      "acc for Psat= 0.17226115283038881 \n",
      "acc for optim= 0.1454977655990256\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.00496499240398407\n",
      "Loss on test= 0.004247339442372322\n",
      "acc for Lsat= 0.08401504303846094 \n",
      "acc for Psat= 0.17032382981334296 \n",
      "acc for optim= 0.12425933892114295\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.005015801638364792\n",
      "Loss on test= 0.0044649564661085606\n",
      "acc for Lsat= 0.11393385696121389 \n",
      "acc for Psat= 0.12336344945166881 \n",
      "acc for optim= 0.13208966847095224\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.004981609061360359\n",
      "Loss on test= 0.004799836315214634\n",
      "acc for Lsat= 0.11195752152707428 \n",
      "acc for Psat= 0.13561215766498613 \n",
      "acc for optim= 0.1525194389331672\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.004782000556588173\n",
      "Loss on test= 0.004589116666465998\n",
      "acc for Lsat= 0.11080052628919172 \n",
      "acc for Psat= 0.1047245240252879 \n",
      "acc for optim= 0.1350120322054459\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.004847084172070026\n",
      "Loss on test= 0.004680894315242767\n",
      "acc for Lsat= 0.0815372958054973 \n",
      "acc for Psat= 0.13501498796459702 \n",
      "acc for optim= 0.14797054986572927\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.004803134128451347\n",
      "Loss on test= 0.0044228434562683105\n",
      "acc for Lsat= 0.16070067178871897 \n",
      "acc for Psat= 0.15970883083840212 \n",
      "acc for optim= 0.15988434726993242\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.004843811970204115\n",
      "Loss on test= 0.004539611283689737\n",
      "acc for Lsat= 0.10856937893873288 \n",
      "acc for Psat= 0.14988147172455987 \n",
      "acc for optim= 0.14489760249853134\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.004995403811335564\n",
      "Loss on test= 0.004551576916128397\n",
      "acc for Lsat= 0.10416134208854702 \n",
      "acc for Psat= 0.14234446651405758 \n",
      "acc for optim= 0.1531046350040318\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.0049356380477547646\n",
      "Loss on test= 0.004698969889432192\n",
      "acc for Lsat= 0.0995589611120522 \n",
      "acc for Psat= 0.14446821446634 \n",
      "acc for optim= 0.14275347450812761\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.004789638798683882\n",
      "Loss on test= 0.004937194753438234\n",
      "acc for Lsat= 0.11235228429238002 \n",
      "acc for Psat= 0.17482614336121413 \n",
      "acc for optim= 0.1384872339420124\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.004953427240252495\n",
      "Loss on test= 0.004356596153229475\n",
      "acc for Lsat= 0.12167192954156134 \n",
      "acc for Psat= 0.1862599468893475 \n",
      "acc for optim= 0.18031111338900196\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.004907490219920874\n",
      "Loss on test= 0.0043928492814302444\n",
      "acc for Lsat= 0.11783543886202905 \n",
      "acc for Psat= 0.1951284825336188 \n",
      "acc for optim= 0.15125450424643028\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.004986825864762068\n",
      "Loss on test= 0.0045393542386591434\n",
      "acc for Lsat= 0.1246737376269367 \n",
      "acc for Psat= 0.18825006754034096 \n",
      "acc for optim= 0.15783828434844813\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.004720072261989117\n",
      "Loss on test= 0.004889168310910463\n",
      "acc for Lsat= 0.10937966181275745 \n",
      "acc for Psat= 0.15752446901751682 \n",
      "acc for optim= 0.15690692617661423\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.004858772736042738\n",
      "Loss on test= 0.004703056067228317\n",
      "acc for Lsat= 0.10776428863755427 \n",
      "acc for Psat= 0.15881598823600346 \n",
      "acc for optim= 0.14076578534311718\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.0048278989270329475\n",
      "Loss on test= 0.0045205168426036835\n",
      "acc for Lsat= 0.10830394045398054 \n",
      "acc for Psat= 0.11021641917694877 \n",
      "acc for optim= 0.15272399741742346\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.004858432803303003\n",
      "Loss on test= 0.004847459029406309\n",
      "acc for Lsat= 0.10838176103101836 \n",
      "acc for Psat= 0.1821356767581569 \n",
      "acc for optim= 0.16740449911190403\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.004843083210289478\n",
      "Loss on test= 0.0045667048543691635\n",
      "acc for Lsat= 0.0885446370812133 \n",
      "acc for Psat= 0.14152118982747197 \n",
      "acc for optim= 0.15795707146430182\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.004748793318867683\n",
      "Loss on test= 0.004311382304877043\n",
      "acc for Lsat= 0.10590577565340532 \n",
      "acc for Psat= 0.166432060353044 \n",
      "acc for optim= 0.13706068777375752\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.004782655276358128\n",
      "Loss on test= 0.004359966143965721\n",
      "acc for Lsat= 0.12045616739326054 \n",
      "acc for Psat= 0.2094350406486127 \n",
      "acc for optim= 0.16437403526571062\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.004724660888314247\n",
      "Loss on test= 0.004406927619129419\n",
      "acc for Lsat= 0.13498838442481226 \n",
      "acc for Psat= 0.12351102607014279 \n",
      "acc for optim= 0.14767079019252882\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.004833936225622892\n",
      "Loss on test= 0.004046794027090073\n",
      "acc for Lsat= 0.08793548158266479 \n",
      "acc for Psat= 0.13064883866657814 \n",
      "acc for optim= 0.1491017680770407\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.004854723811149597\n",
      "Loss on test= 0.004224690143018961\n",
      "acc for Lsat= 0.13581187443600762 \n",
      "acc for Psat= 0.12076458096918133 \n",
      "acc for optim= 0.14625411687625778\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.004846733529120684\n",
      "Loss on test= 0.0044005620293319225\n",
      "acc for Lsat= 0.1064690397017532 \n",
      "acc for Psat= 0.09731783400315584 \n",
      "acc for optim= 0.13663458751721513\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.004746878985315561\n",
      "Loss on test= 0.004469480365514755\n",
      "acc for Lsat= 0.0945256626388679 \n",
      "acc for Psat= 0.10950323046805958 \n",
      "acc for optim= 0.14716748386207554\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.004803341813385487\n",
      "Loss on test= 0.004858097527176142\n",
      "acc for Lsat= 0.10847211106576854 \n",
      "acc for Psat= 0.19291524071660307 \n",
      "acc for optim= 0.1264825780979461\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.0047555239871144295\n",
      "Loss on test= 0.004563929513096809\n",
      "acc for Lsat= 0.13455905992951658 \n",
      "acc for Psat= 0.1728407928927077 \n",
      "acc for optim= 0.12458480588005234\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.004809304140508175\n",
      "Loss on test= 0.00452807080000639\n",
      "acc for Lsat= 0.128996756506644 \n",
      "acc for Psat= 0.13770493906405237 \n",
      "acc for optim= 0.1086227764478988\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.00464343698695302\n",
      "Loss on test= 0.004309758078306913\n",
      "acc for Lsat= 0.12227153206347591 \n",
      "acc for Psat= 0.15279128645650214 \n",
      "acc for optim= 0.13022037792123026\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.004750485997647047\n",
      "Loss on test= 0.004888473078608513\n",
      "acc for Lsat= 0.10421933520895739 \n",
      "acc for Psat= 0.13764961394998762 \n",
      "acc for optim= 0.14378760372185045\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.004765093792229891\n",
      "Loss on test= 0.004404064267873764\n",
      "acc for Lsat= 0.09357636380526754 \n",
      "acc for Psat= 0.16085337474942207 \n",
      "acc for optim= 0.12920136459999615\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.0047218408435583115\n",
      "Loss on test= 0.004512291867285967\n",
      "acc for Lsat= 0.1177042678076153 \n",
      "acc for Psat= 0.1715860978907181 \n",
      "acc for optim= 0.1549294037847883\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.004876413382589817\n",
      "Loss on test= 0.004629969596862793\n",
      "acc for Lsat= 0.139438242237601 \n",
      "acc for Psat= 0.18623464242894747 \n",
      "acc for optim= 0.11036318188740148\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.004682349972426891\n",
      "Loss on test= 0.004467652179300785\n",
      "acc for Lsat= 0.13440490741696623 \n",
      "acc for Psat= 0.17072244816356236 \n",
      "acc for optim= 0.14009380096103996\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.00471716932952404\n",
      "Loss on test= 0.004322430584579706\n",
      "acc for Lsat= 0.11702882431240545 \n",
      "acc for Psat= 0.1284351696053313 \n",
      "acc for optim= 0.1401122881927424\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.004751052241772413\n",
      "Loss on test= 0.004621207248419523\n",
      "acc for Lsat= 0.14073291519242856 \n",
      "acc for Psat= 0.21758853106035125 \n",
      "acc for optim= 0.1377682782864819\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.0047914497554302216\n",
      "Loss on test= 0.004574906546622515\n",
      "acc for Lsat= 0.06983620034427279 \n",
      "acc for Psat= 0.11159281838788754 \n",
      "acc for optim= 0.1377669327581922\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.004643341060727835\n",
      "Loss on test= 0.004281558096408844\n",
      "acc for Lsat= 0.1290014439986812 \n",
      "acc for Psat= 0.1522844875127905 \n",
      "acc for optim= 0.10985894837520188\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.004598430823534727\n",
      "Loss on test= 0.0047865877859294415\n",
      "acc for Lsat= 0.10679828021804699 \n",
      "acc for Psat= 0.11503346440278822 \n",
      "acc for optim= 0.11091873184260395\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.0047210645861923695\n",
      "Loss on test= 0.004788902122527361\n",
      "acc for Lsat= 0.14875763983258772 \n",
      "acc for Psat= 0.15032993965885705 \n",
      "acc for optim= 0.14882625153081286\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.00460081035271287\n",
      "Loss on test= 0.004902081564068794\n",
      "acc for Lsat= 0.10045703790254062 \n",
      "acc for Psat= 0.2032233206037846 \n",
      "acc for optim= 0.1588623503016101\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.004580187611281872\n",
      "Loss on test= 0.004266842734068632\n",
      "acc for Lsat= 0.11270347330719233 \n",
      "acc for Psat= 0.11559338024300006 \n",
      "acc for optim= 0.14841886955158165\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.0047791083343327045\n",
      "Loss on test= 0.004534282721579075\n",
      "acc for Lsat= 0.07657217395090912 \n",
      "acc for Psat= 0.11083108181547788 \n",
      "acc for optim= 0.13919384089402026\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.004571834579110146\n",
      "Loss on test= 0.004386811517179012\n",
      "acc for Lsat= 0.1121020495839831 \n",
      "acc for Psat= 0.13347776668767133 \n",
      "acc for optim= 0.1324375420420741\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.004663539584726095\n",
      "Loss on test= 0.0046205176040530205\n",
      "acc for Lsat= 0.07449234054527348 \n",
      "acc for Psat= 0.140586592670944 \n",
      "acc for optim= 0.12415352357978311\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.004666048102080822\n",
      "Loss on test= 0.005264449864625931\n",
      "acc for Lsat= 0.13582917975468767 \n",
      "acc for Psat= 0.14959307366775143 \n",
      "acc for optim= 0.15482868916458553\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.004516042303293943\n",
      "Loss on test= 0.004846874624490738\n",
      "acc for Lsat= 0.09471024310268047 \n",
      "acc for Psat= 0.14100367606927952 \n",
      "acc for optim= 0.1251028958811528\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.004648769274353981\n",
      "Loss on test= 0.004672667011618614\n",
      "acc for Lsat= 0.11732491788764794 \n",
      "acc for Psat= 0.13499176261636117 \n",
      "acc for optim= 0.13957854370690054\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.004589691758155823\n",
      "Loss on test= 0.004556702449917793\n",
      "acc for Lsat= 0.1332806312582559 \n",
      "acc for Psat= 0.16512227650835282 \n",
      "acc for optim= 0.1345616647352775\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.00471211364492774\n",
      "Loss on test= 0.004417941905558109\n",
      "acc for Lsat= 0.16128989388852866 \n",
      "acc for Psat= 0.10438806068850681 \n",
      "acc for optim= 0.15374597472449145\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.0047097885981202126\n",
      "Loss on test= 0.004521069582551718\n",
      "acc for Lsat= 0.12363320889158382 \n",
      "acc for Psat= 0.14802599927255264 \n",
      "acc for optim= 0.1451865586762627\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.004657756071537733\n",
      "Loss on test= 0.00433519808575511\n",
      "acc for Lsat= 0.12443401661908461 \n",
      "acc for Psat= 0.14286923077371386 \n",
      "acc for optim= 0.13956054010325009\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.004675975069403648\n",
      "Loss on test= 0.004658767953515053\n",
      "acc for Lsat= 0.10982843395322561 \n",
      "acc for Psat= 0.17332938701535264 \n",
      "acc for optim= 0.1501006974528233\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.004652486648410559\n",
      "Loss on test= 0.004671927075833082\n",
      "acc for Lsat= 0.15795742513404953 \n",
      "acc for Psat= 0.21272482060723835 \n",
      "acc for optim= 0.17423145659267902\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.004485359415411949\n",
      "Loss on test= 0.004588552750647068\n",
      "acc for Lsat= 0.1420824039572229 \n",
      "acc for Psat= 0.1654554771569868 \n",
      "acc for optim= 0.14564137243562275\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.004618264269083738\n",
      "Loss on test= 0.004521493334323168\n",
      "acc for Lsat= 0.11159030198016101 \n",
      "acc for Psat= 0.14339766320255068 \n",
      "acc for optim= 0.1518161982918779\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.004707111977040768\n",
      "Loss on test= 0.004747151862829924\n",
      "acc for Lsat= 0.11897565424442291 \n",
      "acc for Psat= 0.17988077706346908 \n",
      "acc for optim= 0.12747327155537075\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.004566480405628681\n",
      "Loss on test= 0.00468977726995945\n",
      "acc for Lsat= 0.12032957737230593 \n",
      "acc for Psat= 0.1754626538604498 \n",
      "acc for optim= 0.15833955920404857\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.004618208389729261\n",
      "Loss on test= 0.004410029388964176\n",
      "acc for Lsat= 0.09137473995279935 \n",
      "acc for Psat= 0.12423506084208687 \n",
      "acc for optim= 0.14750202419236302\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.004754998255521059\n",
      "Loss on test= 0.004337493795901537\n",
      "acc for Lsat= 0.12318056617449555 \n",
      "acc for Psat= 0.14985323035054737 \n",
      "acc for optim= 0.11634213415284951\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.004697018768638372\n",
      "Loss on test= 0.004354449454694986\n",
      "acc for Lsat= 0.14707915598733556 \n",
      "acc for Psat= 0.2337319196926223 \n",
      "acc for optim= 0.15741780100183356\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.004791808780282736\n",
      "Loss on test= 0.004455883987247944\n",
      "acc for Lsat= 0.12000319242684378 \n",
      "acc for Psat= 0.1424230633290588 \n",
      "acc for optim= 0.12407460384484795\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.004678668919950724\n",
      "Loss on test= 0.004462374374270439\n",
      "acc for Lsat= 0.10649944016606444 \n",
      "acc for Psat= 0.16574558801949024 \n",
      "acc for optim= 0.14456627973251873\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.004706962034106255\n",
      "Loss on test= 0.004427799489349127\n",
      "acc for Lsat= 0.1328458274818129 \n",
      "acc for Psat= 0.15048206690698862 \n",
      "acc for optim= 0.14338610186758968\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.004800208378583193\n",
      "Loss on test= 0.004611613228917122\n",
      "acc for Lsat= 0.13225935008085798 \n",
      "acc for Psat= 0.10798925918061286 \n",
      "acc for optim= 0.16218340698267436\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.004546154756098986\n",
      "Loss on test= 0.004627452231943607\n",
      "acc for Lsat= 0.10988575499504805 \n",
      "acc for Psat= 0.1486673750009181 \n",
      "acc for optim= 0.1463766772713926\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.004609396681189537\n",
      "Loss on test= 0.00411960668861866\n",
      "acc for Lsat= 0.12260544340177956 \n",
      "acc for Psat= 0.1690768582953347 \n",
      "acc for optim= 0.18377415396066177\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.004453050903975964\n",
      "Loss on test= 0.004469523672014475\n",
      "acc for Lsat= 0.10420420137880784 \n",
      "acc for Psat= 0.11515167774632573 \n",
      "acc for optim= 0.1313362111751404\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.004639179911464453\n",
      "Loss on test= 0.0042908028699457645\n",
      "acc for Lsat= 0.12165603872078161 \n",
      "acc for Psat= 0.19075650814920664 \n",
      "acc for optim= 0.11603591043967754\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.004468022845685482\n",
      "Loss on test= 0.004222591407597065\n",
      "acc for Lsat= 0.10665044250587623 \n",
      "acc for Psat= 0.16558986715972424 \n",
      "acc for optim= 0.1543541862629354\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.004438449162989855\n",
      "Loss on test= 0.004510206636041403\n",
      "acc for Lsat= 0.13330279546789825 \n",
      "acc for Psat= 0.14184188366764122 \n",
      "acc for optim= 0.1551212499746018\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.004528499674052\n",
      "Loss on test= 0.004755155183374882\n",
      "acc for Lsat= 0.11140602903388855 \n",
      "acc for Psat= 0.121359098288748 \n",
      "acc for optim= 0.12592548178508878\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.004554593935608864\n",
      "Loss on test= 0.004668134730309248\n",
      "acc for Lsat= 0.09517514149451421 \n",
      "acc for Psat= 0.16971037826604313 \n",
      "acc for optim= 0.1527817516018533\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.004421261604875326\n",
      "Loss on test= 0.0045914859510958195\n",
      "acc for Lsat= 0.12914254842326045 \n",
      "acc for Psat= 0.10842532566231158 \n",
      "acc for optim= 0.1331904181667293\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.004512387793511152\n",
      "Loss on test= 0.004477012436836958\n",
      "acc for Lsat= 0.11449854986535178 \n",
      "acc for Psat= 0.1419075946840975 \n",
      "acc for optim= 0.14710985258635548\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.00466409046202898\n",
      "Loss on test= 0.004691937007009983\n",
      "acc for Lsat= 0.12923035139424932 \n",
      "acc for Psat= 0.1524167258499397 \n",
      "acc for optim= 0.13804843054256505\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.004462267737835646\n",
      "Loss on test= 0.00420595146715641\n",
      "acc for Lsat= 0.11054454601576759 \n",
      "acc for Psat= 0.16960214947660765 \n",
      "acc for optim= 0.162659315392375\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.004525491502135992\n",
      "Loss on test= 0.004461165517568588\n",
      "acc for Lsat= 0.09862728472540362 \n",
      "acc for Psat= 0.11720350252047258 \n",
      "acc for optim= 0.13109968157692087\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.004505575634539127\n",
      "Loss on test= 0.004643773660063744\n",
      "acc for Lsat= 0.09450243687671092 \n",
      "acc for Psat= 0.1275688515872591 \n",
      "acc for optim= 0.15497532574873832\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.004633041564375162\n",
      "Loss on test= 0.004509401973336935\n",
      "acc for Lsat= 0.09458551881834865 \n",
      "acc for Psat= 0.11104345817713895 \n",
      "acc for optim= 0.12984516399188173\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.004747980274260044\n",
      "Loss on test= 0.00490663293749094\n",
      "acc for Lsat= 0.08651144604179233 \n",
      "acc for Psat= 0.14326165730340612 \n",
      "acc for optim= 0.14841227005753252\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.004625970497727394\n",
      "Loss on test= 0.00460926815867424\n",
      "acc for Lsat= 0.11823457017696153 \n",
      "acc for Psat= 0.15586539223376247 \n",
      "acc for optim= 0.13290080407427418\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.004435657989233732\n",
      "Loss on test= 0.004452725872397423\n",
      "acc for Lsat= 0.11104100388992164 \n",
      "acc for Psat= 0.1224076804291043 \n",
      "acc for optim= 0.15192603013969752\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.004423629026859999\n",
      "Loss on test= 0.0048003895208239555\n",
      "acc for Lsat= 0.1295815017591748 \n",
      "acc for Psat= 0.19057940076001817 \n",
      "acc for optim= 0.12670826979188454\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.004418871831148863\n",
      "Loss on test= 0.004392866510897875\n",
      "acc for Lsat= 0.1452072393989915 \n",
      "acc for Psat= 0.1682883970077253 \n",
      "acc for optim= 0.16914787691914374\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.0046083140186965466\n",
      "Loss on test= 0.004512480925768614\n",
      "acc for Lsat= 0.12284586221600573 \n",
      "acc for Psat= 0.14357025942040813 \n",
      "acc for optim= 0.1426570164039731\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.004497766960412264\n",
      "Loss on test= 0.004812337923794985\n",
      "acc for Lsat= 0.1312626831026541 \n",
      "acc for Psat= 0.14400876416928238 \n",
      "acc for optim= 0.13828390205485952\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.004535486456006765\n",
      "Loss on test= 0.004527104087173939\n",
      "acc for Lsat= 0.1420231407456514 \n",
      "acc for Psat= 0.12775897670588973 \n",
      "acc for optim= 0.14767122123804358\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.0043836734257638454\n",
      "Loss on test= 0.004297049716114998\n",
      "acc for Lsat= 0.11607245500070146 \n",
      "acc for Psat= 0.08816752148171265 \n",
      "acc for optim= 0.14501339009924172\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.004640066064894199\n",
      "Loss on test= 0.004489778075367212\n",
      "acc for Lsat= 0.08584978775535193 \n",
      "acc for Psat= 0.16181529944555628 \n",
      "acc for optim= 0.1241858208603743\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.004334445111453533\n",
      "Loss on test= 0.004643159452825785\n",
      "acc for Lsat= 0.13229977908647722 \n",
      "acc for Psat= 0.1417819463337461 \n",
      "acc for optim= 0.15040597423083252\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.004364358261227608\n",
      "Loss on test= 0.00438692094758153\n",
      "acc for Lsat= 0.07843082380067143 \n",
      "acc for Psat= 0.12520732536601523 \n",
      "acc for optim= 0.1470307856798172\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.0042831446044147015\n",
      "Loss on test= 0.004446183331310749\n",
      "acc for Lsat= 0.06244667785035239 \n",
      "acc for Psat= 0.10184307885356247 \n",
      "acc for optim= 0.18593009397025323\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.004242674447596073\n",
      "Loss on test= 0.004809131380170584\n",
      "acc for Lsat= 0.17968805951790678 \n",
      "acc for Psat= 0.16429620396552813 \n",
      "acc for optim= 0.12791583386974203\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.004586771596223116\n",
      "Loss on test= 0.004720928147435188\n",
      "acc for Lsat= 0.13272546006677052 \n",
      "acc for Psat= 0.1974090752709243 \n",
      "acc for optim= 0.1772586435286535\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.004478638991713524\n",
      "Loss on test= 0.004178609233349562\n",
      "acc for Lsat= 0.10592055230194496 \n",
      "acc for Psat= 0.14985787966159275 \n",
      "acc for optim= 0.11840825755563048\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.004562927410006523\n",
      "Loss on test= 0.004285604227334261\n",
      "acc for Lsat= 0.12586735690840417 \n",
      "acc for Psat= 0.1467844672087166 \n",
      "acc for optim= 0.11734056043335134\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.004599034320563078\n",
      "Loss on test= 0.0046424162574112415\n",
      "acc for Lsat= 0.10564758388015132 \n",
      "acc for Psat= 0.09665313720082243 \n",
      "acc for optim= 0.1265340116288927\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.004427406936883926\n",
      "Loss on test= 0.004949461203068495\n",
      "acc for Lsat= 0.11296762615287055 \n",
      "acc for Psat= 0.15695562793148887 \n",
      "acc for optim= 0.14647890055655605\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.004300746601074934\n",
      "Loss on test= 0.0044106305576860905\n",
      "acc for Lsat= 0.07862416952331033 \n",
      "acc for Psat= 0.12131983660058016 \n",
      "acc for optim= 0.13092905572719044\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.004553157836198807\n",
      "Loss on test= 0.004615554120391607\n",
      "acc for Lsat= 0.12766938806614941 \n",
      "acc for Psat= 0.14445170460061896 \n",
      "acc for optim= 0.14138624092770946\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.00432024709880352\n",
      "Loss on test= 0.004535239189863205\n",
      "acc for Lsat= 0.1026629174367473 \n",
      "acc for Psat= 0.14814189655913246 \n",
      "acc for optim= 0.1213293777157863\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.004396315198391676\n",
      "Loss on test= 0.004300534725189209\n",
      "acc for Lsat= 0.10319610661180276 \n",
      "acc for Psat= 0.10655705982612239 \n",
      "acc for optim= 0.12903179838839504\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.00448643509298563\n",
      "Loss on test= 0.004346249625086784\n",
      "acc for Lsat= 0.12786152700169218 \n",
      "acc for Psat= 0.1331505555814753 \n",
      "acc for optim= 0.14086733851581812\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.004621836822479963\n",
      "Loss on test= 0.0044548693113029\n",
      "acc for Lsat= 0.13272649044584897 \n",
      "acc for Psat= 0.1813034996804264 \n",
      "acc for optim= 0.1433232548750109\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.004495477303862572\n",
      "Loss on test= 0.004247221630066633\n",
      "acc for Lsat= 0.09096230486304396 \n",
      "acc for Psat= 0.14250013003927758 \n",
      "acc for optim= 0.12139389312101735\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.004246586933732033\n",
      "Loss on test= 0.004892541561275721\n",
      "acc for Lsat= 0.1147434424686556 \n",
      "acc for Psat= 0.14769703563716677 \n",
      "acc for optim= 0.14781459451963505\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.004465014208108187\n",
      "Loss on test= 0.004731869325041771\n",
      "acc for Lsat= 0.09369172117051978 \n",
      "acc for Psat= 0.14073283763395417 \n",
      "acc for optim= 0.1329769969581523\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.004450808744877577\n",
      "Loss on test= 0.004561366513371468\n",
      "acc for Lsat= 0.18090965849761334 \n",
      "acc for Psat= 0.11823186551272455 \n",
      "acc for optim= 0.1410937095578346\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.004574027843773365\n",
      "Loss on test= 0.004483297932893038\n",
      "acc for Lsat= 0.1622547615940372 \n",
      "acc for Psat= 0.16412711350454223 \n",
      "acc for optim= 0.13538356508231825\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.004360448569059372\n",
      "Loss on test= 0.0045828018337488174\n",
      "acc for Lsat= 0.09799921185994107 \n",
      "acc for Psat= 0.11373382131569088 \n",
      "acc for optim= 0.13829106325283647\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.004383513703942299\n",
      "Loss on test= 0.004556495230644941\n",
      "acc for Lsat= 0.09555705760916074 \n",
      "acc for Psat= 0.10544649904800786 \n",
      "acc for optim= 0.14393178704712126\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.004320484586060047\n",
      "Loss on test= 0.004339689388871193\n",
      "acc for Lsat= 0.08348446851596236 \n",
      "acc for Psat= 0.14740124707006746 \n",
      "acc for optim= 0.13224247467911077\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.004494617693126202\n",
      "Loss on test= 0.004744814708828926\n",
      "acc for Lsat= 0.10826937836180958 \n",
      "acc for Psat= 0.14280737235417795 \n",
      "acc for optim= 0.13615292714287838\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.004422237165272236\n",
      "Loss on test= 0.004297742620110512\n",
      "acc for Lsat= 0.08336805402197772 \n",
      "acc for Psat= 0.16796468692417774 \n",
      "acc for optim= 0.14489379649360976\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.004229927435517311\n",
      "Loss on test= 0.004424895625561476\n",
      "acc for Lsat= 0.10312043156267868 \n",
      "acc for Psat= 0.12721588169935988 \n",
      "acc for optim= 0.1269795543824633\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.004482997581362724\n",
      "Loss on test= 0.004464535042643547\n",
      "acc for Lsat= 0.13056601501173443 \n",
      "acc for Psat= 0.13246201801424226 \n",
      "acc for optim= 0.142155840785967\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.00434387382119894\n",
      "Loss on test= 0.0045169647783041\n",
      "acc for Lsat= 0.08608025837586158 \n",
      "acc for Psat= 0.1549807155970484 \n",
      "acc for optim= 0.11154614637295406\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.0042531443759799\n",
      "Loss on test= 0.0044739204458892345\n",
      "acc for Lsat= 0.11146744257873958 \n",
      "acc for Psat= 0.1105230758484039 \n",
      "acc for optim= 0.12834129782600534\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.004195497836917639\n",
      "Loss on test= 0.004527718760073185\n",
      "acc for Lsat= 0.12807453206429878 \n",
      "acc for Psat= 0.13402049731747764 \n",
      "acc for optim= 0.1467099895493852\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.004164088983088732\n",
      "Loss on test= 0.0048533836379647255\n",
      "acc for Lsat= 0.13101178211056524 \n",
      "acc for Psat= 0.15541450824174616 \n",
      "acc for optim= 0.12268491637789541\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.0044136266224086285\n",
      "Loss on test= 0.004672523587942123\n",
      "acc for Lsat= 0.1371013903990388 \n",
      "acc for Psat= 0.17852039500657055 \n",
      "acc for optim= 0.1575026575786372\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.004336239770054817\n",
      "Loss on test= 0.004449102096259594\n",
      "acc for Lsat= 0.11069993178049724 \n",
      "acc for Psat= 0.12471346044912934 \n",
      "acc for optim= 0.11522627306274241\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.004371003247797489\n",
      "Loss on test= 0.004391746129840612\n",
      "acc for Lsat= 0.09755612226823966 \n",
      "acc for Psat= 0.09114562739462902 \n",
      "acc for optim= 0.13095704874851638\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.004403247963637114\n",
      "Loss on test= 0.004526028409600258\n",
      "acc for Lsat= 0.10484657260692781 \n",
      "acc for Psat= 0.13981535813460746 \n",
      "acc for optim= 0.16207916206783718\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.004263340961188078\n",
      "Loss on test= 0.004325477406382561\n",
      "acc for Lsat= 0.11227922679649459 \n",
      "acc for Psat= 0.1616984464150543 \n",
      "acc for optim= 0.09640190763295525\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.004402655642479658\n",
      "Loss on test= 0.004313343204557896\n",
      "acc for Lsat= 0.14601365331974295 \n",
      "acc for Psat= 0.14613925479352474 \n",
      "acc for optim= 0.15122669303996694\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.004332960117608309\n",
      "Loss on test= 0.004446628503501415\n",
      "acc for Lsat= 0.130589234112348 \n",
      "acc for Psat= 0.09904509619809687 \n",
      "acc for optim= 0.13195563053401807\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.004306698217988014\n",
      "Loss on test= 0.00468245055526495\n",
      "acc for Lsat= 0.14219922290390563 \n",
      "acc for Psat= 0.13851465336564514 \n",
      "acc for optim= 0.11866138461563322\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.004201890900731087\n",
      "Loss on test= 0.004313495010137558\n",
      "acc for Lsat= 0.14020802877429459 \n",
      "acc for Psat= 0.1521709949399034 \n",
      "acc for optim= 0.16414438363992506\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.00430193729698658\n",
      "Loss on test= 0.004409067798405886\n",
      "acc for Lsat= 0.09966392142491208 \n",
      "acc for Psat= 0.13324314138541618 \n",
      "acc for optim= 0.11307980854892069\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.004367679823189974\n",
      "Loss on test= 0.004429759457707405\n",
      "acc for Lsat= 0.08835023800687243 \n",
      "acc for Psat= 0.16737286438648072 \n",
      "acc for optim= 0.1657810126327806\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.004122131038457155\n",
      "Loss on test= 0.0046820687130093575\n",
      "acc for Lsat= 0.15556467109773722 \n",
      "acc for Psat= 0.1837573063094169 \n",
      "acc for optim= 0.1553703661257815\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.004289882257580757\n",
      "Loss on test= 0.004446905106306076\n",
      "acc for Lsat= 0.11196493745471041 \n",
      "acc for Psat= 0.13055513975107008 \n",
      "acc for optim= 0.17297225466205013\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.004279029089957476\n",
      "Loss on test= 0.004350405186414719\n",
      "acc for Lsat= 0.09843434219429684 \n",
      "acc for Psat= 0.12322616887589295 \n",
      "acc for optim= 0.13362807572250152\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.004163041245192289\n",
      "Loss on test= 0.004525651223957539\n",
      "acc for Lsat= 0.11546157153012852 \n",
      "acc for Psat= 0.17499586794939306 \n",
      "acc for optim= 0.14016794833716834\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.00433733593672514\n",
      "Loss on test= 0.0045072524808347225\n",
      "acc for Lsat= 0.1292109325942066 \n",
      "acc for Psat= 0.1484591772572862 \n",
      "acc for optim= 0.16707028138140836\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.004282078705728054\n",
      "Loss on test= 0.004692636895924807\n",
      "acc for Lsat= 0.102633976092976 \n",
      "acc for Psat= 0.14294995884928438 \n",
      "acc for optim= 0.13676929825709927\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.004237448796629906\n",
      "Loss on test= 0.004319284576922655\n",
      "acc for Lsat= 0.1223523408277995 \n",
      "acc for Psat= 0.17427079876263937 \n",
      "acc for optim= 0.1380727374408808\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.004342180676758289\n",
      "Loss on test= 0.00442999554798007\n",
      "acc for Lsat= 0.09366335212770435 \n",
      "acc for Psat= 0.15598582931690747 \n",
      "acc for optim= 0.13159565358526176\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.004254162777215242\n",
      "Loss on test= 0.004660485312342644\n",
      "acc for Lsat= 0.11521712773376042 \n",
      "acc for Psat= 0.12764302179049183 \n",
      "acc for optim= 0.1537829198771053\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.004277520347386599\n",
      "Loss on test= 0.004676039330661297\n",
      "acc for Lsat= 0.09194468975894982 \n",
      "acc for Psat= 0.1354284185088343 \n",
      "acc for optim= 0.15923958851231468\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.004231721628457308\n",
      "Loss on test= 0.00446007214486599\n",
      "acc for Lsat= 0.11886985504922147 \n",
      "acc for Psat= 0.17159948153938684 \n",
      "acc for optim= 0.16228026194666098\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.004260511603206396\n",
      "Loss on test= 0.004891286138445139\n",
      "acc for Lsat= 0.07364374391747536 \n",
      "acc for Psat= 0.1190263504265911 \n",
      "acc for optim= 0.13154457747522327\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.00425629923120141\n",
      "Loss on test= 0.004410967230796814\n",
      "acc for Lsat= 0.11225053345939766 \n",
      "acc for Psat= 0.15602160822082725 \n",
      "acc for optim= 0.14552409015595913\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.004331769421696663\n",
      "Loss on test= 0.004486789461225271\n",
      "acc for Lsat= 0.11310907080769539 \n",
      "acc for Psat= 0.1747938721608888 \n",
      "acc for optim= 0.15002192435268727\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.004286262206733227\n",
      "Loss on test= 0.004621172323822975\n",
      "acc for Lsat= 0.08790707026815249 \n",
      "acc for Psat= 0.16753433287117836 \n",
      "acc for optim= 0.15250443449864784\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.004369866568595171\n",
      "Loss on test= 0.00461712246760726\n",
      "acc for Lsat= 0.09755430820708473 \n",
      "acc for Psat= 0.1353557826951146 \n",
      "acc for optim= 0.1588599526633819\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.0041787582449615\n",
      "Loss on test= 0.004369230940937996\n",
      "acc for Lsat= 0.14420939469709992 \n",
      "acc for Psat= 0.15654430129668778 \n",
      "acc for optim= 0.13579201242989963\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.004347569774836302\n",
      "Loss on test= 0.0047418344765901566\n",
      "acc for Lsat= 0.09092950645006365 \n",
      "acc for Psat= 0.12247015608267652 \n",
      "acc for optim= 0.13014292323754895\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.004125815816223621\n",
      "Loss on test= 0.004489084705710411\n",
      "acc for Lsat= 0.09629834940036137 \n",
      "acc for Psat= 0.1022864230391052 \n",
      "acc for optim= 0.12130648813520868\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.004216345492750406\n",
      "Loss on test= 0.004532182589173317\n",
      "acc for Lsat= 0.09054520446807146 \n",
      "acc for Psat= 0.13956739300111723 \n",
      "acc for optim= 0.12857382629428887\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.004174368921667337\n",
      "Loss on test= 0.004516248591244221\n",
      "acc for Lsat= 0.1292802558487488 \n",
      "acc for Psat= 0.16513682353413767 \n",
      "acc for optim= 0.1485097332754069\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.004158000461757183\n",
      "Loss on test= 0.004654238000512123\n",
      "acc for Lsat= 0.10230358607239193 \n",
      "acc for Psat= 0.13208874547854066 \n",
      "acc for optim= 0.11955892760306597\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.004243526142090559\n",
      "Loss on test= 0.00441385805606842\n",
      "acc for Lsat= 0.11201298916421365 \n",
      "acc for Psat= 0.15034480718895793 \n",
      "acc for optim= 0.13987983698542747\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.004294185899198055\n",
      "Loss on test= 0.004417167976498604\n",
      "acc for Lsat= 0.11116724797627991 \n",
      "acc for Psat= 0.1771236545820203 \n",
      "acc for optim= 0.14408757897197372\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.004012534860521555\n",
      "Loss on test= 0.0045992350205779076\n",
      "acc for Lsat= 0.10432323976419866 \n",
      "acc for Psat= 0.14913131586379474 \n",
      "acc for optim= 0.133651418145746\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.00429093511775136\n",
      "Loss on test= 0.0045816064812242985\n",
      "acc for Lsat= 0.11361211155437761 \n",
      "acc for Psat= 0.15076940333367223 \n",
      "acc for optim= 0.12847967453611395\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.004343576263636351\n",
      "Loss on test= 0.004626351408660412\n",
      "acc for Lsat= 0.09763665637001395 \n",
      "acc for Psat= 0.17400053829058176 \n",
      "acc for optim= 0.1321224243276649\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.004309060052037239\n",
      "Loss on test= 0.004619108512997627\n",
      "acc for Lsat= 0.10623413841757509 \n",
      "acc for Psat= 0.13462478181140292 \n",
      "acc for optim= 0.13217084678924745\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.004165432881563902\n",
      "Loss on test= 0.004572457633912563\n",
      "acc for Lsat= 0.14145256501312056 \n",
      "acc for Psat= 0.17444505092377463 \n",
      "acc for optim= 0.13030635110206074\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.003993923310190439\n",
      "Loss on test= 0.004464267287403345\n",
      "acc for Lsat= 0.12741062831547526 \n",
      "acc for Psat= 0.15085366213073334 \n",
      "acc for optim= 0.10597938909712765\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.004171187058091164\n",
      "Loss on test= 0.004853371996432543\n",
      "acc for Lsat= 0.12867918398438227 \n",
      "acc for Psat= 0.15134175799580085 \n",
      "acc for optim= 0.12369155842396948\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.004150231834501028\n",
      "Loss on test= 0.004480203613638878\n",
      "acc for Lsat= 0.0979698666681846 \n",
      "acc for Psat= 0.11149059060133165 \n",
      "acc for optim= 0.13431347999721766\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.004186821635812521\n",
      "Loss on test= 0.004591079894453287\n",
      "acc for Lsat= 0.10728020799191047 \n",
      "acc for Psat= 0.14151439463926685 \n",
      "acc for optim= 0.12393785340504514\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.004181350115686655\n",
      "Loss on test= 0.004648012574762106\n",
      "acc for Lsat= 0.09845551134397586 \n",
      "acc for Psat= 0.13616331783123314 \n",
      "acc for optim= 0.1407716419392576\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.004151794593781233\n",
      "Loss on test= 0.004833766259253025\n",
      "acc for Lsat= 0.13075030100945798 \n",
      "acc for Psat= 0.169737468732314 \n",
      "acc for optim= 0.1259079659098966\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.004094969481229782\n",
      "Loss on test= 0.004274976439774036\n",
      "acc for Lsat= 0.09150075984911786 \n",
      "acc for Psat= 0.12976719883994925 \n",
      "acc for optim= 0.14067052646229664\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.0042300112545490265\n",
      "Loss on test= 0.00431704381480813\n",
      "acc for Lsat= 0.10941639920282695 \n",
      "acc for Psat= 0.158587536153694 \n",
      "acc for optim= 0.17074043759041363\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.004210107494145632\n",
      "Loss on test= 0.004572039004415274\n",
      "acc for Lsat= 0.1010838755222115 \n",
      "acc for Psat= 0.13523911953800255 \n",
      "acc for optim= 0.11657394885292484\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.004181406926363707\n",
      "Loss on test= 0.0045736730098724365\n",
      "acc for Lsat= 0.1322151462857922 \n",
      "acc for Psat= 0.1421672214055434 \n",
      "acc for optim= 0.1210290659736428\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.004125074949115515\n",
      "Loss on test= 0.004135527182370424\n",
      "acc for Lsat= 0.14909387597193322 \n",
      "acc for Psat= 0.1417611766503089 \n",
      "acc for optim= 0.13886853286789524\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.004325308371335268\n",
      "Loss on test= 0.004444639664143324\n",
      "acc for Lsat= 0.06723249796777964 \n",
      "acc for Psat= 0.10749571330638395 \n",
      "acc for optim= 0.1239143115364843\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.004246946424245834\n",
      "Loss on test= 0.004710644017904997\n",
      "acc for Lsat= 0.1376557029111104 \n",
      "acc for Psat= 0.14642294858478838 \n",
      "acc for optim= 0.13617872074246407\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.004042461048811674\n",
      "Loss on test= 0.004520383197814226\n",
      "acc for Lsat= 0.08824709549339281 \n",
      "acc for Psat= 0.13120508400930297 \n",
      "acc for optim= 0.13327289734863573\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.003985485527664423\n",
      "Loss on test= 0.004720676224678755\n",
      "acc for Lsat= 0.09592724185333484 \n",
      "acc for Psat= 0.10361935829213406 \n",
      "acc for optim= 0.1336964190316697\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.004226315300911665\n",
      "Loss on test= 0.004297160543501377\n",
      "acc for Lsat= 0.08838902129274276 \n",
      "acc for Psat= 0.1106509261040224 \n",
      "acc for optim= 0.12029182414213817\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.0041650692000985146\n",
      "Loss on test= 0.00433426583185792\n",
      "acc for Lsat= 0.12299912578115861 \n",
      "acc for Psat= 0.16484506538189533 \n",
      "acc for optim= 0.16326076568414769\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.004365568980574608\n",
      "Loss on test= 0.004485870245844126\n",
      "acc for Lsat= 0.09820849417398374 \n",
      "acc for Psat= 0.1696731514400906 \n",
      "acc for optim= 0.12705346768618458\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.004251851700246334\n",
      "Loss on test= 0.004568645730614662\n",
      "acc for Lsat= 0.13518261569293422 \n",
      "acc for Psat= 0.13514022156596184 \n",
      "acc for optim= 0.14149465898258817\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.004058870952576399\n",
      "Loss on test= 0.004635774530470371\n",
      "acc for Lsat= 0.07574672321788967 \n",
      "acc for Psat= 0.14400337724429038 \n",
      "acc for optim= 0.14001121139153838\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.00416269525885582\n",
      "Loss on test= 0.004819170106202364\n",
      "acc for Lsat= 0.09845435153692961 \n",
      "acc for Psat= 0.12223038421426383 \n",
      "acc for optim= 0.13878585871619484\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.0042287427932024\n",
      "Loss on test= 0.004393058829009533\n",
      "acc for Lsat= 0.09895355474307305 \n",
      "acc for Psat= 0.1396782046908306 \n",
      "acc for optim= 0.11626151799120837\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.0041419826447963715\n",
      "Loss on test= 0.004666164517402649\n",
      "acc for Lsat= 0.07411610733510719 \n",
      "acc for Psat= 0.08917868292580049 \n",
      "acc for optim= 0.14413984480779618\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.0040672398172318935\n",
      "Loss on test= 0.004625913221389055\n",
      "acc for Lsat= 0.13119075830197996 \n",
      "acc for Psat= 0.1753688036567635 \n",
      "acc for optim= 0.13625645966062117\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.004077587742358446\n",
      "Loss on test= 0.004313604906201363\n",
      "acc for Lsat= 0.1005259992606524 \n",
      "acc for Psat= 0.11945440640880002 \n",
      "acc for optim= 0.12105851537651485\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.0041366745717823505\n",
      "Loss on test= 0.004853355698287487\n",
      "acc for Lsat= 0.1536469115720441 \n",
      "acc for Psat= 0.16191889361167947 \n",
      "acc for optim= 0.1396364422721995\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.00413582194596529\n",
      "Loss on test= 0.00425884360447526\n",
      "acc for Lsat= 0.07426654348253375 \n",
      "acc for Psat= 0.12213630389629139 \n",
      "acc for optim= 0.16025174678199822\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.004130687098950148\n",
      "Loss on test= 0.0043836371041834354\n",
      "acc for Lsat= 0.1078538578003645 \n",
      "acc for Psat= 0.12036392526028471 \n",
      "acc for optim= 0.1333176464152833\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.004148478154093027\n",
      "Loss on test= 0.004194027744233608\n",
      "acc for Lsat= 0.12215275638219383 \n",
      "acc for Psat= 0.12353822475092278 \n",
      "acc for optim= 0.18249068450596598\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.004090109374374151\n",
      "Loss on test= 0.0043552350252866745\n",
      "acc for Lsat= 0.1066897561152776 \n",
      "acc for Psat= 0.1461816225071541 \n",
      "acc for optim= 0.11081867520180014\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.0042165969498455524\n",
      "Loss on test= 0.004411100875586271\n",
      "acc for Lsat= 0.11654675477701756 \n",
      "acc for Psat= 0.19156789588224557 \n",
      "acc for optim= 0.14317117610739338\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.004132390487939119\n",
      "Loss on test= 0.004890799522399902\n",
      "acc for Lsat= 0.0928699913331204 \n",
      "acc for Psat= 0.16946199722588062 \n",
      "acc for optim= 0.14719381442086565\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.004171531647443771\n",
      "Loss on test= 0.00445345975458622\n",
      "acc for Lsat= 0.11107748485584226 \n",
      "acc for Psat= 0.12938435851699776 \n",
      "acc for optim= 0.13949040243298644\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.0041129011660814285\n",
      "Loss on test= 0.0047233011573553085\n",
      "acc for Lsat= 0.0800908060433964 \n",
      "acc for Psat= 0.13847361665426028 \n",
      "acc for optim= 0.14628148006482256\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.004113429691642523\n",
      "Loss on test= 0.0043302495032548904\n",
      "acc for Lsat= 0.1411587622828342 \n",
      "acc for Psat= 0.14876033554577994 \n",
      "acc for optim= 0.1301267039962113\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.004078665282577276\n",
      "Loss on test= 0.004328334704041481\n",
      "acc for Lsat= 0.0938382414687011 \n",
      "acc for Psat= 0.14404764481716686 \n",
      "acc for optim= 0.1242103331670579\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.003914345521479845\n",
      "Loss on test= 0.004536001943051815\n",
      "acc for Lsat= 0.10008960475938188 \n",
      "acc for Psat= 0.14308198862191704 \n",
      "acc for optim= 0.16228032681263155\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.004178548231720924\n",
      "Loss on test= 0.0044579412788152695\n",
      "acc for Lsat= 0.11121949390508235 \n",
      "acc for Psat= 0.15702947192928857 \n",
      "acc for optim= 0.12490506734078129\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.0040183099918067455\n",
      "Loss on test= 0.004404081497341394\n",
      "acc for Lsat= 0.12387124795673622 \n",
      "acc for Psat= 0.15563824940990242 \n",
      "acc for optim= 0.1541158009527458\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.004088651388883591\n",
      "Loss on test= 0.004309708718210459\n",
      "acc for Lsat= 0.10320519381720158 \n",
      "acc for Psat= 0.119442335019509 \n",
      "acc for optim= 0.14448553008130854\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.004096085671335459\n",
      "Loss on test= 0.004419853910803795\n",
      "acc for Lsat= 0.12331266835745838 \n",
      "acc for Psat= 0.11697453219029638 \n",
      "acc for optim= 0.14709339880694947\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.003957242239266634\n",
      "Loss on test= 0.0045144278556108475\n",
      "acc for Lsat= 0.11141018015849921 \n",
      "acc for Psat= 0.14456310666476688 \n",
      "acc for optim= 0.09931556250537849\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.004064714536070824\n",
      "Loss on test= 0.004804711788892746\n",
      "acc for Lsat= 0.08133211602560347 \n",
      "acc for Psat= 0.14625768922269344 \n",
      "acc for optim= 0.1522583371713861\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.003972770646214485\n",
      "Loss on test= 0.00426776148378849\n",
      "acc for Lsat= 0.11019958110733165 \n",
      "acc for Psat= 0.11443577010908888 \n",
      "acc for optim= 0.14793206844478846\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.004045281559228897\n",
      "Loss on test= 0.00435115210711956\n",
      "acc for Lsat= 0.10619054714010821 \n",
      "acc for Psat= 0.12757874774332675 \n",
      "acc for optim= 0.14109176997509268\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.004107009153813124\n",
      "Loss on test= 0.0046342844143509865\n",
      "acc for Lsat= 0.12214352087014252 \n",
      "acc for Psat= 0.12318504246650264 \n",
      "acc for optim= 0.17728953508453238\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.004177098162472248\n",
      "Loss on test= 0.004392627160996199\n",
      "acc for Lsat= 0.12835743081652456 \n",
      "acc for Psat= 0.14309925730857584 \n",
      "acc for optim= 0.13806533773377952\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.0038540184032171965\n",
      "Loss on test= 0.004592397715896368\n",
      "acc for Lsat= 0.15034655740277636 \n",
      "acc for Psat= 0.12826185015324476 \n",
      "acc for optim= 0.12077019048026866\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.004012302029877901\n",
      "Loss on test= 0.004773589316755533\n",
      "acc for Lsat= 0.12621371272123522 \n",
      "acc for Psat= 0.19124362017545435 \n",
      "acc for optim= 0.10372708686110046\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.004007029812783003\n",
      "Loss on test= 0.004008473362773657\n",
      "acc for Lsat= 0.11676919827651647 \n",
      "acc for Psat= 0.11359415128309694 \n",
      "acc for optim= 0.1521102815038628\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.004073231015354395\n",
      "Loss on test= 0.004315940197557211\n",
      "acc for Lsat= 0.08154299182610379 \n",
      "acc for Psat= 0.16475454900258532 \n",
      "acc for optim= 0.1428307013379203\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.00405147997662425\n",
      "Loss on test= 0.0045194607228040695\n",
      "acc for Lsat= 0.09869434359845602 \n",
      "acc for Psat= 0.10495035528826217 \n",
      "acc for optim= 0.1870772520908051\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.004067709669470787\n",
      "Loss on test= 0.004511783830821514\n",
      "acc for Lsat= 0.11156746874459916 \n",
      "acc for Psat= 0.16353658219385478 \n",
      "acc for optim= 0.15975111603943837\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.003797992831096053\n",
      "Loss on test= 0.004741623066365719\n",
      "acc for Lsat= 0.06787224240704542 \n",
      "acc for Psat= 0.13485001357427487 \n",
      "acc for optim= 0.1538816632107935\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.004079177509993315\n",
      "Loss on test= 0.00453230133280158\n",
      "acc for Lsat= 0.09955944495999978 \n",
      "acc for Psat= 0.12933683245339328 \n",
      "acc for optim= 0.1408160533885368\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.0040630013681948185\n",
      "Loss on test= 0.0042134057730436325\n",
      "acc for Lsat= 0.09728404362168577 \n",
      "acc for Psat= 0.1370597979467776 \n",
      "acc for optim= 0.12878097428215873\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.004116805270314217\n",
      "Loss on test= 0.004570352844893932\n",
      "acc for Lsat= 0.10752256710677305 \n",
      "acc for Psat= 0.16042211045148885 \n",
      "acc for optim= 0.14598683016892108\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.003961007110774517\n",
      "Loss on test= 0.00466624740511179\n",
      "acc for Lsat= 0.11399549276878436 \n",
      "acc for Psat= 0.09515978714140753 \n",
      "acc for optim= 0.14839366109420857\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.003863331163302064\n",
      "Loss on test= 0.004804653115570545\n",
      "acc for Lsat= 0.12842299437357318 \n",
      "acc for Psat= 0.1307030397308861 \n",
      "acc for optim= 0.12249115553115392\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.003951422870159149\n",
      "Loss on test= 0.00465526944026351\n",
      "acc for Lsat= 0.07890779468127423 \n",
      "acc for Psat= 0.14465414704237547 \n",
      "acc for optim= 0.11969485697853896\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.003919961396604776\n",
      "Loss on test= 0.004504153970628977\n",
      "acc for Lsat= 0.10209984037404259 \n",
      "acc for Psat= 0.1441598132175083 \n",
      "acc for optim= 0.13871355706618893\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.004104352556169033\n",
      "Loss on test= 0.004463631194084883\n",
      "acc for Lsat= 0.1360803598848482 \n",
      "acc for Psat= 0.14869075418553418 \n",
      "acc for optim= 0.11679086989412706\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.0039347452111542225\n",
      "Loss on test= 0.004643858876079321\n",
      "acc for Lsat= 0.07888613220873392 \n",
      "acc for Psat= 0.1294058614100019 \n",
      "acc for optim= 0.14647149180786478\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.003979871980845928\n",
      "Loss on test= 0.004479091614484787\n",
      "acc for Lsat= 0.10962546523660421 \n",
      "acc for Psat= 0.1426777841988951 \n",
      "acc for optim= 0.13132929393193787\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.003992376383394003\n",
      "Loss on test= 0.004490813240408897\n",
      "acc for Lsat= 0.09842176269739866 \n",
      "acc for Psat= 0.1421065703034401 \n",
      "acc for optim= 0.13827393483370543\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.003992761950939894\n",
      "Loss on test= 0.004675066098570824\n",
      "acc for Lsat= 0.08571040974412528 \n",
      "acc for Psat= 0.11211854840318362 \n",
      "acc for optim= 0.14076993298820323\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.003953584004193544\n",
      "Loss on test= 0.004802978131920099\n",
      "acc for Lsat= 0.12431193432874149 \n",
      "acc for Psat= 0.1406975645158026 \n",
      "acc for optim= 0.13675527843750185\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.004059016238898039\n",
      "Loss on test= 0.004667205736041069\n",
      "acc for Lsat= 0.10574835538864136 \n",
      "acc for Psat= 0.1342714399409791 \n",
      "acc for optim= 0.1264530469973882\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.0040433150716125965\n",
      "Loss on test= 0.004278182052075863\n",
      "acc for Lsat= 0.10448264816982879 \n",
      "acc for Psat= 0.12803269508812162 \n",
      "acc for optim= 0.1401330340757138\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.004114710725843906\n",
      "Loss on test= 0.004278041422367096\n",
      "acc for Lsat= 0.13419675674392945 \n",
      "acc for Psat= 0.16414057416841388 \n",
      "acc for optim= 0.1605084196974834\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.004054106771945953\n",
      "Loss on test= 0.004525263328105211\n",
      "acc for Lsat= 0.10493410461478764 \n",
      "acc for Psat= 0.16812764646278489 \n",
      "acc for optim= 0.16676497112752664\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.003980457317084074\n",
      "Loss on test= 0.0043931994587183\n",
      "acc for Lsat= 0.12585979550042087 \n",
      "acc for Psat= 0.15836290373570389 \n",
      "acc for optim= 0.13232333689100212\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.003835121402516961\n",
      "Loss on test= 0.004388520959764719\n",
      "acc for Lsat= 0.08498367532673809 \n",
      "acc for Psat= 0.11156292391630511 \n",
      "acc for optim= 0.11798675580778056\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.004008255898952484\n",
      "Loss on test= 0.0046865064650774\n",
      "acc for Lsat= 0.10705512681872481 \n",
      "acc for Psat= 0.11735707490394513 \n",
      "acc for optim= 0.139737591949395\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.003984895069152117\n",
      "Loss on test= 0.004887377377599478\n",
      "acc for Lsat= 0.1407939651980996 \n",
      "acc for Psat= 0.15176566607422298 \n",
      "acc for optim= 0.1331009842429517\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.003920848947018385\n",
      "Loss on test= 0.004596656188368797\n",
      "acc for Lsat= 0.10918154301665102 \n",
      "acc for Psat= 0.1400934698111895 \n",
      "acc for optim= 0.13352487734260243\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.0040673743933439255\n",
      "Loss on test= 0.004450045060366392\n",
      "acc for Lsat= 0.11193228207735552 \n",
      "acc for Psat= 0.1591961489369472 \n",
      "acc for optim= 0.13349291476576278\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.0038697838317602873\n",
      "Loss on test= 0.004669658374041319\n",
      "acc for Lsat= 0.15232273346434036 \n",
      "acc for Psat= 0.13895474348424208 \n",
      "acc for optim= 0.1251989798879044\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.00393370958045125\n",
      "Loss on test= 0.004252347629517317\n",
      "acc for Lsat= 0.10379717606762522 \n",
      "acc for Psat= 0.1706122882767684 \n",
      "acc for optim= 0.12935432931408286\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.0039324709214270115\n",
      "Loss on test= 0.0048734284937381744\n",
      "acc for Lsat= 0.14848267049011257 \n",
      "acc for Psat= 0.1547462332398734 \n",
      "acc for optim= 0.16017912354113328\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.0038386641535907984\n",
      "Loss on test= 0.004587478470057249\n",
      "acc for Lsat= 0.08866620225469685 \n",
      "acc for Psat= 0.12487559548268716 \n",
      "acc for optim= 0.1368595051010036\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.003992743324488401\n",
      "Loss on test= 0.0047164782881736755\n",
      "acc for Lsat= 0.1372345668884615 \n",
      "acc for Psat= 0.166485871705744 \n",
      "acc for optim= 0.13428499487539133\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.004043099004775286\n",
      "Loss on test= 0.00479844119399786\n",
      "acc for Lsat= 0.10724590470393498 \n",
      "acc for Psat= 0.1531445152229733 \n",
      "acc for optim= 0.12781260488554835\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.003938541281968355\n",
      "Loss on test= 0.0044555035419762135\n",
      "acc for Lsat= 0.08969369028151657 \n",
      "acc for Psat= 0.13591484539210796 \n",
      "acc for optim= 0.1450847307116621\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.003990618046373129\n",
      "Loss on test= 0.004808114841580391\n",
      "acc for Lsat= 0.12225902781938203 \n",
      "acc for Psat= 0.17478750987599292 \n",
      "acc for optim= 0.1181784378649253\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.003931287210434675\n",
      "Loss on test= 0.004511868581175804\n",
      "acc for Lsat= 0.12095718448916967 \n",
      "acc for Psat= 0.10596262809768733 \n",
      "acc for optim= 0.11459860355696744\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.003925568889826536\n",
      "Loss on test= 0.004509843420237303\n",
      "acc for Lsat= 0.08658634860896403 \n",
      "acc for Psat= 0.15365433848152557 \n",
      "acc for optim= 0.11925655593060785\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.004182037431746721\n",
      "Loss on test= 0.004425186198204756\n",
      "acc for Lsat= 0.1147911904586686 \n",
      "acc for Psat= 0.13456267366806665 \n",
      "acc for optim= 0.15205140199719203\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.003966225776821375\n",
      "Loss on test= 0.004362562671303749\n",
      "acc for Lsat= 0.15015941712772474 \n",
      "acc for Psat= 0.16237157919547623 \n",
      "acc for optim= 0.13906134295070338\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.003862632205709815\n",
      "Loss on test= 0.00448150048032403\n",
      "acc for Lsat= 0.12257531844079494 \n",
      "acc for Psat= 0.1399289880775743 \n",
      "acc for optim= 0.12804502879993784\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.003774860640987754\n",
      "Loss on test= 0.004889270756393671\n",
      "acc for Lsat= 0.07375483362314601 \n",
      "acc for Psat= 0.13716764168606865 \n",
      "acc for optim= 0.1273884013062343\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.004065948538482189\n",
      "Loss on test= 0.0046072304248809814\n",
      "acc for Lsat= 0.12547564262018163 \n",
      "acc for Psat= 0.12993106039033997 \n",
      "acc for optim= 0.13423560057870215\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.0039932685904204845\n",
      "Loss on test= 0.00450788252055645\n",
      "acc for Lsat= 0.08215740633507569 \n",
      "acc for Psat= 0.1266839066779034 \n",
      "acc for optim= 0.1325924702687189\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.0039482382126152515\n",
      "Loss on test= 0.004738806281238794\n",
      "acc for Lsat= 0.10969463216477177 \n",
      "acc for Psat= 0.1560431065865689 \n",
      "acc for optim= 0.12942812320155403\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.003933784551918507\n",
      "Loss on test= 0.004522775299847126\n",
      "acc for Lsat= 0.10418127404732837 \n",
      "acc for Psat= 0.11052935058251023 \n",
      "acc for optim= 0.11969811365836197\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.003992239944636822\n",
      "Loss on test= 0.0042547620832920074\n",
      "acc for Lsat= 0.07721555091363068 \n",
      "acc for Psat= 0.13301127341886362 \n",
      "acc for optim= 0.14002818872945177\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.0038051633164286613\n",
      "Loss on test= 0.004594137892127037\n",
      "acc for Lsat= 0.11209456017240882 \n",
      "acc for Psat= 0.1536743927022649 \n",
      "acc for optim= 0.13830149168562558\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.003915479406714439\n",
      "Loss on test= 0.004505722783505917\n",
      "acc for Lsat= 0.12734641791838738 \n",
      "acc for Psat= 0.1390396365119765 \n",
      "acc for optim= 0.1395857096132305\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.0038679884746670723\n",
      "Loss on test= 0.004629874601960182\n",
      "acc for Lsat= 0.1189864050441732 \n",
      "acc for Psat= 0.14550515290142763 \n",
      "acc for optim= 0.12419321139653523\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.0039806971326470375\n",
      "Loss on test= 0.004730765707790852\n",
      "acc for Lsat= 0.09507222639189826 \n",
      "acc for Psat= 0.08946261490281257 \n",
      "acc for optim= 0.1353333031034304\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.0037423258181661367\n",
      "Loss on test= 0.00486457534134388\n",
      "acc for Lsat= 0.12880954436129993 \n",
      "acc for Psat= 0.1287806815881696 \n",
      "acc for optim= 0.12821185956191686\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.0038439615163952112\n",
      "Loss on test= 0.004256886430084705\n",
      "acc for Lsat= 0.10710880750169356 \n",
      "acc for Psat= 0.1558068801338474 \n",
      "acc for optim= 0.11420417618420389\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.0038673721719533205\n",
      "Loss on test= 0.004084289073944092\n",
      "acc for Lsat= 0.1164296578305463 \n",
      "acc for Psat= 0.1627941694524553 \n",
      "acc for optim= 0.14755298637060654\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.003925124183297157\n",
      "Loss on test= 0.004639799240976572\n",
      "acc for Lsat= 0.12111576500400487 \n",
      "acc for Psat= 0.18826744767526785 \n",
      "acc for optim= 0.13052153846042025\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.003896834794431925\n",
      "Loss on test= 0.004493802785873413\n",
      "acc for Lsat= 0.11527737856118216 \n",
      "acc for Psat= 0.13612147635366353 \n",
      "acc for optim= 0.1144953131960291\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.003934693522751331\n",
      "Loss on test= 0.004840033128857613\n",
      "acc for Lsat= 0.09323376060153048 \n",
      "acc for Psat= 0.13853844669130114 \n",
      "acc for optim= 0.1371471576599611\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.0038533636834472418\n",
      "Loss on test= 0.0044692642986774445\n",
      "acc for Lsat= 0.1283487709911747 \n",
      "acc for Psat= 0.1508570940544208 \n",
      "acc for optim= 0.15009558604409298\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.003717181272804737\n",
      "Loss on test= 0.004608333110809326\n",
      "acc for Lsat= 0.11566520358125369 \n",
      "acc for Psat= 0.16596646436179677 \n",
      "acc for optim= 0.12653125941546428\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.0039037615060806274\n",
      "Loss on test= 0.004552693571895361\n",
      "acc for Lsat= 0.11792706734397346 \n",
      "acc for Psat= 0.13900336008130884 \n",
      "acc for optim= 0.1282437735547622\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.003781024133786559\n",
      "Loss on test= 0.004844954703003168\n",
      "acc for Lsat= 0.1110112266712046 \n",
      "acc for Psat= 0.11850662350965042 \n",
      "acc for optim= 0.1443723870648278\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.0038729780353605747\n",
      "Loss on test= 0.0048746708780527115\n",
      "acc for Lsat= 0.10768130843320654 \n",
      "acc for Psat= 0.11150290087486307 \n",
      "acc for optim= 0.12452603432919002\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.0038213967345654964\n",
      "Loss on test= 0.00471910834312439\n",
      "acc for Lsat= 0.10219754382140106 \n",
      "acc for Psat= 0.10849258795173632 \n",
      "acc for optim= 0.11606336974849303\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.003950974438339472\n",
      "Loss on test= 0.0041279918514192104\n",
      "acc for Lsat= 0.1295819029522439 \n",
      "acc for Psat= 0.13142079420180786 \n",
      "acc for optim= 0.1436480809417036\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.003965310752391815\n",
      "Loss on test= 0.004563087597489357\n",
      "acc for Lsat= 0.1329266542258362 \n",
      "acc for Psat= 0.18383414391428232 \n",
      "acc for optim= 0.14123981249415213\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.003878869814798236\n",
      "Loss on test= 0.0042015076614916325\n",
      "acc for Lsat= 0.09683764446526766 \n",
      "acc for Psat= 0.13455856040430567 \n",
      "acc for optim= 0.16184870112273428\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.003810086054727435\n",
      "Loss on test= 0.004506467841565609\n",
      "acc for Lsat= 0.11676677275035116 \n",
      "acc for Psat= 0.11046974780037999 \n",
      "acc for optim= 0.1345212079791559\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.0037202066741883755\n",
      "Loss on test= 0.004169344436377287\n",
      "acc for Lsat= 0.0861510703754094 \n",
      "acc for Psat= 0.1435397733002901 \n",
      "acc for optim= 0.15826279897656706\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.003813705639913678\n",
      "Loss on test= 0.004535527899861336\n",
      "acc for Lsat= 0.12170396953459 \n",
      "acc for Psat= 0.17471623500912553 \n",
      "acc for optim= 0.13535097293141815\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.0038511648308485746\n",
      "Loss on test= 0.0047247582115232944\n",
      "acc for Lsat= 0.0946623981387044 \n",
      "acc for Psat= 0.12664471261410248 \n",
      "acc for optim= 0.13105757751812538\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.003955126274377108\n",
      "Loss on test= 0.004486421123147011\n",
      "acc for Lsat= 0.06903243846156532 \n",
      "acc for Psat= 0.14634616403943962 \n",
      "acc for optim= 0.14302888913597497\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.0038197063840925694\n",
      "Loss on test= 0.004599796142429113\n",
      "acc for Lsat= 0.14264673496493036 \n",
      "acc for Psat= 0.19324391862998405 \n",
      "acc for optim= 0.1499558813456032\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.003990381024777889\n",
      "Loss on test= 0.0044935233891010284\n",
      "acc for Lsat= 0.10192173220113748 \n",
      "acc for Psat= 0.12113312192054258 \n",
      "acc for optim= 0.1372053320374107\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.0038060196675360203\n",
      "Loss on test= 0.004566235933452845\n",
      "acc for Lsat= 0.10849021371945532 \n",
      "acc for Psat= 0.13509889712764156 \n",
      "acc for optim= 0.1299504174126519\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.0037936856970191\n",
      "Loss on test= 0.004410020541399717\n",
      "acc for Lsat= 0.12075222159425418 \n",
      "acc for Psat= 0.14982997377713522 \n",
      "acc for optim= 0.1420170170151525\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.003819689154624939\n",
      "Loss on test= 0.004628041293472052\n",
      "acc for Lsat= 0.12923324033100572 \n",
      "acc for Psat= 0.1620460874401033 \n",
      "acc for optim= 0.11772547062072489\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.0039029009640216827\n",
      "Loss on test= 0.0047463527880609035\n",
      "acc for Lsat= 0.09236277060376273 \n",
      "acc for Psat= 0.12127581549187501 \n",
      "acc for optim= 0.15051036002114415\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.0038744285702705383\n",
      "Loss on test= 0.0046025291085243225\n",
      "acc for Lsat= 0.07182771897512591 \n",
      "acc for Psat= 0.17214478702387875 \n",
      "acc for optim= 0.15235250670876768\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.003807344939559698\n",
      "Loss on test= 0.004530085250735283\n",
      "acc for Lsat= 0.08403035284330447 \n",
      "acc for Psat= 0.13720765047603184 \n",
      "acc for optim= 0.15479865256283018\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.0037104994989931583\n",
      "Loss on test= 0.004596783313900232\n",
      "acc for Lsat= 0.08005652299875186 \n",
      "acc for Psat= 0.10543597668745658 \n",
      "acc for optim= 0.13765386078092787\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.0037785700988024473\n",
      "Loss on test= 0.004835966508835554\n",
      "acc for Lsat= 0.0805656271469262 \n",
      "acc for Psat= 0.12325964306688143 \n",
      "acc for optim= 0.1181823420855734\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.003965829033404589\n",
      "Loss on test= 0.004435755778104067\n",
      "acc for Lsat= 0.10308409994468093 \n",
      "acc for Psat= 0.16492465304003823 \n",
      "acc for optim= 0.1566079573498832\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.0038987668231129646\n",
      "Loss on test= 0.005389062687754631\n",
      "acc for Lsat= 0.11724053121482332 \n",
      "acc for Psat= 0.10027145038151906 \n",
      "acc for optim= 0.12069262957407369\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.0036640299949795008\n",
      "Loss on test= 0.004736014176160097\n",
      "acc for Lsat= 0.1287027040703429 \n",
      "acc for Psat= 0.150405856121021 \n",
      "acc for optim= 0.1307930822432455\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.003813331015408039\n",
      "Loss on test= 0.004512508865445852\n",
      "acc for Lsat= 0.0767145992981063 \n",
      "acc for Psat= 0.1213777886910571 \n",
      "acc for optim= 0.13528872612449858\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.003863552352413535\n",
      "Loss on test= 0.004502840805798769\n",
      "acc for Lsat= 0.1148398521149324 \n",
      "acc for Psat= 0.10332185531862909 \n",
      "acc for optim= 0.10995789353425305\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.0038235222455114126\n",
      "Loss on test= 0.004624225199222565\n",
      "acc for Lsat= 0.10334409618129332 \n",
      "acc for Psat= 0.12954720637450615 \n",
      "acc for optim= 0.16005752121822703\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.0038354017306119204\n",
      "Loss on test= 0.004359116777777672\n",
      "acc for Lsat= 0.11142334543789427 \n",
      "acc for Psat= 0.11804279074486759 \n",
      "acc for optim= 0.12433285773214367\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.003798039862886071\n",
      "Loss on test= 0.00444862712174654\n",
      "acc for Lsat= 0.09474740368831489 \n",
      "acc for Psat= 0.1288749105297029 \n",
      "acc for optim= 0.10891429847106338\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.003877319162711501\n",
      "Loss on test= 0.0043866392225027084\n",
      "acc for Lsat= 0.08163318205495468 \n",
      "acc for Psat= 0.10656234989356664 \n",
      "acc for optim= 0.13451696430436438\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.0036653948482125998\n",
      "Loss on test= 0.0047846827656030655\n",
      "acc for Lsat= 0.10319365242159823 \n",
      "acc for Psat= 0.15010922133094734 \n",
      "acc for optim= 0.13852898799814284\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.0038737317081540823\n",
      "Loss on test= 0.004460075404495001\n",
      "acc for Lsat= 0.08482154624329673 \n",
      "acc for Psat= 0.1351647280777494 \n",
      "acc for optim= 0.14672916713688108\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.003797195153310895\n",
      "Loss on test= 0.004401917103677988\n",
      "acc for Lsat= 0.0750963505771425 \n",
      "acc for Psat= 0.10555687221413892 \n",
      "acc for optim= 0.10656993401547273\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.003793182782828808\n",
      "Loss on test= 0.0044389162212610245\n",
      "acc for Lsat= 0.09139340612778647 \n",
      "acc for Psat= 0.13868168441371787 \n",
      "acc for optim= 0.11936182295903563\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.003858800046145916\n",
      "Loss on test= 0.004611235111951828\n",
      "acc for Lsat= 0.1023156626874374 \n",
      "acc for Psat= 0.11922784470435646 \n",
      "acc for optim= 0.13976092060976145\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.0038423300720751286\n",
      "Loss on test= 0.004711041692644358\n",
      "acc for Lsat= 0.10351419899800224 \n",
      "acc for Psat= 0.1538677047420707 \n",
      "acc for optim= 0.11475032738720377\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.0037901022005826235\n",
      "Loss on test= 0.004609058145433664\n",
      "acc for Lsat= 0.10873839047013058 \n",
      "acc for Psat= 0.13950425727913776 \n",
      "acc for optim= 0.1166505824528738\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.003905551042407751\n",
      "Loss on test= 0.004208425059914589\n",
      "acc for Lsat= 0.12448351183492276 \n",
      "acc for Psat= 0.1338008058567842 \n",
      "acc for optim= 0.12327468564682123\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.0038117715157568455\n",
      "Loss on test= 0.004640674218535423\n",
      "acc for Lsat= 0.10026583649838965 \n",
      "acc for Psat= 0.09844998553550492 \n",
      "acc for optim= 0.15211535141699845\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.003724914975464344\n",
      "Loss on test= 0.0044850376434624195\n",
      "acc for Lsat= 0.09459334451498257 \n",
      "acc for Psat= 0.16276570844153562 \n",
      "acc for optim= 0.1175301705694033\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.003765174187719822\n",
      "Loss on test= 0.004388327244669199\n",
      "acc for Lsat= 0.12285291082743141 \n",
      "acc for Psat= 0.16102805472393003 \n",
      "acc for optim= 0.16033833235916164\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.0037698836531490088\n",
      "Loss on test= 0.004852334503084421\n",
      "acc for Lsat= 0.08651232343011846 \n",
      "acc for Psat= 0.13658931773776808 \n",
      "acc for optim= 0.11237920087296516\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.0038235147949308157\n",
      "Loss on test= 0.004383824300020933\n",
      "acc for Lsat= 0.06765277634581758 \n",
      "acc for Psat= 0.14322957784558335 \n",
      "acc for optim= 0.1244820867302931\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.003966933116316795\n",
      "Loss on test= 0.004348477348685265\n",
      "acc for Lsat= 0.09658861036748728 \n",
      "acc for Psat= 0.10692381636383491 \n",
      "acc for optim= 0.14211076203112802\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.00381716201081872\n",
      "Loss on test= 0.004528552293777466\n",
      "acc for Lsat= 0.10470913003923164 \n",
      "acc for Psat= 0.1513239216680328 \n",
      "acc for optim= 0.12083829975583488\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.0037534022703766823\n",
      "Loss on test= 0.004489494021981955\n",
      "acc for Lsat= 0.09448138396773073 \n",
      "acc for Psat= 0.14457310306736165 \n",
      "acc for optim= 0.14460586989298463\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.0037533966824412346\n",
      "Loss on test= 0.004675664007663727\n",
      "acc for Lsat= 0.11683342429912752 \n",
      "acc for Psat= 0.17891061709572872 \n",
      "acc for optim= 0.12226359181416531\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.0038457512855529785\n",
      "Loss on test= 0.0043977778404951096\n",
      "acc for Lsat= 0.14790120224157968 \n",
      "acc for Psat= 0.14890888813210446 \n",
      "acc for optim= 0.13805127992398208\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.0037541002966463566\n",
      "Loss on test= 0.004688431043177843\n",
      "acc for Lsat= 0.10719973695651991 \n",
      "acc for Psat= 0.12197506354035188 \n",
      "acc for optim= 0.10633834520316061\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.003748256014660001\n",
      "Loss on test= 0.00444265641272068\n",
      "acc for Lsat= 0.09913285749240054 \n",
      "acc for Psat= 0.15021421894845036 \n",
      "acc for optim= 0.14590661520034903\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.003745214780792594\n",
      "Loss on test= 0.004661055281758308\n",
      "acc for Lsat= 0.11316682232750787 \n",
      "acc for Psat= 0.15272183812016416 \n",
      "acc for optim= 0.13768635237486\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.0037620840594172478\n",
      "Loss on test= 0.004399609751999378\n",
      "acc for Lsat= 0.11840826614449422 \n",
      "acc for Psat= 0.13941913998375335 \n",
      "acc for optim= 0.16063274277581108\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.0037066529039293528\n",
      "Loss on test= 0.004582372959703207\n",
      "acc for Lsat= 0.1652301502827969 \n",
      "acc for Psat= 0.13960128836333752 \n",
      "acc for optim= 0.11158168163254029\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.0037269138265401125\n",
      "Loss on test= 0.004557070787996054\n",
      "acc for Lsat= 0.09591738517499632 \n",
      "acc for Psat= 0.14219599382744896 \n",
      "acc for optim= 0.11502045336075956\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.00370074063539505\n",
      "Loss on test= 0.004605434834957123\n",
      "acc for Lsat= 0.11804095547025402 \n",
      "acc for Psat= 0.1085483705262757 \n",
      "acc for optim= 0.12941975255186358\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.003793170442804694\n",
      "Loss on test= 0.004487521946430206\n",
      "acc for Lsat= 0.09111015969473454 \n",
      "acc for Psat= 0.13417298044078052 \n",
      "acc for optim= 0.14106275495659146\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.0038415081799030304\n",
      "Loss on test= 0.0045053306967020035\n",
      "acc for Lsat= 0.07867429916384733 \n",
      "acc for Psat= 0.12547333947279388 \n",
      "acc for optim= 0.14137554313573572\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.0036086796317249537\n",
      "Loss on test= 0.00475021917372942\n",
      "acc for Lsat= 0.1279898171002666 \n",
      "acc for Psat= 0.13000523710312942 \n",
      "acc for optim= 0.09647361572004026\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.003749699331820011\n",
      "Loss on test= 0.005022990982979536\n",
      "acc for Lsat= 0.1124551448608852 \n",
      "acc for Psat= 0.15040978514702552 \n",
      "acc for optim= 0.11403860400120418\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.003707107389345765\n",
      "Loss on test= 0.004787071608006954\n",
      "acc for Lsat= 0.11089191559909119 \n",
      "acc for Psat= 0.13675523052289565 \n",
      "acc for optim= 0.15338983562671477\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.003797889454290271\n",
      "Loss on test= 0.0047459956258535385\n",
      "acc for Lsat= 0.1163964696849386 \n",
      "acc for Psat= 0.14504544167882866 \n",
      "acc for optim= 0.12274027589268775\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.003602409502491355\n",
      "Loss on test= 0.004305518697947264\n",
      "acc for Lsat= 0.07811491434565848 \n",
      "acc for Psat= 0.09420845317395611 \n",
      "acc for optim= 0.14529220102768806\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.0037224506959319115\n",
      "Loss on test= 0.004484265577048063\n",
      "acc for Lsat= 0.08923666207637224 \n",
      "acc for Psat= 0.08169596585341626 \n",
      "acc for optim= 0.15598568056399623\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.0036772640887647867\n",
      "Loss on test= 0.004538991022855043\n",
      "acc for Lsat= 0.0906725687543965 \n",
      "acc for Psat= 0.13393187700098175 \n",
      "acc for optim= 0.1265333500276837\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.003573355730623007\n",
      "Loss on test= 0.004599590785801411\n",
      "acc for Lsat= 0.0926683412948882 \n",
      "acc for Psat= 0.13470154111726312 \n",
      "acc for optim= 0.1412052681359152\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.0037538185715675354\n",
      "Loss on test= 0.004751247353851795\n",
      "acc for Lsat= 0.11676909164008167 \n",
      "acc for Psat= 0.188722250258757 \n",
      "acc for optim= 0.13416234077885747\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.0037424524780362844\n",
      "Loss on test= 0.004754354245960712\n",
      "acc for Lsat= 0.08557637346287568 \n",
      "acc for Psat= 0.10675563965924084 \n",
      "acc for optim= 0.1063965070578787\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.0036507167387753725\n",
      "Loss on test= 0.00440907571464777\n",
      "acc for Lsat= 0.09533818179948463 \n",
      "acc for Psat= 0.08178741024393174 \n",
      "acc for optim= 0.13271586276176903\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.003674991661682725\n",
      "Loss on test= 0.004618032369762659\n",
      "acc for Lsat= 0.10592380497190687 \n",
      "acc for Psat= 0.1130345750393139 \n",
      "acc for optim= 0.14397354237735271\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.0036320218350738287\n",
      "Loss on test= 0.0048274933360517025\n",
      "acc for Lsat= 0.10383875577503608 \n",
      "acc for Psat= 0.17028867091155714 \n",
      "acc for optim= 0.14551663398742676\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.0037491971161216497\n",
      "Loss on test= 0.004647847730666399\n",
      "acc for Lsat= 0.08872989078776704 \n",
      "acc for Psat= 0.10320729509112425 \n",
      "acc for optim= 0.1347201335657802\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.003787266556173563\n",
      "Loss on test= 0.004814520478248596\n",
      "acc for Lsat= 0.07629616289503044 \n",
      "acc for Psat= 0.1317002613019819 \n",
      "acc for optim= 0.1521293065096769\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.003749805735424161\n",
      "Loss on test= 0.00479963980615139\n",
      "acc for Lsat= 0.09929140675295559 \n",
      "acc for Psat= 0.15956811275747088 \n",
      "acc for optim= 0.16186351887881756\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.003582941833883524\n",
      "Loss on test= 0.00436733104288578\n",
      "acc for Lsat= 0.135786028785838 \n",
      "acc for Psat= 0.1371831199309478 \n",
      "acc for optim= 0.1351432845177543\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.0036810755264014006\n",
      "Loss on test= 0.00498715415596962\n",
      "acc for Lsat= 0.10431735310703516 \n",
      "acc for Psat= 0.18547028882635963 \n",
      "acc for optim= 0.09336652115194334\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.0037528029642999172\n",
      "Loss on test= 0.004618553910404444\n",
      "acc for Lsat= 0.1339420136452342 \n",
      "acc for Psat= 0.16704392893653777 \n",
      "acc for optim= 0.1348098137208985\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.0035730572417378426\n",
      "Loss on test= 0.004817045759409666\n",
      "acc for Lsat= 0.12071587031500207 \n",
      "acc for Psat= 0.09150325691896594 \n",
      "acc for optim= 0.12651180991411415\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.0037471787072718143\n",
      "Loss on test= 0.004455938935279846\n",
      "acc for Lsat= 0.08369450930816431 \n",
      "acc for Psat= 0.16111514515553912 \n",
      "acc for optim= 0.15271995629235688\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.0035689338110387325\n",
      "Loss on test= 0.004360103979706764\n",
      "acc for Lsat= 0.1316101318742666 \n",
      "acc for Psat= 0.13456414475674844 \n",
      "acc for optim= 0.1057221441814262\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.0035664208699017763\n",
      "Loss on test= 0.004144648555666208\n",
      "acc for Lsat= 0.13692328473553061 \n",
      "acc for Psat= 0.13506613516559204 \n",
      "acc for optim= 0.1354487519711256\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.00366207561455667\n",
      "Loss on test= 0.004567929543554783\n",
      "acc for Lsat= 0.07927563222539094 \n",
      "acc for Psat= 0.15089173235982242 \n",
      "acc for optim= 0.1429174066417747\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.0036087618209421635\n",
      "Loss on test= 0.0048139095306396484\n",
      "acc for Lsat= 0.10583162897576888 \n",
      "acc for Psat= 0.20912950527336863 \n",
      "acc for optim= 0.11493342354919554\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.0037329033948481083\n",
      "Loss on test= 0.004518219269812107\n",
      "acc for Lsat= 0.11081945047610336 \n",
      "acc for Psat= 0.16640380314654774 \n",
      "acc for optim= 0.1432744031254616\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.003574938280507922\n",
      "Loss on test= 0.004605384543538094\n",
      "acc for Lsat= 0.07348423540436973 \n",
      "acc for Psat= 0.13509093390570748 \n",
      "acc for optim= 0.15952393267717627\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.0037927257362753153\n",
      "Loss on test= 0.004590985365211964\n",
      "acc for Lsat= 0.06870005505495808 \n",
      "acc for Psat= 0.16720194317814377 \n",
      "acc for optim= 0.12987246876582503\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.0038382483180612326\n",
      "Loss on test= 0.004469813778996468\n",
      "acc for Lsat= 0.10312699360979928 \n",
      "acc for Psat= 0.16854743224879107 \n",
      "acc for optim= 0.16906684285236728\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.003589262254536152\n",
      "Loss on test= 0.004495091736316681\n",
      "acc for Lsat= 0.09575402640944554 \n",
      "acc for Psat= 0.1811090354911155 \n",
      "acc for optim= 0.13255823977912465\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.003634057240560651\n",
      "Loss on test= 0.004356857854872942\n",
      "acc for Lsat= 0.08018566124762098 \n",
      "acc for Psat= 0.1267546165553439 \n",
      "acc for optim= 0.13184258464672086\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.0036577319260686636\n",
      "Loss on test= 0.0045554558746516705\n",
      "acc for Lsat= 0.10192086764921744 \n",
      "acc for Psat= 0.09424670024357813 \n",
      "acc for optim= 0.13126955683239633\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.003733530407771468\n",
      "Loss on test= 0.004449404776096344\n",
      "acc for Lsat= 0.1234344674481286 \n",
      "acc for Psat= 0.11229119954320292 \n",
      "acc for optim= 0.12459706331396268\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.0037073937710374594\n",
      "Loss on test= 0.004810401238501072\n",
      "acc for Lsat= 0.15279989730980661 \n",
      "acc for Psat= 0.1262648398729248 \n",
      "acc for optim= 0.12463113800105122\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.0036722428631037474\n",
      "Loss on test= 0.004807878751307726\n",
      "acc for Lsat= 0.08943424018151644 \n",
      "acc for Psat= 0.14527198982735476 \n",
      "acc for optim= 0.14446588771210778\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.0035264380276203156\n",
      "Loss on test= 0.004464857745915651\n",
      "acc for Lsat= 0.07462920207116339 \n",
      "acc for Psat= 0.11213510726035263 \n",
      "acc for optim= 0.1558788829586572\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.0035491965245455503\n",
      "Loss on test= 0.004734931513667107\n",
      "acc for Lsat= 0.09494952462975764 \n",
      "acc for Psat= 0.1284775465933813 \n",
      "acc for optim= 0.12567918106085724\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.0034912414848804474\n",
      "Loss on test= 0.00429432513192296\n",
      "acc for Lsat= 0.09600619631560726 \n",
      "acc for Psat= 0.12611000824512708 \n",
      "acc for optim= 0.10427812699021564\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.0034244901034981012\n",
      "Loss on test= 0.00463646836578846\n",
      "acc for Lsat= 0.09728391037788242 \n",
      "acc for Psat= 0.12099158070567581 \n",
      "acc for optim= 0.15855844712091816\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.0035354269202798605\n",
      "Loss on test= 0.004463116638362408\n",
      "acc for Lsat= 0.09804310261582334 \n",
      "acc for Psat= 0.10049309720893183 \n",
      "acc for optim= 0.13089011630250347\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.0037022714968770742\n",
      "Loss on test= 0.004413798917084932\n",
      "acc for Lsat= 0.10407135788247818 \n",
      "acc for Psat= 0.11936504983653624 \n",
      "acc for optim= 0.1308021692869564\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.0035157741513103247\n",
      "Loss on test= 0.0042128534987568855\n",
      "acc for Lsat= 0.07806935561044763 \n",
      "acc for Psat= 0.11407073649267356 \n",
      "acc for optim= 0.1402351067453209\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.003708932315930724\n",
      "Loss on test= 0.0045829052105546\n",
      "acc for Lsat= 0.0839230137773686 \n",
      "acc for Psat= 0.1179264842454965 \n",
      "acc for optim= 0.1403188349472152\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.0036229484248906374\n",
      "Loss on test= 0.004263856913894415\n",
      "acc for Lsat= 0.10837752441875637 \n",
      "acc for Psat= 0.14412292770834434 \n",
      "acc for optim= 0.1221837797978272\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.003652051789686084\n",
      "Loss on test= 0.004694807808846235\n",
      "acc for Lsat= 0.1017880081716511 \n",
      "acc for Psat= 0.12751526053762063 \n",
      "acc for optim= 0.15273254964914587\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.003610869636759162\n",
      "Loss on test= 0.004686031956225634\n",
      "acc for Lsat= 0.1090244453969515 \n",
      "acc for Psat= 0.1182806388888922 \n",
      "acc for optim= 0.14011049063669312\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.00370976934209466\n",
      "Loss on test= 0.004428768530488014\n",
      "acc for Lsat= 0.11302808030611938 \n",
      "acc for Psat= 0.11165869150621195 \n",
      "acc for optim= 0.1492780631977237\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.003706092946231365\n",
      "Loss on test= 0.004640222527086735\n",
      "acc for Lsat= 0.1517228593842851 \n",
      "acc for Psat= 0.14973005039306977 \n",
      "acc for optim= 0.1344423172995448\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.0035086660645902157\n",
      "Loss on test= 0.004494445398449898\n",
      "acc for Lsat= 0.11757566298668583 \n",
      "acc for Psat= 0.15306506875074571 \n",
      "acc for optim= 0.1355428650147385\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.0036234555300325155\n",
      "Loss on test= 0.004459432326257229\n",
      "acc for Lsat= 0.09769198659341782 \n",
      "acc for Psat= 0.13241148807315362 \n",
      "acc for optim= 0.12283652441369163\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.003671967890113592\n",
      "Loss on test= 0.004663290921598673\n",
      "acc for Lsat= 0.09235330103223936 \n",
      "acc for Psat= 0.08668756790252195 \n",
      "acc for optim= 0.13404337528886068\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.0037019839510321617\n",
      "Loss on test= 0.004834503401070833\n",
      "acc for Lsat= 0.10170228361514294 \n",
      "acc for Psat= 0.15094322493920723 \n",
      "acc for optim= 0.12720430448340872\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.003716871840879321\n",
      "Loss on test= 0.004814894869923592\n",
      "acc for Lsat= 0.119661182619489 \n",
      "acc for Psat= 0.1535515574634903 \n",
      "acc for optim= 0.136595868324447\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.0035379501059651375\n",
      "Loss on test= 0.004452213644981384\n",
      "acc for Lsat= 0.11855985648516151 \n",
      "acc for Psat= 0.1151799979723162 \n",
      "acc for optim= 0.1132388883529024\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.0035890901926904917\n",
      "Loss on test= 0.00427190400660038\n",
      "acc for Lsat= 0.09034641874798884 \n",
      "acc for Psat= 0.131543491811802 \n",
      "acc for optim= 0.12821458600875404\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.0036834878847002983\n",
      "Loss on test= 0.004709397908300161\n",
      "acc for Lsat= 0.07356137192497651 \n",
      "acc for Psat= 0.12221737679404517 \n",
      "acc for optim= 0.12327845932708846\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.003580150194466114\n",
      "Loss on test= 0.004991743713617325\n",
      "acc for Lsat= 0.10696222902172142 \n",
      "acc for Psat= 0.09439564677369264 \n",
      "acc for optim= 0.11311742290854454\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.003577697789296508\n",
      "Loss on test= 0.004330646712332964\n",
      "acc for Lsat= 0.08897235775495776 \n",
      "acc for Psat= 0.1407059665976299 \n",
      "acc for optim= 0.1316978652076715\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.0036770040169358253\n",
      "Loss on test= 0.0046336776576936245\n",
      "acc for Lsat= 0.12013438994634068 \n",
      "acc for Psat= 0.14561773650348186 \n",
      "acc for optim= 0.10508120038947608\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.003615126246586442\n",
      "Loss on test= 0.004693413153290749\n",
      "acc for Lsat= 0.10416783136315644 \n",
      "acc for Psat= 0.14914861807806623 \n",
      "acc for optim= 0.13615949811517364\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.003507991787046194\n",
      "Loss on test= 0.0045205214992165565\n",
      "acc for Lsat= 0.0733879820133249 \n",
      "acc for Psat= 0.13966706558130682 \n",
      "acc for optim= 0.13292648177593946\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.0035742223262786865\n",
      "Loss on test= 0.004791015759110451\n",
      "acc for Lsat= 0.11303348490037024 \n",
      "acc for Psat= 0.13702685618773103 \n",
      "acc for optim= 0.11955242699736522\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.0035566017031669617\n",
      "Loss on test= 0.004532123450189829\n",
      "acc for Lsat= 0.0921788558933056 \n",
      "acc for Psat= 0.12217455010654198 \n",
      "acc for optim= 0.13319118659839863\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.003529932349920273\n",
      "Loss on test= 0.004394856747239828\n",
      "acc for Lsat= 0.08845292264595628 \n",
      "acc for Psat= 0.1472834849005772 \n",
      "acc for optim= 0.11556756196336614\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.0036674588918685913\n",
      "Loss on test= 0.004595374688506126\n",
      "acc for Lsat= 0.09180209904702173 \n",
      "acc for Psat= 0.1365559202580092 \n",
      "acc for optim= 0.12279394959720473\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.003742293920367956\n",
      "Loss on test= 0.004736247006803751\n",
      "acc for Lsat= 0.09610488946135673 \n",
      "acc for Psat= 0.1469779860926792 \n",
      "acc for optim= 0.11971463200946648\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.0035805196966975927\n",
      "Loss on test= 0.004621890839189291\n",
      "acc for Lsat= 0.09949718700307938 \n",
      "acc for Psat= 0.14970667091094786 \n",
      "acc for optim= 0.14544056687090132\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.003726366674527526\n",
      "Loss on test= 0.004482531454414129\n",
      "acc for Lsat= 0.11207761030851139 \n",
      "acc for Psat= 0.13254727161903349 \n",
      "acc for optim= 0.11640169181757504\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.003557829651981592\n",
      "Loss on test= 0.004544959403574467\n",
      "acc for Lsat= 0.1079710649792105 \n",
      "acc for Psat= 0.11747901630587876 \n",
      "acc for optim= 0.12913298917313418\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.0036759565118700266\n",
      "Loss on test= 0.004540179390460253\n",
      "acc for Lsat= 0.12402024570231636 \n",
      "acc for Psat= 0.15443748763451973 \n",
      "acc for optim= 0.1551952947758966\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.003591768443584442\n",
      "Loss on test= 0.004629835020750761\n",
      "acc for Lsat= 0.07862264468955497 \n",
      "acc for Psat= 0.1336299747797764 \n",
      "acc for optim= 0.13274321736147007\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.0034899197053164244\n",
      "Loss on test= 0.0043490431271493435\n",
      "acc for Lsat= 0.09605750244938666 \n",
      "acc for Psat= 0.13164817583229807 \n",
      "acc for optim= 0.11068891557968324\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.0035972946789115667\n",
      "Loss on test= 0.004282398149371147\n",
      "acc for Lsat= 0.12390079375149475 \n",
      "acc for Psat= 0.16785157365827924 \n",
      "acc for optim= 0.12561132334586647\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.0035815201699733734\n",
      "Loss on test= 0.004854459781199694\n",
      "acc for Lsat= 0.09220334007922146 \n",
      "acc for Psat= 0.10398610321701401 \n",
      "acc for optim= 0.11836631451216009\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.00362209090963006\n",
      "Loss on test= 0.004479181952774525\n",
      "acc for Lsat= 0.12031271774321795 \n",
      "acc for Psat= 0.11437945309767707 \n",
      "acc for optim= 0.13731296280295485\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.0037231571041047573\n",
      "Loss on test= 0.004322499968111515\n",
      "acc for Lsat= 0.10372779964301218 \n",
      "acc for Psat= 0.10814401582400832 \n",
      "acc for optim= 0.11603655417760213\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.003565972438082099\n",
      "Loss on test= 0.004447361454367638\n",
      "acc for Lsat= 0.11415486632742816 \n",
      "acc for Psat= 0.10027417675074604 \n",
      "acc for optim= 0.15798311390810543\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.003522282699123025\n",
      "Loss on test= 0.004379676654934883\n",
      "acc for Lsat= 0.10065959638450295 \n",
      "acc for Psat= 0.10967540813402997 \n",
      "acc for optim= 0.11146092523510258\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.0036052577197551727\n",
      "Loss on test= 0.004735302180051804\n",
      "acc for Lsat= 0.1043911927069227 \n",
      "acc for Psat= 0.10879931285873884 \n",
      "acc for optim= 0.13561631242434183\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.003670291043817997\n",
      "Loss on test= 0.004576133098453283\n",
      "acc for Lsat= 0.12477364365218414 \n",
      "acc for Psat= 0.13722172568345237 \n",
      "acc for optim= 0.10200364127134283\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.0036884904839098454\n",
      "Loss on test= 0.0046349698677659035\n",
      "acc for Lsat= 0.0930409652646631 \n",
      "acc for Psat= 0.1296000335779455 \n",
      "acc for optim= 0.12434417221488224\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.0035312948748469353\n",
      "Loss on test= 0.004724106751382351\n",
      "acc for Lsat= 0.11463557636468774 \n",
      "acc for Psat= 0.15685804612520668 \n",
      "acc for optim= 0.12741444378884303\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.003620244562625885\n",
      "Loss on test= 0.004388188011944294\n",
      "acc for Lsat= 0.09959068431312011 \n",
      "acc for Psat= 0.1334107607189152 \n",
      "acc for optim= 0.122944259033021\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.0035662620794028044\n",
      "Loss on test= 0.0046794782392680645\n",
      "acc for Lsat= 0.10284233258830176 \n",
      "acc for Psat= 0.13342523088471758 \n",
      "acc for optim= 0.126099970139977\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.0035781727638095617\n",
      "Loss on test= 0.0043640220537781715\n",
      "acc for Lsat= 0.10587839968502522 \n",
      "acc for Psat= 0.11818047237789465 \n",
      "acc for optim= 0.16153594334092405\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.003673962317407131\n",
      "Loss on test= 0.00429592514410615\n",
      "acc for Lsat= 0.11076298852761586 \n",
      "acc for Psat= 0.10266212405016024 \n",
      "acc for optim= 0.13515880392838475\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.003604512894526124\n",
      "Loss on test= 0.004760941956192255\n",
      "acc for Lsat= 0.08763393014669418 \n",
      "acc for Psat= 0.11954308139562879 \n",
      "acc for optim= 0.12689760348035228\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.0034479000605642796\n",
      "Loss on test= 0.0044367387890815735\n",
      "acc for Lsat= 0.09341814296527041 \n",
      "acc for Psat= 0.11055258577430828 \n",
      "acc for optim= 0.1485261341796205\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.0035565027501434088\n",
      "Loss on test= 0.004356487654149532\n",
      "acc for Lsat= 0.12229444267642167 \n",
      "acc for Psat= 0.14495982274335498 \n",
      "acc for optim= 0.18117091111424896\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.0035230761859565973\n",
      "Loss on test= 0.004513183142989874\n",
      "acc for Lsat= 0.09156380836955375 \n",
      "acc for Psat= 0.14051022967841062 \n",
      "acc for optim= 0.1306592126428667\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.0035819329787045717\n",
      "Loss on test= 0.004589814227074385\n",
      "acc for Lsat= 0.093426998394231 \n",
      "acc for Psat= 0.1367038349724478 \n",
      "acc for optim= 0.11597968813859755\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.003451709635555744\n",
      "Loss on test= 0.004035989288240671\n",
      "acc for Lsat= 0.1299052701021234 \n",
      "acc for Psat= 0.12451586292849647 \n",
      "acc for optim= 0.11252949011719061\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.0035497399512678385\n",
      "Loss on test= 0.004430614411830902\n",
      "acc for Lsat= 0.07546491298772809 \n",
      "acc for Psat= 0.12102286424487829 \n",
      "acc for optim= 0.14879019216944775\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.0035058939829468727\n",
      "Loss on test= 0.004532741382718086\n",
      "acc for Lsat= 0.09341406584199932 \n",
      "acc for Psat= 0.13975579444538905 \n",
      "acc for optim= 0.13251846423372626\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.003655974753201008\n",
      "Loss on test= 0.004607007838785648\n",
      "acc for Lsat= 0.1279096528750314 \n",
      "acc for Psat= 0.13458065843830505 \n",
      "acc for optim= 0.1302248885234197\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.003590399632230401\n",
      "Loss on test= 0.004771100822836161\n",
      "acc for Lsat= 0.10322626095472111 \n",
      "acc for Psat= 0.09710108728096303 \n",
      "acc for optim= 0.11947743137716316\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.003579731099307537\n",
      "Loss on test= 0.0047116330824792385\n",
      "acc for Lsat= 0.09008107994385581 \n",
      "acc for Psat= 0.09634776558313105 \n",
      "acc for optim= 0.12816125803672346\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.0035031535662710667\n",
      "Loss on test= 0.00467694690451026\n",
      "acc for Lsat= 0.12824461671213308 \n",
      "acc for Psat= 0.1291322192410007 \n",
      "acc for optim= 0.13908236328926352\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.0034608759451657534\n",
      "Loss on test= 0.004405832849442959\n",
      "acc for Lsat= 0.10835154867284776 \n",
      "acc for Psat= 0.10604867531219497 \n",
      "acc for optim= 0.14009242370310757\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.003431618446484208\n",
      "Loss on test= 0.0041861264035105705\n",
      "acc for Lsat= 0.1257971259765327 \n",
      "acc for Psat= 0.1175234245408016 \n",
      "acc for optim= 0.12724279208729664\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.0035116432700306177\n",
      "Loss on test= 0.004660600796341896\n",
      "acc for Lsat= 0.1268388407253143 \n",
      "acc for Psat= 0.13561816606670618 \n",
      "acc for optim= 0.11516503266628003\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.003401742083951831\n",
      "Loss on test= 0.004334541037678719\n",
      "acc for Lsat= 0.07175462757651177 \n",
      "acc for Psat= 0.15280106756836176 \n",
      "acc for optim= 0.13811000540024704\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.0034205690026283264\n",
      "Loss on test= 0.004472187254577875\n",
      "acc for Lsat= 0.10463574787394868 \n",
      "acc for Psat= 0.16630764458225006 \n",
      "acc for optim= 0.12387733378111282\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.003539181314408779\n",
      "Loss on test= 0.004412803333252668\n",
      "acc for Lsat= 0.09655097300290233 \n",
      "acc for Psat= 0.13288214849308133 \n",
      "acc for optim= 0.14091568078017896\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.00346206477843225\n",
      "Loss on test= 0.00494941184297204\n",
      "acc for Lsat= 0.11433591194347376 \n",
      "acc for Psat= 0.14954499362243545 \n",
      "acc for optim= 0.12216471037310031\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.00344985444098711\n",
      "Loss on test= 0.0047854953445494175\n",
      "acc for Lsat= 0.10895497331188785 \n",
      "acc for Psat= 0.14667583278949475 \n",
      "acc for optim= 0.13031014890616965\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.003403011942282319\n",
      "Loss on test= 0.004711072891950607\n",
      "acc for Lsat= 0.10223729632950078 \n",
      "acc for Psat= 0.11685393472564304 \n",
      "acc for optim= 0.12256712678612934\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.003428747644647956\n",
      "Loss on test= 0.00461936928331852\n",
      "acc for Lsat= 0.09149857741754709 \n",
      "acc for Psat= 0.1390960995405395 \n",
      "acc for optim= 0.13552144138763347\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.0035290992818772793\n",
      "Loss on test= 0.0045737833715975285\n",
      "acc for Lsat= 0.10506626068510944 \n",
      "acc for Psat= 0.12882219094576108 \n",
      "acc for optim= 0.14260560085272622\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.0034828560892492533\n",
      "Loss on test= 0.004428820684552193\n",
      "acc for Lsat= 0.112418364164316 \n",
      "acc for Psat= 0.14319159535484183 \n",
      "acc for optim= 0.14045821174254847\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.0035577358212321997\n",
      "Loss on test= 0.004293334670364857\n",
      "acc for Lsat= 0.0859202552948975 \n",
      "acc for Psat= 0.11458023350375394 \n",
      "acc for optim= 0.12658996922588509\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.00343130505643785\n",
      "Loss on test= 0.0046861786395311356\n",
      "acc for Lsat= 0.10839483008021489 \n",
      "acc for Psat= 0.1464906655665901 \n",
      "acc for optim= 0.14024475465218225\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.0035474970936775208\n",
      "Loss on test= 0.004416603595018387\n",
      "acc for Lsat= 0.09932083152105203 \n",
      "acc for Psat= 0.12558765002500472 \n",
      "acc for optim= 0.10799777047294709\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.0035857337061315775\n",
      "Loss on test= 0.0043939766474068165\n",
      "acc for Lsat= 0.11614421029419948 \n",
      "acc for Psat= 0.1446171086281538 \n",
      "acc for optim= 0.11813516764798099\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.0034611448645591736\n",
      "Loss on test= 0.004472792614251375\n",
      "acc for Lsat= 0.13484678914149603 \n",
      "acc for Psat= 0.12739610547820726 \n",
      "acc for optim= 0.11538106029749745\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.0035173131618648767\n",
      "Loss on test= 0.004674573894590139\n",
      "acc for Lsat= 0.11647216375503275 \n",
      "acc for Psat= 0.10592637102430065 \n",
      "acc for optim= 0.11734046787023544\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.0034699663519859314\n",
      "Loss on test= 0.0052129002287983894\n",
      "acc for Lsat= 0.09718108446233803 \n",
      "acc for Psat= 0.11066895112809208 \n",
      "acc for optim= 0.12690273902585936\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.0034628824796527624\n",
      "Loss on test= 0.004221414215862751\n",
      "acc for Lsat= 0.09141972122920884 \n",
      "acc for Psat= 0.14075277580155265 \n",
      "acc for optim= 0.11539523761409025\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.003420158987864852\n",
      "Loss on test= 0.004469344392418861\n",
      "acc for Lsat= 0.11615770843086971 \n",
      "acc for Psat= 0.14643512557571134 \n",
      "acc for optim= 0.11828095279633999\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.003499116748571396\n",
      "Loss on test= 0.004726217593997717\n",
      "acc for Lsat= 0.09894224044142498 \n",
      "acc for Psat= 0.12124230966178907 \n",
      "acc for optim= 0.11173544782731268\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.0034375241957604885\n",
      "Loss on test= 0.0044987923465669155\n",
      "acc for Lsat= 0.10476125228322214 \n",
      "acc for Psat= 0.10337069606046295 \n",
      "acc for optim= 0.14191242778259847\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.0033920363057404757\n",
      "Loss on test= 0.004459422081708908\n",
      "acc for Lsat= 0.08826121621920417 \n",
      "acc for Psat= 0.13662385568022728 \n",
      "acc for optim= 0.13247386899052394\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.0033939494751393795\n",
      "Loss on test= 0.004532759543508291\n",
      "acc for Lsat= 0.10370479674182004 \n",
      "acc for Psat= 0.11157759791240096 \n",
      "acc for optim= 0.11646792696168025\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.003436300903558731\n",
      "Loss on test= 0.004599925596266985\n",
      "acc for Lsat= 0.08432450590448247 \n",
      "acc for Psat= 0.14661252710761297 \n",
      "acc for optim= 0.11575031813441052\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.003464855020865798\n",
      "Loss on test= 0.004983046557754278\n",
      "acc for Lsat= 0.12726293074633255 \n",
      "acc for Psat= 0.158521071386834 \n",
      "acc for optim= 0.12318120482895109\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.0034244104754179716\n",
      "Loss on test= 0.0045275939628481865\n",
      "acc for Lsat= 0.08395177488111788 \n",
      "acc for Psat= 0.12307331498919262 \n",
      "acc for optim= 0.1304199419553495\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.003545509185642004\n",
      "Loss on test= 0.004923705942928791\n",
      "acc for Lsat= 0.12193220139791568 \n",
      "acc for Psat= 0.11247523646387789 \n",
      "acc for optim= 0.12625476614468628\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.003491912968456745\n",
      "Loss on test= 0.004682320170104504\n",
      "acc for Lsat= 0.08994397758376887 \n",
      "acc for Psat= 0.1414349810608352 \n",
      "acc for optim= 0.10288527551003629\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.0035513057373464108\n",
      "Loss on test= 0.004625152330845594\n",
      "acc for Lsat= 0.084968388468648 \n",
      "acc for Psat= 0.13051048966331613 \n",
      "acc for optim= 0.13930284045636654\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.0035381761845201254\n",
      "Loss on test= 0.004761488642543554\n",
      "acc for Lsat= 0.0961717024911195 \n",
      "acc for Psat= 0.1383039847585476 \n",
      "acc for optim= 0.10110031775224747\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.00357143790461123\n",
      "Loss on test= 0.004277242813259363\n",
      "acc for Lsat= 0.1027637719655306 \n",
      "acc for Psat= 0.10701461286387509 \n",
      "acc for optim= 0.10929723591026333\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.003423666814342141\n",
      "Loss on test= 0.004489356651902199\n",
      "acc for Lsat= 0.09587127047901352 \n",
      "acc for Psat= 0.11500047787558287 \n",
      "acc for optim= 0.13765856119183204\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.003365056123584509\n",
      "Loss on test= 0.004406211897730827\n",
      "acc for Lsat= 0.10075090337906861 \n",
      "acc for Psat= 0.1258756455240978 \n",
      "acc for optim= 0.09946670707560973\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.003503573127090931\n",
      "Loss on test= 0.0044786082580685616\n",
      "acc for Lsat= 0.0831721902359277 \n",
      "acc for Psat= 0.15038751976357567 \n",
      "acc for optim= 0.12545204281599986\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.0033471190836280584\n",
      "Loss on test= 0.004600847139954567\n",
      "acc for Lsat= 0.07864935520208544 \n",
      "acc for Psat= 0.14810568663395113 \n",
      "acc for optim= 0.15418017065773407\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.003628241363912821\n",
      "Loss on test= 0.004236565437167883\n",
      "acc for Lsat= 0.09283145674918261 \n",
      "acc for Psat= 0.1326495091844764 \n",
      "acc for optim= 0.12247510285427173\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.0034661516547203064\n",
      "Loss on test= 0.004477864596992731\n",
      "acc for Lsat= 0.13948770488301912 \n",
      "acc for Psat= 0.18425400317129162 \n",
      "acc for optim= 0.12831330314899483\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.0034658501390367746\n",
      "Loss on test= 0.004543168470263481\n",
      "acc for Lsat= 0.08883101751820908 \n",
      "acc for Psat= 0.19319353294041422 \n",
      "acc for optim= 0.11418716195556852\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.003409454831853509\n",
      "Loss on test= 0.004616972059011459\n",
      "acc for Lsat= 0.09435376007523802 \n",
      "acc for Psat= 0.1492558711518844 \n",
      "acc for optim= 0.14159856664223802\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.003385152667760849\n",
      "Loss on test= 0.004813637584447861\n",
      "acc for Lsat= 0.13564058900293377 \n",
      "acc for Psat= 0.14526345944937524 \n",
      "acc for optim= 0.12591342664220267\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.0034792087972164154\n",
      "Loss on test= 0.00462064053863287\n",
      "acc for Lsat= 0.07513111302008231 \n",
      "acc for Psat= 0.0982326504567431 \n",
      "acc for optim= 0.11649125118532942\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.0033710389398038387\n",
      "Loss on test= 0.004417060408741236\n",
      "acc for Lsat= 0.07987372460290014 \n",
      "acc for Psat= 0.12899391736007398 \n",
      "acc for optim= 0.13638212386932638\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.003392465179786086\n",
      "Loss on test= 0.004765957128256559\n",
      "acc for Lsat= 0.09276315704401997 \n",
      "acc for Psat= 0.16438399909788537 \n",
      "acc for optim= 0.11826749523687693\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.003502335399389267\n",
      "Loss on test= 0.004387942608445883\n",
      "acc for Lsat= 0.08732751069166828 \n",
      "acc for Psat= 0.13843468413688242 \n",
      "acc for optim= 0.13677583169192076\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.003414770122617483\n",
      "Loss on test= 0.004530818201601505\n",
      "acc for Lsat= 0.12614977571906316 \n",
      "acc for Psat= 0.1113343085679743 \n",
      "acc for optim= 0.10572712335528599\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.003431187476962805\n",
      "Loss on test= 0.004873567260801792\n",
      "acc for Lsat= 0.08169205033320598 \n",
      "acc for Psat= 0.1443934639553643 \n",
      "acc for optim= 0.12958025601175097\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.003351700259372592\n",
      "Loss on test= 0.004595630802214146\n",
      "acc for Lsat= 0.11197042669583526 \n",
      "acc for Psat= 0.14900487688525269 \n",
      "acc for optim= 0.16298663000472718\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.003495674580335617\n",
      "Loss on test= 0.004344431683421135\n",
      "acc for Lsat= 0.1051413067875223 \n",
      "acc for Psat= 0.12852545698276824 \n",
      "acc for optim= 0.13636323830319774\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.0035651118960231543\n",
      "Loss on test= 0.004396940115839243\n",
      "acc for Lsat= 0.09389939372582982 \n",
      "acc for Psat= 0.11746395512293223 \n",
      "acc for optim= 0.12216920840566875\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.00339177786372602\n",
      "Loss on test= 0.0045286077074706554\n",
      "acc for Lsat= 0.10988037008792162 \n",
      "acc for Psat= 0.1540229998321997 \n",
      "acc for optim= 0.1356120877381828\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.0034178963396698236\n",
      "Loss on test= 0.004620576277375221\n",
      "acc for Lsat= 0.13148528503047097 \n",
      "acc for Psat= 0.1602160491877132 \n",
      "acc for optim= 0.13149532272169986\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.0035627714823931456\n",
      "Loss on test= 0.004645777866244316\n",
      "acc for Lsat= 0.08801188883889052 \n",
      "acc for Psat= 0.14593925720287693 \n",
      "acc for optim= 0.13949944492843416\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.0033403837587684393\n",
      "Loss on test= 0.0044727809727191925\n",
      "acc for Lsat= 0.0933567670872435 \n",
      "acc for Psat= 0.12812336081373765 \n",
      "acc for optim= 0.12653710206763613\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.0033278597984462976\n",
      "Loss on test= 0.004471409134566784\n",
      "acc for Lsat= 0.10450782502690951 \n",
      "acc for Psat= 0.14524850921912325 \n",
      "acc for optim= 0.1510163965738482\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.0034627877175807953\n",
      "Loss on test= 0.004553346429020166\n",
      "acc for Lsat= 0.10013172045970957 \n",
      "acc for Psat= 0.11709550468044148 \n",
      "acc for optim= 0.11823646631091833\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.0035081496462225914\n",
      "Loss on test= 0.004868451971560717\n",
      "acc for Lsat= 0.10656709086874293 \n",
      "acc for Psat= 0.15506791106114784 \n",
      "acc for optim= 0.10737183161028144\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.003487415611743927\n",
      "Loss on test= 0.004732606932520866\n",
      "acc for Lsat= 0.12564162061446243 \n",
      "acc for Psat= 0.1337734190423766 \n",
      "acc for optim= 0.1312792557809088\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.0034499841276556253\n",
      "Loss on test= 0.004323696717619896\n",
      "acc for Lsat= 0.11970569917725192 \n",
      "acc for Psat= 0.13479404826648533 \n",
      "acc for optim= 0.09674580025279687\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.003366287564858794\n",
      "Loss on test= 0.004290703218430281\n",
      "acc for Lsat= 0.0873679674954878 \n",
      "acc for Psat= 0.12689640517863962 \n",
      "acc for optim= 0.15976725232192418\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.0036235039588063955\n",
      "Loss on test= 0.004665737971663475\n",
      "acc for Lsat= 0.09944882461180289 \n",
      "acc for Psat= 0.1360308345950519 \n",
      "acc for optim= 0.12900070318331322\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.003388704266399145\n",
      "Loss on test= 0.004701802507042885\n",
      "acc for Lsat= 0.0877586947236624 \n",
      "acc for Psat= 0.13567269038564214 \n",
      "acc for optim= 0.14061557289419901\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.00326707074418664\n",
      "Loss on test= 0.004669900983572006\n",
      "acc for Lsat= 0.08991822469720824 \n",
      "acc for Psat= 0.1313550502786206 \n",
      "acc for optim= 0.1633957536994583\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.003381155664101243\n",
      "Loss on test= 0.004421243444085121\n",
      "acc for Lsat= 0.10763225623264185 \n",
      "acc for Psat= 0.14150591137715512 \n",
      "acc for optim= 0.14072857134872013\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.0033604905474931\n",
      "Loss on test= 0.0044141169637441635\n",
      "acc for Lsat= 0.10479736196187635 \n",
      "acc for Psat= 0.125414106878452 \n",
      "acc for optim= 0.14406376482091016\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.003347876016050577\n",
      "Loss on test= 0.004750687628984451\n",
      "acc for Lsat= 0.0771775283695509 \n",
      "acc for Psat= 0.16564336895114845 \n",
      "acc for optim= 0.14162717511256537\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.0034300729166716337\n",
      "Loss on test= 0.004758050665259361\n",
      "acc for Lsat= 0.1317204763698909 \n",
      "acc for Psat= 0.14100467815943477 \n",
      "acc for optim= 0.1336478334592862\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.0034130753483623266\n",
      "Loss on test= 0.004695114213973284\n",
      "acc for Lsat= 0.10230597181038724 \n",
      "acc for Psat= 0.13510409851248065 \n",
      "acc for optim= 0.12921191829567155\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.0033269391860812902\n",
      "Loss on test= 0.004583165515214205\n",
      "acc for Lsat= 0.11908294208761719 \n",
      "acc for Psat= 0.13706668045779224 \n",
      "acc for optim= 0.13767301261476758\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.0035015875473618507\n",
      "Loss on test= 0.004597445018589497\n",
      "acc for Lsat= 0.08436258416622877 \n",
      "acc for Psat= 0.11332564914806022 \n",
      "acc for optim= 0.13242452415741152\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.0034740963019430637\n",
      "Loss on test= 0.004785835277289152\n",
      "acc for Lsat= 0.11746194822868954 \n",
      "acc for Psat= 0.14266420590380827 \n",
      "acc for optim= 0.12677491466618246\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.003543707774952054\n",
      "Loss on test= 0.0045526293106377125\n",
      "acc for Lsat= 0.105612172667558 \n",
      "acc for Psat= 0.11495213136853029 \n",
      "acc for optim= 0.17122013008015025\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.003427226794883609\n",
      "Loss on test= 0.004614503588527441\n",
      "acc for Lsat= 0.08733471244987515 \n",
      "acc for Psat= 0.14914364052108592 \n",
      "acc for optim= 0.11191630433313549\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.003445015987381339\n",
      "Loss on test= 0.0045587955974042416\n",
      "acc for Lsat= 0.08122998416527277 \n",
      "acc for Psat= 0.12160578111393584 \n",
      "acc for optim= 0.12655340882742572\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.003387055592611432\n",
      "Loss on test= 0.0045324163511395454\n",
      "acc for Lsat= 0.12209800828713924 \n",
      "acc for Psat= 0.13959128657976785 \n",
      "acc for optim= 0.10087050414747661\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.0033481100108474493\n",
      "Loss on test= 0.004725438077002764\n",
      "acc for Lsat= 0.0982326440539004 \n",
      "acc for Psat= 0.1137150549588518 \n",
      "acc for optim= 0.1222257252342792\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.003445772221311927\n",
      "Loss on test= 0.004448408260941505\n",
      "acc for Lsat= 0.09742541186925438 \n",
      "acc for Psat= 0.09732232191082504 \n",
      "acc for optim= 0.13776959225328433\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.003476676531136036\n",
      "Loss on test= 0.004798285663127899\n",
      "acc for Lsat= 0.08261222118744627 \n",
      "acc for Psat= 0.11018931323390764 \n",
      "acc for optim= 0.11720078748961289\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.0032720803283154964\n",
      "Loss on test= 0.004697283264249563\n",
      "acc for Lsat= 0.124838476948854 \n",
      "acc for Psat= 0.13241427143414816 \n",
      "acc for optim= 0.1322295077972942\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.0033861531410366297\n",
      "Loss on test= 0.0047098868526518345\n",
      "acc for Lsat= 0.11393916358550389 \n",
      "acc for Psat= 0.11957497749891546 \n",
      "acc for optim= 0.10150484414771199\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.003270787885412574\n",
      "Loss on test= 0.004659461788833141\n",
      "acc for Lsat= 0.07522306257548432 \n",
      "acc for Psat= 0.10622300104134613 \n",
      "acc for optim= 0.15858558451549876\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.003397288266569376\n",
      "Loss on test= 0.004259267821907997\n",
      "acc for Lsat= 0.10816248479144026 \n",
      "acc for Psat= 0.15452212729077372 \n",
      "acc for optim= 0.17332055367943314\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.00339739047922194\n",
      "Loss on test= 0.00478470791131258\n",
      "acc for Lsat= 0.09710309618256158 \n",
      "acc for Psat= 0.1510821142130428 \n",
      "acc for optim= 0.14992405091308886\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.003401864552870393\n",
      "Loss on test= 0.004560013767331839\n",
      "acc for Lsat= 0.09403018834483293 \n",
      "acc for Psat= 0.14149109204623123 \n",
      "acc for optim= 0.12284647890677054\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.0034867844078689814\n",
      "Loss on test= 0.004992451053112745\n",
      "acc for Lsat= 0.09340283347086774 \n",
      "acc for Psat= 0.12154056204275952 \n",
      "acc for optim= 0.11489352330358492\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.003397303633391857\n",
      "Loss on test= 0.004888748284429312\n",
      "acc for Lsat= 0.08731770572356051 \n",
      "acc for Psat= 0.12261859586255418 \n",
      "acc for optim= 0.11962689195449154\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.0033065711613744497\n",
      "Loss on test= 0.004722118377685547\n",
      "acc for Lsat= 0.08730958386634786 \n",
      "acc for Psat= 0.16064755732400549 \n",
      "acc for optim= 0.13778019060717067\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.003408689983189106\n",
      "Loss on test= 0.004618707112967968\n",
      "acc for Lsat= 0.12476781341764662 \n",
      "acc for Psat= 0.15853209524518913 \n",
      "acc for optim= 0.1251315616019484\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.0033063977025449276\n",
      "Loss on test= 0.004742516204714775\n",
      "acc for Lsat= 0.09763998217466804 \n",
      "acc for Psat= 0.12219489198145715 \n",
      "acc for optim= 0.14340582521011433\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.0035103901755064726\n",
      "Loss on test= 0.0043908171355724335\n",
      "acc for Lsat= 0.10573703950891893 \n",
      "acc for Psat= 0.15522112604230642 \n",
      "acc for optim= 0.11506503991161783\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.003296118462458253\n",
      "Loss on test= 0.004436592571437359\n",
      "acc for Lsat= 0.0785792397800833 \n",
      "acc for Psat= 0.11286742617246798 \n",
      "acc for optim= 0.16960520026946646\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.003368563950061798\n",
      "Loss on test= 0.004702478647232056\n",
      "acc for Lsat= 0.11036291234712634 \n",
      "acc for Psat= 0.09788340389625066 \n",
      "acc for optim= 0.1515272231772542\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.003366389311850071\n",
      "Loss on test= 0.0047209374606609344\n",
      "acc for Lsat= 0.09303610125142667 \n",
      "acc for Psat= 0.14736903986482097 \n",
      "acc for optim= 0.1462301711241404\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.0034410404041409492\n",
      "Loss on test= 0.004736347123980522\n",
      "acc for Lsat= 0.12365873370112644 \n",
      "acc for Psat= 0.12705768688788843 \n",
      "acc for optim= 0.136504201994588\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.0033902309369295835\n",
      "Loss on test= 0.0043402244336903095\n",
      "acc for Lsat= 0.05707352839979447 \n",
      "acc for Psat= 0.09376252787317046 \n",
      "acc for optim= 0.1271589124161336\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.0034435538109391928\n",
      "Loss on test= 0.004555337596684694\n",
      "acc for Lsat= 0.09079652197316238 \n",
      "acc for Psat= 0.12165074673895207 \n",
      "acc for optim= 0.1134697647454838\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.0033924856688827276\n",
      "Loss on test= 0.004689774475991726\n",
      "acc for Lsat= 0.11984984162780973 \n",
      "acc for Psat= 0.15478978099094498 \n",
      "acc for optim= 0.1408364831780394\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.003316880902275443\n",
      "Loss on test= 0.004791783168911934\n",
      "acc for Lsat= 0.10413759976250327 \n",
      "acc for Psat= 0.11856128280568454 \n",
      "acc for optim= 0.13251350175899765\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.0033647234085947275\n",
      "Loss on test= 0.004519364796578884\n",
      "acc for Lsat= 0.08653262614582975 \n",
      "acc for Psat= 0.11418755758010472 \n",
      "acc for optim= 0.11529455613344908\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.003392235143110156\n",
      "Loss on test= 0.004567957483232021\n",
      "acc for Lsat= 0.09947503039923807 \n",
      "acc for Psat= 0.0997543981195324 \n",
      "acc for optim= 0.11021701691465245\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.0031793045345693827\n",
      "Loss on test= 0.004837206564843655\n",
      "acc for Lsat= 0.07978289630005343 \n",
      "acc for Psat= 0.12684069015085697 \n",
      "acc for optim= 0.09574745274666283\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.003426579525694251\n",
      "Loss on test= 0.00437583215534687\n",
      "acc for Lsat= 0.0946352894922408 \n",
      "acc for Psat= 0.12403786073749264 \n",
      "acc for optim= 0.15764757804572582\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.0033455216325819492\n",
      "Loss on test= 0.004490358754992485\n",
      "acc for Lsat= 0.07872160710394382 \n",
      "acc for Psat= 0.1419327555017339 \n",
      "acc for optim= 0.14840804030083948\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.0034007730428129435\n",
      "Loss on test= 0.004594420548528433\n",
      "acc for Lsat= 0.09966035766734017 \n",
      "acc for Psat= 0.14209578651934862 \n",
      "acc for optim= 0.1413718592828243\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.003377073211595416\n",
      "Loss on test= 0.004899679683148861\n",
      "acc for Lsat= 0.07641638360089725 \n",
      "acc for Psat= 0.11543290037661791 \n",
      "acc for optim= 0.13598171670714188\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.003371414728462696\n",
      "Loss on test= 0.0046441880986094475\n",
      "acc for Lsat= 0.09344350412074062 \n",
      "acc for Psat= 0.1418405670620915 \n",
      "acc for optim= 0.12138089775625202\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.003401881316676736\n",
      "Loss on test= 0.004257521592080593\n",
      "acc for Lsat= 0.10299085670461257 \n",
      "acc for Psat= 0.10579917067661881 \n",
      "acc for optim= 0.12626388831995428\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.0033913343213498592\n",
      "Loss on test= 0.0045658075250685215\n",
      "acc for Lsat= 0.10685955163919264 \n",
      "acc for Psat= 0.12568475989003977 \n",
      "acc for optim= 0.10830696682549185\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.00333640375174582\n",
      "Loss on test= 0.004570940509438515\n",
      "acc for Lsat= 0.11064969624082248 \n",
      "acc for Psat= 0.14008989495535693 \n",
      "acc for optim= 0.1287948446891581\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.0032793148420751095\n",
      "Loss on test= 0.00465643685311079\n",
      "acc for Lsat= 0.1178870063352709 \n",
      "acc for Psat= 0.16290079947147104 \n",
      "acc for optim= 0.17266926500532362\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.0033255943562835455\n",
      "Loss on test= 0.004786916542798281\n",
      "acc for Lsat= 0.11441395938810375 \n",
      "acc for Psat= 0.14859644530547989 \n",
      "acc for optim= 0.14194642779572555\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.003264904022216797\n",
      "Loss on test= 0.004779277369379997\n",
      "acc for Lsat= 0.11745826987963584 \n",
      "acc for Psat= 0.15566660929471254 \n",
      "acc for optim= 0.1211854012734774\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.003404981689527631\n",
      "Loss on test= 0.004550314974039793\n",
      "acc for Lsat= 0.09084235320592092 \n",
      "acc for Psat= 0.11884544167777575 \n",
      "acc for optim= 0.12212925747735426\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.003238484961912036\n",
      "Loss on test= 0.004521251190453768\n",
      "acc for Lsat= 0.08801359215026928 \n",
      "acc for Psat= 0.15024663280281755 \n",
      "acc for optim= 0.16296879750572973\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.0034733759239315987\n",
      "Loss on test= 0.00428730808198452\n",
      "acc for Lsat= 0.10825274149990743 \n",
      "acc for Psat= 0.1852908149982492 \n",
      "acc for optim= 0.14280825087593663\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.003457079641520977\n",
      "Loss on test= 0.004775190260261297\n",
      "acc for Lsat= 0.09787618705174989 \n",
      "acc for Psat= 0.12545064226206806 \n",
      "acc for optim= 0.1430282804908024\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.003262690966948867\n",
      "Loss on test= 0.004627215676009655\n",
      "acc for Lsat= 0.08896649408982032 \n",
      "acc for Psat= 0.14037928626122367 \n",
      "acc for optim= 0.1488964483141899\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.003413357539102435\n",
      "Loss on test= 0.004791891202330589\n",
      "acc for Lsat= 0.10977844811148113 \n",
      "acc for Psat= 0.1410788484952516 \n",
      "acc for optim= 0.1178591003538006\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.00334485387429595\n",
      "Loss on test= 0.004479716997593641\n",
      "acc for Lsat= 0.11859305765311648 \n",
      "acc for Psat= 0.1196997422311041 \n",
      "acc for optim= 0.13116828445345163\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.0033880630508065224\n",
      "Loss on test= 0.005196595564484596\n",
      "acc for Lsat= 0.1266478812127995 \n",
      "acc for Psat= 0.13400274660024378 \n",
      "acc for optim= 0.12819511039803425\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.0033657439053058624\n",
      "Loss on test= 0.0047206273302435875\n",
      "acc for Lsat= 0.10979131447513485 \n",
      "acc for Psat= 0.1835331062061919 \n",
      "acc for optim= 0.11538281935888033\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.0033859482500702143\n",
      "Loss on test= 0.004564352799206972\n",
      "acc for Lsat= 0.11396707997967799 \n",
      "acc for Psat= 0.12703674488390485 \n",
      "acc for optim= 0.12060306497086357\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.003266390645876527\n",
      "Loss on test= 0.004824155941605568\n",
      "acc for Lsat= 0.11265055183321238 \n",
      "acc for Psat= 0.11908433193133937 \n",
      "acc for optim= 0.14486185163776907\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.003345597768202424\n",
      "Loss on test= 0.004699211101979017\n",
      "acc for Lsat= 0.15048385333890715 \n",
      "acc for Psat= 0.16090641232828298 \n",
      "acc for optim= 0.17215926639942658\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.0033251680433750153\n",
      "Loss on test= 0.004872554913163185\n",
      "acc for Lsat= 0.10772459229661359 \n",
      "acc for Psat= 0.1752536403429177 \n",
      "acc for optim= 0.1291477977970822\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.0032914981711655855\n",
      "Loss on test= 0.0045854803174734116\n",
      "acc for Lsat= 0.07798407278541061 \n",
      "acc for Psat= 0.1574340500972337 \n",
      "acc for optim= 0.11384266138904625\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.0032876795157790184\n",
      "Loss on test= 0.004712782334536314\n",
      "acc for Lsat= 0.12412325683463779 \n",
      "acc for Psat= 0.11016679119913736 \n",
      "acc for optim= 0.11508830895440446\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.0033700743224471807\n",
      "Loss on test= 0.0044571030884981155\n",
      "acc for Lsat= 0.10198460863385764 \n",
      "acc for Psat= 0.13973129064672524 \n",
      "acc for optim= 0.1480662189424038\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.0033121316228061914\n",
      "Loss on test= 0.004402206279337406\n",
      "acc for Lsat= 0.12566542511598933 \n",
      "acc for Psat= 0.1209314985640554 \n",
      "acc for optim= 0.11079085744374122\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.003334818873554468\n",
      "Loss on test= 0.004600025713443756\n",
      "acc for Lsat= 0.0976675745461964 \n",
      "acc for Psat= 0.12052919617013282 \n",
      "acc for optim= 0.11916109479756819\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.0034381297882646322\n",
      "Loss on test= 0.004604427143931389\n",
      "acc for Lsat= 0.08642316065056042 \n",
      "acc for Psat= 0.11253659215031399 \n",
      "acc for optim= 0.11608083103783429\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.0032986486330628395\n",
      "Loss on test= 0.004568655043840408\n",
      "acc for Lsat= 0.09170511113997135 \n",
      "acc for Psat= 0.101051569579997 \n",
      "acc for optim= 0.10483493107474512\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.0035403654910624027\n",
      "Loss on test= 0.004188081715255976\n",
      "acc for Lsat= 0.12684373635177812 \n",
      "acc for Psat= 0.14142586420186692 \n",
      "acc for optim= 0.14221446556297856\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.003318882780149579\n",
      "Loss on test= 0.004362399689853191\n",
      "acc for Lsat= 0.12536678329989728 \n",
      "acc for Psat= 0.13902271011223397 \n",
      "acc for optim= 0.13784576973153484\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.0034552505239844322\n",
      "Loss on test= 0.00430684769526124\n",
      "acc for Lsat= 0.10686789887646835 \n",
      "acc for Psat= 0.11151828420891736 \n",
      "acc for optim= 0.12144243872414033\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.0032688500359654427\n",
      "Loss on test= 0.004533863160759211\n",
      "acc for Lsat= 0.11014158506360319 \n",
      "acc for Psat= 0.10436530069758494 \n",
      "acc for optim= 0.12096114208300908\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.0033066323958337307\n",
      "Loss on test= 0.004757090006023645\n",
      "acc for Lsat= 0.11851129629131821 \n",
      "acc for Psat= 0.13026891581507194 \n",
      "acc for optim= 0.14280625880281958\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.003245060797780752\n",
      "Loss on test= 0.0046005104668438435\n",
      "acc for Lsat= 0.11198202499912845 \n",
      "acc for Psat= 0.14773368390483987 \n",
      "acc for optim= 0.09405527150051461\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.0032138682436197996\n",
      "Loss on test= 0.004530983045697212\n",
      "acc for Lsat= 0.09680221167703469 \n",
      "acc for Psat= 0.16196676840384802 \n",
      "acc for optim= 0.14523818861279222\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.0033089800272136927\n",
      "Loss on test= 0.004298346117138863\n",
      "acc for Lsat= 0.1191640483836333 \n",
      "acc for Psat= 0.13035477563324901 \n",
      "acc for optim= 0.126204885283692\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.0032788319513201714\n",
      "Loss on test= 0.004726458806544542\n",
      "acc for Lsat= 0.09422114052964996 \n",
      "acc for Psat= 0.16281714955241317 \n",
      "acc for optim= 0.1287168123655849\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.0034074701834470034\n",
      "Loss on test= 0.00438159704208374\n",
      "acc for Lsat= 0.08919883731545673 \n",
      "acc for Psat= 0.13060232438147068 \n",
      "acc for optim= 0.110227111261338\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.0034780746791511774\n",
      "Loss on test= 0.004436346236616373\n",
      "acc for Lsat= 0.10037946706223819 \n",
      "acc for Psat= 0.14780129906204012 \n",
      "acc for optim= 0.1490658256613339\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.003277802374213934\n",
      "Loss on test= 0.0042213755659759045\n",
      "acc for Lsat= 0.08418017985402709 \n",
      "acc for Psat= 0.11375364133467276 \n",
      "acc for optim= 0.14630679455068377\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.003147983457893133\n",
      "Loss on test= 0.00473030935972929\n",
      "acc for Lsat= 0.09233201972933279 \n",
      "acc for Psat= 0.10602462390023801 \n",
      "acc for optim= 0.13339469473188123\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.0031277055386453867\n",
      "Loss on test= 0.0049009425565600395\n",
      "acc for Lsat= 0.11159782991227177 \n",
      "acc for Psat= 0.12994342100703055 \n",
      "acc for optim= 0.12062355832313187\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.0032952732872217894\n",
      "Loss on test= 0.004778116475790739\n",
      "acc for Lsat= 0.071919287296219 \n",
      "acc for Psat= 0.12109404766751039 \n",
      "acc for optim= 0.1381021098091474\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.003381591523066163\n",
      "Loss on test= 0.004286929965019226\n",
      "acc for Lsat= 0.09496513725672331 \n",
      "acc for Psat= 0.1369002245547664 \n",
      "acc for optim= 0.12918114919577622\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.0033104242756962776\n",
      "Loss on test= 0.0046832989901304245\n",
      "acc for Lsat= 0.11767578584193769 \n",
      "acc for Psat= 0.13028992504405323 \n",
      "acc for optim= 0.13763471060277274\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.003276227507740259\n",
      "Loss on test= 0.004613164812326431\n",
      "acc for Lsat= 0.12387252329952186 \n",
      "acc for Psat= 0.14243374309606022 \n",
      "acc for optim= 0.13266395496773636\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.0032448163256049156\n",
      "Loss on test= 0.004606341943144798\n",
      "acc for Lsat= 0.0891906915583402 \n",
      "acc for Psat= 0.1064589581025454 \n",
      "acc for optim= 0.12825100848244297\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.0032259440049529076\n",
      "Loss on test= 0.004793649539351463\n",
      "acc for Lsat= 0.10249663542749153 \n",
      "acc for Psat= 0.10907252341146684 \n",
      "acc for optim= 0.14728068873389727\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.0032209022901952267\n",
      "Loss on test= 0.004436869639903307\n",
      "acc for Lsat= 0.11968102070709898 \n",
      "acc for Psat= 0.1235114743726121 \n",
      "acc for optim= 0.10758509135080709\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.0032186880707740784\n",
      "Loss on test= 0.004363660234957933\n",
      "acc for Lsat= 0.09441334359710002 \n",
      "acc for Psat= 0.15720047377463844 \n",
      "acc for optim= 0.1240760696431001\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.003303917357698083\n",
      "Loss on test= 0.004656810779124498\n",
      "acc for Lsat= 0.08480639331456688 \n",
      "acc for Psat= 0.14166148599340683 \n",
      "acc for optim= 0.12936096956642965\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.0033727986738085747\n",
      "Loss on test= 0.004468787927180529\n",
      "acc for Lsat= 0.12286297617376679 \n",
      "acc for Psat= 0.11435240745130512 \n",
      "acc for optim= 0.10796158465867241\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.0033047585748136044\n",
      "Loss on test= 0.0045102983713150024\n",
      "acc for Lsat= 0.12061443492873675 \n",
      "acc for Psat= 0.14098923922412926 \n",
      "acc for optim= 0.14118831790336925\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.0032991194166243076\n",
      "Loss on test= 0.004561703186482191\n",
      "acc for Lsat= 0.1023242630245578 \n",
      "acc for Psat= 0.10648454120382667 \n",
      "acc for optim= 0.13001696165237162\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.0032760112080723047\n",
      "Loss on test= 0.004175406415015459\n",
      "acc for Lsat= 0.11797391898774852 \n",
      "acc for Psat= 0.1823590960767534 \n",
      "acc for optim= 0.12434987441843583\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.0033208816312253475\n",
      "Loss on test= 0.004654608201235533\n",
      "acc for Lsat= 0.07930817245829126 \n",
      "acc for Psat= 0.14882053636635342 \n",
      "acc for optim= 0.11990511841658089\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.003298839321359992\n",
      "Loss on test= 0.00431461026892066\n",
      "acc for Lsat= 0.1094304613976015 \n",
      "acc for Psat= 0.12051798072126177 \n",
      "acc for optim= 0.15223087846404976\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.003153284080326557\n",
      "Loss on test= 0.004372402094304562\n",
      "acc for Lsat= 0.09091412074243028 \n",
      "acc for Psat= 0.14829407135645548 \n",
      "acc for optim= 0.11307036032667384\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.0033168508671224117\n",
      "Loss on test= 0.004232452251017094\n",
      "acc for Lsat= 0.09080718167954022 \n",
      "acc for Psat= 0.14122504306336245 \n",
      "acc for optim= 0.11319362451063676\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.0032033363822847605\n",
      "Loss on test= 0.004732644651085138\n",
      "acc for Lsat= 0.07534830900840461 \n",
      "acc for Psat= 0.15802678869416317 \n",
      "acc for optim= 0.14938593790349033\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.003216952783986926\n",
      "Loss on test= 0.004549425095319748\n",
      "acc for Lsat= 0.10073704520861308 \n",
      "acc for Psat= 0.10925812336305778 \n",
      "acc for optim= 0.1495801549883456\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.00332599482499063\n",
      "Loss on test= 0.004799707792699337\n",
      "acc for Lsat= 0.0940847580657444 \n",
      "acc for Psat= 0.13328262775515518 \n",
      "acc for optim= 0.11863959482353595\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.0034017458092421293\n",
      "Loss on test= 0.004572843201458454\n",
      "acc for Lsat= 0.1256554130361312 \n",
      "acc for Psat= 0.15399396000429988 \n",
      "acc for optim= 0.11858653644513753\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.003211897099390626\n",
      "Loss on test= 0.004834235180169344\n",
      "acc for Lsat= 0.14845324323202172 \n",
      "acc for Psat= 0.12315319884671933 \n",
      "acc for optim= 0.14394067714197767\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.003320871153846383\n",
      "Loss on test= 0.004682768601924181\n",
      "acc for Lsat= 0.0941581393385099 \n",
      "acc for Psat= 0.1242316943179402 \n",
      "acc for optim= 0.1437821658845577\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.0032836473546922207\n",
      "Loss on test= 0.0045218635350465775\n",
      "acc for Lsat= 0.10824538107650976 \n",
      "acc for Psat= 0.1126631244033989 \n",
      "acc for optim= 0.11051183607843187\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.00319457589648664\n",
      "Loss on test= 0.004400086589157581\n",
      "acc for Lsat= 0.09930821642693546 \n",
      "acc for Psat= 0.13311351126887733 \n",
      "acc for optim= 0.14522088791191992\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.00314605375751853\n",
      "Loss on test= 0.004588121548295021\n",
      "acc for Lsat= 0.10017452140649159 \n",
      "acc for Psat= 0.08971319099267323 \n",
      "acc for optim= 0.1278465032680995\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.0033544590696692467\n",
      "Loss on test= 0.004184884950518608\n",
      "acc for Lsat= 0.08737795448137654 \n",
      "acc for Psat= 0.10650258265539175 \n",
      "acc for optim= 0.13841207353915605\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.0032402242068201303\n",
      "Loss on test= 0.004598570987582207\n",
      "acc for Lsat= 0.11072655068710446 \n",
      "acc for Psat= 0.10989472218271759 \n",
      "acc for optim= 0.13610608112584385\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.0032042248640209436\n",
      "Loss on test= 0.004758268129080534\n",
      "acc for Lsat= 0.07793239942596604 \n",
      "acc for Psat= 0.13874520547688007 \n",
      "acc for optim= 0.1576914869559308\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.0034459144808351994\n",
      "Loss on test= 0.004716322757303715\n",
      "acc for Lsat= 0.12891676085483697 \n",
      "acc for Psat= 0.12123737230689989 \n",
      "acc for optim= 0.14158488851454523\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.003215478267520666\n",
      "Loss on test= 0.004525081720203161\n",
      "acc for Lsat= 0.1059780021249834 \n",
      "acc for Psat= 0.1540027857861585 \n",
      "acc for optim= 0.1356595973484218\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.0033923496957868338\n",
      "Loss on test= 0.004635885823518038\n",
      "acc for Lsat= 0.09218412833676363 \n",
      "acc for Psat= 0.1346565920781965 \n",
      "acc for optim= 0.15859982785251406\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.003282481338828802\n",
      "Loss on test= 0.004854327533394098\n",
      "acc for Lsat= 0.08414576575160027 \n",
      "acc for Psat= 0.15426810872223642 \n",
      "acc for optim= 0.12392496027880245\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.0033805666025727987\n",
      "Loss on test= 0.004630016628652811\n",
      "acc for Lsat= 0.08698706743174019 \n",
      "acc for Psat= 0.13629509053296512 \n",
      "acc for optim= 0.14459140311616162\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.0033458247780799866\n",
      "Loss on test= 0.004505594726651907\n",
      "acc for Lsat= 0.077279045789813 \n",
      "acc for Psat= 0.12541150327564943 \n",
      "acc for optim= 0.14861417755795023\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.0032493381295353174\n",
      "Loss on test= 0.004730771295726299\n",
      "acc for Lsat= 0.14190403171556276 \n",
      "acc for Psat= 0.12323726202723467 \n",
      "acc for optim= 0.1180379450864469\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.003388773649930954\n",
      "Loss on test= 0.004423653241246939\n",
      "acc for Lsat= 0.10115917251419483 \n",
      "acc for Psat= 0.15861061722454098 \n",
      "acc for optim= 0.12376479514771038\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.003346327692270279\n",
      "Loss on test= 0.004783749580383301\n",
      "acc for Lsat= 0.11040628372898532 \n",
      "acc for Psat= 0.13581513327598158 \n",
      "acc for optim= 0.14750039758574632\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.0032238902058452368\n",
      "Loss on test= 0.004852436948567629\n",
      "acc for Lsat= 0.08301382620508473 \n",
      "acc for Psat= 0.15251312917098403 \n",
      "acc for optim= 0.12966617429628968\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.0032669552601873875\n",
      "Loss on test= 0.0043935044668614864\n",
      "acc for Lsat= 0.09567579585644934 \n",
      "acc for Psat= 0.12474295527337947 \n",
      "acc for optim= 0.10729583624439935\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.0031846945639699697\n",
      "Loss on test= 0.004717170260846615\n",
      "acc for Lsat= 0.07645856036752877 \n",
      "acc for Psat= 0.1325969616009388 \n",
      "acc for optim= 0.16118357386181337\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.0033699735067784786\n",
      "Loss on test= 0.004540934227406979\n",
      "acc for Lsat= 0.08543842452733467 \n",
      "acc for Psat= 0.10678557027131319 \n",
      "acc for optim= 0.1261313445866108\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.0032341720070689917\n",
      "Loss on test= 0.0045391772873699665\n",
      "acc for Lsat= 0.1109366233771046 \n",
      "acc for Psat= 0.1387706903947724 \n",
      "acc for optim= 0.1391680354718119\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.0031903847120702267\n",
      "Loss on test= 0.004845315590500832\n",
      "acc for Lsat= 0.1004862859715811 \n",
      "acc for Psat= 0.10161213429334263 \n",
      "acc for optim= 0.11006263746983475\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.0031895197462290525\n",
      "Loss on test= 0.004435734823346138\n",
      "acc for Lsat= 0.0796602393190066 \n",
      "acc for Psat= 0.13603020107580555 \n",
      "acc for optim= 0.11200418380192584\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.0032424896489828825\n",
      "Loss on test= 0.004687538370490074\n",
      "acc for Lsat= 0.1236029187631276 \n",
      "acc for Psat= 0.12475305671493213 \n",
      "acc for optim= 0.12528585120000774\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.003197902347892523\n",
      "Loss on test= 0.004998247139155865\n",
      "acc for Lsat= 0.11088503566053179 \n",
      "acc for Psat= 0.15351800579163763 \n",
      "acc for optim= 0.11885895807709959\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.003223721170797944\n",
      "Loss on test= 0.00456642359495163\n",
      "acc for Lsat= 0.10845713643357158 \n",
      "acc for Psat= 0.08690893084793869 \n",
      "acc for optim= 0.12057283243888782\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.003296006703749299\n",
      "Loss on test= 0.004538137000054121\n",
      "acc for Lsat= 0.09526258641077827 \n",
      "acc for Psat= 0.1525613364453117 \n",
      "acc for optim= 0.09038854509385096\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.0032843737863004208\n",
      "Loss on test= 0.004597105551511049\n",
      "acc for Lsat= 0.1125803441447412 \n",
      "acc for Psat= 0.1659003235399723 \n",
      "acc for optim= 0.10836338471724755\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.0032948136795312166\n",
      "Loss on test= 0.004549117758870125\n",
      "acc for Lsat= 0.10929708286292023 \n",
      "acc for Psat= 0.12615973877513575 \n",
      "acc for optim= 0.15174932720967466\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.0033090750221163034\n",
      "Loss on test= 0.004667480941861868\n",
      "acc for Lsat= 0.11413487864451276 \n",
      "acc for Psat= 0.16671566178815234 \n",
      "acc for optim= 0.12154114968143404\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.003196708858013153\n",
      "Loss on test= 0.004977650474756956\n",
      "acc for Lsat= 0.07996307556317737 \n",
      "acc for Psat= 0.10295469399231176 \n",
      "acc for optim= 0.12564356185288894\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.0032215865794569254\n",
      "Loss on test= 0.004332497250288725\n",
      "acc for Lsat= 0.12168636771902028 \n",
      "acc for Psat= 0.13455382662100923 \n",
      "acc for optim= 0.12324017251376063\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.0033063848968595266\n",
      "Loss on test= 0.004356790333986282\n",
      "acc for Lsat= 0.08339121027125253 \n",
      "acc for Psat= 0.1600683860273825 \n",
      "acc for optim= 0.14789147431858712\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.0032042255625128746\n",
      "Loss on test= 0.004554396029561758\n",
      "acc for Lsat= 0.11384019234942065 \n",
      "acc for Psat= 0.11429816890611416 \n",
      "acc for optim= 0.11199980151529114\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.0032349848188459873\n",
      "Loss on test= 0.004629740957170725\n",
      "acc for Lsat= 0.12565837523693013 \n",
      "acc for Psat= 0.14124709688540962 \n",
      "acc for optim= 0.14575992995459172\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.0032833016011863947\n",
      "Loss on test= 0.004766965284943581\n",
      "acc for Lsat= 0.08001239152832164 \n",
      "acc for Psat= 0.11970575834210548 \n",
      "acc for optim= 0.11438583737860124\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.003241586033254862\n",
      "Loss on test= 0.00460852449759841\n",
      "acc for Lsat= 0.09099792616648807 \n",
      "acc for Psat= 0.11147142770803636 \n",
      "acc for optim= 0.13543719674150148\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.0033098391722887754\n",
      "Loss on test= 0.004624685272574425\n",
      "acc for Lsat= 0.1046184563698868 \n",
      "acc for Psat= 0.11730873351916671 \n",
      "acc for optim= 0.10441117971721622\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.003183189546689391\n",
      "Loss on test= 0.004773709923028946\n",
      "acc for Lsat= 0.10251479699379867 \n",
      "acc for Psat= 0.10052212697014005 \n",
      "acc for optim= 0.1329580343121456\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.0032389620319008827\n",
      "Loss on test= 0.004340738523751497\n",
      "acc for Lsat= 0.10507535251478355 \n",
      "acc for Psat= 0.17395235063223582 \n",
      "acc for optim= 0.09948888312404354\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.00313828163780272\n",
      "Loss on test= 0.004228717647492886\n",
      "acc for Lsat= 0.08441876708012488 \n",
      "acc for Psat= 0.12389861616409487 \n",
      "acc for optim= 0.12067177881383234\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.0032867600675672293\n",
      "Loss on test= 0.004568209405988455\n",
      "acc for Lsat= 0.11920303478837013 \n",
      "acc for Psat= 0.16373347832510868 \n",
      "acc for optim= 0.12906983150039902\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.003245634026825428\n",
      "Loss on test= 0.004560374654829502\n",
      "acc for Lsat= 0.11362852445907062 \n",
      "acc for Psat= 0.13994905311200354 \n",
      "acc for optim= 0.14002548722136351\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.0031718893442302942\n",
      "Loss on test= 0.00456777960062027\n",
      "acc for Lsat= 0.0803930028859112 \n",
      "acc for Psat= 0.15302223629421657 \n",
      "acc for optim= 0.14285554428028668\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.0033232830464839935\n",
      "Loss on test= 0.004698720294982195\n",
      "acc for Lsat= 0.08341389677176873 \n",
      "acc for Psat= 0.11969570559449494 \n",
      "acc for optim= 0.14223431666485137\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.003230252768844366\n",
      "Loss on test= 0.004582768306136131\n",
      "acc for Lsat= 0.11449442255414194 \n",
      "acc for Psat= 0.16143677507837614 \n",
      "acc for optim= 0.11670718207541439\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.003181249601766467\n",
      "Loss on test= 0.004633677192032337\n",
      "acc for Lsat= 0.07706414639121956 \n",
      "acc for Psat= 0.09320848775354938 \n",
      "acc for optim= 0.12626963183801207\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.0031080313492566347\n",
      "Loss on test= 0.0048264022916555405\n",
      "acc for Lsat= 0.10392624875142549 \n",
      "acc for Psat= 0.12582436193285199 \n",
      "acc for optim= 0.12274052694232927\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.0032120072282850742\n",
      "Loss on test= 0.004370409529656172\n",
      "acc for Lsat= 0.1676807819555203 \n",
      "acc for Psat= 0.13525656051933765 \n",
      "acc for optim= 0.1241046456206176\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.0032712980173528194\n",
      "Loss on test= 0.004494894295930862\n",
      "acc for Lsat= 0.12835341412574053 \n",
      "acc for Psat= 0.1400577250557641 \n",
      "acc for optim= 0.1164108511681358\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.003233075374737382\n",
      "Loss on test= 0.004868811462074518\n",
      "acc for Lsat= 0.08575789376886354 \n",
      "acc for Psat= 0.12349149610640274 \n",
      "acc for optim= 0.16713528469618824\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.0032277859281748533\n",
      "Loss on test= 0.0044685592874884605\n",
      "acc for Lsat= 0.11727499871307777 \n",
      "acc for Psat= 0.13087176500509182 \n",
      "acc for optim= 0.12607469982079542\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.0032208063639700413\n",
      "Loss on test= 0.004486067220568657\n",
      "acc for Lsat= 0.09209019654533929 \n",
      "acc for Psat= 0.15121512202959922 \n",
      "acc for optim= 0.1033246461302042\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.003206482622772455\n",
      "Loss on test= 0.004564028233289719\n",
      "acc for Lsat= 0.09748561130577905 \n",
      "acc for Psat= 0.13107008931951392 \n",
      "acc for optim= 0.14657221672435602\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.0032482699025422335\n",
      "Loss on test= 0.0046479180455207825\n",
      "acc for Lsat= 0.10844780121826464 \n",
      "acc for Psat= 0.16944860780818594 \n",
      "acc for optim= 0.12507446218902865\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.0032055715564638376\n",
      "Loss on test= 0.004611921962350607\n",
      "acc for Lsat= 0.10897166033585866 \n",
      "acc for Psat= 0.09702792142747461 \n",
      "acc for optim= 0.11016885752582715\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.003255861345678568\n",
      "Loss on test= 0.0044669341295957565\n",
      "acc for Lsat= 0.09021058115306207 \n",
      "acc for Psat= 0.10312071908265352 \n",
      "acc for optim= 0.10631756463812457\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.003428699215874076\n",
      "Loss on test= 0.004458163399249315\n",
      "acc for Lsat= 0.11299417323122422 \n",
      "acc for Psat= 0.12781774507473326 \n",
      "acc for optim= 0.14652203540835115\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.0032793795689940453\n",
      "Loss on test= 0.0047159562818706036\n",
      "acc for Lsat= 0.1172289281255669 \n",
      "acc for Psat= 0.11606569442018452 \n",
      "acc for optim= 0.1605719372423159\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.0031661465764045715\n",
      "Loss on test= 0.0046688588336110115\n",
      "acc for Lsat= 0.10534557544936736 \n",
      "acc for Psat= 0.10967745088661711 \n",
      "acc for optim= 0.10397242146751119\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.003186351852491498\n",
      "Loss on test= 0.004454233683645725\n",
      "acc for Lsat= 0.11284055470282005 \n",
      "acc for Psat= 0.14698617760505941 \n",
      "acc for optim= 0.1319029229020493\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.0031603267416357994\n",
      "Loss on test= 0.004735374823212624\n",
      "acc for Lsat= 0.13648124903233516 \n",
      "acc for Psat= 0.16659945323287198 \n",
      "acc for optim= 0.12655456653899616\n",
      "Fold 4\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.08422791212797165\n",
      "Loss on test= 0.033582281321287155\n",
      "acc for Lsat= 0.48497122557212907 \n",
      "acc for Psat= 0.46662940705815953 \n",
      "acc for optim= 0.276856345228023\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.03262672945857048\n",
      "Loss on test= 0.02692803554236889\n",
      "acc for Lsat= 0.45846296374737805 \n",
      "acc for Psat= 0.6480768255682455 \n",
      "acc for optim= 0.2691043465294772\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.026408355683088303\n",
      "Loss on test= 0.023169053718447685\n",
      "acc for Lsat= 0.41154894863979685 \n",
      "acc for Psat= 0.5946750748488638 \n",
      "acc for optim= 0.277342543264644\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.023670261725783348\n",
      "Loss on test= 0.021458052098751068\n",
      "acc for Lsat= 0.6072072121832106 \n",
      "acc for Psat= 0.8696381287235353 \n",
      "acc for optim= 0.2755910839057631\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.021682897582650185\n",
      "Loss on test= 0.023556988686323166\n",
      "acc for Lsat= 0.49028787658446366 \n",
      "acc for Psat= 0.5278573296964169 \n",
      "acc for optim= 0.24299122439697385\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.021105647087097168\n",
      "Loss on test= 0.020476067438721657\n",
      "acc for Lsat= 0.3405211993182699 \n",
      "acc for Psat= 0.6921034056124173 \n",
      "acc for optim= 0.27951525270731914\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.021072905510663986\n",
      "Loss on test= 0.0205239225178957\n",
      "acc for Lsat= 0.5018320257465044 \n",
      "acc for Psat= 0.9378673136234283 \n",
      "acc for optim= 0.2828171987138275\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.019975580275058746\n",
      "Loss on test= 0.0197399090975523\n",
      "acc for Lsat= 0.4478533336271842 \n",
      "acc for Psat= 0.7820756035960383 \n",
      "acc for optim= 0.27255116087488\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.019294515252113342\n",
      "Loss on test= 0.01805771142244339\n",
      "acc for Lsat= 0.4529827373723189 \n",
      "acc for Psat= 0.5713783575014936 \n",
      "acc for optim= 0.22018587806572518\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.018484914675354958\n",
      "Loss on test= 0.017932765185832977\n",
      "acc for Lsat= 0.45980893737739986 \n",
      "acc for Psat= 0.5314782630238268 \n",
      "acc for optim= 0.26651995520417887\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.01747419685125351\n",
      "Loss on test= 0.018509652465581894\n",
      "acc for Lsat= 0.627845198329952 \n",
      "acc for Psat= 0.6141327230466737 \n",
      "acc for optim= 0.20820802619629022\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.017480719834566116\n",
      "Loss on test= 0.018109992146492004\n",
      "acc for Lsat= 0.36978407721552586 \n",
      "acc for Psat= 0.695341980136517 \n",
      "acc for optim= 0.17694871210389668\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.017565064132213593\n",
      "Loss on test= 0.016735099256038666\n",
      "acc for Lsat= 0.4159437164457308 \n",
      "acc for Psat= 0.5753027488374047 \n",
      "acc for optim= 0.2156254492227971\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.01753975823521614\n",
      "Loss on test= 0.016359740868210793\n",
      "acc for Lsat= 0.38685090881254935 \n",
      "acc for Psat= 0.4916391169859303 \n",
      "acc for optim= 0.2504570028848118\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.01647225022315979\n",
      "Loss on test= 0.01671501249074936\n",
      "acc for Lsat= 0.3186293188029797 \n",
      "acc for Psat= 0.6215438782496171 \n",
      "acc for optim= 0.1765365635122483\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.01634885184466839\n",
      "Loss on test= 0.01826600730419159\n",
      "acc for Lsat= 0.4504990517679188 \n",
      "acc for Psat= 0.7021372533506818 \n",
      "acc for optim= 0.17973381663776106\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.015829160809516907\n",
      "Loss on test= 0.015473672188818455\n",
      "acc for Lsat= 0.387042903716469 \n",
      "acc for Psat= 0.6409461452729173 \n",
      "acc for optim= 0.19272298055390516\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.01586097665131092\n",
      "Loss on test= 0.016192667186260223\n",
      "acc for Lsat= 0.3389668456899623 \n",
      "acc for Psat= 0.5297874193638563 \n",
      "acc for optim= 0.20654488815408614\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.015719735994935036\n",
      "Loss on test= 0.016784382984042168\n",
      "acc for Lsat= 0.2829709596828454 \n",
      "acc for Psat= 0.5756995795915524 \n",
      "acc for optim= 0.1629749055330952\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.015926241874694824\n",
      "Loss on test= 0.015652570873498917\n",
      "acc for Lsat= 0.3338877140647835 \n",
      "acc for Psat= 0.47124780900776386 \n",
      "acc for optim= 0.16896429980341862\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.016067875549197197\n",
      "Loss on test= 0.015029311180114746\n",
      "acc for Lsat= 0.3997033186412106 \n",
      "acc for Psat= 0.5142618872018324 \n",
      "acc for optim= 0.20239357138052583\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.014585088938474655\n",
      "Loss on test= 0.015060300938785076\n",
      "acc for Lsat= 0.3547630583246549 \n",
      "acc for Psat= 0.6589496468918191 \n",
      "acc for optim= 0.17571705931590664\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.015322472900152206\n",
      "Loss on test= 0.015898508951067924\n",
      "acc for Lsat= 0.32504545162535375 \n",
      "acc for Psat= 0.503062154373361 \n",
      "acc for optim= 0.15384475785120028\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.014844704419374466\n",
      "Loss on test= 0.014690318144857883\n",
      "acc for Lsat= 0.38809145421772784 \n",
      "acc for Psat= 0.5978686403897073 \n",
      "acc for optim= 0.20393208797193235\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.0143897645175457\n",
      "Loss on test= 0.015608012676239014\n",
      "acc for Lsat= 0.34063121065911317 \n",
      "acc for Psat= 0.5038122576144006 \n",
      "acc for optim= 0.20188770101716122\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.014741909690201283\n",
      "Loss on test= 0.01661071926355362\n",
      "acc for Lsat= 0.40526217470566434 \n",
      "acc for Psat= 0.47613984739614856 \n",
      "acc for optim= 0.18768668257527882\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.014388241805136204\n",
      "Loss on test= 0.015152143314480782\n",
      "acc for Lsat= 0.47252234319845837 \n",
      "acc for Psat= 0.553187677067601 \n",
      "acc for optim= 0.18561952876754934\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.014300771988928318\n",
      "Loss on test= 0.01505845133215189\n",
      "acc for Lsat= 0.30496392872494954 \n",
      "acc for Psat= 0.4345573814999726 \n",
      "acc for optim= 0.19185333737793067\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.01419529877603054\n",
      "Loss on test= 0.014154192060232162\n",
      "acc for Lsat= 0.41658892430779004 \n",
      "acc for Psat= 0.3753168767822596 \n",
      "acc for optim= 0.21645816881209612\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.013815101236104965\n",
      "Loss on test= 0.0159942377358675\n",
      "acc for Lsat= 0.25700118967021507 \n",
      "acc for Psat= 0.5477459170959063 \n",
      "acc for optim= 0.2090841017715219\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.014066330157220364\n",
      "Loss on test= 0.015173809602856636\n",
      "acc for Lsat= 0.330032003894707 \n",
      "acc for Psat= 0.48761514607920414 \n",
      "acc for optim= 0.2057965004609691\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.013466542586684227\n",
      "Loss on test= 0.013688519597053528\n",
      "acc for Lsat= 0.4711846543165545 \n",
      "acc for Psat= 0.6745093874633312 \n",
      "acc for optim= 0.24205677896841532\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.013269882649183273\n",
      "Loss on test= 0.013772491365671158\n",
      "acc for Lsat= 0.41277542984527016 \n",
      "acc for Psat= 0.6025135624739859 \n",
      "acc for optim= 0.1434900440904635\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.013952464796602726\n",
      "Loss on test= 0.01469200849533081\n",
      "acc for Lsat= 0.27904997238268453 \n",
      "acc for Psat= 0.6239725781811608 \n",
      "acc for optim= 0.1764279148644871\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.013910621404647827\n",
      "Loss on test= 0.013959459029138088\n",
      "acc for Lsat= 0.2918340227463179 \n",
      "acc for Psat= 0.3814527751463983 \n",
      "acc for optim= 0.20669897769888243\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.014247887767851353\n",
      "Loss on test= 0.015170987695455551\n",
      "acc for Lsat= 0.28185533866700196 \n",
      "acc for Psat= 0.3466635279667874 \n",
      "acc for optim= 0.15811474724776214\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.013291943818330765\n",
      "Loss on test= 0.013768387027084827\n",
      "acc for Lsat= 0.48508355487138033 \n",
      "acc for Psat= 0.4466509144339297 \n",
      "acc for optim= 0.20540818137427172\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.013193631544709206\n",
      "Loss on test= 0.01338107604533434\n",
      "acc for Lsat= 0.25720078208380276 \n",
      "acc for Psat= 0.4996992110197122 \n",
      "acc for optim= 0.17864486396623155\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.013098317198455334\n",
      "Loss on test= 0.014568145386874676\n",
      "acc for Lsat= 0.32718740093211335 \n",
      "acc for Psat= 0.5823827852727845 \n",
      "acc for optim= 0.2570119731956058\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.013338237069547176\n",
      "Loss on test= 0.012977688573300838\n",
      "acc for Lsat= 0.3478796393610537 \n",
      "acc for Psat= 0.506497674725122 \n",
      "acc for optim= 0.2107017619224886\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.012794962152838707\n",
      "Loss on test= 0.01243103388696909\n",
      "acc for Lsat= 0.3573664219843017 \n",
      "acc for Psat= 0.40023583986072075 \n",
      "acc for optim= 0.19272811048560673\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.012536495923995972\n",
      "Loss on test= 0.01322112139314413\n",
      "acc for Lsat= 0.2796955265932613 \n",
      "acc for Psat= 0.3787547250588735 \n",
      "acc for optim= 0.2070498039635519\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.0127219557762146\n",
      "Loss on test= 0.01331606786698103\n",
      "acc for Lsat= 0.41514137925373185 \n",
      "acc for Psat= 0.48551103307141197 \n",
      "acc for optim= 0.1862109591667023\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.01258747186511755\n",
      "Loss on test= 0.013423209078609943\n",
      "acc for Lsat= 0.37358107086684966 \n",
      "acc for Psat= 0.4803734279703349 \n",
      "acc for optim= 0.17952466079603052\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.012625491246581078\n",
      "Loss on test= 0.013791097328066826\n",
      "acc for Lsat= 0.33537931595411563 \n",
      "acc for Psat= 0.37996560105481575 \n",
      "acc for optim= 0.15846316971955174\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.012080559507012367\n",
      "Loss on test= 0.012389621697366238\n",
      "acc for Lsat= 0.2787850631607903 \n",
      "acc for Psat= 0.28873307366545004 \n",
      "acc for optim= 0.16887009190395474\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.012337052263319492\n",
      "Loss on test= 0.01355063822120428\n",
      "acc for Lsat= 0.3998551484481949 \n",
      "acc for Psat= 0.45969475236617857 \n",
      "acc for optim= 0.2286129074378146\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.012439969927072525\n",
      "Loss on test= 0.013222443871200085\n",
      "acc for Lsat= 0.4068499445501301 \n",
      "acc for Psat= 0.39763405443065697 \n",
      "acc for optim= 0.18894671413323116\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.012722284533083439\n",
      "Loss on test= 0.011520822532474995\n",
      "acc for Lsat= 0.3121071114308304 \n",
      "acc for Psat= 0.5065098731882043 \n",
      "acc for optim= 0.21192974431647194\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.012593597173690796\n",
      "Loss on test= 0.01296935137361288\n",
      "acc for Lsat= 0.34413299585382146 \n",
      "acc for Psat= 0.4067145132770141 \n",
      "acc for optim= 0.17932441654718584\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.012128451839089394\n",
      "Loss on test= 0.013100806623697281\n",
      "acc for Lsat= 0.22677111335926586 \n",
      "acc for Psat= 0.3603103492512471 \n",
      "acc for optim= 0.22225713497027755\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.012623718939721584\n",
      "Loss on test= 0.012299676425755024\n",
      "acc for Lsat= 0.28256924147717655 \n",
      "acc for Psat= 0.26078078378729214 \n",
      "acc for optim= 0.18722918793921256\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.011956271715462208\n",
      "Loss on test= 0.012101881206035614\n",
      "acc for Lsat= 0.35583124304604197 \n",
      "acc for Psat= 0.39347318537895465 \n",
      "acc for optim= 0.17930931390987503\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.011967402882874012\n",
      "Loss on test= 0.011998598463833332\n",
      "acc for Lsat= 0.23831800412800577 \n",
      "acc for Psat= 0.3891615226295673 \n",
      "acc for optim= 0.18754294770769775\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.011760256253182888\n",
      "Loss on test= 0.012489903718233109\n",
      "acc for Lsat= 0.3222082228037632 \n",
      "acc for Psat= 0.3537493356400066 \n",
      "acc for optim= 0.2085658481810242\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.012017923407256603\n",
      "Loss on test= 0.012446281500160694\n",
      "acc for Lsat= 0.3911134809669521 \n",
      "acc for Psat= 0.38685468879217905 \n",
      "acc for optim= 0.17632074441967738\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.01151979062706232\n",
      "Loss on test= 0.012739207595586777\n",
      "acc for Lsat= 0.32188989998151857 \n",
      "acc for Psat= 0.35612381042705643 \n",
      "acc for optim= 0.1919433277928167\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.011811836622655392\n",
      "Loss on test= 0.01338797528296709\n",
      "acc for Lsat= 0.2633160274061892 \n",
      "acc for Psat= 0.5196659945779376 \n",
      "acc for optim= 0.18973624292347166\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.011731859296560287\n",
      "Loss on test= 0.012050636112689972\n",
      "acc for Lsat= 0.46664423164394164 \n",
      "acc for Psat= 0.29891367794738877 \n",
      "acc for optim= 0.19659527983619934\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.011747341603040695\n",
      "Loss on test= 0.011841459199786186\n",
      "acc for Lsat= 0.411296381511622 \n",
      "acc for Psat= 0.47142710805767113 \n",
      "acc for optim= 0.1824581968701548\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.012177583761513233\n",
      "Loss on test= 0.011458330787718296\n",
      "acc for Lsat= 0.2744192722926123 \n",
      "acc for Psat= 0.33746626548882985 \n",
      "acc for optim= 0.18835974886961696\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.011901586316525936\n",
      "Loss on test= 0.011926750652492046\n",
      "acc for Lsat= 0.2378144615019361 \n",
      "acc for Psat= 0.41273311163402265 \n",
      "acc for optim= 0.21326309877137342\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.0122093940153718\n",
      "Loss on test= 0.012000411748886108\n",
      "acc for Lsat= 0.3526780912652612 \n",
      "acc for Psat= 0.3615689693639676 \n",
      "acc for optim= 0.15438068182104164\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.011640028096735477\n",
      "Loss on test= 0.011476189829409122\n",
      "acc for Lsat= 0.3689010617801816 \n",
      "acc for Psat= 0.2987766807459088 \n",
      "acc for optim= 0.18275019706278625\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.011544063687324524\n",
      "Loss on test= 0.011712092906236649\n",
      "acc for Lsat= 0.2874485747888684 \n",
      "acc for Psat= 0.4155065073735184 \n",
      "acc for optim= 0.16534120228607208\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.011437708511948586\n",
      "Loss on test= 0.01179580669850111\n",
      "acc for Lsat= 0.2459605565915505 \n",
      "acc for Psat= 0.3228406231953866 \n",
      "acc for optim= 0.1629418147365666\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.011100588366389275\n",
      "Loss on test= 0.011623910628259182\n",
      "acc for Lsat= 0.2850852666629685 \n",
      "acc for Psat= 0.31596012734290624 \n",
      "acc for optim= 0.16525390286309025\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.010961731895804405\n",
      "Loss on test= 0.012871918268501759\n",
      "acc for Lsat= 0.42313613059620064 \n",
      "acc for Psat= 0.4787919881443183 \n",
      "acc for optim= 0.16364315016350398\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.01130730751901865\n",
      "Loss on test= 0.012300687842071056\n",
      "acc for Lsat= 0.3902825026048554 \n",
      "acc for Psat= 0.3755583314794219 \n",
      "acc for optim= 0.15893306769430637\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.01147253904491663\n",
      "Loss on test= 0.011711935512721539\n",
      "acc for Lsat= 0.3588428021305137 \n",
      "acc for Psat= 0.39381307715343106 \n",
      "acc for optim= 0.17950192877065596\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.011184348724782467\n",
      "Loss on test= 0.011406468227505684\n",
      "acc for Lsat= 0.3778598901246571 \n",
      "acc for Psat= 0.5211137353132168 \n",
      "acc for optim= 0.18998773328752983\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.011229069903492928\n",
      "Loss on test= 0.011693622916936874\n",
      "acc for Lsat= 0.3153042233445578 \n",
      "acc for Psat= 0.45575978317194515 \n",
      "acc for optim= 0.18874638015404344\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.011545922607183456\n",
      "Loss on test= 0.011539831757545471\n",
      "acc for Lsat= 0.35393878838254345 \n",
      "acc for Psat= 0.3396043713049342 \n",
      "acc for optim= 0.18006946006789804\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.01107237208634615\n",
      "Loss on test= 0.010340757668018341\n",
      "acc for Lsat= 0.433528380559033 \n",
      "acc for Psat= 0.3441354708953036 \n",
      "acc for optim= 0.18547794760929215\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.010774459689855576\n",
      "Loss on test= 0.011806493625044823\n",
      "acc for Lsat= 0.34722456253237194 \n",
      "acc for Psat= 0.378440376992027 \n",
      "acc for optim= 0.17578838020563126\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.01093614473938942\n",
      "Loss on test= 0.01138530857861042\n",
      "acc for Lsat= 0.3217546213547596 \n",
      "acc for Psat= 0.3606132486990343 \n",
      "acc for optim= 0.18480715942051676\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.01067870482802391\n",
      "Loss on test= 0.011612346395850182\n",
      "acc for Lsat= 0.3803118057549 \n",
      "acc for Psat= 0.28013188640276593 \n",
      "acc for optim= 0.1978982071030057\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.010582209564745426\n",
      "Loss on test= 0.011615057475864887\n",
      "acc for Lsat= 0.3644215166568756 \n",
      "acc for Psat= 0.3938285544928577 \n",
      "acc for optim= 0.21360660618585017\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.010673745535314083\n",
      "Loss on test= 0.011604096740484238\n",
      "acc for Lsat= 0.33193708087007207 \n",
      "acc for Psat= 0.31963382930391365 \n",
      "acc for optim= 0.19121929631930673\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.010577171109616756\n",
      "Loss on test= 0.01099373959004879\n",
      "acc for Lsat= 0.2989574612842666 \n",
      "acc for Psat= 0.32718714844021535 \n",
      "acc for optim= 0.1827887190091941\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.010890473611652851\n",
      "Loss on test= 0.012289239093661308\n",
      "acc for Lsat= 0.27209140670796234 \n",
      "acc for Psat= 0.5856397174712684 \n",
      "acc for optim= 0.21004266809258196\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.010798470117151737\n",
      "Loss on test= 0.0111719761043787\n",
      "acc for Lsat= 0.33912103954288697 \n",
      "acc for Psat= 0.4748879431022538 \n",
      "acc for optim= 0.16563316507058012\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.01080944761633873\n",
      "Loss on test= 0.01074639055877924\n",
      "acc for Lsat= 0.3822888794044654 \n",
      "acc for Psat= 0.3387912122739686 \n",
      "acc for optim= 0.17486588346461454\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.010604148730635643\n",
      "Loss on test= 0.011466654017567635\n",
      "acc for Lsat= 0.36580898447169197 \n",
      "acc for Psat= 0.29376941025030745 \n",
      "acc for optim= 0.19174838591263527\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.010636135935783386\n",
      "Loss on test= 0.011711778119206429\n",
      "acc for Lsat= 0.3556003572626246 \n",
      "acc for Psat= 0.3695288473002923 \n",
      "acc for optim= 0.19070535691248047\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.01063102949410677\n",
      "Loss on test= 0.010872874408960342\n",
      "acc for Lsat= 0.298774733622041 \n",
      "acc for Psat= 0.3928192993108597 \n",
      "acc for optim= 0.1824672981682751\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.010593765415251255\n",
      "Loss on test= 0.011364736594259739\n",
      "acc for Lsat= 0.29031591386430794 \n",
      "acc for Psat= 0.2430441150855687 \n",
      "acc for optim= 0.17858587396848533\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.010284953750669956\n",
      "Loss on test= 0.010992173105478287\n",
      "acc for Lsat= 0.2787231102378832 \n",
      "acc for Psat= 0.36876698045267 \n",
      "acc for optim= 0.16993906982760462\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.010472644120454788\n",
      "Loss on test= 0.010919751599431038\n",
      "acc for Lsat= 0.3139478406972355 \n",
      "acc for Psat= 0.2471437682915065 \n",
      "acc for optim= 0.18001699478675923\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.010445009917020798\n",
      "Loss on test= 0.01177956536412239\n",
      "acc for Lsat= 0.3577375088094009 \n",
      "acc for Psat= 0.2910337716522109 \n",
      "acc for optim= 0.18823867534390754\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.01006876491010189\n",
      "Loss on test= 0.011574272997677326\n",
      "acc for Lsat= 0.36518076057028437 \n",
      "acc for Psat= 0.41254317201673985 \n",
      "acc for optim= 0.2002344894895537\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.010129239410161972\n",
      "Loss on test= 0.012224423699080944\n",
      "acc for Lsat= 0.3028939254581928 \n",
      "acc for Psat= 0.45047790536450016 \n",
      "acc for optim= 0.17185349317474496\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.01053755171597004\n",
      "Loss on test= 0.0105285057798028\n",
      "acc for Lsat= 0.2641857614637249 \n",
      "acc for Psat= 0.34824056261115605 \n",
      "acc for optim= 0.1833012388087809\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.010329069569706917\n",
      "Loss on test= 0.010174545459449291\n",
      "acc for Lsat= 0.2898296962181727 \n",
      "acc for Psat= 0.33135015993482536 \n",
      "acc for optim= 0.1978504499549874\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.01009537186473608\n",
      "Loss on test= 0.010849974118173122\n",
      "acc for Lsat= 0.33626951028903324 \n",
      "acc for Psat= 0.38375962070292896 \n",
      "acc for optim= 0.20427770540118217\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.010759680531919003\n",
      "Loss on test= 0.010886861011385918\n",
      "acc for Lsat= 0.3181608563496007 \n",
      "acc for Psat= 0.2996618307499577 \n",
      "acc for optim= 0.1864902833282637\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.01047560665756464\n",
      "Loss on test= 0.011084564961493015\n",
      "acc for Lsat= 0.26508940463989145 \n",
      "acc for Psat= 0.43150221343320383 \n",
      "acc for optim= 0.1968737623343865\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.01033526100218296\n",
      "Loss on test= 0.011201538145542145\n",
      "acc for Lsat= 0.3207519104083379 \n",
      "acc for Psat= 0.3300392451799578 \n",
      "acc for optim= 0.1777475735741771\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.0103585384786129\n",
      "Loss on test= 0.010557498782873154\n",
      "acc for Lsat= 0.3324524197313521 \n",
      "acc for Psat= 0.3495228418873416 \n",
      "acc for optim= 0.20335149273483288\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.010368499904870987\n",
      "Loss on test= 0.011063522659242153\n",
      "acc for Lsat= 0.3531862505608135 \n",
      "acc for Psat= 0.31352329197236234 \n",
      "acc for optim= 0.1771456300177508\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.010142139159142971\n",
      "Loss on test= 0.011024304665625095\n",
      "acc for Lsat= 0.26226996319989365 \n",
      "acc for Psat= 0.3544852963338296 \n",
      "acc for optim= 0.19429219756178404\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.010058610700070858\n",
      "Loss on test= 0.01039245817810297\n",
      "acc for Lsat= 0.28392223733115113 \n",
      "acc for Psat= 0.3380909842025075 \n",
      "acc for optim= 0.18085815219415557\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.010097973980009556\n",
      "Loss on test= 0.011029192246496677\n",
      "acc for Lsat= 0.31982212648209596 \n",
      "acc for Psat= 0.29609974085663754 \n",
      "acc for optim= 0.2198570026602182\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.010236021131277084\n",
      "Loss on test= 0.010662081651389599\n",
      "acc for Lsat= 0.3747349898848269 \n",
      "acc for Psat= 0.37154664585573804 \n",
      "acc for optim= 0.1847520193292035\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.010123984888195992\n",
      "Loss on test= 0.010619924403727055\n",
      "acc for Lsat= 0.2932798475699706 \n",
      "acc for Psat= 0.29096632942350376 \n",
      "acc for optim= 0.1650879248045385\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.009924783371388912\n",
      "Loss on test= 0.010762441903352737\n",
      "acc for Lsat= 0.3549008041025243 \n",
      "acc for Psat= 0.3415642311382625 \n",
      "acc for optim= 0.1918820585641596\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.009961421601474285\n",
      "Loss on test= 0.010650478303432465\n",
      "acc for Lsat= 0.31987641306800974 \n",
      "acc for Psat= 0.37587349354806876 \n",
      "acc for optim= 0.1718387304701739\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.010033817030489445\n",
      "Loss on test= 0.010406432673335075\n",
      "acc for Lsat= 0.3330195855556263 \n",
      "acc for Psat= 0.3055961312105258 \n",
      "acc for optim= 0.21009691494206587\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.010116608813405037\n",
      "Loss on test= 0.010785208083689213\n",
      "acc for Lsat= 0.36781592749887043 \n",
      "acc for Psat= 0.25775131072926644 \n",
      "acc for optim= 0.15100955052508247\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.009914861060678959\n",
      "Loss on test= 0.01057579554617405\n",
      "acc for Lsat= 0.3310847021639347 \n",
      "acc for Psat= 0.2784928267614709 \n",
      "acc for optim= 0.19521732442080975\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.010066024959087372\n",
      "Loss on test= 0.010727706365287304\n",
      "acc for Lsat= 0.34449209169381195 \n",
      "acc for Psat= 0.4007526909311612 \n",
      "acc for optim= 0.18767328932881355\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.010267099365592003\n",
      "Loss on test= 0.010959049686789513\n",
      "acc for Lsat= 0.3423087840071983 \n",
      "acc for Psat= 0.44535290594730115 \n",
      "acc for optim= 0.20037303937392104\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.009981208480894566\n",
      "Loss on test= 0.010169962421059608\n",
      "acc for Lsat= 0.4250280982814729 \n",
      "acc for Psat= 0.34441599518888527 \n",
      "acc for optim= 0.1874786012340337\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.009551718831062317\n",
      "Loss on test= 0.010962596163153648\n",
      "acc for Lsat= 0.44071193411946297 \n",
      "acc for Psat= 0.3472924340102408 \n",
      "acc for optim= 0.18826225337882838\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.009584270417690277\n",
      "Loss on test= 0.011487205512821674\n",
      "acc for Lsat= 0.24309039568632013 \n",
      "acc for Psat= 0.2733676333187355 \n",
      "acc for optim= 0.182551566666613\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.010029605589807034\n",
      "Loss on test= 0.011000718921422958\n",
      "acc for Lsat= 0.3606162820425298 \n",
      "acc for Psat= 0.40183874416268534 \n",
      "acc for optim= 0.1881159183362292\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.009420137852430344\n",
      "Loss on test= 0.010145362466573715\n",
      "acc for Lsat= 0.38473307713866234 \n",
      "acc for Psat= 0.25700470836212236 \n",
      "acc for optim= 0.17961229722843403\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.010139131918549538\n",
      "Loss on test= 0.00968105997890234\n",
      "acc for Lsat= 0.31930019292566514 \n",
      "acc for Psat= 0.264383089935614 \n",
      "acc for optim= 0.15731358965341416\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.009453040547668934\n",
      "Loss on test= 0.009892968460917473\n",
      "acc for Lsat= 0.34186808376883465 \n",
      "acc for Psat= 0.3173302647709433 \n",
      "acc for optim= 0.17796086271603903\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.009328633546829224\n",
      "Loss on test= 0.010461235418915749\n",
      "acc for Lsat= 0.3101601139900999 \n",
      "acc for Psat= 0.3538950741187566 \n",
      "acc for optim= 0.17026941711083055\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.009571900591254234\n",
      "Loss on test= 0.010993406176567078\n",
      "acc for Lsat= 0.27729878119296497 \n",
      "acc for Psat= 0.2547912825312879 \n",
      "acc for optim= 0.16044487070111144\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.009369760751724243\n",
      "Loss on test= 0.010567212477326393\n",
      "acc for Lsat= 0.3382760776827733 \n",
      "acc for Psat= 0.29329959365228814 \n",
      "acc for optim= 0.18140418643856215\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.009198368526995182\n",
      "Loss on test= 0.00974954478442669\n",
      "acc for Lsat= 0.3304981378217538 \n",
      "acc for Psat= 0.32025475634468925 \n",
      "acc for optim= 0.20621939189732075\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.00956556387245655\n",
      "Loss on test= 0.010330471210181713\n",
      "acc for Lsat= 0.26703108068452114 \n",
      "acc for Psat= 0.30184693536203766 \n",
      "acc for optim= 0.17210150212566885\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.009225703775882721\n",
      "Loss on test= 0.010647905990481377\n",
      "acc for Lsat= 0.39154838724061847 \n",
      "acc for Psat= 0.3351247011580401 \n",
      "acc for optim= 0.20319911886730957\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.009511824697256088\n",
      "Loss on test= 0.010067577473819256\n",
      "acc for Lsat= 0.2935229148198333 \n",
      "acc for Psat= 0.35696820040336913 \n",
      "acc for optim= 0.2128348257392645\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.00930487085133791\n",
      "Loss on test= 0.010358843952417374\n",
      "acc for Lsat= 0.39952375408675933 \n",
      "acc for Psat= 0.3060963741607136 \n",
      "acc for optim= 0.19698299219210944\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.009186173789203167\n",
      "Loss on test= 0.010219202376902103\n",
      "acc for Lsat= 0.3159540461169349 \n",
      "acc for Psat= 0.32225253702037865 \n",
      "acc for optim= 0.18019660824858066\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.009373142383992672\n",
      "Loss on test= 0.009744605049490929\n",
      "acc for Lsat= 0.3712025298219588 \n",
      "acc for Psat= 0.194523280305374 \n",
      "acc for optim= 0.1881564264703128\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.009416954591870308\n",
      "Loss on test= 0.009798345156013966\n",
      "acc for Lsat= 0.2937090216178654 \n",
      "acc for Psat= 0.4106962639424536 \n",
      "acc for optim= 0.18423062531898418\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.009426661767065525\n",
      "Loss on test= 0.009863153100013733\n",
      "acc for Lsat= 0.3096431742111842 \n",
      "acc for Psat= 0.25975309785765904 \n",
      "acc for optim= 0.1876084536520971\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.009573820978403091\n",
      "Loss on test= 0.010213368572294712\n",
      "acc for Lsat= 0.23561560595408082 \n",
      "acc for Psat= 0.2929274528804753 \n",
      "acc for optim= 0.2005185270940678\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.009221329353749752\n",
      "Loss on test= 0.010401501320302486\n",
      "acc for Lsat= 0.29160322952601647 \n",
      "acc for Psat= 0.3822809038780785 \n",
      "acc for optim= 0.18180275088848752\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.00893938448280096\n",
      "Loss on test= 0.010275627486407757\n",
      "acc for Lsat= 0.353044371586293 \n",
      "acc for Psat= 0.37616974156763816 \n",
      "acc for optim= 0.18293133284896612\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.00902481283992529\n",
      "Loss on test= 0.009460304863750935\n",
      "acc for Lsat= 0.31258032533029717 \n",
      "acc for Psat= 0.2802475670663019 \n",
      "acc for optim= 0.17695820088394815\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.009173501282930374\n",
      "Loss on test= 0.00992293655872345\n",
      "acc for Lsat= 0.3412328180339601 \n",
      "acc for Psat= 0.29165904389487374 \n",
      "acc for optim= 0.17466640482760137\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.00899860542267561\n",
      "Loss on test= 0.009688657708466053\n",
      "acc for Lsat= 0.40264758550458485 \n",
      "acc for Psat= 0.2754121060586638 \n",
      "acc for optim= 0.18095879272247353\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.00882376916706562\n",
      "Loss on test= 0.009761580266058445\n",
      "acc for Lsat= 0.29811825116889346 \n",
      "acc for Psat= 0.27398974676099086 \n",
      "acc for optim= 0.1820604962607225\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.008902955800294876\n",
      "Loss on test= 0.009446410462260246\n",
      "acc for Lsat= 0.311139651056793 \n",
      "acc for Psat= 0.2789174240703384 \n",
      "acc for optim= 0.1983497231784794\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.00888415053486824\n",
      "Loss on test= 0.009978476911783218\n",
      "acc for Lsat= 0.20717774166001213 \n",
      "acc for Psat= 0.230688986601308 \n",
      "acc for optim= 0.19086484652426508\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.008564833551645279\n",
      "Loss on test= 0.009405497461557388\n",
      "acc for Lsat= 0.31222724601522917 \n",
      "acc for Psat= 0.31271480375693905 \n",
      "acc for optim= 0.1760790013552954\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.008541854098439217\n",
      "Loss on test= 0.009600933641195297\n",
      "acc for Lsat= 0.29960094288819367 \n",
      "acc for Psat= 0.28402547631412745 \n",
      "acc for optim= 0.18934634659025404\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.009204155765473843\n",
      "Loss on test= 0.01043028011918068\n",
      "acc for Lsat= 0.3785964209172461 \n",
      "acc for Psat= 0.26812039134610033 \n",
      "acc for optim= 0.2004709562493695\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.0088558504357934\n",
      "Loss on test= 0.009042409248650074\n",
      "acc for Lsat= 0.2950019071706467 \n",
      "acc for Psat= 0.2552869740045733 \n",
      "acc for optim= 0.1910353654012498\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.008515364490449429\n",
      "Loss on test= 0.010101956315338612\n",
      "acc for Lsat= 0.29363470400373143 \n",
      "acc for Psat= 0.34511478886836106 \n",
      "acc for optim= 0.15567736113573322\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.008451112546026707\n",
      "Loss on test= 0.009686129167675972\n",
      "acc for Lsat= 0.2285824529826641 \n",
      "acc for Psat= 0.2921270862635639 \n",
      "acc for optim= 0.19908818924644342\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.00868209544569254\n",
      "Loss on test= 0.00945487804710865\n",
      "acc for Lsat= 0.31941949514051277 \n",
      "acc for Psat= 0.36651355400681496 \n",
      "acc for optim= 0.18823188175964686\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.008247912861406803\n",
      "Loss on test= 0.009580595418810844\n",
      "acc for Lsat= 0.2674421424874001 \n",
      "acc for Psat= 0.33202474812666577 \n",
      "acc for optim= 0.19963326139582527\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.008141260594129562\n",
      "Loss on test= 0.008915909565985203\n",
      "acc for Lsat= 0.2839791249069903 \n",
      "acc for Psat= 0.38279356869558495 \n",
      "acc for optim= 0.16241105345802176\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.008183465339243412\n",
      "Loss on test= 0.009031322784721851\n",
      "acc for Lsat= 0.2944256893048684 \n",
      "acc for Psat= 0.2900636384470595 \n",
      "acc for optim= 0.18911004066467285\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.008168107829988003\n",
      "Loss on test= 0.009281312115490437\n",
      "acc for Lsat= 0.293049612806903 \n",
      "acc for Psat= 0.289257750639485 \n",
      "acc for optim= 0.20950213147120345\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.008210331201553345\n",
      "Loss on test= 0.008913043886423111\n",
      "acc for Lsat= 0.25744627436829937 \n",
      "acc for Psat= 0.33203562752654153 \n",
      "acc for optim= 0.20860666792011923\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.008313619531691074\n",
      "Loss on test= 0.009624633006751537\n",
      "acc for Lsat= 0.30664078637750614 \n",
      "acc for Psat= 0.3192908831147684 \n",
      "acc for optim= 0.1539001173288044\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.007999108172953129\n",
      "Loss on test= 0.008898921310901642\n",
      "acc for Lsat= 0.32031981548708344 \n",
      "acc for Psat= 0.27032092813816333 \n",
      "acc for optim= 0.1496469709996341\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.007920301519334316\n",
      "Loss on test= 0.008687581866979599\n",
      "acc for Lsat= 0.2588990537139277 \n",
      "acc for Psat= 0.2311284449727585 \n",
      "acc for optim= 0.1826368168565548\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.007925596088171005\n",
      "Loss on test= 0.009171239100396633\n",
      "acc for Lsat= 0.22438300584649873 \n",
      "acc for Psat= 0.2492507113299022 \n",
      "acc for optim= 0.20062428899109364\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.008225313387811184\n",
      "Loss on test= 0.008918708190321922\n",
      "acc for Lsat= 0.23068694972122708 \n",
      "acc for Psat= 0.2108422671137507 \n",
      "acc for optim= 0.17137548699975014\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.007939901202917099\n",
      "Loss on test= 0.00931414682418108\n",
      "acc for Lsat= 0.2399455306844579 \n",
      "acc for Psat= 0.2934102070414358 \n",
      "acc for optim= 0.1879633030233284\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.007751156110316515\n",
      "Loss on test= 0.00900909211486578\n",
      "acc for Lsat= 0.1588560162215597 \n",
      "acc for Psat= 0.28924813494086266 \n",
      "acc for optim= 0.17397437784044692\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.007764441892504692\n",
      "Loss on test= 0.00792594626545906\n",
      "acc for Lsat= 0.16118017966962522 \n",
      "acc for Psat= 0.19581164026425946 \n",
      "acc for optim= 0.17523409052066402\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.00779001833871007\n",
      "Loss on test= 0.008809653110802174\n",
      "acc for Lsat= 0.23224779021822745 \n",
      "acc for Psat= 0.2589517460308141 \n",
      "acc for optim= 0.17549668909567925\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.007688856218010187\n",
      "Loss on test= 0.008084199391305447\n",
      "acc for Lsat= 0.29589150038858253 \n",
      "acc for Psat= 0.3397946601940526 \n",
      "acc for optim= 0.1862036487760229\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.007637349888682365\n",
      "Loss on test= 0.008755321614444256\n",
      "acc for Lsat= 0.2966160434815619 \n",
      "acc for Psat= 0.2954251223968135 \n",
      "acc for optim= 0.1723105688061979\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.007480156142264605\n",
      "Loss on test= 0.008193228393793106\n",
      "acc for Lsat= 0.24765031453635958 \n",
      "acc for Psat= 0.24082990107126534 \n",
      "acc for optim= 0.16257430951938862\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.007566203363239765\n",
      "Loss on test= 0.008777691051363945\n",
      "acc for Lsat= 0.22361491444624132 \n",
      "acc for Psat= 0.15009269521882138 \n",
      "acc for optim= 0.15894686792873675\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.007415148429572582\n",
      "Loss on test= 0.009280215948820114\n",
      "acc for Lsat= 0.2109868477823006 \n",
      "acc for Psat= 0.25527658354904914 \n",
      "acc for optim= 0.17261113743815157\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.007378784939646721\n",
      "Loss on test= 0.008885100483894348\n",
      "acc for Lsat= 0.22061024026738274 \n",
      "acc for Psat= 0.3085837973178261 \n",
      "acc for optim= 0.17557286967833838\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.007463827263563871\n",
      "Loss on test= 0.007986241951584816\n",
      "acc for Lsat= 0.25572533574369216 \n",
      "acc for Psat= 0.2840565811428759 \n",
      "acc for optim= 0.150281792661796\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.007429867517203093\n",
      "Loss on test= 0.008528478443622589\n",
      "acc for Lsat= 0.27266356881268117 \n",
      "acc for Psat= 0.23575493910660347 \n",
      "acc for optim= 0.17655439959425065\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.00740163354203105\n",
      "Loss on test= 0.008492731489241123\n",
      "acc for Lsat= 0.23311108790545 \n",
      "acc for Psat= 0.22850076642094386 \n",
      "acc for optim= 0.1601828956368586\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.0072954315692186356\n",
      "Loss on test= 0.007419731933623552\n",
      "acc for Lsat= 0.25735959873418324 \n",
      "acc for Psat= 0.258962024261968 \n",
      "acc for optim= 0.1874174350976116\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.007572907488793135\n",
      "Loss on test= 0.008230866864323616\n",
      "acc for Lsat= 0.21019540620424473 \n",
      "acc for Psat= 0.26498021609667277 \n",
      "acc for optim= 0.18446479351001066\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.007347480859607458\n",
      "Loss on test= 0.008147213608026505\n",
      "acc for Lsat= 0.23523865515987077 \n",
      "acc for Psat= 0.21073455166899496 \n",
      "acc for optim= 0.17349985124181128\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.0074895890429615974\n",
      "Loss on test= 0.008332332596182823\n",
      "acc for Lsat= 0.22207310568127367 \n",
      "acc for Psat= 0.21099241514134015 \n",
      "acc for optim= 0.18048937608384424\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.007213577628135681\n",
      "Loss on test= 0.00806055311113596\n",
      "acc for Lsat= 0.22178555176489884 \n",
      "acc for Psat= 0.28302447870373726 \n",
      "acc for optim= 0.17982908700489336\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.006986845750361681\n",
      "Loss on test= 0.007810002192854881\n",
      "acc for Lsat= 0.31427029747929836 \n",
      "acc for Psat= 0.2141134561712129 \n",
      "acc for optim= 0.18813642067834735\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.007234953809529543\n",
      "Loss on test= 0.007978469133377075\n",
      "acc for Lsat= 0.22685484629538324 \n",
      "acc for Psat= 0.2686031217518676 \n",
      "acc for optim= 0.1677099773919003\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.007033715024590492\n",
      "Loss on test= 0.008057882077991962\n",
      "acc for Lsat= 0.18906150437477562 \n",
      "acc for Psat= 0.2536977147683501 \n",
      "acc for optim= 0.18145940649426645\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.00737578421831131\n",
      "Loss on test= 0.007740192115306854\n",
      "acc for Lsat= 0.23066013927261034 \n",
      "acc for Psat= 0.23613698184878254 \n",
      "acc for optim= 0.18332432061692494\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.007170341908931732\n",
      "Loss on test= 0.007740715518593788\n",
      "acc for Lsat= 0.2138178820282014 \n",
      "acc for Psat= 0.21095445338222715 \n",
      "acc for optim= 0.16526102499725917\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.007189844269305468\n",
      "Loss on test= 0.007162194233387709\n",
      "acc for Lsat= 0.2645461081216733 \n",
      "acc for Psat= 0.2282999252072639 \n",
      "acc for optim= 0.1927223468471008\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.007142195478081703\n",
      "Loss on test= 0.007804988883435726\n",
      "acc for Lsat= 0.23498832496503988 \n",
      "acc for Psat= 0.3321375095595916 \n",
      "acc for optim= 0.16830574274839213\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.007115337532013655\n",
      "Loss on test= 0.007802225649356842\n",
      "acc for Lsat= 0.2771607045498159 \n",
      "acc for Psat= 0.23595125559303495 \n",
      "acc for optim= 0.16108500667744213\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.00696822302415967\n",
      "Loss on test= 0.007619926705956459\n",
      "acc for Lsat= 0.1763310080083708 \n",
      "acc for Psat= 0.2139012703879012 \n",
      "acc for optim= 0.1790989682906204\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.0069032590836286545\n",
      "Loss on test= 0.007433176971971989\n",
      "acc for Lsat= 0.18934855859131655 \n",
      "acc for Psat= 0.23113896467515993 \n",
      "acc for optim= 0.17166727100912896\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.006982811260968447\n",
      "Loss on test= 0.00770826218649745\n",
      "acc for Lsat= 0.23758943316837153 \n",
      "acc for Psat= 0.1754687318785323 \n",
      "acc for optim= 0.17068662387060207\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.006770358886569738\n",
      "Loss on test= 0.008432493545114994\n",
      "acc for Lsat= 0.22959446891521415 \n",
      "acc for Psat= 0.24349380993387765 \n",
      "acc for optim= 0.17085431231599715\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.006972655188292265\n",
      "Loss on test= 0.007451419252902269\n",
      "acc for Lsat= 0.2159216890318526 \n",
      "acc for Psat= 0.25636202779908973 \n",
      "acc for optim= 0.17295450624078512\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.00705595500767231\n",
      "Loss on test= 0.007675007916986942\n",
      "acc for Lsat= 0.16961341702456897 \n",
      "acc for Psat= 0.21034141977886772 \n",
      "acc for optim= 0.17551061609346005\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.007018257398158312\n",
      "Loss on test= 0.00751691497862339\n",
      "acc for Lsat= 0.29098158169330823 \n",
      "acc for Psat= 0.2240615473290543 \n",
      "acc for optim= 0.1835434831575387\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.006861897185444832\n",
      "Loss on test= 0.008033820427954197\n",
      "acc for Lsat= 0.18320193152046865 \n",
      "acc for Psat= 0.2352894702926278 \n",
      "acc for optim= 0.1756401313468814\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.007090935483574867\n",
      "Loss on test= 0.008073065429925919\n",
      "acc for Lsat= 0.18449560097522205 \n",
      "acc for Psat= 0.27746898552868515 \n",
      "acc for optim= 0.16765720412756005\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.007025117054581642\n",
      "Loss on test= 0.007635713554918766\n",
      "acc for Lsat= 0.20401613279763195 \n",
      "acc for Psat= 0.17185211893067592 \n",
      "acc for optim= 0.1946102969555391\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.006864443887025118\n",
      "Loss on test= 0.006959497928619385\n",
      "acc for Lsat= 0.20152649472260642 \n",
      "acc for Psat= 0.28599401159832877 \n",
      "acc for optim= 0.1978194359689951\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.006473584100604057\n",
      "Loss on test= 0.007440753281116486\n",
      "acc for Lsat= 0.136371746348838 \n",
      "acc for Psat= 0.17945530886451402 \n",
      "acc for optim= 0.17271416344576412\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.006754592526704073\n",
      "Loss on test= 0.007926467806100845\n",
      "acc for Lsat= 0.2481221610473262 \n",
      "acc for Psat= 0.259646844274054 \n",
      "acc for optim= 0.1579765673312876\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.006878479849547148\n",
      "Loss on test= 0.007244260981678963\n",
      "acc for Lsat= 0.27071412369453657 \n",
      "acc for Psat= 0.21035208354765522 \n",
      "acc for optim= 0.16397188524974304\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.006553804501891136\n",
      "Loss on test= 0.007322791498154402\n",
      "acc for Lsat= 0.3041474328428093 \n",
      "acc for Psat= 0.19258547915766636 \n",
      "acc for optim= 0.16594857806598562\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.006664293818175793\n",
      "Loss on test= 0.007295746821910143\n",
      "acc for Lsat= 0.21410064315488045 \n",
      "acc for Psat= 0.2551168768356244 \n",
      "acc for optim= 0.1876043999671108\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.006606858689337969\n",
      "Loss on test= 0.007999781519174576\n",
      "acc for Lsat= 0.16763336418403518 \n",
      "acc for Psat= 0.15621159475348476 \n",
      "acc for optim= 0.15942434855969623\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.006567268166691065\n",
      "Loss on test= 0.0074716126546263695\n",
      "acc for Lsat= 0.21126308004992703 \n",
      "acc for Psat= 0.2222188195705207 \n",
      "acc for optim= 0.1765925165058838\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.006426580250263214\n",
      "Loss on test= 0.007751292549073696\n",
      "acc for Lsat= 0.16600944582993785 \n",
      "acc for Psat= 0.2731578114649488 \n",
      "acc for optim= 0.18482906619707742\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.006447490770369768\n",
      "Loss on test= 0.007018411997705698\n",
      "acc for Lsat= 0.17567835127313933 \n",
      "acc for Psat= 0.21024265016118684 \n",
      "acc for optim= 0.1852829407952312\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.006558150518685579\n",
      "Loss on test= 0.00757862301543355\n",
      "acc for Lsat= 0.21863224908399084 \n",
      "acc for Psat= 0.18658878343800703 \n",
      "acc for optim= 0.19522001278690165\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.006686307955533266\n",
      "Loss on test= 0.007051799912005663\n",
      "acc for Lsat= 0.23828733236425453 \n",
      "acc for Psat= 0.2518986591053868 \n",
      "acc for optim= 0.19257611227739188\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.006665318738669157\n",
      "Loss on test= 0.007199606858193874\n",
      "acc for Lsat= 0.22950721666630772 \n",
      "acc for Psat= 0.1999166213726211 \n",
      "acc for optim= 0.1836630579111645\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.006389537826180458\n",
      "Loss on test= 0.006596447434276342\n",
      "acc for Lsat= 0.14990488320149276 \n",
      "acc for Psat= 0.19619894069102076 \n",
      "acc for optim= 0.16106378926067716\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.006352280266582966\n",
      "Loss on test= 0.007073872722685337\n",
      "acc for Lsat= 0.14691190297404924 \n",
      "acc for Psat= 0.21463199642797312 \n",
      "acc for optim= 0.1794197946793348\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.006494465284049511\n",
      "Loss on test= 0.006582670379430056\n",
      "acc for Lsat= 0.14869627664383087 \n",
      "acc for Psat= 0.16959425636256734 \n",
      "acc for optim= 0.16870991436816338\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.006399058271199465\n",
      "Loss on test= 0.007108598947525024\n",
      "acc for Lsat= 0.19174096950640282 \n",
      "acc for Psat= 0.18943932755953735 \n",
      "acc for optim= 0.1795456399882419\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.006297230254858732\n",
      "Loss on test= 0.006954587996006012\n",
      "acc for Lsat= 0.20231370565791926 \n",
      "acc for Psat= 0.2201858186421709 \n",
      "acc for optim= 0.14955709716822538\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.006584457587450743\n",
      "Loss on test= 0.007874643430113792\n",
      "acc for Lsat= 0.16293402093773088 \n",
      "acc for Psat= 0.20583932593257892 \n",
      "acc for optim= 0.1709128212597635\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.006213480141013861\n",
      "Loss on test= 0.006672115530818701\n",
      "acc for Lsat= 0.1710322980975939 \n",
      "acc for Psat= 0.27215420366782284 \n",
      "acc for optim= 0.19277414720919397\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.006297446321696043\n",
      "Loss on test= 0.00692133791744709\n",
      "acc for Lsat= 0.1698347729527288 \n",
      "acc for Psat= 0.23326220001197523 \n",
      "acc for optim= 0.17151148384436965\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.00608805613592267\n",
      "Loss on test= 0.006746858358383179\n",
      "acc for Lsat= 0.15855901270535672 \n",
      "acc for Psat= 0.3148791537516647 \n",
      "acc for optim= 0.17699987537020612\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.006379489321261644\n",
      "Loss on test= 0.006890411488711834\n",
      "acc for Lsat= 0.2201426559024387 \n",
      "acc for Psat= 0.3416265861855613 \n",
      "acc for optim= 0.1778946082211203\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.006286903750151396\n",
      "Loss on test= 0.0067288633435964584\n",
      "acc for Lsat= 0.1970985856104461 \n",
      "acc for Psat= 0.18133646773640066 \n",
      "acc for optim= 0.19139666004209882\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.0061727906577289104\n",
      "Loss on test= 0.00683008274063468\n",
      "acc for Lsat= 0.14756434979952043 \n",
      "acc for Psat= 0.2738739545457065 \n",
      "acc for optim= 0.1608606077885876\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.006183702033013105\n",
      "Loss on test= 0.007442403119057417\n",
      "acc for Lsat= 0.1660113680538618 \n",
      "acc for Psat= 0.17540574234185946 \n",
      "acc for optim= 0.17707926593720913\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.006236095912754536\n",
      "Loss on test= 0.0064495219849050045\n",
      "acc for Lsat= 0.16500887160913813 \n",
      "acc for Psat= 0.22616053827934796 \n",
      "acc for optim= 0.19204378210835987\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.006024360191076994\n",
      "Loss on test= 0.006993512157350779\n",
      "acc for Lsat= 0.15552015473885047 \n",
      "acc for Psat= 0.17465696245845821 \n",
      "acc for optim= 0.15345660069336495\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.006154129281640053\n",
      "Loss on test= 0.007411315105855465\n",
      "acc for Lsat= 0.16475633141170773 \n",
      "acc for Psat= 0.1950405133732905 \n",
      "acc for optim= 0.17790800022582212\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.006388829555362463\n",
      "Loss on test= 0.007075402420014143\n",
      "acc for Lsat= 0.19369313420934808 \n",
      "acc for Psat= 0.2611863828367657 \n",
      "acc for optim= 0.18631580142149082\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.006143370643258095\n",
      "Loss on test= 0.007059777621179819\n",
      "acc for Lsat= 0.1741724486152331 \n",
      "acc for Psat= 0.212516997462242 \n",
      "acc for optim= 0.17556080139992344\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.006078021135181189\n",
      "Loss on test= 0.005997175350785255\n",
      "acc for Lsat= 0.19605202476183572 \n",
      "acc for Psat= 0.26791687723663116 \n",
      "acc for optim= 0.18792681282179224\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.006220401730388403\n",
      "Loss on test= 0.007043099030852318\n",
      "acc for Lsat= 0.15318938153278497 \n",
      "acc for Psat= 0.17470111633237037 \n",
      "acc for optim= 0.137716932532688\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.006046086549758911\n",
      "Loss on test= 0.00696794455870986\n",
      "acc for Lsat= 0.2113013948417372 \n",
      "acc for Psat= 0.20600588604186973 \n",
      "acc for optim= 0.165871450289463\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.005985322408378124\n",
      "Loss on test= 0.006424380000680685\n",
      "acc for Lsat= 0.19015458148593703 \n",
      "acc for Psat= 0.19131326635316429 \n",
      "acc for optim= 0.18373403553333548\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.006076444406062365\n",
      "Loss on test= 0.00654799398034811\n",
      "acc for Lsat= 0.15051129651773307 \n",
      "acc for Psat= 0.2566462324725257 \n",
      "acc for optim= 0.18078830444978344\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.0060231988318264484\n",
      "Loss on test= 0.007178843021392822\n",
      "acc for Lsat= 0.13636515141115524 \n",
      "acc for Psat= 0.20627329808970293 \n",
      "acc for optim= 0.17723372816625568\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.006119251251220703\n",
      "Loss on test= 0.0068548088893294334\n",
      "acc for Lsat= 0.16645600177601713 \n",
      "acc for Psat= 0.24010884992053938 \n",
      "acc for optim= 0.1969238262002667\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.006089060101658106\n",
      "Loss on test= 0.00721217505633831\n",
      "acc for Lsat= 0.22184809483587742 \n",
      "acc for Psat= 0.20024806405935022 \n",
      "acc for optim= 0.1684299074113369\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.006049023475497961\n",
      "Loss on test= 0.0066444156691432\n",
      "acc for Lsat= 0.1987186868985494 \n",
      "acc for Psat= 0.21216746631802785 \n",
      "acc for optim= 0.18654578717218506\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.006397861056029797\n",
      "Loss on test= 0.006327219307422638\n",
      "acc for Lsat= 0.20242840693228775 \n",
      "acc for Psat= 0.21300292977442345 \n",
      "acc for optim= 0.16947974607400182\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.005889279767870903\n",
      "Loss on test= 0.007050433196127415\n",
      "acc for Lsat= 0.1974380480694688 \n",
      "acc for Psat= 0.14009755115128225 \n",
      "acc for optim= 0.1689459594587485\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.0060668704099953175\n",
      "Loss on test= 0.00650861905887723\n",
      "acc for Lsat= 0.11959290672611031 \n",
      "acc for Psat= 0.1703210160550144 \n",
      "acc for optim= 0.18530589869866768\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.006105361506342888\n",
      "Loss on test= 0.006509467028081417\n",
      "acc for Lsat= 0.226612472285827 \n",
      "acc for Psat= 0.255145783846577 \n",
      "acc for optim= 0.18012765857080618\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.006027115974575281\n",
      "Loss on test= 0.007829729467630386\n",
      "acc for Lsat= 0.23541030669326168 \n",
      "acc for Psat= 0.2602595816262894 \n",
      "acc for optim= 0.17683666467200965\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.005811007227748632\n",
      "Loss on test= 0.006960088387131691\n",
      "acc for Lsat= 0.19008672943002441 \n",
      "acc for Psat= 0.27736266930070186 \n",
      "acc for optim= 0.1848762028126253\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.006088770925998688\n",
      "Loss on test= 0.006462814752012491\n",
      "acc for Lsat= 0.20153318406341392 \n",
      "acc for Psat= 0.2788140407452981 \n",
      "acc for optim= 0.15641026043643555\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.005864812061190605\n",
      "Loss on test= 0.006237441673874855\n",
      "acc for Lsat= 0.15368191574816592 \n",
      "acc for Psat= 0.24945939192548394 \n",
      "acc for optim= 0.18804605501807398\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.005803780630230904\n",
      "Loss on test= 0.006234241183847189\n",
      "acc for Lsat= 0.1954295350652602 \n",
      "acc for Psat= 0.23985041781432098 \n",
      "acc for optim= 0.17508787183194524\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.005787253845483065\n",
      "Loss on test= 0.0068006194196641445\n",
      "acc for Lsat= 0.1449473678237862 \n",
      "acc for Psat= 0.152112638629559 \n",
      "acc for optim= 0.15933013521134853\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.005773710086941719\n",
      "Loss on test= 0.006579142529517412\n",
      "acc for Lsat= 0.16572636138233873 \n",
      "acc for Psat= 0.20613679113901323 \n",
      "acc for optim= 0.1892024218622181\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.005951784551143646\n",
      "Loss on test= 0.006965413689613342\n",
      "acc for Lsat= 0.21055415205450523 \n",
      "acc for Psat= 0.21861487418775344 \n",
      "acc for optim= 0.16082103736698627\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.005681754555553198\n",
      "Loss on test= 0.006567666307091713\n",
      "acc for Lsat= 0.1269114698904256 \n",
      "acc for Psat= 0.20693962854986442 \n",
      "acc for optim= 0.1710891149317225\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.00568529823794961\n",
      "Loss on test= 0.0063296230509877205\n",
      "acc for Lsat= 0.1092433154117316 \n",
      "acc for Psat= 0.1247409597530754 \n",
      "acc for optim= 0.17695900901324219\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.005931468214839697\n",
      "Loss on test= 0.006103277672082186\n",
      "acc for Lsat= 0.1497357603899824 \n",
      "acc for Psat= 0.2604813799262047 \n",
      "acc for optim= 0.16523743803716368\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.005679998081177473\n",
      "Loss on test= 0.006399063393473625\n",
      "acc for Lsat= 0.14935319342960915 \n",
      "acc for Psat= 0.20809671518024211 \n",
      "acc for optim= 0.1780326222586963\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.005626711528748274\n",
      "Loss on test= 0.006628300528973341\n",
      "acc for Lsat= 0.16137854361699688 \n",
      "acc for Psat= 0.20253868670099312 \n",
      "acc for optim= 0.16964711339419913\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.005983470473438501\n",
      "Loss on test= 0.006568323355168104\n",
      "acc for Lsat= 0.15525336822287905 \n",
      "acc for Psat= 0.2265314921581497 \n",
      "acc for optim= 0.1850304827094078\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.0056666964665055275\n",
      "Loss on test= 0.006362163461744785\n",
      "acc for Lsat= 0.12868457349638143 \n",
      "acc for Psat= 0.20305851955587664 \n",
      "acc for optim= 0.1687687329120106\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.005753106903284788\n",
      "Loss on test= 0.006589948665350676\n",
      "acc for Lsat= 0.19741720263846219 \n",
      "acc for Psat= 0.2420887624224027 \n",
      "acc for optim= 0.16284063013477457\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.005968374200165272\n",
      "Loss on test= 0.006405824329704046\n",
      "acc for Lsat= 0.17816888799683916 \n",
      "acc for Psat= 0.212031413283613 \n",
      "acc for optim= 0.1836851876642969\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.005824896972626448\n",
      "Loss on test= 0.006163841113448143\n",
      "acc for Lsat= 0.1315277403239937 \n",
      "acc for Psat= 0.1914938255213201 \n",
      "acc for optim= 0.18717971340649658\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.005675109568983316\n",
      "Loss on test= 0.006219278555363417\n",
      "acc for Lsat= 0.17549771805190378 \n",
      "acc for Psat= 0.24338240404095915 \n",
      "acc for optim= 0.1798809449165775\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.005865388084203005\n",
      "Loss on test= 0.006575881037861109\n",
      "acc for Lsat= 0.14745930564175877 \n",
      "acc for Psat= 0.1901862315911179 \n",
      "acc for optim= 0.15300820359132355\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.0056769815273582935\n",
      "Loss on test= 0.006288798525929451\n",
      "acc for Lsat= 0.14010809475762975 \n",
      "acc for Psat= 0.2572086876154774 \n",
      "acc for optim= 0.1477801911532879\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.005588009487837553\n",
      "Loss on test= 0.00662294402718544\n",
      "acc for Lsat= 0.14828450563881132 \n",
      "acc for Psat= 0.19118890647465983 \n",
      "acc for optim= 0.1545957843368847\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.0056804087944328785\n",
      "Loss on test= 0.00666544446721673\n",
      "acc for Lsat= 0.12635349296033382 \n",
      "acc for Psat= 0.20833678944553766 \n",
      "acc for optim= 0.18019149949153265\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.005674905609339476\n",
      "Loss on test= 0.006172075401991606\n",
      "acc for Lsat= 0.14763916182952622 \n",
      "acc for Psat= 0.22145927459415463 \n",
      "acc for optim= 0.18172861154501638\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.005672540981322527\n",
      "Loss on test= 0.007205530069768429\n",
      "acc for Lsat= 0.1805435222470098 \n",
      "acc for Psat= 0.22008104218790928 \n",
      "acc for optim= 0.17027735544575584\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.005639947485178709\n",
      "Loss on test= 0.0063647134229540825\n",
      "acc for Lsat= 0.18277596728876233 \n",
      "acc for Psat= 0.28525497971309555 \n",
      "acc for optim= 0.177614855269591\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.005702984519302845\n",
      "Loss on test= 0.006313989404588938\n",
      "acc for Lsat= 0.15539747458468708 \n",
      "acc for Psat= 0.20353083485840923 \n",
      "acc for optim= 0.1735946492602428\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.005476407706737518\n",
      "Loss on test= 0.0065401289612054825\n",
      "acc for Lsat= 0.14619158024692702 \n",
      "acc for Psat= 0.1829716891774701 \n",
      "acc for optim= 0.1621564382997652\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.005505717825144529\n",
      "Loss on test= 0.006105518434196711\n",
      "acc for Lsat= 0.2141723827355438 \n",
      "acc for Psat= 0.2202718396567636 \n",
      "acc for optim= 0.1507335128262639\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.005644672550261021\n",
      "Loss on test= 0.006619652733206749\n",
      "acc for Lsat= 0.16063038414965072 \n",
      "acc for Psat= 0.18099720124155283 \n",
      "acc for optim= 0.16734405791956103\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.005702384281903505\n",
      "Loss on test= 0.006260700989514589\n",
      "acc for Lsat= 0.11314051968252493 \n",
      "acc for Psat= 0.18999746462537181 \n",
      "acc for optim= 0.16456769530971846\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.005387991666793823\n",
      "Loss on test= 0.006384750362485647\n",
      "acc for Lsat= 0.17193974337230125 \n",
      "acc for Psat= 0.18283831242782375 \n",
      "acc for optim= 0.17670617459548843\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.0055619534105062485\n",
      "Loss on test= 0.006335927173495293\n",
      "acc for Lsat= 0.1251598689414095 \n",
      "acc for Psat= 0.24414153562651741 \n",
      "acc for optim= 0.18284308672365215\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.005572916939854622\n",
      "Loss on test= 0.006196776404976845\n",
      "acc for Lsat= 0.12502144887629482 \n",
      "acc for Psat= 0.20740291295159194 \n",
      "acc for optim= 0.16927479869789547\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.005581931676715612\n",
      "Loss on test= 0.006372800096869469\n",
      "acc for Lsat= 0.1921992457161347 \n",
      "acc for Psat= 0.21050576456925935 \n",
      "acc for optim= 0.1656463418362869\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.005670941900461912\n",
      "Loss on test= 0.007046978455036879\n",
      "acc for Lsat= 0.21730350744393137 \n",
      "acc for Psat= 0.2027812652910749 \n",
      "acc for optim= 0.17544050105950898\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.005567992106080055\n",
      "Loss on test= 0.0063549187034368515\n",
      "acc for Lsat= 0.09868866520830327 \n",
      "acc for Psat= 0.17319818182537952 \n",
      "acc for optim= 0.19576262408453557\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.005545291118323803\n",
      "Loss on test= 0.006267962045967579\n",
      "acc for Lsat= 0.15055002481676638 \n",
      "acc for Psat= 0.20947617592497003 \n",
      "acc for optim= 0.1598356451270067\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.005432378966361284\n",
      "Loss on test= 0.006375431083142757\n",
      "acc for Lsat= 0.16011189286493593 \n",
      "acc for Psat= 0.19039838016033173 \n",
      "acc for optim= 0.1975193751665453\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.0055099125020205975\n",
      "Loss on test= 0.00678342767059803\n",
      "acc for Lsat= 0.1298154132285466 \n",
      "acc for Psat= 0.25197605943928164 \n",
      "acc for optim= 0.1667727087624371\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.005583110265433788\n",
      "Loss on test= 0.006370770279318094\n",
      "acc for Lsat= 0.08897112599677509 \n",
      "acc for Psat= 0.2288817036896944 \n",
      "acc for optim= 0.19334925193753508\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.005379803944379091\n",
      "Loss on test= 0.006821188610047102\n",
      "acc for Lsat= 0.15031147525749272 \n",
      "acc for Psat= 0.14352664773145485 \n",
      "acc for optim= 0.18095159497008556\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.0054710786789655685\n",
      "Loss on test= 0.006225606892257929\n",
      "acc for Lsat= 0.10132831333683295 \n",
      "acc for Psat= 0.15372891817241907 \n",
      "acc for optim= 0.17774259702612957\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.005488830152899027\n",
      "Loss on test= 0.006726446561515331\n",
      "acc for Lsat= 0.11848254495837157 \n",
      "acc for Psat= 0.1389847547850675 \n",
      "acc for optim= 0.15437345493895313\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.005325161386281252\n",
      "Loss on test= 0.006365204229950905\n",
      "acc for Lsat= 0.13641076281459796 \n",
      "acc for Psat= 0.2023288936664661 \n",
      "acc for optim= 0.1495653865341511\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.005507109221071005\n",
      "Loss on test= 0.005734174512326717\n",
      "acc for Lsat= 0.12668836830804744 \n",
      "acc for Psat= 0.2360793658428722 \n",
      "acc for optim= 0.162028314138297\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.005792943760752678\n",
      "Loss on test= 0.006000129505991936\n",
      "acc for Lsat= 0.13084700310557512 \n",
      "acc for Psat= 0.16159437514013714 \n",
      "acc for optim= 0.16499359636671013\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.0053766523487865925\n",
      "Loss on test= 0.006411314010620117\n",
      "acc for Lsat= 0.1446630256767902 \n",
      "acc for Psat= 0.18340401030662987 \n",
      "acc for optim= 0.1781105517099301\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.005518825724720955\n",
      "Loss on test= 0.006518801674246788\n",
      "acc for Lsat= 0.16346673212117618 \n",
      "acc for Psat= 0.20783936333221695 \n",
      "acc for optim= 0.181564725521538\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.005567289423197508\n",
      "Loss on test= 0.006248443387448788\n",
      "acc for Lsat= 0.15817005549454027 \n",
      "acc for Psat= 0.18323566529175472 \n",
      "acc for optim= 0.17781403184764916\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.005261633079499006\n",
      "Loss on test= 0.006104938220232725\n",
      "acc for Lsat= 0.15367687542715835 \n",
      "acc for Psat= 0.17840160434651706 \n",
      "acc for optim= 0.1605193979727725\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.005323505029082298\n",
      "Loss on test= 0.006076691672205925\n",
      "acc for Lsat= 0.13980759074911475 \n",
      "acc for Psat= 0.17390196242680153 \n",
      "acc for optim= 0.16268935888042002\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.005492211785167456\n",
      "Loss on test= 0.0060340361669659615\n",
      "acc for Lsat= 0.1944291920711597 \n",
      "acc for Psat= 0.1557351150485273 \n",
      "acc for optim= 0.15258847199018216\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.0054632690735161304\n",
      "Loss on test= 0.0063812448643147945\n",
      "acc for Lsat= 0.15601610469942293 \n",
      "acc for Psat= 0.20146443653437826 \n",
      "acc for optim= 0.1934371767565608\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.005494266282767057\n",
      "Loss on test= 0.005788292735815048\n",
      "acc for Lsat= 0.20947382490461072 \n",
      "acc for Psat= 0.2729297153289533 \n",
      "acc for optim= 0.18215811997652054\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.005368222948163748\n",
      "Loss on test= 0.006171774584800005\n",
      "acc for Lsat= 0.16491478963548112 \n",
      "acc for Psat= 0.21828026697039604 \n",
      "acc for optim= 0.17267315534667838\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.00525700906291604\n",
      "Loss on test= 0.006063196342438459\n",
      "acc for Lsat= 0.15598250549131384 \n",
      "acc for Psat= 0.18247308897682363 \n",
      "acc for optim= 0.1955605810508132\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.005301033146679401\n",
      "Loss on test= 0.006162882316857576\n",
      "acc for Lsat= 0.13799852934769458 \n",
      "acc for Psat= 0.19728991472058827 \n",
      "acc for optim= 0.17791192399130928\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.005252114497125149\n",
      "Loss on test= 0.006041120737791061\n",
      "acc for Lsat= 0.12022158255179723 \n",
      "acc for Psat= 0.1579916502556039 \n",
      "acc for optim= 0.17939821309927437\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.005242851562798023\n",
      "Loss on test= 0.005994867533445358\n",
      "acc for Lsat= 0.196156872358794 \n",
      "acc for Psat= 0.1817668177601364 \n",
      "acc for optim= 0.1800287678423855\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.005284391809254885\n",
      "Loss on test= 0.006653290241956711\n",
      "acc for Lsat= 0.19571874740843972 \n",
      "acc for Psat= 0.2591748489649035 \n",
      "acc for optim= 0.17201040282897237\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.00524603296071291\n",
      "Loss on test= 0.006377811543643475\n",
      "acc for Lsat= 0.18648258451786306 \n",
      "acc for Psat= 0.19967806867013374 \n",
      "acc for optim= 0.1714336952815453\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.005201829597353935\n",
      "Loss on test= 0.006252928636968136\n",
      "acc for Lsat= 0.098625152811615 \n",
      "acc for Psat= 0.16225088563644224 \n",
      "acc for optim= 0.18930706281551263\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.0052819629199802876\n",
      "Loss on test= 0.0063727074302732944\n",
      "acc for Lsat= 0.08520996394670671 \n",
      "acc for Psat= 0.15530320497540137 \n",
      "acc for optim= 0.1733453239624699\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.005130499601364136\n",
      "Loss on test= 0.006704614032059908\n",
      "acc for Lsat= 0.12762630596343014 \n",
      "acc for Psat= 0.1642965024544133 \n",
      "acc for optim= 0.15690591113848817\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.005204150453209877\n",
      "Loss on test= 0.005730407312512398\n",
      "acc for Lsat= 0.14124423825544202 \n",
      "acc for Psat= 0.2076719474668304 \n",
      "acc for optim= 0.18134020434485543\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.005224419292062521\n",
      "Loss on test= 0.005989274010062218\n",
      "acc for Lsat= 0.13685894747161204 \n",
      "acc for Psat= 0.1540844035593586 \n",
      "acc for optim= 0.20782430837344792\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.005110998637974262\n",
      "Loss on test= 0.006065575405955315\n",
      "acc for Lsat= 0.18128193418184915 \n",
      "acc for Psat= 0.2096833437681198 \n",
      "acc for optim= 0.1786358054830796\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.005165591835975647\n",
      "Loss on test= 0.006088407710194588\n",
      "acc for Lsat= 0.11095687591781218 \n",
      "acc for Psat= 0.16924352968473816 \n",
      "acc for optim= 0.19544496930514774\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.005165671929717064\n",
      "Loss on test= 0.0064227283000946045\n",
      "acc for Lsat= 0.12433295148528284 \n",
      "acc for Psat= 0.15366453043599096 \n",
      "acc for optim= 0.17342642937890357\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.0052453456446528435\n",
      "Loss on test= 0.005888512823730707\n",
      "acc for Lsat= 0.14301598584279418 \n",
      "acc for Psat= 0.1596125514091303 \n",
      "acc for optim= 0.17822204916996676\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.005149818491190672\n",
      "Loss on test= 0.006053834687918425\n",
      "acc for Lsat= 0.15823071248208484 \n",
      "acc for Psat= 0.2120627909898758 \n",
      "acc for optim= 0.17858642375924522\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.005192868411540985\n",
      "Loss on test= 0.006076926365494728\n",
      "acc for Lsat= 0.12203129701730278 \n",
      "acc for Psat= 0.159307351284143 \n",
      "acc for optim= 0.18282265836993852\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.0051636663265526295\n",
      "Loss on test= 0.00592815363779664\n",
      "acc for Lsat= 0.15264717054863772 \n",
      "acc for Psat= 0.16048821815962178 \n",
      "acc for optim= 0.17947190503279367\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.005225909408181906\n",
      "Loss on test= 0.006180272903293371\n",
      "acc for Lsat= 0.17357971995241112 \n",
      "acc for Psat= 0.23170587047934532 \n",
      "acc for optim= 0.17945829758213627\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.005163218360394239\n",
      "Loss on test= 0.006148594431579113\n",
      "acc for Lsat= 0.15810127007878488 \n",
      "acc for Psat= 0.178091989364475 \n",
      "acc for optim= 0.18743835560356578\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.005168404430150986\n",
      "Loss on test= 0.00590083934366703\n",
      "acc for Lsat= 0.11659278959915456 \n",
      "acc for Psat= 0.17738484694725937 \n",
      "acc for optim= 0.17782600715549457\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.005021483637392521\n",
      "Loss on test= 0.0061963824555277824\n",
      "acc for Lsat= 0.10961999544977313 \n",
      "acc for Psat= 0.1670435703902816 \n",
      "acc for optim= 0.16670982568110856\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.005301434546709061\n",
      "Loss on test= 0.006009524688124657\n",
      "acc for Lsat= 0.1291378445716368 \n",
      "acc for Psat= 0.15134698243087363 \n",
      "acc for optim= 0.18652691014318\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.005236321594566107\n",
      "Loss on test= 0.005950476508587599\n",
      "acc for Lsat= 0.12214169133868483 \n",
      "acc for Psat= 0.17444268401919139 \n",
      "acc for optim= 0.18124712641454405\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.005171875935047865\n",
      "Loss on test= 0.005696491338312626\n",
      "acc for Lsat= 0.08495832545061906 \n",
      "acc for Psat= 0.1955309191511737 \n",
      "acc for optim= 0.14960209109509984\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.005033540539443493\n",
      "Loss on test= 0.0061917994171381\n",
      "acc for Lsat= 0.10348172992881802 \n",
      "acc for Psat= 0.17813169402587745 \n",
      "acc for optim= 0.16140875892920625\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.00511181028559804\n",
      "Loss on test= 0.006224511191248894\n",
      "acc for Lsat= 0.18160994379367265 \n",
      "acc for Psat= 0.20220699388947752 \n",
      "acc for optim= 0.17991504119709134\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.0051633636467158794\n",
      "Loss on test= 0.005937607958912849\n",
      "acc for Lsat= 0.14392168967363736 \n",
      "acc for Psat= 0.1789569941142367 \n",
      "acc for optim= 0.17376066671891344\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.005109723191708326\n",
      "Loss on test= 0.005618351511657238\n",
      "acc for Lsat= 0.16309776581409904 \n",
      "acc for Psat= 0.2225756881137689 \n",
      "acc for optim= 0.1831913124769926\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.004952697083353996\n",
      "Loss on test= 0.00582465436309576\n",
      "acc for Lsat= 0.14547198162310654 \n",
      "acc for Psat= 0.18845881895044336 \n",
      "acc for optim= 0.18448306573554873\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.005115162115544081\n",
      "Loss on test= 0.006471153814345598\n",
      "acc for Lsat= 0.11078588493789236 \n",
      "acc for Psat= 0.17026460610537064 \n",
      "acc for optim= 0.1938640241407686\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.00507594458758831\n",
      "Loss on test= 0.006174339447170496\n",
      "acc for Lsat= 0.13051056771332192 \n",
      "acc for Psat= 0.18969431783383092 \n",
      "acc for optim= 0.17637543799355626\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.005133680533617735\n",
      "Loss on test= 0.006673056166619062\n",
      "acc for Lsat= 0.12493680759022634 \n",
      "acc for Psat= 0.21776748433088264 \n",
      "acc for optim= 0.19293325901445416\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.005043583922088146\n",
      "Loss on test= 0.006357935722917318\n",
      "acc for Lsat= 0.13832569018834168 \n",
      "acc for Psat= 0.19399417380595374 \n",
      "acc for optim= 0.1632233800418261\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.0051562427543103695\n",
      "Loss on test= 0.005983870476484299\n",
      "acc for Lsat= 0.1614038622420695 \n",
      "acc for Psat= 0.1277588949435287 \n",
      "acc for optim= 0.16741267796088424\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.005013900808990002\n",
      "Loss on test= 0.00574011355638504\n",
      "acc for Lsat= 0.1446853913496145 \n",
      "acc for Psat= 0.22437914217718774 \n",
      "acc for optim= 0.16893741622981098\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.005196563899517059\n",
      "Loss on test= 0.005782033316791058\n",
      "acc for Lsat= 0.1328802741287897 \n",
      "acc for Psat= 0.17269267992944354 \n",
      "acc for optim= 0.1868443675080521\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.005171326920390129\n",
      "Loss on test= 0.0058271316811442375\n",
      "acc for Lsat= 0.11509094076852004 \n",
      "acc for Psat= 0.14605983633858463 \n",
      "acc for optim= 0.18564660526398155\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.0051199207082390785\n",
      "Loss on test= 0.005449259653687477\n",
      "acc for Lsat= 0.12339377315301034 \n",
      "acc for Psat= 0.16866651793114013 \n",
      "acc for optim= 0.19382737406219044\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.0051929219625890255\n",
      "Loss on test= 0.005887105129659176\n",
      "acc for Lsat= 0.17860352196213272 \n",
      "acc for Psat= 0.22703755709032217 \n",
      "acc for optim= 0.17372321587107661\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.005120687652379274\n",
      "Loss on test= 0.006121436599642038\n",
      "acc for Lsat= 0.12438685653938188 \n",
      "acc for Psat= 0.22416607663035393 \n",
      "acc for optim= 0.17417607916932967\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.005041241180151701\n",
      "Loss on test= 0.00614066980779171\n",
      "acc for Lsat= 0.17756290407851338 \n",
      "acc for Psat= 0.2176323953188128 \n",
      "acc for optim= 0.18979645727409256\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.005114393774420023\n",
      "Loss on test= 0.00609832676127553\n",
      "acc for Lsat= 0.13525724235094255 \n",
      "acc for Psat= 0.21584351774719027 \n",
      "acc for optim= 0.18438710737973452\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.00502619706094265\n",
      "Loss on test= 0.00561811588704586\n",
      "acc for Lsat= 0.1461718047431633 \n",
      "acc for Psat= 0.15985140199255612 \n",
      "acc for optim= 0.17512770550739434\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.004984621424227953\n",
      "Loss on test= 0.005547207780182362\n",
      "acc for Lsat= 0.12952481670719054 \n",
      "acc for Psat= 0.19344743775824705 \n",
      "acc for optim= 0.15936086011222667\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.004914453253149986\n",
      "Loss on test= 0.0062560285441577435\n",
      "acc for Lsat= 0.11153551008222469 \n",
      "acc for Psat= 0.21561214017371336 \n",
      "acc for optim= 0.15450483550214106\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.0049443598836660385\n",
      "Loss on test= 0.005841818638145924\n",
      "acc for Lsat= 0.1240209355019033 \n",
      "acc for Psat= 0.18614768482641214 \n",
      "acc for optim= 0.19152560498979357\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.004977174568921328\n",
      "Loss on test= 0.006158542353659868\n",
      "acc for Lsat= 0.1708742873225775 \n",
      "acc for Psat= 0.18688663240108225 \n",
      "acc for optim= 0.17095260477314392\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.00507700489833951\n",
      "Loss on test= 0.006169318221509457\n",
      "acc for Lsat= 0.17724469531741407 \n",
      "acc for Psat= 0.1814251546230581 \n",
      "acc for optim= 0.1716482819045066\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.004987552296370268\n",
      "Loss on test= 0.00565626984462142\n",
      "acc for Lsat= 0.14428844075236055 \n",
      "acc for Psat= 0.16389481292571872 \n",
      "acc for optim= 0.17562180736826527\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.005024139303714037\n",
      "Loss on test= 0.005659261718392372\n",
      "acc for Lsat= 0.08322872914787796 \n",
      "acc for Psat= 0.18166135913795894 \n",
      "acc for optim= 0.18838675071795782\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.004850864410400391\n",
      "Loss on test= 0.0054695182479918\n",
      "acc for Lsat= 0.10661831218749285 \n",
      "acc for Psat= 0.16151418692121902 \n",
      "acc for optim= 0.2010435579965512\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.004835154395550489\n",
      "Loss on test= 0.005899561569094658\n",
      "acc for Lsat= 0.0888426294291599 \n",
      "acc for Psat= 0.15197410103347567 \n",
      "acc for optim= 0.17209536230398548\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.0049194409511983395\n",
      "Loss on test= 0.0063741630874574184\n",
      "acc for Lsat= 0.13605929924071664 \n",
      "acc for Psat= 0.1372087077729197 \n",
      "acc for optim= 0.16193958754754728\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.004988796077668667\n",
      "Loss on test= 0.005899953190237284\n",
      "acc for Lsat= 0.12389785867546582 \n",
      "acc for Psat= 0.20069594546738598 \n",
      "acc for optim= 0.180832287012082\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.004765072837471962\n",
      "Loss on test= 0.005750582553446293\n",
      "acc for Lsat= 0.07866651710355654 \n",
      "acc for Psat= 0.20200867702563605 \n",
      "acc for optim= 0.17888073517113096\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.0049239336512982845\n",
      "Loss on test= 0.005850065033882856\n",
      "acc for Lsat= 0.17383170491343158 \n",
      "acc for Psat= 0.2062161413228346 \n",
      "acc for optim= 0.1847520613939398\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.004793993197381496\n",
      "Loss on test= 0.005468921735882759\n",
      "acc for Lsat= 0.09135603913778646 \n",
      "acc for Psat= 0.18320908128387398 \n",
      "acc for optim= 0.20316622054411304\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.005004150792956352\n",
      "Loss on test= 0.0058339620009064674\n",
      "acc for Lsat= 0.09576843709995349 \n",
      "acc for Psat= 0.15004795512908864 \n",
      "acc for optim= 0.18956887646992174\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.005023522302508354\n",
      "Loss on test= 0.005686778575181961\n",
      "acc for Lsat= 0.10181990451059796 \n",
      "acc for Psat= 0.2053620745945308 \n",
      "acc for optim= 0.17896165057188934\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.004963685292750597\n",
      "Loss on test= 0.006177127361297607\n",
      "acc for Lsat= 0.13535887437562147 \n",
      "acc for Psat= 0.138341525879999 \n",
      "acc for optim= 0.1767321981282698\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.004815968684852123\n",
      "Loss on test= 0.005507131107151508\n",
      "acc for Lsat= 0.1476235923667749 \n",
      "acc for Psat= 0.18901868247323567 \n",
      "acc for optim= 0.15536652072640006\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.004708507098257542\n",
      "Loss on test= 0.006491548847407103\n",
      "acc for Lsat= 0.1526966148780452 \n",
      "acc for Psat= 0.1836141456539432 \n",
      "acc for optim= 0.20090966784240058\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.004795892629772425\n",
      "Loss on test= 0.006030329968780279\n",
      "acc for Lsat= 0.11375017990616874 \n",
      "acc for Psat= 0.18142663659010497 \n",
      "acc for optim= 0.1744857138643662\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.004735197406262159\n",
      "Loss on test= 0.0058904048055410385\n",
      "acc for Lsat= 0.12152730756335789 \n",
      "acc for Psat= 0.1876378446403477 \n",
      "acc for optim= 0.16499354048735565\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.0048858230002224445\n",
      "Loss on test= 0.005746427923440933\n",
      "acc for Lsat= 0.12715756831069788 \n",
      "acc for Psat= 0.1297846027624069 \n",
      "acc for optim= 0.19489415445261532\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.00488098431378603\n",
      "Loss on test= 0.005672804079949856\n",
      "acc for Lsat= 0.1208287286054757 \n",
      "acc for Psat= 0.17914415575149986 \n",
      "acc for optim= 0.19354997047533593\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.00486499909311533\n",
      "Loss on test= 0.005481996573507786\n",
      "acc for Lsat= 0.09301860102762778 \n",
      "acc for Psat= 0.14851834940620595 \n",
      "acc for optim= 0.19597478987028202\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.004843722563236952\n",
      "Loss on test= 0.005897183436900377\n",
      "acc for Lsat= 0.12435227863412972 \n",
      "acc for Psat= 0.17790442208449045 \n",
      "acc for optim= 0.19064242051293454\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.0047804429195821285\n",
      "Loss on test= 0.005796787329018116\n",
      "acc for Lsat= 0.12107232062327158 \n",
      "acc for Psat= 0.21284920937614515 \n",
      "acc for optim= 0.17219417953553298\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.004836522042751312\n",
      "Loss on test= 0.005949841812252998\n",
      "acc for Lsat= 0.08287337827884282 \n",
      "acc for Psat= 0.17922564204006144 \n",
      "acc for optim= 0.17055971791139907\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.004927618894726038\n",
      "Loss on test= 0.005757555365562439\n",
      "acc for Lsat= 0.09880711345209016 \n",
      "acc for Psat= 0.1503557465556595 \n",
      "acc for optim= 0.17963044604079592\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.004808679688721895\n",
      "Loss on test= 0.0057281372137367725\n",
      "acc for Lsat= 0.07256375385137896 \n",
      "acc for Psat= 0.14473708097769608 \n",
      "acc for optim= 0.16508551993562529\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.0047212447971105576\n",
      "Loss on test= 0.006185484584420919\n",
      "acc for Lsat= 0.1501145529715965 \n",
      "acc for Psat= 0.15044383854708737 \n",
      "acc for optim= 0.17333930730819702\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.004785915836691856\n",
      "Loss on test= 0.005932329222559929\n",
      "acc for Lsat= 0.14154248023987748 \n",
      "acc for Psat= 0.13171276103498208 \n",
      "acc for optim= 0.1967679497061504\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.00483289547264576\n",
      "Loss on test= 0.005981406196951866\n",
      "acc for Lsat= 0.1429795273579657 \n",
      "acc for Psat= 0.1811761078166051 \n",
      "acc for optim= 0.17028795353447398\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.004776204004883766\n",
      "Loss on test= 0.005748186260461807\n",
      "acc for Lsat= 0.1656905648156276 \n",
      "acc for Psat= 0.17428392394342357 \n",
      "acc for optim= 0.1776921010783149\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.004884202033281326\n",
      "Loss on test= 0.005594870075583458\n",
      "acc for Lsat= 0.10737266391515732 \n",
      "acc for Psat= 0.19397518913158113 \n",
      "acc for optim= 0.1745707836881694\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.00477968342602253\n",
      "Loss on test= 0.0059106070548295975\n",
      "acc for Lsat= 0.12247331763824655 \n",
      "acc for Psat= 0.13582458183453935 \n",
      "acc for optim= 0.19231481343093845\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.004927083384245634\n",
      "Loss on test= 0.005932945292443037\n",
      "acc for Lsat= 0.06778666715965503 \n",
      "acc for Psat= 0.1138869228048457 \n",
      "acc for optim= 0.18560676358821285\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.004738537594676018\n",
      "Loss on test= 0.005226713605225086\n",
      "acc for Lsat= 0.1287092130062067 \n",
      "acc for Psat= 0.21410715988733703 \n",
      "acc for optim= 0.1951874126162794\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.004864642862230539\n",
      "Loss on test= 0.005745772738009691\n",
      "acc for Lsat= 0.11628412450146344 \n",
      "acc for Psat= 0.197315023752809 \n",
      "acc for optim= 0.16674707798908153\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.004720269236713648\n",
      "Loss on test= 0.006050093565136194\n",
      "acc for Lsat= 0.1304631810894029 \n",
      "acc for Psat= 0.1785128484480083 \n",
      "acc for optim= 0.17791725577101009\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.0046401796862483025\n",
      "Loss on test= 0.005585998296737671\n",
      "acc for Lsat= 0.10659772182245636 \n",
      "acc for Psat= 0.12292990719692574 \n",
      "acc for optim= 0.17748001693851417\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.00458409683778882\n",
      "Loss on test= 0.006031320430338383\n",
      "acc for Lsat= 0.15532269691013628 \n",
      "acc for Psat= 0.17741588054377644 \n",
      "acc for optim= 0.1884089092620545\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.0048056719824671745\n",
      "Loss on test= 0.005448793061077595\n",
      "acc for Lsat= 0.16362335649318993 \n",
      "acc for Psat= 0.200450182840642 \n",
      "acc for optim= 0.17404627236020234\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.004684236366301775\n",
      "Loss on test= 0.006359454244375229\n",
      "acc for Lsat= 0.13228436042037275 \n",
      "acc for Psat= 0.14669042660130394 \n",
      "acc for optim= 0.1936777949643632\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.004892559256404638\n",
      "Loss on test= 0.0055480832234025\n",
      "acc for Lsat= 0.11233244939810699 \n",
      "acc for Psat= 0.17326063021189636 \n",
      "acc for optim= 0.17795607362252971\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.0047644260339438915\n",
      "Loss on test= 0.00571906054392457\n",
      "acc for Lsat= 0.16694104174772897 \n",
      "acc for Psat= 0.16973370025193113 \n",
      "acc for optim= 0.1866124417218897\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.004632916301488876\n",
      "Loss on test= 0.005895838141441345\n",
      "acc for Lsat= 0.12013782053771946 \n",
      "acc for Psat= 0.1711164324854811 \n",
      "acc for optim= 0.1989429939745201\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.004739685915410519\n",
      "Loss on test= 0.0055579328909516335\n",
      "acc for Lsat= 0.11070889193150732 \n",
      "acc for Psat= 0.17849384393129084 \n",
      "acc for optim= 0.16400623797542518\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.004639251157641411\n",
      "Loss on test= 0.005809078458696604\n",
      "acc for Lsat= 0.16376815860470137 \n",
      "acc for Psat= 0.20917481846279568 \n",
      "acc for optim= 0.16530108922678563\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.004812132101505995\n",
      "Loss on test= 0.005534269381314516\n",
      "acc for Lsat= 0.1309272956310047 \n",
      "acc for Psat= 0.1976519231684506 \n",
      "acc for optim= 0.19118544935352272\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.004787187557667494\n",
      "Loss on test= 0.005440851207822561\n",
      "acc for Lsat= 0.09673005477007893 \n",
      "acc for Psat= 0.2263942640274763 \n",
      "acc for optim= 0.18806695782889923\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.0047607203014194965\n",
      "Loss on test= 0.005390523001551628\n",
      "acc for Lsat= 0.12792023830115795 \n",
      "acc for Psat= 0.19800094763437906 \n",
      "acc for optim= 0.17199905364153287\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.004679906647652388\n",
      "Loss on test= 0.005634617991745472\n",
      "acc for Lsat= 0.12180267439948188 \n",
      "acc for Psat= 0.20491117311434615 \n",
      "acc for optim= 0.1666075630734364\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.004647310357540846\n",
      "Loss on test= 0.005747148301452398\n",
      "acc for Lsat= 0.12839273632400566 \n",
      "acc for Psat= 0.16772587483541834 \n",
      "acc for optim= 0.18931783244220746\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.004656026139855385\n",
      "Loss on test= 0.005606027320027351\n",
      "acc for Lsat= 0.07244966075652176 \n",
      "acc for Psat= 0.1651455869173838 \n",
      "acc for optim= 0.2040267272127999\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.004651244264096022\n",
      "Loss on test= 0.005242850165814161\n",
      "acc for Lsat= 0.11281144302079661 \n",
      "acc for Psat= 0.20657627848494384 \n",
      "acc for optim= 0.20830286532226536\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.004818851128220558\n",
      "Loss on test= 0.00568363256752491\n",
      "acc for Lsat= 0.16493758341918388 \n",
      "acc for Psat= 0.14321291110374862 \n",
      "acc for optim= 0.1932563927128083\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.004679861478507519\n",
      "Loss on test= 0.005420248955488205\n",
      "acc for Lsat= 0.12409540265798569 \n",
      "acc for Psat= 0.14873837299334505 \n",
      "acc for optim= 0.1682672504749563\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.004688222426921129\n",
      "Loss on test= 0.005504456348717213\n",
      "acc for Lsat= 0.12136558393507989 \n",
      "acc for Psat= 0.1484107053913451 \n",
      "acc for optim= 0.1930830851714644\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.004698952194303274\n",
      "Loss on test= 0.005365090910345316\n",
      "acc for Lsat= 0.1493717691498912 \n",
      "acc for Psat= 0.197826168862068 \n",
      "acc for optim= 0.1564523277597295\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.004780025687068701\n",
      "Loss on test= 0.005504797678440809\n",
      "acc for Lsat= 0.08299642640890346 \n",
      "acc for Psat= 0.15402464935969976 \n",
      "acc for optim= 0.19414502941071987\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.004902577959001064\n",
      "Loss on test= 0.005691041238605976\n",
      "acc for Lsat= 0.13355739052510923 \n",
      "acc for Psat= 0.18614670891676927 \n",
      "acc for optim= 0.17134109677539933\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.004738495219498873\n",
      "Loss on test= 0.005577044561505318\n",
      "acc for Lsat= 0.10179778481445585 \n",
      "acc for Psat= 0.13830540109807365 \n",
      "acc for optim= 0.17978472542017698\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.004527292679995298\n",
      "Loss on test= 0.005714103113859892\n",
      "acc for Lsat= 0.12267881631851196 \n",
      "acc for Psat= 0.19644406662943462 \n",
      "acc for optim= 0.1832186384126544\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.004727579187601805\n",
      "Loss on test= 0.00531383091583848\n",
      "acc for Lsat= 0.1256850323277629 \n",
      "acc for Psat= 0.1930745169520378 \n",
      "acc for optim= 0.17662473767995834\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.004611032083630562\n",
      "Loss on test= 0.005591664928942919\n",
      "acc for Lsat= 0.10608451482322481 \n",
      "acc for Psat= 0.17542075174343255 \n",
      "acc for optim= 0.1729153174544788\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.004623730201274157\n",
      "Loss on test= 0.006024044472724199\n",
      "acc for Lsat= 0.1400596186415189 \n",
      "acc for Psat= 0.17061109483862916 \n",
      "acc for optim= 0.17120472221480063\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.004596169106662273\n",
      "Loss on test= 0.005377084016799927\n",
      "acc for Lsat= 0.10105775664043096 \n",
      "acc for Psat= 0.15981281714306939 \n",
      "acc for optim= 0.1824606366507295\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.00461845425888896\n",
      "Loss on test= 0.005900632124394178\n",
      "acc for Lsat= 0.09927985271335477 \n",
      "acc for Psat= 0.18166964242441785 \n",
      "acc for optim= 0.18799738466946614\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.00464803958311677\n",
      "Loss on test= 0.0058095138520002365\n",
      "acc for Lsat= 0.08481081339737608 \n",
      "acc for Psat= 0.2026248201727867 \n",
      "acc for optim= 0.18498880367001724\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.004495586734265089\n",
      "Loss on test= 0.005791792180389166\n",
      "acc for Lsat= 0.12611174143643844 \n",
      "acc for Psat= 0.17562187540655336 \n",
      "acc for optim= 0.1617038190468318\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.004601635504513979\n",
      "Loss on test= 0.005708834156394005\n",
      "acc for Lsat= 0.11621793990747796 \n",
      "acc for Psat= 0.15412278773470056 \n",
      "acc for optim= 0.17025065949807563\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.004750716965645552\n",
      "Loss on test= 0.005537537392228842\n",
      "acc for Lsat= 0.14507106791198668 \n",
      "acc for Psat= 0.17253063793759793 \n",
      "acc for optim= 0.15439860055792248\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.004541263449937105\n",
      "Loss on test= 0.005351257044821978\n",
      "acc for Lsat= 0.12022511948210497 \n",
      "acc for Psat= 0.16748705925419927 \n",
      "acc for optim= 0.16760399259833825\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.00462773023173213\n",
      "Loss on test= 0.005651532672345638\n",
      "acc for Lsat= 0.10587572371069756 \n",
      "acc for Psat= 0.20642591847313774 \n",
      "acc for optim= 0.17936241026553842\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.0046048653312027454\n",
      "Loss on test= 0.005795499309897423\n",
      "acc for Lsat= 0.16793954274099734 \n",
      "acc for Psat= 0.19185061059478256 \n",
      "acc for optim= 0.16565749544598576\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.004726044833660126\n",
      "Loss on test= 0.0053700897842645645\n",
      "acc for Lsat= 0.10502692901839812 \n",
      "acc for Psat= 0.1722038889096843 \n",
      "acc for optim= 0.16351056546490225\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.004716199357062578\n",
      "Loss on test= 0.005465701688081026\n",
      "acc for Lsat= 0.0952825504872534 \n",
      "acc for Psat= 0.17675330345001486 \n",
      "acc for optim= 0.1695917132504595\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.004502197727560997\n",
      "Loss on test= 0.005688544362783432\n",
      "acc for Lsat= 0.11641486130085671 \n",
      "acc for Psat= 0.22204587856928507 \n",
      "acc for optim= 0.16528652773963082\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.004717960953712463\n",
      "Loss on test= 0.005498116370290518\n",
      "acc for Lsat= 0.09442832771067818 \n",
      "acc for Psat= 0.1699715941083721 \n",
      "acc for optim= 0.1869328677162735\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.004661518149077892\n",
      "Loss on test= 0.005411354824900627\n",
      "acc for Lsat= 0.11395578963371615 \n",
      "acc for Psat= 0.13853714866046277 \n",
      "acc for optim= 0.1730688519568907\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.0045769731514155865\n",
      "Loss on test= 0.005532886367291212\n",
      "acc for Lsat= 0.11097209143594632 \n",
      "acc for Psat= 0.16968306112620565 \n",
      "acc for optim= 0.18342207827501827\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.004730498418211937\n",
      "Loss on test= 0.00569952093064785\n",
      "acc for Lsat= 0.1040985927813583 \n",
      "acc for Psat= 0.18069976040472588 \n",
      "acc for optim= 0.19793437897331184\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.004647759720683098\n",
      "Loss on test= 0.006095232907682657\n",
      "acc for Lsat= 0.1508264139087664 \n",
      "acc for Psat= 0.192867040892856 \n",
      "acc for optim= 0.1635827037712766\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.004540047608315945\n",
      "Loss on test= 0.005497824400663376\n",
      "acc for Lsat= 0.10572848567325208 \n",
      "acc for Psat= 0.15088080532020992 \n",
      "acc for optim= 0.1999863071574105\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.0047392169944942\n",
      "Loss on test= 0.005611616186797619\n",
      "acc for Lsat= 0.13191684625215 \n",
      "acc for Psat= 0.1884285549943646 \n",
      "acc for optim= 0.1921516752982926\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.004511332139372826\n",
      "Loss on test= 0.00566427456215024\n",
      "acc for Lsat= 0.16047121812072065 \n",
      "acc for Psat= 0.17525573079991671 \n",
      "acc for optim= 0.17920256923470232\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.004504676908254623\n",
      "Loss on test= 0.005348124075680971\n",
      "acc for Lsat= 0.07096409531206721 \n",
      "acc for Psat= 0.15376616414222452 \n",
      "acc for optim= 0.2055456613500913\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.00455747963860631\n",
      "Loss on test= 0.005258915945887566\n",
      "acc for Lsat= 0.12758807138258513 \n",
      "acc for Psat= 0.20356795745384362 \n",
      "acc for optim= 0.16184673618732226\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.004631239455193281\n",
      "Loss on test= 0.005350368097424507\n",
      "acc for Lsat= 0.07437896500858995 \n",
      "acc for Psat= 0.11600924179785782 \n",
      "acc for optim= 0.1798944165930152\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.004558783024549484\n",
      "Loss on test= 0.005685997195541859\n",
      "acc for Lsat= 0.11935847590858531 \n",
      "acc for Psat= 0.12100227316841483 \n",
      "acc for optim= 0.16985796549771395\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.0046174474991858006\n",
      "Loss on test= 0.0055207060649991035\n",
      "acc for Lsat= 0.11719256111731131 \n",
      "acc for Psat= 0.14517543411865416 \n",
      "acc for optim= 0.17659168377415174\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.004622593056410551\n",
      "Loss on test= 0.005815254524350166\n",
      "acc for Lsat= 0.12393994259441064 \n",
      "acc for Psat= 0.1304580548312515 \n",
      "acc for optim= 0.19312278662497798\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.004634395241737366\n",
      "Loss on test= 0.005623537581413984\n",
      "acc for Lsat= 0.11664513022535378 \n",
      "acc for Psat= 0.167372886194951 \n",
      "acc for optim= 0.1916840108525422\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.004567496012896299\n",
      "Loss on test= 0.005332460626959801\n",
      "acc for Lsat= 0.13507573089251915 \n",
      "acc for Psat= 0.13874753235561205 \n",
      "acc for optim= 0.1846803847907318\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.004511676728725433\n",
      "Loss on test= 0.005468687973916531\n",
      "acc for Lsat= 0.1104141081450507 \n",
      "acc for Psat= 0.16783766096664798 \n",
      "acc for optim= 0.1659916854566998\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.004603314213454723\n",
      "Loss on test= 0.0056225513108074665\n",
      "acc for Lsat= 0.0871872114431527 \n",
      "acc for Psat= 0.1714793726698392 \n",
      "acc for optim= 0.1734847751342588\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.004604337736964226\n",
      "Loss on test= 0.0054553779773414135\n",
      "acc for Lsat= 0.11825846621973647 \n",
      "acc for Psat= 0.16755847729897747 \n",
      "acc for optim= 0.18056323751807213\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.004656486678868532\n",
      "Loss on test= 0.005688140168786049\n",
      "acc for Lsat= 0.09714640418274535 \n",
      "acc for Psat= 0.1487684010838469 \n",
      "acc for optim= 0.16836076269262573\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.0044469102285802364\n",
      "Loss on test= 0.005560765042901039\n",
      "acc for Lsat= 0.11116400785330269 \n",
      "acc for Psat= 0.19969601401438317 \n",
      "acc for optim= 0.17418585438281298\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.004512378480285406\n",
      "Loss on test= 0.005508667789399624\n",
      "acc for Lsat= 0.10294552530265516 \n",
      "acc for Psat= 0.14373616341294515 \n",
      "acc for optim= 0.21504084015679029\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.004549827892333269\n",
      "Loss on test= 0.005709280259907246\n",
      "acc for Lsat= 0.11024919191064934 \n",
      "acc for Psat= 0.15351991611532867 \n",
      "acc for optim= 0.17249860746475557\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.004520067013800144\n",
      "Loss on test= 0.005487515591084957\n",
      "acc for Lsat= 0.132672899691291 \n",
      "acc for Psat= 0.2350389922244681 \n",
      "acc for optim= 0.16638945570836464\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.004576361738145351\n",
      "Loss on test= 0.005897090770304203\n",
      "acc for Lsat= 0.11363236945019001 \n",
      "acc for Psat= 0.15956458512745383 \n",
      "acc for optim= 0.17379689537402657\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.004429088905453682\n",
      "Loss on test= 0.0053830258548259735\n",
      "acc for Lsat= 0.1307917500186401 \n",
      "acc for Psat= 0.21038808047564495 \n",
      "acc for optim= 0.14705481018043226\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.0044892276637256145\n",
      "Loss on test= 0.005470508709549904\n",
      "acc for Lsat= 0.12565410918452674 \n",
      "acc for Psat= 0.15676396014168859 \n",
      "acc for optim= 0.19711708546512657\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.004469319712370634\n",
      "Loss on test= 0.0054896557703614235\n",
      "acc for Lsat= 0.08925854748425384 \n",
      "acc for Psat= 0.1560197396773017 \n",
      "acc for optim= 0.19747551987206358\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.004573233891278505\n",
      "Loss on test= 0.005424181930720806\n",
      "acc for Lsat= 0.1281293147864441 \n",
      "acc for Psat= 0.15024946423040497 \n",
      "acc for optim= 0.2028023520639787\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.004589949268847704\n",
      "Loss on test= 0.005511611234396696\n",
      "acc for Lsat= 0.13594795561706027 \n",
      "acc for Psat= 0.18510452559631732 \n",
      "acc for optim= 0.16918172552767727\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.004552579950541258\n",
      "Loss on test= 0.005751440301537514\n",
      "acc for Lsat= 0.11721182368799216 \n",
      "acc for Psat= 0.1775007116763542 \n",
      "acc for optim= 0.19191373522496885\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.004483394790440798\n",
      "Loss on test= 0.0056292470544576645\n",
      "acc for Lsat= 0.13142561464984384 \n",
      "acc for Psat= 0.15474423786832225 \n",
      "acc for optim= 0.18666971723238626\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.004410750698298216\n",
      "Loss on test= 0.005717132706195116\n",
      "acc for Lsat= 0.12472493667155504 \n",
      "acc for Psat= 0.17278922660948914 \n",
      "acc for optim= 0.18862955277371737\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.004494577180594206\n",
      "Loss on test= 0.005481989122927189\n",
      "acc for Lsat= 0.133291426114738 \n",
      "acc for Psat= 0.1865768509192599 \n",
      "acc for optim= 0.17812487503720653\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.004482797812670469\n",
      "Loss on test= 0.005688926205039024\n",
      "acc for Lsat= 0.11782983359363344 \n",
      "acc for Psat= 0.13740690942439768 \n",
      "acc for optim= 0.18647163100023237\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.004478706046938896\n",
      "Loss on test= 0.005419927649199963\n",
      "acc for Lsat= 0.11190802187451886 \n",
      "acc for Psat= 0.17519374722097483 \n",
      "acc for optim= 0.18964169955708915\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.004513545427471399\n",
      "Loss on test= 0.005182212684303522\n",
      "acc for Lsat= 0.10504596263894604 \n",
      "acc for Psat= 0.17300191834672457 \n",
      "acc for optim= 0.18117044928173223\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.004514075815677643\n",
      "Loss on test= 0.00550216156989336\n",
      "acc for Lsat= 0.13098517515593106 \n",
      "acc for Psat= 0.14455148039592636 \n",
      "acc for optim= 0.17617905357231697\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.004466739948838949\n",
      "Loss on test= 0.005145613569766283\n",
      "acc for Lsat= 0.0822669068713569 \n",
      "acc for Psat= 0.1586799407377839 \n",
      "acc for optim= 0.19358848676913315\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.004427580162882805\n",
      "Loss on test= 0.005310283042490482\n",
      "acc for Lsat= 0.08222369505609903 \n",
      "acc for Psat= 0.16565789266799888 \n",
      "acc for optim= 0.17054800492607886\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.0042053889483213425\n",
      "Loss on test= 0.00566394068300724\n",
      "acc for Lsat= 0.1118036547365288 \n",
      "acc for Psat= 0.17799318261030647 \n",
      "acc for optim= 0.18194892324714196\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.004480559844523668\n",
      "Loss on test= 0.006238757632672787\n",
      "acc for Lsat= 0.11097189794398016 \n",
      "acc for Psat= 0.17722809532036385 \n",
      "acc for optim= 0.1905991319153044\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.00446055643260479\n",
      "Loss on test= 0.005529184825718403\n",
      "acc for Lsat= 0.11415014643636015 \n",
      "acc for Psat= 0.16602423171409303 \n",
      "acc for optim= 0.167604025427459\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.004509556572884321\n",
      "Loss on test= 0.005300828721374273\n",
      "acc for Lsat= 0.10319795208569202 \n",
      "acc for Psat= 0.19565947498712274 \n",
      "acc for optim= 0.1743895871978667\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.004335213918238878\n",
      "Loss on test= 0.005252747796475887\n",
      "acc for Lsat= 0.10861556216453512 \n",
      "acc for Psat= 0.14699667919841078 \n",
      "acc for optim= 0.18834374317278466\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.00435970863327384\n",
      "Loss on test= 0.005734915845096111\n",
      "acc for Lsat= 0.11108133512445623 \n",
      "acc for Psat= 0.12965212995186448 \n",
      "acc for optim= 0.18494873051531613\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.004546523559838533\n",
      "Loss on test= 0.005638414528220892\n",
      "acc for Lsat= 0.16173574204246202 \n",
      "acc for Psat= 0.19401404502827468 \n",
      "acc for optim= 0.1713214700317217\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.004504884127527475\n",
      "Loss on test= 0.005264070350676775\n",
      "acc for Lsat= 0.10285874396666056 \n",
      "acc for Psat= 0.1847344991337094 \n",
      "acc for optim= 0.17528074990130132\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.004240584094077349\n",
      "Loss on test= 0.005333980545401573\n",
      "acc for Lsat= 0.133060774145027 \n",
      "acc for Psat= 0.21795950581630072 \n",
      "acc for optim= 0.1514306153662296\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.0044252886436879635\n",
      "Loss on test= 0.005307672079652548\n",
      "acc for Lsat= 0.1241393249688877 \n",
      "acc for Psat= 0.17209099150366253 \n",
      "acc for optim= 0.17754698687026071\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.004487732890993357\n",
      "Loss on test= 0.005415476858615875\n",
      "acc for Lsat= 0.12881576413443932 \n",
      "acc for Psat= 0.1575818844139576 \n",
      "acc for optim= 0.17712161884022257\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.0043234992772340775\n",
      "Loss on test= 0.005162226036190987\n",
      "acc for Lsat= 0.1146159548791022 \n",
      "acc for Psat= 0.18843012794645297 \n",
      "acc for optim= 0.18325304788433844\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.0046432120725512505\n",
      "Loss on test= 0.005449588876217604\n",
      "acc for Lsat= 0.07485276082944539 \n",
      "acc for Psat= 0.16798190658705103 \n",
      "acc for optim= 0.16439234874107772\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.004460865166038275\n",
      "Loss on test= 0.005662715062499046\n",
      "acc for Lsat= 0.10580238260121809 \n",
      "acc for Psat= 0.16726545699768597 \n",
      "acc for optim= 0.17509035958856758\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.004377185832709074\n",
      "Loss on test= 0.005519038997590542\n",
      "acc for Lsat= 0.10034559198862149 \n",
      "acc for Psat= 0.12106500777412697 \n",
      "acc for optim= 0.1905145715508196\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.004224815405905247\n",
      "Loss on test= 0.00552354846149683\n",
      "acc for Lsat= 0.09437562421792084 \n",
      "acc for Psat= 0.18289365262414017 \n",
      "acc for optim= 0.19768780811379352\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.004289836157113314\n",
      "Loss on test= 0.005200567655265331\n",
      "acc for Lsat= 0.08038315544318822 \n",
      "acc for Psat= 0.14687091888137932 \n",
      "acc for optim= 0.1838010468830665\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.004369734786450863\n",
      "Loss on test= 0.0058503164909780025\n",
      "acc for Lsat= 0.1421886016614735 \n",
      "acc for Psat= 0.19776266088916195 \n",
      "acc for optim= 0.18913735263049603\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.004529494326561689\n",
      "Loss on test= 0.005871910136193037\n",
      "acc for Lsat= 0.11198967895082508 \n",
      "acc for Psat= 0.1559346267151543 \n",
      "acc for optim= 0.18653509289854103\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.004319718107581139\n",
      "Loss on test= 0.005574813578277826\n",
      "acc for Lsat= 0.1029841687478539 \n",
      "acc for Psat= 0.150703110318217 \n",
      "acc for optim= 0.17684966584460604\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.004535013809800148\n",
      "Loss on test= 0.005526973865926266\n",
      "acc for Lsat= 0.09870601460958521 \n",
      "acc for Psat= 0.181182865674297 \n",
      "acc for optim= 0.18440577909091693\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.004456088878214359\n",
      "Loss on test= 0.0053866892121732235\n",
      "acc for Lsat= 0.10420420931445228 \n",
      "acc for Psat= 0.181757684590088 \n",
      "acc for optim= 0.16910072757552067\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.004399057012051344\n",
      "Loss on test= 0.005486403126269579\n",
      "acc for Lsat= 0.10520306464362268 \n",
      "acc for Psat= 0.1221131742802552 \n",
      "acc for optim= 0.16089402661762303\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.004369569476693869\n",
      "Loss on test= 0.00547192245721817\n",
      "acc for Lsat= 0.08393935570752041 \n",
      "acc for Psat= 0.12152234646782745 \n",
      "acc for optim= 0.19256419295238125\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.004402162041515112\n",
      "Loss on test= 0.005706209223717451\n",
      "acc for Lsat= 0.10633877716544601 \n",
      "acc for Psat= 0.20170626724656257 \n",
      "acc for optim= 0.162835185480718\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.0043206969276070595\n",
      "Loss on test= 0.005751350428909063\n",
      "acc for Lsat= 0.10994622866726583 \n",
      "acc for Psat= 0.21088182377732462 \n",
      "acc for optim= 0.20816233161733383\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.004450397100299597\n",
      "Loss on test= 0.005923885386437178\n",
      "acc for Lsat= 0.10552544653829601 \n",
      "acc for Psat= 0.13879128453683937 \n",
      "acc for optim= 0.19191066258483463\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.004498626571148634\n",
      "Loss on test= 0.005642440635710955\n",
      "acc for Lsat= 0.11477073178523117 \n",
      "acc for Psat= 0.16009835650523505 \n",
      "acc for optim= 0.17762842836479345\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.0043204124085605145\n",
      "Loss on test= 0.005587475374341011\n",
      "acc for Lsat= 0.09896550006750557 \n",
      "acc for Psat= 0.16012650438480908 \n",
      "acc for optim= 0.17443090077075693\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.004346636589616537\n",
      "Loss on test= 0.005431680008769035\n",
      "acc for Lsat= 0.08479322881127398 \n",
      "acc for Psat= 0.12824413895658734 \n",
      "acc for optim= 0.20558623721202215\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.004349954891949892\n",
      "Loss on test= 0.005367312114685774\n",
      "acc for Lsat= 0.10150401232143243 \n",
      "acc for Psat= 0.15793940730185974 \n",
      "acc for optim= 0.1834507528692484\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.004361400380730629\n",
      "Loss on test= 0.005736821331083775\n",
      "acc for Lsat= 0.1001722514629364 \n",
      "acc for Psat= 0.1865779085136536 \n",
      "acc for optim= 0.2040408182785743\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.0042932662181556225\n",
      "Loss on test= 0.0052052950486540794\n",
      "acc for Lsat= 0.14620844238541192 \n",
      "acc for Psat= 0.15787006456715366 \n",
      "acc for optim= 0.1914568574478229\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.004402784630656242\n",
      "Loss on test= 0.0057558780536055565\n",
      "acc for Lsat= 0.12289816560223699 \n",
      "acc for Psat= 0.17157206187645593 \n",
      "acc for optim= 0.16778766047597551\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.0042701163329184055\n",
      "Loss on test= 0.005592679139226675\n",
      "acc for Lsat= 0.098670688082671 \n",
      "acc for Psat= 0.1704828089310063 \n",
      "acc for optim= 0.1844406689827641\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.004313428420573473\n",
      "Loss on test= 0.005905643105506897\n",
      "acc for Lsat= 0.10063970896104972 \n",
      "acc for Psat= 0.2100612047749261 \n",
      "acc for optim= 0.171927596287181\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.004289219155907631\n",
      "Loss on test= 0.005368972197175026\n",
      "acc for Lsat= 0.1184226473075493 \n",
      "acc for Psat= 0.18945148654489052 \n",
      "acc for optim= 0.1742515680897567\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.004283827263861895\n",
      "Loss on test= 0.005777051672339439\n",
      "acc for Lsat= 0.10205772244888875 \n",
      "acc for Psat= 0.18440641762895715 \n",
      "acc for optim= 0.1800922008826294\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.004256070591509342\n",
      "Loss on test= 0.005636259913444519\n",
      "acc for Lsat= 0.09631241826314686 \n",
      "acc for Psat= 0.16207674073262346 \n",
      "acc for optim= 0.18618053673870033\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.00428693788126111\n",
      "Loss on test= 0.005402963608503342\n",
      "acc for Lsat= 0.11796889609346788 \n",
      "acc for Psat= 0.21856458195381695 \n",
      "acc for optim= 0.19168978391422165\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.004300727508962154\n",
      "Loss on test= 0.005377735942602158\n",
      "acc for Lsat= 0.09145992421286388 \n",
      "acc for Psat= 0.16776661947369576 \n",
      "acc for optim= 0.19172703495456112\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.004355285782366991\n",
      "Loss on test= 0.005565522704273462\n",
      "acc for Lsat= 0.06398570951488283 \n",
      "acc for Psat= 0.14443387574930158 \n",
      "acc for optim= 0.16373120752784112\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.004366107285022736\n",
      "Loss on test= 0.005348633509129286\n",
      "acc for Lsat= 0.09875629061005181 \n",
      "acc for Psat= 0.13485251967277792 \n",
      "acc for optim= 0.1853232996331321\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.004426430910825729\n",
      "Loss on test= 0.005523395258933306\n",
      "acc for Lsat= 0.09688187447480029 \n",
      "acc for Psat= 0.18406935336275232 \n",
      "acc for optim= 0.19015713413763377\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.0045023285783827305\n",
      "Loss on test= 0.00551351485773921\n",
      "acc for Lsat= 0.06386081230205794 \n",
      "acc for Psat= 0.16445794246262974 \n",
      "acc for optim= 0.1754338906870948\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.0041789826937019825\n",
      "Loss on test= 0.005467774346470833\n",
      "acc for Lsat= 0.10607472888659686 \n",
      "acc for Psat= 0.17730321248786318 \n",
      "acc for optim= 0.16868403812663424\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.004357025492936373\n",
      "Loss on test= 0.005463256500661373\n",
      "acc for Lsat= 0.13000149352269041 \n",
      "acc for Psat= 0.19673124054356272 \n",
      "acc for optim= 0.17170178891521776\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.004365008324384689\n",
      "Loss on test= 0.005126426927745342\n",
      "acc for Lsat= 0.07190669384888476 \n",
      "acc for Psat= 0.1356763629656699 \n",
      "acc for optim= 0.20043873429919282\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.004247171804308891\n",
      "Loss on test= 0.005364519078284502\n",
      "acc for Lsat= 0.12928189026812711 \n",
      "acc for Psat= 0.16250086793055138 \n",
      "acc for optim= 0.16183128601147068\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.004278183449059725\n",
      "Loss on test= 0.005412768572568893\n",
      "acc for Lsat= 0.1438223712094542 \n",
      "acc for Psat= 0.18401016648082683 \n",
      "acc for optim= 0.18510130047151405\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.004161010961979628\n",
      "Loss on test= 0.0054704006761312485\n",
      "acc for Lsat= 0.1537710327215286 \n",
      "acc for Psat= 0.17652502624938884 \n",
      "acc for optim= 0.1804293179884553\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.004259237553924322\n",
      "Loss on test= 0.005609903950244188\n",
      "acc for Lsat= 0.10700694787212545 \n",
      "acc for Psat= 0.16241734029932153 \n",
      "acc for optim= 0.18610131501271907\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.0042501515708863735\n",
      "Loss on test= 0.00557883782312274\n",
      "acc for Lsat= 0.11661982035730034 \n",
      "acc for Psat= 0.13607704285014835 \n",
      "acc for optim= 0.18767400794766015\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.004174763336777687\n",
      "Loss on test= 0.005534579511731863\n",
      "acc for Lsat= 0.10760252601984474 \n",
      "acc for Psat= 0.172307109589585 \n",
      "acc for optim= 0.17430865060951975\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.004286738112568855\n",
      "Loss on test= 0.005866887979209423\n",
      "acc for Lsat= 0.14251801469880673 \n",
      "acc for Psat= 0.18909067451022565 \n",
      "acc for optim= 0.16254775521034995\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.004194905981421471\n",
      "Loss on test= 0.005422912538051605\n",
      "acc for Lsat= 0.12782127844790617 \n",
      "acc for Psat= 0.1599286845109115 \n",
      "acc for optim= 0.16512496059941542\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.004294972401112318\n",
      "Loss on test= 0.005604461766779423\n",
      "acc for Lsat= 0.08911263446013133 \n",
      "acc for Psat= 0.12908395524654123 \n",
      "acc for optim= 0.1952368209345473\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.004230615217238665\n",
      "Loss on test= 0.005645329598337412\n",
      "acc for Lsat= 0.09606522244090836 \n",
      "acc for Psat= 0.17783595756110218 \n",
      "acc for optim= 0.1654357315144605\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.004207279067486525\n",
      "Loss on test= 0.005446934141218662\n",
      "acc for Lsat= 0.12904271545509496 \n",
      "acc for Psat= 0.16879374430411392 \n",
      "acc for optim= 0.17807847478737435\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.004256341140717268\n",
      "Loss on test= 0.005039063282310963\n",
      "acc for Lsat= 0.14642938247157467 \n",
      "acc for Psat= 0.18084263822270763 \n",
      "acc for optim= 0.15831257299578283\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.004178844857960939\n",
      "Loss on test= 0.005614848341792822\n",
      "acc for Lsat= 0.12060140156083637 \n",
      "acc for Psat= 0.1386697029358604 \n",
      "acc for optim= 0.2007376498853167\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.004140566103160381\n",
      "Loss on test= 0.00554947042837739\n",
      "acc for Lsat= 0.08807335048913956 \n",
      "acc for Psat= 0.1855566773770584 \n",
      "acc for optim= 0.1831180326666476\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.00420199753716588\n",
      "Loss on test= 0.005313178990036249\n",
      "acc for Lsat= 0.11381741708868907 \n",
      "acc for Psat= 0.10710870430597828 \n",
      "acc for optim= 0.1921768483912779\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.004142114892601967\n",
      "Loss on test= 0.005852441769093275\n",
      "acc for Lsat= 0.09261990762833092 \n",
      "acc for Psat= 0.12741947712169754 \n",
      "acc for optim= 0.1922717574569914\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.004222870338708162\n",
      "Loss on test= 0.005502772517502308\n",
      "acc for Lsat= 0.13449076858038703 \n",
      "acc for Psat= 0.1691923032825192 \n",
      "acc for optim= 0.16969801651106942\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.004212081898003817\n",
      "Loss on test= 0.005563396494835615\n",
      "acc for Lsat= 0.09259444599350293 \n",
      "acc for Psat= 0.1690120142367151 \n",
      "acc for optim= 0.17212531715631485\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.004145910497754812\n",
      "Loss on test= 0.005725561641156673\n",
      "acc for Lsat= 0.1215622746773685 \n",
      "acc for Psat= 0.17920606919667786 \n",
      "acc for optim= 0.18019920183966556\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.004249865654855967\n",
      "Loss on test= 0.0053992122411727905\n",
      "acc for Lsat= 0.09417450655665663 \n",
      "acc for Psat= 0.16342765952059482 \n",
      "acc for optim= 0.17195520881149504\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.004251803737133741\n",
      "Loss on test= 0.0053930338472127914\n",
      "acc for Lsat= 0.07944232136813095 \n",
      "acc for Psat= 0.10816775918162118 \n",
      "acc for optim= 0.16809532672373784\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.0043734414502978325\n",
      "Loss on test= 0.005515763536095619\n",
      "acc for Lsat= 0.08425317629654375 \n",
      "acc for Psat= 0.14479998778551817 \n",
      "acc for optim= 0.17930284432239002\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.004267811309546232\n",
      "Loss on test= 0.005283830687403679\n",
      "acc for Lsat= 0.10679859017222447 \n",
      "acc for Psat= 0.16827100318753058 \n",
      "acc for optim= 0.18823694644702804\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.004160311073064804\n",
      "Loss on test= 0.005122942849993706\n",
      "acc for Lsat= 0.09713811512079297 \n",
      "acc for Psat= 0.10606670822663647 \n",
      "acc for optim= 0.21071236642698446\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.004202777519822121\n",
      "Loss on test= 0.0059733339585363865\n",
      "acc for Lsat= 0.10814456377799313 \n",
      "acc for Psat= 0.2008215594622824 \n",
      "acc for optim= 0.19690375086954898\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.004210669081658125\n",
      "Loss on test= 0.005362502299249172\n",
      "acc for Lsat= 0.0623095589172509 \n",
      "acc for Psat= 0.17178849917319086 \n",
      "acc for optim= 0.19920333723227182\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.004190817475318909\n",
      "Loss on test= 0.005322044249624014\n",
      "acc for Lsat= 0.0820192195630322 \n",
      "acc for Psat= 0.17670512704515 \n",
      "acc for optim= 0.17212255247351196\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.004116374533623457\n",
      "Loss on test= 0.00530437333509326\n",
      "acc for Lsat= 0.10504051513918158 \n",
      "acc for Psat= 0.1600387002237969 \n",
      "acc for optim= 0.187859366233978\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.00418194429948926\n",
      "Loss on test= 0.005632161628454924\n",
      "acc for Lsat= 0.09121537731132573 \n",
      "acc for Psat= 0.15991574386134744 \n",
      "acc for optim= 0.1838827415679892\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.004259792156517506\n",
      "Loss on test= 0.005379704758524895\n",
      "acc for Lsat= 0.12417143221116728 \n",
      "acc for Psat= 0.23836301805244553 \n",
      "acc for optim= 0.18112190088464153\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.00411775941029191\n",
      "Loss on test= 0.005458173342049122\n",
      "acc for Lsat= 0.123425024923765 \n",
      "acc for Psat= 0.13680334898850155 \n",
      "acc for optim= 0.1916310707779808\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.004099017009139061\n",
      "Loss on test= 0.005484340712428093\n",
      "acc for Lsat= 0.10245845311631759 \n",
      "acc for Psat= 0.165727111717893 \n",
      "acc for optim= 0.17214005673465888\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.0042616380378603935\n",
      "Loss on test= 0.0053472560830414295\n",
      "acc for Lsat= 0.10129044096296032 \n",
      "acc for Psat= 0.12907254729523426 \n",
      "acc for optim= 0.1619057075327469\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.004240039270371199\n",
      "Loss on test= 0.005443642847239971\n",
      "acc for Lsat= 0.10417259458659424 \n",
      "acc for Psat= 0.15509405686882222 \n",
      "acc for optim= 0.16300407874708375\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.004236700478941202\n",
      "Loss on test= 0.005399825517088175\n",
      "acc for Lsat= 0.12694605907866693 \n",
      "acc for Psat= 0.1425124662249194 \n",
      "acc for optim= 0.19662628012398878\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.004271341487765312\n",
      "Loss on test= 0.005410673096776009\n",
      "acc for Lsat= 0.09464658724351062 \n",
      "acc for Psat= 0.16815678061296543 \n",
      "acc for optim= 0.1504600416455004\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.004154613241553307\n",
      "Loss on test= 0.005322827957570553\n",
      "acc for Lsat= 0.10249423784100348 \n",
      "acc for Psat= 0.17230928194476292 \n",
      "acc for optim= 0.1875448047131714\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.004152670037001371\n",
      "Loss on test= 0.00544360838830471\n",
      "acc for Lsat= 0.10022816178388894 \n",
      "acc for Psat= 0.1553865425262807 \n",
      "acc for optim= 0.18828494277679259\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.00413824338465929\n",
      "Loss on test= 0.005345191340893507\n",
      "acc for Lsat= 0.12260459280676311 \n",
      "acc for Psat= 0.19700757538278899 \n",
      "acc for optim= 0.16693025496270922\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.004190462175756693\n",
      "Loss on test= 0.0056513394229114056\n",
      "acc for Lsat= 0.13238230707874107 \n",
      "acc for Psat= 0.17414270082695615 \n",
      "acc for optim= 0.18493977126975855\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.004252257756888866\n",
      "Loss on test= 0.00538170151412487\n",
      "acc for Lsat= 0.08294328175381654 \n",
      "acc for Psat= 0.14561240318127805 \n",
      "acc for optim= 0.16690998074611546\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.004224786534905434\n",
      "Loss on test= 0.005740595981478691\n",
      "acc for Lsat= 0.14033860229473147 \n",
      "acc for Psat= 0.17238275189366606 \n",
      "acc for optim= 0.1892028312625674\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.004124696832150221\n",
      "Loss on test= 0.0052558304741978645\n",
      "acc for Lsat= 0.11134020570251676 \n",
      "acc for Psat= 0.15235814441823298 \n",
      "acc for optim= 0.1994696824500958\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.004181575961410999\n",
      "Loss on test= 0.005185447633266449\n",
      "acc for Lsat= 0.10614246968179941 \n",
      "acc for Psat= 0.1382064785959503 \n",
      "acc for optim= 0.18171372285319698\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.0042138476856052876\n",
      "Loss on test= 0.005265304818749428\n",
      "acc for Lsat= 0.11742647416475746 \n",
      "acc for Psat= 0.17010712830556762 \n",
      "acc for optim= 0.17063068546768692\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.004205149132758379\n",
      "Loss on test= 0.0055260187946259975\n",
      "acc for Lsat= 0.09573041081118087 \n",
      "acc for Psat= 0.1833286357836591 \n",
      "acc for optim= 0.21039695468627745\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.004042851272970438\n",
      "Loss on test= 0.005526226479560137\n",
      "acc for Lsat= 0.11316086200531572 \n",
      "acc for Psat= 0.2246378674171865 \n",
      "acc for optim= 0.18760127243068483\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.004205777309834957\n",
      "Loss on test= 0.005242751445621252\n",
      "acc for Lsat= 0.10844574862211528 \n",
      "acc for Psat= 0.19811978129049143 \n",
      "acc for optim= 0.1917434933388399\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.004231464583426714\n",
      "Loss on test= 0.005356731358915567\n",
      "acc for Lsat= 0.0857860110182729 \n",
      "acc for Psat= 0.1753471044616567 \n",
      "acc for optim= 0.19808038137853146\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.004299945197999477\n",
      "Loss on test= 0.005656221881508827\n",
      "acc for Lsat= 0.09051142202224582 \n",
      "acc for Psat= 0.190835930303567 \n",
      "acc for optim= 0.17579284072336224\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.0042310114949941635\n",
      "Loss on test= 0.005534658674150705\n",
      "acc for Lsat= 0.1574788748079704 \n",
      "acc for Psat= 0.1661862852051854 \n",
      "acc for optim= 0.190260888918096\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.00411167461425066\n",
      "Loss on test= 0.005690762773156166\n",
      "acc for Lsat= 0.1245028628489106 \n",
      "acc for Psat= 0.1210212957424422 \n",
      "acc for optim= 0.19860497241218886\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.0041986689902842045\n",
      "Loss on test= 0.00569731742143631\n",
      "acc for Lsat= 0.09623446409952724 \n",
      "acc for Psat= 0.1279480196018186 \n",
      "acc for optim= 0.17807940916261739\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.0040004984475672245\n",
      "Loss on test= 0.005643232725560665\n",
      "acc for Lsat= 0.0861897598952055 \n",
      "acc for Psat= 0.1251579418571459 \n",
      "acc for optim= 0.20593492898883092\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.003950319718569517\n",
      "Loss on test= 0.005341269541531801\n",
      "acc for Lsat= 0.11786643565735883 \n",
      "acc for Psat= 0.18630346614453527 \n",
      "acc for optim= 0.15273731307954425\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.0042406837455928326\n",
      "Loss on test= 0.0052210320718586445\n",
      "acc for Lsat= 0.10127206581334273 \n",
      "acc for Psat= 0.2127842580796116 \n",
      "acc for optim= 0.16825712110019392\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.004124172497540712\n",
      "Loss on test= 0.00532910879701376\n",
      "acc for Lsat= 0.08046020968726629 \n",
      "acc for Psat= 0.1780155971646309 \n",
      "acc for optim= 0.18729488600123054\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.0040735239163041115\n",
      "Loss on test= 0.005408117547631264\n",
      "acc for Lsat= 0.08873656397271487 \n",
      "acc for Psat= 0.15306264482852486 \n",
      "acc for optim= 0.18789310689963815\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.004028778523206711\n",
      "Loss on test= 0.005633129272609949\n",
      "acc for Lsat= 0.12119650760562056 \n",
      "acc for Psat= 0.14941911722740364 \n",
      "acc for optim= 0.18542873735229173\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.004027809482067823\n",
      "Loss on test= 0.005710926838219166\n",
      "acc for Lsat= 0.1237940898604898 \n",
      "acc for Psat= 0.1809594662724218 \n",
      "acc for optim= 0.1801994458461801\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.004151930101215839\n",
      "Loss on test= 0.005240410100668669\n",
      "acc for Lsat= 0.07034102925616834 \n",
      "acc for Psat= 0.11880166582866675 \n",
      "acc for optim= 0.1691062869762795\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.004310033284127712\n",
      "Loss on test= 0.00546287652105093\n",
      "acc for Lsat= 0.08413481163895792 \n",
      "acc for Psat= 0.14281677411377636 \n",
      "acc for optim= 0.19837364223268297\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.004075845703482628\n",
      "Loss on test= 0.005085023120045662\n",
      "acc for Lsat= 0.09299717525330682 \n",
      "acc for Psat= 0.15012563040686977 \n",
      "acc for optim= 0.18418133144991267\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.004053972195833921\n",
      "Loss on test= 0.005920362193137407\n",
      "acc for Lsat= 0.08464036028211315 \n",
      "acc for Psat= 0.16617329242742723 \n",
      "acc for optim= 0.17777416322173345\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.004154270514845848\n",
      "Loss on test= 0.005613122135400772\n",
      "acc for Lsat= 0.09803646471765307 \n",
      "acc for Psat= 0.17146853688690397 \n",
      "acc for optim= 0.16860577455049175\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.0040675378404557705\n",
      "Loss on test= 0.005169368349015713\n",
      "acc for Lsat= 0.11799331801335534 \n",
      "acc for Psat= 0.1594264398639401 \n",
      "acc for optim= 0.17308103886898607\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.004038873594254255\n",
      "Loss on test= 0.005162304267287254\n",
      "acc for Lsat= 0.1179074564586497 \n",
      "acc for Psat= 0.13129889188955227 \n",
      "acc for optim= 0.1855663386070066\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.004187340382486582\n",
      "Loss on test= 0.0053503504022955894\n",
      "acc for Lsat= 0.13048847643141118 \n",
      "acc for Psat= 0.17996471385575002 \n",
      "acc for optim= 0.1791377910412848\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.004058811813592911\n",
      "Loss on test= 0.0057820603251457214\n",
      "acc for Lsat= 0.09580990242668325 \n",
      "acc for Psat= 0.15929786881638897 \n",
      "acc for optim= 0.19244503720094347\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.004126376938074827\n",
      "Loss on test= 0.005069805309176445\n",
      "acc for Lsat= 0.10719936385673161 \n",
      "acc for Psat= 0.16860897466540337 \n",
      "acc for optim= 0.20699066927449572\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.004066080320626497\n",
      "Loss on test= 0.005364544223994017\n",
      "acc for Lsat= 0.09513523605548674 \n",
      "acc for Psat= 0.1780774532817304 \n",
      "acc for optim= 0.20211764187034634\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.003945861477404833\n",
      "Loss on test= 0.005334323737770319\n",
      "acc for Lsat= 0.1617035214892692 \n",
      "acc for Psat= 0.2330970100334121 \n",
      "acc for optim= 0.18996886973683205\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.0039967321790754795\n",
      "Loss on test= 0.005173373501747847\n",
      "acc for Lsat= 0.09841222344483766 \n",
      "acc for Psat= 0.2222786233243015 \n",
      "acc for optim= 0.18505845125764608\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.0040452261455357075\n",
      "Loss on test= 0.005505042150616646\n",
      "acc for Lsat= 0.11917802293060555 \n",
      "acc for Psat= 0.17274261359125376 \n",
      "acc for optim= 0.2090503269703024\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.004110835026949644\n",
      "Loss on test= 0.005381705239415169\n",
      "acc for Lsat= 0.09197270699466269 \n",
      "acc for Psat= 0.1214640337922093 \n",
      "acc for optim= 0.17839096781487265\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.0040578776970505714\n",
      "Loss on test= 0.006006008014082909\n",
      "acc for Lsat= 0.11733045656647947 \n",
      "acc for Psat= 0.1866199674291743 \n",
      "acc for optim= 0.16272024261868662\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.004110962618142366\n",
      "Loss on test= 0.005449060816317797\n",
      "acc for Lsat= 0.11929864627826545 \n",
      "acc for Psat= 0.1818115659795391 \n",
      "acc for optim= 0.17204634317507347\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.00407335814088583\n",
      "Loss on test= 0.005046340636909008\n",
      "acc for Lsat= 0.09114605353938209 \n",
      "acc for Psat= 0.18879849732749993 \n",
      "acc for optim= 0.19500758569403034\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.0041026766411960125\n",
      "Loss on test= 0.0051931459456682205\n",
      "acc for Lsat= 0.08565199554302833 \n",
      "acc for Psat= 0.1501878215931356 \n",
      "acc for optim= 0.1814000022908052\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.004149118438363075\n",
      "Loss on test= 0.005266503430902958\n",
      "acc for Lsat= 0.0761916787079018 \n",
      "acc for Psat= 0.1980989436722464 \n",
      "acc for optim= 0.1560498189711426\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.004156326409429312\n",
      "Loss on test= 0.005534913390874863\n",
      "acc for Lsat= 0.07769795170881683 \n",
      "acc for Psat= 0.14283263927791268 \n",
      "acc for optim= 0.20094198019554219\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.004064552951604128\n",
      "Loss on test= 0.00556948920711875\n",
      "acc for Lsat= 0.08486239715582794 \n",
      "acc for Psat= 0.18244766850127941 \n",
      "acc for optim= 0.19379292888980773\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.003943454008549452\n",
      "Loss on test= 0.005286881700158119\n",
      "acc for Lsat= 0.10233588909937276 \n",
      "acc for Psat= 0.14580473733238047 \n",
      "acc for optim= 0.15958820117844474\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.0039702774956822395\n",
      "Loss on test= 0.005273954942822456\n",
      "acc for Lsat= 0.11013883859333065 \n",
      "acc for Psat= 0.13401362131440286 \n",
      "acc for optim= 0.19796476994330683\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.004008034244179726\n",
      "Loss on test= 0.005324867554008961\n",
      "acc for Lsat= 0.1347374557517469 \n",
      "acc for Psat= 0.1665103264256484 \n",
      "acc for optim= 0.18677789459211958\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.004087846260517836\n",
      "Loss on test= 0.005362591706216335\n",
      "acc for Lsat= 0.10371493620591031 \n",
      "acc for Psat= 0.18790809898119834 \n",
      "acc for optim= 0.2070191447209153\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.004265018738806248\n",
      "Loss on test= 0.005323268938809633\n",
      "acc for Lsat= 0.11319917713181996 \n",
      "acc for Psat= 0.1443909341469407 \n",
      "acc for optim= 0.1957949831460913\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.003978550899773836\n",
      "Loss on test= 0.005547271575778723\n",
      "acc for Lsat= 0.12205692742847735 \n",
      "acc for Psat= 0.19742485042661428 \n",
      "acc for optim= 0.18247542305228612\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.00402172701433301\n",
      "Loss on test= 0.00525967963039875\n",
      "acc for Lsat= 0.11965593610269327 \n",
      "acc for Psat= 0.19840722963757193 \n",
      "acc for optim= 0.17210427444014284\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.004020240623503923\n",
      "Loss on test= 0.005370665341615677\n",
      "acc for Lsat= 0.13120132526698094 \n",
      "acc for Psat= 0.1538561543242799 \n",
      "acc for optim= 0.19290099655174547\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.003895742353051901\n",
      "Loss on test= 0.005147392395883799\n",
      "acc for Lsat= 0.08427416985957986 \n",
      "acc for Psat= 0.14597135368320677 \n",
      "acc for optim= 0.19450775866344985\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.00403607077896595\n",
      "Loss on test= 0.005229420494288206\n",
      "acc for Lsat= 0.060034697762198955 \n",
      "acc for Psat= 0.12575502465996477 \n",
      "acc for optim= 0.1905981070350309\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.004167999140918255\n",
      "Loss on test= 0.0056848470121622086\n",
      "acc for Lsat= 0.07801535420326723 \n",
      "acc for Psat= 0.15716939623881546 \n",
      "acc for optim= 0.1856046739137835\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.004227275028824806\n",
      "Loss on test= 0.005221828818321228\n",
      "acc for Lsat= 0.11744872159841988 \n",
      "acc for Psat= 0.17157522102610934 \n",
      "acc for optim= 0.16456300817016098\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.004033595323562622\n",
      "Loss on test= 0.0052719092927873135\n",
      "acc for Lsat= 0.1268570527123908 \n",
      "acc for Psat= 0.20732518109596437 \n",
      "acc for optim= 0.18808541907411483\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.00409267982468009\n",
      "Loss on test= 0.005329234525561333\n",
      "acc for Lsat= 0.12939257044086439 \n",
      "acc for Psat= 0.16573392768946682 \n",
      "acc for optim= 0.18085434784491858\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.0040490408428013325\n",
      "Loss on test= 0.005521868821233511\n",
      "acc for Lsat= 0.10550409168515923 \n",
      "acc for Psat= 0.14899917367923385 \n",
      "acc for optim= 0.18691192919181454\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.00397309847176075\n",
      "Loss on test= 0.005358219612389803\n",
      "acc for Lsat= 0.10284478098361029 \n",
      "acc for Psat= 0.1254950307516588 \n",
      "acc for optim= 0.20657609639844546\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.0040020933374762535\n",
      "Loss on test= 0.005240329075604677\n",
      "acc for Lsat= 0.13339061827476448 \n",
      "acc for Psat= 0.18152562519794124 \n",
      "acc for optim= 0.1913197000717951\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.004056048113852739\n",
      "Loss on test= 0.005274577531963587\n",
      "acc for Lsat= 0.084177144156355 \n",
      "acc for Psat= 0.16149905706859297 \n",
      "acc for optim= 0.17470095187632573\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.004076039418578148\n",
      "Loss on test= 0.005429529584944248\n",
      "acc for Lsat= 0.11547792490778698 \n",
      "acc for Psat= 0.15781031673153242 \n",
      "acc for optim= 0.17476059222179982\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.004113605711609125\n",
      "Loss on test= 0.0051645440980792046\n",
      "acc for Lsat= 0.09131796689083178 \n",
      "acc for Psat= 0.19475301055030692 \n",
      "acc for optim= 0.19347509131249455\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.004015768878161907\n",
      "Loss on test= 0.005544490646570921\n",
      "acc for Lsat= 0.09716551223148902 \n",
      "acc for Psat= 0.11914136171496163 \n",
      "acc for optim= 0.18242664413992316\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.003906973171979189\n",
      "Loss on test= 0.005322630051523447\n",
      "acc for Lsat= 0.1283937527073754 \n",
      "acc for Psat= 0.14995863940566778 \n",
      "acc for optim= 0.17741034521410862\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.003922168631106615\n",
      "Loss on test= 0.005282189697027206\n",
      "acc for Lsat= 0.11506249828057157 \n",
      "acc for Psat= 0.18196154209888643 \n",
      "acc for optim= 0.19487391557130548\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.00410634558647871\n",
      "Loss on test= 0.0053867450915277\n",
      "acc for Lsat= 0.09903923146581899 \n",
      "acc for Psat= 0.17086220504198638 \n",
      "acc for optim= 0.16202183978425133\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.003974884282797575\n",
      "Loss on test= 0.005348946899175644\n",
      "acc for Lsat= 0.10622159363184538 \n",
      "acc for Psat= 0.18815650464966893 \n",
      "acc for optim= 0.17916386243369845\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.004060857463628054\n",
      "Loss on test= 0.00534225394949317\n",
      "acc for Lsat= 0.0924850922698776 \n",
      "acc for Psat= 0.18629009675027597 \n",
      "acc for optim= 0.16943629805205596\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.0039166538044810295\n",
      "Loss on test= 0.005073705688118935\n",
      "acc for Lsat= 0.10283010652185315 \n",
      "acc for Psat= 0.1731806880949686 \n",
      "acc for optim= 0.18458095270519456\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.003835981246083975\n",
      "Loss on test= 0.005479561630636454\n",
      "acc for Lsat= 0.1079040031052298 \n",
      "acc for Psat= 0.16995635708897477 \n",
      "acc for optim= 0.20385047079374394\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.003931243438273668\n",
      "Loss on test= 0.0058171097189188\n",
      "acc for Lsat= 0.09803393358985583 \n",
      "acc for Psat= 0.12318797280184096 \n",
      "acc for optim= 0.17663462780829933\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.004043382592499256\n",
      "Loss on test= 0.005137300118803978\n",
      "acc for Lsat= 0.11567114074973182 \n",
      "acc for Psat= 0.15784756852210396 \n",
      "acc for optim= 0.21672242657384938\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.004060034174472094\n",
      "Loss on test= 0.005303981248289347\n",
      "acc for Lsat= 0.13438404930962455 \n",
      "acc for Psat= 0.17550004035648373 \n",
      "acc for optim= 0.19060984440147877\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.003798563266173005\n",
      "Loss on test= 0.005717520602047443\n",
      "acc for Lsat= 0.1415034634216378 \n",
      "acc for Psat= 0.19208089593384 \n",
      "acc for optim= 0.19148654506231347\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.004046401008963585\n",
      "Loss on test= 0.005358391907066107\n",
      "acc for Lsat= 0.08911848994385865 \n",
      "acc for Psat= 0.1191736491293543 \n",
      "acc for optim= 0.19606963048378626\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.004074667114764452\n",
      "Loss on test= 0.0054946355521678925\n",
      "acc for Lsat= 0.08074324425413376 \n",
      "acc for Psat= 0.15092411626958185 \n",
      "acc for optim= 0.21510120558862886\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.003966341260820627\n",
      "Loss on test= 0.0058080232702195644\n",
      "acc for Lsat= 0.1147225705596308 \n",
      "acc for Psat= 0.13263614434334967 \n",
      "acc for optim= 0.16796749398215777\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.004086486995220184\n",
      "Loss on test= 0.005523000378161669\n",
      "acc for Lsat= 0.1369022831527723 \n",
      "acc for Psat= 0.18452736054961053 \n",
      "acc for optim= 0.1781826229998842\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.004015221726149321\n",
      "Loss on test= 0.005362159572541714\n",
      "acc for Lsat= 0.12597571059854495 \n",
      "acc for Psat= 0.18128300683262447 \n",
      "acc for optim= 0.1664120919174618\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.004054352641105652\n",
      "Loss on test= 0.00534030282869935\n",
      "acc for Lsat= 0.10158381025798412 \n",
      "acc for Psat= 0.16463088751253155 \n",
      "acc for optim= 0.1712668280945056\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.004044953268021345\n",
      "Loss on test= 0.005443746689707041\n",
      "acc for Lsat= 0.10828731591916746 \n",
      "acc for Psat= 0.15534105307112137 \n",
      "acc for optim= 0.1753257381885002\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.0039972965605556965\n",
      "Loss on test= 0.005536768119782209\n",
      "acc for Lsat= 0.1463106577672685 \n",
      "acc for Psat= 0.18700729564039242 \n",
      "acc for optim= 0.18336190663588545\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.004002349451184273\n",
      "Loss on test= 0.006044845096766949\n",
      "acc for Lsat= 0.11551012466144231 \n",
      "acc for Psat= 0.14231838593776855 \n",
      "acc for optim= 0.1779852258041501\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.004043137189000845\n",
      "Loss on test= 0.005578264128416777\n",
      "acc for Lsat= 0.1149823565243019 \n",
      "acc for Psat= 0.2021795201451621 \n",
      "acc for optim= 0.1841613625486692\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.003963444847613573\n",
      "Loss on test= 0.005443447735160589\n",
      "acc for Lsat= 0.08649651437169975 \n",
      "acc for Psat= 0.13026875386842424 \n",
      "acc for optim= 0.18128226692270902\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.004006302449852228\n",
      "Loss on test= 0.005255143623799086\n",
      "acc for Lsat= 0.10803313466668543 \n",
      "acc for Psat= 0.17390722336454523 \n",
      "acc for optim= 0.18345546681019995\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.003982042893767357\n",
      "Loss on test= 0.0053086960688233376\n",
      "acc for Lsat= 0.0965888233234485 \n",
      "acc for Psat= 0.18376901962943115 \n",
      "acc for optim= 0.18763804166681236\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.0040020570158958435\n",
      "Loss on test= 0.0053783562034368515\n",
      "acc for Lsat= 0.12409512574474017 \n",
      "acc for Psat= 0.13508224397406188 \n",
      "acc for optim= 0.1840059823460049\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.004076882265508175\n",
      "Loss on test= 0.0052663530223071575\n",
      "acc for Lsat= 0.0892082227833776 \n",
      "acc for Psat= 0.16696278585327995 \n",
      "acc for optim= 0.17477938768246937\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.003952361177653074\n",
      "Loss on test= 0.005064638331532478\n",
      "acc for Lsat= 0.135967279454538 \n",
      "acc for Psat= 0.1681143596716639 \n",
      "acc for optim= 0.16319820853985018\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.0038942135870456696\n",
      "Loss on test= 0.005799769423902035\n",
      "acc for Lsat= 0.10424612243009 \n",
      "acc for Psat= 0.19737857120991167 \n",
      "acc for optim= 0.2276035552430484\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.00390780670568347\n",
      "Loss on test= 0.0052218385972082615\n",
      "acc for Lsat= 0.10102467578447734 \n",
      "acc for Psat= 0.1391050936266159 \n",
      "acc for optim= 0.18106567085811143\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.003938200417906046\n",
      "Loss on test= 0.005629354156553745\n",
      "acc for Lsat= 0.09617505413997504 \n",
      "acc for Psat= 0.13112276357909045 \n",
      "acc for optim= 0.1767896748561826\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.003924764692783356\n",
      "Loss on test= 0.005664316937327385\n",
      "acc for Lsat= 0.08806078800343028 \n",
      "acc for Psat= 0.1524875285103917 \n",
      "acc for optim= 0.17544673245477801\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.004029414150863886\n",
      "Loss on test= 0.0052507184445858\n",
      "acc for Lsat= 0.12029583897027704 \n",
      "acc for Psat= 0.17171732031015885 \n",
      "acc for optim= 0.16483988856068915\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.003968209959566593\n",
      "Loss on test= 0.00549800880253315\n",
      "acc for Lsat= 0.08440730480813524 \n",
      "acc for Psat= 0.18026780448336568 \n",
      "acc for optim= 0.1990623123322924\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.003970214165747166\n",
      "Loss on test= 0.005110283847898245\n",
      "acc for Lsat= 0.09342546067718002 \n",
      "acc for Psat= 0.1323540098965168 \n",
      "acc for optim= 0.19746085732347435\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.00412715645506978\n",
      "Loss on test= 0.005667604506015778\n",
      "acc for Lsat= 0.07608732777751154 \n",
      "acc for Psat= 0.16673048425258863 \n",
      "acc for optim= 0.17269498290908006\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.0040519083850085735\n",
      "Loss on test= 0.005407276097685099\n",
      "acc for Lsat= 0.1346021897883879 \n",
      "acc for Psat= 0.15313297375622723 \n",
      "acc for optim= 0.17893212847411633\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.0038687512278556824\n",
      "Loss on test= 0.005549236666411161\n",
      "acc for Lsat= 0.10387458176248604 \n",
      "acc for Psat= 0.14284780942317513 \n",
      "acc for optim= 0.1778968965453613\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.003798122750595212\n",
      "Loss on test= 0.005414910614490509\n",
      "acc for Lsat= 0.11514636874198914 \n",
      "acc for Psat= 0.19801452021218008 \n",
      "acc for optim= 0.14419528314222893\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.0037438252475112677\n",
      "Loss on test= 0.005128310993313789\n",
      "acc for Lsat= 0.06986169418733981 \n",
      "acc for Psat= 0.15316155770172676 \n",
      "acc for optim= 0.15931576600350025\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.0039013668429106474\n",
      "Loss on test= 0.005353424232453108\n",
      "acc for Lsat= 0.11797624953194624 \n",
      "acc for Psat= 0.16982665300990143 \n",
      "acc for optim= 0.18076426991158062\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.003943704999983311\n",
      "Loss on test= 0.005535706877708435\n",
      "acc for Lsat= 0.10875055526978233 \n",
      "acc for Psat= 0.14591121999546885 \n",
      "acc for optim= 0.19631287512472934\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.0038248030468821526\n",
      "Loss on test= 0.0055045573972165585\n",
      "acc for Lsat= 0.1358317888031403 \n",
      "acc for Psat= 0.12478668672136134 \n",
      "acc for optim= 0.1911146134758989\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.003945414908230305\n",
      "Loss on test= 0.005539275240153074\n",
      "acc for Lsat= 0.13002013466838333 \n",
      "acc for Psat= 0.19673129750622642 \n",
      "acc for optim= 0.18652112730261353\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.003969424869865179\n",
      "Loss on test= 0.005517718382179737\n",
      "acc for Lsat= 0.10239674893414809 \n",
      "acc for Psat= 0.17183557276924452 \n",
      "acc for optim= 0.1851368411961529\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.003826780477538705\n",
      "Loss on test= 0.005442919675260782\n",
      "acc for Lsat= 0.10205357485554284 \n",
      "acc for Psat= 0.14685943257063627 \n",
      "acc for optim= 0.2012484763852424\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.0038810602854937315\n",
      "Loss on test= 0.005592375993728638\n",
      "acc for Lsat= 0.0986511169725822 \n",
      "acc for Psat= 0.16284565270567933 \n",
      "acc for optim= 0.2062035128991637\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.0039541455917060375\n",
      "Loss on test= 0.005673352163285017\n",
      "acc for Lsat= 0.15277184038940403 \n",
      "acc for Psat= 0.17685425771762514 \n",
      "acc for optim= 0.21403056041647991\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.003803814761340618\n",
      "Loss on test= 0.005436251871287823\n",
      "acc for Lsat= 0.09775187700223695 \n",
      "acc for Psat= 0.13904125144472346 \n",
      "acc for optim= 0.1584534380171034\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.003873996203765273\n",
      "Loss on test= 0.0053518470376729965\n",
      "acc for Lsat= 0.09792159662336214 \n",
      "acc for Psat= 0.14743049546248382 \n",
      "acc for optim= 0.1830769831625124\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.0038636287208646536\n",
      "Loss on test= 0.005334534682333469\n",
      "acc for Lsat= 0.10536553442943841 \n",
      "acc for Psat= 0.149176769838151 \n",
      "acc for optim= 0.16296240552845928\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.00394393689930439\n",
      "Loss on test= 0.005234457086771727\n",
      "acc for Lsat= 0.12410796992480755 \n",
      "acc for Psat= 0.14828493422828615 \n",
      "acc for optim= 0.19340924070113236\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.0039008057210594416\n",
      "Loss on test= 0.005586078856140375\n",
      "acc for Lsat= 0.09301634629567464 \n",
      "acc for Psat= 0.13183593455081186 \n",
      "acc for optim= 0.19015575746177799\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.0038767217192798853\n",
      "Loss on test= 0.005220804829150438\n",
      "acc for Lsat= 0.10455905665488292 \n",
      "acc for Psat= 0.1733911782503128 \n",
      "acc for optim= 0.17917124652821156\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.003794163465499878\n",
      "Loss on test= 0.0055555496364831924\n",
      "acc for Lsat= 0.12714826750258604 \n",
      "acc for Psat= 0.1396542751851181 \n",
      "acc for optim= 0.21315684955981043\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.003917684778571129\n",
      "Loss on test= 0.005429469048976898\n",
      "acc for Lsat= 0.11793683536881064 \n",
      "acc for Psat= 0.22096676443470642 \n",
      "acc for optim= 0.1734450652471019\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.0038938724901527166\n",
      "Loss on test= 0.005471548531204462\n",
      "acc for Lsat= 0.07372192308927576 \n",
      "acc for Psat= 0.13106717365897363 \n",
      "acc for optim= 0.20546288695186377\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.0037167409900575876\n",
      "Loss on test= 0.005532223265618086\n",
      "acc for Lsat= 0.12526420157195794 \n",
      "acc for Psat= 0.16986674012150615 \n",
      "acc for optim= 0.20096723991446197\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.0040070791728794575\n",
      "Loss on test= 0.005620745941996574\n",
      "acc for Lsat= 0.06872389843273494 \n",
      "acc for Psat= 0.21258641784596774 \n",
      "acc for optim= 0.19263729837257415\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.003840532386675477\n",
      "Loss on test= 0.005540008191019297\n",
      "acc for Lsat= 0.08657844832891391 \n",
      "acc for Psat= 0.1505609068295194 \n",
      "acc for optim= 0.18389830246774685\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.0038573609199374914\n",
      "Loss on test= 0.005099169909954071\n",
      "acc for Lsat= 0.10160846969423194 \n",
      "acc for Psat= 0.2175786985963997 \n",
      "acc for optim= 0.19943366908571786\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.0038722679018974304\n",
      "Loss on test= 0.005295971408486366\n",
      "acc for Lsat= 0.09133188792879486 \n",
      "acc for Psat= 0.1695227589354747 \n",
      "acc for optim= 0.19303867523558438\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.003924344200640917\n",
      "Loss on test= 0.005346214398741722\n",
      "acc for Lsat= 0.1141877305538704 \n",
      "acc for Psat= 0.19310649587876266 \n",
      "acc for optim= 0.17386833899137047\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.0037829203065484762\n",
      "Loss on test= 0.005181100219488144\n",
      "acc for Lsat= 0.10104704963871175 \n",
      "acc for Psat= 0.2055197582554279 \n",
      "acc for optim= 0.2075635012653139\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.003992251120507717\n",
      "Loss on test= 0.005534648429602385\n",
      "acc for Lsat= 0.09844707118140326 \n",
      "acc for Psat= 0.13251648124100435 \n",
      "acc for optim= 0.19198155185828605\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.0037947846576571465\n",
      "Loss on test= 0.005242003593593836\n",
      "acc for Lsat= 0.09681079537969911 \n",
      "acc for Psat= 0.10093660327968085 \n",
      "acc for optim= 0.19027513169890475\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.0038877674378454685\n",
      "Loss on test= 0.005308423191308975\n",
      "acc for Lsat= 0.12171195907932189 \n",
      "acc for Psat= 0.15654463474897462 \n",
      "acc for optim= 0.20811338619225556\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.003917789086699486\n",
      "Loss on test= 0.005506101064383984\n",
      "acc for Lsat= 0.11899552937312466 \n",
      "acc for Psat= 0.17946043413960272 \n",
      "acc for optim= 0.18352623842656612\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.003940250724554062\n",
      "Loss on test= 0.005502169951796532\n",
      "acc for Lsat= 0.11485691016746892 \n",
      "acc for Psat= 0.1798626740152637 \n",
      "acc for optim= 0.21716363474519718\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.004007027484476566\n",
      "Loss on test= 0.00538147846236825\n",
      "acc for Lsat= 0.09034647037171656 \n",
      "acc for Psat= 0.15362824682233622 \n",
      "acc for optim= 0.21340009890910652\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.003933705389499664\n",
      "Loss on test= 0.005483343731611967\n",
      "acc for Lsat= 0.17699418247987828 \n",
      "acc for Psat= 0.22828051903181606 \n",
      "acc for optim= 0.17504910074381363\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.003785440232604742\n",
      "Loss on test= 0.005356795620173216\n",
      "acc for Lsat= 0.062193012861017555 \n",
      "acc for Psat= 0.1469010754566019 \n",
      "acc for optim= 0.18876008026482952\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.003867528634145856\n",
      "Loss on test= 0.005237429868429899\n",
      "acc for Lsat= 0.10815035287911694 \n",
      "acc for Psat= 0.14434847784125143 \n",
      "acc for optim= 0.15631917610557544\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.003838106757029891\n",
      "Loss on test= 0.005317008122801781\n",
      "acc for Lsat= 0.07937314764906962 \n",
      "acc for Psat= 0.21662116226636702 \n",
      "acc for optim= 0.18182461253470844\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.0037322482094168663\n",
      "Loss on test= 0.005739552900195122\n",
      "acc for Lsat= 0.1278720267323984 \n",
      "acc for Psat= 0.12283582986694658 \n",
      "acc for optim= 0.1781822738962041\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.0038300054147839546\n",
      "Loss on test= 0.0056326077319681644\n",
      "acc for Lsat= 0.13251890174837577 \n",
      "acc for Psat= 0.1421065622319778 \n",
      "acc for optim= 0.1768801361322403\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.003847654676064849\n",
      "Loss on test= 0.00530881667509675\n",
      "acc for Lsat= 0.11329344176273379 \n",
      "acc for Psat= 0.1632858746452257 \n",
      "acc for optim= 0.18074264408399662\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.0038634196389466524\n",
      "Loss on test= 0.005515512079000473\n",
      "acc for Lsat= 0.12111508137443 \n",
      "acc for Psat= 0.14665111143969828 \n",
      "acc for optim= 0.15016141991751888\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.0038240381982177496\n",
      "Loss on test= 0.005231993272900581\n",
      "acc for Lsat= 0.08243352917229964 \n",
      "acc for Psat= 0.15570928684125343 \n",
      "acc for optim= 0.20651089369008938\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.003863211954012513\n",
      "Loss on test= 0.00553923798725009\n",
      "acc for Lsat= 0.09490220445311731 \n",
      "acc for Psat= 0.18881137927787173 \n",
      "acc for optim= 0.18658014883597693\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.003679749323055148\n",
      "Loss on test= 0.005488696973770857\n",
      "acc for Lsat= 0.13304662379798377 \n",
      "acc for Psat= 0.18672953251128396 \n",
      "acc for optim= 0.19987172240184414\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.003780580125749111\n",
      "Loss on test= 0.0057657575234770775\n",
      "acc for Lsat= 0.07507134016810192 \n",
      "acc for Psat= 0.169909350367056 \n",
      "acc for optim= 0.1905160733602113\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.003863207995891571\n",
      "Loss on test= 0.005774615332484245\n",
      "acc for Lsat= 0.12422126676473352 \n",
      "acc for Psat= 0.19248739485111502 \n",
      "acc for optim= 0.18082303725208881\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.003911715000867844\n",
      "Loss on test= 0.005290858447551727\n",
      "acc for Lsat= 0.1079144078410334 \n",
      "acc for Psat= 0.15255805975498837 \n",
      "acc for optim= 0.1672368864755198\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.00381394918076694\n",
      "Loss on test= 0.005522285122424364\n",
      "acc for Lsat= 0.06698351102467212 \n",
      "acc for Psat= 0.14184359269630578 \n",
      "acc for optim= 0.1729135650417043\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.0037110403645783663\n",
      "Loss on test= 0.004968786612153053\n",
      "acc for Lsat= 0.09991685311413473 \n",
      "acc for Psat= 0.18606964237470594 \n",
      "acc for optim= 0.17724727045020294\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.00388908083550632\n",
      "Loss on test= 0.0054054055362939835\n",
      "acc for Lsat= 0.12803111288101515 \n",
      "acc for Psat= 0.1415244753782948 \n",
      "acc for optim= 0.18403211241174075\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.003701288951560855\n",
      "Loss on test= 0.005367136560380459\n",
      "acc for Lsat= 0.08333434531879094 \n",
      "acc for Psat= 0.18056429824274448 \n",
      "acc for optim= 0.20212483018015823\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.003836436429992318\n",
      "Loss on test= 0.004880346357822418\n",
      "acc for Lsat= 0.08432025387365785 \n",
      "acc for Psat= 0.12694249359062976 \n",
      "acc for optim= 0.17240554373711348\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.0037827109917998314\n",
      "Loss on test= 0.005497680976986885\n",
      "acc for Lsat= 0.0999974743463099 \n",
      "acc for Psat= 0.1606795551100125 \n",
      "acc for optim= 0.18398282216447923\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.0037607578560709953\n",
      "Loss on test= 0.005157472565770149\n",
      "acc for Lsat= 0.12040307031323512 \n",
      "acc for Psat= 0.18067323750195405 \n",
      "acc for optim= 0.19147322729178187\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.0038437729235738516\n",
      "Loss on test= 0.005495755467563868\n",
      "acc for Lsat= 0.0764162871055305 \n",
      "acc for Psat= 0.16096018803202444 \n",
      "acc for optim= 0.19873418083039318\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.0038616149686276913\n",
      "Loss on test= 0.005365895107388496\n",
      "acc for Lsat= 0.08248573751350502 \n",
      "acc for Psat= 0.13145388973255953 \n",
      "acc for optim= 0.20093317650672463\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.0039128754287958145\n",
      "Loss on test= 0.005672610830515623\n",
      "acc for Lsat= 0.07867538923811582 \n",
      "acc for Psat= 0.1636321002410518 \n",
      "acc for optim= 0.20066364745919904\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.00389851164072752\n",
      "Loss on test= 0.0056516192853450775\n",
      "acc for Lsat= 0.09718577267550346 \n",
      "acc for Psat= 0.19744878039798802 \n",
      "acc for optim= 0.18541112257581618\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.0038491101004183292\n",
      "Loss on test= 0.005329089239239693\n",
      "acc for Lsat= 0.11068456513910657 \n",
      "acc for Psat= 0.17727349807197848 \n",
      "acc for optim= 0.18142018810289706\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.0037434289697557688\n",
      "Loss on test= 0.005633335094898939\n",
      "acc for Lsat= 0.1444348796374268 \n",
      "acc for Psat= 0.18376201818076274 \n",
      "acc for optim= 0.210003312677145\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.0037375232204794884\n",
      "Loss on test= 0.00577619718387723\n",
      "acc for Lsat= 0.11553131032431135 \n",
      "acc for Psat= 0.18812494393852022 \n",
      "acc for optim= 0.16734748820049894\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.003771805902943015\n",
      "Loss on test= 0.005542384460568428\n",
      "acc for Lsat= 0.09664814717446764 \n",
      "acc for Psat= 0.16315483125961489 \n",
      "acc for optim= 0.20414425225721466\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.0038481608498841524\n",
      "Loss on test= 0.00535963661968708\n",
      "acc for Lsat= 0.10469334388876127 \n",
      "acc for Psat= 0.2039066543802619 \n",
      "acc for optim= 0.19255502045982414\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.0037956079468131065\n",
      "Loss on test= 0.005620700307190418\n",
      "acc for Lsat= 0.06465845888144234 \n",
      "acc for Psat= 0.15521767682993312 \n",
      "acc for optim= 0.19100930738366312\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.0038387314416468143\n",
      "Loss on test= 0.005366239231079817\n",
      "acc for Lsat= 0.07967779609478182 \n",
      "acc for Psat= 0.13558577068357003 \n",
      "acc for optim= 0.19156311354082492\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.003726246766746044\n",
      "Loss on test= 0.005340726114809513\n",
      "acc for Lsat= 0.1263185862917453 \n",
      "acc for Psat= 0.16115268050796455 \n",
      "acc for optim= 0.18757312442176044\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.003958185203373432\n",
      "Loss on test= 0.00556501979008317\n",
      "acc for Lsat= 0.08267162716947496 \n",
      "acc for Psat= 0.1599179228586662 \n",
      "acc for optim= 0.18368745916005638\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.0037077998276799917\n",
      "Loss on test= 0.005247827619314194\n",
      "acc for Lsat= 0.10390312447109157 \n",
      "acc for Psat= 0.15459304797049198 \n",
      "acc for optim= 0.17217430161933103\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.003902222029864788\n",
      "Loss on test= 0.0054552904330194\n",
      "acc for Lsat= 0.09318666848250562 \n",
      "acc for Psat= 0.1469572503378408 \n",
      "acc for optim= 0.19100426986632454\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.0038116753567010164\n",
      "Loss on test= 0.0055944789201021194\n",
      "acc for Lsat= 0.08925667746613423 \n",
      "acc for Psat= 0.1541132963547069 \n",
      "acc for optim= 0.1887575472291145\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.003947125747799873\n",
      "Loss on test= 0.00545460544526577\n",
      "acc for Lsat= 0.12334247471557723 \n",
      "acc for Psat= 0.1658604290957252 \n",
      "acc for optim= 0.18663387704226705\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.003743054810911417\n",
      "Loss on test= 0.00545341894030571\n",
      "acc for Lsat= 0.10863540135324001 \n",
      "acc for Psat= 0.18272782320855185 \n",
      "acc for optim= 0.22588342086722454\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.003828700864687562\n",
      "Loss on test= 0.005739560350775719\n",
      "acc for Lsat= 0.11684145354148415 \n",
      "acc for Psat= 0.188648977316916 \n",
      "acc for optim= 0.21528305320276153\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.0038627691101282835\n",
      "Loss on test= 0.005381165072321892\n",
      "acc for Lsat= 0.0924806108361938 \n",
      "acc for Psat= 0.14906347346388632 \n",
      "acc for optim= 0.16813736760781872\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.003859234508126974\n",
      "Loss on test= 0.005226018372923136\n",
      "acc for Lsat= 0.08852040043307675 \n",
      "acc for Psat= 0.11888338022658394 \n",
      "acc for optim= 0.1803543832567003\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.003753488417714834\n",
      "Loss on test= 0.0056394850835204124\n",
      "acc for Lsat= 0.10306613142084745 \n",
      "acc for Psat= 0.17069425920231474 \n",
      "acc for optim= 0.1668713947551118\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.0036943762097507715\n",
      "Loss on test= 0.005678533110767603\n",
      "acc for Lsat= 0.09388558863429353 \n",
      "acc for Psat= 0.19734120606962177 \n",
      "acc for optim= 0.19746879928020966\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.0037898258306086063\n",
      "Loss on test= 0.005578418727964163\n",
      "acc for Lsat= 0.11592790543929571 \n",
      "acc for Psat= 0.19173263313455713 \n",
      "acc for optim= 0.184058171722831\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.0038136409129947424\n",
      "Loss on test= 0.004830012563616037\n",
      "acc for Lsat= 0.07886118152075344 \n",
      "acc for Psat= 0.18827174914379916 \n",
      "acc for optim= 0.1632703412793085\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.003646621247753501\n",
      "Loss on test= 0.005317241884768009\n",
      "acc for Lsat= 0.1541424229120215 \n",
      "acc for Psat= 0.17764206597995427 \n",
      "acc for optim= 0.1737094171759155\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.0038036792539060116\n",
      "Loss on test= 0.005739640444517136\n",
      "acc for Lsat= 0.14716446679085493 \n",
      "acc for Psat= 0.13531934971817666 \n",
      "acc for optim= 0.19409431361903748\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.003751961747184396\n",
      "Loss on test= 0.005315327551215887\n",
      "acc for Lsat= 0.08380899059961343 \n",
      "acc for Psat= 0.14555390018762815 \n",
      "acc for optim= 0.15920495328545156\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.003802522784098983\n",
      "Loss on test= 0.005701596383005381\n",
      "acc for Lsat= 0.10877601445342104 \n",
      "acc for Psat= 0.2334277592599392 \n",
      "acc for optim= 0.17862246066538823\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.0037940845359116793\n",
      "Loss on test= 0.005504080560058355\n",
      "acc for Lsat= 0.09324861025541192 \n",
      "acc for Psat= 0.1521714841979297 \n",
      "acc for optim= 0.17418772892819512\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.003945998381823301\n",
      "Loss on test= 0.0054995156824588776\n",
      "acc for Lsat= 0.1129513759062522 \n",
      "acc for Psat= 0.1514064904509319 \n",
      "acc for optim= 0.1781804348122225\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.003802746534347534\n",
      "Loss on test= 0.00548549834638834\n",
      "acc for Lsat= 0.08510039371645285 \n",
      "acc for Psat= 0.1563862185511324 \n",
      "acc for optim= 0.16747824707999825\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.003671655198559165\n",
      "Loss on test= 0.005620348267257214\n",
      "acc for Lsat= 0.12680779247441226 \n",
      "acc for Psat= 0.19196632931319377 \n",
      "acc for optim= 0.2049555291628672\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.0037741095293313265\n",
      "Loss on test= 0.005517847836017609\n",
      "acc for Lsat= 0.07961359940883186 \n",
      "acc for Psat= 0.15177956650344035 \n",
      "acc for optim= 0.18473912108068666\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.003601859323680401\n",
      "Loss on test= 0.005563423968851566\n",
      "acc for Lsat= 0.11489423167788321 \n",
      "acc for Psat= 0.1714280790442394 \n",
      "acc for optim= 0.21867775420347849\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.0037799454294145107\n",
      "Loss on test= 0.005354821681976318\n",
      "acc for Lsat= 0.1111359094211366 \n",
      "acc for Psat= 0.12938451259914371 \n",
      "acc for optim= 0.21927846010981333\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.003888513194397092\n",
      "Loss on test= 0.0052353148348629475\n",
      "acc for Lsat= 0.10812735831778911 \n",
      "acc for Psat= 0.14657317428565067 \n",
      "acc for optim= 0.21341650278514457\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.0037859806325286627\n",
      "Loss on test= 0.005045472644269466\n",
      "acc for Lsat= 0.08128566714003682 \n",
      "acc for Psat= 0.16542277494833493 \n",
      "acc for optim= 0.16372907192756733\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.003777247853577137\n",
      "Loss on test= 0.005333754234015942\n",
      "acc for Lsat= 0.10780732706189156 \n",
      "acc for Psat= 0.17130578412777847 \n",
      "acc for optim= 0.19637809259196123\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.003778881626203656\n",
      "Loss on test= 0.005441546440124512\n",
      "acc for Lsat= 0.12332465044326252 \n",
      "acc for Psat= 0.19047933351248503 \n",
      "acc for optim= 0.1768284355186754\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.003637034446001053\n",
      "Loss on test= 0.005271890200674534\n",
      "acc for Lsat= 0.07248110422450635 \n",
      "acc for Psat= 0.12834346227140891 \n",
      "acc for optim= 0.21296101870636144\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.003698243759572506\n",
      "Loss on test= 0.0059010726399719715\n",
      "acc for Lsat= 0.09782619708372901 \n",
      "acc for Psat= 0.18079089342306057 \n",
      "acc for optim= 0.19055849813028342\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.0036819479428231716\n",
      "Loss on test= 0.005450150463730097\n",
      "acc for Lsat= 0.13432724385832748 \n",
      "acc for Psat= 0.17291105310950014 \n",
      "acc for optim= 0.19162511960085896\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.0036396735813468695\n",
      "Loss on test= 0.00538415415212512\n",
      "acc for Lsat= 0.09670814462394144 \n",
      "acc for Psat= 0.1472403171679212 \n",
      "acc for optim= 0.18178545735362503\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.0037299899850040674\n",
      "Loss on test= 0.005775415804237127\n",
      "acc for Lsat= 0.08753829658962786 \n",
      "acc for Psat= 0.14385880824799338 \n",
      "acc for optim= 0.16866089111297494\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.00370422238484025\n",
      "Loss on test= 0.005677563603967428\n",
      "acc for Lsat= 0.0940240141741621 \n",
      "acc for Psat= 0.16665597259998322 \n",
      "acc for optim= 0.198901927150372\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.003740984946489334\n",
      "Loss on test= 0.0056028058752417564\n",
      "acc for Lsat= 0.08771644898742023 \n",
      "acc for Psat= 0.13913953500903314 \n",
      "acc for optim= 0.1737446757680219\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.0036841894034296274\n",
      "Loss on test= 0.005623865872621536\n",
      "acc for Lsat= 0.09483424999376035 \n",
      "acc for Psat= 0.20496963119755188 \n",
      "acc for optim= 0.17752157581142253\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.0037667853757739067\n",
      "Loss on test= 0.005261471029371023\n",
      "acc for Lsat= 0.07967099524103105 \n",
      "acc for Psat= 0.1598906988898913 \n",
      "acc for optim= 0.18218913909772205\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.0036366877611726522\n",
      "Loss on test= 0.005852661561220884\n",
      "acc for Lsat= 0.10461340865327252 \n",
      "acc for Psat= 0.1255729403346777 \n",
      "acc for optim= 0.1941045763798886\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.0036895291414111853\n",
      "Loss on test= 0.005096768960356712\n",
      "acc for Lsat= 0.07737034372985363 \n",
      "acc for Psat= 0.18323502405029204 \n",
      "acc for optim= 0.19057930685165855\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.0036925198510289192\n",
      "Loss on test= 0.005309403408318758\n",
      "acc for Lsat= 0.09814325735593836 \n",
      "acc for Psat= 0.14535625306113312 \n",
      "acc for optim= 0.20554226854195198\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.003911258652806282\n",
      "Loss on test= 0.005675420165061951\n",
      "acc for Lsat= 0.08277352737625027 \n",
      "acc for Psat= 0.1555163985532191 \n",
      "acc for optim= 0.189685600111261\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.0038582212291657925\n",
      "Loss on test= 0.005453144665807486\n",
      "acc for Lsat= 0.13522008889251286 \n",
      "acc for Psat= 0.16332230442720982 \n",
      "acc for optim= 0.1876879768549568\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.0036026141606271267\n",
      "Loss on test= 0.005405894014984369\n",
      "acc for Lsat= 0.1173235731839668 \n",
      "acc for Psat= 0.19008425110951066 \n",
      "acc for optim= 0.18484659812464896\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.003808011068031192\n",
      "Loss on test= 0.005386528559029102\n",
      "acc for Lsat= 0.0811286050076079 \n",
      "acc for Psat= 0.15357042595537174 \n",
      "acc for optim= 0.1774483497461511\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.003652354469522834\n",
      "Loss on test= 0.00528087979182601\n",
      "acc for Lsat= 0.08118639433652991 \n",
      "acc for Psat= 0.2060479839435882 \n",
      "acc for optim= 0.17550639120034045\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.003651781938970089\n",
      "Loss on test= 0.005753237754106522\n",
      "acc for Lsat= 0.09923683823500243 \n",
      "acc for Psat= 0.1987946235264341 \n",
      "acc for optim= 0.1948100882064965\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.0037165165413171053\n",
      "Loss on test= 0.005125860217958689\n",
      "acc for Lsat= 0.10303317551087174 \n",
      "acc for Psat= 0.16754368734028605 \n",
      "acc for optim= 0.18335188175034192\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.003666090313345194\n",
      "Loss on test= 0.005552817601710558\n",
      "acc for Lsat= 0.10804670479976469 \n",
      "acc for Psat= 0.1345537037899097 \n",
      "acc for optim= 0.16381094601011784\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.0035402479115873575\n",
      "Loss on test= 0.005488162860274315\n",
      "acc for Lsat= 0.0851696065057897 \n",
      "acc for Psat= 0.16238524011957148 \n",
      "acc for optim= 0.19957537529990077\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.0037011171225458384\n",
      "Loss on test= 0.005587545223534107\n",
      "acc for Lsat= 0.08676733772477342 \n",
      "acc for Psat= 0.2103989230365389 \n",
      "acc for optim= 0.18572502358195683\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.0037228770088404417\n",
      "Loss on test= 0.004745090380311012\n",
      "acc for Lsat= 0.0688775887247175 \n",
      "acc for Psat= 0.17317411256954074 \n",
      "acc for optim= 0.18610770288958317\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.003714228980243206\n",
      "Loss on test= 0.005346377845853567\n",
      "acc for Lsat= 0.06965798591166579 \n",
      "acc for Psat= 0.12123189742366473 \n",
      "acc for optim= 0.20743393152952194\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.003776928875595331\n",
      "Loss on test= 0.0057160453870892525\n",
      "acc for Lsat= 0.0982821855512965 \n",
      "acc for Psat= 0.23645581383930725 \n",
      "acc for optim= 0.1728758078146105\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.003710108110681176\n",
      "Loss on test= 0.005641791503876448\n",
      "acc for Lsat= 0.06441355418549695 \n",
      "acc for Psat= 0.1567004171407057 \n",
      "acc for optim= 0.1957839020372679\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.0036865277215838432\n",
      "Loss on test= 0.005173986777663231\n",
      "acc for Lsat= 0.11434980465047476 \n",
      "acc for Psat= 0.18235608148905966 \n",
      "acc for optim= 0.18951558870159918\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.0037376058753579855\n",
      "Loss on test= 0.0050521548837423325\n",
      "acc for Lsat= 0.0973487278032634 \n",
      "acc for Psat= 0.11974728354511575 \n",
      "acc for optim= 0.18884237441751692\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.003632859094068408\n",
      "Loss on test= 0.005034872330725193\n",
      "acc for Lsat= 0.10880103127823935 \n",
      "acc for Psat= 0.1475478420034051 \n",
      "acc for optim= 0.20019484748546448\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.0036882690619677305\n",
      "Loss on test= 0.004926205612719059\n",
      "acc for Lsat= 0.10179404634982347 \n",
      "acc for Psat= 0.17667992040514946 \n",
      "acc for optim= 0.18843197553522056\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.0037298870738595724\n",
      "Loss on test= 0.0051144496537745\n",
      "acc for Lsat= 0.09630020147758639 \n",
      "acc for Psat= 0.1509376648399565 \n",
      "acc for optim= 0.1864476981314106\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.0036506056785583496\n",
      "Loss on test= 0.005218261852860451\n",
      "acc for Lsat= 0.084068682950197 \n",
      "acc for Psat= 0.1717430301165829 \n",
      "acc for optim= 0.20313058245099253\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.003687858348712325\n",
      "Loss on test= 0.005504853557795286\n",
      "acc for Lsat= 0.10051005168093576 \n",
      "acc for Psat= 0.14558016723539266 \n",
      "acc for optim= 0.20225921562976307\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.003674218663945794\n",
      "Loss on test= 0.005231565795838833\n",
      "acc for Lsat= 0.0927824142757648 \n",
      "acc for Psat= 0.14509666749897102 \n",
      "acc for optim= 0.19971355932971668\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.0037726713344454765\n",
      "Loss on test= 0.005462726578116417\n",
      "acc for Lsat= 0.12729991248084438 \n",
      "acc for Psat= 0.1626729592680931 \n",
      "acc for optim= 0.17115848180320528\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.003736653132364154\n",
      "Loss on test= 0.005427391268312931\n",
      "acc for Lsat= 0.12243042265375455 \n",
      "acc for Psat= 0.2020120343659073 \n",
      "acc for optim= 0.18807853768683142\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.003674497362226248\n",
      "Loss on test= 0.005412308033555746\n",
      "acc for Lsat= 0.08417865120443618 \n",
      "acc for Psat= 0.15443314265252817 \n",
      "acc for optim= 0.20013834494683477\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.0038566486909985542\n",
      "Loss on test= 0.005543067120015621\n",
      "acc for Lsat= 0.08983377799935018 \n",
      "acc for Psat= 0.12137968052734828 \n",
      "acc for optim= 0.18627385774420369\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.003702990710735321\n",
      "Loss on test= 0.005696585401892662\n",
      "acc for Lsat= 0.10701090160162291 \n",
      "acc for Psat= 0.19209949009948307 \n",
      "acc for optim= 0.1627814050556885\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.0036375580821186304\n",
      "Loss on test= 0.0053330110386013985\n",
      "acc for Lsat= 0.09376698093385333 \n",
      "acc for Psat= 0.14279241295945314 \n",
      "acc for optim= 0.20978533481765124\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.0036912669893354177\n",
      "Loss on test= 0.005351323168724775\n",
      "acc for Lsat= 0.11638662446704176 \n",
      "acc for Psat= 0.19663693529501972 \n",
      "acc for optim= 0.1925686960005098\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.0036820003297179937\n",
      "Loss on test= 0.004999041091650724\n",
      "acc for Lsat= 0.09696919326153067 \n",
      "acc for Psat= 0.20688916851455966 \n",
      "acc for optim= 0.18514909745297498\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.003722084453329444\n",
      "Loss on test= 0.0054566687904298306\n",
      "acc for Lsat= 0.1201590850121445 \n",
      "acc for Psat= 0.13372434034115738 \n",
      "acc for optim= 0.1952906814403832\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.0038570761680603027\n",
      "Loss on test= 0.0056529720313847065\n",
      "acc for Lsat= 0.0738970392331895 \n",
      "acc for Psat= 0.11845602291739649 \n",
      "acc for optim= 0.19570612477966481\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.0036412363406270742\n",
      "Loss on test= 0.005109164398163557\n",
      "acc for Lsat= 0.12227078313622365 \n",
      "acc for Psat= 0.16439216516705024 \n",
      "acc for optim= 0.19725887260089317\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.0036891589406877756\n",
      "Loss on test= 0.005186626221984625\n",
      "acc for Lsat= 0.05803718974089457 \n",
      "acc for Psat= 0.12352514801831502 \n",
      "acc for optim= 0.18247303946150673\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.0036866592708975077\n",
      "Loss on test= 0.005144002381712198\n",
      "acc for Lsat= 0.10395454683910227 \n",
      "acc for Psat= 0.14443815551284286 \n",
      "acc for optim= 0.18939480495949587\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.003647529287263751\n",
      "Loss on test= 0.005669580772519112\n",
      "acc for Lsat= 0.09362854051869363 \n",
      "acc for Psat= 0.18141011360825765 \n",
      "acc for optim= 0.1818345708048178\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.00365231791511178\n",
      "Loss on test= 0.00533240707591176\n",
      "acc for Lsat= 0.08572443046917518 \n",
      "acc for Psat= 0.1643238276657131 \n",
      "acc for optim= 0.17686670964273313\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.0037134536541998386\n",
      "Loss on test= 0.005194332916289568\n",
      "acc for Lsat= 0.07593618584845292 \n",
      "acc for Psat= 0.17929003780914676 \n",
      "acc for optim= 0.19862884319283897\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.003545390907675028\n",
      "Loss on test= 0.005630203988403082\n",
      "acc for Lsat= 0.07648369355592877 \n",
      "acc for Psat= 0.12645302071339554 \n",
      "acc for optim= 0.18035922315903008\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.003604626515880227\n",
      "Loss on test= 0.00557699054479599\n",
      "acc for Lsat= 0.08732691218352152 \n",
      "acc for Psat= 0.2018587328493595 \n",
      "acc for optim= 0.18635787051688465\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.0037040673196315765\n",
      "Loss on test= 0.005263607017695904\n",
      "acc for Lsat= 0.10495896787486142 \n",
      "acc for Psat= 0.17719504754576418 \n",
      "acc for optim= 0.1922257833907174\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.0037126115057617426\n",
      "Loss on test= 0.005469536408782005\n",
      "acc for Lsat= 0.11588568100705743 \n",
      "acc for Psat= 0.21915096189412805 \n",
      "acc for optim= 0.18592603136009225\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.003554126713424921\n",
      "Loss on test= 0.0057578133419156075\n",
      "acc for Lsat= 0.10050255256808466 \n",
      "acc for Psat= 0.20051703069152105 \n",
      "acc for optim= 0.2083239983767271\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.0035216682590544224\n",
      "Loss on test= 0.005598294548690319\n",
      "acc for Lsat= 0.10572774894535542 \n",
      "acc for Psat= 0.13315281450438002 \n",
      "acc for optim= 0.17188944822798172\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.0037310810294002295\n",
      "Loss on test= 0.0051216548308730125\n",
      "acc for Lsat= 0.08973175432119104 \n",
      "acc for Psat= 0.13703864554150236 \n",
      "acc for optim= 0.1798465374029345\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.003519937163218856\n",
      "Loss on test= 0.00522516667842865\n",
      "acc for Lsat= 0.11011719908047882 \n",
      "acc for Psat= 0.16687724330565995 \n",
      "acc for optim= 0.18801271304902104\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.0037356852553784847\n",
      "Loss on test= 0.00536767952144146\n",
      "acc for Lsat= 0.08596530603244901 \n",
      "acc for Psat= 0.1678993172891852 \n",
      "acc for optim= 0.2003385993755526\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.0036253086291253567\n",
      "Loss on test= 0.005340235307812691\n",
      "acc for Lsat= 0.09949871090551217 \n",
      "acc for Psat= 0.19156158570614126 \n",
      "acc for optim= 0.17665952041796926\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.0036631112452596426\n",
      "Loss on test= 0.005092379171401262\n",
      "acc for Lsat= 0.08859236778355101 \n",
      "acc for Psat= 0.15438844429122078 \n",
      "acc for optim= 0.18135073191175857\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.0037538635078817606\n",
      "Loss on test= 0.005331520456820726\n",
      "acc for Lsat= 0.10751759859785023 \n",
      "acc for Psat= 0.18670411169942883 \n",
      "acc for optim= 0.19955633438399267\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.0037113307043910027\n",
      "Loss on test= 0.0053285276517271996\n",
      "acc for Lsat= 0.0914251475284497 \n",
      "acc for Psat= 0.1450845516907672 \n",
      "acc for optim= 0.18767850815008083\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.0036316995974630117\n",
      "Loss on test= 0.00543990358710289\n",
      "acc for Lsat= 0.09665664694168502 \n",
      "acc for Psat= 0.1474779352493998 \n",
      "acc for optim= 0.18526279317706618\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.0035742209292948246\n",
      "Loss on test= 0.005704279523342848\n",
      "acc for Lsat= 0.08505817732980682 \n",
      "acc for Psat= 0.17683078351223636 \n",
      "acc for optim= 0.18645493391280374\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.0036936767864972353\n",
      "Loss on test= 0.005631374195218086\n",
      "acc for Lsat= 0.0701106420213667 \n",
      "acc for Psat= 0.12150421407487658 \n",
      "acc for optim= 0.1912314895954397\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.0036233693826943636\n",
      "Loss on test= 0.005357242655009031\n",
      "acc for Lsat= 0.09411070309579372 \n",
      "acc for Psat= 0.13983913216119012 \n",
      "acc for optim= 0.19197092946463576\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.003634597407653928\n",
      "Loss on test= 0.005186239257454872\n",
      "acc for Lsat= 0.12182575115002692 \n",
      "acc for Psat= 0.1605880299790038 \n",
      "acc for optim= 0.1668003061786294\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.003566448576748371\n",
      "Loss on test= 0.005569271743297577\n",
      "acc for Lsat= 0.08656421795280443 \n",
      "acc for Psat= 0.1805853901637925 \n",
      "acc for optim= 0.1670347262536072\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.0036774969194084406\n",
      "Loss on test= 0.005210827570408583\n",
      "acc for Lsat= 0.11735316272825003 \n",
      "acc for Psat= 0.14286575246498817 \n",
      "acc for optim= 0.2292092895756165\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.0035490228328853846\n",
      "Loss on test= 0.005492230877280235\n",
      "acc for Lsat= 0.0814219484002226 \n",
      "acc for Psat= 0.17220530969401202 \n",
      "acc for optim= 0.21477105147722694\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.0036406689323484898\n",
      "Loss on test= 0.005567444488406181\n",
      "acc for Lsat= 0.10185680538415909 \n",
      "acc for Psat= 0.13118834731479487 \n",
      "acc for optim= 0.17656566125030318\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.0035694846883416176\n",
      "Loss on test= 0.0051915268413722515\n",
      "acc for Lsat= 0.11660153849516064 \n",
      "acc for Psat= 0.1597769299712834 \n",
      "acc for optim= 0.1698520268417067\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.0035593793727457523\n",
      "Loss on test= 0.00533860269933939\n",
      "acc for Lsat= 0.08783025268672241 \n",
      "acc for Psat= 0.13917399365972313 \n",
      "acc for optim= 0.1655246074984057\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.0036093471571803093\n",
      "Loss on test= 0.005875838920474052\n",
      "acc for Lsat= 0.08423036270930122 \n",
      "acc for Psat= 0.1791701827508708 \n",
      "acc for optim= 0.17231551355992755\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.0036430805921554565\n",
      "Loss on test= 0.005879881791770458\n",
      "acc for Lsat= 0.1108226095740166 \n",
      "acc for Psat= 0.13805078752597588 \n",
      "acc for optim= 0.1882962854579091\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.0036235875450074673\n",
      "Loss on test= 0.0052179438062012196\n",
      "acc for Lsat= 0.08808317294137345 \n",
      "acc for Psat= 0.11116189972704484 \n",
      "acc for optim= 0.20685919146570894\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.003501732600852847\n",
      "Loss on test= 0.005532087758183479\n",
      "acc for Lsat= 0.11541031003515753 \n",
      "acc for Psat= 0.17302963351054737 \n",
      "acc for optim= 0.1723392391577363\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.003506462322548032\n",
      "Loss on test= 0.005669809877872467\n",
      "acc for Lsat= 0.10252482425938877 \n",
      "acc for Psat= 0.176975710873699 \n",
      "acc for optim= 0.20846597612318066\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.003613085485994816\n",
      "Loss on test= 0.005491066724061966\n",
      "acc for Lsat= 0.11635066574025485 \n",
      "acc for Psat= 0.14229005003451473 \n",
      "acc for optim= 0.18943820438451237\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.003508523106575012\n",
      "Loss on test= 0.005035091191530228\n",
      "acc for Lsat= 0.10523986286069784 \n",
      "acc for Psat= 0.15027552793293986 \n",
      "acc for optim= 0.208938542029096\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.0036787500139325857\n",
      "Loss on test= 0.0055600982159376144\n",
      "acc for Lsat= 0.11818225733521912 \n",
      "acc for Psat= 0.1742629965560304 \n",
      "acc for optim= 0.18212728132493794\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.003648319048807025\n",
      "Loss on test= 0.005411695223301649\n",
      "acc for Lsat= 0.1344212320012351 \n",
      "acc for Psat= 0.21460967873119646 \n",
      "acc for optim= 0.18652409901713124\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.003577113151550293\n",
      "Loss on test= 0.005026922561228275\n",
      "acc for Lsat= 0.10047765327100125 \n",
      "acc for Psat= 0.21052237620784175 \n",
      "acc for optim= 0.20569279303567278\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.0034871662501245737\n",
      "Loss on test= 0.005617249757051468\n",
      "acc for Lsat= 0.08386323038980158 \n",
      "acc for Psat= 0.12201617849576804 \n",
      "acc for optim= 0.19072992634028196\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.0036844380665570498\n",
      "Loss on test= 0.004925677552819252\n",
      "acc for Lsat= 0.12057983769207364 \n",
      "acc for Psat= 0.14895415409571594 \n",
      "acc for optim= 0.18914665592213473\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.003592744702473283\n",
      "Loss on test= 0.005308947060257196\n",
      "acc for Lsat= 0.11606019064654699 \n",
      "acc for Psat= 0.16104480732853213 \n",
      "acc for optim= 0.1776958416303387\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.0035722502507269382\n",
      "Loss on test= 0.005413216073065996\n",
      "acc for Lsat= 0.09747081094731887 \n",
      "acc for Psat= 0.1867780979308817 \n",
      "acc for optim= 0.18514186112831035\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.0035804002545773983\n",
      "Loss on test= 0.005264860112220049\n",
      "acc for Lsat= 0.10694801665118171 \n",
      "acc for Psat= 0.1570197789826327 \n",
      "acc for optim= 0.20609367343907556\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.003626819932833314\n",
      "Loss on test= 0.005398294888436794\n",
      "acc for Lsat= 0.1063368714789653 \n",
      "acc for Psat= 0.14736184048362905 \n",
      "acc for optim= 0.19931823229934606\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.003654184052720666\n",
      "Loss on test= 0.005295290611684322\n",
      "acc for Lsat= 0.09755877335555851 \n",
      "acc for Psat= 0.1685127435872952 \n",
      "acc for optim= 0.16500547962884107\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.0036723753437399864\n",
      "Loss on test= 0.005289944354444742\n",
      "acc for Lsat= 0.09510875673085037 \n",
      "acc for Psat= 0.12802992780214278 \n",
      "acc for optim= 0.17925683269277215\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.003554349299520254\n",
      "Loss on test= 0.005352561827749014\n",
      "acc for Lsat= 0.08821529906708747 \n",
      "acc for Psat= 0.1575942535677718 \n",
      "acc for optim= 0.20247207078824025\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.0037408426869660616\n",
      "Loss on test= 0.005315339658409357\n",
      "acc for Lsat= 0.10573894846149617 \n",
      "acc for Psat= 0.12484413703593115 \n",
      "acc for optim= 0.2010207733967238\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.0035138996317982674\n",
      "Loss on test= 0.005138372536748648\n",
      "acc for Lsat= 0.07221553270291123 \n",
      "acc for Psat= 0.15466623991313908 \n",
      "acc for optim= 0.19163710623979568\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.003608870320022106\n",
      "Loss on test= 0.0057608638890087605\n",
      "acc for Lsat= 0.11167658705057369 \n",
      "acc for Psat= 0.15400891152158794 \n",
      "acc for optim= 0.21837646095082164\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.0035582652781158686\n",
      "Loss on test= 0.005372340325266123\n",
      "acc for Lsat= 0.13959293688337007 \n",
      "acc for Psat= 0.16686071828007698 \n",
      "acc for optim= 0.19443218358274963\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.0034978315234184265\n",
      "Loss on test= 0.005320216063410044\n",
      "acc for Lsat= 0.11057512563032408 \n",
      "acc for Psat= 0.16688607424859786 \n",
      "acc for optim= 0.19791687559336424\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.0035409419797360897\n",
      "Loss on test= 0.005455174017697573\n",
      "acc for Lsat= 0.14239017023808426 \n",
      "acc for Psat= 0.21229356488523385 \n",
      "acc for optim= 0.1914706985052261\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.0036873503122478724\n",
      "Loss on test= 0.0054976195096969604\n",
      "acc for Lsat= 0.1372395326745593 \n",
      "acc for Psat= 0.19943669358811653 \n",
      "acc for optim= 0.2144420820598801\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.0036329173017293215\n",
      "Loss on test= 0.005577847361564636\n",
      "acc for Lsat= 0.10396021754584378 \n",
      "acc for Psat= 0.18035788492610058 \n",
      "acc for optim= 0.18753925876484978\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.0035027305129915476\n",
      "Loss on test= 0.005456617102026939\n",
      "acc for Lsat= 0.10750128527999753 \n",
      "acc for Psat= 0.16866189153451058 \n",
      "acc for optim= 0.1952981504922112\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.003548450767993927\n",
      "Loss on test= 0.005275309085845947\n",
      "acc for Lsat= 0.12229553713566726 \n",
      "acc for Psat= 0.18023656525959572 \n",
      "acc for optim= 0.14990865553004873\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.003598145442083478\n",
      "Loss on test= 0.005290890112519264\n",
      "acc for Lsat= 0.07983627346240812 \n",
      "acc for Psat= 0.1469876340512807 \n",
      "acc for optim= 0.1992924571968615\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.003553249640390277\n",
      "Loss on test= 0.005415339954197407\n",
      "acc for Lsat= 0.09752566517434186 \n",
      "acc for Psat= 0.13136018561716709 \n",
      "acc for optim= 0.20082997841139635\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.003593548433855176\n",
      "Loss on test= 0.005420988891273737\n",
      "acc for Lsat= 0.0861783695872873 \n",
      "acc for Psat= 0.16858452103204197 \n",
      "acc for optim= 0.1981456637279027\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.003674493869766593\n",
      "Loss on test= 0.005738334730267525\n",
      "acc for Lsat= 0.12394806473619407 \n",
      "acc for Psat= 0.19116621369418377 \n",
      "acc for optim= 0.17515199518917748\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.0036206922959536314\n",
      "Loss on test= 0.005096140783280134\n",
      "acc for Lsat= 0.12120367369304101 \n",
      "acc for Psat= 0.18187711532745096 \n",
      "acc for optim= 0.170427151179562\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.0035220978315919638\n",
      "Loss on test= 0.005355974193662405\n",
      "acc for Lsat= 0.12911110940492815 \n",
      "acc for Psat= 0.15414577370716465 \n",
      "acc for optim= 0.2065877478259305\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.003577505238354206\n",
      "Loss on test= 0.005239454098045826\n",
      "acc for Lsat= 0.06527770734909508 \n",
      "acc for Psat= 0.1802123139324168 \n",
      "acc for optim= 0.18250391399487853\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.0034614140167832375\n",
      "Loss on test= 0.005274944007396698\n",
      "acc for Lsat= 0.08251320922540294 \n",
      "acc for Psat= 0.17622672580182552 \n",
      "acc for optim= 0.19174579965571562\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.0036615515127778053\n",
      "Loss on test= 0.005503728520125151\n",
      "acc for Lsat= 0.11059569044866496 \n",
      "acc for Psat= 0.13083769926904804 \n",
      "acc for optim= 0.1769095477518729\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.003476217156276107\n",
      "Loss on test= 0.005232537165284157\n",
      "acc for Lsat= 0.09429490742170149 \n",
      "acc for Psat= 0.1630680543474025 \n",
      "acc for optim= 0.19794921370016205\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.0036450678016990423\n",
      "Loss on test= 0.005277806427329779\n",
      "acc for Lsat= 0.11389381210837099 \n",
      "acc for Psat= 0.1349491598084569 \n",
      "acc for optim= 0.19380943109798762\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.0036678253673017025\n",
      "Loss on test= 0.00531386723741889\n",
      "acc for Lsat= 0.1145247564288891 \n",
      "acc for Psat= 0.1417812261109551 \n",
      "acc for optim= 0.16175753881947863\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.0034528744872659445\n",
      "Loss on test= 0.005494152661412954\n",
      "acc for Lsat= 0.0913303016811066 \n",
      "acc for Psat= 0.18683607917692927 \n",
      "acc for optim= 0.19972422625869513\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.003498823381960392\n",
      "Loss on test= 0.005401992704719305\n",
      "acc for Lsat= 0.07496963115409017 \n",
      "acc for Psat= 0.14783580849568048 \n",
      "acc for optim= 0.19876550676094162\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.0036186391953378916\n",
      "Loss on test= 0.005567355081439018\n",
      "acc for Lsat= 0.11408560045270456 \n",
      "acc for Psat= 0.16604367077040175 \n",
      "acc for optim= 0.1948580550443795\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.003501118626445532\n",
      "Loss on test= 0.0052186427637934685\n",
      "acc for Lsat= 0.10453673110653956 \n",
      "acc for Psat= 0.16968197836023238 \n",
      "acc for optim= 0.1933753064626621\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.0035219332203269005\n",
      "Loss on test= 0.005539819598197937\n",
      "acc for Lsat= 0.10021060715532965 \n",
      "acc for Psat= 0.16098865980489385 \n",
      "acc for optim= 0.1882576996770998\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.0037265366408973932\n",
      "Loss on test= 0.00580486049875617\n",
      "acc for Lsat= 0.09109966723351842 \n",
      "acc for Psat= 0.16620344412755608 \n",
      "acc for optim= 0.19543123955211034\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.0035754286218434572\n",
      "Loss on test= 0.005290566012263298\n",
      "acc for Lsat= 0.0949767730716202 \n",
      "acc for Psat= 0.18775090989139345 \n",
      "acc for optim= 0.18051280479671228\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.003625699784606695\n",
      "Loss on test= 0.005294133443385363\n",
      "acc for Lsat= 0.13012815080583096 \n",
      "acc for Psat= 0.20711862802919415 \n",
      "acc for optim= 0.18102130178724313\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.003698006272315979\n",
      "Loss on test= 0.005667392164468765\n",
      "acc for Lsat= 0.12420227910236765 \n",
      "acc for Psat= 0.16439080781613788 \n",
      "acc for optim= 0.20553623822828135\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.0035926848649978638\n",
      "Loss on test= 0.005526295863091946\n",
      "acc for Lsat= 0.08787684181394677 \n",
      "acc for Psat= 0.16843002879371247 \n",
      "acc for optim= 0.1926041686286529\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.0035487867426127195\n",
      "Loss on test= 0.005419399589300156\n",
      "acc for Lsat= 0.07892264602439052 \n",
      "acc for Psat= 0.1718599350295133 \n",
      "acc for optim= 0.16491335969314808\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.00364380469545722\n",
      "Loss on test= 0.005350557621568441\n",
      "acc for Lsat= 0.12154213452918662 \n",
      "acc for Psat= 0.13351054908707738 \n",
      "acc for optim= 0.18085749881962934\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.003413584316149354\n",
      "Loss on test= 0.005418018437922001\n",
      "acc for Lsat= 0.08901148505133784 \n",
      "acc for Psat= 0.10846111991041754 \n",
      "acc for optim= 0.19745497346027857\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.003509438131004572\n",
      "Loss on test= 0.00560423731803894\n",
      "acc for Lsat= 0.07799282688130107 \n",
      "acc for Psat= 0.1586960222468608 \n",
      "acc for optim= 0.20586089882999659\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.003531031310558319\n",
      "Loss on test= 0.0054481374099850655\n",
      "acc for Lsat= 0.06657924817409366 \n",
      "acc for Psat= 0.14387035980406734 \n",
      "acc for optim= 0.20912748365662992\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.003532151225954294\n",
      "Loss on test= 0.005649130325764418\n",
      "acc for Lsat= 0.07815751410089433 \n",
      "acc for Psat= 0.18920637615438965 \n",
      "acc for optim= 0.16588106389260954\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.00360479555092752\n",
      "Loss on test= 0.0054481662809848785\n",
      "acc for Lsat= 0.10225079953670502 \n",
      "acc for Psat= 0.17099484925468764 \n",
      "acc for optim= 0.19117143170701134\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.0034906663931906223\n",
      "Loss on test= 0.0054013049229979515\n",
      "acc for Lsat= 0.0983676565811038 \n",
      "acc for Psat= 0.17200347322957693 \n",
      "acc for optim= 0.19192864580286872\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.003589081112295389\n",
      "Loss on test= 0.005215722601860762\n",
      "acc for Lsat= 0.0932663808667308 \n",
      "acc for Psat= 0.18701665041023968 \n",
      "acc for optim= 0.17940386101448288\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.003498347010463476\n",
      "Loss on test= 0.005429568234831095\n",
      "acc for Lsat= 0.07134064687933359 \n",
      "acc for Psat= 0.1519020901954112 \n",
      "acc for optim= 0.22685210541304615\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.0036086260806769133\n",
      "Loss on test= 0.005458182655274868\n",
      "acc for Lsat= 0.13732691429969338 \n",
      "acc for Psat= 0.16136513008839554 \n",
      "acc for optim= 0.17573314907753634\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.003579821204766631\n",
      "Loss on test= 0.005508759059011936\n",
      "acc for Lsat= 0.12446035537868738 \n",
      "acc for Psat= 0.16754670906811953 \n",
      "acc for optim= 0.18812440304706493\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.003466762602329254\n",
      "Loss on test= 0.005321090575307608\n",
      "acc for Lsat= 0.12040311325755385 \n",
      "acc for Psat= 0.10778046758625554 \n",
      "acc for optim= 0.1949153000023216\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.0034280491527169943\n",
      "Loss on test= 0.005242090206593275\n",
      "acc for Lsat= 0.07250263712679346 \n",
      "acc for Psat= 0.1483228644162106 \n",
      "acc for optim= 0.18450456267843643\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.0035167590249329805\n",
      "Loss on test= 0.005615304224193096\n",
      "acc for Lsat= 0.08804290713224974 \n",
      "acc for Psat= 0.17257628646782702 \n",
      "acc for optim= 0.16405037742677248\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.0036322956439107656\n",
      "Loss on test= 0.005115197971463203\n",
      "acc for Lsat= 0.1003548176959157 \n",
      "acc for Psat= 0.1384574230760336 \n",
      "acc for optim= 0.17704655054128832\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.003530262503772974\n",
      "Loss on test= 0.005274209193885326\n",
      "acc for Lsat= 0.11872879648581147 \n",
      "acc for Psat= 0.16899312535921732 \n",
      "acc for optim= 0.19438454250080717\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.003431522287428379\n",
      "Loss on test= 0.005644745659083128\n",
      "acc for Lsat= 0.141925810629295 \n",
      "acc for Psat= 0.18231994648360544 \n",
      "acc for optim= 0.2051607115815083\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.0035628832411020994\n",
      "Loss on test= 0.005345580168068409\n",
      "acc for Lsat= 0.1103346282357557 \n",
      "acc for Psat= 0.15933165417259765 \n",
      "acc for optim= 0.19998193444270226\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.0035705058835446835\n",
      "Loss on test= 0.005396542605012655\n",
      "acc for Lsat= 0.12059653684910801 \n",
      "acc for Psat= 0.1765469799025191 \n",
      "acc for optim= 0.16870495759778553\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.0033643164206296206\n",
      "Loss on test= 0.005247051361948252\n",
      "acc for Lsat= 0.09361690665698713 \n",
      "acc for Psat= 0.15748706247864497 \n",
      "acc for optim= 0.17149486796309552\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.003516749944537878\n",
      "Loss on test= 0.005214494187384844\n",
      "acc for Lsat= 0.12214924054892941 \n",
      "acc for Psat= 0.12213472242890727 \n",
      "acc for optim= 0.178935169811464\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.0034807645715773106\n",
      "Loss on test= 0.005091006401926279\n",
      "acc for Lsat= 0.10402300999946117 \n",
      "acc for Psat= 0.1729060055481063 \n",
      "acc for optim= 0.2134495101668613\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.0035555819049477577\n",
      "Loss on test= 0.0056728278286755085\n",
      "acc for Lsat= 0.12873948919069436 \n",
      "acc for Psat= 0.14854776026267144 \n",
      "acc for optim= 0.19302297366731283\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.003597118891775608\n",
      "Loss on test= 0.0053010620176792145\n",
      "acc for Lsat= 0.12702572445333418 \n",
      "acc for Psat= 0.14665191465367874 \n",
      "acc for optim= 0.2038055693782452\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.0034811950754374266\n",
      "Loss on test= 0.005526902619749308\n",
      "acc for Lsat= 0.09396242997091678 \n",
      "acc for Psat= 0.15268473365964988 \n",
      "acc for optim= 0.1873562224985411\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.0035684348549693823\n",
      "Loss on test= 0.005564684513956308\n",
      "acc for Lsat= 0.10322065190929505 \n",
      "acc for Psat= 0.1651583582473298 \n",
      "acc for optim= 0.18749915610533208\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.00348876416683197\n",
      "Loss on test= 0.005802275612950325\n",
      "acc for Lsat= 0.09591078385710716 \n",
      "acc for Psat= 0.1287085282189461 \n",
      "acc for optim= 0.19679198859052527\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.003565635532140732\n",
      "Loss on test= 0.005569934844970703\n",
      "acc for Lsat= 0.06698284529718673 \n",
      "acc for Psat= 0.15878001710047507 \n",
      "acc for optim= 0.19798092749099144\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.0036135187838226557\n",
      "Loss on test= 0.00540167186409235\n",
      "acc for Lsat= 0.1221030234462685 \n",
      "acc for Psat= 0.1809632494308365 \n",
      "acc for optim= 0.22007461368209785\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.003601220203563571\n",
      "Loss on test= 0.005294119939208031\n",
      "acc for Lsat= 0.1094953174599343 \n",
      "acc for Psat= 0.16252523546831477 \n",
      "acc for optim= 0.1731554474422915\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.0036237933672964573\n",
      "Loss on test= 0.005618108902126551\n",
      "acc for Lsat= 0.09171407576650381 \n",
      "acc for Psat= 0.1999141692908274 \n",
      "acc for optim= 0.1589942735930284\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.0034110024571418762\n",
      "Loss on test= 0.005297603085637093\n",
      "acc for Lsat= 0.07917037955485284 \n",
      "acc for Psat= 0.12451085813033085 \n",
      "acc for optim= 0.21320967127879462\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.003530090907588601\n",
      "Loss on test= 0.005507736001163721\n",
      "acc for Lsat= 0.0847029692441639 \n",
      "acc for Psat= 0.15139067535185152 \n",
      "acc for optim= 0.2046889601689246\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.0034721053671091795\n",
      "Loss on test= 0.005504650063812733\n",
      "acc for Lsat= 0.11223689611587259 \n",
      "acc for Psat= 0.16761283789916584 \n",
      "acc for optim= 0.1915240538203054\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.003488594200462103\n",
      "Loss on test= 0.005722402594983578\n",
      "acc for Lsat= 0.08359390241093934 \n",
      "acc for Psat= 0.1622360600417273 \n",
      "acc for optim= 0.2009891236407889\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.0036425376310944557\n",
      "Loss on test= 0.005392768885940313\n",
      "acc for Lsat= 0.10436551887283309 \n",
      "acc for Psat= 0.15046590463154846 \n",
      "acc for optim= 0.19947322791752717\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.0034855154808610678\n",
      "Loss on test= 0.005494111683219671\n",
      "acc for Lsat= 0.1161974446537594 \n",
      "acc for Psat= 0.17778518014690942 \n",
      "acc for optim= 0.18109860379869738\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.003587959101423621\n",
      "Loss on test= 0.005476152524352074\n",
      "acc for Lsat= 0.11540858025869562 \n",
      "acc for Psat= 0.15390965378739768 \n",
      "acc for optim= 0.1774996370335834\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.0035503210965543985\n",
      "Loss on test= 0.005569584667682648\n",
      "acc for Lsat= 0.10119925633383293 \n",
      "acc for Psat= 0.17087720454825708 \n",
      "acc for optim= 0.18804742426921925\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.003481746418401599\n",
      "Loss on test= 0.005015201400965452\n",
      "acc for Lsat= 0.08910533552989364 \n",
      "acc for Psat= 0.146717494353652 \n",
      "acc for optim= 0.18554835207760334\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.003475902834907174\n",
      "Loss on test= 0.005254857242107391\n",
      "acc for Lsat= 0.12064910498965117 \n",
      "acc for Psat= 0.16003643938650688 \n",
      "acc for optim= 0.173010728677683\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.003462457563728094\n",
      "Loss on test= 0.005249414127320051\n",
      "acc for Lsat= 0.11550734212829007 \n",
      "acc for Psat= 0.17205677729927832 \n",
      "acc for optim= 0.19092074673001966\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.003548785811290145\n",
      "Loss on test= 0.005859838332980871\n",
      "acc for Lsat= 0.1083098239161902 \n",
      "acc for Psat= 0.20160978856599993 \n",
      "acc for optim= 0.23257912240094608\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.003513439791277051\n",
      "Loss on test= 0.0052070412784814835\n",
      "acc for Lsat= 0.09375384455132815 \n",
      "acc for Psat= 0.15347341960296035 \n",
      "acc for optim= 0.205406805086467\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.0035775841679424047\n",
      "Loss on test= 0.005240919999778271\n",
      "acc for Lsat= 0.11498618664013015 \n",
      "acc for Psat= 0.17698048474267125 \n",
      "acc for optim= 0.20225527075429758\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.003531745169311762\n",
      "Loss on test= 0.005137328524142504\n",
      "acc for Lsat= 0.09168106498004312 \n",
      "acc for Psat= 0.18572577058027187 \n",
      "acc for optim= 0.18263343361387444\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.003493363969027996\n",
      "Loss on test= 0.005703370086848736\n",
      "acc for Lsat= 0.08475905087673002 \n",
      "acc for Psat= 0.15578267811280158 \n",
      "acc for optim= 0.17717664869916108\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.0033680542837828398\n",
      "Loss on test= 0.005637696012854576\n",
      "acc for Lsat= 0.0982266005852984 \n",
      "acc for Psat= 0.16432455642562774 \n",
      "acc for optim= 0.20681635674554855\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.003458492225036025\n",
      "Loss on test= 0.0057425484992563725\n",
      "acc for Lsat= 0.097800403729909 \n",
      "acc for Psat= 0.12983357585552666 \n",
      "acc for optim= 0.15888641367200762\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.0035107487346976995\n",
      "Loss on test= 0.005571267567574978\n",
      "acc for Lsat= 0.07900187135156658 \n",
      "acc for Psat= 0.142167281307694 \n",
      "acc for optim= 0.20043703013410172\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.003336468245834112\n",
      "Loss on test= 0.005410236772149801\n",
      "acc for Lsat= 0.08592266686415921 \n",
      "acc for Psat= 0.18397452475296128 \n",
      "acc for optim= 0.19625995486664274\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.0034473950508981943\n",
      "Loss on test= 0.005471234209835529\n",
      "acc for Lsat= 0.08242422921790017 \n",
      "acc for Psat= 0.17571170560808647 \n",
      "acc for optim= 0.1927348165255454\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.0035089256707578897\n",
      "Loss on test= 0.005419549997895956\n",
      "acc for Lsat= 0.11384829374340673 \n",
      "acc for Psat= 0.1396546476882779 \n",
      "acc for optim= 0.18064709415193647\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.003543590195477009\n",
      "Loss on test= 0.0054525649175047874\n",
      "acc for Lsat= 0.08950556411097448 \n",
      "acc for Psat= 0.14603574843042427 \n",
      "acc for optim= 0.18115104160582027\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.0035121815744787455\n",
      "Loss on test= 0.005495273973792791\n",
      "acc for Lsat= 0.11189514864236116 \n",
      "acc for Psat= 0.17519204711748493 \n",
      "acc for optim= 0.18740350853962204\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.0035012548323720694\n",
      "Loss on test= 0.005115238483995199\n",
      "acc for Lsat= 0.07584145872129334 \n",
      "acc for Psat= 0.15721322774576643 \n",
      "acc for optim= 0.2189115100643701\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.003362097544595599\n",
      "Loss on test= 0.005388793535530567\n",
      "acc for Lsat= 0.09569381452133206 \n",
      "acc for Psat= 0.14235191001918995 \n",
      "acc for optim= 0.18170857853773567\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.0035307579673826694\n",
      "Loss on test= 0.005394672974944115\n",
      "acc for Lsat= 0.054985469879789486 \n",
      "acc for Psat= 0.12986661436864072 \n",
      "acc for optim= 0.20701651487292516\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.003490185597911477\n",
      "Loss on test= 0.0055488538928329945\n",
      "acc for Lsat= 0.10302792706837256 \n",
      "acc for Psat= 0.1860989012121637 \n",
      "acc for optim= 0.19505642323444286\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.003488774411380291\n",
      "Loss on test= 0.0050404127687215805\n",
      "acc for Lsat= 0.1459546099843768 \n",
      "acc for Psat= 0.1589446651438872 \n",
      "acc for optim= 0.17868635399887958\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.003510318463668227\n",
      "Loss on test= 0.005154305137693882\n",
      "acc for Lsat= 0.06117240724981659 \n",
      "acc for Psat= 0.16118957402391565 \n",
      "acc for optim= 0.1690914642272724\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.0033929243218153715\n",
      "Loss on test= 0.004990072455257177\n",
      "acc for Lsat= 0.0984165340455042 \n",
      "acc for Psat= 0.21373559080853333 \n",
      "acc for optim= 0.17123564249939388\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.0035306259524077177\n",
      "Loss on test= 0.00551282474771142\n",
      "acc for Lsat= 0.0932235670172506 \n",
      "acc for Psat= 0.18475287976778215 \n",
      "acc for optim= 0.21145106624397966\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.0033600502647459507\n",
      "Loss on test= 0.005357970017939806\n",
      "acc for Lsat= 0.0986811388283968 \n",
      "acc for Psat= 0.16566294761529812 \n",
      "acc for optim= 0.20951754103104273\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.003549187444150448\n",
      "Loss on test= 0.005336681380867958\n",
      "acc for Lsat= 0.11528919099105729 \n",
      "acc for Psat= 0.1698425379064348 \n",
      "acc for optim= 0.18749549361463222\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.0035333798732608557\n",
      "Loss on test= 0.005296534858644009\n",
      "acc for Lsat= 0.11768939565970665 \n",
      "acc for Psat= 0.15790364214545763 \n",
      "acc for optim= 0.17159990304046208\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.003517395816743374\n",
      "Loss on test= 0.005145328119397163\n",
      "acc for Lsat= 0.11480547754197484 \n",
      "acc for Psat= 0.21615450624893937 \n",
      "acc for optim= 0.19286907327154446\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.0036020653788000345\n",
      "Loss on test= 0.005480322986841202\n",
      "acc for Lsat= 0.11358530332088573 \n",
      "acc for Psat= 0.14387360211306563 \n",
      "acc for optim= 0.23429991765361693\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.0034415735863149166\n",
      "Loss on test= 0.005065059754997492\n",
      "acc for Lsat= 0.09705201532536496 \n",
      "acc for Psat= 0.13232636398040792 \n",
      "acc for optim= 0.19831775145656946\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.0034832798410207033\n",
      "Loss on test= 0.005450728815048933\n",
      "acc for Lsat= 0.0675964835875978 \n",
      "acc for Psat= 0.13796858430012232 \n",
      "acc for optim= 0.22605238900157726\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.0034720508847385645\n",
      "Loss on test= 0.005404908210039139\n",
      "acc for Lsat= 0.09396430943161249 \n",
      "acc for Psat= 0.1190677367719925 \n",
      "acc for optim= 0.16277053802170688\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.0035420649219304323\n",
      "Loss on test= 0.005366798490285873\n",
      "acc for Lsat= 0.07749602840178543 \n",
      "acc for Psat= 0.1543230254513522 \n",
      "acc for optim= 0.1733071006617845\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.003503369400277734\n",
      "Loss on test= 0.00505372928455472\n",
      "acc for Lsat= 0.08349418870137823 \n",
      "acc for Psat= 0.14013149770390657 \n",
      "acc for optim= 0.17530088431926238\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.0035104004200547934\n",
      "Loss on test= 0.005179982632398605\n",
      "acc for Lsat= 0.07590959966182709 \n",
      "acc for Psat= 0.13468237563049318 \n",
      "acc for optim= 0.18715177753862614\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.00343505316413939\n",
      "Loss on test= 0.005578665994107723\n",
      "acc for Lsat= 0.0946651925591545 \n",
      "acc for Psat= 0.19887689811487994 \n",
      "acc for optim= 0.1803632906327645\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.0035139292012900114\n",
      "Loss on test= 0.005433628335595131\n",
      "acc for Lsat= 0.10059187058100684 \n",
      "acc for Psat= 0.14290867200017804 \n",
      "acc for optim= 0.1887002121269082\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.003435824764892459\n",
      "Loss on test= 0.005147780757397413\n",
      "acc for Lsat= 0.11894415805323257 \n",
      "acc for Psat= 0.19984888756233785 \n",
      "acc for optim= 0.17343100571694473\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.0034130988642573357\n",
      "Loss on test= 0.0051806289702653885\n",
      "acc for Lsat= 0.08068433224171814 \n",
      "acc for Psat= 0.16978475839520493 \n",
      "acc for optim= 0.1588628311227593\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.0034713291097432375\n",
      "Loss on test= 0.005109221208840609\n",
      "acc for Lsat= 0.09742364807364841 \n",
      "acc for Psat= 0.1632480128124977 \n",
      "acc for optim= 0.1612793877462132\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.0033942065201699734\n",
      "Loss on test= 0.005183379165828228\n",
      "acc for Lsat= 0.13248462023006546 \n",
      "acc for Psat= 0.16053295668098144 \n",
      "acc for optim= 0.20342943682852718\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.0034967921674251556\n",
      "Loss on test= 0.005227000452578068\n",
      "acc for Lsat= 0.10168762484358417 \n",
      "acc for Psat= 0.13753795313338438 \n",
      "acc for optim= 0.18735300118310583\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.0034157729241997004\n",
      "Loss on test= 0.005305863451212645\n",
      "acc for Lsat= 0.09127490455284715 \n",
      "acc for Psat= 0.1640549187690744 \n",
      "acc for optim= 0.19175974150291747\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.003364474279806018\n",
      "Loss on test= 0.005424410104751587\n",
      "acc for Lsat= 0.0812448151409626 \n",
      "acc for Psat= 0.12164416521166761 \n",
      "acc for optim= 0.1983860425858034\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.003457928542047739\n",
      "Loss on test= 0.005303810816258192\n",
      "acc for Lsat= 0.12770114357893667 \n",
      "acc for Psat= 0.1978805905414952 \n",
      "acc for optim= 0.17395713076823288\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.0035769150126725435\n",
      "Loss on test= 0.005321315489709377\n",
      "acc for Lsat= 0.11055204787084626 \n",
      "acc for Psat= 0.16350626635054746 \n",
      "acc for optim= 0.17390172219731742\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.0033700463827699423\n",
      "Loss on test= 0.005254549905657768\n",
      "acc for Lsat= 0.07589522092085746 \n",
      "acc for Psat= 0.16216521727619693 \n",
      "acc for optim= 0.17213610875316793\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.003515152493491769\n",
      "Loss on test= 0.005087201949208975\n",
      "acc for Lsat= 0.11025440154804124 \n",
      "acc for Psat= 0.16420620697964397 \n",
      "acc for optim= 0.192512898085018\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.003536564763635397\n",
      "Loss on test= 0.005312965717166662\n",
      "acc for Lsat= 0.10434773440162341 \n",
      "acc for Psat= 0.15273249686126494 \n",
      "acc for optim= 0.18656062254578704\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.003564500017091632\n",
      "Loss on test= 0.005793259013444185\n",
      "acc for Lsat= 0.12357144326799446 \n",
      "acc for Psat= 0.12987220270507452 \n",
      "acc for optim= 0.18061841108525792\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.0035013563465327024\n",
      "Loss on test= 0.005477650091052055\n",
      "acc for Lsat= 0.10219396692183283 \n",
      "acc for Psat= 0.18005704900456798 \n",
      "acc for optim= 0.15303178840096937\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.0033648512326180935\n",
      "Loss on test= 0.005294910632073879\n",
      "acc for Lsat= 0.09589506652102703 \n",
      "acc for Psat= 0.18711568601429462 \n",
      "acc for optim= 0.17041653653399813\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.0034420921001583338\n",
      "Loss on test= 0.005101774353533983\n",
      "acc for Lsat= 0.12210921953535742 \n",
      "acc for Psat= 0.19140366402765116 \n",
      "acc for optim= 0.1887733448917667\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.0033833549823611975\n",
      "Loss on test= 0.005228058435022831\n",
      "acc for Lsat= 0.11393724449185862 \n",
      "acc for Psat= 0.192611634472592 \n",
      "acc for optim= 0.19077317075182995\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.003472797339782119\n",
      "Loss on test= 0.00573342852294445\n",
      "acc for Lsat= 0.13573576420054045 \n",
      "acc for Psat= 0.22077779424823044 \n",
      "acc for optim= 0.18702135338551468\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.0034811915829777718\n",
      "Loss on test= 0.005449277814477682\n",
      "acc for Lsat= 0.11445521656423807 \n",
      "acc for Psat= 0.20571039213488498 \n",
      "acc for optim= 0.17445727520518833\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.0034934566356241703\n",
      "Loss on test= 0.005272057838737965\n",
      "acc for Lsat= 0.1023794149255587 \n",
      "acc for Psat= 0.12946600053045484 \n",
      "acc for optim= 0.19116783431834644\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.003403519978746772\n",
      "Loss on test= 0.005415286403149366\n",
      "acc for Lsat= 0.10394397678060664 \n",
      "acc for Psat= 0.1634334477647725 \n",
      "acc for optim= 0.20695708423025078\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.0033622845076024532\n",
      "Loss on test= 0.005226557143032551\n",
      "acc for Lsat= 0.10659839342244798 \n",
      "acc for Psat= 0.18940340142904055 \n",
      "acc for optim= 0.2052329129849871\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.0034729531034827232\n",
      "Loss on test= 0.005422355141490698\n",
      "acc for Lsat= 0.09520218650706941 \n",
      "acc for Psat= 0.1478225433578094 \n",
      "acc for optim= 0.1663113042078395\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.0034216807689517736\n",
      "Loss on test= 0.0052746133878827095\n",
      "acc for Lsat= 0.0779615787582265 \n",
      "acc for Psat= 0.1369605908791224 \n",
      "acc for optim= 0.21239578346204427\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.0034867837093770504\n",
      "Loss on test= 0.005244533531367779\n",
      "acc for Lsat= 0.11314345250139013 \n",
      "acc for Psat= 0.18066156334761116 \n",
      "acc for optim= 0.20235223504197267\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.003416486084461212\n",
      "Loss on test= 0.005622869357466698\n",
      "acc for Lsat= 0.07943442912720558 \n",
      "acc for Psat= 0.18887283371037078 \n",
      "acc for optim= 0.17940775151105803\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.003431263379752636\n",
      "Loss on test= 0.005499189719557762\n",
      "acc for Lsat= 0.07878298806543979 \n",
      "acc for Psat= 0.17545114986650232 \n",
      "acc for optim= 0.20244557513958877\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.0035891346633434296\n",
      "Loss on test= 0.00548723665997386\n",
      "acc for Lsat= 0.0922775116438667 \n",
      "acc for Psat= 0.1653536760972606 \n",
      "acc for optim= 0.1555080505915814\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.0034780369605869055\n",
      "Loss on test= 0.005366229452192783\n",
      "acc for Lsat= 0.09954170153165857 \n",
      "acc for Psat= 0.1681824866682291 \n",
      "acc for optim= 0.2161590006823341\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.0034879089798778296\n",
      "Loss on test= 0.005157692823559046\n",
      "acc for Lsat= 0.09784234698033994 \n",
      "acc for Psat= 0.13508623809967604 \n",
      "acc for optim= 0.17691131267282698\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.0035320513416081667\n",
      "Loss on test= 0.005630158353596926\n",
      "acc for Lsat= 0.09227965761803919 \n",
      "acc for Psat= 0.16498629531512657 \n",
      "acc for optim= 0.2134271853461137\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.0033682005014270544\n",
      "Loss on test= 0.005357588641345501\n",
      "acc for Lsat= 0.10081040460823311 \n",
      "acc for Psat= 0.18597033247351646 \n",
      "acc for optim= 0.17607320089721018\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.0033668645191937685\n",
      "Loss on test= 0.005135075654834509\n",
      "acc for Lsat= 0.10098407766781747 \n",
      "acc for Psat= 0.20652881423787525 \n",
      "acc for optim= 0.18610634792841868\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.003333775559440255\n",
      "Loss on test= 0.005431686993688345\n",
      "acc for Lsat= 0.08855408343434748 \n",
      "acc for Psat= 0.17229198335876894 \n",
      "acc for optim= 0.16691093281325367\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.003349181031808257\n",
      "Loss on test= 0.0057481760159134865\n",
      "acc for Lsat= 0.087942725720091 \n",
      "acc for Psat= 0.14531615213491023 \n",
      "acc for optim= 0.21284537900161618\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.0033783146645873785\n",
      "Loss on test= 0.0054632010869681835\n",
      "acc for Lsat= 0.09295069828577754 \n",
      "acc for Psat= 0.14566665365257198 \n",
      "acc for optim= 0.17974017068950665\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.00351016316562891\n",
      "Loss on test= 0.005542844533920288\n",
      "acc for Lsat= 0.0866108810943034 \n",
      "acc for Psat= 0.1487759264289505 \n",
      "acc for optim= 0.16363998235384417\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.003499323735013604\n",
      "Loss on test= 0.005470364820212126\n",
      "acc for Lsat= 0.10932741614265575 \n",
      "acc for Psat= 0.18502750161052164 \n",
      "acc for optim= 0.17577445316904536\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.0034438795410096645\n",
      "Loss on test= 0.005071232095360756\n",
      "acc for Lsat= 0.09811442441100048 \n",
      "acc for Psat= 0.2118565582463311 \n",
      "acc for optim= 0.2156630759127438\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.003470959374681115\n",
      "Loss on test= 0.0053748502396047115\n",
      "acc for Lsat= 0.10970486571184462 \n",
      "acc for Psat= 0.16827284446400073 \n",
      "acc for optim= 0.19309943966153595\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.0034368708729743958\n",
      "Loss on test= 0.005309978500008583\n",
      "acc for Lsat= 0.09608696703799069 \n",
      "acc for Psat= 0.14037137902859184 \n",
      "acc for optim= 0.1781627262502702\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.0035219003912061453\n",
      "Loss on test= 0.005194193683564663\n",
      "acc for Lsat= 0.07619041796877152 \n",
      "acc for Psat= 0.15105863461374408 \n",
      "acc for optim= 0.17136061284691095\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.003381316317245364\n",
      "Loss on test= 0.005756143480539322\n",
      "acc for Lsat= 0.09400067092954284 \n",
      "acc for Psat= 0.17271965573955742 \n",
      "acc for optim= 0.22683235327713192\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.0033710477873682976\n",
      "Loss on test= 0.005382182542234659\n",
      "acc for Lsat= 0.11042058498909076 \n",
      "acc for Psat= 0.15828930089871088 \n",
      "acc for optim= 0.1692744253927635\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.0033359206281602383\n",
      "Loss on test= 0.00530109740793705\n",
      "acc for Lsat= 0.12156372724307908 \n",
      "acc for Psat= 0.177516600296561 \n",
      "acc for optim= 0.19250044123166138\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.0033955799881368876\n",
      "Loss on test= 0.0052072289399802685\n",
      "acc for Lsat= 0.07570926596721013 \n",
      "acc for Psat= 0.19365877363209924 \n",
      "acc for optim= 0.17134787041383484\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.0033019341062754393\n",
      "Loss on test= 0.005522126331925392\n",
      "acc for Lsat= 0.09724672874371107 \n",
      "acc for Psat= 0.1505310505033574 \n",
      "acc for optim= 0.1909307044827276\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.003452289616689086\n",
      "Loss on test= 0.005582307931035757\n",
      "acc for Lsat= 0.10229958340318666 \n",
      "acc for Psat= 0.20955276820394728 \n",
      "acc for optim= 0.16791411090849173\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.003230673260986805\n",
      "Loss on test= 0.005436768755316734\n",
      "acc for Lsat= 0.06942543242540625 \n",
      "acc for Psat= 0.17038125741398996 \n",
      "acc for optim= 0.17881104841621387\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.003373287618160248\n",
      "Loss on test= 0.0055570658296346664\n",
      "acc for Lsat= 0.08570914136685638 \n",
      "acc for Psat= 0.15516975139164263 \n",
      "acc for optim= 0.16903679406580827\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.0034293176140636206\n",
      "Loss on test= 0.005322350654751062\n",
      "acc for Lsat= 0.06813547936164671 \n",
      "acc for Psat= 0.15052529054810293 \n",
      "acc for optim= 0.1692823898823311\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.0034640945959836245\n",
      "Loss on test= 0.005319518502801657\n",
      "acc for Lsat= 0.09041304788034824 \n",
      "acc for Psat= 0.15611865950955284 \n",
      "acc for optim= 0.21528563265585238\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.003413126105442643\n",
      "Loss on test= 0.006060398183763027\n",
      "acc for Lsat= 0.08962245730476247 \n",
      "acc for Psat= 0.10622937344790746 \n",
      "acc for optim= 0.15914777562850052\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.003356878412887454\n",
      "Loss on test= 0.005402394104748964\n",
      "acc for Lsat= 0.09035016254832347 \n",
      "acc for Psat= 0.18745512867139447 \n",
      "acc for optim= 0.18898341360424334\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.0033072398509830236\n",
      "Loss on test= 0.005474244710057974\n",
      "acc for Lsat= 0.10594446615626414 \n",
      "acc for Psat= 0.12944323735104668 \n",
      "acc for optim= 0.19192123578816084\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.0034188644494861364\n",
      "Loss on test= 0.0052353679202497005\n",
      "acc for Lsat= 0.12265387014485896 \n",
      "acc for Psat= 0.1380750969466236 \n",
      "acc for optim= 0.18929520052754217\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.0034421607851982117\n",
      "Loss on test= 0.0050048003904521465\n",
      "acc for Lsat= 0.08408060199063686 \n",
      "acc for Psat= 0.1421483065932989 \n",
      "acc for optim= 0.1778392241232925\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.0033714023884385824\n",
      "Loss on test= 0.005733883939683437\n",
      "acc for Lsat= 0.10820540371868345 \n",
      "acc for Psat= 0.15392421359299785 \n",
      "acc for optim= 0.18490075775318676\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.00344554684124887\n",
      "Loss on test= 0.005839580669999123\n",
      "acc for Lsat= 0.07630022441864842 \n",
      "acc for Psat= 0.16352847570346463 \n",
      "acc for optim= 0.19542022773789036\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.0033367148134857416\n",
      "Loss on test= 0.00554838590323925\n",
      "acc for Lsat= 0.08407844509929419 \n",
      "acc for Psat= 0.15798129477641648 \n",
      "acc for optim= 0.1780371415273597\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.003453588578850031\n",
      "Loss on test= 0.005386905279010534\n",
      "acc for Lsat= 0.06816887162211868 \n",
      "acc for Psat= 0.1573081770653112 \n",
      "acc for optim= 0.19575092206812567\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.003534098155796528\n",
      "Loss on test= 0.005579147022217512\n",
      "acc for Lsat= 0.1066863563998292 \n",
      "acc for Psat= 0.19496066889001262 \n",
      "acc for optim= 0.17771465582255688\n",
      "Fold 5\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.07265591621398926\n",
      "Loss on test= 0.031047575175762177\n",
      "acc for Lsat= 0.571874887165096 \n",
      "acc for Psat= 0.39451994840055704 \n",
      "acc for optim= 0.21823431665608142\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.03122335486114025\n",
      "Loss on test= 0.026935216039419174\n",
      "acc for Lsat= 0.7179313774718644 \n",
      "acc for Psat= 0.4646429982450273 \n",
      "acc for optim= 0.19066070170245236\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.023993564769625664\n",
      "Loss on test= 0.022764554247260094\n",
      "acc for Lsat= 0.3691978384223249 \n",
      "acc for Psat= 0.482782621971435 \n",
      "acc for optim= 0.15448792514184284\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.02144777961075306\n",
      "Loss on test= 0.020492516458034515\n",
      "acc for Lsat= 0.32606868963274693 \n",
      "acc for Psat= 0.3725342522957362 \n",
      "acc for optim= 0.18899985723611382\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.020103005692362785\n",
      "Loss on test= 0.018281862139701843\n",
      "acc for Lsat= 0.5335960255728828 \n",
      "acc for Psat= 0.2882796602530612 \n",
      "acc for optim= 0.17558655851624078\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.01906830631196499\n",
      "Loss on test= 0.018554316833615303\n",
      "acc for Lsat= 0.3016690543542306 \n",
      "acc for Psat= 0.2635078974482086 \n",
      "acc for optim= 0.1642361218497778\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.019537989050149918\n",
      "Loss on test= 0.019630007445812225\n",
      "acc for Lsat= 0.6109055231014887 \n",
      "acc for Psat= 0.3899529975735479 \n",
      "acc for optim= 0.2174489794092046\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.019210485741496086\n",
      "Loss on test= 0.017956914380192757\n",
      "acc for Lsat= 0.34857496060431004 \n",
      "acc for Psat= 0.28806824868337977 \n",
      "acc for optim= 0.1986682092667454\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.01777874305844307\n",
      "Loss on test= 0.016866914927959442\n",
      "acc for Lsat= 0.46035026101809406 \n",
      "acc for Psat= 0.24143849039036366 \n",
      "acc for optim= 0.16558790701027545\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.01685742288827896\n",
      "Loss on test= 0.017797911539673805\n",
      "acc for Lsat= 0.3531302755905522 \n",
      "acc for Psat= 0.30965884073844385 \n",
      "acc for optim= 0.12712140091591412\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.01674259640276432\n",
      "Loss on test= 0.017244812101125717\n",
      "acc for Lsat= 0.3060937631978757 \n",
      "acc for Psat= 0.2734134540789657 \n",
      "acc for optim= 0.15288641966051525\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.016456877812743187\n",
      "Loss on test= 0.014553437940776348\n",
      "acc for Lsat= 0.31740609199429554 \n",
      "acc for Psat= 0.25379271154007355 \n",
      "acc for optim= 0.1327795209363103\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.015940265730023384\n",
      "Loss on test= 0.0145896440371871\n",
      "acc for Lsat= 0.5072304435695211 \n",
      "acc for Psat= 0.28927173206789625 \n",
      "acc for optim= 0.19556947807884878\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.015595224685966969\n",
      "Loss on test= 0.016108371317386627\n",
      "acc for Lsat= 0.5317513959275352 \n",
      "acc for Psat= 0.22611066264410815 \n",
      "acc for optim= 0.15040707050098312\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.016024889424443245\n",
      "Loss on test= 0.01712457649409771\n",
      "acc for Lsat= 0.3810934571677838 \n",
      "acc for Psat= 0.24326684936467144 \n",
      "acc for optim= 0.20693389150417513\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.015049353241920471\n",
      "Loss on test= 0.015934960916638374\n",
      "acc for Lsat= 0.47882230766117573 \n",
      "acc for Psat= 0.34940490768187576 \n",
      "acc for optim= 0.17068801364964908\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.015395808033645153\n",
      "Loss on test= 0.014340854249894619\n",
      "acc for Lsat= 0.39992472499660736 \n",
      "acc for Psat= 0.18524548238039845 \n",
      "acc for optim= 0.13027277998884934\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.015261468477547169\n",
      "Loss on test= 0.014218553900718689\n",
      "acc for Lsat= 0.3036253177043464 \n",
      "acc for Psat= 0.27476291648215717 \n",
      "acc for optim= 0.1707748139484061\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.01541335228830576\n",
      "Loss on test= 0.01529581006616354\n",
      "acc for Lsat= 0.5770613327622414 \n",
      "acc for Psat= 0.3037112102740341 \n",
      "acc for optim= 0.13794890175470048\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.014521357603371143\n",
      "Loss on test= 0.015420584008097649\n",
      "acc for Lsat= 0.5163498773343034 \n",
      "acc for Psat= 0.32058600470837617 \n",
      "acc for optim= 0.1717339994178878\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.014443307183682919\n",
      "Loss on test= 0.013347961939871311\n",
      "acc for Lsat= 0.3245566464546654 \n",
      "acc for Psat= 0.2847119671189123 \n",
      "acc for optim= 0.149952346058045\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.014233818277716637\n",
      "Loss on test= 0.013803500682115555\n",
      "acc for Lsat= 0.2856057468387816 \n",
      "acc for Psat= 0.2395063418791526 \n",
      "acc for optim= 0.14770052613069615\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.01359967328608036\n",
      "Loss on test= 0.013708043843507767\n",
      "acc for Lsat= 0.36610870342701674 \n",
      "acc for Psat= 0.24653155128988954 \n",
      "acc for optim= 0.1485696926376679\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.014292219653725624\n",
      "Loss on test= 0.013535594567656517\n",
      "acc for Lsat= 0.3817455619573593 \n",
      "acc for Psat= 0.2693160567432642 \n",
      "acc for optim= 0.16270503864830566\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.01356490608304739\n",
      "Loss on test= 0.012904994189739227\n",
      "acc for Lsat= 0.360215533547388 \n",
      "acc for Psat= 0.2300643034072386 \n",
      "acc for optim= 0.13734721110409331\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.013951224274933338\n",
      "Loss on test= 0.012958920560777187\n",
      "acc for Lsat= 0.41392092117004925 \n",
      "acc for Psat= 0.2288203082797635 \n",
      "acc for optim= 0.15441934417726266\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.01375844981521368\n",
      "Loss on test= 0.013259335421025753\n",
      "acc for Lsat= 0.39709200244396925 \n",
      "acc for Psat= 0.24724790164166027 \n",
      "acc for optim= 0.14839107153562103\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.013822552748024464\n",
      "Loss on test= 0.012988526374101639\n",
      "acc for Lsat= 0.48966770577761864 \n",
      "acc for Psat= 0.35126368432409233 \n",
      "acc for optim= 0.1888369373563263\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.013326483778655529\n",
      "Loss on test= 0.01257986482232809\n",
      "acc for Lsat= 0.21038330097993216 \n",
      "acc for Psat= 0.23390717121462026 \n",
      "acc for optim= 0.14505154049644867\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.013790908269584179\n",
      "Loss on test= 0.013076407834887505\n",
      "acc for Lsat= 0.4367198575701978 \n",
      "acc for Psat= 0.2190178850044807 \n",
      "acc for optim= 0.14659900526102218\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.01331756915897131\n",
      "Loss on test= 0.012895593419671059\n",
      "acc for Lsat= 0.257164995599952 \n",
      "acc for Psat= 0.27824563688288134 \n",
      "acc for optim= 0.13878462261830768\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.013404842466115952\n",
      "Loss on test= 0.012897798791527748\n",
      "acc for Lsat= 0.3399432265820603 \n",
      "acc for Psat= 0.24445288338594967 \n",
      "acc for optim= 0.12271903268992901\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.013267620466649532\n",
      "Loss on test= 0.012592511251568794\n",
      "acc for Lsat= 0.3650575637196501 \n",
      "acc for Psat= 0.20348767931055692 \n",
      "acc for optim= 0.1545274319166007\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.012752300128340721\n",
      "Loss on test= 0.013873951509594917\n",
      "acc for Lsat= 0.22464733322461447 \n",
      "acc for Psat= 0.29698142657677334 \n",
      "acc for optim= 0.1426082506724116\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.012875299900770187\n",
      "Loss on test= 0.013613002374768257\n",
      "acc for Lsat= 0.3581241983920336 \n",
      "acc for Psat= 0.2552256494657033 \n",
      "acc for optim= 0.15727564102659622\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.012462959624826908\n",
      "Loss on test= 0.0132382120937109\n",
      "acc for Lsat= 0.28768778695828384 \n",
      "acc for Psat= 0.23456593747768137 \n",
      "acc for optim= 0.11535368566142602\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.012910150922834873\n",
      "Loss on test= 0.014516081660985947\n",
      "acc for Lsat= 0.3782036275499397 \n",
      "acc for Psat= 0.29689938781989944 \n",
      "acc for optim= 0.1710178268403979\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.012665515765547752\n",
      "Loss on test= 0.012969860807061195\n",
      "acc for Lsat= 0.4266367827852567 \n",
      "acc for Psat= 0.24955635724796188 \n",
      "acc for optim= 0.12717854650691152\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.012609741650521755\n",
      "Loss on test= 0.012949170544743538\n",
      "acc for Lsat= 0.36413867036915487 \n",
      "acc for Psat= 0.2056801193393767 \n",
      "acc for optim= 0.14455830124724242\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.01242054346948862\n",
      "Loss on test= 0.012081744149327278\n",
      "acc for Lsat= 0.40385202318429947 \n",
      "acc for Psat= 0.2695983503945172 \n",
      "acc for optim= 0.1387803139578965\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.01227584108710289\n",
      "Loss on test= 0.011749125085771084\n",
      "acc for Lsat= 0.4134282696371277 \n",
      "acc for Psat= 0.27058634939344806 \n",
      "acc for optim= 0.15795415246652234\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.012173491530120373\n",
      "Loss on test= 0.011759214103221893\n",
      "acc for Lsat= 0.20953838682423034 \n",
      "acc for Psat= 0.2192268423580875 \n",
      "acc for optim= 0.13471691372493902\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.012177922762930393\n",
      "Loss on test= 0.013240436092019081\n",
      "acc for Lsat= 0.2765716714396452 \n",
      "acc for Psat= 0.3093997035175562 \n",
      "acc for optim= 0.17993597055060995\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.012220129370689392\n",
      "Loss on test= 0.012574756518006325\n",
      "acc for Lsat= 0.3159351547300402 \n",
      "acc for Psat= 0.288904968675019 \n",
      "acc for optim= 0.13511009827359682\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.011821025982499123\n",
      "Loss on test= 0.011823788285255432\n",
      "acc for Lsat= 0.24699819274246693 \n",
      "acc for Psat= 0.25600617735957104 \n",
      "acc for optim= 0.1469125241662065\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.01200068835169077\n",
      "Loss on test= 0.011680777184665203\n",
      "acc for Lsat= 0.33887710484365624 \n",
      "acc for Psat= 0.20187694212007853 \n",
      "acc for optim= 0.13536149294426045\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.011834791861474514\n",
      "Loss on test= 0.01224515400826931\n",
      "acc for Lsat= 0.3486236987842454 \n",
      "acc for Psat= 0.30510951206088066 \n",
      "acc for optim= 0.15009293844923377\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.011869021691381931\n",
      "Loss on test= 0.012410319410264492\n",
      "acc for Lsat= 0.3250008272039445 \n",
      "acc for Psat= 0.24902618531551626 \n",
      "acc for optim= 0.1551890079345968\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.011475755833089352\n",
      "Loss on test= 0.011896505020558834\n",
      "acc for Lsat= 0.308646017478572 \n",
      "acc for Psat= 0.1880070779265629 \n",
      "acc for optim= 0.1556654641818669\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.011744936928153038\n",
      "Loss on test= 0.012177761644124985\n",
      "acc for Lsat= 0.36315792167766225 \n",
      "acc for Psat= 0.26425646680096787 \n",
      "acc for optim= 0.14227091509383172\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.011445880867540836\n",
      "Loss on test= 0.011683016084134579\n",
      "acc for Lsat= 0.45806136002971065 \n",
      "acc for Psat= 0.2378523973748088 \n",
      "acc for optim= 0.1308833963962065\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.011587616056203842\n",
      "Loss on test= 0.012935230508446693\n",
      "acc for Lsat= 0.3385715189700325 \n",
      "acc for Psat= 0.2919532110293706 \n",
      "acc for optim= 0.14927319721836182\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.011883130297064781\n",
      "Loss on test= 0.010898541659116745\n",
      "acc for Lsat= 0.410407612617645 \n",
      "acc for Psat= 0.19747122346113125 \n",
      "acc for optim= 0.13846076538579333\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.011253911070525646\n",
      "Loss on test= 0.012375440448522568\n",
      "acc for Lsat= 0.295174583999647 \n",
      "acc for Psat= 0.22591868560347292 \n",
      "acc for optim= 0.1421450617587349\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.011552747339010239\n",
      "Loss on test= 0.010908890515565872\n",
      "acc for Lsat= 0.32605326387824285 \n",
      "acc for Psat= 0.3154293896837367 \n",
      "acc for optim= 0.15741018826762834\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.01121754851192236\n",
      "Loss on test= 0.012041468173265457\n",
      "acc for Lsat= 0.49617257548703086 \n",
      "acc for Psat= 0.3155814976327949 \n",
      "acc for optim= 0.15808419986731476\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.011710084043443203\n",
      "Loss on test= 0.012083552777767181\n",
      "acc for Lsat= 0.4269004538655281 \n",
      "acc for Psat= 0.2571369800199237 \n",
      "acc for optim= 0.1271949199338754\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.011604363098740578\n",
      "Loss on test= 0.010315300896763802\n",
      "acc for Lsat= 0.29010864026430583 \n",
      "acc for Psat= 0.2576860612672236 \n",
      "acc for optim= 0.13501460125876796\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.011365026235580444\n",
      "Loss on test= 0.011050201952457428\n",
      "acc for Lsat= 0.3016213905066252 \n",
      "acc for Psat= 0.278149486415916 \n",
      "acc for optim= 0.13930388912558556\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.01103625912219286\n",
      "Loss on test= 0.011608523316681385\n",
      "acc for Lsat= 0.44093028269708157 \n",
      "acc for Psat= 0.2010356764205628 \n",
      "acc for optim= 0.13081470757929814\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.01163634005934\n",
      "Loss on test= 0.010855104774236679\n",
      "acc for Lsat= 0.3319274489250448 \n",
      "acc for Psat= 0.2512335590759499 \n",
      "acc for optim= 0.15744044269538587\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.011043205857276917\n",
      "Loss on test= 0.011366833001375198\n",
      "acc for Lsat= 0.2744100352283567 \n",
      "acc for Psat= 0.19866537054379782 \n",
      "acc for optim= 0.14423785431103575\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.010925335809588432\n",
      "Loss on test= 0.010733178816735744\n",
      "acc for Lsat= 0.42395677469256854 \n",
      "acc for Psat= 0.3004571845134099 \n",
      "acc for optim= 0.1434216774844875\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.011034827679395676\n",
      "Loss on test= 0.010971123352646828\n",
      "acc for Lsat= 0.4330923319276836 \n",
      "acc for Psat= 0.23315322564707863 \n",
      "acc for optim= 0.13190420194425517\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.010768777690827847\n",
      "Loss on test= 0.012124513275921345\n",
      "acc for Lsat= 0.40501284863178927 \n",
      "acc for Psat= 0.2240519132465124 \n",
      "acc for optim= 0.13526916697931787\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.010779990814626217\n",
      "Loss on test= 0.0114435451105237\n",
      "acc for Lsat= 0.42164051801794106 \n",
      "acc for Psat= 0.2507744451933023 \n",
      "acc for optim= 0.10959240501850015\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.011007861234247684\n",
      "Loss on test= 0.010587790049612522\n",
      "acc for Lsat= 0.31584993853337234 \n",
      "acc for Psat= 0.2418220972435342 \n",
      "acc for optim= 0.14901002920750114\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.01065392978489399\n",
      "Loss on test= 0.01060207188129425\n",
      "acc for Lsat= 0.2613474486602677 \n",
      "acc for Psat= 0.20208245562389493 \n",
      "acc for optim= 0.14692048935426605\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.010842685587704182\n",
      "Loss on test= 0.012706310488283634\n",
      "acc for Lsat= 0.5340674422267411 \n",
      "acc for Psat= 0.25033598613097435 \n",
      "acc for optim= 0.14736121479007933\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.010899663902819157\n",
      "Loss on test= 0.010966688394546509\n",
      "acc for Lsat= 0.318069221244918 \n",
      "acc for Psat= 0.2480448345757193 \n",
      "acc for optim= 0.13037285912368032\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.010973084717988968\n",
      "Loss on test= 0.011611947789788246\n",
      "acc for Lsat= 0.31022361169258755 \n",
      "acc for Psat= 0.214269046464728 \n",
      "acc for optim= 0.15945486362195677\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.010731863789260387\n",
      "Loss on test= 0.01047802995890379\n",
      "acc for Lsat= 0.3746335018012259 \n",
      "acc for Psat= 0.2592925935362776 \n",
      "acc for optim= 0.1260157311335206\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.010389366187155247\n",
      "Loss on test= 0.011134891770780087\n",
      "acc for Lsat= 0.2771612479765382 \n",
      "acc for Psat= 0.3135979336996873 \n",
      "acc for optim= 0.16337058843216962\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.01061914674937725\n",
      "Loss on test= 0.010550232604146004\n",
      "acc for Lsat= 0.24286768084857613 \n",
      "acc for Psat= 0.25196735685070354 \n",
      "acc for optim= 0.1473601727435986\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.010677075013518333\n",
      "Loss on test= 0.010648984462022781\n",
      "acc for Lsat= 0.3130918886098597 \n",
      "acc for Psat= 0.24892923142760992 \n",
      "acc for optim= 0.14003514454493093\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.010424723848700523\n",
      "Loss on test= 0.011602072976529598\n",
      "acc for Lsat= 0.29631983799239 \n",
      "acc for Psat= 0.2609954327862296 \n",
      "acc for optim= 0.15430740608523288\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.010126226581633091\n",
      "Loss on test= 0.010352645069360733\n",
      "acc for Lsat= 0.43723724306457573 \n",
      "acc for Psat= 0.23634391365986732 \n",
      "acc for optim= 0.13573802707509863\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.010267398320138454\n",
      "Loss on test= 0.010393199510872364\n",
      "acc for Lsat= 0.41323685666753185 \n",
      "acc for Psat= 0.2718678567972448 \n",
      "acc for optim= 0.13553357988389003\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.010207423940300941\n",
      "Loss on test= 0.01065659150481224\n",
      "acc for Lsat= 0.4071731090856095 \n",
      "acc for Psat= 0.2686252775084641 \n",
      "acc for optim= 0.16394786008944115\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.010329018346965313\n",
      "Loss on test= 0.009980354458093643\n",
      "acc for Lsat= 0.3042573155835271 \n",
      "acc for Psat= 0.1728535554268294 \n",
      "acc for optim= 0.12701749511890942\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.010264183394610882\n",
      "Loss on test= 0.010757967829704285\n",
      "acc for Lsat= 0.4134477512497041 \n",
      "acc for Psat= 0.2370569817463143 \n",
      "acc for optim= 0.1143734951555315\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.010032950900495052\n",
      "Loss on test= 0.009796633385121822\n",
      "acc for Lsat= 0.21763807400647137 \n",
      "acc for Psat= 0.21842142921458516 \n",
      "acc for optim= 0.17613294472297034\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.00972053688019514\n",
      "Loss on test= 0.009903650730848312\n",
      "acc for Lsat= 0.3945876843192511 \n",
      "acc for Psat= 0.2710813367221918 \n",
      "acc for optim= 0.14805868257664972\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.010083177126944065\n",
      "Loss on test= 0.010927489958703518\n",
      "acc for Lsat= 0.4677257761359215 \n",
      "acc for Psat= 0.28442455848885906 \n",
      "acc for optim= 0.13487088496589827\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.009824695996940136\n",
      "Loss on test= 0.009906165301799774\n",
      "acc for Lsat= 0.3049310406463014 \n",
      "acc for Psat= 0.19606808283262783 \n",
      "acc for optim= 0.13922628237762386\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.01024628896266222\n",
      "Loss on test= 0.010406355373561382\n",
      "acc for Lsat= 0.331487434812718 \n",
      "acc for Psat= 0.18773713231914574 \n",
      "acc for optim= 0.1454498559857408\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.010236241854727268\n",
      "Loss on test= 0.010753299109637737\n",
      "acc for Lsat= 0.3974344346465336 \n",
      "acc for Psat= 0.2379038909243213 \n",
      "acc for optim= 0.1505467933602631\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.009729785844683647\n",
      "Loss on test= 0.011103437282145023\n",
      "acc for Lsat= 0.29456142739703256 \n",
      "acc for Psat= 0.20240140475410348 \n",
      "acc for optim= 0.1345653799879882\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.009970862418413162\n",
      "Loss on test= 0.010136597789824009\n",
      "acc for Lsat= 0.33865897605816525 \n",
      "acc for Psat= 0.23089165219830143 \n",
      "acc for optim= 0.1464539278919498\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.009607777930796146\n",
      "Loss on test= 0.009382110089063644\n",
      "acc for Lsat= 0.40538543048832154 \n",
      "acc for Psat= 0.2224171814482866 \n",
      "acc for optim= 0.17335347934729523\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.009878360666334629\n",
      "Loss on test= 0.010007020086050034\n",
      "acc for Lsat= 0.36284667635077816 \n",
      "acc for Psat= 0.2347932325469123 \n",
      "acc for optim= 0.11845287670277888\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.009744983166456223\n",
      "Loss on test= 0.009344574064016342\n",
      "acc for Lsat= 0.30359894978917307 \n",
      "acc for Psat= 0.24720489751133654 \n",
      "acc for optim= 0.14235102156979135\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.009933007881045341\n",
      "Loss on test= 0.00925975851714611\n",
      "acc for Lsat= 0.28541483440332943 \n",
      "acc for Psat= 0.26483966534336406 \n",
      "acc for optim= 0.13455925685250097\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.009619795717298985\n",
      "Loss on test= 0.00954449363052845\n",
      "acc for Lsat= 0.18397147932814228 \n",
      "acc for Psat= 0.19404730785431135 \n",
      "acc for optim= 0.12691637376944223\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.009669703431427479\n",
      "Loss on test= 0.009465280920267105\n",
      "acc for Lsat= 0.29153156290865606 \n",
      "acc for Psat= 0.19378691125247213 \n",
      "acc for optim= 0.12973166417537463\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.009775805287063122\n",
      "Loss on test= 0.009180224500596523\n",
      "acc for Lsat= 0.3353079698152012 \n",
      "acc for Psat= 0.2599949806980375 \n",
      "acc for optim= 0.14031710057881558\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.009383265860378742\n",
      "Loss on test= 0.009561633691191673\n",
      "acc for Lsat= 0.3111827992316749 \n",
      "acc for Psat= 0.2541054976948847 \n",
      "acc for optim= 0.12144615966826677\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.009092294611036777\n",
      "Loss on test= 0.009313107468187809\n",
      "acc for Lsat= 0.2563282103381223 \n",
      "acc for Psat= 0.21804803718502322 \n",
      "acc for optim= 0.1426811065612128\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.009315342642366886\n",
      "Loss on test= 0.009686693549156189\n",
      "acc for Lsat= 0.2855391783070647 \n",
      "acc for Psat= 0.23686164376946786 \n",
      "acc for optim= 0.15964482269353336\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.00934208557009697\n",
      "Loss on test= 0.00903335865586996\n",
      "acc for Lsat= 0.34445723870562184 \n",
      "acc for Psat= 0.2822013261417548 \n",
      "acc for optim= 0.1185008997304572\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.00919213704764843\n",
      "Loss on test= 0.009709935635328293\n",
      "acc for Lsat= 0.3059054381834964 \n",
      "acc for Psat= 0.22031544293794367 \n",
      "acc for optim= 0.1385640879161656\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.009174342267215252\n",
      "Loss on test= 0.010393476113677025\n",
      "acc for Lsat= 0.23888345021340582 \n",
      "acc for Psat= 0.19505080610461947 \n",
      "acc for optim= 0.11367922522024149\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.00907956063747406\n",
      "Loss on test= 0.008497427217662334\n",
      "acc for Lsat= 0.24048939916408724 \n",
      "acc for Psat= 0.2243558649594585 \n",
      "acc for optim= 0.15892108974771368\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.009138170629739761\n",
      "Loss on test= 0.009355004876852036\n",
      "acc for Lsat= 0.2748260609546883 \n",
      "acc for Psat= 0.15837688229900473 \n",
      "acc for optim= 0.1253990504062838\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.0089650833979249\n",
      "Loss on test= 0.01011903490871191\n",
      "acc for Lsat= 0.17502917038897672 \n",
      "acc for Psat= 0.18104511313140392 \n",
      "acc for optim= 0.15230056912534767\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.008709104731678963\n",
      "Loss on test= 0.008358748629689217\n",
      "acc for Lsat= 0.3422947383175294 \n",
      "acc for Psat= 0.2261109638752209 \n",
      "acc for optim= 0.14418025829622316\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.008757498115301132\n",
      "Loss on test= 0.009178714826703072\n",
      "acc for Lsat= 0.3698018263611529 \n",
      "acc for Psat= 0.25002557810188997 \n",
      "acc for optim= 0.12007221175978582\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.008903952315449715\n",
      "Loss on test= 0.009078564122319221\n",
      "acc for Lsat= 0.2841086516984635 \n",
      "acc for Psat= 0.22426721381230486 \n",
      "acc for optim= 0.12878860326276886\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.008924199268221855\n",
      "Loss on test= 0.009030691348016262\n",
      "acc for Lsat= 0.25016165105625987 \n",
      "acc for Psat= 0.1968743179200424 \n",
      "acc for optim= 0.12394731703190903\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.008960423991084099\n",
      "Loss on test= 0.009441706351935863\n",
      "acc for Lsat= 0.2906218963778681 \n",
      "acc for Psat= 0.2214106973260641 \n",
      "acc for optim= 0.11949510338147068\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.008742016740143299\n",
      "Loss on test= 0.008895349688827991\n",
      "acc for Lsat= 0.2066823961859983 \n",
      "acc for Psat= 0.1924148238160544 \n",
      "acc for optim= 0.1592136840077324\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.00860131997615099\n",
      "Loss on test= 0.009448948316276073\n",
      "acc for Lsat= 0.3804764525137014 \n",
      "acc for Psat= 0.3012186312634084 \n",
      "acc for optim= 0.11932786812798844\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.008516677655279636\n",
      "Loss on test= 0.00906392652541399\n",
      "acc for Lsat= 0.24658755497593018 \n",
      "acc for Psat= 0.19918531386388671 \n",
      "acc for optim= 0.13188408570001936\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.008181086741387844\n",
      "Loss on test= 0.00937805324792862\n",
      "acc for Lsat= 0.4147854621211688 \n",
      "acc for Psat= 0.22170809092414048 \n",
      "acc for optim= 0.14420781377702951\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.008647442795336246\n",
      "Loss on test= 0.009853512048721313\n",
      "acc for Lsat= 0.20781220384459528 \n",
      "acc for Psat= 0.22792487322456306 \n",
      "acc for optim= 0.14855020233598124\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.008886465802788734\n",
      "Loss on test= 0.008501159027218819\n",
      "acc for Lsat= 0.2754375713767432 \n",
      "acc for Psat= 0.23332824599411753 \n",
      "acc for optim= 0.12472411431372166\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.00815366581082344\n",
      "Loss on test= 0.00933804176747799\n",
      "acc for Lsat= 0.3462827626305322 \n",
      "acc for Psat= 0.26739331596117055 \n",
      "acc for optim= 0.12379060018186767\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.008347674272954464\n",
      "Loss on test= 0.007928157225251198\n",
      "acc for Lsat= 0.27029182682357106 \n",
      "acc for Psat= 0.18188143262442383 \n",
      "acc for optim= 0.11562649646980895\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.008075959049165249\n",
      "Loss on test= 0.008248996920883656\n",
      "acc for Lsat= 0.2812549949934085 \n",
      "acc for Psat= 0.2572468697714309 \n",
      "acc for optim= 0.14514320861134264\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.008178499527275562\n",
      "Loss on test= 0.007934331893920898\n",
      "acc for Lsat= 0.2383432989526126 \n",
      "acc for Psat= 0.24428404350247648 \n",
      "acc for optim= 0.1460778925360905\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.008233079686760902\n",
      "Loss on test= 0.009489198215305805\n",
      "acc for Lsat= 0.26866323382354396 \n",
      "acc for Psat= 0.21576273130873838 \n",
      "acc for optim= 0.12372736467255487\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.008269064128398895\n",
      "Loss on test= 0.008401695638895035\n",
      "acc for Lsat= 0.21475243589116466 \n",
      "acc for Psat= 0.1985583213261432 \n",
      "acc for optim= 0.13216853814406526\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.007961669936776161\n",
      "Loss on test= 0.008975399658083916\n",
      "acc for Lsat= 0.2147489295134114 \n",
      "acc for Psat= 0.1928537314136823 \n",
      "acc for optim= 0.12307209645708402\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.008128819987177849\n",
      "Loss on test= 0.008060920983552933\n",
      "acc for Lsat= 0.23050463132353294 \n",
      "acc for Psat= 0.2519911660088433 \n",
      "acc for optim= 0.1573236868199375\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.008095861412584782\n",
      "Loss on test= 0.008212174288928509\n",
      "acc for Lsat= 0.2222616555324445 \n",
      "acc for Psat= 0.18916255423876768 \n",
      "acc for optim= 0.130649003562414\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.007916933856904507\n",
      "Loss on test= 0.008375944569706917\n",
      "acc for Lsat= 0.28692514600697905 \n",
      "acc for Psat= 0.24829895163161886 \n",
      "acc for optim= 0.1145833694220831\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.008057598024606705\n",
      "Loss on test= 0.007648844737559557\n",
      "acc for Lsat= 0.33367509162053466 \n",
      "acc for Psat= 0.18818065343010756 \n",
      "acc for optim= 0.11695379267136256\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.0077494066208601\n",
      "Loss on test= 0.007640805561095476\n",
      "acc for Lsat= 0.20430484724541506 \n",
      "acc for Psat= 0.202844292546312 \n",
      "acc for optim= 0.1549015428043074\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.007851130329072475\n",
      "Loss on test= 0.007727811112999916\n",
      "acc for Lsat= 0.2110124667071634 \n",
      "acc for Psat= 0.22921043924159473 \n",
      "acc for optim= 0.15097915888246563\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.008343902416527271\n",
      "Loss on test= 0.007185679394751787\n",
      "acc for Lsat= 0.28923497086442596 \n",
      "acc for Psat= 0.2525543020003372 \n",
      "acc for optim= 0.13622829147304097\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.007796192541718483\n",
      "Loss on test= 0.008251463063061237\n",
      "acc for Lsat= 0.25039648321560687 \n",
      "acc for Psat= 0.20886962136460674 \n",
      "acc for optim= 0.13300891606033677\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.007622369099408388\n",
      "Loss on test= 0.007810983341187239\n",
      "acc for Lsat= 0.21434603538364172 \n",
      "acc for Psat= 0.18105992188470232 \n",
      "acc for optim= 0.13551700177292028\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.0074212150648236275\n",
      "Loss on test= 0.008446088060736656\n",
      "acc for Lsat= 0.18093652412709263 \n",
      "acc for Psat= 0.19347812483708063 \n",
      "acc for optim= 0.14406734104785654\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.007776281330734491\n",
      "Loss on test= 0.008303621783852577\n",
      "acc for Lsat= 0.15246465947065088 \n",
      "acc for Psat= 0.1617797329607937 \n",
      "acc for optim= 0.13945447290057522\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.007649144623428583\n",
      "Loss on test= 0.007039010524749756\n",
      "acc for Lsat= 0.18663628130323356 \n",
      "acc for Psat= 0.18101390782976523 \n",
      "acc for optim= 0.14759305554131666\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.007775969337671995\n",
      "Loss on test= 0.007345546502619982\n",
      "acc for Lsat= 0.20538080541882664 \n",
      "acc for Psat= 0.20346349032802713 \n",
      "acc for optim= 0.14418271711717048\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.007529247086495161\n",
      "Loss on test= 0.007450864650309086\n",
      "acc for Lsat= 0.23690385731040603 \n",
      "acc for Psat= 0.21002882346510887 \n",
      "acc for optim= 0.1325292616772155\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.007620797958225012\n",
      "Loss on test= 0.007612181361764669\n",
      "acc for Lsat= 0.18271287344396114 \n",
      "acc for Psat= 0.21439480326241916 \n",
      "acc for optim= 0.15584142888999647\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.007799640763550997\n",
      "Loss on test= 0.007457522209733725\n",
      "acc for Lsat= 0.18846450482184687 \n",
      "acc for Psat= 0.19056179027797449 \n",
      "acc for optim= 0.14328688962592018\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.007451428100466728\n",
      "Loss on test= 0.0073958453722298145\n",
      "acc for Lsat= 0.2417765502921409 \n",
      "acc for Psat= 0.16489252893047202 \n",
      "acc for optim= 0.15376362228481513\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.007606303319334984\n",
      "Loss on test= 0.007553440053015947\n",
      "acc for Lsat= 0.2143237181007862 \n",
      "acc for Psat= 0.20728810004786485 \n",
      "acc for optim= 0.10750874983043307\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.007528482470661402\n",
      "Loss on test= 0.008527069352567196\n",
      "acc for Lsat= 0.18221009445066252 \n",
      "acc for Psat= 0.16925600271820762 \n",
      "acc for optim= 0.12590540800657538\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.0075235203839838505\n",
      "Loss on test= 0.007405695039778948\n",
      "acc for Lsat= 0.1659428682178259 \n",
      "acc for Psat= 0.15177793580531013 \n",
      "acc for optim= 0.13198235046325457\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.0073369513265788555\n",
      "Loss on test= 0.007287144660949707\n",
      "acc for Lsat= 0.21300387548075783 \n",
      "acc for Psat= 0.18551664305333462 \n",
      "acc for optim= 0.12852596108698183\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.007111718878149986\n",
      "Loss on test= 0.008015268482267857\n",
      "acc for Lsat= 0.20235406904895273 \n",
      "acc for Psat= 0.16804639084471595 \n",
      "acc for optim= 0.12542598528994453\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.007055040914565325\n",
      "Loss on test= 0.007333593443036079\n",
      "acc for Lsat= 0.3226216907302539 \n",
      "acc for Psat= 0.19567408064419092 \n",
      "acc for optim= 0.13791607659206623\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.007334382738918066\n",
      "Loss on test= 0.007834088057279587\n",
      "acc for Lsat= 0.2771746467591988 \n",
      "acc for Psat= 0.23102756889743936 \n",
      "acc for optim= 0.14644690802217358\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.007229097653180361\n",
      "Loss on test= 0.007598277647048235\n",
      "acc for Lsat= 0.2644807980913255 \n",
      "acc for Psat= 0.2193386962171644 \n",
      "acc for optim= 0.14167575082845157\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.007224517874419689\n",
      "Loss on test= 0.0065619912929832935\n",
      "acc for Lsat= 0.15668099200249547 \n",
      "acc for Psat= 0.20738008675268954 \n",
      "acc for optim= 0.12416662896672885\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.007236994802951813\n",
      "Loss on test= 0.007720268331468105\n",
      "acc for Lsat= 0.1852196779412528 \n",
      "acc for Psat= 0.2070814874669951 \n",
      "acc for optim= 0.12866276238734523\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.007367233745753765\n",
      "Loss on test= 0.006982884369790554\n",
      "acc for Lsat= 0.18020299413344926 \n",
      "acc for Psat= 0.21147757747934925 \n",
      "acc for optim= 0.11250037993078069\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.006915475707501173\n",
      "Loss on test= 0.007057248614728451\n",
      "acc for Lsat= 0.271569329003493 \n",
      "acc for Psat= 0.2618148369818098 \n",
      "acc for optim= 0.12943323173870644\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.006945876870304346\n",
      "Loss on test= 0.007217679638415575\n",
      "acc for Lsat= 0.24614407629188564 \n",
      "acc for Psat= 0.171509455372062 \n",
      "acc for optim= 0.12615937220915738\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.007147203665226698\n",
      "Loss on test= 0.0068456027656793594\n",
      "acc for Lsat= 0.19961077947583464 \n",
      "acc for Psat= 0.15023602208950454 \n",
      "acc for optim= 0.14065803688329956\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.007126283831894398\n",
      "Loss on test= 0.007576384581625462\n",
      "acc for Lsat= 0.20080470154061913 \n",
      "acc for Psat= 0.16494924947619438 \n",
      "acc for optim= 0.12727971556079057\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.006978519260883331\n",
      "Loss on test= 0.007240304723381996\n",
      "acc for Lsat= 0.1894540155513419 \n",
      "acc for Psat= 0.227815592312254 \n",
      "acc for optim= 0.11990441207955074\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.006937631871551275\n",
      "Loss on test= 0.006792861502617598\n",
      "acc for Lsat= 0.17541363008462618 \n",
      "acc for Psat= 0.1674343315276524 \n",
      "acc for optim= 0.11925919224611586\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.007214710116386414\n",
      "Loss on test= 0.00680806627497077\n",
      "acc for Lsat= 0.18798364610928628 \n",
      "acc for Psat= 0.2364160718344566 \n",
      "acc for optim= 0.12618293122957563\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.00704536447301507\n",
      "Loss on test= 0.006899500265717506\n",
      "acc for Lsat= 0.20721535239782599 \n",
      "acc for Psat= 0.16623125463310215 \n",
      "acc for optim= 0.12551603983673784\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.006824229843914509\n",
      "Loss on test= 0.007015161216259003\n",
      "acc for Lsat= 0.14880612837926796 \n",
      "acc for Psat= 0.26136156792442006 \n",
      "acc for optim= 0.13547176111023873\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.006863933987915516\n",
      "Loss on test= 0.007608799263834953\n",
      "acc for Lsat= 0.23399575282302168 \n",
      "acc for Psat= 0.2050034227884478 \n",
      "acc for optim= 0.13796899115226957\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.006786641664803028\n",
      "Loss on test= 0.007131410297006369\n",
      "acc for Lsat= 0.16480212807396633 \n",
      "acc for Psat= 0.1890319868301352 \n",
      "acc for optim= 0.13529746185263825\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.006810460705310106\n",
      "Loss on test= 0.00792484451085329\n",
      "acc for Lsat= 0.1577683256732093 \n",
      "acc for Psat= 0.1834441360293163 \n",
      "acc for optim= 0.1250471271471017\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.006719337776303291\n",
      "Loss on test= 0.0069487011060118675\n",
      "acc for Lsat= 0.14997472013864252 \n",
      "acc for Psat= 0.1888748517052995 \n",
      "acc for optim= 0.14066283419055658\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.006823658477514982\n",
      "Loss on test= 0.006853158585727215\n",
      "acc for Lsat= 0.22327564982697368 \n",
      "acc for Psat= 0.16787760296008652 \n",
      "acc for optim= 0.13516192878079084\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.00683234678581357\n",
      "Loss on test= 0.006832607090473175\n",
      "acc for Lsat= 0.17045530416039079 \n",
      "acc for Psat= 0.17294727258720538 \n",
      "acc for optim= 0.11119439489104682\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.006817147601395845\n",
      "Loss on test= 0.0067647420801222324\n",
      "acc for Lsat= 0.1626222565666669 \n",
      "acc for Psat= 0.14529582754605347 \n",
      "acc for optim= 0.12240662574509366\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.00695726228877902\n",
      "Loss on test= 0.007140696980059147\n",
      "acc for Lsat= 0.18407221955971587 \n",
      "acc for Psat= 0.1868922484314276 \n",
      "acc for optim= 0.12484677342904939\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.0067037851549685\n",
      "Loss on test= 0.006651496514678001\n",
      "acc for Lsat= 0.1738142396012942 \n",
      "acc for Psat= 0.13543978752568364 \n",
      "acc for optim= 0.13760705292224884\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.006732046138495207\n",
      "Loss on test= 0.0071103391237556934\n",
      "acc for Lsat= 0.12675158006863463 \n",
      "acc for Psat= 0.18298784208794436 \n",
      "acc for optim= 0.13419625546117053\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.006542250048369169\n",
      "Loss on test= 0.006825271528214216\n",
      "acc for Lsat= 0.18670497138777542 \n",
      "acc for Psat= 0.16425621581988203 \n",
      "acc for optim= 0.1354564499730865\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.006515508983284235\n",
      "Loss on test= 0.006207896396517754\n",
      "acc for Lsat= 0.14589289218808213 \n",
      "acc for Psat= 0.1626250317527188 \n",
      "acc for optim= 0.14357113000005484\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.00643776822835207\n",
      "Loss on test= 0.007608096580952406\n",
      "acc for Lsat= 0.2009142703997592 \n",
      "acc for Psat= 0.1825598809454176 \n",
      "acc for optim= 0.12786727696786532\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.006757925730198622\n",
      "Loss on test= 0.006622709799557924\n",
      "acc for Lsat= 0.1818143410039031 \n",
      "acc for Psat= 0.177296021539304 \n",
      "acc for optim= 0.1291250583405296\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.006442774552851915\n",
      "Loss on test= 0.006538428831845522\n",
      "acc for Lsat= 0.21200507019077325 \n",
      "acc for Psat= 0.13652448169887066 \n",
      "acc for optim= 0.11138912486947244\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.006539676804095507\n",
      "Loss on test= 0.00651273550465703\n",
      "acc for Lsat= 0.17037061361285546 \n",
      "acc for Psat= 0.13638952762509385 \n",
      "acc for optim= 0.15465426610575783\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.006669812370091677\n",
      "Loss on test= 0.006578505504876375\n",
      "acc for Lsat= 0.18853157316334546 \n",
      "acc for Psat= 0.1481343504662315 \n",
      "acc for optim= 0.1240358042737676\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.006860591005533934\n",
      "Loss on test= 0.006751669570803642\n",
      "acc for Lsat= 0.22171405759743518 \n",
      "acc for Psat= 0.19544580371843445 \n",
      "acc for optim= 0.12418414251361456\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.006562547758221626\n",
      "Loss on test= 0.0071746897883713245\n",
      "acc for Lsat= 0.16856970296551785 \n",
      "acc for Psat= 0.17801688414894873 \n",
      "acc for optim= 0.13200182287255302\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.00647875526919961\n",
      "Loss on test= 0.006812669336795807\n",
      "acc for Lsat= 0.285451321138276 \n",
      "acc for Psat= 0.20437723957002163 \n",
      "acc for optim= 0.09942357934131804\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.006821407470852137\n",
      "Loss on test= 0.006588698830455542\n",
      "acc for Lsat= 0.24231687486947825 \n",
      "acc for Psat= 0.17952048959624436 \n",
      "acc for optim= 0.14587771770958272\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.0067457775585353374\n",
      "Loss on test= 0.0067438180558383465\n",
      "acc for Lsat= 0.1315643159776098 \n",
      "acc for Psat= 0.1501967711891565 \n",
      "acc for optim= 0.10544773367130095\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.006591515615582466\n",
      "Loss on test= 0.006373715121299028\n",
      "acc for Lsat= 0.25515552144497633 \n",
      "acc for Psat= 0.17572076675585574 \n",
      "acc for optim= 0.13446152510328424\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.006374359596520662\n",
      "Loss on test= 0.006709795445203781\n",
      "acc for Lsat= 0.2265297147548861 \n",
      "acc for Psat= 0.19176252773548993 \n",
      "acc for optim= 0.13206128538068798\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.00655723549425602\n",
      "Loss on test= 0.0063664172776043415\n",
      "acc for Lsat= 0.1807650609148873 \n",
      "acc for Psat= 0.16709575791739756 \n",
      "acc for optim= 0.13497910777934724\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.006399410776793957\n",
      "Loss on test= 0.006701158359646797\n",
      "acc for Lsat= 0.1773150481749326 \n",
      "acc for Psat= 0.16073066500636438 \n",
      "acc for optim= 0.1262229667045176\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.006287185475230217\n",
      "Loss on test= 0.007071193773299456\n",
      "acc for Lsat= 0.2564702466285477 \n",
      "acc for Psat= 0.18976357558535206 \n",
      "acc for optim= 0.12396097804109256\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.006402898114174604\n",
      "Loss on test= 0.006691931281238794\n",
      "acc for Lsat= 0.21659623686638144 \n",
      "acc for Psat= 0.22937081423070696 \n",
      "acc for optim= 0.13174181866149107\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.00634100753813982\n",
      "Loss on test= 0.00635524420067668\n",
      "acc for Lsat= 0.15700092270142502 \n",
      "acc for Psat= 0.2132646135158009 \n",
      "acc for optim= 0.1495359249206053\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.006428413093090057\n",
      "Loss on test= 0.006232064682990313\n",
      "acc for Lsat= 0.24139135118780863 \n",
      "acc for Psat= 0.15904653574236566 \n",
      "acc for optim= 0.12415424724005991\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.006403274834156036\n",
      "Loss on test= 0.006366493180394173\n",
      "acc for Lsat= 0.24608699227165845 \n",
      "acc for Psat= 0.17826287996851736 \n",
      "acc for optim= 0.13706011583821642\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.006353345699608326\n",
      "Loss on test= 0.006582407280802727\n",
      "acc for Lsat= 0.17707815495992285 \n",
      "acc for Psat= 0.18600668820242086 \n",
      "acc for optim= 0.12643989247994292\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.006254758220165968\n",
      "Loss on test= 0.006181323900818825\n",
      "acc for Lsat= 0.1934178810980585 \n",
      "acc for Psat= 0.14660938625456765 \n",
      "acc for optim= 0.1371992491185665\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.00619032047688961\n",
      "Loss on test= 0.00618588924407959\n",
      "acc for Lsat= 0.21031672631700835 \n",
      "acc for Psat= 0.17796743588729036 \n",
      "acc for optim= 0.14568749939401945\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.006430273875594139\n",
      "Loss on test= 0.006216721143573523\n",
      "acc for Lsat= 0.1689782724198368 \n",
      "acc for Psat= 0.20064130153817436 \n",
      "acc for optim= 0.11786932718112236\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.006376786157488823\n",
      "Loss on test= 0.006456559989601374\n",
      "acc for Lsat= 0.2158375018172794 \n",
      "acc for Psat= 0.15343533396824366 \n",
      "acc for optim= 0.11677966785565433\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.0062494222074747086\n",
      "Loss on test= 0.006172720342874527\n",
      "acc for Lsat= 0.10310740075591537 \n",
      "acc for Psat= 0.12181035915596618 \n",
      "acc for optim= 0.14285217593391686\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.006549431476742029\n",
      "Loss on test= 0.005918020848184824\n",
      "acc for Lsat= 0.16637120944344336 \n",
      "acc for Psat= 0.13335334095689985 \n",
      "acc for optim= 0.12818817359705767\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.006423318758606911\n",
      "Loss on test= 0.006508061662316322\n",
      "acc for Lsat= 0.23590930036476088 \n",
      "acc for Psat= 0.22051475259164968 \n",
      "acc for optim= 0.11517780191368526\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.0064843278378248215\n",
      "Loss on test= 0.006974200252443552\n",
      "acc for Lsat= 0.1883965733771523 \n",
      "acc for Psat= 0.13916671717177248 \n",
      "acc for optim= 0.1537366403758319\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.0063934107311069965\n",
      "Loss on test= 0.006335495971143246\n",
      "acc for Lsat= 0.1585327624860737 \n",
      "acc for Psat= 0.1682293682048718 \n",
      "acc for optim= 0.12470723704124491\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.006131735164672136\n",
      "Loss on test= 0.005877953488379717\n",
      "acc for Lsat= 0.20013902564015654 \n",
      "acc for Psat= 0.17505204191224444 \n",
      "acc for optim= 0.13066579163488415\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.006341927219182253\n",
      "Loss on test= 0.006226673722267151\n",
      "acc for Lsat= 0.15821076608780357 \n",
      "acc for Psat= 0.16364178930719694 \n",
      "acc for optim= 0.12979770694962806\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.005979695823043585\n",
      "Loss on test= 0.005857066251337528\n",
      "acc for Lsat= 0.156104069073788 \n",
      "acc for Psat= 0.12045915714568561 \n",
      "acc for optim= 0.11524544783040053\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.006045491900295019\n",
      "Loss on test= 0.005957263521850109\n",
      "acc for Lsat= 0.21742239128798246 \n",
      "acc for Psat= 0.1851994790033334 \n",
      "acc for optim= 0.13054726171928147\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.005922498181462288\n",
      "Loss on test= 0.007094099186360836\n",
      "acc for Lsat= 0.21946950629353523 \n",
      "acc for Psat= 0.15098498544345298 \n",
      "acc for optim= 0.1318958933568663\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.00599617650732398\n",
      "Loss on test= 0.006506847217679024\n",
      "acc for Lsat= 0.13796898608820307 \n",
      "acc for Psat= 0.1779181378790074 \n",
      "acc for optim= 0.1215115974450277\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.00595832010731101\n",
      "Loss on test= 0.006387617904692888\n",
      "acc for Lsat= 0.1369521568542243 \n",
      "acc for Psat= 0.14776674132897621 \n",
      "acc for optim= 0.14123820485029784\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.006150234956294298\n",
      "Loss on test= 0.006395991425961256\n",
      "acc for Lsat= 0.16808332055289713 \n",
      "acc for Psat= 0.11209261311321622 \n",
      "acc for optim= 0.11290968695862426\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.006120580248534679\n",
      "Loss on test= 0.005884623154997826\n",
      "acc for Lsat= 0.16549671306792232 \n",
      "acc for Psat= 0.1383527699444029 \n",
      "acc for optim= 0.12751479035553834\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.006284885574132204\n",
      "Loss on test= 0.00595708517357707\n",
      "acc for Lsat= 0.21291981708620572 \n",
      "acc for Psat= 0.19734766975873047 \n",
      "acc for optim= 0.14476681128144264\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.005975749809294939\n",
      "Loss on test= 0.006589215248823166\n",
      "acc for Lsat= 0.13599647560881245 \n",
      "acc for Psat= 0.13863031224658093 \n",
      "acc for optim= 0.10529961261434234\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.006034092977643013\n",
      "Loss on test= 0.00652341591194272\n",
      "acc for Lsat= 0.20561296410030788 \n",
      "acc for Psat= 0.17429486279272371 \n",
      "acc for optim= 0.145348747053908\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.006038816180080175\n",
      "Loss on test= 0.0064088222570717335\n",
      "acc for Lsat= 0.13002952726350891 \n",
      "acc for Psat= 0.1816066516459816 \n",
      "acc for optim= 0.12542433617636561\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.0060926214791834354\n",
      "Loss on test= 0.005543126258999109\n",
      "acc for Lsat= 0.18846313220759234 \n",
      "acc for Psat= 0.1710008057869143 \n",
      "acc for optim= 0.12096351523521459\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.006050397176295519\n",
      "Loss on test= 0.006372714880853891\n",
      "acc for Lsat= 0.10607797492088543 \n",
      "acc for Psat= 0.18175202939245436 \n",
      "acc for optim= 0.14468698824445406\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.006237475201487541\n",
      "Loss on test= 0.006119741592556238\n",
      "acc for Lsat= 0.16482992454742393 \n",
      "acc for Psat= 0.13226903975009918 \n",
      "acc for optim= 0.13226401417826614\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.006079936400055885\n",
      "Loss on test= 0.005970379337668419\n",
      "acc for Lsat= 0.12760758529313737 \n",
      "acc for Psat= 0.16982632596045732 \n",
      "acc for optim= 0.11707050239460336\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.005863153841346502\n",
      "Loss on test= 0.005898166913539171\n",
      "acc for Lsat= 0.167040696212401 \n",
      "acc for Psat= 0.2136929525165922 \n",
      "acc for optim= 0.12817240356364185\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.005767825525254011\n",
      "Loss on test= 0.005677027627825737\n",
      "acc for Lsat= 0.17981032902995744 \n",
      "acc for Psat= 0.14573165994241005 \n",
      "acc for optim= 0.1309750646404508\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.00606795959174633\n",
      "Loss on test= 0.006244911812245846\n",
      "acc for Lsat= 0.17686363969308636 \n",
      "acc for Psat= 0.182804447294782 \n",
      "acc for optim= 0.12529895922893453\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.005836667027324438\n",
      "Loss on test= 0.00608050636947155\n",
      "acc for Lsat= 0.1737992866999573 \n",
      "acc for Psat= 0.18951624802624187 \n",
      "acc for optim= 0.12188869735432996\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.005737717729061842\n",
      "Loss on test= 0.005869245156645775\n",
      "acc for Lsat= 0.14671315894358689 \n",
      "acc for Psat= 0.16180541287435013 \n",
      "acc for optim= 0.13583509613656336\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.00594473909586668\n",
      "Loss on test= 0.005900662858039141\n",
      "acc for Lsat= 0.2100145979784429 \n",
      "acc for Psat= 0.16912657125956482 \n",
      "acc for optim= 0.14448212175112632\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.0060745119117200375\n",
      "Loss on test= 0.005907915066927671\n",
      "acc for Lsat= 0.14944875315349135 \n",
      "acc for Psat= 0.16265000532277757 \n",
      "acc for optim= 0.13911018706858158\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.005890012253075838\n",
      "Loss on test= 0.006185568869113922\n",
      "acc for Lsat= 0.09695635979167289 \n",
      "acc for Psat= 0.11026204251619573 \n",
      "acc for optim= 0.13846054336883956\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.005874261260032654\n",
      "Loss on test= 0.006016988772898912\n",
      "acc for Lsat= 0.15118059662118968 \n",
      "acc for Psat= 0.1557563323682795 \n",
      "acc for optim= 0.11619193906274934\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.005827367305755615\n",
      "Loss on test= 0.005993626080453396\n",
      "acc for Lsat= 0.2001292708252246 \n",
      "acc for Psat= 0.1818807814270258 \n",
      "acc for optim= 0.13393760847652125\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.0055410778149962425\n",
      "Loss on test= 0.0060182614251971245\n",
      "acc for Lsat= 0.11367651023384598 \n",
      "acc for Psat= 0.15635991694741985 \n",
      "acc for optim= 0.12266127815382788\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.005762879736721516\n",
      "Loss on test= 0.005933911539614201\n",
      "acc for Lsat= 0.13468365479881564 \n",
      "acc for Psat= 0.1384139272591306 \n",
      "acc for optim= 0.11742609622888267\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.005875907838344574\n",
      "Loss on test= 0.0059770685620605946\n",
      "acc for Lsat= 0.14730330559218097 \n",
      "acc for Psat= 0.1990709077152941 \n",
      "acc for optim= 0.1015448151415007\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.005748495925217867\n",
      "Loss on test= 0.006273600738495588\n",
      "acc for Lsat= 0.11158831728001435 \n",
      "acc for Psat= 0.17190560108671585 \n",
      "acc for optim= 0.13145106073675883\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.0056594968773424625\n",
      "Loss on test= 0.006782296113669872\n",
      "acc for Lsat= 0.22903760232859188 \n",
      "acc for Psat= 0.21033388852245277 \n",
      "acc for optim= 0.13621722084159651\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.005757221952080727\n",
      "Loss on test= 0.005973375868052244\n",
      "acc for Lsat= 0.20105426251474354 \n",
      "acc for Psat= 0.12395098013803363 \n",
      "acc for optim= 0.12205195732207762\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.005732567980885506\n",
      "Loss on test= 0.006066904403269291\n",
      "acc for Lsat= 0.18139317817986012 \n",
      "acc for Psat= 0.1834152184633745 \n",
      "acc for optim= 0.11272643607420225\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.005926716141402721\n",
      "Loss on test= 0.005762623157352209\n",
      "acc for Lsat= 0.12485239318468505 \n",
      "acc for Psat= 0.1963564549676246 \n",
      "acc for optim= 0.13422246142807934\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.005779990926384926\n",
      "Loss on test= 0.005822938866913319\n",
      "acc for Lsat= 0.14149526012544003 \n",
      "acc for Psat= 0.12281551801910003 \n",
      "acc for optim= 0.14737262597514522\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.005619578994810581\n",
      "Loss on test= 0.00634140707552433\n",
      "acc for Lsat= 0.18607418328368416 \n",
      "acc for Psat= 0.18134391318178839 \n",
      "acc for optim= 0.1317612243195375\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.005636910442262888\n",
      "Loss on test= 0.005667472258210182\n",
      "acc for Lsat= 0.1348211747697658 \n",
      "acc for Psat= 0.15330734983500507 \n",
      "acc for optim= 0.141363761057922\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.00556001765653491\n",
      "Loss on test= 0.00589009327813983\n",
      "acc for Lsat= 0.13791397252740958 \n",
      "acc for Psat= 0.14599703485146165 \n",
      "acc for optim= 0.13075338994773725\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.005957551300525665\n",
      "Loss on test= 0.005662286188453436\n",
      "acc for Lsat= 0.18703077940477264 \n",
      "acc for Psat= 0.16730059818170653 \n",
      "acc for optim= 0.13589247970634866\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.005607385188341141\n",
      "Loss on test= 0.005766826216131449\n",
      "acc for Lsat= 0.15158226783387363 \n",
      "acc for Psat= 0.16767002828419209 \n",
      "acc for optim= 0.1034164146727158\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.005736588034778833\n",
      "Loss on test= 0.00600516889244318\n",
      "acc for Lsat= 0.210637179759538 \n",
      "acc for Psat= 0.19262581499060616 \n",
      "acc for optim= 0.1382777886206491\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.005644454155117273\n",
      "Loss on test= 0.006032539531588554\n",
      "acc for Lsat= 0.1559837127311362 \n",
      "acc for Psat= 0.15641841592474115 \n",
      "acc for optim= 0.11510946679239471\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.005565906874835491\n",
      "Loss on test= 0.005725491791963577\n",
      "acc for Lsat= 0.109560696201192 \n",
      "acc for Psat= 0.12687297788862553 \n",
      "acc for optim= 0.12685864806796113\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.005538366734981537\n",
      "Loss on test= 0.0058305105194449425\n",
      "acc for Lsat= 0.19085876064168084 \n",
      "acc for Psat= 0.15177646548383766 \n",
      "acc for optim= 0.13966686422160515\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.005591070279479027\n",
      "Loss on test= 0.0055747502483427525\n",
      "acc for Lsat= 0.19202305591251287 \n",
      "acc for Psat= 0.19534008536073896 \n",
      "acc for optim= 0.11064119595620367\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.005624530836939812\n",
      "Loss on test= 0.005993915256112814\n",
      "acc for Lsat= 0.15643775882199407 \n",
      "acc for Psat= 0.15557375974539253 \n",
      "acc for optim= 0.106566948302821\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.0054060001857578754\n",
      "Loss on test= 0.005761541426181793\n",
      "acc for Lsat= 0.15672534688686332 \n",
      "acc for Psat= 0.15849200134269065 \n",
      "acc for optim= 0.12598255831593028\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.005665007047355175\n",
      "Loss on test= 0.006126524414867163\n",
      "acc for Lsat= 0.18062596664660507 \n",
      "acc for Psat= 0.17697932705697086 \n",
      "acc for optim= 0.11463355888716048\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.00580383138731122\n",
      "Loss on test= 0.0059707071632146835\n",
      "acc for Lsat= 0.18115114513784647 \n",
      "acc for Psat= 0.14380304321336249 \n",
      "acc for optim= 0.10826297818372647\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.0055963727645576\n",
      "Loss on test= 0.005836987867951393\n",
      "acc for Lsat= 0.19755410941110718 \n",
      "acc for Psat= 0.13740035524177882 \n",
      "acc for optim= 0.13004035016314852\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.005600078962743282\n",
      "Loss on test= 0.0056834411807358265\n",
      "acc for Lsat= 0.12577743949239245 \n",
      "acc for Psat= 0.13787613157182932 \n",
      "acc for optim= 0.12256414991699988\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.005784748122096062\n",
      "Loss on test= 0.0066910842433571815\n",
      "acc for Lsat= 0.18876373152145082 \n",
      "acc for Psat= 0.12252612505108118 \n",
      "acc for optim= 0.14392826962284744\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.005730179138481617\n",
      "Loss on test= 0.006458842195570469\n",
      "acc for Lsat= 0.1241479976516631 \n",
      "acc for Psat= 0.1598958344871385 \n",
      "acc for optim= 0.1432687086570594\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.005528461653739214\n",
      "Loss on test= 0.005602519493550062\n",
      "acc for Lsat= 0.14246816746890545 \n",
      "acc for Psat= 0.14931669355266625 \n",
      "acc for optim= 0.11546924353266756\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.005488624330610037\n",
      "Loss on test= 0.0059836977161467075\n",
      "acc for Lsat= 0.1137388748013311 \n",
      "acc for Psat= 0.12875838407004872 \n",
      "acc for optim= 0.11369878498630391\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.00549019081518054\n",
      "Loss on test= 0.006169518455862999\n",
      "acc for Lsat= 0.1615976386043864 \n",
      "acc for Psat= 0.1801187437441614 \n",
      "acc for optim= 0.11872715061892652\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.005482636857777834\n",
      "Loss on test= 0.005399135872721672\n",
      "acc for Lsat= 0.17446253986822235 \n",
      "acc for Psat= 0.19227800130223235 \n",
      "acc for optim= 0.11516873401382731\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.005620189476758242\n",
      "Loss on test= 0.005539774429053068\n",
      "acc for Lsat= 0.13415197355465758 \n",
      "acc for Psat= 0.159198474087235 \n",
      "acc for optim= 0.11143572993266086\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.005360196810215712\n",
      "Loss on test= 0.005847121588885784\n",
      "acc for Lsat= 0.11618266665350853 \n",
      "acc for Psat= 0.2042903577287992 \n",
      "acc for optim= 0.14578423173063332\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.005201182793825865\n",
      "Loss on test= 0.00579021917656064\n",
      "acc for Lsat= 0.10982785584767246 \n",
      "acc for Psat= 0.1454725611127085 \n",
      "acc for optim= 0.1177115944835047\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.005457404535263777\n",
      "Loss on test= 0.0055304476991295815\n",
      "acc for Lsat= 0.1628558627433247 \n",
      "acc for Psat= 0.12946909355620542 \n",
      "acc for optim= 0.16599290041873851\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.005381329450756311\n",
      "Loss on test= 0.005749482661485672\n",
      "acc for Lsat= 0.11956711491155955 \n",
      "acc for Psat= 0.12508357923232122 \n",
      "acc for optim= 0.12185343440311651\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.005427225958555937\n",
      "Loss on test= 0.00626752432435751\n",
      "acc for Lsat= 0.18939366720021805 \n",
      "acc for Psat= 0.19294372494591194 \n",
      "acc for optim= 0.14061589704619515\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.00550897978246212\n",
      "Loss on test= 0.005591286346316338\n",
      "acc for Lsat= 0.1848948649648163 \n",
      "acc for Psat= 0.13561782561656502 \n",
      "acc for optim= 0.11905636478008495\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.005427660420536995\n",
      "Loss on test= 0.006233351770788431\n",
      "acc for Lsat= 0.18736224207613203 \n",
      "acc for Psat= 0.19188858134051165 \n",
      "acc for optim= 0.12244643900905633\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.005549287889152765\n",
      "Loss on test= 0.005146679002791643\n",
      "acc for Lsat= 0.16123273697060844 \n",
      "acc for Psat= 0.1665117381554511 \n",
      "acc for optim= 0.11761401950692137\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.005412550643086433\n",
      "Loss on test= 0.005585309583693743\n",
      "acc for Lsat= 0.11387728749670917 \n",
      "acc for Psat= 0.1523201910054518 \n",
      "acc for optim= 0.11126038241976251\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.0055172196589410305\n",
      "Loss on test= 0.00576438196003437\n",
      "acc for Lsat= 0.14371707114494509 \n",
      "acc for Psat= 0.11827517304401328 \n",
      "acc for optim= 0.1330422760349595\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.005463941488415003\n",
      "Loss on test= 0.005459711421281099\n",
      "acc for Lsat= 0.12475052198634431 \n",
      "acc for Psat= 0.08742128731682897 \n",
      "acc for optim= 0.11805994042919742\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.005484497174620628\n",
      "Loss on test= 0.0057219951413571835\n",
      "acc for Lsat= 0.17095694597810507 \n",
      "acc for Psat= 0.12971548945643008 \n",
      "acc for optim= 0.1316650555883017\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.005448650103062391\n",
      "Loss on test= 0.005278524477034807\n",
      "acc for Lsat= 0.16996481184226772 \n",
      "acc for Psat= 0.14588663113924363 \n",
      "acc for optim= 0.12573455160276759\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.005324580240994692\n",
      "Loss on test= 0.005919983610510826\n",
      "acc for Lsat= 0.12046267050835821 \n",
      "acc for Psat= 0.1339191685999847 \n",
      "acc for optim= 0.11687839719363385\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.005383582785725594\n",
      "Loss on test= 0.005530130118131638\n",
      "acc for Lsat= 0.13287009526458052 \n",
      "acc for Psat= 0.16278683725330564 \n",
      "acc for optim= 0.11585982485363881\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.005248663015663624\n",
      "Loss on test= 0.005502132698893547\n",
      "acc for Lsat= 0.11376004904094669 \n",
      "acc for Psat= 0.11538221313255942 \n",
      "acc for optim= 0.13352896578402984\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.005306482780724764\n",
      "Loss on test= 0.005664343014359474\n",
      "acc for Lsat= 0.1272523839854532 \n",
      "acc for Psat= 0.1458880605771103 \n",
      "acc for optim= 0.13144714791431195\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.005402848124504089\n",
      "Loss on test= 0.005401456728577614\n",
      "acc for Lsat= 0.14361727428735727 \n",
      "acc for Psat= 0.14756403335680565 \n",
      "acc for optim= 0.12714074852152002\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.005253369454294443\n",
      "Loss on test= 0.005505457986146212\n",
      "acc for Lsat= 0.14615785982338517 \n",
      "acc for Psat= 0.12695596367120743 \n",
      "acc for optim= 0.11063181758961743\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.005269432440400124\n",
      "Loss on test= 0.005702288821339607\n",
      "acc for Lsat= 0.1092803092324175 \n",
      "acc for Psat= 0.13260587035781807 \n",
      "acc for optim= 0.11386715395686527\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.005297618452459574\n",
      "Loss on test= 0.005584621336311102\n",
      "acc for Lsat= 0.11288123066252512 \n",
      "acc for Psat= 0.12493105698376894 \n",
      "acc for optim= 0.13019804348004982\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.005288899410516024\n",
      "Loss on test= 0.005884150043129921\n",
      "acc for Lsat= 0.11867575861752913 \n",
      "acc for Psat= 0.11682721604463747 \n",
      "acc for optim= 0.1158531203141643\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.005385366268455982\n",
      "Loss on test= 0.005861611571162939\n",
      "acc for Lsat= 0.15080652736489558 \n",
      "acc for Psat= 0.16624664194467995 \n",
      "acc for optim= 0.14548701751563284\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.005334870889782906\n",
      "Loss on test= 0.0054437932558357716\n",
      "acc for Lsat= 0.09138494938249803 \n",
      "acc for Psat= 0.1301122111423562 \n",
      "acc for optim= 0.14856578782200813\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.0051195030100643635\n",
      "Loss on test= 0.005426786839962006\n",
      "acc for Lsat= 0.11915621457026443 \n",
      "acc for Psat= 0.11829925250882904 \n",
      "acc for optim= 0.1376487616928191\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.005444867070764303\n",
      "Loss on test= 0.005829980131238699\n",
      "acc for Lsat= 0.08280151414995392 \n",
      "acc for Psat= 0.15112996644650897 \n",
      "acc for optim= 0.1353929981123656\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.005197909194976091\n",
      "Loss on test= 0.005777218844741583\n",
      "acc for Lsat= 0.15231640746868733 \n",
      "acc for Psat= 0.1798307569180098 \n",
      "acc for optim= 0.12938931693012515\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.005469958297908306\n",
      "Loss on test= 0.00613370118662715\n",
      "acc for Lsat= 0.16346924177681407 \n",
      "acc for Psat= 0.14775469361080062 \n",
      "acc for optim= 0.10805300229953395\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.005404466297477484\n",
      "Loss on test= 0.005932495929300785\n",
      "acc for Lsat= 0.177409118351837 \n",
      "acc for Psat= 0.15269502335124546 \n",
      "acc for optim= 0.14540182136827046\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.005276032257825136\n",
      "Loss on test= 0.005373222287744284\n",
      "acc for Lsat= 0.12016430890394582 \n",
      "acc for Psat= 0.14762221100843614 \n",
      "acc for optim= 0.11368617513734433\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.005158846732228994\n",
      "Loss on test= 0.005582033656537533\n",
      "acc for Lsat= 0.15075629514952502 \n",
      "acc for Psat= 0.15939994239144856 \n",
      "acc for optim= 0.12046735040429565\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.005312532652169466\n",
      "Loss on test= 0.005423237103968859\n",
      "acc for Lsat= 0.13303816077920297 \n",
      "acc for Psat= 0.13622523207838336 \n",
      "acc for optim= 0.12919051471787193\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.005502354819327593\n",
      "Loss on test= 0.005420216824859381\n",
      "acc for Lsat= 0.16731006227847603 \n",
      "acc for Psat= 0.12608780134986672 \n",
      "acc for optim= 0.1317627450916916\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.0051926118321716785\n",
      "Loss on test= 0.005718121770769358\n",
      "acc for Lsat= 0.1443949536834326 \n",
      "acc for Psat= 0.1695448705383266 \n",
      "acc for optim= 0.13133475365531114\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.005248828325420618\n",
      "Loss on test= 0.005474611651152372\n",
      "acc for Lsat= 0.1530839273085197 \n",
      "acc for Psat= 0.11681447648960683 \n",
      "acc for optim= 0.12893691009149835\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.0053048585541546345\n",
      "Loss on test= 0.005698740016669035\n",
      "acc for Lsat= 0.16251956785304678 \n",
      "acc for Psat= 0.1934504210948944 \n",
      "acc for optim= 0.12840313149273344\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.005271602887660265\n",
      "Loss on test= 0.005343748722225428\n",
      "acc for Lsat= 0.20758152401281726 \n",
      "acc for Psat= 0.128108495949871 \n",
      "acc for optim= 0.1218204102349571\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.005226507782936096\n",
      "Loss on test= 0.005877484567463398\n",
      "acc for Lsat= 0.11408119378352745 \n",
      "acc for Psat= 0.13016848222145605 \n",
      "acc for optim= 0.12207294360268861\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.005141196772456169\n",
      "Loss on test= 0.005337193142622709\n",
      "acc for Lsat= 0.09947892914836605 \n",
      "acc for Psat= 0.13126868966759908 \n",
      "acc for optim= 0.12707447364098495\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.005109220277518034\n",
      "Loss on test= 0.005469111725687981\n",
      "acc for Lsat= 0.14944305984924236 \n",
      "acc for Psat= 0.14171786275174883 \n",
      "acc for optim= 0.1388829436360134\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.005062559619545937\n",
      "Loss on test= 0.0057530091144144535\n",
      "acc for Lsat= 0.07466244061167042 \n",
      "acc for Psat= 0.1631019999816393 \n",
      "acc for optim= 0.1215233228997224\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.005113324150443077\n",
      "Loss on test= 0.00538508128374815\n",
      "acc for Lsat= 0.1162140482208795 \n",
      "acc for Psat= 0.1605271493188209 \n",
      "acc for optim= 0.12086335186743075\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.00516667403280735\n",
      "Loss on test= 0.005411915946751833\n",
      "acc for Lsat= 0.13774864986124966 \n",
      "acc for Psat= 0.1579785594302747 \n",
      "acc for optim= 0.1357021494380509\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.005314316134899855\n",
      "Loss on test= 0.006019404623657465\n",
      "acc for Lsat= 0.16332951058737105 \n",
      "acc for Psat= 0.18809828276021612 \n",
      "acc for optim= 0.14511977304290566\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.005143540911376476\n",
      "Loss on test= 0.005897331051528454\n",
      "acc for Lsat= 0.146312838016052 \n",
      "acc for Psat= 0.15547425475799376 \n",
      "acc for optim= 0.12674850023662051\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.005096946377307177\n",
      "Loss on test= 0.005776521284133196\n",
      "acc for Lsat= 0.1189760209268166 \n",
      "acc for Psat= 0.12741379156553498 \n",
      "acc for optim= 0.11364018252222902\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.005202328786253929\n",
      "Loss on test= 0.005412437953054905\n",
      "acc for Lsat= 0.14878201795767787 \n",
      "acc for Psat= 0.08861530323823293 \n",
      "acc for optim= 0.14691631651173034\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.004953560885041952\n",
      "Loss on test= 0.0056214118376374245\n",
      "acc for Lsat= 0.15716524706739518 \n",
      "acc for Psat= 0.1464311017965277 \n",
      "acc for optim= 0.13818862079157648\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.00509692681953311\n",
      "Loss on test= 0.00566099351271987\n",
      "acc for Lsat= 0.10759472720221513 \n",
      "acc for Psat= 0.11109062796458602 \n",
      "acc for optim= 0.13128347913475913\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.0051607489585876465\n",
      "Loss on test= 0.005747324787080288\n",
      "acc for Lsat= 0.1962496679690149 \n",
      "acc for Psat= 0.1542923603620794 \n",
      "acc for optim= 0.1326264017778966\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.005281876306980848\n",
      "Loss on test= 0.005188878625631332\n",
      "acc for Lsat= 0.13933163058633605 \n",
      "acc for Psat= 0.1629121692417862 \n",
      "acc for optim= 0.1226429386685292\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.0051935999654233456\n",
      "Loss on test= 0.005607948638498783\n",
      "acc for Lsat= 0.1809831933480584 \n",
      "acc for Psat= 0.1807402241263642 \n",
      "acc for optim= 0.13451253146760994\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.005056892056018114\n",
      "Loss on test= 0.005947405006736517\n",
      "acc for Lsat= 0.12090901006013155 \n",
      "acc for Psat= 0.14261883235950437 \n",
      "acc for optim= 0.13143610568820602\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.00513463094830513\n",
      "Loss on test= 0.00554796913638711\n",
      "acc for Lsat= 0.14627955062314868 \n",
      "acc for Psat= 0.14370027813129127 \n",
      "acc for optim= 0.11007950259631293\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.0049878875724971294\n",
      "Loss on test= 0.005009185057133436\n",
      "acc for Lsat= 0.11069315529635383 \n",
      "acc for Psat= 0.10230587298671405 \n",
      "acc for optim= 0.1329093629287349\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.004789453465491533\n",
      "Loss on test= 0.005511351395398378\n",
      "acc for Lsat= 0.13428124816143988 \n",
      "acc for Psat= 0.1588257207379987 \n",
      "acc for optim= 0.1254721415332622\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.0049874247051775455\n",
      "Loss on test= 0.005142822861671448\n",
      "acc for Lsat= 0.177177963933597 \n",
      "acc for Psat= 0.13300081414894926 \n",
      "acc for optim= 0.1254223530154882\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.004978731740266085\n",
      "Loss on test= 0.005316773429512978\n",
      "acc for Lsat= 0.1435833559371531 \n",
      "acc for Psat= 0.18819793877709243 \n",
      "acc for optim= 0.11748222008787303\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.005073877051472664\n",
      "Loss on test= 0.005064368713647127\n",
      "acc for Lsat= 0.11944274537139184 \n",
      "acc for Psat= 0.17198781705357963 \n",
      "acc for optim= 0.11667355169386913\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.004930819384753704\n",
      "Loss on test= 0.004779891110956669\n",
      "acc for Lsat= 0.15737708386344215 \n",
      "acc for Psat= 0.18096662659405005 \n",
      "acc for optim= 0.13669317141627996\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.005110030993819237\n",
      "Loss on test= 0.005429096519947052\n",
      "acc for Lsat= 0.09749402517142396 \n",
      "acc for Psat= 0.1352370206473602 \n",
      "acc for optim= 0.1272381767630577\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.005042640492320061\n",
      "Loss on test= 0.005744844675064087\n",
      "acc for Lsat= 0.15481176703340477 \n",
      "acc for Psat= 0.15350300466848743 \n",
      "acc for optim= 0.12770154883360696\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.004990340210497379\n",
      "Loss on test= 0.005238437559455633\n",
      "acc for Lsat= 0.12897372701101834 \n",
      "acc for Psat= 0.15805046550101703 \n",
      "acc for optim= 0.10569576407498163\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.005050953943282366\n",
      "Loss on test= 0.005471395328640938\n",
      "acc for Lsat= 0.07890386474577503 \n",
      "acc for Psat= 0.0860087404338022 \n",
      "acc for optim= 0.1642527239293688\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.0050671775825321674\n",
      "Loss on test= 0.005608207080513239\n",
      "acc for Lsat= 0.08926495835961153 \n",
      "acc for Psat= 0.1212861895457738 \n",
      "acc for optim= 0.14840138788955906\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.004979838617146015\n",
      "Loss on test= 0.0052439142018556595\n",
      "acc for Lsat= 0.17153518988440433 \n",
      "acc for Psat= 0.15371121191937062 \n",
      "acc for optim= 0.1314783232519403\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.004864792339503765\n",
      "Loss on test= 0.00538555346429348\n",
      "acc for Lsat= 0.1800964193729063 \n",
      "acc for Psat= 0.14601859517602456 \n",
      "acc for optim= 0.13882595600767267\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.004941701423376799\n",
      "Loss on test= 0.005231289193034172\n",
      "acc for Lsat= 0.1288903990967406 \n",
      "acc for Psat= 0.12874610370231998 \n",
      "acc for optim= 0.12028856068435642\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.004819713067263365\n",
      "Loss on test= 0.005778884515166283\n",
      "acc for Lsat= 0.14824232955773672 \n",
      "acc for Psat= 0.13137476477358076 \n",
      "acc for optim= 0.13437236948973602\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.005071100313216448\n",
      "Loss on test= 0.005223533138632774\n",
      "acc for Lsat= 0.1334961057226691 \n",
      "acc for Psat= 0.13016550222204792 \n",
      "acc for optim= 0.10824513502625956\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.004797019530087709\n",
      "Loss on test= 0.0051606204360723495\n",
      "acc for Lsat= 0.08068167308293697 \n",
      "acc for Psat= 0.1328751330470873 \n",
      "acc for optim= 0.11647353580014573\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.0049509513191878796\n",
      "Loss on test= 0.0053162043914198875\n",
      "acc for Lsat= 0.1471337896719989 \n",
      "acc for Psat= 0.13505045852313438 \n",
      "acc for optim= 0.14482191330494565\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.0050300476141273975\n",
      "Loss on test= 0.005067520774900913\n",
      "acc for Lsat= 0.11633886099702472 \n",
      "acc for Psat= 0.13563816652943692 \n",
      "acc for optim= 0.13800698498056996\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.005075924098491669\n",
      "Loss on test= 0.005372843239456415\n",
      "acc for Lsat= 0.08825854470099632 \n",
      "acc for Psat= 0.12870780978765753 \n",
      "acc for optim= 0.11240130114472574\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.004899555817246437\n",
      "Loss on test= 0.005238755140453577\n",
      "acc for Lsat= 0.14537551171249813 \n",
      "acc for Psat= 0.13818417854054132 \n",
      "acc for optim= 0.12206041762450089\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.004844237118959427\n",
      "Loss on test= 0.005262048915028572\n",
      "acc for Lsat= 0.16974008220454884 \n",
      "acc for Psat= 0.14506572655712566 \n",
      "acc for optim= 0.13000172906969157\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.0049511585384607315\n",
      "Loss on test= 0.0053295171819627285\n",
      "acc for Lsat= 0.11452925950288773 \n",
      "acc for Psat= 0.11355883677929847 \n",
      "acc for optim= 0.12327584324197637\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.0048025669530034065\n",
      "Loss on test= 0.0056800320744514465\n",
      "acc for Lsat= 0.15735832032644087 \n",
      "acc for Psat= 0.14867332854515147 \n",
      "acc for optim= 0.13616996152429944\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.004976034630089998\n",
      "Loss on test= 0.005203964188694954\n",
      "acc for Lsat= 0.1473456503202518 \n",
      "acc for Psat= 0.16730292379442188 \n",
      "acc for optim= 0.14169618451139993\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.004935114644467831\n",
      "Loss on test= 0.005192268174141645\n",
      "acc for Lsat= 0.11211893676469724 \n",
      "acc for Psat= 0.16581378111408818 \n",
      "acc for optim= 0.13943130925245997\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.005056178662925959\n",
      "Loss on test= 0.005290310364216566\n",
      "acc for Lsat= 0.15564397854420045 \n",
      "acc for Psat= 0.1501042420665423 \n",
      "acc for optim= 0.14435079704142278\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.00499442545697093\n",
      "Loss on test= 0.0052571045234799385\n",
      "acc for Lsat= 0.11840008111741757 \n",
      "acc for Psat= 0.17391656950510676 \n",
      "acc for optim= 0.13469192180976583\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.004832303151488304\n",
      "Loss on test= 0.0057298289611935616\n",
      "acc for Lsat= 0.17665508637825647 \n",
      "acc for Psat= 0.16550411325361994 \n",
      "acc for optim= 0.13890571782960454\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.005132121499627829\n",
      "Loss on test= 0.005219276994466782\n",
      "acc for Lsat= 0.1354695429197616 \n",
      "acc for Psat= 0.13563351089962655 \n",
      "acc for optim= 0.11945961855558886\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.004797481931746006\n",
      "Loss on test= 0.005316246300935745\n",
      "acc for Lsat= 0.16203083506681853 \n",
      "acc for Psat= 0.17133912094383655 \n",
      "acc for optim= 0.15278974240128365\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.004995111841708422\n",
      "Loss on test= 0.0051920656114816666\n",
      "acc for Lsat= 0.15327392518520355 \n",
      "acc for Psat= 0.22146141425602967 \n",
      "acc for optim= 0.12814686374945772\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.0048788441345095634\n",
      "Loss on test= 0.005442544352263212\n",
      "acc for Lsat= 0.08856676428371833 \n",
      "acc for Psat= 0.1543968231158538 \n",
      "acc for optim= 0.10911446538779677\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.004874464590102434\n",
      "Loss on test= 0.005554845090955496\n",
      "acc for Lsat= 0.13055416248324844 \n",
      "acc for Psat= 0.1757870347549518 \n",
      "acc for optim= 0.11557206051010224\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.004932028241455555\n",
      "Loss on test= 0.005094275809824467\n",
      "acc for Lsat= 0.095445958017889 \n",
      "acc for Psat= 0.12649376379946867 \n",
      "acc for optim= 0.12504526641633776\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.004810289479792118\n",
      "Loss on test= 0.005043531768023968\n",
      "acc for Lsat= 0.11914141145017412 \n",
      "acc for Psat= 0.11622192296716902 \n",
      "acc for optim= 0.14213179680518806\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.0049079968594014645\n",
      "Loss on test= 0.005107898730784655\n",
      "acc for Lsat= 0.19180870019934243 \n",
      "acc for Psat= 0.11972564430389968 \n",
      "acc for optim= 0.14094672250858922\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.004756812937557697\n",
      "Loss on test= 0.004772940184921026\n",
      "acc for Lsat= 0.09823129512369633 \n",
      "acc for Psat= 0.11000549084403449 \n",
      "acc for optim= 0.132746291346848\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.004835269879549742\n",
      "Loss on test= 0.005113968625664711\n",
      "acc for Lsat= 0.087537701590918 \n",
      "acc for Psat= 0.1302434429526329 \n",
      "acc for optim= 0.12346047194053729\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.004864376969635487\n",
      "Loss on test= 0.00511389784514904\n",
      "acc for Lsat= 0.11927708375474645 \n",
      "acc for Psat= 0.13147159347621104 \n",
      "acc for optim= 0.14274175126209027\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.004983880557119846\n",
      "Loss on test= 0.005229730624705553\n",
      "acc for Lsat= 0.09956033746453209 \n",
      "acc for Psat= 0.10394385115553935 \n",
      "acc for optim= 0.11854195788813134\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.004945195745676756\n",
      "Loss on test= 0.005222030449658632\n",
      "acc for Lsat= 0.14827401004731655 \n",
      "acc for Psat= 0.17731496857272255 \n",
      "acc for optim= 0.12949361305476892\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.004840258974581957\n",
      "Loss on test= 0.005974951200187206\n",
      "acc for Lsat= 0.10862144543271926 \n",
      "acc for Psat= 0.1618398912768397 \n",
      "acc for optim= 0.12621010715762773\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.004853087943047285\n",
      "Loss on test= 0.005409315228462219\n",
      "acc for Lsat= 0.10608216054323646 \n",
      "acc for Psat= 0.14231510093021724 \n",
      "acc for optim= 0.13236617718616295\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.0048956554383039474\n",
      "Loss on test= 0.005100575275719166\n",
      "acc for Lsat= 0.12641546983892718 \n",
      "acc for Psat= 0.14839363900116748 \n",
      "acc for optim= 0.13061074798719752\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.004690117202699184\n",
      "Loss on test= 0.005415911320596933\n",
      "acc for Lsat= 0.13023034053751165 \n",
      "acc for Psat= 0.13431836509456238 \n",
      "acc for optim= 0.12985987071361807\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.004773077089339495\n",
      "Loss on test= 0.004910147283226252\n",
      "acc for Lsat= 0.08964336055537893 \n",
      "acc for Psat= 0.11558379595064455 \n",
      "acc for optim= 0.1267888637828744\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.004750982858240604\n",
      "Loss on test= 0.005496724974364042\n",
      "acc for Lsat= 0.11837917762911981 \n",
      "acc for Psat= 0.14595198232887518 \n",
      "acc for optim= 0.13979039672348234\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.004751655738800764\n",
      "Loss on test= 0.004952921997755766\n",
      "acc for Lsat= 0.11326658063464695 \n",
      "acc for Psat= 0.13186359418452615 \n",
      "acc for optim= 0.1473645209852192\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.004685351625084877\n",
      "Loss on test= 0.005444010719656944\n",
      "acc for Lsat= 0.13147469907481638 \n",
      "acc for Psat= 0.18794710214974153 \n",
      "acc for optim= 0.12125394539260823\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.004994963761419058\n",
      "Loss on test= 0.005496486555784941\n",
      "acc for Lsat= 0.13291563008291027 \n",
      "acc for Psat= 0.16661767478540745 \n",
      "acc for optim= 0.12982065001657853\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.004719895776361227\n",
      "Loss on test= 0.005090796854346991\n",
      "acc for Lsat= 0.15426590172056523 \n",
      "acc for Psat= 0.1462838829870129 \n",
      "acc for optim= 0.10811550868675113\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.004676246549934149\n",
      "Loss on test= 0.005220783408731222\n",
      "acc for Lsat= 0.1265981894555605 \n",
      "acc for Psat= 0.13447154700083452 \n",
      "acc for optim= 0.11288239092876513\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.004754825960844755\n",
      "Loss on test= 0.0054063620045781136\n",
      "acc for Lsat= 0.10782558827971418 \n",
      "acc for Psat= 0.09239275646298968 \n",
      "acc for optim= 0.12029907265160647\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.004840117879211903\n",
      "Loss on test= 0.0052457875572144985\n",
      "acc for Lsat= 0.11550223961886433 \n",
      "acc for Psat= 0.17542141061211522 \n",
      "acc for optim= 0.1333267373136348\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.0047817714512348175\n",
      "Loss on test= 0.0050174156203866005\n",
      "acc for Lsat= 0.09508116982437463 \n",
      "acc for Psat= 0.10816011971716459 \n",
      "acc for optim= 0.13204017121137845\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.004685813561081886\n",
      "Loss on test= 0.004911905154585838\n",
      "acc for Lsat= 0.1211787109884123 \n",
      "acc for Psat= 0.09417631697013146 \n",
      "acc for optim= 0.13222518702322203\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.004801956936717033\n",
      "Loss on test= 0.005132025573402643\n",
      "acc for Lsat= 0.14323255885392427 \n",
      "acc for Psat= 0.17272980097267362 \n",
      "acc for optim= 0.134411265866624\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.004768006969243288\n",
      "Loss on test= 0.005245782434940338\n",
      "acc for Lsat= 0.10734241056100775 \n",
      "acc for Psat= 0.1619582169999679 \n",
      "acc for optim= 0.13177524230235982\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.004954715259373188\n",
      "Loss on test= 0.005389092490077019\n",
      "acc for Lsat= 0.1417606986231274 \n",
      "acc for Psat= 0.15938386279675695 \n",
      "acc for optim= 0.1302197332034767\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.004980572033673525\n",
      "Loss on test= 0.005150910466909409\n",
      "acc for Lsat= 0.11026091806383596 \n",
      "acc for Psat= 0.12755629337496227 \n",
      "acc for optim= 0.12293720819676916\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.004522664938122034\n",
      "Loss on test= 0.004919834900647402\n",
      "acc for Lsat= 0.1302697880892083 \n",
      "acc for Psat= 0.13030739043218395 \n",
      "acc for optim= 0.1247669860151493\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.0046933721750974655\n",
      "Loss on test= 0.005436155013740063\n",
      "acc for Lsat= 0.13417769197581542 \n",
      "acc for Psat= 0.12076011672616005 \n",
      "acc for optim= 0.13306860219583744\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.0048317317850887775\n",
      "Loss on test= 0.005059824325144291\n",
      "acc for Lsat= 0.12163768488810295 \n",
      "acc for Psat= 0.11130597713377534 \n",
      "acc for optim= 0.11420686015238364\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.004641393199563026\n",
      "Loss on test= 0.005301244556903839\n",
      "acc for Lsat= 0.092266534341939 \n",
      "acc for Psat= 0.14785964768897328 \n",
      "acc for optim= 0.11416906796188818\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.004709871485829353\n",
      "Loss on test= 0.004916153848171234\n",
      "acc for Lsat= 0.11262028294408487 \n",
      "acc for Psat= 0.12680089364423314 \n",
      "acc for optim= 0.09444305960561097\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.00470696808770299\n",
      "Loss on test= 0.004800696857273579\n",
      "acc for Lsat= 0.12919401755142543 \n",
      "acc for Psat= 0.12095165707998806 \n",
      "acc for optim= 0.13182501065441304\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.0047606113366782665\n",
      "Loss on test= 0.005629675462841988\n",
      "acc for Lsat= 0.14562152556997413 \n",
      "acc for Psat= 0.1396304893747179 \n",
      "acc for optim= 0.12919118276072872\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.004715421237051487\n",
      "Loss on test= 0.005213525146245956\n",
      "acc for Lsat= 0.1375756237345437 \n",
      "acc for Psat= 0.1494085188411797 \n",
      "acc for optim= 0.11293771101110098\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.0046445163898169994\n",
      "Loss on test= 0.005391248036175966\n",
      "acc for Lsat= 0.1346445174680816 \n",
      "acc for Psat= 0.1542485235258937 \n",
      "acc for optim= 0.13085487189447223\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.004675421863794327\n",
      "Loss on test= 0.004855545237660408\n",
      "acc for Lsat= 0.12397223835190137 \n",
      "acc for Psat= 0.14311937056481838 \n",
      "acc for optim= 0.13336165725357002\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.0047317142598330975\n",
      "Loss on test= 0.005122521426528692\n",
      "acc for Lsat= 0.14559384321586955 \n",
      "acc for Psat= 0.1329368258431916 \n",
      "acc for optim= 0.146260800318689\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.004801492672413588\n",
      "Loss on test= 0.004967713728547096\n",
      "acc for Lsat= 0.11560981884637538 \n",
      "acc for Psat= 0.16655905079096556 \n",
      "acc for optim= 0.12851981474604043\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.004638690035790205\n",
      "Loss on test= 0.005320324096828699\n",
      "acc for Lsat= 0.10340660531073809 \n",
      "acc for Psat= 0.08460891389081047 \n",
      "acc for optim= 0.12041887992786036\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.004684089682996273\n",
      "Loss on test= 0.005033384542912245\n",
      "acc for Lsat= 0.14221222608143258 \n",
      "acc for Psat= 0.16065396394373643 \n",
      "acc for optim= 0.12709063990041614\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.004566957708448172\n",
      "Loss on test= 0.005019904114305973\n",
      "acc for Lsat= 0.12812713388767508 \n",
      "acc for Psat= 0.10655801712224881 \n",
      "acc for optim= 0.13148545996389455\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.004550973419100046\n",
      "Loss on test= 0.0049756551161408424\n",
      "acc for Lsat= 0.09769616679598887 \n",
      "acc for Psat= 0.1775893939452039 \n",
      "acc for optim= 0.1324619453581464\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.0048848413862288\n",
      "Loss on test= 0.005472688935697079\n",
      "acc for Lsat= 0.13775238249541466 \n",
      "acc for Psat= 0.1530987937003374 \n",
      "acc for optim= 0.14363235452522835\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.00461496040225029\n",
      "Loss on test= 0.005270419642329216\n",
      "acc for Lsat= 0.13382367267169887 \n",
      "acc for Psat= 0.1421652326049904 \n",
      "acc for optim= 0.13587427506637242\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.004709433298557997\n",
      "Loss on test= 0.005381407216191292\n",
      "acc for Lsat= 0.12323376480101918 \n",
      "acc for Psat= 0.1397321424447 \n",
      "acc for optim= 0.12339533422426838\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.004598990548402071\n",
      "Loss on test= 0.005916642490774393\n",
      "acc for Lsat= 0.13888686258966723 \n",
      "acc for Psat= 0.16136878377680355 \n",
      "acc for optim= 0.10592517682299432\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.004642128944396973\n",
      "Loss on test= 0.004975359886884689\n",
      "acc for Lsat= 0.08938049126623406 \n",
      "acc for Psat= 0.11798565001744363 \n",
      "acc for optim= 0.11319451244263393\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.004762770142406225\n",
      "Loss on test= 0.005060966592282057\n",
      "acc for Lsat= 0.1304207522318595 \n",
      "acc for Psat= 0.16053588264104393 \n",
      "acc for optim= 0.13854004119720129\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.0046158735640347\n",
      "Loss on test= 0.005130979232490063\n",
      "acc for Lsat= 0.13381443971108334 \n",
      "acc for Psat= 0.16608878732141522 \n",
      "acc for optim= 0.13086750407496262\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.004565542563796043\n",
      "Loss on test= 0.0055852895602583885\n",
      "acc for Lsat= 0.10388287224082483 \n",
      "acc for Psat= 0.13616526147557628 \n",
      "acc for optim= 0.12944043955455223\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.004708569496870041\n",
      "Loss on test= 0.005132483784109354\n",
      "acc for Lsat= 0.09782851544312304 \n",
      "acc for Psat= 0.13101574247573605 \n",
      "acc for optim= 0.14773097292830548\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.004648457746952772\n",
      "Loss on test= 0.005197212565690279\n",
      "acc for Lsat= 0.12240242395718168 \n",
      "acc for Psat= 0.09026493944434656 \n",
      "acc for optim= 0.12014023444013826\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.004552180878818035\n",
      "Loss on test= 0.004942211788147688\n",
      "acc for Lsat= 0.09364579242861105 \n",
      "acc for Psat= 0.13536483432269758 \n",
      "acc for optim= 0.11953148432075977\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.004649513401091099\n",
      "Loss on test= 0.005511771887540817\n",
      "acc for Lsat= 0.1317550622754627 \n",
      "acc for Psat= 0.10018133319034758 \n",
      "acc for optim= 0.1092946832973717\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.0047176494263112545\n",
      "Loss on test= 0.005898959934711456\n",
      "acc for Lsat= 0.11567737410465877 \n",
      "acc for Psat= 0.13314807616795102 \n",
      "acc for optim= 0.14938780484307143\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.004661243874579668\n",
      "Loss on test= 0.005060234107077122\n",
      "acc for Lsat= 0.10320447405360432 \n",
      "acc for Psat= 0.1661629650948776 \n",
      "acc for optim= 0.11230780217900044\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.004643533378839493\n",
      "Loss on test= 0.0052082110196352005\n",
      "acc for Lsat= 0.10731375445741126 \n",
      "acc for Psat= 0.16772268894581227 \n",
      "acc for optim= 0.14388741894314686\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.004903176799416542\n",
      "Loss on test= 0.0049913679249584675\n",
      "acc for Lsat= 0.12286489035209848 \n",
      "acc for Psat= 0.09290184297270167 \n",
      "acc for optim= 0.14015381917771366\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.004654550924897194\n",
      "Loss on test= 0.005486903712153435\n",
      "acc for Lsat= 0.1304971368194351 \n",
      "acc for Psat= 0.16877209208905697 \n",
      "acc for optim= 0.13515080366697577\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.004639267455786467\n",
      "Loss on test= 0.005244256928563118\n",
      "acc for Lsat= 0.12201045453548431 \n",
      "acc for Psat= 0.1522366213094857 \n",
      "acc for optim= 0.1288762875418696\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.004597972147166729\n",
      "Loss on test= 0.00488649308681488\n",
      "acc for Lsat= 0.10888536119212706 \n",
      "acc for Psat= 0.1003058475907892 \n",
      "acc for optim= 0.1437877118587494\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.004394138231873512\n",
      "Loss on test= 0.0049336799420416355\n",
      "acc for Lsat= 0.11285684511272444 \n",
      "acc for Psat= 0.1464789224167665 \n",
      "acc for optim= 0.10811315655721249\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.004523907322436571\n",
      "Loss on test= 0.0052315304055809975\n",
      "acc for Lsat= 0.1380213296247853 \n",
      "acc for Psat= 0.13270278264664942 \n",
      "acc for optim= 0.14903510392953953\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.004461257252842188\n",
      "Loss on test= 0.005122510250657797\n",
      "acc for Lsat= 0.1392727703269985 \n",
      "acc for Psat= 0.11922514186395954 \n",
      "acc for optim= 0.13316976293834967\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.004608396906405687\n",
      "Loss on test= 0.004896172787994146\n",
      "acc for Lsat= 0.09984005718595451 \n",
      "acc for Psat= 0.10600324984019001 \n",
      "acc for optim= 0.11463149005754127\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.00459768483415246\n",
      "Loss on test= 0.004921008832752705\n",
      "acc for Lsat= 0.13683797189150937 \n",
      "acc for Psat= 0.16609574626717302 \n",
      "acc for optim= 0.14717796569069228\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.004505148157477379\n",
      "Loss on test= 0.00498158298432827\n",
      "acc for Lsat= 0.12123046463562383 \n",
      "acc for Psat= 0.1288494528578465 \n",
      "acc for optim= 0.14005103735770616\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.004469516221433878\n",
      "Loss on test= 0.004955703392624855\n",
      "acc for Lsat= 0.13798446771882786 \n",
      "acc for Psat= 0.13293657146601212 \n",
      "acc for optim= 0.11513690114952624\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.004665776621550322\n",
      "Loss on test= 0.0051397234201431274\n",
      "acc for Lsat= 0.1051222955639888 \n",
      "acc for Psat= 0.1923289710862769 \n",
      "acc for optim= 0.12890359316952527\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.00452040322124958\n",
      "Loss on test= 0.005097331013530493\n",
      "acc for Lsat= 0.09979938450528102 \n",
      "acc for Psat= 0.16942369212241223 \n",
      "acc for optim= 0.14425222795560128\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.004516690503805876\n",
      "Loss on test= 0.005090152844786644\n",
      "acc for Lsat= 0.10399853768629125 \n",
      "acc for Psat= 0.1235795450500316 \n",
      "acc for optim= 0.1429662804843651\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.004489240702241659\n",
      "Loss on test= 0.004854864906519651\n",
      "acc for Lsat= 0.099951275876568 \n",
      "acc for Psat= 0.1179989206397699 \n",
      "acc for optim= 0.1335488883778453\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.004437288269400597\n",
      "Loss on test= 0.004936660639941692\n",
      "acc for Lsat= 0.08126795589406458 \n",
      "acc for Psat= 0.08345638176736732 \n",
      "acc for optim= 0.12012288887571129\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.00437679048627615\n",
      "Loss on test= 0.00500738900154829\n",
      "acc for Lsat= 0.07406694373478079 \n",
      "acc for Psat= 0.09657111969621231 \n",
      "acc for optim= 0.13306190994141312\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.0044756922870874405\n",
      "Loss on test= 0.005776523146778345\n",
      "acc for Lsat= 0.0995709931885358 \n",
      "acc for Psat= 0.17219501857956251 \n",
      "acc for optim= 0.14017524200284648\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.004506580997258425\n",
      "Loss on test= 0.005281319376081228\n",
      "acc for Lsat= 0.09082002249649829 \n",
      "acc for Psat= 0.08341565398020773 \n",
      "acc for optim= 0.15129111890888047\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.004836589563637972\n",
      "Loss on test= 0.005292089655995369\n",
      "acc for Lsat= 0.09704020779786839 \n",
      "acc for Psat= 0.1076569073419604 \n",
      "acc for optim= 0.14422142810912597\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.0046287719160318375\n",
      "Loss on test= 0.005433241371065378\n",
      "acc for Lsat= 0.12853152967161602 \n",
      "acc for Psat= 0.11136141666469888 \n",
      "acc for optim= 0.11778584398497413\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.004522384610027075\n",
      "Loss on test= 0.005133619531989098\n",
      "acc for Lsat= 0.10544013997746839 \n",
      "acc for Psat= 0.12096239900630382 \n",
      "acc for optim= 0.14794196033229431\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.004446517210453749\n",
      "Loss on test= 0.00518307089805603\n",
      "acc for Lsat= 0.17128101689741015 \n",
      "acc for Psat= 0.1361473843183679 \n",
      "acc for optim= 0.1281729969713423\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.004516142886132002\n",
      "Loss on test= 0.00527140311896801\n",
      "acc for Lsat= 0.13651139723757902 \n",
      "acc for Psat= 0.12094141284210815 \n",
      "acc for optim= 0.12881144939456135\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.004547069780528545\n",
      "Loss on test= 0.005131598562002182\n",
      "acc for Lsat= 0.12464188142783111 \n",
      "acc for Psat= 0.14517664640314049 \n",
      "acc for optim= 0.1272292575190982\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.004518358036875725\n",
      "Loss on test= 0.005516642704606056\n",
      "acc for Lsat= 0.14750519601835144 \n",
      "acc for Psat= 0.12873258312336272 \n",
      "acc for optim= 0.11206762901403838\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.0045371330343186855\n",
      "Loss on test= 0.0050786337815225124\n",
      "acc for Lsat= 0.13048992243905863 \n",
      "acc for Psat= 0.1572592676190349 \n",
      "acc for optim= 0.11442015962448851\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.0045660496689379215\n",
      "Loss on test= 0.004924790933728218\n",
      "acc for Lsat= 0.14956691338253827 \n",
      "acc for Psat= 0.15431471947684056 \n",
      "acc for optim= 0.12846466949688168\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.004414194729179144\n",
      "Loss on test= 0.005341352894902229\n",
      "acc for Lsat= 0.11827704993387063 \n",
      "acc for Psat= 0.21021304455482298 \n",
      "acc for optim= 0.13496148321104962\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.004441083874553442\n",
      "Loss on test= 0.004819853231310844\n",
      "acc for Lsat= 0.13538368273940352 \n",
      "acc for Psat= 0.1409091006240083 \n",
      "acc for optim= 0.13036955437726444\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.004501129034906626\n",
      "Loss on test= 0.005010259337723255\n",
      "acc for Lsat= 0.1287119009454424 \n",
      "acc for Psat= 0.09700095150361045 \n",
      "acc for optim= 0.14949635271396902\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.004480935633182526\n",
      "Loss on test= 0.005213017575442791\n",
      "acc for Lsat= 0.12295185991873343 \n",
      "acc for Psat= 0.15239039047931632 \n",
      "acc for optim= 0.12767098135211402\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.004447307903319597\n",
      "Loss on test= 0.004883690737187862\n",
      "acc for Lsat= 0.09773265250906762 \n",
      "acc for Psat= 0.15213832755883536 \n",
      "acc for optim= 0.1448988724603421\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.0044975061900913715\n",
      "Loss on test= 0.004918012768030167\n",
      "acc for Lsat= 0.0999514376744628 \n",
      "acc for Psat= 0.1281292699277401 \n",
      "acc for optim= 0.14368345712622008\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.004480001050978899\n",
      "Loss on test= 0.0051913997158408165\n",
      "acc for Lsat= 0.1282236937420546 \n",
      "acc for Psat= 0.095146462890423 \n",
      "acc for optim= 0.1554062861121363\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.004447783809155226\n",
      "Loss on test= 0.0052426583133637905\n",
      "acc for Lsat= 0.1079065422527492 \n",
      "acc for Psat= 0.11640596821800703 \n",
      "acc for optim= 0.1129468671602404\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.004394212272018194\n",
      "Loss on test= 0.004986931569874287\n",
      "acc for Lsat= 0.12589149283141726 \n",
      "acc for Psat= 0.12903585988614294 \n",
      "acc for optim= 0.14066149946302176\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.00468834675848484\n",
      "Loss on test= 0.005028420593589544\n",
      "acc for Lsat= 0.07828261356593834 \n",
      "acc for Psat= 0.11606637479013039 \n",
      "acc for optim= 0.1533509898516867\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.00443647475913167\n",
      "Loss on test= 0.004975273739546537\n",
      "acc for Lsat= 0.09649626456666738 \n",
      "acc for Psat= 0.14298147062719282 \n",
      "acc for optim= 0.11289479401117812\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.004392084199935198\n",
      "Loss on test= 0.004937892779707909\n",
      "acc for Lsat= 0.11103767507463796 \n",
      "acc for Psat= 0.1578900274148004 \n",
      "acc for optim= 0.14623228615770736\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.004455315414816141\n",
      "Loss on test= 0.005033888854086399\n",
      "acc for Lsat= 0.13496744963857862 \n",
      "acc for Psat= 0.13562548708998495 \n",
      "acc for optim= 0.14066270247308743\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.004310243763029575\n",
      "Loss on test= 0.004942410625517368\n",
      "acc for Lsat= 0.08582578833900495 \n",
      "acc for Psat= 0.10597087890427145 \n",
      "acc for optim= 0.16232147295441893\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.0044339727610349655\n",
      "Loss on test= 0.004820526111871004\n",
      "acc for Lsat= 0.08670374603631596 \n",
      "acc for Psat= 0.1209680627928012 \n",
      "acc for optim= 0.1345716891810298\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.004346202593296766\n",
      "Loss on test= 0.004987205378711224\n",
      "acc for Lsat= 0.12253613500959343 \n",
      "acc for Psat= 0.12091136465379451 \n",
      "acc for optim= 0.1087086448031995\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.004450205247849226\n",
      "Loss on test= 0.0048507885076105595\n",
      "acc for Lsat= 0.12288455716851684 \n",
      "acc for Psat= 0.2006776347083764 \n",
      "acc for optim= 0.15274985279473993\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.00435612490400672\n",
      "Loss on test= 0.0051734852604568005\n",
      "acc for Lsat= 0.09090276248753071 \n",
      "acc for Psat= 0.11872858829312666 \n",
      "acc for optim= 0.13996970187872648\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.0043753222562372684\n",
      "Loss on test= 0.005055230110883713\n",
      "acc for Lsat= 0.1062737556381358 \n",
      "acc for Psat= 0.12659093189156717 \n",
      "acc for optim= 0.15672190937524041\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.004352330230176449\n",
      "Loss on test= 0.004806244745850563\n",
      "acc for Lsat= 0.08352009799434906 \n",
      "acc for Psat= 0.09707743757300907 \n",
      "acc for optim= 0.13121364493336943\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.004376503638923168\n",
      "Loss on test= 0.005040282383561134\n",
      "acc for Lsat= 0.1124591709037001 \n",
      "acc for Psat= 0.14351258338946435 \n",
      "acc for optim= 0.14911731448955834\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.004399760160595179\n",
      "Loss on test= 0.0051225111819803715\n",
      "acc for Lsat= 0.07621049805958238 \n",
      "acc for Psat= 0.11187260592770246 \n",
      "acc for optim= 0.13493013857967323\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.004160016309469938\n",
      "Loss on test= 0.005105968564748764\n",
      "acc for Lsat= 0.12765400442812178 \n",
      "acc for Psat= 0.1548249744810164 \n",
      "acc for optim= 0.1352362631716662\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.004399864934384823\n",
      "Loss on test= 0.004822660703212023\n",
      "acc for Lsat= 0.10672482786402623 \n",
      "acc for Psat= 0.10152403441154295 \n",
      "acc for optim= 0.15149908631833064\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.0042574480175971985\n",
      "Loss on test= 0.00481402687728405\n",
      "acc for Lsat= 0.12264174491994911 \n",
      "acc for Psat= 0.10063499996128182 \n",
      "acc for optim= 0.18098359619681206\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.004414636176079512\n",
      "Loss on test= 0.004978491924703121\n",
      "acc for Lsat= 0.13982947455305192 \n",
      "acc for Psat= 0.14482122328546312 \n",
      "acc for optim= 0.1406302134459515\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.004525028634816408\n",
      "Loss on test= 0.005183938890695572\n",
      "acc for Lsat= 0.10332659081985993 \n",
      "acc for Psat= 0.11069774371571839 \n",
      "acc for optim= 0.12952535069133672\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.004488732665777206\n",
      "Loss on test= 0.004701400175690651\n",
      "acc for Lsat= 0.08831747207376692 \n",
      "acc for Psat= 0.09305352384560844 \n",
      "acc for optim= 0.13781367728693616\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.004336220677942038\n",
      "Loss on test= 0.004903136286884546\n",
      "acc for Lsat= 0.087766758415253 \n",
      "acc for Psat= 0.1280774331599888 \n",
      "acc for optim= 0.12901687148648003\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.004451875574886799\n",
      "Loss on test= 0.004781279247254133\n",
      "acc for Lsat= 0.09722212416171613 \n",
      "acc for Psat= 0.11457787865462403 \n",
      "acc for optim= 0.13537380921318093\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.00428816257044673\n",
      "Loss on test= 0.005019610747694969\n",
      "acc for Lsat= 0.1346730722838806 \n",
      "acc for Psat= 0.12582593460360336 \n",
      "acc for optim= 0.14289709558296534\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.00437427731230855\n",
      "Loss on test= 0.005038006231188774\n",
      "acc for Lsat= 0.10857350311966406 \n",
      "acc for Psat= 0.12866979599412945 \n",
      "acc for optim= 0.13818971375829076\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.004420402459800243\n",
      "Loss on test= 0.005064900498837233\n",
      "acc for Lsat= 0.096371821153702 \n",
      "acc for Psat= 0.11142715043388307 \n",
      "acc for optim= 0.17226598349710306\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.00444063963368535\n",
      "Loss on test= 0.004736531991511583\n",
      "acc for Lsat= 0.0774061938540803 \n",
      "acc for Psat= 0.12947103802354024 \n",
      "acc for optim= 0.1580409813258383\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.0043563684448599815\n",
      "Loss on test= 0.005416944622993469\n",
      "acc for Lsat= 0.09551051789377299 \n",
      "acc for Psat= 0.13234547204855415 \n",
      "acc for optim= 0.13568113175117308\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.004411722533404827\n",
      "Loss on test= 0.005039385985583067\n",
      "acc for Lsat= 0.13490282154331604 \n",
      "acc for Psat= 0.15345724609990916 \n",
      "acc for optim= 0.13625689119928414\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.004273941274732351\n",
      "Loss on test= 0.005170305725187063\n",
      "acc for Lsat= 0.09996762349166805 \n",
      "acc for Psat= 0.11258990589218835 \n",
      "acc for optim= 0.1217480453196913\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.004421141929924488\n",
      "Loss on test= 0.00495242839679122\n",
      "acc for Lsat= 0.09488678398904288 \n",
      "acc for Psat= 0.13408719463687804 \n",
      "acc for optim= 0.14339983810593063\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.0043940674513578415\n",
      "Loss on test= 0.004967089742422104\n",
      "acc for Lsat= 0.12432698424284656 \n",
      "acc for Psat= 0.15304234313468137 \n",
      "acc for optim= 0.1402684434110092\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.004387969616800547\n",
      "Loss on test= 0.005304692778736353\n",
      "acc for Lsat= 0.11154857264288391 \n",
      "acc for Psat= 0.09882839659177181 \n",
      "acc for optim= 0.11692336217189829\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.0045012617483735085\n",
      "Loss on test= 0.005149269476532936\n",
      "acc for Lsat= 0.10121518765420963 \n",
      "acc for Psat= 0.1560275557761391 \n",
      "acc for optim= 0.1394126154999766\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.004375889897346497\n",
      "Loss on test= 0.005403866991400719\n",
      "acc for Lsat= 0.11742761431054936 \n",
      "acc for Psat= 0.10578480043396768 \n",
      "acc for optim= 0.11918890331354406\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.00439854059368372\n",
      "Loss on test= 0.0050874026492238045\n",
      "acc for Lsat= 0.13132702166007626 \n",
      "acc for Psat= 0.14999789454870754 \n",
      "acc for optim= 0.13273262858597767\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.0043308609165251255\n",
      "Loss on test= 0.004992933943867683\n",
      "acc for Lsat= 0.14222851349040866 \n",
      "acc for Psat= 0.13827072187430328 \n",
      "acc for optim= 0.14236906646854347\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.0043129632249474525\n",
      "Loss on test= 0.00482673104852438\n",
      "acc for Lsat= 0.09628794005968505 \n",
      "acc for Psat= 0.10447479114453825 \n",
      "acc for optim= 0.13703046128567722\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.004272174555808306\n",
      "Loss on test= 0.005343569442629814\n",
      "acc for Lsat= 0.11747834546905425 \n",
      "acc for Psat= 0.152143709471501 \n",
      "acc for optim= 0.12880126583493418\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.004337828140705824\n",
      "Loss on test= 0.005116499029099941\n",
      "acc for Lsat= 0.10887853966818915 \n",
      "acc for Psat= 0.13077383514286745 \n",
      "acc for optim= 0.1442873014861511\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.004409288987517357\n",
      "Loss on test= 0.0051356349140405655\n",
      "acc for Lsat= 0.1122390848532733 \n",
      "acc for Psat= 0.14297440071823075 \n",
      "acc for optim= 0.1375790524503423\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.004430432338267565\n",
      "Loss on test= 0.005276718642562628\n",
      "acc for Lsat= 0.11817888079935478 \n",
      "acc for Psat= 0.09962696909335339 \n",
      "acc for optim= 0.14508614223450422\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.004273201804608107\n",
      "Loss on test= 0.005080036353319883\n",
      "acc for Lsat= 0.10780337866809633 \n",
      "acc for Psat= 0.13525311964460546 \n",
      "acc for optim= 0.14350887781216037\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.004195671994239092\n",
      "Loss on test= 0.004743953701108694\n",
      "acc for Lsat= 0.12689859766720069 \n",
      "acc for Psat= 0.10994975222274661 \n",
      "acc for optim= 0.14297013202061257\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.0042725419625639915\n",
      "Loss on test= 0.005255385767668486\n",
      "acc for Lsat= 0.12323136647076656 \n",
      "acc for Psat= 0.12623536633327603 \n",
      "acc for optim= 0.14153252851166245\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.004263247828930616\n",
      "Loss on test= 0.005186804570257664\n",
      "acc for Lsat= 0.11123580402798122 \n",
      "acc for Psat= 0.09797458599011104 \n",
      "acc for optim= 0.14100321863467494\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.004225139040499926\n",
      "Loss on test= 0.005265931598842144\n",
      "acc for Lsat= 0.14092067618750864 \n",
      "acc for Psat= 0.12312749310189651 \n",
      "acc for optim= 0.1448823252899779\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.004340287763625383\n",
      "Loss on test= 0.004842597059905529\n",
      "acc for Lsat= 0.13620865695439635 \n",
      "acc for Psat= 0.15389549318287107 \n",
      "acc for optim= 0.13887912927505872\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.004320607054978609\n",
      "Loss on test= 0.005372972227632999\n",
      "acc for Lsat= 0.11112504845692052 \n",
      "acc for Psat= 0.10820830015776058 \n",
      "acc for optim= 0.13501493079173896\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.004314470570534468\n",
      "Loss on test= 0.005064846016466618\n",
      "acc for Lsat= 0.1112654220002393 \n",
      "acc for Psat= 0.12495510467690313 \n",
      "acc for optim= 0.13861105306487945\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.004279762506484985\n",
      "Loss on test= 0.0053507438860833645\n",
      "acc for Lsat= 0.13611269721554387 \n",
      "acc for Psat= 0.11895606017464565 \n",
      "acc for optim= 0.12122985758792816\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.004195082001388073\n",
      "Loss on test= 0.0050642229616642\n",
      "acc for Lsat= 0.09097270300844684 \n",
      "acc for Psat= 0.15071286716394955 \n",
      "acc for optim= 0.1361738008240031\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.004436315968632698\n",
      "Loss on test= 0.004724911879748106\n",
      "acc for Lsat= 0.10934562511586894 \n",
      "acc for Psat= 0.14683628977379864 \n",
      "acc for optim= 0.13296930021088985\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.004198204725980759\n",
      "Loss on test= 0.004868729040026665\n",
      "acc for Lsat= 0.10481770186581546 \n",
      "acc for Psat= 0.14719019561178154 \n",
      "acc for optim= 0.13242098022924942\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.004224398639053106\n",
      "Loss on test= 0.0052160173654556274\n",
      "acc for Lsat= 0.1016966494369424 \n",
      "acc for Psat= 0.1316621013538679 \n",
      "acc for optim= 0.1253528391308565\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.004454557318240404\n",
      "Loss on test= 0.005186505150049925\n",
      "acc for Lsat= 0.08741403816060887 \n",
      "acc for Psat= 0.12215474579069349 \n",
      "acc for optim= 0.16121183855769536\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.004230192396789789\n",
      "Loss on test= 0.00513738626614213\n",
      "acc for Lsat= 0.14177526119682524 \n",
      "acc for Psat= 0.14241316293676695 \n",
      "acc for optim= 0.14072785141049987\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.00431578466668725\n",
      "Loss on test= 0.005198502913117409\n",
      "acc for Lsat= 0.1377739776055225 \n",
      "acc for Psat= 0.16670721914205286 \n",
      "acc for optim= 0.1638467712327838\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.004410713445395231\n",
      "Loss on test= 0.004956156015396118\n",
      "acc for Lsat= 0.13313693418684933 \n",
      "acc for Psat= 0.12192664502395524 \n",
      "acc for optim= 0.16432371937359372\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.0041600423865020275\n",
      "Loss on test= 0.005154885817319155\n",
      "acc for Lsat= 0.11333595009960441 \n",
      "acc for Psat= 0.11902205216594869 \n",
      "acc for optim= 0.13176853256300092\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.004223026800900698\n",
      "Loss on test= 0.005192935466766357\n",
      "acc for Lsat= 0.11865587584260437 \n",
      "acc for Psat= 0.0975067645130265 \n",
      "acc for optim= 0.11206339462660253\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.00419847946614027\n",
      "Loss on test= 0.004717505071312189\n",
      "acc for Lsat= 0.08754667897139573 \n",
      "acc for Psat= 0.1278148763683728 \n",
      "acc for optim= 0.14990057026605225\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.004401463083922863\n",
      "Loss on test= 0.005189239513128996\n",
      "acc for Lsat= 0.09270286249617736 \n",
      "acc for Psat= 0.11465684862600432 \n",
      "acc for optim= 0.13703260749268034\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.004046365153044462\n",
      "Loss on test= 0.0045929234474897385\n",
      "acc for Lsat= 0.10118245359303223 \n",
      "acc for Psat= 0.1067049760862978 \n",
      "acc for optim= 0.13861745813240609\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.004218838643282652\n",
      "Loss on test= 0.004921289160847664\n",
      "acc for Lsat= 0.13475384498532447 \n",
      "acc for Psat= 0.12750381784927514 \n",
      "acc for optim= 0.13682964065163913\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.0041313995607197285\n",
      "Loss on test= 0.005103302653878927\n",
      "acc for Lsat= 0.12482112920972416 \n",
      "acc for Psat= 0.15972700192489558 \n",
      "acc for optim= 0.11733976079914202\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.004132208880037069\n",
      "Loss on test= 0.005192174576222897\n",
      "acc for Lsat= 0.1486847638669941 \n",
      "acc for Psat= 0.11421483693023522 \n",
      "acc for optim= 0.14937134260415202\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.004260004032403231\n",
      "Loss on test= 0.004986817482858896\n",
      "acc for Lsat= 0.10110951366287838 \n",
      "acc for Psat= 0.09544100157088703 \n",
      "acc for optim= 0.14521417104535633\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.004226600751280785\n",
      "Loss on test= 0.005007859785109758\n",
      "acc for Lsat= 0.1065861919325673 \n",
      "acc for Psat= 0.13746389530650857 \n",
      "acc for optim= 0.1588381885085255\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.004513567313551903\n",
      "Loss on test= 0.005244807340204716\n",
      "acc for Lsat= 0.12378888991143969 \n",
      "acc for Psat= 0.09951559687033296 \n",
      "acc for optim= 0.1370403501399172\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.004247638862580061\n",
      "Loss on test= 0.004883253946900368\n",
      "acc for Lsat= 0.12220080745302969 \n",
      "acc for Psat= 0.18041224169751835 \n",
      "acc for optim= 0.12669604160085632\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.004102778621017933\n",
      "Loss on test= 0.004926948342472315\n",
      "acc for Lsat= 0.138037512337582 \n",
      "acc for Psat= 0.12435385626223353 \n",
      "acc for optim= 0.12435601257311646\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.004107751417905092\n",
      "Loss on test= 0.005642480682581663\n",
      "acc for Lsat= 0.09986468041056974 \n",
      "acc for Psat= 0.1487723131560617 \n",
      "acc for optim= 0.14272191727326977\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.0042810277082026005\n",
      "Loss on test= 0.005036268848925829\n",
      "acc for Lsat= 0.12689407438867623 \n",
      "acc for Psat= 0.08954203824719621 \n",
      "acc for optim= 0.12695888582513565\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.004257583990693092\n",
      "Loss on test= 0.005013741087168455\n",
      "acc for Lsat= 0.11837427090439531 \n",
      "acc for Psat= 0.1159220050709943 \n",
      "acc for optim= 0.12086561001423332\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.00427029887214303\n",
      "Loss on test= 0.005288597662001848\n",
      "acc for Lsat= 0.10723397810943425 \n",
      "acc for Psat= 0.1377292037424114 \n",
      "acc for optim= 0.15129097318276763\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.00403718464076519\n",
      "Loss on test= 0.0047431206330657005\n",
      "acc for Lsat= 0.15173941859716755 \n",
      "acc for Psat= 0.13815167003000775 \n",
      "acc for optim= 0.12578942502538362\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.004268859513103962\n",
      "Loss on test= 0.005431337747722864\n",
      "acc for Lsat= 0.15374869698037705 \n",
      "acc for Psat= 0.14310716181838265 \n",
      "acc for optim= 0.16896152642503795\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.004185706842690706\n",
      "Loss on test= 0.004929411690682173\n",
      "acc for Lsat= 0.08385874002447559 \n",
      "acc for Psat= 0.1346984775736928 \n",
      "acc for optim= 0.14017843682732847\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.004123159684240818\n",
      "Loss on test= 0.00525016849860549\n",
      "acc for Lsat= 0.1596779136194123 \n",
      "acc for Psat= 0.1486205216109132 \n",
      "acc for optim= 0.12692355478389394\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.004184606950730085\n",
      "Loss on test= 0.0054550617933273315\n",
      "acc for Lsat= 0.11918239678359693 \n",
      "acc for Psat= 0.12777162374307713 \n",
      "acc for optim= 0.13796253707550932\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.0043093059211969376\n",
      "Loss on test= 0.005204566288739443\n",
      "acc for Lsat= 0.0749145900675406 \n",
      "acc for Psat= 0.1386865874648922 \n",
      "acc for optim= 0.1284248008289271\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.004082281608134508\n",
      "Loss on test= 0.004626287147402763\n",
      "acc for Lsat= 0.12728682725638565 \n",
      "acc for Psat= 0.11844148248847988 \n",
      "acc for optim= 0.1299891620874405\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.004399597179144621\n",
      "Loss on test= 0.004921076353639364\n",
      "acc for Lsat= 0.1094896570365462 \n",
      "acc for Psat= 0.15292625589710143 \n",
      "acc for optim= 0.14125749468803406\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.004170377738773823\n",
      "Loss on test= 0.00497426325455308\n",
      "acc for Lsat= 0.0888337599268804 \n",
      "acc for Psat= 0.13274205742507345 \n",
      "acc for optim= 0.15972058239599896\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.004339647013694048\n",
      "Loss on test= 0.005155323073267937\n",
      "acc for Lsat= 0.08204975900136763 \n",
      "acc for Psat= 0.12275000734047757 \n",
      "acc for optim= 0.13190107378694746\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.004141847603023052\n",
      "Loss on test= 0.0049553061835467815\n",
      "acc for Lsat= 0.09313350289853083 \n",
      "acc for Psat= 0.10765938624455076 \n",
      "acc for optim= 0.1183593360086282\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.004093865863978863\n",
      "Loss on test= 0.004663171246647835\n",
      "acc for Lsat= 0.14945249052511322 \n",
      "acc for Psat= 0.13394111511297524 \n",
      "acc for optim= 0.15398907997748917\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.004154443275183439\n",
      "Loss on test= 0.0055356454104185104\n",
      "acc for Lsat= 0.07953802917877005 \n",
      "acc for Psat= 0.11719264835119247 \n",
      "acc for optim= 0.12535086439715493\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.004039641935378313\n",
      "Loss on test= 0.004698451142758131\n",
      "acc for Lsat= 0.11997847587594555 \n",
      "acc for Psat= 0.13147302706622416 \n",
      "acc for optim= 0.1279407441098657\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.004182826261967421\n",
      "Loss on test= 0.005042719189077616\n",
      "acc for Lsat= 0.08345362511722164 \n",
      "acc for Psat= 0.09885659493092033 \n",
      "acc for optim= 0.15771421618087011\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.0041082557290792465\n",
      "Loss on test= 0.004847580101341009\n",
      "acc for Lsat= 0.08042590723683436 \n",
      "acc for Psat= 0.08130108254651229 \n",
      "acc for optim= 0.1447124406695366\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.004200750961899757\n",
      "Loss on test= 0.005672626197338104\n",
      "acc for Lsat= 0.10854762854675452 \n",
      "acc for Psat= 0.13965502091579968 \n",
      "acc for optim= 0.1475847901828173\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.004214477259665728\n",
      "Loss on test= 0.004886978771537542\n",
      "acc for Lsat= 0.13428298908830685 \n",
      "acc for Psat= 0.12482428949119316 \n",
      "acc for optim= 0.1405040806469818\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.004167029168456793\n",
      "Loss on test= 0.005095394793897867\n",
      "acc for Lsat= 0.1282270389298598 \n",
      "acc for Psat= 0.16850882665150696 \n",
      "acc for optim= 0.09466470240537699\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.004089598543941975\n",
      "Loss on test= 0.004735320806503296\n",
      "acc for Lsat= 0.07241320849344549 \n",
      "acc for Psat= 0.10800552026679118 \n",
      "acc for optim= 0.1353702462899188\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.0041164434514939785\n",
      "Loss on test= 0.0047890604473650455\n",
      "acc for Lsat= 0.07527664221318749 \n",
      "acc for Psat= 0.14139401897167167 \n",
      "acc for optim= 0.1588593384044038\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.004241328686475754\n",
      "Loss on test= 0.004970171954482794\n",
      "acc for Lsat= 0.12605943396273586 \n",
      "acc for Psat= 0.1652810103777382 \n",
      "acc for optim= 0.14945287857618597\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.00407478166744113\n",
      "Loss on test= 0.005143510643392801\n",
      "acc for Lsat= 0.08874241166955067 \n",
      "acc for Psat= 0.13051104116150075 \n",
      "acc for optim= 0.12961127588318455\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.004158222582191229\n",
      "Loss on test= 0.0053719584830105305\n",
      "acc for Lsat= 0.11886304337531328 \n",
      "acc for Psat= 0.17403606459912327 \n",
      "acc for optim= 0.1438491001414756\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.0040931846015155315\n",
      "Loss on test= 0.004991710651665926\n",
      "acc for Lsat= 0.10235609475057572 \n",
      "acc for Psat= 0.13516959401830617 \n",
      "acc for optim= 0.13006755469056466\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.004004800692200661\n",
      "Loss on test= 0.00477241538465023\n",
      "acc for Lsat= 0.13926434620387024 \n",
      "acc for Psat= 0.1405853330054217 \n",
      "acc for optim= 0.12308806537960966\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.004179093055427074\n",
      "Loss on test= 0.00533224456012249\n",
      "acc for Lsat= 0.08592737789472772 \n",
      "acc for Psat= 0.10489808861166239 \n",
      "acc for optim= 0.15174125962787205\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.004062563646584749\n",
      "Loss on test= 0.004960105754435062\n",
      "acc for Lsat= 0.08158792379415697 \n",
      "acc for Psat= 0.11120129503413206 \n",
      "acc for optim= 0.15113708084552652\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.004104577470570803\n",
      "Loss on test= 0.004895369987934828\n",
      "acc for Lsat= 0.12002921987894094 \n",
      "acc for Psat= 0.09581159241497517 \n",
      "acc for optim= 0.13875851451626253\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.003970709629356861\n",
      "Loss on test= 0.005399737972766161\n",
      "acc for Lsat= 0.13096581546900174 \n",
      "acc for Psat= 0.12281095699614121 \n",
      "acc for optim= 0.1396848739952677\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.00415267376229167\n",
      "Loss on test= 0.004981368780136108\n",
      "acc for Lsat= 0.12479970958601269 \n",
      "acc for Psat= 0.11598365444741729 \n",
      "acc for optim= 0.1321515453617192\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.004021230153739452\n",
      "Loss on test= 0.0050319647416472435\n",
      "acc for Lsat= 0.10186765756871966 \n",
      "acc for Psat= 0.12719012271716362 \n",
      "acc for optim= 0.11822120948798126\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.00397475203499198\n",
      "Loss on test= 0.005373131018131971\n",
      "acc for Lsat= 0.12027493822905752 \n",
      "acc for Psat= 0.14423321477240986 \n",
      "acc for optim= 0.1462978660646412\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.0039601135067641735\n",
      "Loss on test= 0.0052142939530313015\n",
      "acc for Lsat= 0.1168910328609248 \n",
      "acc for Psat= 0.12647784263309506 \n",
      "acc for optim= 0.13452865535186398\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.004115692339837551\n",
      "Loss on test= 0.005142104346305132\n",
      "acc for Lsat= 0.08185968183291455 \n",
      "acc for Psat= 0.12367330827853745 \n",
      "acc for optim= 0.13009870326560405\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.0041392226703464985\n",
      "Loss on test= 0.00526338629424572\n",
      "acc for Lsat= 0.09132077365292288 \n",
      "acc for Psat= 0.12722631585266855 \n",
      "acc for optim= 0.13002865311379233\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.004112805239856243\n",
      "Loss on test= 0.004739485681056976\n",
      "acc for Lsat= 0.11339673498231503 \n",
      "acc for Psat= 0.13798915449943808 \n",
      "acc for optim= 0.1474596292504834\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.004093770869076252\n",
      "Loss on test= 0.005372543353587389\n",
      "acc for Lsat= 0.12561580264526936 \n",
      "acc for Psat= 0.0905547677539289 \n",
      "acc for optim= 0.1357578510004613\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.004147259518504143\n",
      "Loss on test= 0.004686816595494747\n",
      "acc for Lsat= 0.1156927853460527 \n",
      "acc for Psat= 0.13517330731782648 \n",
      "acc for optim= 0.1420945291303926\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.004051005467772484\n",
      "Loss on test= 0.005003869999200106\n",
      "acc for Lsat= 0.15202627905334035 \n",
      "acc for Psat= 0.13507611511482132 \n",
      "acc for optim= 0.139353194170528\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.004146949388086796\n",
      "Loss on test= 0.005048598162829876\n",
      "acc for Lsat= 0.08947161114257243 \n",
      "acc for Psat= 0.10260623837045084 \n",
      "acc for optim= 0.13761056985499132\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.00392431253567338\n",
      "Loss on test= 0.004817966837435961\n",
      "acc for Lsat= 0.08059231140133408 \n",
      "acc for Psat= 0.09575453048778905 \n",
      "acc for optim= 0.14407756988819326\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.004102456849068403\n",
      "Loss on test= 0.005427800118923187\n",
      "acc for Lsat= 0.08681348199024796 \n",
      "acc for Psat= 0.14165361329085296 \n",
      "acc for optim= 0.11727458246362706\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.004132725764065981\n",
      "Loss on test= 0.0055023301392793655\n",
      "acc for Lsat= 0.13152169788049328 \n",
      "acc for Psat= 0.11551027131887774 \n",
      "acc for optim= 0.13685662634088658\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.0039911516942083836\n",
      "Loss on test= 0.005145584233105183\n",
      "acc for Lsat= 0.10882284943687005 \n",
      "acc for Psat= 0.11813554084963268 \n",
      "acc for optim= 0.09475460715798868\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.004062982741743326\n",
      "Loss on test= 0.004716683644801378\n",
      "acc for Lsat= 0.1274724042272687 \n",
      "acc for Psat= 0.08156836106920512 \n",
      "acc for optim= 0.1432153114065942\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.0041358936578035355\n",
      "Loss on test= 0.005634209141135216\n",
      "acc for Lsat= 0.1621725367149338 \n",
      "acc for Psat= 0.14580133826368386 \n",
      "acc for optim= 0.12341784478889571\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.004056188743561506\n",
      "Loss on test= 0.00508797587826848\n",
      "acc for Lsat= 0.10036185923187683 \n",
      "acc for Psat= 0.12290898881231745 \n",
      "acc for optim= 0.12445633152189355\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.004105337429791689\n",
      "Loss on test= 0.004865300375968218\n",
      "acc for Lsat= 0.08708826061855587 \n",
      "acc for Psat= 0.10308877391313824 \n",
      "acc for optim= 0.1345526318376263\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.00410155113786459\n",
      "Loss on test= 0.00507926382124424\n",
      "acc for Lsat= 0.10255625207598011 \n",
      "acc for Psat= 0.12984386045071813 \n",
      "acc for optim= 0.1207231897343364\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.004087002947926521\n",
      "Loss on test= 0.005013637710362673\n",
      "acc for Lsat= 0.11243842852612336 \n",
      "acc for Psat= 0.13621243430922428 \n",
      "acc for optim= 0.14683721690542167\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.004033728502690792\n",
      "Loss on test= 0.005350680090487003\n",
      "acc for Lsat= 0.11117522082188064 \n",
      "acc for Psat= 0.10836253682565358 \n",
      "acc for optim= 0.12233599068389998\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.004001256078481674\n",
      "Loss on test= 0.004761847201734781\n",
      "acc for Lsat= 0.0926668403359751 \n",
      "acc for Psat= 0.11048460490484205 \n",
      "acc for optim= 0.1364919360243625\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.00403161346912384\n",
      "Loss on test= 0.005186981521546841\n",
      "acc for Lsat= 0.10768961533904076 \n",
      "acc for Psat= 0.12117509432654414 \n",
      "acc for optim= 0.1302836335057186\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.0038732567336410284\n",
      "Loss on test= 0.004795874934643507\n",
      "acc for Lsat= 0.11280443757358524 \n",
      "acc for Psat= 0.1314457029932075 \n",
      "acc for optim= 0.11915276830808984\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.00401989696547389\n",
      "Loss on test= 0.0047322893515229225\n",
      "acc for Lsat= 0.1271636027118398 \n",
      "acc for Psat= 0.13150239183515725 \n",
      "acc for optim= 0.12516071096373102\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.004103284794837236\n",
      "Loss on test= 0.004883870016783476\n",
      "acc for Lsat= 0.11599796393420547 \n",
      "acc for Psat= 0.11715483453331722 \n",
      "acc for optim= 0.13372512808483508\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.004143386147916317\n",
      "Loss on test= 0.005305079743266106\n",
      "acc for Lsat= 0.09847149824620122 \n",
      "acc for Psat= 0.07357032573781908 \n",
      "acc for optim= 0.15400851502393684\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.004175642039626837\n",
      "Loss on test= 0.005346597172319889\n",
      "acc for Lsat= 0.11543691427343422 \n",
      "acc for Psat= 0.09493298352592522 \n",
      "acc for optim= 0.14748854717860618\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.0040456014685332775\n",
      "Loss on test= 0.004634600132703781\n",
      "acc for Lsat= 0.08318721756546034 \n",
      "acc for Psat= 0.1248547960486677 \n",
      "acc for optim= 0.13636141932672924\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.003968393430113792\n",
      "Loss on test= 0.005414716899394989\n",
      "acc for Lsat= 0.09838035275849204 \n",
      "acc for Psat= 0.09820515543429388 \n",
      "acc for optim= 0.1372982902167779\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.004153016954660416\n",
      "Loss on test= 0.005097885616123676\n",
      "acc for Lsat= 0.14313507069730097 \n",
      "acc for Psat= 0.10565377418727924 \n",
      "acc for optim= 0.1216990520608508\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.004089747089892626\n",
      "Loss on test= 0.004717625677585602\n",
      "acc for Lsat= 0.07857915613567457 \n",
      "acc for Psat= 0.11430543286001517 \n",
      "acc for optim= 0.13527720923432046\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.003992772661149502\n",
      "Loss on test= 0.004990131128579378\n",
      "acc for Lsat= 0.06919274914253037 \n",
      "acc for Psat= 0.13101227838261467 \n",
      "acc for optim= 0.1744904662999842\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.004035562742501497\n",
      "Loss on test= 0.00490229669958353\n",
      "acc for Lsat= 0.10525754254518284 \n",
      "acc for Psat= 0.11018274685031632 \n",
      "acc for optim= 0.14542686980631617\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.004030878655612469\n",
      "Loss on test= 0.0049250018782913685\n",
      "acc for Lsat= 0.12321062061689897 \n",
      "acc for Psat= 0.11480064930704732 \n",
      "acc for optim= 0.15543596829391187\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.00390888936817646\n",
      "Loss on test= 0.00486013712361455\n",
      "acc for Lsat= 0.11146685191326672 \n",
      "acc for Psat= 0.14942907381595838 \n",
      "acc for optim= 0.1471235766592953\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.003974974155426025\n",
      "Loss on test= 0.005129443481564522\n",
      "acc for Lsat= 0.11490665246836013 \n",
      "acc for Psat= 0.10844910165501966 \n",
      "acc for optim= 0.14571145833987328\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.0040471856482326984\n",
      "Loss on test= 0.0052099283784627914\n",
      "acc for Lsat= 0.11307575496741468 \n",
      "acc for Psat= 0.11051063309423625 \n",
      "acc for optim= 0.11963399760942492\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.0039778235368430614\n",
      "Loss on test= 0.004675635602325201\n",
      "acc for Lsat= 0.12550831011806926 \n",
      "acc for Psat= 0.139658857576756 \n",
      "acc for optim= 0.1349138390376336\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.003948279656469822\n",
      "Loss on test= 0.004969485569745302\n",
      "acc for Lsat= 0.11714755241862601 \n",
      "acc for Psat= 0.14581951943950522 \n",
      "acc for optim= 0.152366332606309\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.003915802575647831\n",
      "Loss on test= 0.005138269159942865\n",
      "acc for Lsat= 0.0986404798200561 \n",
      "acc for Psat= 0.08899777299827999 \n",
      "acc for optim= 0.116164414516081\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.003993013873696327\n",
      "Loss on test= 0.004929621238261461\n",
      "acc for Lsat= 0.10630807694461611 \n",
      "acc for Psat= 0.12936062727951342 \n",
      "acc for optim= 0.14506949678373834\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.003988246899098158\n",
      "Loss on test= 0.005100851878523827\n",
      "acc for Lsat= 0.1315295402891934 \n",
      "acc for Psat= 0.10293417674903241 \n",
      "acc for optim= 0.1359569708713227\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.004014536272734404\n",
      "Loss on test= 0.005004597827792168\n",
      "acc for Lsat= 0.09610895812511444 \n",
      "acc for Psat= 0.11519161767015855 \n",
      "acc for optim= 0.14336060523055494\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.003963454160839319\n",
      "Loss on test= 0.004927004221826792\n",
      "acc for Lsat= 0.11165222854146527 \n",
      "acc for Psat= 0.10056313515330355 \n",
      "acc for optim= 0.15216229059539424\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.0039626602083444595\n",
      "Loss on test= 0.005611954722553492\n",
      "acc for Lsat= 0.10446443336938198 \n",
      "acc for Psat= 0.13766559213399887 \n",
      "acc for optim= 0.1172257695838602\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.0040065874345600605\n",
      "Loss on test= 0.005026549566537142\n",
      "acc for Lsat= 0.13534566717377552 \n",
      "acc for Psat= 0.13873728023221096 \n",
      "acc for optim= 0.14358726396393548\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.003938134294003248\n",
      "Loss on test= 0.005031443666666746\n",
      "acc for Lsat= 0.10629038488453564 \n",
      "acc for Psat= 0.11632040220623215 \n",
      "acc for optim= 0.11815900914371014\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.00395311089232564\n",
      "Loss on test= 0.004830199293792248\n",
      "acc for Lsat= 0.12652375031676558 \n",
      "acc for Psat= 0.13093418850459987 \n",
      "acc for optim= 0.14078575721941888\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.003971828613430262\n",
      "Loss on test= 0.004865681286901236\n",
      "acc for Lsat= 0.1295306618299542 \n",
      "acc for Psat= 0.10605278135173851 \n",
      "acc for optim= 0.14854107910974157\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.0039089638739824295\n",
      "Loss on test= 0.005036229267716408\n",
      "acc for Lsat= 0.141668024369412 \n",
      "acc for Psat= 0.10617124328079323 \n",
      "acc for optim= 0.13546802724401155\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.00397212291136384\n",
      "Loss on test= 0.0048902519047260284\n",
      "acc for Lsat= 0.16048328687126437 \n",
      "acc for Psat= 0.1338849544732107 \n",
      "acc for optim= 0.14614306235065064\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.0040613156743347645\n",
      "Loss on test= 0.005017549265176058\n",
      "acc for Lsat= 0.06289243642499463 \n",
      "acc for Psat= 0.1180069941199488 \n",
      "acc for optim= 0.14761222940352228\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.0040183402597904205\n",
      "Loss on test= 0.004930135793983936\n",
      "acc for Lsat= 0.1299405944430166 \n",
      "acc for Psat= 0.12909573233789867 \n",
      "acc for optim= 0.11075770482420921\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.0040534320287406445\n",
      "Loss on test= 0.004719419404864311\n",
      "acc for Lsat= 0.09424327728548734 \n",
      "acc for Psat= 0.11327316736181577 \n",
      "acc for optim= 0.1255305916678885\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.0038161056581884623\n",
      "Loss on test= 0.005025061313062906\n",
      "acc for Lsat= 0.08710370789695945 \n",
      "acc for Psat= 0.13262465958380038 \n",
      "acc for optim= 0.14914315316774365\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.003937482368201017\n",
      "Loss on test= 0.004911800380796194\n",
      "acc for Lsat= 0.09501195081975311 \n",
      "acc for Psat= 0.11485119070857763 \n",
      "acc for optim= 0.12075528895689382\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.003960700705647469\n",
      "Loss on test= 0.00461011053994298\n",
      "acc for Lsat= 0.09194868725414078 \n",
      "acc for Psat= 0.1264378221757296 \n",
      "acc for optim= 0.12929254666798645\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.003828144632279873\n",
      "Loss on test= 0.00481540709733963\n",
      "acc for Lsat= 0.10158376064120805 \n",
      "acc for Psat= 0.13801356617154348 \n",
      "acc for optim= 0.12413200730871823\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.003910392988473177\n",
      "Loss on test= 0.005089828744530678\n",
      "acc for Lsat= 0.13125396923472485 \n",
      "acc for Psat= 0.12512973242297043 \n",
      "acc for optim= 0.13543271645903587\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.00388484844006598\n",
      "Loss on test= 0.004852486774325371\n",
      "acc for Lsat= 0.10525330394092533 \n",
      "acc for Psat= 0.09690193593915966 \n",
      "acc for optim= 0.11178881540480587\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.003914628643542528\n",
      "Loss on test= 0.0047026826068758965\n",
      "acc for Lsat= 0.10002632078249007 \n",
      "acc for Psat= 0.10077249186320437 \n",
      "acc for optim= 0.14414323390358025\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.003895796602591872\n",
      "Loss on test= 0.005043883807957172\n",
      "acc for Lsat= 0.10654304600838158 \n",
      "acc for Psat= 0.13035059201582852 \n",
      "acc for optim= 0.10957857743940419\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.004162764176726341\n",
      "Loss on test= 0.005034790374338627\n",
      "acc for Lsat= 0.11258113549815284 \n",
      "acc for Psat= 0.12088611701296435 \n",
      "acc for optim= 0.11583177424553368\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.004031759221106768\n",
      "Loss on test= 0.004900900647044182\n",
      "acc for Lsat= 0.08489467955142674 \n",
      "acc for Psat= 0.10704523142582427 \n",
      "acc for optim= 0.12249637314946288\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.0037233850453048944\n",
      "Loss on test= 0.004910309799015522\n",
      "acc for Lsat= 0.08765753620698685 \n",
      "acc for Psat= 0.07914130609586006 \n",
      "acc for optim= 0.1274576330712686\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.0040355706587433815\n",
      "Loss on test= 0.005131195764988661\n",
      "acc for Lsat= 0.11280637573347324 \n",
      "acc for Psat= 0.08535634163611878 \n",
      "acc for optim= 0.13556324928585026\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.0038835855666548014\n",
      "Loss on test= 0.0047941142693161964\n",
      "acc for Lsat= 0.08105044066905975 \n",
      "acc for Psat= 0.11575707834627894 \n",
      "acc for optim= 0.13688841348307001\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.003754175268113613\n",
      "Loss on test= 0.004776879213750362\n",
      "acc for Lsat= 0.053932737869520984 \n",
      "acc for Psat= 0.0853250389368946 \n",
      "acc for optim= 0.12137405263880889\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.0038778220769017935\n",
      "Loss on test= 0.005887922365218401\n",
      "acc for Lsat= 0.1391709360630355 \n",
      "acc for Psat= 0.11950305906227893 \n",
      "acc for optim= 0.13328100689169434\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.00394148426130414\n",
      "Loss on test= 0.005205540917813778\n",
      "acc for Lsat= 0.10800798516720533 \n",
      "acc for Psat= 0.14325057425432736 \n",
      "acc for optim= 0.1626031513636311\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.0039026543963700533\n",
      "Loss on test= 0.005257566925138235\n",
      "acc for Lsat= 0.10890656688328211 \n",
      "acc for Psat= 0.12131890551083618 \n",
      "acc for optim= 0.14003475926195583\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.0038711719680577517\n",
      "Loss on test= 0.006455696653574705\n",
      "acc for Lsat= 0.13447122194015215 \n",
      "acc for Psat= 0.11558690868938963 \n",
      "acc for optim= 0.15741773758135322\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.0038932180032134056\n",
      "Loss on test= 0.0052247438579797745\n",
      "acc for Lsat= 0.10796993013678326 \n",
      "acc for Psat= 0.14729912175486484 \n",
      "acc for optim= 0.11699199454031056\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.0038494737818837166\n",
      "Loss on test= 0.004678457975387573\n",
      "acc for Lsat= 0.11938376638702014 \n",
      "acc for Psat= 0.12880441515396038 \n",
      "acc for optim= 0.14066571849657017\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.003925678785890341\n",
      "Loss on test= 0.005158081650733948\n",
      "acc for Lsat= 0.09174476680345833 \n",
      "acc for Psat= 0.08816314289449817 \n",
      "acc for optim= 0.16135788739969334\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.0038655868265777826\n",
      "Loss on test= 0.005079252645373344\n",
      "acc for Lsat= 0.1543023371842638 \n",
      "acc for Psat= 0.15948573054952753 \n",
      "acc for optim= 0.12723176827421412\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.0038394539151340723\n",
      "Loss on test= 0.004906860645860434\n",
      "acc for Lsat= 0.08612996474322346 \n",
      "acc for Psat= 0.13628273169484195 \n",
      "acc for optim= 0.1519411193827788\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.00384913245216012\n",
      "Loss on test= 0.005068568047136068\n",
      "acc for Lsat= 0.10486225878897433 \n",
      "acc for Psat= 0.1737875708171891 \n",
      "acc for optim= 0.11897659182755484\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.004017264116555452\n",
      "Loss on test= 0.00445853965356946\n",
      "acc for Lsat= 0.11347889752748112 \n",
      "acc for Psat= 0.09070425806567073 \n",
      "acc for optim= 0.17608435940928757\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.004011249169707298\n",
      "Loss on test= 0.005242039915174246\n",
      "acc for Lsat= 0.07955824759685332 \n",
      "acc for Psat= 0.11560330625313024 \n",
      "acc for optim= 0.1528014039569017\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.0038571341428905725\n",
      "Loss on test= 0.004981648176908493\n",
      "acc for Lsat= 0.1181942421115107 \n",
      "acc for Psat= 0.15573724372208947 \n",
      "acc for optim= 0.1240618154535898\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.0038800155743956566\n",
      "Loss on test= 0.004969913512468338\n",
      "acc for Lsat= 0.09600327319155137 \n",
      "acc for Psat= 0.061592034180648625 \n",
      "acc for optim= 0.15179012736512554\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.003919842187315226\n",
      "Loss on test= 0.005245482549071312\n",
      "acc for Lsat= 0.09450807702443045 \n",
      "acc for Psat= 0.1434964139221443 \n",
      "acc for optim= 0.13596831908863452\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.0038603930734097958\n",
      "Loss on test= 0.004785607103258371\n",
      "acc for Lsat= 0.07724319794215262 \n",
      "acc for Psat= 0.09809374074555105 \n",
      "acc for optim= 0.1400220498908311\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.003873295383527875\n",
      "Loss on test= 0.0053404043428599834\n",
      "acc for Lsat= 0.1463393055730396 \n",
      "acc for Psat= 0.1287514286943608 \n",
      "acc for optim= 0.11100966007345253\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.003960250411182642\n",
      "Loss on test= 0.005401180125772953\n",
      "acc for Lsat= 0.1153204505616385 \n",
      "acc for Psat= 0.09818542510684994 \n",
      "acc for optim= 0.133005067680238\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.0037581876385957003\n",
      "Loss on test= 0.0050619859248399734\n",
      "acc for Lsat= 0.11974963483711083 \n",
      "acc for Psat= 0.1609027562662959 \n",
      "acc for optim= 0.13723541196021768\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.003874937305226922\n",
      "Loss on test= 0.005202597007155418\n",
      "acc for Lsat= 0.11591286858957675 \n",
      "acc for Psat= 0.155951964099788 \n",
      "acc for optim= 0.11317041381779644\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.003962943330407143\n",
      "Loss on test= 0.005300236400216818\n",
      "acc for Lsat= 0.12602567905560136 \n",
      "acc for Psat= 0.15831092827849919 \n",
      "acc for optim= 0.13505542278289795\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.003832386340945959\n",
      "Loss on test= 0.005269369576126337\n",
      "acc for Lsat= 0.14003111370321777 \n",
      "acc for Psat= 0.12975347761271727 \n",
      "acc for optim= 0.13421082328002537\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.0038945162668824196\n",
      "Loss on test= 0.004824814386665821\n",
      "acc for Lsat= 0.10849880447818173 \n",
      "acc for Psat= 0.10410556155774328 \n",
      "acc for optim= 0.1597095395748814\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.00395188806578517\n",
      "Loss on test= 0.005001255311071873\n",
      "acc for Lsat= 0.09209229473748969 \n",
      "acc for Psat= 0.12667641043663025 \n",
      "acc for optim= 0.14876340940180752\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.003944511525332928\n",
      "Loss on test= 0.005019271746277809\n",
      "acc for Lsat= 0.13486763366705012 \n",
      "acc for Psat= 0.15299429842788312 \n",
      "acc for optim= 0.13959912764322427\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.003916803747415543\n",
      "Loss on test= 0.004988630767911673\n",
      "acc for Lsat= 0.10586831729031271 \n",
      "acc for Psat= 0.16614314014764708 \n",
      "acc for optim= 0.14778306831916174\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.0036924874875694513\n",
      "Loss on test= 0.0050195613875985146\n",
      "acc for Lsat= 0.12434821005444974 \n",
      "acc for Psat= 0.13911991964818704 \n",
      "acc for optim= 0.13263579085469246\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.003768283873796463\n",
      "Loss on test= 0.005062807351350784\n",
      "acc for Lsat= 0.09429578762501478 \n",
      "acc for Psat= 0.11889300723042753 \n",
      "acc for optim= 0.14867541939020157\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.0038498162757605314\n",
      "Loss on test= 0.005000454839318991\n",
      "acc for Lsat= 0.06884258892387152 \n",
      "acc for Psat= 0.11910489139457543 \n",
      "acc for optim= 0.13770956218811786\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.0038411682471632957\n",
      "Loss on test= 0.004958948120474815\n",
      "acc for Lsat= 0.09088717463924291 \n",
      "acc for Psat= 0.1230178906634036 \n",
      "acc for optim= 0.15062936659281453\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.0038356357254087925\n",
      "Loss on test= 0.005265137180685997\n",
      "acc for Lsat= 0.08918137830268177 \n",
      "acc for Psat= 0.08388858922343287 \n",
      "acc for optim= 0.13920974110563597\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.003862123703584075\n",
      "Loss on test= 0.005577243864536285\n",
      "acc for Lsat= 0.10307134530093107 \n",
      "acc for Psat= 0.15212359155217806 \n",
      "acc for optim= 0.11153183285043472\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.0038804239593446255\n",
      "Loss on test= 0.004970224108546972\n",
      "acc for Lsat= 0.12471207903905047 \n",
      "acc for Psat= 0.09319672112663586 \n",
      "acc for optim= 0.17786810567809475\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.0038537385407835245\n",
      "Loss on test= 0.004829311743378639\n",
      "acc for Lsat= 0.10826538182381126 \n",
      "acc for Psat= 0.09488011586169402 \n",
      "acc for optim= 0.12837215663037366\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.003759801620617509\n",
      "Loss on test= 0.004952048882842064\n",
      "acc for Lsat= 0.12182326917536557 \n",
      "acc for Psat= 0.13782293968445933 \n",
      "acc for optim= 0.1393100718560163\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.0037385104224085808\n",
      "Loss on test= 0.004957359749823809\n",
      "acc for Lsat= 0.1270712947783371 \n",
      "acc for Psat= 0.14035665639676154 \n",
      "acc for optim= 0.14192858369400105\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.00382411340251565\n",
      "Loss on test= 0.0052584316581487656\n",
      "acc for Lsat= 0.09042246679827157 \n",
      "acc for Psat= 0.11892994120717049 \n",
      "acc for optim= 0.1220969286126395\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.0038208006881177425\n",
      "Loss on test= 0.005422767251729965\n",
      "acc for Lsat= 0.09330029164286519 \n",
      "acc for Psat= 0.12424588855355978 \n",
      "acc for optim= 0.129190055343012\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.0038117319345474243\n",
      "Loss on test= 0.004619647283107042\n",
      "acc for Lsat= 0.11021036789235142 \n",
      "acc for Psat= 0.12003748245640761 \n",
      "acc for optim= 0.1139764782985569\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.003723382018506527\n",
      "Loss on test= 0.005262758582830429\n",
      "acc for Lsat= 0.10003017947181231 \n",
      "acc for Psat= 0.1553960184683092 \n",
      "acc for optim= 0.14201259105983707\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.0037284395657479763\n",
      "Loss on test= 0.004816190805286169\n",
      "acc for Lsat= 0.07966616987768146 \n",
      "acc for Psat= 0.10908953136660987 \n",
      "acc for optim= 0.13139725843858388\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.0037457256112247705\n",
      "Loss on test= 0.0049597229808568954\n",
      "acc for Lsat= 0.11392901749867532 \n",
      "acc for Psat= 0.08827021265298957 \n",
      "acc for optim= 0.13940855612357458\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.003911901265382767\n",
      "Loss on test= 0.005016014911234379\n",
      "acc for Lsat= 0.09782554489922607 \n",
      "acc for Psat= 0.1644430579100218 \n",
      "acc for optim= 0.11876398790627718\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.0036958830896764994\n",
      "Loss on test= 0.004962093196809292\n",
      "acc for Lsat= 0.08772519173928434 \n",
      "acc for Psat= 0.07773525174707174 \n",
      "acc for optim= 0.16224301918151063\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.004010457079857588\n",
      "Loss on test= 0.005008464679121971\n",
      "acc for Lsat= 0.10673874616622925 \n",
      "acc for Psat= 0.12237748469245464 \n",
      "acc for optim= 0.15028178158940542\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.0037587920669466257\n",
      "Loss on test= 0.005387475248426199\n",
      "acc for Lsat= 0.12803235893241233 \n",
      "acc for Psat= 0.12077732958520453 \n",
      "acc for optim= 0.10987149358778778\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.003799796337261796\n",
      "Loss on test= 0.0052284058183431625\n",
      "acc for Lsat= 0.09488240228448477 \n",
      "acc for Psat= 0.10127553286858731 \n",
      "acc for optim= 0.11518440204155114\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.0038464097306132317\n",
      "Loss on test= 0.005368133075535297\n",
      "acc for Lsat= 0.08543739959390627 \n",
      "acc for Psat= 0.08250731057826972 \n",
      "acc for optim= 0.1469042204423911\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.003839830169454217\n",
      "Loss on test= 0.004717372823506594\n",
      "acc for Lsat= 0.0910614483938035 \n",
      "acc for Psat= 0.11604864657339123 \n",
      "acc for optim= 0.12644024514075783\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.0037153714802116156\n",
      "Loss on test= 0.0052394443191587925\n",
      "acc for Lsat= 0.10602378367912024 \n",
      "acc for Psat= 0.10407206519610351 \n",
      "acc for optim= 0.1509118162923389\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.0037410741206258535\n",
      "Loss on test= 0.004884491208940744\n",
      "acc for Lsat= 0.17596806766879228 \n",
      "acc for Psat= 0.16214715798075 \n",
      "acc for optim= 0.14721734387179217\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.003728544572368264\n",
      "Loss on test= 0.004887053277343512\n",
      "acc for Lsat= 0.10472072702315119 \n",
      "acc for Psat= 0.10674473933047718 \n",
      "acc for optim= 0.1237297223156525\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.0038069719448685646\n",
      "Loss on test= 0.0048649851232767105\n",
      "acc for Lsat= 0.12694524155489895 \n",
      "acc for Psat= 0.14570286518169773 \n",
      "acc for optim= 0.11152239335286948\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.0036673175636678934\n",
      "Loss on test= 0.004810177721083164\n",
      "acc for Lsat= 0.12761867977678776 \n",
      "acc for Psat= 0.10509829871201266 \n",
      "acc for optim= 0.12272998773389393\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.0039125727489590645\n",
      "Loss on test= 0.004569931421428919\n",
      "acc for Lsat= 0.10298974211845133 \n",
      "acc for Psat= 0.11634391047280385 \n",
      "acc for optim= 0.12528694007131788\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.003806224325671792\n",
      "Loss on test= 0.005145394708961248\n",
      "acc for Lsat= 0.10463668975151247 \n",
      "acc for Psat= 0.11866088646476985 \n",
      "acc for optim= 0.12039256352525424\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.0038168118335306644\n",
      "Loss on test= 0.005071383435279131\n",
      "acc for Lsat= 0.11828475148003134 \n",
      "acc for Psat= 0.13790090816716352 \n",
      "acc for optim= 0.15082460792230754\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.00380725204013288\n",
      "Loss on test= 0.004901324398815632\n",
      "acc for Lsat= 0.14430785207595262 \n",
      "acc for Psat= 0.17299179452917693 \n",
      "acc for optim= 0.13220665136921322\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.003695977618917823\n",
      "Loss on test= 0.004882723093032837\n",
      "acc for Lsat= 0.11082729930058122 \n",
      "acc for Psat= 0.16892031458620396 \n",
      "acc for optim= 0.10885233825602983\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.003659098641946912\n",
      "Loss on test= 0.005184162873774767\n",
      "acc for Lsat= 0.08761147906382878 \n",
      "acc for Psat= 0.10182053719957669 \n",
      "acc for optim= 0.1193319820643713\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.003849332919344306\n",
      "Loss on test= 0.004922723397612572\n",
      "acc for Lsat= 0.11163445034374793 \n",
      "acc for Psat= 0.14701983974211746 \n",
      "acc for optim= 0.14404702292651766\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.003725450485944748\n",
      "Loss on test= 0.004796711262315512\n",
      "acc for Lsat= 0.0987711109014021 \n",
      "acc for Psat= 0.13647994042063752 \n",
      "acc for optim= 0.11330161667946312\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.003658411093056202\n",
      "Loss on test= 0.005446494556963444\n",
      "acc for Lsat= 0.06995048278218342 \n",
      "acc for Psat= 0.12326550142218669 \n",
      "acc for optim= 0.10581728903990653\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.003750602714717388\n",
      "Loss on test= 0.0045904056169092655\n",
      "acc for Lsat= 0.10001765566832749 \n",
      "acc for Psat= 0.08348732767626643 \n",
      "acc for optim= 0.15197645200209486\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.0036953752860426903\n",
      "Loss on test= 0.00476895971223712\n",
      "acc for Lsat= 0.0935490458440553 \n",
      "acc for Psat= 0.10139272853525148 \n",
      "acc for optim= 0.10448085397688879\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.0037195750046521425\n",
      "Loss on test= 0.0052431379444897175\n",
      "acc for Lsat= 0.09391785256512877 \n",
      "acc for Psat= 0.10790175957501763 \n",
      "acc for optim= 0.12355399385301603\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.0037794315721839666\n",
      "Loss on test= 0.004555715247988701\n",
      "acc for Lsat= 0.13020242786862785 \n",
      "acc for Psat= 0.1293660078404678 \n",
      "acc for optim= 0.1375265363086429\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.0037277282681316137\n",
      "Loss on test= 0.005113302264362574\n",
      "acc for Lsat= 0.133880117494199 \n",
      "acc for Psat= 0.12593156210560766 \n",
      "acc for optim= 0.13878641727690896\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.0036785805132240057\n",
      "Loss on test= 0.004834104795008898\n",
      "acc for Lsat= 0.12538037987218964 \n",
      "acc for Psat= 0.13681292595962682 \n",
      "acc for optim= 0.11427975352853537\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.003775360295549035\n",
      "Loss on test= 0.005309423431754112\n",
      "acc for Lsat= 0.12057831901862907 \n",
      "acc for Psat= 0.10447133730890022 \n",
      "acc for optim= 0.12390988496028715\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.0037788907065987587\n",
      "Loss on test= 0.005102791823446751\n",
      "acc for Lsat= 0.12075436772364709 \n",
      "acc for Psat= 0.14958771204368937 \n",
      "acc for optim= 0.1264076603886982\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.0038263672031462193\n",
      "Loss on test= 0.004790225997567177\n",
      "acc for Lsat= 0.12585631876168513 \n",
      "acc for Psat= 0.15494797358082402 \n",
      "acc for optim= 0.1452296753737351\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.0036561868619173765\n",
      "Loss on test= 0.00541049474850297\n",
      "acc for Lsat= 0.10719886779164274 \n",
      "acc for Psat= 0.10481913041116463 \n",
      "acc for optim= 0.11137791415159073\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.0037435770500451326\n",
      "Loss on test= 0.004605156369507313\n",
      "acc for Lsat= 0.1370075163948867 \n",
      "acc for Psat= 0.16067995250018108 \n",
      "acc for optim= 0.15202754399635726\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.0036592648830264807\n",
      "Loss on test= 0.0050339666195213795\n",
      "acc for Lsat= 0.07870917643109958 \n",
      "acc for Psat= 0.09902796204227747 \n",
      "acc for optim= 0.13294124147958225\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.0036464340519160032\n",
      "Loss on test= 0.005150375887751579\n",
      "acc for Lsat= 0.15056851164748272 \n",
      "acc for Psat= 0.14860860170382592 \n",
      "acc for optim= 0.11416150303557515\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.0036430920008569956\n",
      "Loss on test= 0.004888737108558416\n",
      "acc for Lsat= 0.09526100450764513 \n",
      "acc for Psat= 0.1429021319684883 \n",
      "acc for optim= 0.1100239177337951\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.0036752140149474144\n",
      "Loss on test= 0.005053857807070017\n",
      "acc for Lsat= 0.11945097893476486 \n",
      "acc for Psat= 0.1367487565924724 \n",
      "acc for optim= 0.1658840549385382\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.0038316601421684027\n",
      "Loss on test= 0.004844223614782095\n",
      "acc for Lsat= 0.11682604868999785 \n",
      "acc for Psat= 0.09441962093114853 \n",
      "acc for optim= 0.12229233312730987\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.003635960863903165\n",
      "Loss on test= 0.004880586639046669\n",
      "acc for Lsat= 0.12341720936819911 \n",
      "acc for Psat= 0.11303001678445274 \n",
      "acc for optim= 0.13947785982034272\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.003801969578489661\n",
      "Loss on test= 0.004780272021889687\n",
      "acc for Lsat= 0.08929781730855918 \n",
      "acc for Psat= 0.12040442181751132 \n",
      "acc for optim= 0.12338284413433737\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.0037566758692264557\n",
      "Loss on test= 0.0051470473408699036\n",
      "acc for Lsat= 0.11255831561154789 \n",
      "acc for Psat= 0.10048751858994365 \n",
      "acc for optim= 0.1508525312011544\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.00366735621355474\n",
      "Loss on test= 0.0048407986760139465\n",
      "acc for Lsat= 0.10456119767493671 \n",
      "acc for Psat= 0.13140865373942587 \n",
      "acc for optim= 0.13563827205345863\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.003884270554408431\n",
      "Loss on test= 0.005322255194187164\n",
      "acc for Lsat= 0.13436239233447445 \n",
      "acc for Psat= 0.13200580732276043 \n",
      "acc for optim= 0.1585452583514982\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.0037091507110744715\n",
      "Loss on test= 0.005094400607049465\n",
      "acc for Lsat= 0.09546286729164422 \n",
      "acc for Psat= 0.09386781760905352 \n",
      "acc for optim= 0.1249482130838765\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.0037276363000273705\n",
      "Loss on test= 0.004816856700927019\n",
      "acc for Lsat= 0.14684041615368593 \n",
      "acc for Psat= 0.13365413952204916 \n",
      "acc for optim= 0.14661659305501315\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.0036315233446657658\n",
      "Loss on test= 0.004714364185929298\n",
      "acc for Lsat= 0.12695160999687183 \n",
      "acc for Psat= 0.12624458906551203 \n",
      "acc for optim= 0.13682914090653261\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.0037029983941465616\n",
      "Loss on test= 0.00485948845744133\n",
      "acc for Lsat= 0.13913788611534983 \n",
      "acc for Psat= 0.19038108456879854 \n",
      "acc for optim= 0.14387088072382742\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.0036384230479598045\n",
      "Loss on test= 0.005009062588214874\n",
      "acc for Lsat= 0.09272581121573846 \n",
      "acc for Psat= 0.15384748184846508 \n",
      "acc for optim= 0.13579863578908974\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.0035956657957285643\n",
      "Loss on test= 0.0051345559768378735\n",
      "acc for Lsat= 0.11625537240696657 \n",
      "acc for Psat= 0.11059367092740205 \n",
      "acc for optim= 0.15866294239337245\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.003715445753186941\n",
      "Loss on test= 0.005072408355772495\n",
      "acc for Lsat= 0.12458444831685887 \n",
      "acc for Psat= 0.12546951034002835 \n",
      "acc for optim= 0.15638172326402533\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.003663252340629697\n",
      "Loss on test= 0.0050943815149366856\n",
      "acc for Lsat= 0.1081654992303811 \n",
      "acc for Psat= 0.11577613475835985 \n",
      "acc for optim= 0.11696859725957943\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.0038626042660325766\n",
      "Loss on test= 0.004731765016913414\n",
      "acc for Lsat= 0.0964085542364046 \n",
      "acc for Psat= 0.12702218568220916 \n",
      "acc for optim= 0.12546336609456274\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.003716178936883807\n",
      "Loss on test= 0.0049208286218345165\n",
      "acc for Lsat= 0.09600790398609307 \n",
      "acc for Psat= 0.11452601205868025 \n",
      "acc for optim= 0.1341315631547736\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.003707063151523471\n",
      "Loss on test= 0.005038617178797722\n",
      "acc for Lsat= 0.12136175167850322 \n",
      "acc for Psat= 0.1518923704408937 \n",
      "acc for optim= 0.13032315366177094\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.0037371860817074776\n",
      "Loss on test= 0.005173810757696629\n",
      "acc for Lsat= 0.10344932919057707 \n",
      "acc for Psat= 0.12323641859822804 \n",
      "acc for optim= 0.1258483617566526\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.003649146296083927\n",
      "Loss on test= 0.00466753076761961\n",
      "acc for Lsat= 0.09221419940392177 \n",
      "acc for Psat= 0.11613386340872643 \n",
      "acc for optim= 0.12729909581442675\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.003670023288577795\n",
      "Loss on test= 0.004838924389332533\n",
      "acc for Lsat= 0.11492304962141336 \n",
      "acc for Psat= 0.138408199004415 \n",
      "acc for optim= 0.0996988284168765\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.003532402217388153\n",
      "Loss on test= 0.004995835479348898\n",
      "acc for Lsat= 0.11416297081288779 \n",
      "acc for Psat= 0.10859952861857083 \n",
      "acc for optim= 0.1247197322987227\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.003565607825294137\n",
      "Loss on test= 0.0046226088888943195\n",
      "acc for Lsat= 0.13813933367297673 \n",
      "acc for Psat= 0.16608155441160002 \n",
      "acc for optim= 0.1268527244942056\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.003791899885982275\n",
      "Loss on test= 0.004674787633121014\n",
      "acc for Lsat= 0.1130202832735247 \n",
      "acc for Psat= 0.093105411519193 \n",
      "acc for optim= 0.1255410531302914\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.0036614416167140007\n",
      "Loss on test= 0.004768985789269209\n",
      "acc for Lsat= 0.10157326110897379 \n",
      "acc for Psat= 0.14165509424896705 \n",
      "acc for optim= 0.15171834200413692\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.003657062305137515\n",
      "Loss on test= 0.00493590859696269\n",
      "acc for Lsat= 0.13232633823321927 \n",
      "acc for Psat= 0.12418820978038841 \n",
      "acc for optim= 0.11713786002817667\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.0036819360684603453\n",
      "Loss on test= 0.005167174153029919\n",
      "acc for Lsat= 0.10354561193121804 \n",
      "acc for Psat= 0.11882421946696316 \n",
      "acc for optim= 0.11788257307570246\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.0037821256555616856\n",
      "Loss on test= 0.004869657102972269\n",
      "acc for Lsat= 0.09633519484325209 \n",
      "acc for Psat= 0.10042798685996483 \n",
      "acc for optim= 0.136746140766061\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.0037246383726596832\n",
      "Loss on test= 0.0049934228882193565\n",
      "acc for Lsat= 0.08813802461372688 \n",
      "acc for Psat= 0.1075883858009345 \n",
      "acc for optim= 0.1355330863928733\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.0035768060479313135\n",
      "Loss on test= 0.00468253530561924\n",
      "acc for Lsat= 0.08402991918329564 \n",
      "acc for Psat= 0.09995857895248467 \n",
      "acc for optim= 0.12534712446439597\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.0037942968774586916\n",
      "Loss on test= 0.005005794111639261\n",
      "acc for Lsat= 0.11271048740794261 \n",
      "acc for Psat= 0.08059237255818313 \n",
      "acc for optim= 0.1508617719066226\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.0036196091677993536\n",
      "Loss on test= 0.005158656742423773\n",
      "acc for Lsat= 0.10418418639649947 \n",
      "acc for Psat= 0.13636930907766023 \n",
      "acc for optim= 0.12588623675724697\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.003463772824034095\n",
      "Loss on test= 0.004734561778604984\n",
      "acc for Lsat= 0.13259857189324167 \n",
      "acc for Psat= 0.10538186381260554 \n",
      "acc for optim= 0.12177554240527873\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.0036598527804017067\n",
      "Loss on test= 0.004787075333297253\n",
      "acc for Lsat= 0.0861098863857074 \n",
      "acc for Psat= 0.09697346562623149 \n",
      "acc for optim= 0.1438689035260015\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.003640461713075638\n",
      "Loss on test= 0.004763009026646614\n",
      "acc for Lsat= 0.11362686339351866 \n",
      "acc for Psat= 0.15046194842499164 \n",
      "acc for optim= 0.13987369946618047\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.0037058317102491856\n",
      "Loss on test= 0.0046607982367277145\n",
      "acc for Lsat= 0.11494024667061037 \n",
      "acc for Psat= 0.11778066198651989 \n",
      "acc for optim= 0.13304456551041868\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.0037405183538794518\n",
      "Loss on test= 0.004807274788618088\n",
      "acc for Lsat= 0.10141527767862296 \n",
      "acc for Psat= 0.07419986070858108 \n",
      "acc for optim= 0.15354443698500594\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.0035855956375598907\n",
      "Loss on test= 0.005155408754944801\n",
      "acc for Lsat= 0.07162344440196951 \n",
      "acc for Psat= 0.10872369549340671 \n",
      "acc for optim= 0.11651593732757545\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.0036526250187307596\n",
      "Loss on test= 0.004984429571777582\n",
      "acc for Lsat= 0.07966575585305691 \n",
      "acc for Psat= 0.08194980597020024 \n",
      "acc for optim= 0.11422599603732426\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.003472904907539487\n",
      "Loss on test= 0.005195797421038151\n",
      "acc for Lsat= 0.07470657099555764 \n",
      "acc for Psat= 0.10306989036810894 \n",
      "acc for optim= 0.15171530649402282\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.003644906682893634\n",
      "Loss on test= 0.0047527942806482315\n",
      "acc for Lsat= 0.10487428105746706 \n",
      "acc for Psat= 0.11531459661718044 \n",
      "acc for optim= 0.15458302520629433\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.0038289627991616726\n",
      "Loss on test= 0.005277056712657213\n",
      "acc for Lsat= 0.09424830404006773 \n",
      "acc for Psat= 0.11084125418629912 \n",
      "acc for optim= 0.16100778572985697\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.0036359152290970087\n",
      "Loss on test= 0.004904700443148613\n",
      "acc for Lsat= 0.08216001507632124 \n",
      "acc for Psat= 0.09739659788707893 \n",
      "acc for optim= 0.10867420063974957\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.003610328072682023\n",
      "Loss on test= 0.004936255048960447\n",
      "acc for Lsat= 0.07281259856083327 \n",
      "acc for Psat= 0.10536544961440894 \n",
      "acc for optim= 0.16130926149586836\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.0036353671457618475\n",
      "Loss on test= 0.004886253736913204\n",
      "acc for Lsat= 0.11034146543048944 \n",
      "acc for Psat= 0.10717149800459286 \n",
      "acc for optim= 0.13945191436343723\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.0035278303548693657\n",
      "Loss on test= 0.004991911817342043\n",
      "acc for Lsat= 0.09851974116948743 \n",
      "acc for Psat= 0.1493935434975558 \n",
      "acc for optim= 0.12789195319378954\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.0034886919893324375\n",
      "Loss on test= 0.00489809550344944\n",
      "acc for Lsat= 0.10625916274471416 \n",
      "acc for Psat= 0.12822345923632383 \n",
      "acc for optim= 0.1489814150457581\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.0035606613382697105\n",
      "Loss on test= 0.00464647589251399\n",
      "acc for Lsat= 0.11260836488670772 \n",
      "acc for Psat= 0.08147241007019249 \n",
      "acc for optim= 0.12105160905048251\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.003627668833360076\n",
      "Loss on test= 0.004916597623378038\n",
      "acc for Lsat= 0.09447884432867998 \n",
      "acc for Psat= 0.1218063559046843 \n",
      "acc for optim= 0.13433259702287614\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.0037132047582417727\n",
      "Loss on test= 0.005281846038997173\n",
      "acc for Lsat= 0.12853437824459332 \n",
      "acc for Psat= 0.1425915809555186 \n",
      "acc for optim= 0.14988586927453676\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.003578485455363989\n",
      "Loss on test= 0.004651679657399654\n",
      "acc for Lsat= 0.07797050472193708 \n",
      "acc for Psat= 0.1184760597275777 \n",
      "acc for optim= 0.15708292254971135\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.0035544668789952993\n",
      "Loss on test= 0.005391212180256844\n",
      "acc for Lsat= 0.07602748047793284 \n",
      "acc for Psat= 0.11325542040220979 \n",
      "acc for optim= 0.11763889583138128\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.003607437014579773\n",
      "Loss on test= 0.0051123914308846\n",
      "acc for Lsat= 0.13185001962564355 \n",
      "acc for Psat= 0.13343817947639358 \n",
      "acc for optim= 0.1186041004774678\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.00361295766197145\n",
      "Loss on test= 0.005123842973262072\n",
      "acc for Lsat= 0.09286541062303716 \n",
      "acc for Psat= 0.07943231933232811 \n",
      "acc for optim= 0.13105170190748242\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.0035903053358197212\n",
      "Loss on test= 0.005434371531009674\n",
      "acc for Lsat= 0.09203554917540815 \n",
      "acc for Psat= 0.13457935872591203 \n",
      "acc for optim= 0.14559505616004267\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.0036089024506509304\n",
      "Loss on test= 0.0049782609567046165\n",
      "acc for Lsat= 0.12897056162667772 \n",
      "acc for Psat= 0.14262635591957304 \n",
      "acc for optim= 0.13805655281369886\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.0036775858607143164\n",
      "Loss on test= 0.005556998774409294\n",
      "acc for Lsat= 0.09100236557424068 \n",
      "acc for Psat= 0.11592946517177755 \n",
      "acc for optim= 0.13988785443103147\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.0035761361941695213\n",
      "Loss on test= 0.004766140598803759\n",
      "acc for Lsat= 0.10883865054024176 \n",
      "acc for Psat= 0.11878768603006999 \n",
      "acc for optim= 0.13297762592426604\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.0034938587341457605\n",
      "Loss on test= 0.005201879423111677\n",
      "acc for Lsat= 0.11654577443752917 \n",
      "acc for Psat= 0.11365686879596776 \n",
      "acc for optim= 0.12175386643502861\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.0036657070741057396\n",
      "Loss on test= 0.004667628090828657\n",
      "acc for Lsat= 0.10967943669917683 \n",
      "acc for Psat= 0.09941663162317127 \n",
      "acc for optim= 0.12946496698229262\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.003494419390335679\n",
      "Loss on test= 0.004782259929925203\n",
      "acc for Lsat= 0.1371643152087927 \n",
      "acc for Psat= 0.14284488119948138 \n",
      "acc for optim= 0.13200709441055855\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.0036286013200879097\n",
      "Loss on test= 0.00479282857850194\n",
      "acc for Lsat= 0.11884756893333462 \n",
      "acc for Psat= 0.11271203743914764 \n",
      "acc for optim= 0.13529041349991328\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.003708017524331808\n",
      "Loss on test= 0.004891904536634684\n",
      "acc for Lsat= 0.10437207588337413 \n",
      "acc for Psat= 0.13169099664729503 \n",
      "acc for optim= 0.14175239805546072\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.003668201854452491\n",
      "Loss on test= 0.004974332172423601\n",
      "acc for Lsat= 0.10963139320827192 \n",
      "acc for Psat= 0.17167878119895855 \n",
      "acc for optim= 0.11353468222336636\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.003632049774751067\n",
      "Loss on test= 0.005256848409771919\n",
      "acc for Lsat= 0.07699837809842494 \n",
      "acc for Psat= 0.12551493490011328 \n",
      "acc for optim= 0.11720355668189263\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.0035953966435045004\n",
      "Loss on test= 0.0046343496069312096\n",
      "acc for Lsat= 0.11073886626400054 \n",
      "acc for Psat= 0.11472088455532987 \n",
      "acc for optim= 0.1386187537573278\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.003745637834072113\n",
      "Loss on test= 0.005097192246466875\n",
      "acc for Lsat= 0.11184562517640491 \n",
      "acc for Psat= 0.09076405218284991 \n",
      "acc for optim= 0.1595665383566585\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.0035996290389448404\n",
      "Loss on test= 0.004634259268641472\n",
      "acc for Lsat= 0.10624478550420867 \n",
      "acc for Psat= 0.1463773642770118 \n",
      "acc for optim= 0.11723111831169161\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.003459065919741988\n",
      "Loss on test= 0.005225363653153181\n",
      "acc for Lsat= 0.11986128225301702 \n",
      "acc for Psat= 0.13429015347113213 \n",
      "acc for optim= 0.15569846223418912\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.003609498031437397\n",
      "Loss on test= 0.005306677892804146\n",
      "acc for Lsat= 0.10396238861398564 \n",
      "acc for Psat= 0.10945169447687578 \n",
      "acc for optim= 0.13764045890032625\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.0035899782087653875\n",
      "Loss on test= 0.004708709195256233\n",
      "acc for Lsat= 0.10567701369937924 \n",
      "acc for Psat= 0.10679793040940745 \n",
      "acc for optim= 0.13871320844110516\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.0035472847521305084\n",
      "Loss on test= 0.005112862214446068\n",
      "acc for Lsat= 0.1050687095719493 \n",
      "acc for Psat= 0.14262291725673196 \n",
      "acc for optim= 0.1598793785346465\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.0035713710822165012\n",
      "Loss on test= 0.005218928679823875\n",
      "acc for Lsat= 0.10614322920122908 \n",
      "acc for Psat= 0.12752115245287618 \n",
      "acc for optim= 0.12689201536381411\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.003572330577298999\n",
      "Loss on test= 0.004956109914928675\n",
      "acc for Lsat= 0.13186496860321817 \n",
      "acc for Psat= 0.09957378242527032 \n",
      "acc for optim= 0.1336597782921874\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.0036162694450467825\n",
      "Loss on test= 0.004952627699822187\n",
      "acc for Lsat= 0.12313490071230465 \n",
      "acc for Psat= 0.12408913713362482 \n",
      "acc for optim= 0.150622163588802\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.0035900117363780737\n",
      "Loss on test= 0.004949814639985561\n",
      "acc for Lsat= 0.10372774458179872 \n",
      "acc for Psat= 0.0881389466424783 \n",
      "acc for optim= 0.1332471386865816\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.0035818179603666067\n",
      "Loss on test= 0.005069204140454531\n",
      "acc for Lsat= 0.13587206084695128 \n",
      "acc for Psat= 0.16409000309391153 \n",
      "acc for optim= 0.1090748229697864\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.003586307168006897\n",
      "Loss on test= 0.004955241922289133\n",
      "acc for Lsat= 0.12194145413943464 \n",
      "acc for Psat= 0.11855509784072638 \n",
      "acc for optim= 0.14113573364900528\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.003442995948716998\n",
      "Loss on test= 0.005253709852695465\n",
      "acc for Lsat= 0.11798340330521266 \n",
      "acc for Psat= 0.10500850157243097 \n",
      "acc for optim= 0.1194701145739398\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.0034597478806972504\n",
      "Loss on test= 0.004846698604524136\n",
      "acc for Lsat= 0.11274948654722215 \n",
      "acc for Psat= 0.17002599427683485 \n",
      "acc for optim= 0.13843964060975444\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.0037348507903516293\n",
      "Loss on test= 0.004724185913801193\n",
      "acc for Lsat= 0.10590842397262652 \n",
      "acc for Psat= 0.12304749800306228 \n",
      "acc for optim= 0.11696833475596374\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.003669524798169732\n",
      "Loss on test= 0.004991445690393448\n",
      "acc for Lsat= 0.1251255694983734 \n",
      "acc for Psat= 0.11247328927533494 \n",
      "acc for optim= 0.14851753920730618\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.0033935094252228737\n",
      "Loss on test= 0.0050302352756261826\n",
      "acc for Lsat= 0.10734272559380366 \n",
      "acc for Psat= 0.12219193256977531 \n",
      "acc for optim= 0.162826449636163\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.0033944607712328434\n",
      "Loss on test= 0.005052223801612854\n",
      "acc for Lsat= 0.1039833348125588 \n",
      "acc for Psat= 0.11264417539091988 \n",
      "acc for optim= 0.13292803136735326\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.0034244467969983816\n",
      "Loss on test= 0.004995756782591343\n",
      "acc for Lsat= 0.1100572560292979 \n",
      "acc for Psat= 0.10517035036658247 \n",
      "acc for optim= 0.14323298710708818\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.0035042883828282356\n",
      "Loss on test= 0.004834990948438644\n",
      "acc for Lsat= 0.10136263789091673 \n",
      "acc for Psat= 0.13291045997498763 \n",
      "acc for optim= 0.15644558984786272\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.003473073011264205\n",
      "Loss on test= 0.005042445380240679\n",
      "acc for Lsat= 0.08799960738138503 \n",
      "acc for Psat= 0.1127811474725604 \n",
      "acc for optim= 0.14031351373220483\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.003588292049244046\n",
      "Loss on test= 0.004978270269930363\n",
      "acc for Lsat= 0.12299734667693782 \n",
      "acc for Psat= 0.09468731299663584 \n",
      "acc for optim= 0.1429283207592865\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.0035103613045066595\n",
      "Loss on test= 0.005305108614265919\n",
      "acc for Lsat= 0.1343153003027611 \n",
      "acc for Psat= 0.16190999389962396 \n",
      "acc for optim= 0.11602607237485547\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.003554396331310272\n",
      "Loss on test= 0.004790032282471657\n",
      "acc for Lsat= 0.10629929596527493 \n",
      "acc for Psat= 0.13687272479809406 \n",
      "acc for optim= 0.16182936458951896\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.0034861653111875057\n",
      "Loss on test= 0.004931807052344084\n",
      "acc for Lsat= 0.10446864070319054 \n",
      "acc for Psat= 0.12272319839232498 \n",
      "acc for optim= 0.16967604950898224\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.003451733384281397\n",
      "Loss on test= 0.00501299137249589\n",
      "acc for Lsat= 0.14909913300329614 \n",
      "acc for Psat= 0.12518173556115167 \n",
      "acc for optim= 0.1328915064740512\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.003550885710865259\n",
      "Loss on test= 0.004839917179197073\n",
      "acc for Lsat= 0.09081227358223663 \n",
      "acc for Psat= 0.10013930811288042 \n",
      "acc for optim= 0.11140998701254527\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.0036943440791219473\n",
      "Loss on test= 0.005509832873940468\n",
      "acc for Lsat= 0.12501643059982193 \n",
      "acc for Psat= 0.1167632227556573 \n",
      "acc for optim= 0.1744203380981667\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.003567600157111883\n",
      "Loss on test= 0.00502883642911911\n",
      "acc for Lsat= 0.12160647039612134 \n",
      "acc for Psat= 0.10602167253899905 \n",
      "acc for optim= 0.12240080530237821\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.0035851786378771067\n",
      "Loss on test= 0.004592027515172958\n",
      "acc for Lsat= 0.09838612623409265 \n",
      "acc for Psat= 0.10187149225061552 \n",
      "acc for optim= 0.14048393311612825\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.0035857530310750008\n",
      "Loss on test= 0.004824465606361628\n",
      "acc for Lsat= 0.13097222643490466 \n",
      "acc for Psat= 0.13020225383418924 \n",
      "acc for optim= 0.11248327514881061\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.003492813790217042\n",
      "Loss on test= 0.005036436952650547\n",
      "acc for Lsat= 0.11646440441513227 \n",
      "acc for Psat= 0.1269556650529719 \n",
      "acc for optim= 0.11678999020821518\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.003516074037179351\n",
      "Loss on test= 0.004874135833233595\n",
      "acc for Lsat= 0.05580956197809428 \n",
      "acc for Psat= 0.0954361687375543 \n",
      "acc for optim= 0.15355622626116705\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.0034670636523514986\n",
      "Loss on test= 0.005863273050636053\n",
      "acc for Lsat= 0.08652214120633693 \n",
      "acc for Psat= 0.15662768563359147 \n",
      "acc for optim= 0.13167878568896818\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.003708433359861374\n",
      "Loss on test= 0.00517801009118557\n",
      "acc for Lsat= 0.12662265573938689 \n",
      "acc for Psat= 0.11222744055299295 \n",
      "acc for optim= 0.13013807891143692\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.0035277900751680136\n",
      "Loss on test= 0.004807187709957361\n",
      "acc for Lsat= 0.10299351700167689 \n",
      "acc for Psat= 0.15856346819135878 \n",
      "acc for optim= 0.11088791136636347\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.0035334446001797915\n",
      "Loss on test= 0.0047055939212441444\n",
      "acc for Lsat= 0.10799300023871991 \n",
      "acc for Psat= 0.12326371090279685 \n",
      "acc for optim= 0.11516410091684924\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.0036142198368906975\n",
      "Loss on test= 0.0051276953890919685\n",
      "acc for Lsat= 0.08049465808047292 \n",
      "acc for Psat= 0.11100892810564902 \n",
      "acc for optim= 0.14859800516731209\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.0035418381448835135\n",
      "Loss on test= 0.004992211237549782\n",
      "acc for Lsat= 0.09121672229634391 \n",
      "acc for Psat= 0.1221880302247074 \n",
      "acc for optim= 0.10923991693481286\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.0036596828140318394\n",
      "Loss on test= 0.00480233458802104\n",
      "acc for Lsat= 0.09130891526324882 \n",
      "acc for Psat= 0.10908469992379348 \n",
      "acc for optim= 0.12846156023442745\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.0034772418439388275\n",
      "Loss on test= 0.004932146053761244\n",
      "acc for Lsat= 0.11054765515857273 \n",
      "acc for Psat= 0.1153726877269542 \n",
      "acc for optim= 0.1224478457071301\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.0034083419013768435\n",
      "Loss on test= 0.004711411893367767\n",
      "acc for Lsat= 0.08534968833232091 \n",
      "acc for Psat= 0.10174497856577444 \n",
      "acc for optim= 0.10461881016898486\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.003528977744281292\n",
      "Loss on test= 0.004949331283569336\n",
      "acc for Lsat= 0.10097306750766519 \n",
      "acc for Psat= 0.12007168306606925 \n",
      "acc for optim= 0.11383066694058168\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.0036348968278616667\n",
      "Loss on test= 0.005339530296623707\n",
      "acc for Lsat= 0.09155587350121802 \n",
      "acc for Psat= 0.1291729794918663 \n",
      "acc for optim= 0.15316551983252996\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.003549132263287902\n",
      "Loss on test= 0.004710803274065256\n",
      "acc for Lsat= 0.10235332402711113 \n",
      "acc for Psat= 0.11615993585049485 \n",
      "acc for optim= 0.13155561178508732\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.00352234928868711\n",
      "Loss on test= 0.004960066173225641\n",
      "acc for Lsat= 0.11726660172765453 \n",
      "acc for Psat= 0.1337528247386217 \n",
      "acc for optim= 0.11242735598029362\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.003567414591088891\n",
      "Loss on test= 0.004906220827251673\n",
      "acc for Lsat= 0.10288477192322414 \n",
      "acc for Psat= 0.0798978399252519 \n",
      "acc for optim= 0.13238074749501216\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.0036154678091406822\n",
      "Loss on test= 0.005357557907700539\n",
      "acc for Lsat= 0.10983813838619325 \n",
      "acc for Psat= 0.13279437051258153 \n",
      "acc for optim= 0.16657207326756585\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.0035127243027091026\n",
      "Loss on test= 0.005508963484317064\n",
      "acc for Lsat= 0.10183429723191592 \n",
      "acc for Psat= 0.11837205223532186 \n",
      "acc for optim= 0.13804385016879273\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.0036907398607581854\n",
      "Loss on test= 0.004751565866172314\n",
      "acc for Lsat= 0.11088855476636025 \n",
      "acc for Psat= 0.1105618645540542 \n",
      "acc for optim= 0.12673454343651733\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.00359755358658731\n",
      "Loss on test= 0.0054861875250935555\n",
      "acc for Lsat= 0.08101597101065433 \n",
      "acc for Psat= 0.09238441343445124 \n",
      "acc for optim= 0.16117086872044536\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.0035212873481214046\n",
      "Loss on test= 0.005499504040926695\n",
      "acc for Lsat= 0.08340960267620783 \n",
      "acc for Psat= 0.14771923412465388 \n",
      "acc for optim= 0.11283199901097557\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.0035333274863660336\n",
      "Loss on test= 0.005226312205195427\n",
      "acc for Lsat= 0.09289071094503419 \n",
      "acc for Psat= 0.1125538447457883 \n",
      "acc for optim= 0.13064217443267503\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.00349079049192369\n",
      "Loss on test= 0.005073157139122486\n",
      "acc for Lsat= 0.14065726867152584 \n",
      "acc for Psat= 0.11193243353368922 \n",
      "acc for optim= 0.11580325399215023\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.003553851041942835\n",
      "Loss on test= 0.005671970546245575\n",
      "acc for Lsat= 0.11082862941030827 \n",
      "acc for Psat= 0.10803976706746551 \n",
      "acc for optim= 0.15711181128345844\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.0034514234866946936\n",
      "Loss on test= 0.005004028789699078\n",
      "acc for Lsat= 0.09021589811891317 \n",
      "acc for Psat= 0.09927307887604304 \n",
      "acc for optim= 0.1414279549693068\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.003439894411712885\n",
      "Loss on test= 0.004982909187674522\n",
      "acc for Lsat= 0.07558934734616843 \n",
      "acc for Psat= 0.13547705873174387 \n",
      "acc for optim= 0.1261714993096474\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.00339685520157218\n",
      "Loss on test= 0.005014313384890556\n",
      "acc for Lsat= 0.060240942545028195 \n",
      "acc for Psat= 0.10263787504906456 \n",
      "acc for optim= 0.12662349429188502\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.0035202025901526213\n",
      "Loss on test= 0.004941584542393684\n",
      "acc for Lsat= 0.10052797291427851 \n",
      "acc for Psat= 0.10218535847444501 \n",
      "acc for optim= 0.13738681523439786\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.0034368194174021482\n",
      "Loss on test= 0.005164292640984058\n",
      "acc for Lsat= 0.09717242490215641 \n",
      "acc for Psat= 0.1108025008191665 \n",
      "acc for optim= 0.13605381009013703\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.003532157279551029\n",
      "Loss on test= 0.004857048857957125\n",
      "acc for Lsat= 0.13448250048612762 \n",
      "acc for Psat= 0.09375881071900949 \n",
      "acc for optim= 0.10086702699643663\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.003474337048828602\n",
      "Loss on test= 0.0052018254064023495\n",
      "acc for Lsat= 0.1259323517119305 \n",
      "acc for Psat= 0.14544898863985306 \n",
      "acc for optim= 0.14426434153897894\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.0034299595281481743\n",
      "Loss on test= 0.005120948888361454\n",
      "acc for Lsat= 0.09740583687865485 \n",
      "acc for Psat= 0.09003480314923865 \n",
      "acc for optim= 0.12632460561063555\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.0034219487570226192\n",
      "Loss on test= 0.005177425220608711\n",
      "acc for Lsat= 0.10380155155305854 \n",
      "acc for Psat= 0.10204824510340889 \n",
      "acc for optim= 0.1435384572380119\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.00350769842043519\n",
      "Loss on test= 0.0049590058624744415\n",
      "acc for Lsat= 0.07887095095874327 \n",
      "acc for Psat= 0.1369970314618614 \n",
      "acc for optim= 0.12907752844815454\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.0034546295646578074\n",
      "Loss on test= 0.004753606393933296\n",
      "acc for Lsat= 0.12334810559534365 \n",
      "acc for Psat= 0.16223434609774914 \n",
      "acc for optim= 0.12386763758129543\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.0035892827436327934\n",
      "Loss on test= 0.00508886156603694\n",
      "acc for Lsat= 0.12393743793169658 \n",
      "acc for Psat= 0.09698096616193652 \n",
      "acc for optim= 0.15054147152437103\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.0034704566933214664\n",
      "Loss on test= 0.004828121047466993\n",
      "acc for Lsat= 0.10805288624639313 \n",
      "acc for Psat= 0.100864396926934 \n",
      "acc for optim= 0.13721286484764683\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.0035212039947509766\n",
      "Loss on test= 0.005441837944090366\n",
      "acc for Lsat= 0.11526773885513346 \n",
      "acc for Psat= 0.1236058814295878 \n",
      "acc for optim= 0.13227672522447798\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.0035413079895079136\n",
      "Loss on test= 0.004981299862265587\n",
      "acc for Lsat= 0.0949282498994661 \n",
      "acc for Psat= 0.13352441968163475 \n",
      "acc for optim= 0.13399900950025767\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.003432397497817874\n",
      "Loss on test= 0.005018807481974363\n",
      "acc for Lsat= 0.11165630120214903 \n",
      "acc for Psat= 0.15112973236116684 \n",
      "acc for optim= 0.12321753179033597\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.003416316118091345\n",
      "Loss on test= 0.0048781391233205795\n",
      "acc for Lsat= 0.11817633773251954 \n",
      "acc for Psat= 0.1427791335930427 \n",
      "acc for optim= 0.12001324077654216\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.0033955099061131477\n",
      "Loss on test= 0.005300020799040794\n",
      "acc for Lsat= 0.11082672087165217 \n",
      "acc for Psat= 0.12200425451414453 \n",
      "acc for optim= 0.14921183666835228\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.003399227513000369\n",
      "Loss on test= 0.004760379903018475\n",
      "acc for Lsat= 0.08164958446286619 \n",
      "acc for Psat= 0.12081944200003313 \n",
      "acc for optim= 0.14154450970494914\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.0034693293273448944\n",
      "Loss on test= 0.004523301497101784\n",
      "acc for Lsat= 0.10136944785093267 \n",
      "acc for Psat= 0.10646628906639914 \n",
      "acc for optim= 0.13162330450076196\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.0034655018243938684\n",
      "Loss on test= 0.0054902140982449055\n",
      "acc for Lsat= 0.08600307882039084 \n",
      "acc for Psat= 0.09896848299023178 \n",
      "acc for optim= 0.1428392725194701\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.0035396406892687082\n",
      "Loss on test= 0.0048726447857916355\n",
      "acc for Lsat= 0.12075860022256772 \n",
      "acc for Psat= 0.13461339775110698 \n",
      "acc for optim= 0.13235432116521728\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.003426474519073963\n",
      "Loss on test= 0.004994700662791729\n",
      "acc for Lsat= 0.10691364610102028 \n",
      "acc for Psat= 0.08051105686980817 \n",
      "acc for optim= 0.1325954032751421\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.0034887539222836494\n",
      "Loss on test= 0.00537104019895196\n",
      "acc for Lsat= 0.11933870717055267 \n",
      "acc for Psat= 0.151906228882985 \n",
      "acc for optim= 0.12387426117978369\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.0034801894798874855\n",
      "Loss on test= 0.004855291452258825\n",
      "acc for Lsat= 0.11450711399730709 \n",
      "acc for Psat= 0.13138524184210432 \n",
      "acc for optim= 0.1193154520717346\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.0036146047059446573\n",
      "Loss on test= 0.004956824705004692\n",
      "acc for Lsat= 0.10940434735837495 \n",
      "acc for Psat= 0.13084833111820948 \n",
      "acc for optim= 0.11804009682964534\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.003477661404758692\n",
      "Loss on test= 0.005241811741143465\n",
      "acc for Lsat= 0.10576938570011407 \n",
      "acc for Psat= 0.1355557187149922 \n",
      "acc for optim= 0.13114001335472697\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.0035541600082069635\n",
      "Loss on test= 0.004755976144224405\n",
      "acc for Lsat= 0.10752055497788307 \n",
      "acc for Psat= 0.09940938641213709 \n",
      "acc for optim= 0.12184775486174557\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.0034789724741131067\n",
      "Loss on test= 0.004904739558696747\n",
      "acc for Lsat= 0.10379855862508218 \n",
      "acc for Psat= 0.1027350172193514 \n",
      "acc for optim= 0.12223351976394446\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.0035018662456423044\n",
      "Loss on test= 0.00519542396068573\n",
      "acc for Lsat= 0.11928703309968114 \n",
      "acc for Psat= 0.1383603023779061 \n",
      "acc for optim= 0.14131702960973294\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.0034618491772562265\n",
      "Loss on test= 0.004643438849598169\n",
      "acc for Lsat= 0.13556400976247257 \n",
      "acc for Psat= 0.1463353146876519 \n",
      "acc for optim= 0.12028456256828374\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.0034045239444822073\n",
      "Loss on test= 0.004763723351061344\n",
      "acc for Lsat= 0.0954485926259723 \n",
      "acc for Psat= 0.14088468558879363 \n",
      "acc for optim= 0.15735018201586273\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.0034000917803496122\n",
      "Loss on test= 0.00478701526299119\n",
      "acc for Lsat= 0.10278418815384309 \n",
      "acc for Psat= 0.12084469960407457 \n",
      "acc for optim= 0.1204050823321773\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.0034217997454106808\n",
      "Loss on test= 0.004946778994053602\n",
      "acc for Lsat= 0.11816339468997386 \n",
      "acc for Psat= 0.11267501985033353 \n",
      "acc for optim= 0.13453909922908577\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.0034269096795469522\n",
      "Loss on test= 0.005152036901563406\n",
      "acc for Lsat= 0.11967216690795289 \n",
      "acc for Psat= 0.1414109988965922 \n",
      "acc for optim= 0.1299638910115593\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.0033831342589110136\n",
      "Loss on test= 0.004767828155308962\n",
      "acc for Lsat= 0.12186662661325601 \n",
      "acc for Psat= 0.1307133181641499 \n",
      "acc for optim= 0.1143369109534736\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.0034122876822948456\n",
      "Loss on test= 0.004914994351565838\n",
      "acc for Lsat= 0.12253610145611067 \n",
      "acc for Psat= 0.1512203457661801 \n",
      "acc for optim= 0.1272244320458008\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.003476249286904931\n",
      "Loss on test= 0.004872256889939308\n",
      "acc for Lsat= 0.08874748861934575 \n",
      "acc for Psat= 0.08555724502204815 \n",
      "acc for optim= 0.15921525988313887\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.0034082664642482996\n",
      "Loss on test= 0.004980364814400673\n",
      "acc for Lsat= 0.09658240393683729 \n",
      "acc for Psat= 0.09721096302382648 \n",
      "acc for optim= 0.1342853204243713\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.0034439214505255222\n",
      "Loss on test= 0.004764305427670479\n",
      "acc for Lsat= 0.09580433461815119 \n",
      "acc for Psat= 0.07982624650725888 \n",
      "acc for optim= 0.12475824495777488\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.003472857875749469\n",
      "Loss on test= 0.004841328132897615\n",
      "acc for Lsat= 0.08649412953915696 \n",
      "acc for Psat= 0.11078705090201563 \n",
      "acc for optim= 0.14769942771332958\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.0035804875660687685\n",
      "Loss on test= 0.0050236526876688\n",
      "acc for Lsat= 0.09339994326647785 \n",
      "acc for Psat= 0.132785194967356 \n",
      "acc for optim= 0.1523602956181599\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.0034566810354590416\n",
      "Loss on test= 0.004807576537132263\n",
      "acc for Lsat= 0.10791580979194906 \n",
      "acc for Psat= 0.10753804797099696 \n",
      "acc for optim= 0.11732729428654744\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.0034742141142487526\n",
      "Loss on test= 0.005176297854632139\n",
      "acc for Lsat= 0.0807365958090587 \n",
      "acc for Psat= 0.12157338992175129 \n",
      "acc for optim= 0.16593881613678402\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.003336676862090826\n",
      "Loss on test= 0.004863580223172903\n",
      "acc for Lsat= 0.11038384477918346 \n",
      "acc for Psat= 0.13537955579037467 \n",
      "acc for optim= 0.1544206684662236\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.0032987522426992655\n",
      "Loss on test= 0.004442648496478796\n",
      "acc for Lsat= 0.11966414511617687 \n",
      "acc for Psat= 0.13366809849523836 \n",
      "acc for optim= 0.12754454132583407\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.0033903270959854126\n",
      "Loss on test= 0.005245876032859087\n",
      "acc for Lsat= 0.0788069753277038 \n",
      "acc for Psat= 0.09442588399785261 \n",
      "acc for optim= 0.11988089013094497\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.0033508827909827232\n",
      "Loss on test= 0.004881471861153841\n",
      "acc for Lsat= 0.12348913088337415 \n",
      "acc for Psat= 0.1059394488369839 \n",
      "acc for optim= 0.14252521974655488\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.0033926537726074457\n",
      "Loss on test= 0.005263829603791237\n",
      "acc for Lsat= 0.10627583212529619 \n",
      "acc for Psat= 0.09581258282479313 \n",
      "acc for optim= 0.11604833463206887\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.003440587082877755\n",
      "Loss on test= 0.005123181268572807\n",
      "acc for Lsat= 0.11469934570292632 \n",
      "acc for Psat= 0.07277042639796288 \n",
      "acc for optim= 0.16651329108410412\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.0033950572833418846\n",
      "Loss on test= 0.004999253898859024\n",
      "acc for Lsat= 0.070382843621903 \n",
      "acc for Psat= 0.08043216964385162 \n",
      "acc for optim= 0.13120605123953688\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.003378906287252903\n",
      "Loss on test= 0.005284530576318502\n",
      "acc for Lsat= 0.0916914535870698 \n",
      "acc for Psat= 0.14209047125445473 \n",
      "acc for optim= 0.16140717015756914\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.003413260215893388\n",
      "Loss on test= 0.0049208360724151134\n",
      "acc for Lsat= 0.11794317348135842 \n",
      "acc for Psat= 0.13428057982431105 \n",
      "acc for optim= 0.14665170650308332\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.0033573186956346035\n",
      "Loss on test= 0.004912738688290119\n",
      "acc for Lsat= 0.1108813975782444 \n",
      "acc for Psat= 0.11139197802791993 \n",
      "acc for optim= 0.12610578703849265\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.003402682486921549\n",
      "Loss on test= 0.005456758663058281\n",
      "acc for Lsat= 0.1138032200332317 \n",
      "acc for Psat= 0.12547406217911178 \n",
      "acc for optim= 0.1358061594526387\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.0033789658918976784\n",
      "Loss on test= 0.0046407803893089294\n",
      "acc for Lsat= 0.10388350812718272 \n",
      "acc for Psat= 0.11152049785272942 \n",
      "acc for optim= 0.1202943455427885\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.0033485402818769217\n",
      "Loss on test= 0.004670342430472374\n",
      "acc for Lsat= 0.11331875486454616 \n",
      "acc for Psat= 0.07160468345197539 \n",
      "acc for optim= 0.1499957786872983\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.0034489461686462164\n",
      "Loss on test= 0.005532143637537956\n",
      "acc for Lsat= 0.12132424312747186 \n",
      "acc for Psat= 0.10889709352826078 \n",
      "acc for optim= 0.10594571868164672\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.0034315339289605618\n",
      "Loss on test= 0.005352175794541836\n",
      "acc for Lsat= 0.11603187547168797 \n",
      "acc for Psat= 0.10649416802657975 \n",
      "acc for optim= 0.12141377737538682\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.003282929304987192\n",
      "Loss on test= 0.005212532822042704\n",
      "acc for Lsat= 0.09972336738266879 \n",
      "acc for Psat= 0.12385057083641489 \n",
      "acc for optim= 0.13269373712440333\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.003435215912759304\n",
      "Loss on test= 0.005046821665018797\n",
      "acc for Lsat= 0.10812559990315801 \n",
      "acc for Psat= 0.13708818062312073 \n",
      "acc for optim= 0.13032137126558357\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.003532151225954294\n",
      "Loss on test= 0.005130311474204063\n",
      "acc for Lsat= 0.11635205517652342 \n",
      "acc for Psat= 0.11084059077418512 \n",
      "acc for optim= 0.16353425450829995\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.0032791492994874716\n",
      "Loss on test= 0.0050430744886398315\n",
      "acc for Lsat= 0.11882716559598015 \n",
      "acc for Psat= 0.09812390263363745 \n",
      "acc for optim= 0.133429076263888\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.0034160218201577663\n",
      "Loss on test= 0.005113576538860798\n",
      "acc for Lsat= 0.10467475730304916 \n",
      "acc for Psat= 0.12114494365070844 \n",
      "acc for optim= 0.12170581403188407\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.0034902056213468313\n",
      "Loss on test= 0.005047548562288284\n",
      "acc for Lsat= 0.10445322397734141 \n",
      "acc for Psat= 0.13167207861422664 \n",
      "acc for optim= 0.1490448231084479\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.0032919084187597036\n",
      "Loss on test= 0.004889878444373608\n",
      "acc for Lsat= 0.0846054800786078 \n",
      "acc for Psat= 0.10906638117093179 \n",
      "acc for optim= 0.14263941771868202\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.0033774457406252623\n",
      "Loss on test= 0.004954538308084011\n",
      "acc for Lsat= 0.11754858385150631 \n",
      "acc for Psat= 0.1333563596320649 \n",
      "acc for optim= 0.12434811372723845\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.00332488096319139\n",
      "Loss on test= 0.0049555664882063866\n",
      "acc for Lsat= 0.11400719162904555 \n",
      "acc for Psat= 0.07678896613005134 \n",
      "acc for optim= 0.11109780293837604\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.0033720701467245817\n",
      "Loss on test= 0.005304510239511728\n",
      "acc for Lsat= 0.10465896326220697 \n",
      "acc for Psat= 0.08057747680383424 \n",
      "acc for optim= 0.14028185616350836\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.003368040081113577\n",
      "Loss on test= 0.005365460645407438\n",
      "acc for Lsat= 0.10377948079258204 \n",
      "acc for Psat= 0.13532870421962193 \n",
      "acc for optim= 0.14216341347330147\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.0034028475638478994\n",
      "Loss on test= 0.005082899704575539\n",
      "acc for Lsat= 0.1358740975200716 \n",
      "acc for Psat= 0.12203161154563229 \n",
      "acc for optim= 0.14164580227548462\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.0033176608849316835\n",
      "Loss on test= 0.005087563768029213\n",
      "acc for Lsat= 0.12220801315399715 \n",
      "acc for Psat= 0.08935779126154052 \n",
      "acc for optim= 0.13828422697002274\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.0033767572604119778\n",
      "Loss on test= 0.004996741656213999\n",
      "acc for Lsat= 0.10247700010788524 \n",
      "acc for Psat= 0.14150145755977267 \n",
      "acc for optim= 0.12172946237519176\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.003447603201493621\n",
      "Loss on test= 0.005067687947303057\n",
      "acc for Lsat= 0.0812351511946569 \n",
      "acc for Psat= 0.08780374189114405 \n",
      "acc for optim= 0.12414249030148818\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.003297906368970871\n",
      "Loss on test= 0.005443940870463848\n",
      "acc for Lsat= 0.10973692964762449 \n",
      "acc for Psat= 0.11196902259770367 \n",
      "acc for optim= 0.15552565530459914\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.0033361390233039856\n",
      "Loss on test= 0.005230339709669352\n",
      "acc for Lsat= 0.06767964340461832 \n",
      "acc for Psat= 0.1366391432368093 \n",
      "acc for optim= 0.1434646088688775\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.003437989391386509\n",
      "Loss on test= 0.005193654913455248\n",
      "acc for Lsat= 0.06276953536952432 \n",
      "acc for Psat= 0.10395511947313531 \n",
      "acc for optim= 0.1256479300920748\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.003208099165931344\n",
      "Loss on test= 0.004921631421893835\n",
      "acc for Lsat= 0.1090603603515774 \n",
      "acc for Psat= 0.12521651727406102 \n",
      "acc for optim= 0.12444373468557994\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.003458548104390502\n",
      "Loss on test= 0.004874050617218018\n",
      "acc for Lsat= 0.10148070928537184 \n",
      "acc for Psat= 0.13482805095716482 \n",
      "acc for optim= 0.11070605315681961\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.003323249751701951\n",
      "Loss on test= 0.0046922434121370316\n",
      "acc for Lsat= 0.09459419305332833 \n",
      "acc for Psat= 0.12135193683207035 \n",
      "acc for optim= 0.13688840996474028\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.003468258073553443\n",
      "Loss on test= 0.004742670338600874\n",
      "acc for Lsat= 0.10912265447485778 \n",
      "acc for Psat= 0.15470295761608416 \n",
      "acc for optim= 0.17512936315809688\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.0032670265063643456\n",
      "Loss on test= 0.0050946446135640144\n",
      "acc for Lsat= 0.09461349911159939 \n",
      "acc for Psat= 0.11778570494304101 \n",
      "acc for optim= 0.14031987883047098\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.003460040781646967\n",
      "Loss on test= 0.004677669145166874\n",
      "acc for Lsat= 0.13730542341040242 \n",
      "acc for Psat= 0.11915381310973316 \n",
      "acc for optim= 0.14137294239157605\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.003413398051634431\n",
      "Loss on test= 0.005080300848931074\n",
      "acc for Lsat= 0.0860969375870708 \n",
      "acc for Psat= 0.1275921824077765 \n",
      "acc for optim= 0.1545498433212439\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.003370516235008836\n",
      "Loss on test= 0.0050181071273982525\n",
      "acc for Lsat= 0.11986138744072782 \n",
      "acc for Psat= 0.14059494673791859 \n",
      "acc for optim= 0.13408939043680826\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.0033486997708678246\n",
      "Loss on test= 0.0052933599799871445\n",
      "acc for Lsat= 0.10178450553535691 \n",
      "acc for Psat= 0.14828173629939556 \n",
      "acc for optim= 0.09918227290230182\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.003302989760413766\n",
      "Loss on test= 0.004622452426701784\n",
      "acc for Lsat= 0.12236482183086789 \n",
      "acc for Psat= 0.12782314137762618 \n",
      "acc for optim= 0.1252968143671751\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.0033693427685648203\n",
      "Loss on test= 0.005254578310996294\n",
      "acc for Lsat= 0.06688663871803631 \n",
      "acc for Psat= 0.07365110299239556 \n",
      "acc for optim= 0.1450773160904646\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.0033289247658103704\n",
      "Loss on test= 0.005006255581974983\n",
      "acc for Lsat= 0.09217829909175634 \n",
      "acc for Psat= 0.09626620811306769 \n",
      "acc for optim= 0.15217291843146086\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.003225737949833274\n",
      "Loss on test= 0.005033070687204599\n",
      "acc for Lsat= 0.07193233248674208 \n",
      "acc for Psat= 0.12998914470275244 \n",
      "acc for optim= 0.14659340034834006\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.003386945463716984\n",
      "Loss on test= 0.005132828373461962\n",
      "acc for Lsat= 0.08807601365778181 \n",
      "acc for Psat= 0.14264223023524714 \n",
      "acc for optim= 0.14055019477705677\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.0032349496614187956\n",
      "Loss on test= 0.004886142909526825\n",
      "acc for Lsat= 0.09445086090515058 \n",
      "acc for Psat= 0.07857433760849138 \n",
      "acc for optim= 0.13267201940632528\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.0033932176884263754\n",
      "Loss on test= 0.005125773139297962\n",
      "acc for Lsat= 0.09806617281153901 \n",
      "acc for Psat= 0.11479401868483466 \n",
      "acc for optim= 0.14058478052417436\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.00344487139955163\n",
      "Loss on test= 0.004891644697636366\n",
      "acc for Lsat= 0.10040883629375862 \n",
      "acc for Psat= 0.10802861531394431 \n",
      "acc for optim= 0.11821178170955843\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.0033840415999293327\n",
      "Loss on test= 0.005010394379496574\n",
      "acc for Lsat= 0.08400797181659275 \n",
      "acc for Psat= 0.100415231504788 \n",
      "acc for optim= 0.12383730781988965\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.003363179974257946\n",
      "Loss on test= 0.004945200402289629\n",
      "acc for Lsat= 0.09061587846372277 \n",
      "acc for Psat= 0.14088854535172382 \n",
      "acc for optim= 0.12527977876986066\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.003317791037261486\n",
      "Loss on test= 0.005020002834498882\n",
      "acc for Lsat= 0.1098865043475396 \n",
      "acc for Psat= 0.09927339227094005 \n",
      "acc for optim= 0.14304799462358156\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.003364515257999301\n",
      "Loss on test= 0.005071206949651241\n",
      "acc for Lsat= 0.11574131791065964 \n",
      "acc for Psat= 0.10274232977664927 \n",
      "acc for optim= 0.13054326135251257\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.0032802396453917027\n",
      "Loss on test= 0.004673854447901249\n",
      "acc for Lsat= 0.13561749724774724 \n",
      "acc for Psat= 0.13232816321154436 \n",
      "acc for optim= 0.12788653900174218\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.003340409602969885\n",
      "Loss on test= 0.005428497213870287\n",
      "acc for Lsat= 0.09871137752715084 \n",
      "acc for Psat= 0.12608648042401505 \n",
      "acc for optim= 0.13088320335373282\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.0034980587661266327\n",
      "Loss on test= 0.004958617500960827\n",
      "acc for Lsat= 0.08983829497204472 \n",
      "acc for Psat= 0.06961570069607761 \n",
      "acc for optim= 0.13409791295675355\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.003387907985597849\n",
      "Loss on test= 0.005378318950533867\n",
      "acc for Lsat= 0.13264608103781939 \n",
      "acc for Psat= 0.15714473644685414 \n",
      "acc for optim= 0.12973069285766947\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.003232566174119711\n",
      "Loss on test= 0.005080718081444502\n",
      "acc for Lsat= 0.11967776809857848 \n",
      "acc for Psat= 0.09030377564744817 \n",
      "acc for optim= 0.12014207099046972\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.003283983562141657\n",
      "Loss on test= 0.0048169344663619995\n",
      "acc for Lsat= 0.11368876537825498 \n",
      "acc for Psat= 0.10882740679921375 \n",
      "acc for optim= 0.1364419381522263\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.0034719996619969606\n",
      "Loss on test= 0.004912199452519417\n",
      "acc for Lsat= 0.1209054083770348 \n",
      "acc for Psat= 0.1310374852683809 \n",
      "acc for optim= 0.12830973732181722\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.0033581771422177553\n",
      "Loss on test= 0.004793023224920034\n",
      "acc for Lsat= 0.11435304747687446 \n",
      "acc for Psat= 0.11842282369939817 \n",
      "acc for optim= 0.11089289685090382\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.003188920207321644\n",
      "Loss on test= 0.004895264282822609\n",
      "acc for Lsat= 0.10048209384290709 \n",
      "acc for Psat= 0.15408786117202705 \n",
      "acc for optim= 0.14393364726048377\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.003373377025127411\n",
      "Loss on test= 0.0048596980050206184\n",
      "acc for Lsat= 0.11545708654577741 \n",
      "acc for Psat= 0.13227198159761933 \n",
      "acc for optim= 0.14558611003061137\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.0034685893915593624\n",
      "Loss on test= 0.004837900400161743\n",
      "acc for Lsat= 0.08819410784376992 \n",
      "acc for Psat= 0.09755264348091765 \n",
      "acc for optim= 0.11967172354666723\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.0032276965212076902\n",
      "Loss on test= 0.004846049007028341\n",
      "acc for Lsat= 0.09248368421362506 \n",
      "acc for Psat= 0.09988456620420846 \n",
      "acc for optim= 0.13691744435992506\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.003308410756289959\n",
      "Loss on test= 0.004934783559292555\n",
      "acc for Lsat= 0.09526970505248755 \n",
      "acc for Psat= 0.12316997941888985 \n",
      "acc for optim= 0.15065266978409556\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.0032886015251278877\n",
      "Loss on test= 0.005001476034522057\n",
      "acc for Lsat= 0.09952660514197002 \n",
      "acc for Psat= 0.1325726235906283 \n",
      "acc for optim= 0.1349131526528961\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.0034592135343700647\n",
      "Loss on test= 0.005279641132801771\n",
      "acc for Lsat= 0.06990796675543404 \n",
      "acc for Psat= 0.0986948168461418 \n",
      "acc for optim= 0.14196675995157826\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.00318264146335423\n",
      "Loss on test= 0.0054677072912454605\n",
      "acc for Lsat= 0.08876264229830769 \n",
      "acc for Psat= 0.09551305874871711 \n",
      "acc for optim= 0.15216116855541864\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.003263253951445222\n",
      "Loss on test= 0.005338281858712435\n",
      "acc for Lsat= 0.10538830645641105 \n",
      "acc for Psat= 0.16843293333012196 \n",
      "acc for optim= 0.11985386454034597\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.0034828968346118927\n",
      "Loss on test= 0.004628583788871765\n",
      "acc for Lsat= 0.07665149800272451 \n",
      "acc for Psat= 0.10149373715588202 \n",
      "acc for optim= 0.14968315460201767\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.003221608465537429\n",
      "Loss on test= 0.005423144903033972\n",
      "acc for Lsat= 0.09750187697096004 \n",
      "acc for Psat= 0.10502886904093127 \n",
      "acc for optim= 0.13581435929518193\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.0034157251939177513\n",
      "Loss on test= 0.00505322590470314\n",
      "acc for Lsat= 0.0786381296089126 \n",
      "acc for Psat= 0.12474768919249375 \n",
      "acc for optim= 0.13819781240696707\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.003308027284219861\n",
      "Loss on test= 0.0050087920390069485\n",
      "acc for Lsat= 0.1089647199648122 \n",
      "acc for Psat= 0.1045081243953771 \n",
      "acc for optim= 0.12410021835886356\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.00339331547729671\n",
      "Loss on test= 0.0048151519149541855\n",
      "acc for Lsat= 0.07785988900124924 \n",
      "acc for Psat= 0.1171928041379336 \n",
      "acc for optim= 0.13112308491124874\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.003406028961762786\n",
      "Loss on test= 0.005291317589581013\n",
      "acc for Lsat= 0.10651078173153412 \n",
      "acc for Psat= 0.13751348356405893 \n",
      "acc for optim= 0.1382054678655954\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.003398873610422015\n",
      "Loss on test= 0.004818323068320751\n",
      "acc for Lsat= 0.08141018512348334 \n",
      "acc for Psat= 0.12409474429053564 \n",
      "acc for optim= 0.13398636797339553\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.0033469684422016144\n",
      "Loss on test= 0.0050350455567240715\n",
      "acc for Lsat= 0.0933553298883554 \n",
      "acc for Psat= 0.10413409516008364 \n",
      "acc for optim= 0.13093350747496718\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.003260029712691903\n",
      "Loss on test= 0.004990865476429462\n",
      "acc for Lsat= 0.11090092526541816 \n",
      "acc for Psat= 0.14529846978580785 \n",
      "acc for optim= 0.13509100979556227\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.0033405935391783714\n",
      "Loss on test= 0.004754220601171255\n",
      "acc for Lsat= 0.09214903910954793 \n",
      "acc for Psat= 0.10968179441341716 \n",
      "acc for optim= 0.17103370325639844\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.0033634500578045845\n",
      "Loss on test= 0.004390371963381767\n",
      "acc for Lsat= 0.10417382388065259 \n",
      "acc for Psat= 0.1420172972397672 \n",
      "acc for optim= 0.12423684391089612\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.0033139935694634914\n",
      "Loss on test= 0.004732521250844002\n",
      "acc for Lsat= 0.10280749410352048 \n",
      "acc for Psat= 0.10377774925695525 \n",
      "acc for optim= 0.1461837716245403\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.003296222537755966\n",
      "Loss on test= 0.004974167328327894\n",
      "acc for Lsat= 0.11609709640550944 \n",
      "acc for Psat= 0.13920371669034162 \n",
      "acc for optim= 0.12529335993652543\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.0034473275300115347\n",
      "Loss on test= 0.005212254822254181\n",
      "acc for Lsat= 0.10352518510060488 \n",
      "acc for Psat= 0.10570106704512404 \n",
      "acc for optim= 0.1205370203177962\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.0032706891652196646\n",
      "Loss on test= 0.004859554581344128\n",
      "acc for Lsat= 0.11049840573428406 \n",
      "acc for Psat= 0.14597946492075506 \n",
      "acc for optim= 0.12047903513303027\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.003516292665153742\n",
      "Loss on test= 0.005095376167446375\n",
      "acc for Lsat= 0.10464724093132342 \n",
      "acc for Psat= 0.1309154600215455 \n",
      "acc for optim= 0.12155333515774044\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.003287520259618759\n",
      "Loss on test= 0.005300055257976055\n",
      "acc for Lsat= 0.0942469909787178 \n",
      "acc for Psat= 0.10879275476973918 \n",
      "acc for optim= 0.1437242030644686\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.003248059656471014\n",
      "Loss on test= 0.005098664201796055\n",
      "acc for Lsat= 0.09473363454324296 \n",
      "acc for Psat= 0.11771779942015807 \n",
      "acc for optim= 0.13482795831643873\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.0033780254889279604\n",
      "Loss on test= 0.005056459456682205\n",
      "acc for Lsat= 0.10185617132164124 \n",
      "acc for Psat= 0.09876004019234744 \n",
      "acc for optim= 0.11340614077117708\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.003170267678797245\n",
      "Loss on test= 0.005121500696986914\n",
      "acc for Lsat= 0.09327707178373304 \n",
      "acc for Psat= 0.09092020067489809 \n",
      "acc for optim= 0.1293393634550739\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.0032549493480473757\n",
      "Loss on test= 0.005307434592396021\n",
      "acc for Lsat= 0.11980576337211662 \n",
      "acc for Psat= 0.16046040587955052 \n",
      "acc for optim= 0.13626026186264223\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.0032317929435521364\n",
      "Loss on test= 0.00474773533642292\n",
      "acc for Lsat= 0.09100411031653897 \n",
      "acc for Psat= 0.09481558472745949 \n",
      "acc for optim= 0.12110097913278474\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.0031956126913428307\n",
      "Loss on test= 0.004995262250304222\n",
      "acc for Lsat= 0.08021306782352945 \n",
      "acc for Psat= 0.10942610989635189 \n",
      "acc for optim= 0.12851277736222577\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.0033436447847634554\n",
      "Loss on test= 0.004828917793929577\n",
      "acc for Lsat= 0.11930856918398705 \n",
      "acc for Psat= 0.13039272878732946 \n",
      "acc for optim= 0.1595401134238475\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.0033380931708961725\n",
      "Loss on test= 0.005021811928600073\n",
      "acc for Lsat= 0.10961563955061138 \n",
      "acc for Psat= 0.10270598711859849 \n",
      "acc for optim= 0.10945826259234713\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.0032136880327016115\n",
      "Loss on test= 0.004858744330704212\n",
      "acc for Lsat= 0.1319289017523665 \n",
      "acc for Psat= 0.13721026645766365 \n",
      "acc for optim= 0.13824714135585559\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.003289021784439683\n",
      "Loss on test= 0.005489980801939964\n",
      "acc for Lsat= 0.08650118861502658 \n",
      "acc for Psat= 0.105996558145206 \n",
      "acc for optim= 0.13433877140697506\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.003218370722606778\n",
      "Loss on test= 0.004893319681286812\n",
      "acc for Lsat= 0.10256723107563125 \n",
      "acc for Psat= 0.14546316547138202 \n",
      "acc for optim= 0.14144223576618564\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.0032180570997297764\n",
      "Loss on test= 0.005530099850147963\n",
      "acc for Lsat= 0.10414650650798446 \n",
      "acc for Psat= 0.08407892232450347 \n",
      "acc for optim= 0.14743857848871914\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.0034481333568692207\n",
      "Loss on test= 0.005055168643593788\n",
      "acc for Lsat= 0.11718702490907162 \n",
      "acc for Psat= 0.10477833967241976 \n",
      "acc for optim= 0.16528484991027248\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.0033131560776382685\n",
      "Loss on test= 0.004885359667241573\n",
      "acc for Lsat= 0.1171102462685667 \n",
      "acc for Psat= 0.1314759584557679 \n",
      "acc for optim= 0.12567138065221822\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.003296965267509222\n",
      "Loss on test= 0.004776766058057547\n",
      "acc for Lsat= 0.09911572803846663 \n",
      "acc for Psat= 0.13712940354728037 \n",
      "acc for optim= 0.1494778645121389\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.003279024502262473\n",
      "Loss on test= 0.004782817792147398\n",
      "acc for Lsat= 0.11802153998158044 \n",
      "acc for Psat= 0.13913999296103916 \n",
      "acc for optim= 0.13635235776503882\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.0032822727225720882\n",
      "Loss on test= 0.005800397600978613\n",
      "acc for Lsat= 0.06457661408542965 \n",
      "acc for Psat= 0.11247330045120583 \n",
      "acc for optim= 0.13814591163019133\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.003358581569045782\n",
      "Loss on test= 0.005487132351845503\n",
      "acc for Lsat= 0.1118520908575091 \n",
      "acc for Psat= 0.09183243713859054 \n",
      "acc for optim= 0.1408400683172254\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.0032799975015223026\n",
      "Loss on test= 0.005262845195829868\n",
      "acc for Lsat= 0.10454049054533243 \n",
      "acc for Psat= 0.11239501854611768 \n",
      "acc for optim= 0.11201923239665727\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.0031621111556887627\n",
      "Loss on test= 0.004687190987169743\n",
      "acc for Lsat= 0.10303936184694369 \n",
      "acc for Psat= 0.0923027283925977 \n",
      "acc for optim= 0.14503416439725292\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.003416994819417596\n",
      "Loss on test= 0.00488470820710063\n",
      "acc for Lsat= 0.10368221063011636 \n",
      "acc for Psat= 0.10038219016213487 \n",
      "acc for optim= 0.136826918563909\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.0033584265038371086\n",
      "Loss on test= 0.004694231785833836\n",
      "acc for Lsat= 0.08099010338062523 \n",
      "acc for Psat= 0.14215702518898374 \n",
      "acc for optim= 0.13338719949954086\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.003181357169523835\n",
      "Loss on test= 0.005388752091675997\n",
      "acc for Lsat= 0.09233307041641739 \n",
      "acc for Psat= 0.08532366373886664 \n",
      "acc for optim= 0.15280673197574085\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.0033489877823740244\n",
      "Loss on test= 0.005157483741641045\n",
      "acc for Lsat= 0.11660287174163386 \n",
      "acc for Psat= 0.1426231006367339 \n",
      "acc for optim= 0.14410905571033558\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.0032357394229620695\n",
      "Loss on test= 0.004815889522433281\n",
      "acc for Lsat= 0.10234290125986768 \n",
      "acc for Psat= 0.1349405322689563 \n",
      "acc for optim= 0.15787976576636234\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.0032452279701828957\n",
      "Loss on test= 0.005278471391648054\n",
      "acc for Lsat= 0.08079681269979726 \n",
      "acc for Psat= 0.10497864884220892 \n",
      "acc for optim= 0.16185202604780594\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.0032215258106589317\n",
      "Loss on test= 0.004771283362060785\n",
      "acc for Lsat= 0.07411119661992416 \n",
      "acc for Psat= 0.10745992477677646 \n",
      "acc for optim= 0.12251363084134129\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.003255247138440609\n",
      "Loss on test= 0.005154449958354235\n",
      "acc for Lsat= 0.09449606211597307 \n",
      "acc for Psat= 0.06002050850333439 \n",
      "acc for optim= 0.12963327579200268\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.0031355731189250946\n",
      "Loss on test= 0.005458306986838579\n",
      "acc for Lsat= 0.09935332053444451 \n",
      "acc for Psat= 0.08331605554040936 \n",
      "acc for optim= 0.15714384936210182\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.003282516496255994\n",
      "Loss on test= 0.004721527453511953\n",
      "acc for Lsat= 0.05617836412663261 \n",
      "acc for Psat= 0.10008979795707597 \n",
      "acc for optim= 0.12449235458754832\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.003273002803325653\n",
      "Loss on test= 0.005012831650674343\n",
      "acc for Lsat= 0.14205690504362187 \n",
      "acc for Psat= 0.08817647992853178 \n",
      "acc for optim= 0.1270175026729703\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.003326467238366604\n",
      "Loss on test= 0.004814357031136751\n",
      "acc for Lsat= 0.11149890896760756 \n",
      "acc for Psat= 0.167784648688717 \n",
      "acc for optim= 0.12051981185666388\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.0032540748361498117\n",
      "Loss on test= 0.004883674439042807\n",
      "acc for Lsat= 0.10911157044271629 \n",
      "acc for Psat= 0.1242006230685446 \n",
      "acc for optim= 0.1361177230460776\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.0032593205105513334\n",
      "Loss on test= 0.005613274872303009\n",
      "acc for Lsat= 0.1051706008406149 \n",
      "acc for Psat= 0.12013045739796427 \n",
      "acc for optim= 0.12523395803550053\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.003293786197900772\n",
      "Loss on test= 0.0051675778813660145\n",
      "acc for Lsat= 0.11538438912894991 \n",
      "acc for Psat= 0.12250146240047696 \n",
      "acc for optim= 0.1525565464463499\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.003303718054667115\n",
      "Loss on test= 0.004632959142327309\n",
      "acc for Lsat= 0.10007810189078252 \n",
      "acc for Psat= 0.11596401051307718 \n",
      "acc for optim= 0.13018741454773894\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.003283992176875472\n",
      "Loss on test= 0.005549081601202488\n",
      "acc for Lsat= 0.11438791557318634 \n",
      "acc for Psat= 0.0926295241418605 \n",
      "acc for optim= 0.09529329421638977\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.0032811055425554514\n",
      "Loss on test= 0.004687818232923746\n",
      "acc for Lsat= 0.11423265561461449 \n",
      "acc for Psat= 0.09240651032369998 \n",
      "acc for optim= 0.14125034034562609\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.0032526878640055656\n",
      "Loss on test= 0.00502614863216877\n",
      "acc for Lsat= 0.10641513682074016 \n",
      "acc for Psat= 0.1300671968816055 \n",
      "acc for optim= 0.12327147585650285\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.003237494733184576\n",
      "Loss on test= 0.004614641424268484\n",
      "acc for Lsat= 0.1050738791624705 \n",
      "acc for Psat= 0.13102317826511958 \n",
      "acc for optim= 0.16701028351154593\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.003190763294696808\n",
      "Loss on test= 0.0048690615221858025\n",
      "acc for Lsat= 0.1103191203955147 \n",
      "acc for Psat= 0.08363937762462431 \n",
      "acc for optim= 0.1400140845346161\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.003113808576017618\n",
      "Loss on test= 0.004672900773584843\n",
      "acc for Lsat= 0.1195582425635722 \n",
      "acc for Psat= 0.14272663903991795 \n",
      "acc for optim= 0.12552049659684095\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.003297255141660571\n",
      "Loss on test= 0.005153873469680548\n",
      "acc for Lsat= 0.09673821605328056 \n",
      "acc for Psat= 0.1365740435818831 \n",
      "acc for optim= 0.14945531275912394\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.0033359297085553408\n",
      "Loss on test= 0.005182025954127312\n",
      "acc for Lsat= 0.1071349890747418 \n",
      "acc for Psat= 0.11928964840869109 \n",
      "acc for optim= 0.1080543150827806\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.0032901642844080925\n",
      "Loss on test= 0.005400241352617741\n",
      "acc for Lsat= 0.1369694710786765 \n",
      "acc for Psat= 0.12295892138758467 \n",
      "acc for optim= 0.13494773522122866\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.0031946152448654175\n",
      "Loss on test= 0.00492614833638072\n",
      "acc for Lsat= 0.11757661862712768 \n",
      "acc for Psat= 0.11500066244560811 \n",
      "acc for optim= 0.11605867001021074\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.003193552140146494\n",
      "Loss on test= 0.004829226527363062\n",
      "acc for Lsat= 0.08404197991411719 \n",
      "acc for Psat= 0.07848052942426875 \n",
      "acc for optim= 0.1589489992087086\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.0032281288877129555\n",
      "Loss on test= 0.004962222650647163\n",
      "acc for Lsat= 0.09111273154202434 \n",
      "acc for Psat= 0.12609503542383513 \n",
      "acc for optim= 0.1300870974858602\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.003333332948386669\n",
      "Loss on test= 0.004790048114955425\n",
      "acc for Lsat= 0.08821032031361635 \n",
      "acc for Psat= 0.11473808490619478 \n",
      "acc for optim= 0.1634302215857638\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.003326208796352148\n",
      "Loss on test= 0.0049801599234342575\n",
      "acc for Lsat= 0.12585699123640856 \n",
      "acc for Psat= 0.10484876454574987 \n",
      "acc for optim= 0.13431883748206827\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.003426333423703909\n",
      "Loss on test= 0.004844950512051582\n",
      "acc for Lsat= 0.10232431745518827 \n",
      "acc for Psat= 0.17156031800227034 \n",
      "acc for optim= 0.12386031904154354\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.0030419433023780584\n",
      "Loss on test= 0.005013478919863701\n",
      "acc for Lsat= 0.10569665803470546 \n",
      "acc for Psat= 0.10546409706067708 \n",
      "acc for optim= 0.12440425602512227\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.003259141929447651\n",
      "Loss on test= 0.005124850198626518\n",
      "acc for Lsat= 0.11450467377694117 \n",
      "acc for Psat= 0.10987935395031753 \n",
      "acc for optim= 0.12133429251197311\n"
     ]
    }
   ],
   "source": [
    "history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc1':[], 'test_acc2':[], \n",
    "          'test_acc3':[]}\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(df1)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    \n",
    "    X_train = df1.iloc[train_idx]\n",
    "    X_test = df1.iloc[val_idx]\n",
    "    y_train = df2.iloc[train_idx]\n",
    "    y_test = df2.iloc[val_idx]\n",
    "    \n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(X_train)\n",
    "\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "    scaler2 = MinMaxScaler()\n",
    "    scaler2.fit(y_train)\n",
    "\n",
    "    y_train = scaler2.transform(y_train)\n",
    "    y_test = scaler2.transform(y_test)\n",
    "    \n",
    "    \n",
    "    X_train = torch.Tensor(X_train) \n",
    "    y_train = torch.Tensor(y_train)\n",
    "\n",
    "    X_test = torch.Tensor(X_test)\n",
    "    y_test = torch.Tensor(y_test)\n",
    "\n",
    "    train_set = TensorDataset(X_train, y_train) \n",
    "    test_set = TensorDataset(X_test, y_test) \n",
    "\n",
    "\n",
    "    # Create Dataloader to read the data within batch sizes and put into memory. \n",
    "    train_loader = DataLoader(train_set, batch_size = 64, shuffle = True) \n",
    "    test_loader = DataLoader(test_set, batch_size = 20)\n",
    "\n",
    "    \n",
    "    model = Network(input_size,output_size).to(device) \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "    \n",
    "    lambda1 = lambda epoch: 0.998 ** epoch\n",
    "    scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1, last_epoch = -1)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_on_train = train_epoch(model, optimizer, criterion, train_loader)\n",
    "        train_loss = float(np.mean(loss_on_train))\n",
    "        _, loss_on_test = validate(model, criterion, test_loader)\n",
    "        test_loss = float(np.mean(loss_on_test))\n",
    "        train_acc = test(model, train_loader)\n",
    "        test_acc = test(model, test_loader)\n",
    "        scheduler.step()\n",
    "        \n",
    "        print(\"Epoch:{}/{}\".format(epoch + 1, num_epochs))\n",
    "        print('Loss on train=', train_loss)\n",
    "        print('Loss on test=', test_loss)\n",
    "        print('acc for Lsat=', test_acc[0],'\\n' 'acc for Psat=', test_acc[1], '\\n' 'acc for optim=', test_acc[2])\n",
    "        \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    #history['train_acc'].append(train_acc)\n",
    "    history['test_acc1'].append(test_acc[0])  \n",
    "    history['test_acc2'].append(test_acc[1])  \n",
    "    history['test_acc3'].append(test_acc[2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "1cd2aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of 5 fold cross validation\n",
      "Average Training Loss: 0.0033 \t Average Test Loss: 0.0054 \t Average Lsat Acc: 0.122 \t Average Psat Acc: 0.150 \t Average Loptim Acc: 0.142\n"
     ]
    }
   ],
   "source": [
    "avg_train_loss = np.mean(history['train_loss'])\n",
    "avg_test_loss = np.mean(history['test_loss'])\n",
    "avg_test_acc1 = np.mean(history['test_acc1'])\n",
    "avg_test_acc2 = np.mean(history['test_acc2'])\n",
    "avg_test_acc3 = np.mean(history['test_acc3'])\n",
    "\n",
    "print('Performance of {} fold cross validation'.format(k))\n",
    "print(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f} \\t Average Lsat Acc: {:.3f} \\t Average Psat Acc: {:.3f} \\t Average Loptim Acc: {:.3f}\".format(avg_train_loss,avg_test_loss,avg_test_acc1,avg_test_acc2,\n",
    "avg_test_acc3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6341f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
