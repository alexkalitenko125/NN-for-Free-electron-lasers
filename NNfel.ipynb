{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "1d4cf661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset \n",
    "import torch.nn.functional as F \n",
    "import numpy as np \n",
    "import torch.optim as optim \n",
    "from torch.optim import AdamW \n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import os    \n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "21fc117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Данные.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "a3c142df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>lu</th>\n",
       "      <th>P0</th>\n",
       "      <th>I</th>\n",
       "      <th>gamma</th>\n",
       "      <th>sgamma</th>\n",
       "      <th>r</th>\n",
       "      <th>Psat</th>\n",
       "      <th>Lsat</th>\n",
       "      <th>loptim</th>\n",
       "      <th>lres</th>\n",
       "      <th>loptim/lres</th>\n",
       "      <th>Psat/Pall</th>\n",
       "      <th>Lsat/lu</th>\n",
       "      <th>f</th>\n",
       "      <th>rho</th>\n",
       "      <th>P0/Pall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>12800000.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.430000e+08</td>\n",
       "      <td>18.5</td>\n",
       "      <td>2.261250e-08</td>\n",
       "      <td>2.257770e-08</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>0.00132</td>\n",
       "      <td>5.01</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.000965</td>\n",
       "      <td>1.180000e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>12800.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>9.800000e+07</td>\n",
       "      <td>16.7</td>\n",
       "      <td>1.585280e-07</td>\n",
       "      <td>1.580440e-07</td>\n",
       "      <td>0.003065</td>\n",
       "      <td>0.00240</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.002550</td>\n",
       "      <td>3.130000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.130000e+09</td>\n",
       "      <td>20.3</td>\n",
       "      <td>2.061380e-08</td>\n",
       "      <td>2.057220e-08</td>\n",
       "      <td>0.002024</td>\n",
       "      <td>0.00156</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>2.070000e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>1500000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.100000e+09</td>\n",
       "      <td>18.3</td>\n",
       "      <td>1.648760e-08</td>\n",
       "      <td>1.645770e-08</td>\n",
       "      <td>0.001814</td>\n",
       "      <td>0.00136</td>\n",
       "      <td>4.96</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.001510</td>\n",
       "      <td>1.850000e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>150000.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>1.180000e+09</td>\n",
       "      <td>19.4</td>\n",
       "      <td>2.356200e-08</td>\n",
       "      <td>2.351110e-08</td>\n",
       "      <td>0.002164</td>\n",
       "      <td>0.00175</td>\n",
       "      <td>5.25</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>2.210000e-07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k    lu          P0      I   gamma  sgamma       r          Psat  Lsat  \\\n",
       "0  3.89  3.69  12800000.0   80.0  2650.0     0.0  0.0001  1.430000e+08  18.5   \n",
       "1  3.89  3.69     12800.0   80.0  1000.0     0.0  0.0001  9.800000e+07  16.7   \n",
       "2  3.98  3.69    150000.0  500.0  2830.0     0.0  0.0001  1.130000e+09  20.3   \n",
       "3  3.98  3.69   1500000.0  500.0  3160.0     0.0  0.0001  1.100000e+09  18.3   \n",
       "4  3.98  3.69    150000.0  500.0  2650.0     0.0  0.0001  1.180000e+09  19.4   \n",
       "\n",
       "         loptim          lres  loptim/lres  Psat/Pall  Lsat/lu      f  \\\n",
       "0  2.261250e-08  2.257770e-08     0.001542    0.00132     5.01  0.736   \n",
       "1  1.585280e-07  1.580440e-07     0.003065    0.00240     4.52  0.736   \n",
       "2  2.061380e-08  2.057220e-08     0.002024    0.00156     5.49  0.735   \n",
       "3  1.648760e-08  1.645770e-08     0.001814    0.00136     4.96  0.735   \n",
       "4  2.356200e-08  2.351110e-08     0.002164    0.00175     5.25  0.735   \n",
       "\n",
       "        rho       P0/Pall  \n",
       "0  0.000965  1.180000e-04  \n",
       "1  0.002550  3.130000e-07  \n",
       "2  0.001690  2.070000e-07  \n",
       "3  0.001510  1.850000e-06  \n",
       "4  0.001800  2.210000e-07  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "140b811d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "52e1ec78",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "243cc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Psat/Pall']<0.008]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "2f6103f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['log'] = np.log(df[['Psat/Pall']])\n",
    "df['log0'] = np.log(df['P0']/df['I']/df['gamma']/511000)\n",
    "df['optim'] = df['loptim/lres']/df['Psat/Pall']\n",
    "df['Lsat/lu'] = np.log(df['Lsat/lu'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "ee8f0be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['optim']<2.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "294bf40c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9296040226272785"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)/l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "611d767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['optim'] = df['loptim/lres']/df['rho']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "cf41df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['optim'] = (df['optim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f418fb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.drop(columns=['P0', 'optim', 'P0/Pall', 'Psat', 'Lsat', 'loptim','lres', 'loptim/lres', 'Psat/Pall', 'Lsat/lu', 'f', 'rho', 'log'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "3642dca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>lu</th>\n",
       "      <th>I</th>\n",
       "      <th>gamma</th>\n",
       "      <th>sgamma</th>\n",
       "      <th>r</th>\n",
       "      <th>log0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>80.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-9.043511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.89</td>\n",
       "      <td>3.69</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-14.976706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2830.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-15.388374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3160.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-13.196085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.98</td>\n",
       "      <td>3.69</td>\n",
       "      <td>500.0</td>\n",
       "      <td>2650.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-15.322657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>2.91</td>\n",
       "      <td>3.37</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>2450.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-18.011076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1.77</td>\n",
       "      <td>3.37</td>\n",
       "      <td>50.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-15.531475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1.25</td>\n",
       "      <td>3.37</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>949.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-17.737771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>1.83</td>\n",
       "      <td>3.37</td>\n",
       "      <td>50.0</td>\n",
       "      <td>775.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-16.516077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>3.96</td>\n",
       "      <td>3.67</td>\n",
       "      <td>800.0</td>\n",
       "      <td>1410.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>-13.314812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1479 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         k    lu       I   gamma  sgamma       r       log0\n",
       "0     3.89  3.69    80.0  2650.0     0.0  0.0001  -9.043511\n",
       "1     3.89  3.69    80.0  1000.0     0.0  0.0001 -14.976706\n",
       "2     3.98  3.69   500.0  2830.0     0.0  0.0001 -15.388374\n",
       "3     3.98  3.69   500.0  3160.0     0.0  0.0001 -13.196085\n",
       "4     3.98  3.69   500.0  2650.0     0.0  0.0001 -15.322657\n",
       "...    ...   ...     ...     ...     ...     ...        ...\n",
       "1586  2.91  3.37  7000.0  2450.0     0.0  0.0005 -18.011076\n",
       "1587  1.77  3.37    50.0   283.0     0.0  0.0005 -15.531475\n",
       "1588  1.25  3.37  5000.0   949.0     0.0  0.0005 -17.737771\n",
       "1589  1.83  3.37    50.0   775.0     0.0  0.0005 -16.516077\n",
       "1590  3.96  3.67   800.0  1410.0     0.0  0.0005 -13.314812\n",
       "\n",
       "[1479 rows x 7 columns]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "17404835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(columns=[ 'k', 'lu', 'I', 'gamma', 'sgamma', 'r', 'log0', 'P0', 'P0/Pall', 'loptim','lres', 'loptim/lres', 'Psat/Pall', 'Lsat', 'f', 'rho', 'Psat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "01cfb8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lsat/lu</th>\n",
       "      <th>log</th>\n",
       "      <th>optim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.611436</td>\n",
       "      <td>-6.630124</td>\n",
       "      <td>1.598041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.508512</td>\n",
       "      <td>-6.032287</td>\n",
       "      <td>1.201894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.702928</td>\n",
       "      <td>-6.463069</td>\n",
       "      <td>1.197420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.601406</td>\n",
       "      <td>-6.600271</td>\n",
       "      <td>1.201364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.658228</td>\n",
       "      <td>-6.348139</td>\n",
       "      <td>1.202222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>1.996060</td>\n",
       "      <td>-7.132150</td>\n",
       "      <td>0.796190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>1.780024</td>\n",
       "      <td>-6.489045</td>\n",
       "      <td>1.199050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>1.652497</td>\n",
       "      <td>-6.676644</td>\n",
       "      <td>0.797769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>2.674149</td>\n",
       "      <td>-7.740165</td>\n",
       "      <td>0.800961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1590</th>\n",
       "      <td>1.644805</td>\n",
       "      <td>-6.849486</td>\n",
       "      <td>0.796284</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1479 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Lsat/lu       log     optim\n",
       "0     1.611436 -6.630124  1.598041\n",
       "1     1.508512 -6.032287  1.201894\n",
       "2     1.702928 -6.463069  1.197420\n",
       "3     1.601406 -6.600271  1.201364\n",
       "4     1.658228 -6.348139  1.202222\n",
       "...        ...       ...       ...\n",
       "1586  1.996060 -7.132150  0.796190\n",
       "1587  1.780024 -6.489045  1.199050\n",
       "1588  1.652497 -6.676644  0.797769\n",
       "1589  2.674149 -7.740165  0.800961\n",
       "1590  1.644805 -6.849486  0.796284\n",
       "\n",
       "[1479 rows x 3 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "2a77acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df1, df2, test_size=0.1, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "515fa4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_val = scaler.transform(X_val)\n",
    "\n",
    "scaler2 = MinMaxScaler()\n",
    "scaler2.fit(y_train)\n",
    "\n",
    "y_train = scaler2.transform(y_train)\n",
    "y_test = scaler2.transform(y_test)\n",
    "y_val = scaler2.transform(y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "dcc3a304",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = torch.Tensor(X_train) \n",
    "y_train = torch.Tensor(y_train)\n",
    "X_val = torch.Tensor(X_val)\n",
    "y_val = torch.Tensor(y_val)\n",
    "X_test = torch.Tensor(X_test)\n",
    "y_test = torch.Tensor(y_test)\n",
    "\n",
    "train_set = TensorDataset(X_train, y_train) \n",
    "validate_set = TensorDataset(X_val, y_val) \n",
    "test_set = TensorDataset(X_test, y_test) \n",
    "\n",
    "\n",
    "# Create Dataloader to read the data within batch sizes and put into memory. \n",
    "train_loader = DataLoader(train_set, batch_size = 64, shuffle = True) \n",
    "validate_loader = DataLoader(validate_set, batch_size = 20) \n",
    "test_loader = DataLoader(test_set, batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "541c3e38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.33110368, 0.55518395, 0.6226415 , 0.0677541 , 0.        ,\n",
       "        0.13043478, 0.83860534],\n",
       "       [0.9397993 , 0.85953176, 1.        , 0.31383172, 0.        ,\n",
       "        0.42028984, 0.545985  ],\n",
       "       [0.5618729 , 0.27090302, 0.09433962, 0.1703784 , 0.        ,\n",
       "        0.2753623 , 0.32036537],\n",
       "       [0.5250836 , 0.93645483, 0.08176101, 0.31383172, 0.        ,\n",
       "        0.13043478, 0.5225734 ],\n",
       "       [0.9799331 , 0.2173913 , 0.8742138 , 0.77428675, 0.        ,\n",
       "        0.13043478, 0.6709657 ],\n",
       "       [0.06688963, 0.90301   , 0.05660377, 0.0677541 , 0.        ,\n",
       "        0.5652174 , 0.33718285],\n",
       "       [0.20735785, 0.74916387, 0.08176101, 0.2807271 , 0.1       ,\n",
       "        0.02898551, 0.74127436],\n",
       "       [0.03344481, 0.46488294, 0.09433962, 0.09203082, 0.        ,\n",
       "        0.11594203, 0.37697557],\n",
       "       [0.04682274, 0.5652174 , 0.6226415 , 0.26267004, 1.        ,\n",
       "        0.2753623 , 0.67089766],\n",
       "       [0.8896321 , 0.3645485 , 0.00377358, 0.01420539, 0.2       ,\n",
       "        0.42028984, 0.8028687 ],\n",
       "       [0.48160535, 0.23411371, 0.8742138 , 0.22114582, 0.2       ,\n",
       "        0.5652174 , 0.4925781 ],\n",
       "       [0.01337793, 0.15384616, 0.06918239, 0.02853015, 1.        ,\n",
       "        0.2753623 , 0.5652946 ],\n",
       "       [0.7993311 , 0.9632107 , 0.7484277 , 0.63083345, 0.1       ,\n",
       "        0.13043478, 0.53969634],\n",
       "       [0.02006689, 0.67558527, 0.8742138 , 0.1703784 , 0.1       ,\n",
       "        0.20289855, 0.37045807],\n",
       "       [0.5852843 , 0.84615386, 0.6226415 , 0.31383172, 0.5       ,\n",
       "        0.05797102, 0.789353  ],\n",
       "       [0.61204016, 0.46153846, 1.        , 0.09203082, 0.1       ,\n",
       "        0.13043478, 0.480574  ],\n",
       "       [0.30769232, 0.8929766 , 0.08176101, 0.02692508, 0.2       ,\n",
       "        0.71014494, 0.7855168 ],\n",
       "       [0.9130435 , 0.93645483, 0.00251572, 0.01418482, 0.5       ,\n",
       "        1.        , 0.607387  ],\n",
       "       [0.819398  , 0.632107  , 0.00251572, 0.2807271 , 0.2       ,\n",
       "        0.10144927, 0.663703  ],\n",
       "       [0.6923077 , 0.9866221 , 0.00377358, 0.19746399, 0.        ,\n",
       "        0.10144927, 0.8846735 ],\n",
       "       [0.03010033, 0.8695652 , 0.        , 0.06023033, 0.        ,\n",
       "        0.08695652, 0.19038974],\n",
       "       [0.6086956 , 0.4916388 , 0.08176101, 0.8364833 , 0.1       ,\n",
       "        0.02898551, 0.31134954],\n",
       "       [0.44147158, 0.451505  , 0.6226415 , 0.08651339, 0.        ,\n",
       "        0.85507244, 0.5485034 ],\n",
       "       [0.9632107 , 0.19063546, 0.06918239, 0.54656714, 0.        ,\n",
       "        0.05797102, 0.30662882],\n",
       "       [0.23076923, 0.5852843 , 0.7484277 , 0.31383172, 0.        ,\n",
       "        0.01449275, 0.62350464],\n",
       "       [0.32441473, 0.69899666, 0.00377358, 0.31383172, 0.        ,\n",
       "        0.01449275, 0.7049925 ],\n",
       "       [0.5719063 , 0.8695652 , 0.        , 0.06023033, 0.1       ,\n",
       "        0.13043478, 0.7593999 ],\n",
       "       [0.77257526, 0.48160535, 0.00125786, 0.08651339, 0.        ,\n",
       "        0.5652174 , 0.47493732],\n",
       "       [0.04347826, 0.54180604, 0.6226415 , 0.8364833 , 0.1       ,\n",
       "        0.07246377, 0.46197835],\n",
       "       [0.4381271 , 0.7826087 , 0.08176101, 0.31383172, 0.1       ,\n",
       "        0.10144927, 0.3416948 ],\n",
       "       [0.8896321 , 0.3645485 , 0.00377358, 0.02520395, 0.2       ,\n",
       "        0.42028984, 0.58453107],\n",
       "       [0.5284281 , 0.9866221 , 1.        , 0.24260664, 0.1       ,\n",
       "        0.2753623 , 0.5718741 ],\n",
       "       [0.28093645, 0.4214047 , 0.05660377, 0.00460455, 0.5       ,\n",
       "        1.        , 0.83742505],\n",
       "       [0.9632107 , 0.72240806, 0.00377358, 0.31383172, 0.        ,\n",
       "        0.10144927, 0.8495007 ],\n",
       "       [0.9230769 , 0.9832776 , 0.09433962, 0.63129085, 0.        ,\n",
       "        0.10144927, 0.6849984 ],\n",
       "       [0.8762542 , 0.9230769 , 0.6226415 , 0.1703784 , 1.        ,\n",
       "        0.71014494, 0.37427214],\n",
       "       [0.07023411, 0.29765886, 0.05660377, 0.24260664, 0.        ,\n",
       "        0.13043478, 0.45782444],\n",
       "       [0.458194  , 0.8762542 , 0.6226415 , 0.8364833 , 0.        ,\n",
       "        0.13043478, 0.4906088 ],\n",
       "       [0.01337793, 0.46488294, 0.6226415 , 0.22154006, 0.        ,\n",
       "        0.11594203, 0.53481704],\n",
       "       [0.84615386, 0.6555184 , 0.8742138 , 0.09714699, 1.        ,\n",
       "        0.20289855, 0.47468838],\n",
       "       [0.4147157 , 0.4715719 , 0.6226415 , 0.13827695, 0.1       ,\n",
       "        0.71014494, 0.5219541 ],\n",
       "       [0.1638796 , 0.75250834, 0.6226415 , 0.63083345, 0.        ,\n",
       "        0.05797102, 0.51890767],\n",
       "       [0.13712375, 0.5150502 , 1.        , 0.8364833 , 0.        ,\n",
       "        0.07246377, 0.3040431 ],\n",
       "       [0.4916388 , 0.34448162, 0.8742138 , 0.445247  , 0.        ,\n",
       "        0.42028984, 0.6435468 ],\n",
       "       [0.9866221 , 0.44481605, 0.7484277 , 0.54656714, 0.        ,\n",
       "        0.42028984, 0.47511965],\n",
       "       [0.96989965, 0.03010033, 0.7484277 , 0.54656714, 0.2       ,\n",
       "        0.20289855, 0.4706831 ],\n",
       "       [0.451505  , 0.01003344, 0.7484277 , 0.54656714, 0.1       ,\n",
       "        0.        , 0.76267797],\n",
       "       [0.48160535, 0.909699  , 0.        , 0.26267004, 0.1       ,\n",
       "        0.04347826, 0.69128126],\n",
       "       [0.12374582, 0.6020067 , 1.        , 0.24260664, 0.1       ,\n",
       "        0.10144927, 0.3886608 ],\n",
       "       [0.6220736 , 0.85953176, 0.7484277 , 0.297781  , 0.        ,\n",
       "        0.07246377, 0.6114423 ],\n",
       "       [0.03344481, 0.8662207 , 0.00125786, 0.06023033, 0.        ,\n",
       "        0.2753623 , 0.680713  ],\n",
       "       [0.14046822, 0.19063546, 1.        , 0.01418482, 0.5       ,\n",
       "        0.5652174 , 0.6636834 ],\n",
       "       [0.78595316, 0.8929766 , 0.09433962, 0.09714699, 0.2       ,\n",
       "        0.71014494, 0.36395207],\n",
       "       [0.14381272, 0.9632107 , 0.6226415 , 0.19746399, 0.1       ,\n",
       "        0.11594203, 0.40550315],\n",
       "       [0.19063546, 0.5518395 , 0.00251572, 0.22154006, 0.        ,\n",
       "        0.08695652, 0.2833716 ],\n",
       "       [0.09698997, 0.06020067, 0.09433962, 0.02853015, 0.1       ,\n",
       "        0.05797102, 0.46512166],\n",
       "       [0.76254183, 0.9799331 , 0.05660377, 0.54656714, 0.        ,\n",
       "        0.07246377, 0.33172613],\n",
       "       [0.8862876 , 0.29431438, 0.8742138 , 0.09203082, 0.        ,\n",
       "        0.11594203, 0.8434753 ],\n",
       "       [0.6956522 , 0.44147158, 0.00251572, 0.01689338, 0.1       ,\n",
       "        0.71014494, 0.39792898],\n",
       "       [0.36789298, 0.15719064, 0.05660377, 0.24260664, 0.        ,\n",
       "        0.11594203, 0.29890132],\n",
       "       [0.6555184 , 0.5451505 , 0.00377358, 0.1703784 , 0.        ,\n",
       "        0.11594203, 0.32660115],\n",
       "       [0.4949833 , 0.8160535 , 0.        , 0.31383172, 0.        ,\n",
       "        0.01449275, 0.71022266],\n",
       "       [0.02006689, 0.9632107 , 0.7484277 , 0.09203082, 0.        ,\n",
       "        0.2753623 , 0.77130455],\n",
       "       [0.16722408, 0.26755852, 0.8742138 , 0.24260664, 0.5       ,\n",
       "        0.02898551, 0.7779523 ]], dtype=float32)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_array = next(iter(train_loader))[0].numpy()\n",
    "train_dataset_array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "db94f3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters \n",
    "input_size = list(X_train.shape)[1]   \n",
    "output_size = list(y_train.shape)[1]  \n",
    "\n",
    "\n",
    "\n",
    "# Define neural network \n",
    "class Network(nn.Module): \n",
    "    def __init__(self, input_size, output_size, init_form=\"normal\"): \n",
    "        super().__init__() \n",
    "        self.conv_stack = nn.Sequential(\n",
    "        nn.Linear(input_size, 50), \n",
    "        nn.Tanh(),\n",
    "        nn.Linear(50, 50),\n",
    "        nn.Tanh(), \n",
    "        nn.Linear(50, 30),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(30, 30),\n",
    "        nn.Dropout(p=0.1),\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(30, output_size) )\n",
    "        self.init_form = init_form\n",
    "        if self.init_form is not None:\n",
    "            self.init()\n",
    "\n",
    "    def forward(self, x): \n",
    "        return self.conv_stack(x)\n",
    "    \n",
    "        # xavier weight initialization\n",
    "    def init(self):\n",
    "        sigmoid_gain = torch.nn.init.calculate_gain(\"tanh\")\n",
    "        for child in self.conv_stack.children():\n",
    "            if isinstance(child, nn.Linear):\n",
    "                if self.init_form == \"normal\":\n",
    "                    torch.nn.init.xavier_normal_(child.weight,\n",
    "                                                 gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                elif self.init_form == \"uniform\":\n",
    "                    torch.nn.init.xavier_uniform_(child.weight,\n",
    "                                                  gain=sigmoid_gain)\n",
    "                    if child.bias is not None:\n",
    "                        torch.nn.init.zeros_(child.bias)\n",
    "                else:\n",
    "                    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a50d04b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def train_epoch(model,\n",
    "                optimizer,\n",
    "                criterion,\n",
    "                train_loader):\n",
    "    loss_history = []\n",
    "    for batch in train_loader: \n",
    "        optimizer.zero_grad()\n",
    "        x_train, y_train = batch # parse data\n",
    "        x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "        y_pred = model(x_train) # get predictions\n",
    "        loss = criterion(y_pred, y_train) # compute loss\n",
    "        loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return loss_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8a6c7ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model,\n",
    "             criterion,\n",
    "             val_loader):\n",
    "    cumloss = 0\n",
    "    loss_history = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_train, y_train = batch # parse data\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "            y_pred = model(x_train) # get predictions\n",
    "            loss = criterion(y_pred, y_train) # compute loss\n",
    "            loss_history.append(loss.cpu().detach().numpy()) # write loss to log\n",
    "            cumloss += loss\n",
    "    return cumloss / len(val_loader), loss_history # mean loss and history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "f3fed850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train_model(model, optimizer, model_name=None, n_epochs=5):\n",
    "  \n",
    "    criterion = nn.MSELoss().to(device)\n",
    "\n",
    "    train_history = {}\n",
    "    train_history['model_name'] = model_name\n",
    "    train_history['loss_on_train'] = []\n",
    "    train_history['loss_on_test'] = []\n",
    "\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        loss_on_train = train_epoch(model,\n",
    "                                    optimizer,\n",
    "                                    criterion,\n",
    "                                    train_loader)\n",
    "        _, loss_on_test = validate(model,\n",
    "                                   criterion,\n",
    "                                   validate_loader)\n",
    "        train_history['loss_on_train'].append(np.mean(loss_on_train))\n",
    "        train_history['loss_on_test'].append(np.mean(loss_on_test))\n",
    "        scheduler.step()\n",
    "    return train_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a2e8bae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_smoothing(scalars, weight):  \n",
    "    last = scalars[0]  \n",
    "    smoothed = []\n",
    "    for point in scalars:\n",
    "        smoothed_val = last * weight + (1 - weight) * point  \n",
    "        smoothed.append(smoothed_val)                        \n",
    "        last = smoothed_val                                 \n",
    "\n",
    "    return smoothed\n",
    "\n",
    "\n",
    "def plot_history(history, n_epochs=5, smooth_val=0.9):\n",
    "    fig, ax =  plt.subplots(3, 1, figsize=(12, 14))\n",
    "    for stage_idx, (stage_lbl, stage_title) in enumerate(\n",
    "        zip(['loss_on_train', 'loss_on_test'],\n",
    "            ['train loss', 'test loss'])):\n",
    "        # plot history on each learning step\n",
    "        epoch_len = len(history[stage_lbl])//n_epochs\n",
    "        full_stage_len = len(history[stage_lbl])\n",
    "        ax[stage_idx].plot(exponential_smoothing(history[stage_lbl], smooth_val),\n",
    "                           label='smoothed',\n",
    "                           color='m')\n",
    "        ax[stage_idx].plot(history[stage_lbl],\n",
    "                           label='raw',\n",
    "                           alpha=0.2,\n",
    "                           color='c')\n",
    "        ax[stage_idx].set_title(stage_title)\n",
    "        ax[stage_idx].set_xlabel('epochs')\n",
    "        ax[stage_idx].set_ylabel('loss')\n",
    "        epochs_ticks_positions = np.arange(stop=full_stage_len+1,\n",
    "                                           step=epoch_len)\n",
    "        ax[stage_idx].set_xticks(epochs_ticks_positions)\n",
    "        ax[stage_idx].set_xticklabels(np.arange(n_epochs+1))\n",
    "        ax[stage_idx].legend()\n",
    "\n",
    "        # plot mean train and test loss combined\n",
    "        mean_loss_on_epoch = [np.mean(history[stage_lbl][i:i+epoch_len]) \\\n",
    "                              for i in range(0, full_stage_len, epoch_len)]\n",
    "        std_loss_on_epoch = [np.std(history[stage_lbl][i:i+epoch_len]) \\\n",
    "                              for i in range(0, full_stage_len, epoch_len)]\n",
    "\n",
    "        ax[2].set_title('\\nAverage loss per epoch')\n",
    "        ax[2].errorbar(np.arange(n_epochs) + stage_idx / 30.,\n",
    "                       mean_loss_on_epoch,\n",
    "                       yerr=std_loss_on_epoch,\n",
    "                       capsize=5,\n",
    "                       fmt=\"X--\",\n",
    "                       label=stage_title)\n",
    "        ax[2].set_xticks(np.arange(5))\n",
    "        ax[2].set_xticklabels(np.arange(5))\n",
    "        ax[2].set_xlabel('epochs')\n",
    "        ax[2].set_ylabel('loss')\n",
    "        ax[2].legend()\n",
    "\n",
    "    fig.suptitle(history['model_name'], fontsize=24)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "f030e212",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:37<00:00, 26.78it/s]\n"
     ]
    }
   ],
   "source": [
    "def set_random_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "set_random_seed(42)\n",
    "\n",
    "model = Network(input_size,output_size).to(device) \n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.01)\n",
    "\n",
    "lambda1 = lambda epoch: 0.99 ** epoch\n",
    "scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda1, last_epoch = -1)\n",
    "\n",
    "n_epochs = 1000\n",
    "history = train_model(model, optimizer, model_name='model', n_epochs=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "6971052a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x1008 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_history(history, n_epochs=n_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "fc83567c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x231eacbe3d0>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(1,n_epochs+1), (history['loss_on_train']), label='train')\n",
    "plt.plot(range(1,n_epochs+1), (history['loss_on_test']), label='test')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6986b941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv_stack): Sequential(\n",
       "    (0): Linear(in_features=7, out_features=50, bias=True)\n",
       "    (1): Tanh()\n",
       "    (2): Linear(in_features=50, out_features=50, bias=True)\n",
       "    (3): Tanh()\n",
       "    (4): Linear(in_features=50, out_features=30, bias=True)\n",
       "    (5): Dropout(p=0.1, inplace=False)\n",
       "    (6): Tanh()\n",
       "    (7): Linear(in_features=30, out_features=30, bias=True)\n",
       "    (8): Dropout(p=0.1, inplace=False)\n",
       "    (9): Tanh()\n",
       "    (10): Linear(in_features=30, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c7685f5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc for Lsat= 0.07444017437425114 \n",
      "acc for Psat= 0.1344079938905968 \n",
      "acc for optim= 0.18338023010000068\n"
     ]
    }
   ],
   "source": [
    "def relative_root_mean_squared_error(true, pred):\n",
    "    num = np.sum(np.square(true - pred))\n",
    "    den = np.sum(np.square(true))\n",
    "    squared_error = num/den\n",
    "    rrmse_loss = np.sqrt(squared_error)\n",
    "    return rrmse_loss\n",
    "\n",
    "\n",
    "def test(model, val_loader):\n",
    "    cumloss1 = 0\n",
    "    cumloss2 = 0\n",
    "    cumloss3 = 0\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    l3 = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            x_train, y_train = batch # parse data\n",
    "            x_train, y_train = x_train.to(device), y_train.to(device) # compute on gpu\n",
    "            y_pred = model(x_train) # get predictions\n",
    "            y_pred = scaler2.inverse_transform(y_pred.cpu().detach().numpy())\n",
    "            y_train = scaler2.inverse_transform(y_train.cpu().detach().numpy())\n",
    "            loss1 = relative_root_mean_squared_error(np.exp(y_pred[0][0]), \n",
    "                                                    np.exp(y_train[0][0])) # compute loss\n",
    "            loss2 = relative_root_mean_squared_error(np.exp(y_pred[0][1]), \n",
    "                                                    np.exp(y_train[0][1]))\n",
    "            loss3 = relative_root_mean_squared_error((y_pred[0][2]), \n",
    "                                                    (y_train[0][2]))\n",
    "            cumloss1 += loss1\n",
    "            cumloss2 += loss2\n",
    "            cumloss3 += loss3\n",
    "            l1.append(loss1)\n",
    "            l2.append(loss2)\n",
    "            l3.append(loss3)\n",
    "    return cumloss1 / len(val_loader), cumloss2 / len(val_loader), cumloss3 / len(val_loader), l1, l2, l3\n",
    "\n",
    "\n",
    "l = test(model, test_loader)\n",
    "print('acc for Lsat=', l[0],'\\n' 'acc for Psat=', l[1], '\\n' 'acc for optim=', l[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "39faae6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Lsat error')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(l[3])\n",
    "plt.title(\"Lsat error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "fe589d0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Power error')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(l[4])\n",
    "plt.title(\"Power error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4214a0dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "122    0.001776\n",
       "67     0.002290\n",
       "35     0.002593\n",
       "110    0.003047\n",
       "141    0.005712\n",
       "         ...   \n",
       "19     0.384689\n",
       "2      0.431483\n",
       "33     0.463424\n",
       "104    0.495667\n",
       "24     0.553373\n",
       "Length: 148, dtype: float32"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(l[4]).sort_values()\n",
    "#scaler.inverse_transform(np.array([X_test[103].cpu().detach().numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c55302e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'optim error')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(l[5])\n",
    "plt.title(\"optim error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "6404a9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import jv\n",
    "\n",
    "X = pd.DataFrame({'k':[2.13], 'lu':[2.8], 'I':[53], 'gamma':[300], 'sgamma':[0.0002], \n",
    "                  'r':[0.00012], 'log0':[10]})\n",
    "\n",
    "ksi = X['k']**2/(1+X['k']**2/2)/4\n",
    "f = jv(0,ksi)-jv(1,ksi)\n",
    "\n",
    "rho = 1/2/(X['gamma'])*(X['I']/X['r']**2/np.pi/4/np.pi/17000*(X['lu']/100*X['k']*f)**2)**(1/3)\n",
    "X['log0'] = np.log(X['log0']/X['I']/X['gamma']/511000)\n",
    "\n",
    "\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "f47cf5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = torch.Tensor(X) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "fba5bf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.6093262, -5.9498634,  0.9480156]], dtype=float32)"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = model(input1.to(device)).cpu().detach().numpy()\n",
    "a= scaler2.inverse_transform(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "64901883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lsat= 13.998437881469727 Psat= 21175086.445198394 loptim= 5.102878910083144e-07\n"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame({'k':[2.13], 'lu':[2.8], 'I':[53], 'gamma':[300], 'sgamma':[0.0002], \n",
    "                  'r':[0.00012], 'log0':[2000]})\n",
    "\n",
    "ksi = X['k']**2/(1+X['k']**2/2)/4\n",
    "f = jv(0,ksi)-jv(1,ksi)\n",
    "\n",
    "rho = 1/2/(X['gamma'])*(X['I']/X['r']**2/np.pi/4/np.pi/17000*(X['lu']/100*X['k']*f)**2)**(1/3)\n",
    "X['log0'] = np.log(X['log0']/X['I']/X['gamma']/511000)\n",
    "\n",
    "print('Lsat=', np.exp(a[0][0])*X['lu'][0], 'Psat=', (np.exp(a[0][1])*X['gamma']*511000*X['I'])[0], \n",
    "'loptim=',(((a[0][2])*rho+1)*X['lu']/100/2/X['gamma']/X['gamma']*(1+X['k']*X['k']/2))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "9992987d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1479"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c36cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset, random_split, SubsetRandomSampler, ConcatDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "0a148458",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ConcatDataset([train_set, validate_set, test_set])\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "set_random_seed(42)\n",
    "\n",
    "num_epochs=1000\n",
    "batch_size=64\n",
    "k=5\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "foldperf={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a1a8b1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.9075688719749451\n",
      "Loss on test= 0.5354357361793518\n",
      "acc for Lsat= 12.675286777732843 \n",
      "acc for Psat= 15.028976193764105 \n",
      "acc for optim= 1.767096430582397\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.4660698175430298\n",
      "Loss on test= 0.40753287076950073\n",
      "acc for Lsat= 3.4897319687172206 \n",
      "acc for Psat= 25.57257642223684 \n",
      "acc for optim= 7.5673507890120115\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.39954495429992676\n",
      "Loss on test= 0.42483633756637573\n",
      "acc for Lsat= 3.5954389084347627 \n",
      "acc for Psat= 29.07677797697692 \n",
      "acc for optim= 3.8742001732005864\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.3521634340286255\n",
      "Loss on test= 0.34133070707321167\n",
      "acc for Lsat= 3.9502644785695606 \n",
      "acc for Psat= 10.036501438212596 \n",
      "acc for optim= 3.31379267357359\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.3161024749279022\n",
      "Loss on test= 0.3092920482158661\n",
      "acc for Lsat= 1.8272392559352935 \n",
      "acc for Psat= 9.649961680325784 \n",
      "acc for optim= 1.9633544147127886\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.29110974073410034\n",
      "Loss on test= 0.2933821678161621\n",
      "acc for Lsat= 2.9710332493272587 \n",
      "acc for Psat= 9.431408232744985 \n",
      "acc for optim= 3.123505476226627\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.25052395462989807\n",
      "Loss on test= 0.23818916082382202\n",
      "acc for Lsat= 1.7055792173550062 \n",
      "acc for Psat= 7.711911868775968 \n",
      "acc for optim= 3.0129600999628297\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.2212458699941635\n",
      "Loss on test= 0.21502897143363953\n",
      "acc for Lsat= 1.7907288330512725 \n",
      "acc for Psat= 6.303099315162005 \n",
      "acc for optim= 2.0075357435538583\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.20448775589466095\n",
      "Loss on test= 0.19400441646575928\n",
      "acc for Lsat= 1.9542530396759723 \n",
      "acc for Psat= 3.854306734600057 \n",
      "acc for optim= 3.9706120601603585\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.17358005046844482\n",
      "Loss on test= 0.17269977927207947\n",
      "acc for Lsat= 1.6944763999718644 \n",
      "acc for Psat= 4.619208532868495 \n",
      "acc for optim= 2.594733333298496\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.1555965393781662\n",
      "Loss on test= 0.15642282366752625\n",
      "acc for Lsat= 1.4106185859575793 \n",
      "acc for Psat= 1.5706863683834043 \n",
      "acc for optim= 1.4649358737165745\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.13926319777965546\n",
      "Loss on test= 0.12779885530471802\n",
      "acc for Lsat= 1.305548708974006 \n",
      "acc for Psat= 2.007388376177767 \n",
      "acc for optim= 1.2415205293187141\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.12717323005199432\n",
      "Loss on test= 0.12289843708276749\n",
      "acc for Lsat= 1.0655390097967323 \n",
      "acc for Psat= 1.9802862303793616 \n",
      "acc for optim= 2.914886935651019\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.1127258762717247\n",
      "Loss on test= 0.09831874072551727\n",
      "acc for Lsat= 1.0626813532486463 \n",
      "acc for Psat= 1.5929439261577696 \n",
      "acc for optim= 3.6655877126802414\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.09694778174161911\n",
      "Loss on test= 0.09856890887022018\n",
      "acc for Lsat= 0.8812688304484205 \n",
      "acc for Psat= 1.7207388659916358 \n",
      "acc for optim= 4.631621664061567\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.08960578590631485\n",
      "Loss on test= 0.07609665393829346\n",
      "acc for Lsat= 0.8491139789363621 \n",
      "acc for Psat= 1.9961778307805542 \n",
      "acc for optim= 0.9492907485267071\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.07690221816301346\n",
      "Loss on test= 0.07260310649871826\n",
      "acc for Lsat= 0.9978362575127756 \n",
      "acc for Psat= 1.0253764402404084 \n",
      "acc for optim= 1.985739851774761\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.07050136476755142\n",
      "Loss on test= 0.059719596058130264\n",
      "acc for Lsat= 0.7462954037434207 \n",
      "acc for Psat= 1.0587055253433661 \n",
      "acc for optim= 1.5094919979035055\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.06461560726165771\n",
      "Loss on test= 0.06370281428098679\n",
      "acc for Lsat= 0.7446281614955641 \n",
      "acc for Psat= 1.1569847198080498 \n",
      "acc for optim= 1.320422124885718\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.0568493977189064\n",
      "Loss on test= 0.0568515807390213\n",
      "acc for Lsat= 0.6587965016196659 \n",
      "acc for Psat= 1.0137888547914051 \n",
      "acc for optim= 0.8204823216309141\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.05391601473093033\n",
      "Loss on test= 0.05124719813466072\n",
      "acc for Lsat= 0.7460524118460189 \n",
      "acc for Psat= 0.8045259390979678 \n",
      "acc for optim= 0.6455558210696295\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.05230461433529854\n",
      "Loss on test= 0.05228009074926376\n",
      "acc for Lsat= 0.7382239756446546 \n",
      "acc for Psat= 1.2008291545317735 \n",
      "acc for optim= 1.2562819623846146\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.048627641052007675\n",
      "Loss on test= 0.04515969380736351\n",
      "acc for Lsat= 0.6111085915283577 \n",
      "acc for Psat= 0.7499978286780518 \n",
      "acc for optim= 1.1671451404509827\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.04313390329480171\n",
      "Loss on test= 0.04424489289522171\n",
      "acc for Lsat= 0.631022087926819 \n",
      "acc for Psat= 0.8662417886717358 \n",
      "acc for optim= 0.909916879576977\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.04283700883388519\n",
      "Loss on test= 0.04009478539228439\n",
      "acc for Lsat= 0.6467520643247455 \n",
      "acc for Psat= 0.7525169041198365 \n",
      "acc for optim= 2.001360993804131\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.04263066500425339\n",
      "Loss on test= 0.039912931621074677\n",
      "acc for Lsat= 0.5921100262384169 \n",
      "acc for Psat= 0.7204223115331843 \n",
      "acc for optim= 0.40496381902375034\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.037558380514383316\n",
      "Loss on test= 0.03700336068868637\n",
      "acc for Lsat= 0.5929903087530259 \n",
      "acc for Psat= 0.7875648699905345 \n",
      "acc for optim= 0.4827788913307076\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.03617619723081589\n",
      "Loss on test= 0.03374410420656204\n",
      "acc for Lsat= 0.48559573749898355 \n",
      "acc for Psat= 0.8060917631845694 \n",
      "acc for optim= 0.3661537430669194\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.03644026815891266\n",
      "Loss on test= 0.03276418522000313\n",
      "acc for Lsat= 0.5825625998833267 \n",
      "acc for Psat= 0.6858704951088372 \n",
      "acc for optim= 0.5571189415983295\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.03650141507387161\n",
      "Loss on test= 0.030559929087758064\n",
      "acc for Lsat= 0.5313716320607282 \n",
      "acc for Psat= 0.7352326505865061 \n",
      "acc for optim= 0.3560915183908848\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.032590631395578384\n",
      "Loss on test= 0.031459711492061615\n",
      "acc for Lsat= 0.5146959569679599 \n",
      "acc for Psat= 0.7360537557625149 \n",
      "acc for optim= 0.41084726764883445\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.03130752593278885\n",
      "Loss on test= 0.03540431335568428\n",
      "acc for Lsat= 0.5552003451283216 \n",
      "acc for Psat= 0.9386291572717145 \n",
      "acc for optim= 0.43086238546852285\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.03079604171216488\n",
      "Loss on test= 0.027853550389409065\n",
      "acc for Lsat= 0.4880500857142505 \n",
      "acc for Psat= 0.6666692709560094 \n",
      "acc for optim= 0.741305188662876\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.03030174970626831\n",
      "Loss on test= 0.029299503192305565\n",
      "acc for Lsat= 0.5792748041331416 \n",
      "acc for Psat= 0.6899335713423096 \n",
      "acc for optim= 0.341303077443012\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.02918311208486557\n",
      "Loss on test= 0.029692810028791428\n",
      "acc for Lsat= 0.4753664686018916 \n",
      "acc for Psat= 0.7087037181915327 \n",
      "acc for optim= 0.39014605607809316\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.028553351759910583\n",
      "Loss on test= 0.029422203078866005\n",
      "acc for Lsat= 0.47268275917362973 \n",
      "acc for Psat= 0.5863155554508086 \n",
      "acc for optim= 0.4060198552251677\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.027809197083115578\n",
      "Loss on test= 0.028141789138317108\n",
      "acc for Lsat= 0.5173087425614908 \n",
      "acc for Psat= 0.6367463773018932 \n",
      "acc for optim= 0.2723043650143203\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.028361087664961815\n",
      "Loss on test= 0.029597578570246696\n",
      "acc for Lsat= 0.540966331378464 \n",
      "acc for Psat= 0.6361251224416019 \n",
      "acc for optim= 0.4140488511435939\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.025912834331393242\n",
      "Loss on test= 0.026198571547865868\n",
      "acc for Lsat= 0.46742885707990844 \n",
      "acc for Psat= 0.5959307021489745 \n",
      "acc for optim= 0.29246677564377616\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.026880258694291115\n",
      "Loss on test= 0.02690131589770317\n",
      "acc for Lsat= 0.5060303434639118 \n",
      "acc for Psat= 0.6602161196406579 \n",
      "acc for optim= 0.3084273903736962\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.026630615815520287\n",
      "Loss on test= 0.02468767762184143\n",
      "acc for Lsat= 0.505028080423103 \n",
      "acc for Psat= 0.6379188643453794 \n",
      "acc for optim= 0.2544926916100824\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.02630561590194702\n",
      "Loss on test= 0.026464439928531647\n",
      "acc for Lsat= 0.5013163619257063 \n",
      "acc for Psat= 0.5658185112249182 \n",
      "acc for optim= 0.27076071132457424\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.025607315823435783\n",
      "Loss on test= 0.02818906307220459\n",
      "acc for Lsat= 0.4600461716842334 \n",
      "acc for Psat= 0.5495280230652252 \n",
      "acc for optim= 0.243603512721067\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.02468363754451275\n",
      "Loss on test= 0.026369426399469376\n",
      "acc for Lsat= 0.49026244759679194 \n",
      "acc for Psat= 0.49050614513052515 \n",
      "acc for optim= 0.26034383572137765\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.024867745116353035\n",
      "Loss on test= 0.025690197944641113\n",
      "acc for Lsat= 0.49813560357418013 \n",
      "acc for Psat= 0.5258232392339237 \n",
      "acc for optim= 0.2627796170252967\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.02395710162818432\n",
      "Loss on test= 0.023253129795193672\n",
      "acc for Lsat= 0.4434567173845386 \n",
      "acc for Psat= 0.5989565157624138 \n",
      "acc for optim= 0.6807525137317104\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.024512872099876404\n",
      "Loss on test= 0.023455362766981125\n",
      "acc for Lsat= 0.5069134098486596 \n",
      "acc for Psat= 0.6707920369800696 \n",
      "acc for optim= 0.35658235857389065\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.024787375703454018\n",
      "Loss on test= 0.024720177054405212\n",
      "acc for Lsat= 0.4310621658567814 \n",
      "acc for Psat= 0.6585029936883271 \n",
      "acc for optim= 0.2654860012411813\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.023713676258921623\n",
      "Loss on test= 0.023795241490006447\n",
      "acc for Lsat= 0.48460797700288427 \n",
      "acc for Psat= 0.5517151673547405 \n",
      "acc for optim= 0.25362493884353177\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.022539054974913597\n",
      "Loss on test= 0.022441498935222626\n",
      "acc for Lsat= 0.46584318241976025 \n",
      "acc for Psat= 0.5066276725595565 \n",
      "acc for optim= 0.26180330496080806\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.0232620257884264\n",
      "Loss on test= 0.023315757513046265\n",
      "acc for Lsat= 0.41989037369746035 \n",
      "acc for Psat= 0.5194465048564755 \n",
      "acc for optim= 0.2779121391567232\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.022798703983426094\n",
      "Loss on test= 0.02267342247068882\n",
      "acc for Lsat= 0.44693362548659443 \n",
      "acc for Psat= 0.5411530563586574 \n",
      "acc for optim= 0.23653694748311346\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.022291023284196854\n",
      "Loss on test= 0.022156432271003723\n",
      "acc for Lsat= 0.49391110090977774 \n",
      "acc for Psat= 0.53911118480389 \n",
      "acc for optim= 0.2966671041288378\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.023837147280573845\n",
      "Loss on test= 0.020863210782408714\n",
      "acc for Lsat= 0.5063590439275611 \n",
      "acc for Psat= 0.5510447790084687 \n",
      "acc for optim= 0.23525289608900296\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.022142039611935616\n",
      "Loss on test= 0.021847933530807495\n",
      "acc for Lsat= 0.4450101577071158 \n",
      "acc for Psat= 0.5326573310146184 \n",
      "acc for optim= 0.3165235393539046\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.021291369572281837\n",
      "Loss on test= 0.023597557097673416\n",
      "acc for Lsat= 0.5062479779248737 \n",
      "acc for Psat= 0.5473335047218653 \n",
      "acc for optim= 0.23704311358183938\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.02148084156215191\n",
      "Loss on test= 0.020270565524697304\n",
      "acc for Lsat= 0.391451733077505 \n",
      "acc for Psat= 0.508037928832031 \n",
      "acc for optim= 0.23729882282173462\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.021397698670625687\n",
      "Loss on test= 0.020166808739304543\n",
      "acc for Lsat= 0.41070617840199014 \n",
      "acc for Psat= 0.541913505542136 \n",
      "acc for optim= 0.25471767146479357\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.020687079057097435\n",
      "Loss on test= 0.021229784935712814\n",
      "acc for Lsat= 0.4221535050015223 \n",
      "acc for Psat= 0.5973495269285489 \n",
      "acc for optim= 0.2218488484162466\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.02072693407535553\n",
      "Loss on test= 0.022112369537353516\n",
      "acc for Lsat= 0.41009569769640447 \n",
      "acc for Psat= 0.5432381716295699 \n",
      "acc for optim= 0.252740073072444\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.021564383059740067\n",
      "Loss on test= 0.020533906295895576\n",
      "acc for Lsat= 0.40771457400626027 \n",
      "acc for Psat= 0.5489713869701026 \n",
      "acc for optim= 0.23818274902299202\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.021150512620806694\n",
      "Loss on test= 0.021400686353445053\n",
      "acc for Lsat= 0.404593913500493 \n",
      "acc for Psat= 0.5401383632175762 \n",
      "acc for optim= 0.2244759741448876\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.020087912678718567\n",
      "Loss on test= 0.02035442739725113\n",
      "acc for Lsat= 0.4456107549513281 \n",
      "acc for Psat= 0.4890007468568148 \n",
      "acc for optim= 0.2280154992166334\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.019711017608642578\n",
      "Loss on test= 0.020708441734313965\n",
      "acc for Lsat= 0.43900682274928643 \n",
      "acc for Psat= 0.4463837438125739 \n",
      "acc for optim= 0.27827825745633755\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.019650334492325783\n",
      "Loss on test= 0.020094435662031174\n",
      "acc for Lsat= 0.4631779366251509 \n",
      "acc for Psat= 0.4624472889058902 \n",
      "acc for optim= 0.22456920868795793\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.019679810851812363\n",
      "Loss on test= 0.02006479911506176\n",
      "acc for Lsat= 0.40190492028597036 \n",
      "acc for Psat= 0.456269001650071 \n",
      "acc for optim= 0.22094032939895517\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.019817564636468887\n",
      "Loss on test= 0.020589523017406464\n",
      "acc for Lsat= 0.40855648478405 \n",
      "acc for Psat= 0.5429802497170828 \n",
      "acc for optim= 0.2222600688156318\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.02004595845937729\n",
      "Loss on test= 0.0190836600959301\n",
      "acc for Lsat= 0.3817334858735243 \n",
      "acc for Psat= 0.5150306778751483 \n",
      "acc for optim= 0.21331996261456831\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.01895061694085598\n",
      "Loss on test= 0.019949300214648247\n",
      "acc for Lsat= 0.4373783099690627 \n",
      "acc for Psat= 0.5190147205785497 \n",
      "acc for optim= 0.20861292696677206\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.019291788339614868\n",
      "Loss on test= 0.01718321442604065\n",
      "acc for Lsat= 0.3665504167721657 \n",
      "acc for Psat= 0.4308735310610123 \n",
      "acc for optim= 0.23457563816574858\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.019316893070936203\n",
      "Loss on test= 0.019111862406134605\n",
      "acc for Lsat= 0.38117621130722174 \n",
      "acc for Psat= 0.499112957361708 \n",
      "acc for optim= 0.25738940527741294\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.01985696144402027\n",
      "Loss on test= 0.016974903643131256\n",
      "acc for Lsat= 0.39235580977323037 \n",
      "acc for Psat= 0.5110608130249799 \n",
      "acc for optim= 0.20755238012517677\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.019172998145222664\n",
      "Loss on test= 0.020673776045441628\n",
      "acc for Lsat= 0.37841415260993166 \n",
      "acc for Psat= 0.528321336930841 \n",
      "acc for optim= 0.20147221094191844\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.018379366025328636\n",
      "Loss on test= 0.018407266587018967\n",
      "acc for Lsat= 0.3682495815596544 \n",
      "acc for Psat= 0.42659121843147707 \n",
      "acc for optim= 0.24716787067829402\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.017978452146053314\n",
      "Loss on test= 0.01792082004249096\n",
      "acc for Lsat= 0.41872321991393224 \n",
      "acc for Psat= 0.4609693967309254 \n",
      "acc for optim= 0.22995278642682368\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.018711112439632416\n",
      "Loss on test= 0.017631644383072853\n",
      "acc for Lsat= 0.3543078047569489 \n",
      "acc for Psat= 0.5475648255740305 \n",
      "acc for optim= 0.2024676042044145\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.01756184734404087\n",
      "Loss on test= 0.018369432538747787\n",
      "acc for Lsat= 0.3855461230583092 \n",
      "acc for Psat= 0.4958667845262303 \n",
      "acc for optim= 0.20346055551655465\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.018147384747862816\n",
      "Loss on test= 0.017460910603404045\n",
      "acc for Lsat= 0.367516729130895 \n",
      "acc for Psat= 0.41666538855015706 \n",
      "acc for optim= 0.2487973658670042\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.01805516704916954\n",
      "Loss on test= 0.01703343540430069\n",
      "acc for Lsat= 0.3697553822279084 \n",
      "acc for Psat= 0.4608198411840292 \n",
      "acc for optim= 0.22538376360112247\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.01727622002363205\n",
      "Loss on test= 0.0174105204641819\n",
      "acc for Lsat= 0.3435872910269756 \n",
      "acc for Psat= 0.382291627332027 \n",
      "acc for optim= 0.1991739521460683\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.017497533932328224\n",
      "Loss on test= 0.01701701618731022\n",
      "acc for Lsat= 0.3461166588012192 \n",
      "acc for Psat= 0.4478914360224735 \n",
      "acc for optim= 0.2184862895127161\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.01709713228046894\n",
      "Loss on test= 0.017597688362002373\n",
      "acc for Lsat= 0.3310019217637632 \n",
      "acc for Psat= 0.5116953108545449 \n",
      "acc for optim= 0.20452257697910978\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.017313092947006226\n",
      "Loss on test= 0.015174453146755695\n",
      "acc for Lsat= 0.37452252685742116 \n",
      "acc for Psat= 0.39368003397248685 \n",
      "acc for optim= 0.19686544509101156\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.01719905063509941\n",
      "Loss on test= 0.015818560495972633\n",
      "acc for Lsat= 0.3688849316716408 \n",
      "acc for Psat= 0.4097690005953671 \n",
      "acc for optim= 0.2132033975242332\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.016600539907813072\n",
      "Loss on test= 0.016050325706601143\n",
      "acc for Lsat= 0.3300244222525696 \n",
      "acc for Psat= 0.40420079480296606 \n",
      "acc for optim= 0.19392926183924852\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.016310324892401695\n",
      "Loss on test= 0.015400215983390808\n",
      "acc for Lsat= 0.3440795750176295 \n",
      "acc for Psat= 0.44816937780588223 \n",
      "acc for optim= 0.2208884007618385\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.015875589102506638\n",
      "Loss on test= 0.017168164253234863\n",
      "acc for Lsat= 0.32577173547212157 \n",
      "acc for Psat= 0.4414111704232783 \n",
      "acc for optim= 0.21192523645240235\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.01660606451332569\n",
      "Loss on test= 0.016575677320361137\n",
      "acc for Lsat= 0.37244365813849317 \n",
      "acc for Psat= 0.3928106843161151 \n",
      "acc for optim= 0.205221598548854\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.016396822407841682\n",
      "Loss on test= 0.015890195965766907\n",
      "acc for Lsat= 0.3782832345400616 \n",
      "acc for Psat= 0.39636959438035235 \n",
      "acc for optim= 0.20082553474168055\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.016284232959151268\n",
      "Loss on test= 0.018201686441898346\n",
      "acc for Lsat= 0.33330804177913287 \n",
      "acc for Psat= 0.569861978909545 \n",
      "acc for optim= 0.2473221429884418\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.016813423484563828\n",
      "Loss on test= 0.01582184247672558\n",
      "acc for Lsat= 0.36115050254148945 \n",
      "acc for Psat= 0.45613905637937197 \n",
      "acc for optim= 0.21864672512900732\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.015417329967021942\n",
      "Loss on test= 0.015507726930081844\n",
      "acc for Lsat= 0.3309411309782189 \n",
      "acc for Psat= 0.40814158249948473 \n",
      "acc for optim= 0.1965144089432166\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.015462315641343594\n",
      "Loss on test= 0.014751328155398369\n",
      "acc for Lsat= 0.3449668490769958 \n",
      "acc for Psat= 0.37392995629272413 \n",
      "acc for optim= 0.21483271080737845\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.01625269092619419\n",
      "Loss on test= 0.017871994525194168\n",
      "acc for Lsat= 0.3393165546499281 \n",
      "acc for Psat= 0.4660088165979392 \n",
      "acc for optim= 0.23665997627540492\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.015731362625956535\n",
      "Loss on test= 0.01641242578625679\n",
      "acc for Lsat= 0.37981877679526777 \n",
      "acc for Psat= 0.39500997613514127 \n",
      "acc for optim= 0.19875936257665525\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.015571308322250843\n",
      "Loss on test= 0.015229019336402416\n",
      "acc for Lsat= 0.322524640221476 \n",
      "acc for Psat= 0.39047479398731094 \n",
      "acc for optim= 0.20500156301656985\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.01563679613173008\n",
      "Loss on test= 0.015242157503962517\n",
      "acc for Lsat= 0.302217240286228 \n",
      "acc for Psat= 0.4343349341306256 \n",
      "acc for optim= 0.22693457193452413\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.015111364424228668\n",
      "Loss on test= 0.014756061136722565\n",
      "acc for Lsat= 0.3509135573938791 \n",
      "acc for Psat= 0.41139165095341307 \n",
      "acc for optim= 0.19350921345018857\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.015052974224090576\n",
      "Loss on test= 0.014854159206151962\n",
      "acc for Lsat= 0.3180411601340008 \n",
      "acc for Psat= 0.45013007672182664 \n",
      "acc for optim= 0.20164996330026339\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.015703435987234116\n",
      "Loss on test= 0.01608586311340332\n",
      "acc for Lsat= 0.33450770714301364 \n",
      "acc for Psat= 0.39908675960818857 \n",
      "acc for optim= 0.19522712786783813\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.01518215611577034\n",
      "Loss on test= 0.015046169981360435\n",
      "acc for Lsat= 0.33240036356840613 \n",
      "acc for Psat= 0.375616070117303 \n",
      "acc for optim= 0.2268841119022565\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.014634904451668262\n",
      "Loss on test= 0.01461120042949915\n",
      "acc for Lsat= 0.33564802531445576 \n",
      "acc for Psat= 0.4450867513045326 \n",
      "acc for optim= 0.1925511328002825\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.014388957992196083\n",
      "Loss on test= 0.014817366376519203\n",
      "acc for Lsat= 0.32966528748705526 \n",
      "acc for Psat= 0.3773426719573665 \n",
      "acc for optim= 0.19835978252278338\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.014530873857438564\n",
      "Loss on test= 0.013837683945894241\n",
      "acc for Lsat= 0.29384889695211314 \n",
      "acc for Psat= 0.4357657718379365 \n",
      "acc for optim= 0.21703444260355034\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.014431371353566647\n",
      "Loss on test= 0.015241890214383602\n",
      "acc for Lsat= 0.3614152009034336 \n",
      "acc for Psat= 0.36324655692992935 \n",
      "acc for optim= 0.21301662782836403\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.014812481589615345\n",
      "Loss on test= 0.015341470018029213\n",
      "acc for Lsat= 0.2933495026439699 \n",
      "acc for Psat= 0.4156013670899729 \n",
      "acc for optim= 0.23097862451371887\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.015260966494679451\n",
      "Loss on test= 0.015730077400803566\n",
      "acc for Lsat= 0.3725858647337215 \n",
      "acc for Psat= 0.3982313622341403 \n",
      "acc for optim= 0.20308072226144586\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.015026597306132317\n",
      "Loss on test= 0.014793073758482933\n",
      "acc for Lsat= 0.3130253341504785 \n",
      "acc for Psat= 0.3879496174987572 \n",
      "acc for optim= 0.1944207370366171\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.014314667321741581\n",
      "Loss on test= 0.014475003816187382\n",
      "acc for Lsat= 0.3395711447995603 \n",
      "acc for Psat= 0.38311172139436017 \n",
      "acc for optim= 0.19739603108806675\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.014933198690414429\n",
      "Loss on test= 0.01588214747607708\n",
      "acc for Lsat= 0.31077549250236386 \n",
      "acc for Psat= 0.39079861180771086 \n",
      "acc for optim= 0.19635589673236756\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.014738094061613083\n",
      "Loss on test= 0.014542771503329277\n",
      "acc for Lsat= 0.28075107283154 \n",
      "acc for Psat= 0.47190037814731556 \n",
      "acc for optim= 0.19903022006375878\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.01461364421993494\n",
      "Loss on test= 0.012990313582122326\n",
      "acc for Lsat= 0.31191313490743033 \n",
      "acc for Psat= 0.3685587703118988 \n",
      "acc for optim= 0.20833258944991473\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.014207014814019203\n",
      "Loss on test= 0.012976888567209244\n",
      "acc for Lsat= 0.32013189020752275 \n",
      "acc for Psat= 0.4027672199465726 \n",
      "acc for optim= 0.187897633267189\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.014031469821929932\n",
      "Loss on test= 0.013983133248984814\n",
      "acc for Lsat= 0.3408629638984535 \n",
      "acc for Psat= 0.34559958314875494 \n",
      "acc for optim= 0.17901462686102212\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.01415990386158228\n",
      "Loss on test= 0.014604488387703896\n",
      "acc for Lsat= 0.2930463108798879 \n",
      "acc for Psat= 0.40899227894153006 \n",
      "acc for optim= 0.18033792010533647\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.014652399346232414\n",
      "Loss on test= 0.013645297847688198\n",
      "acc for Lsat= 0.29764268820518563 \n",
      "acc for Psat= 0.3867151783527555 \n",
      "acc for optim= 0.2222682269376811\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.014431266114115715\n",
      "Loss on test= 0.014486809261143208\n",
      "acc for Lsat= 0.3197339312000376 \n",
      "acc for Psat= 0.3477219501061906 \n",
      "acc for optim= 0.20151287271260485\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.015153985470533371\n",
      "Loss on test= 0.014815050177276134\n",
      "acc for Lsat= 0.30802808678394333 \n",
      "acc for Psat= 0.4443338442625965 \n",
      "acc for optim= 0.19866722082322766\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.014123518019914627\n",
      "Loss on test= 0.013896162621676922\n",
      "acc for Lsat= 0.29553378887995013 \n",
      "acc for Psat= 0.37392768727432985 \n",
      "acc for optim= 0.19404752384306867\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.013678682036697865\n",
      "Loss on test= 0.014599519781768322\n",
      "acc for Lsat= 0.3397886502547457 \n",
      "acc for Psat= 0.37366632178010467 \n",
      "acc for optim= 0.18966872806777246\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.013612322509288788\n",
      "Loss on test= 0.014601224102079868\n",
      "acc for Lsat= 0.29571032107019535 \n",
      "acc for Psat= 0.4102629664018939 \n",
      "acc for optim= 0.22854433943811692\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.013276542536914349\n",
      "Loss on test= 0.012881099246442318\n",
      "acc for Lsat= 0.3170346759225386 \n",
      "acc for Psat= 0.3507083127092055 \n",
      "acc for optim= 0.18206270536550595\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.013637848198413849\n",
      "Loss on test= 0.013937031850218773\n",
      "acc for Lsat= 0.3017398337764757 \n",
      "acc for Psat= 0.32856972912063737 \n",
      "acc for optim= 0.1877525356502628\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.013533959165215492\n",
      "Loss on test= 0.014297637157142162\n",
      "acc for Lsat= 0.3446780552443965 \n",
      "acc for Psat= 0.3567369740135414 \n",
      "acc for optim= 0.19353107267218278\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.013452418148517609\n",
      "Loss on test= 0.01394838560372591\n",
      "acc for Lsat= 0.290763915192361 \n",
      "acc for Psat= 0.37785760246903943 \n",
      "acc for optim= 0.19164684887977815\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.013866287656128407\n",
      "Loss on test= 0.013810415752232075\n",
      "acc for Lsat= 0.3561974427744595 \n",
      "acc for Psat= 0.3535742319186652 \n",
      "acc for optim= 0.2024152878411523\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.013583027757704258\n",
      "Loss on test= 0.01298581063747406\n",
      "acc for Lsat= 0.26740183438035986 \n",
      "acc for Psat= 0.3915106822178869 \n",
      "acc for optim= 0.19228151393332843\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.013346252031624317\n",
      "Loss on test= 0.013023141771554947\n",
      "acc for Lsat= 0.3158639888232436 \n",
      "acc for Psat= 0.339363693356407 \n",
      "acc for optim= 0.18452191466308618\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.013063516467809677\n",
      "Loss on test= 0.013366279192268848\n",
      "acc for Lsat= 0.32456405623737294 \n",
      "acc for Psat= 0.3588784340222569 \n",
      "acc for optim= 0.19157485049603368\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.014159108512103558\n",
      "Loss on test= 0.012638791464269161\n",
      "acc for Lsat= 0.3184403498634237 \n",
      "acc for Psat= 0.35621151476909685 \n",
      "acc for optim= 0.1947794265201869\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.013155805878341198\n",
      "Loss on test= 0.013205652125179768\n",
      "acc for Lsat= 0.2936345383450562 \n",
      "acc for Psat= 0.3682650813727955 \n",
      "acc for optim= 0.1903821793190169\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.013605979271233082\n",
      "Loss on test= 0.01403014361858368\n",
      "acc for Lsat= 0.27029621946811044 \n",
      "acc for Psat= 0.4262236257934116 \n",
      "acc for optim= 0.1918820183886596\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.014283033087849617\n",
      "Loss on test= 0.01298569142818451\n",
      "acc for Lsat= 0.3202721880917198 \n",
      "acc for Psat= 0.33969341802199976 \n",
      "acc for optim= 0.18226335129253818\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.013803014531731606\n",
      "Loss on test= 0.013073812238872051\n",
      "acc for Lsat= 0.3342757780038802 \n",
      "acc for Psat= 0.32797217922838956 \n",
      "acc for optim= 0.19198850240334994\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.012979934923350811\n",
      "Loss on test= 0.013614799827337265\n",
      "acc for Lsat= 0.3584303798089988 \n",
      "acc for Psat= 0.36889205838402583 \n",
      "acc for optim= 0.19397883148544556\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.014448890462517738\n",
      "Loss on test= 0.016204705461859703\n",
      "acc for Lsat= 0.28170919283847734 \n",
      "acc for Psat= 0.47431838148701433 \n",
      "acc for optim= 0.18898227324615544\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.013885892927646637\n",
      "Loss on test= 0.013102874159812927\n",
      "acc for Lsat= 0.30390671421534804 \n",
      "acc for Psat= 0.36047815701238356 \n",
      "acc for optim= 0.19155849762161803\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.01333712600171566\n",
      "Loss on test= 0.014811853878200054\n",
      "acc for Lsat= 0.3452613410604868 \n",
      "acc for Psat= 0.364919317374409 \n",
      "acc for optim= 0.19289360633587962\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.014276075176894665\n",
      "Loss on test= 0.012927194125950336\n",
      "acc for Lsat= 0.3042118957661866 \n",
      "acc for Psat= 0.3479439519222659 \n",
      "acc for optim= 0.19785730564010895\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.013567653484642506\n",
      "Loss on test= 0.013075655326247215\n",
      "acc for Lsat= 0.2745088435565137 \n",
      "acc for Psat= 0.42584133867765905 \n",
      "acc for optim= 0.19690493999518663\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.013777943328022957\n",
      "Loss on test= 0.014663186855614185\n",
      "acc for Lsat= 0.26439089667727067 \n",
      "acc for Psat= 0.43052144010780957 \n",
      "acc for optim= 0.19181454572272078\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.01350944023579359\n",
      "Loss on test= 0.012126409448683262\n",
      "acc for Lsat= 0.2883550192337999 \n",
      "acc for Psat= 0.3263141139735593 \n",
      "acc for optim= 0.188848057878597\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.012703634798526764\n",
      "Loss on test= 0.013397261500358582\n",
      "acc for Lsat= 0.29520997660541537 \n",
      "acc for Psat= 0.3422168776388217 \n",
      "acc for optim= 0.2000039194274696\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.013112318702042103\n",
      "Loss on test= 0.01272626407444477\n",
      "acc for Lsat= 0.339039835531563 \n",
      "acc for Psat= 0.3870613729542694 \n",
      "acc for optim= 0.18128119033998874\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.012538251467049122\n",
      "Loss on test= 0.014288482256233692\n",
      "acc for Lsat= 0.26250103586101653 \n",
      "acc for Psat= 0.42737638060532696 \n",
      "acc for optim= 0.18929553355760495\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.01328926533460617\n",
      "Loss on test= 0.01303323358297348\n",
      "acc for Lsat= 0.30020470288503487 \n",
      "acc for Psat= 0.35943327426635685 \n",
      "acc for optim= 0.18823215835397383\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.013192754238843918\n",
      "Loss on test= 0.012761586345732212\n",
      "acc for Lsat= 0.2566783029359539 \n",
      "acc for Psat= 0.3808592757276209 \n",
      "acc for optim= 0.1957951466584819\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.013445391319692135\n",
      "Loss on test= 0.012508450075984001\n",
      "acc for Lsat= 0.2942155214433434 \n",
      "acc for Psat= 0.3640592536859323 \n",
      "acc for optim= 0.18380793988030378\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.01249804999679327\n",
      "Loss on test= 0.012481487356126308\n",
      "acc for Lsat= 0.31199640123196404 \n",
      "acc for Psat= 0.318599509864922 \n",
      "acc for optim= 0.18823015216578307\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.012914205901324749\n",
      "Loss on test= 0.013777436688542366\n",
      "acc for Lsat= 0.2836708918786482 \n",
      "acc for Psat= 0.37668120414978273 \n",
      "acc for optim= 0.18694482281002506\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.012693044729530811\n",
      "Loss on test= 0.012258545495569706\n",
      "acc for Lsat= 0.2597058021744266 \n",
      "acc for Psat= 0.40335019639619657 \n",
      "acc for optim= 0.18809136253155492\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.012504298239946365\n",
      "Loss on test= 0.012052887119352818\n",
      "acc for Lsat= 0.31254459507417287 \n",
      "acc for Psat= 0.3560660158620669 \n",
      "acc for optim= 0.19414687320818916\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.013112076558172703\n",
      "Loss on test= 0.012687952257692814\n",
      "acc for Lsat= 0.29618811055095995 \n",
      "acc for Psat= 0.3239361801502496 \n",
      "acc for optim= 0.18157225206094743\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.013284094631671906\n",
      "Loss on test= 0.012359843589365482\n",
      "acc for Lsat= 0.2593000712354174 \n",
      "acc for Psat= 0.4045451790028204 \n",
      "acc for optim= 0.1861423021410529\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.0127327935770154\n",
      "Loss on test= 0.012111769057810307\n",
      "acc for Lsat= 0.2729140476381085 \n",
      "acc for Psat= 0.3451309004870111 \n",
      "acc for optim= 0.1983818244468755\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.01293996162712574\n",
      "Loss on test= 0.015075286850333214\n",
      "acc for Lsat= 0.2899841677863151 \n",
      "acc for Psat= 0.49729304805244995 \n",
      "acc for optim= 0.1931771673844196\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.012879875488579273\n",
      "Loss on test= 0.012327435426414013\n",
      "acc for Lsat= 0.277540947021948 \n",
      "acc for Psat= 0.3529754083838024 \n",
      "acc for optim= 0.20200179806085322\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.012582117691636086\n",
      "Loss on test= 0.011713191866874695\n",
      "acc for Lsat= 0.25198153878492935 \n",
      "acc for Psat= 0.31587356524431853 \n",
      "acc for optim= 0.1809423323734459\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.012286800891160965\n",
      "Loss on test= 0.012716280296444893\n",
      "acc for Lsat= 0.2657761748387939 \n",
      "acc for Psat= 0.38287420781322196 \n",
      "acc for optim= 0.18132300529415826\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.012358424253761768\n",
      "Loss on test= 0.011957917362451553\n",
      "acc for Lsat= 0.29151813484310657 \n",
      "acc for Psat= 0.36349987056313987 \n",
      "acc for optim= 0.19947673304862268\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.012813128530979156\n",
      "Loss on test= 0.01203084271401167\n",
      "acc for Lsat= 0.2718625377841621 \n",
      "acc for Psat= 0.3519604664745841 \n",
      "acc for optim= 0.19124359627961451\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.012521285563707352\n",
      "Loss on test= 0.013170328922569752\n",
      "acc for Lsat= 0.3339619646242165 \n",
      "acc for Psat= 0.3637188249188979 \n",
      "acc for optim= 0.18254933477126886\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.013543360866606236\n",
      "Loss on test= 0.01228192076086998\n",
      "acc for Lsat= 0.2773713090687493 \n",
      "acc for Psat= 0.34979667180655144 \n",
      "acc for optim= 0.17825870709930314\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.012631407007575035\n",
      "Loss on test= 0.012265884317457676\n",
      "acc for Lsat= 0.2931383924792376 \n",
      "acc for Psat= 0.3251310701104828 \n",
      "acc for optim= 0.1808954206443977\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.012593083083629608\n",
      "Loss on test= 0.011732366867363453\n",
      "acc for Lsat= 0.297472223970446 \n",
      "acc for Psat= 0.3331432826946823 \n",
      "acc for optim= 0.19744749982301318\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.012215218506753445\n",
      "Loss on test= 0.013821321539580822\n",
      "acc for Lsat= 0.2655562699736628 \n",
      "acc for Psat= 0.4002860211820351 \n",
      "acc for optim= 0.21473403929495188\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.012332362122833729\n",
      "Loss on test= 0.012136206962168217\n",
      "acc for Lsat= 0.30115538567416306 \n",
      "acc for Psat= 0.3442866323308113 \n",
      "acc for optim= 0.19907065788622177\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.012572057545185089\n",
      "Loss on test= 0.012824592180550098\n",
      "acc for Lsat= 0.2751542080903262 \n",
      "acc for Psat= 0.3717972444719635 \n",
      "acc for optim= 0.19073837292160387\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.013016986660659313\n",
      "Loss on test= 0.011781171895563602\n",
      "acc for Lsat= 0.2669304335998006 \n",
      "acc for Psat= 0.3462058787957397 \n",
      "acc for optim= 0.1953723262722633\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.012584097683429718\n",
      "Loss on test= 0.011163554154336452\n",
      "acc for Lsat= 0.2841732333338744 \n",
      "acc for Psat= 0.322880738086816 \n",
      "acc for optim= 0.1779103803293421\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.012427375651896\n",
      "Loss on test= 0.012170498259365559\n",
      "acc for Lsat= 0.2636833975698824 \n",
      "acc for Psat= 0.35312941966018313 \n",
      "acc for optim= 0.18986174073251202\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.0120376106351614\n",
      "Loss on test= 0.011572903953492641\n",
      "acc for Lsat= 0.3073012544439218 \n",
      "acc for Psat= 0.3204501137881527 \n",
      "acc for optim= 0.1889666880922689\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.01184582058340311\n",
      "Loss on test= 0.012214018031954765\n",
      "acc for Lsat= 0.2674407443657794 \n",
      "acc for Psat= 0.34460251516469037 \n",
      "acc for optim= 0.1774585229785943\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.012230481952428818\n",
      "Loss on test= 0.011652400717139244\n",
      "acc for Lsat= 0.30545717401892525 \n",
      "acc for Psat= 0.32037038332782686 \n",
      "acc for optim= 0.18428059299028088\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.011666076257824898\n",
      "Loss on test= 0.011579304933547974\n",
      "acc for Lsat= 0.25644218168973393 \n",
      "acc for Psat= 0.31674008511677004 \n",
      "acc for optim= 0.18048265464981464\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.011872527189552784\n",
      "Loss on test= 0.012131615541875362\n",
      "acc for Lsat= 0.27197305100285246 \n",
      "acc for Psat= 0.3348227036641785 \n",
      "acc for optim= 0.1783726753820038\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.011980998329818249\n",
      "Loss on test= 0.011560646817088127\n",
      "acc for Lsat= 0.28741533448919654 \n",
      "acc for Psat= 0.3387739444914513 \n",
      "acc for optim= 0.1750114907697787\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.012339921668171883\n",
      "Loss on test= 0.012281355448067188\n",
      "acc for Lsat= 0.32674799342144195 \n",
      "acc for Psat= 0.327276617023312 \n",
      "acc for optim= 0.18281439145868864\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.012389639392495155\n",
      "Loss on test= 0.012382608838379383\n",
      "acc for Lsat= 0.25665227417296077 \n",
      "acc for Psat= 0.40803445559750134 \n",
      "acc for optim= 0.18972894792976738\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.012212157249450684\n",
      "Loss on test= 0.011291745118796825\n",
      "acc for Lsat= 0.2611078429468467 \n",
      "acc for Psat= 0.332783301578004 \n",
      "acc for optim= 0.1876350675058249\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.012080431915819645\n",
      "Loss on test= 0.012115326710045338\n",
      "acc for Lsat= 0.282528325223924 \n",
      "acc for Psat= 0.31858304998289944 \n",
      "acc for optim= 0.17655693371705491\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.011609458364546299\n",
      "Loss on test= 0.012854444794356823\n",
      "acc for Lsat= 0.30850935301340715 \n",
      "acc for Psat= 0.32052844813773157 \n",
      "acc for optim= 0.17525111242021257\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.011918687261641026\n",
      "Loss on test= 0.011787017807364464\n",
      "acc for Lsat= 0.2584003167011778 \n",
      "acc for Psat= 0.37295202330779226 \n",
      "acc for optim= 0.20318374191835598\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.011847217567265034\n",
      "Loss on test= 0.012113913893699646\n",
      "acc for Lsat= 0.25384749707685644 \n",
      "acc for Psat= 0.37275235836647413 \n",
      "acc for optim= 0.1899274345896383\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.012039919383823872\n",
      "Loss on test= 0.01234488096088171\n",
      "acc for Lsat= 0.32115624487640754 \n",
      "acc for Psat= 0.3238765428733943 \n",
      "acc for optim= 0.21417418520001308\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.012329228222370148\n",
      "Loss on test= 0.011457087472081184\n",
      "acc for Lsat= 0.26188131838067863 \n",
      "acc for Psat= 0.3202530603441512 \n",
      "acc for optim= 0.1828557608406865\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.011879511177539825\n",
      "Loss on test= 0.011130472645163536\n",
      "acc for Lsat= 0.2569036840716 \n",
      "acc for Psat= 0.3742800535330536 \n",
      "acc for optim= 0.17973673168445523\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.011704903095960617\n",
      "Loss on test= 0.011285794898867607\n",
      "acc for Lsat= 0.2525049655122456 \n",
      "acc for Psat= 0.38555926980169153 \n",
      "acc for optim= 0.18631010703491582\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.012100933119654655\n",
      "Loss on test= 0.012602463364601135\n",
      "acc for Lsat= 0.2811755516475485 \n",
      "acc for Psat= 0.3347231797727275 \n",
      "acc for optim= 0.17669144783320842\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.012474589049816132\n",
      "Loss on test= 0.011562756262719631\n",
      "acc for Lsat= 0.25837902387246614 \n",
      "acc for Psat= 0.384593328008688 \n",
      "acc for optim= 0.17597951140644885\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.011528552509844303\n",
      "Loss on test= 0.011557864025235176\n",
      "acc for Lsat= 0.2721882372680812 \n",
      "acc for Psat= 0.31303105648918506 \n",
      "acc for optim= 0.18676946614149792\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.011479676701128483\n",
      "Loss on test= 0.011842698790133\n",
      "acc for Lsat= 0.24019527031939375 \n",
      "acc for Psat= 0.3228144461313727 \n",
      "acc for optim= 0.18046891874601478\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.011813586577773094\n",
      "Loss on test= 0.011540024541318417\n",
      "acc for Lsat= 0.25649104038303766 \n",
      "acc for Psat= 0.3402578879837607 \n",
      "acc for optim= 0.17758001947663002\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.01141707319766283\n",
      "Loss on test= 0.012403447180986404\n",
      "acc for Lsat= 0.2544561338845351 \n",
      "acc for Psat= 0.35361546233852514 \n",
      "acc for optim= 0.18799032076836936\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.01213764026761055\n",
      "Loss on test= 0.011260147206485271\n",
      "acc for Lsat= 0.3019341448106806 \n",
      "acc for Psat= 0.307257562636231 \n",
      "acc for optim= 0.1814585263448346\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.011522422544658184\n",
      "Loss on test= 0.0113459387794137\n",
      "acc for Lsat= 0.2603577519137714 \n",
      "acc for Psat= 0.32328274764979537 \n",
      "acc for optim= 0.17859250763222992\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.011260219849646091\n",
      "Loss on test= 0.011578783392906189\n",
      "acc for Lsat= 0.2633413302782346 \n",
      "acc for Psat= 0.3478667289862249 \n",
      "acc for optim= 0.1873603855268369\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.011462691240012646\n",
      "Loss on test= 0.011039961129426956\n",
      "acc for Lsat= 0.2919745539311899 \n",
      "acc for Psat= 0.31475495183157076 \n",
      "acc for optim= 0.18495526234304682\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.01115129329264164\n",
      "Loss on test= 0.011722840368747711\n",
      "acc for Lsat= 0.28021805887554957 \n",
      "acc for Psat= 0.3104370597543616 \n",
      "acc for optim= 0.18392329765265458\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.012178624980151653\n",
      "Loss on test= 0.011687646619975567\n",
      "acc for Lsat= 0.24510180556948447 \n",
      "acc for Psat= 0.3503044345536084 \n",
      "acc for optim= 0.17415288220527636\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.01152637880295515\n",
      "Loss on test= 0.011849489063024521\n",
      "acc for Lsat= 0.25872261698650373 \n",
      "acc for Psat= 0.3398003997233998 \n",
      "acc for optim= 0.1715552052998179\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.011822077445685863\n",
      "Loss on test= 0.011600264348089695\n",
      "acc for Lsat= 0.2535075330595007 \n",
      "acc for Psat= 0.32932580548741325 \n",
      "acc for optim= 0.18315052384089023\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.011459988541901112\n",
      "Loss on test= 0.011397883296012878\n",
      "acc for Lsat= 0.2422756460948369 \n",
      "acc for Psat= 0.3499933555328942 \n",
      "acc for optim= 0.17281670179461897\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.010950040072202682\n",
      "Loss on test= 0.011046274565160275\n",
      "acc for Lsat= 0.26904054694632823 \n",
      "acc for Psat= 0.2990596178263061 \n",
      "acc for optim= 0.1829104643815348\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.011241095140576363\n",
      "Loss on test= 0.010852416045963764\n",
      "acc for Lsat= 0.2712888168397193 \n",
      "acc for Psat= 0.3019996706126541 \n",
      "acc for optim= 0.19622297644732375\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.011197509244084358\n",
      "Loss on test= 0.010515309870243073\n",
      "acc for Lsat= 0.2811685527692159 \n",
      "acc for Psat= 0.3136671659162243 \n",
      "acc for optim= 0.18454769810479185\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.011076457798480988\n",
      "Loss on test= 0.01298168022185564\n",
      "acc for Lsat= 0.3758275528309388 \n",
      "acc for Psat= 0.3179780386146032 \n",
      "acc for optim= 0.17454525313243377\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.011307605542242527\n",
      "Loss on test= 0.011194440536201\n",
      "acc for Lsat= 0.2556040235209071 \n",
      "acc for Psat= 0.3508301499107777 \n",
      "acc for optim= 0.18303053174561165\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.01207025907933712\n",
      "Loss on test= 0.01230591256171465\n",
      "acc for Lsat= 0.35513779144762464 \n",
      "acc for Psat= 0.34030294262039523 \n",
      "acc for optim= 0.1859577953352552\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.011421402916312218\n",
      "Loss on test= 0.011131513863801956\n",
      "acc for Lsat= 0.2704491467503013 \n",
      "acc for Psat= 0.3173724974826532 \n",
      "acc for optim= 0.1847291416394197\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.011192279867827892\n",
      "Loss on test= 0.011366570368409157\n",
      "acc for Lsat= 0.29014611787302735 \n",
      "acc for Psat= 0.2990681050934064 \n",
      "acc for optim= 0.17327126700960482\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.011208153329789639\n",
      "Loss on test= 0.011731461621820927\n",
      "acc for Lsat= 0.2598044778435881 \n",
      "acc for Psat= 0.3232614969759173 \n",
      "acc for optim= 0.1779289136894796\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.010940040461719036\n",
      "Loss on test= 0.010826240293681622\n",
      "acc for Lsat= 0.30012516805279144 \n",
      "acc for Psat= 0.31409512902492015 \n",
      "acc for optim= 0.18451773380582234\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.011155939660966396\n",
      "Loss on test= 0.011076741851866245\n",
      "acc for Lsat= 0.25343255079654203 \n",
      "acc for Psat= 0.324044136491343 \n",
      "acc for optim= 0.18577078275297568\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.01136063039302826\n",
      "Loss on test= 0.010900301858782768\n",
      "acc for Lsat= 0.27311471899707074 \n",
      "acc for Psat= 0.2938465471888315 \n",
      "acc for optim= 0.18148382354037668\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.011431224644184113\n",
      "Loss on test= 0.011296364478766918\n",
      "acc for Lsat= 0.24632407862662983 \n",
      "acc for Psat= 0.348450985982561 \n",
      "acc for optim= 0.2027018911278385\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.011762378737330437\n",
      "Loss on test= 0.010690576396882534\n",
      "acc for Lsat= 0.2537740669559335 \n",
      "acc for Psat= 0.3255818052271639 \n",
      "acc for optim= 0.17763150245003556\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.010926675982773304\n",
      "Loss on test= 0.012745324522256851\n",
      "acc for Lsat= 0.2466371905462143 \n",
      "acc for Psat= 0.4687821638856533 \n",
      "acc for optim= 0.18140204654156225\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.011400774121284485\n",
      "Loss on test= 0.011673470959067345\n",
      "acc for Lsat= 0.30362651977574806 \n",
      "acc for Psat= 0.2929824284050532 \n",
      "acc for optim= 0.17834858234375525\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.010917230509221554\n",
      "Loss on test= 0.011330850422382355\n",
      "acc for Lsat= 0.24746297964687786 \n",
      "acc for Psat= 0.35408650400967345 \n",
      "acc for optim= 0.1836706857065528\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.011609002947807312\n",
      "Loss on test= 0.011178936809301376\n",
      "acc for Lsat= 0.24631313811177452 \n",
      "acc for Psat= 0.3140076542255662 \n",
      "acc for optim= 0.18165047263280515\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.011275497265160084\n",
      "Loss on test= 0.011151477694511414\n",
      "acc for Lsat= 0.24542128628063192 \n",
      "acc for Psat= 0.3359936427682319 \n",
      "acc for optim= 0.19151850856419392\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.010787840001285076\n",
      "Loss on test= 0.011413075029850006\n",
      "acc for Lsat= 0.27698543895432426 \n",
      "acc for Psat= 0.30154082488985984 \n",
      "acc for optim= 0.17658110433321045\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.01128796860575676\n",
      "Loss on test= 0.011718452908098698\n",
      "acc for Lsat= 0.2862775843573586 \n",
      "acc for Psat= 0.2988240174293153 \n",
      "acc for optim= 0.18374391759091332\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.010916653089225292\n",
      "Loss on test= 0.010117795318365097\n",
      "acc for Lsat= 0.2829801837003804 \n",
      "acc for Psat= 0.31056029801242696 \n",
      "acc for optim= 0.17717033501147042\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.010555528104305267\n",
      "Loss on test= 0.010949318297207355\n",
      "acc for Lsat= 0.25680862921817116 \n",
      "acc for Psat= 0.3575138598056755 \n",
      "acc for optim= 0.19489732649919853\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.010769516229629517\n",
      "Loss on test= 0.01107275765389204\n",
      "acc for Lsat= 0.23943128953436138 \n",
      "acc for Psat= 0.30111423247684355 \n",
      "acc for optim= 0.17579842324045564\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.010684248991310596\n",
      "Loss on test= 0.010737435892224312\n",
      "acc for Lsat= 0.2688344538847387 \n",
      "acc for Psat= 0.3119074587087419 \n",
      "acc for optim= 0.18451826551078027\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.011029429733753204\n",
      "Loss on test= 0.010677619837224483\n",
      "acc for Lsat= 0.2654577179149586 \n",
      "acc for Psat= 0.3107378201334418 \n",
      "acc for optim= 0.18150641613445603\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.01109264511615038\n",
      "Loss on test= 0.0114532969892025\n",
      "acc for Lsat= 0.2739686598895885 \n",
      "acc for Psat= 0.2948925052761616 \n",
      "acc for optim= 0.18163212529268363\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.011330114677548409\n",
      "Loss on test= 0.010621760971844196\n",
      "acc for Lsat= 0.2518751379485931 \n",
      "acc for Psat= 0.32810059348078024 \n",
      "acc for optim= 0.17381250746217808\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.010952352546155453\n",
      "Loss on test= 0.01081871148198843\n",
      "acc for Lsat= 0.2529115371997594 \n",
      "acc for Psat= 0.31152875145710063 \n",
      "acc for optim= 0.1727666852613667\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.01048032846301794\n",
      "Loss on test= 0.010268043726682663\n",
      "acc for Lsat= 0.27481559708610653 \n",
      "acc for Psat= 0.2889909685498522 \n",
      "acc for optim= 0.17960190060900483\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.010377507656812668\n",
      "Loss on test= 0.010593399405479431\n",
      "acc for Lsat= 0.24652536590882526 \n",
      "acc for Psat= 0.35811953371897265 \n",
      "acc for optim= 0.1737709966723373\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.010726402513682842\n",
      "Loss on test= 0.010851411148905754\n",
      "acc for Lsat= 0.23935419955720333 \n",
      "acc for Psat= 0.35780692661206265 \n",
      "acc for optim= 0.19072627715394372\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.01121198758482933\n",
      "Loss on test= 0.011047936975955963\n",
      "acc for Lsat= 0.23361620476590064 \n",
      "acc for Psat= 0.29911871207720675 \n",
      "acc for optim= 0.18116912621661793\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.010784653015434742\n",
      "Loss on test= 0.01034653838723898\n",
      "acc for Lsat= 0.26059282641398496 \n",
      "acc for Psat= 0.29160714555198225 \n",
      "acc for optim= 0.18364760337037198\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.010315168648958206\n",
      "Loss on test= 0.01042954158037901\n",
      "acc for Lsat= 0.26119788517725456 \n",
      "acc for Psat= 0.2821031391712667 \n",
      "acc for optim= 0.18322958058687053\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.01140274666249752\n",
      "Loss on test= 0.01060075219720602\n",
      "acc for Lsat= 0.25779101750300176 \n",
      "acc for Psat= 0.3178022093266131 \n",
      "acc for optim= 0.17693014959002393\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.01055093016475439\n",
      "Loss on test= 0.010380265302956104\n",
      "acc for Lsat= 0.2375977396755794 \n",
      "acc for Psat= 0.31060160781300905 \n",
      "acc for optim= 0.18278155268313098\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.010955996811389923\n",
      "Loss on test= 0.010646132752299309\n",
      "acc for Lsat= 0.2541475605590873 \n",
      "acc for Psat= 0.328807646785847 \n",
      "acc for optim= 0.18815728273782312\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.011093047447502613\n",
      "Loss on test= 0.010669478215277195\n",
      "acc for Lsat= 0.23858805802140254 \n",
      "acc for Psat= 0.340437117332545 \n",
      "acc for optim= 0.1804798555401519\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.010571684688329697\n",
      "Loss on test= 0.010580773465335369\n",
      "acc for Lsat= 0.26891049294932307 \n",
      "acc for Psat= 0.27982421373992505 \n",
      "acc for optim= 0.1749847425925804\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.010639719665050507\n",
      "Loss on test= 0.010954229161143303\n",
      "acc for Lsat= 0.23274946226848517 \n",
      "acc for Psat= 0.34710250569785145 \n",
      "acc for optim= 0.17890246343744662\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.010932525619864464\n",
      "Loss on test= 0.010519053786993027\n",
      "acc for Lsat= 0.25997308732169316 \n",
      "acc for Psat= 0.30827522788722245 \n",
      "acc for optim= 0.1762825172317625\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.010486829094588757\n",
      "Loss on test= 0.01133093610405922\n",
      "acc for Lsat= 0.26204043177878356 \n",
      "acc for Psat= 0.325140766682248 \n",
      "acc for optim= 0.18891005984325013\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.01127362810075283\n",
      "Loss on test= 0.010525339283049107\n",
      "acc for Lsat= 0.3036429320103756 \n",
      "acc for Psat= 0.29138473569961404 \n",
      "acc for optim= 0.17706316041595355\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.010932054370641708\n",
      "Loss on test= 0.010458329692482948\n",
      "acc for Lsat= 0.25113393619697466 \n",
      "acc for Psat= 0.3127492961015181 \n",
      "acc for optim= 0.18442351784166955\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.010450816713273525\n",
      "Loss on test= 0.0104411905631423\n",
      "acc for Lsat= 0.23453354464554405 \n",
      "acc for Psat= 0.3223426038669926 \n",
      "acc for optim= 0.18787622206375976\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.010826348327100277\n",
      "Loss on test= 0.01084870658814907\n",
      "acc for Lsat= 0.30557558079630864 \n",
      "acc for Psat= 0.3166638826589553 \n",
      "acc for optim= 0.17617717297115312\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.01133617665618658\n",
      "Loss on test= 0.01117762178182602\n",
      "acc for Lsat= 0.23050322241112087 \n",
      "acc for Psat= 0.34816844541362385 \n",
      "acc for optim= 0.17618028021585103\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.010290803387761116\n",
      "Loss on test= 0.011589434929192066\n",
      "acc for Lsat= 0.34064854037176306 \n",
      "acc for Psat= 0.32091496723778373 \n",
      "acc for optim= 0.18144855730123882\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.010846013203263283\n",
      "Loss on test= 0.010072204284369946\n",
      "acc for Lsat= 0.2336213193169946 \n",
      "acc for Psat= 0.3061417558346875 \n",
      "acc for optim= 0.17455241591177756\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.010309654287993908\n",
      "Loss on test= 0.010271774604916573\n",
      "acc for Lsat= 0.2349280642215367 \n",
      "acc for Psat= 0.30564559798418683 \n",
      "acc for optim= 0.18643931064060953\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.01049928180873394\n",
      "Loss on test= 0.010909955017268658\n",
      "acc for Lsat= 0.23790623536537955 \n",
      "acc for Psat= 0.3018426732553446 \n",
      "acc for optim= 0.19104382759915833\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.010353846475481987\n",
      "Loss on test= 0.01107674092054367\n",
      "acc for Lsat= 0.27105521237889835 \n",
      "acc for Psat= 0.2821127653355074 \n",
      "acc for optim= 0.1839999564501734\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.010439111851155758\n",
      "Loss on test= 0.011235305108129978\n",
      "acc for Lsat= 0.26415700975937667 \n",
      "acc for Psat= 0.2794482757856934 \n",
      "acc for optim= 0.1724857433496131\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.01068627368658781\n",
      "Loss on test= 0.010570132173597813\n",
      "acc for Lsat= 0.22653910461667692 \n",
      "acc for Psat= 0.31483092443650584 \n",
      "acc for optim= 0.17617057127653105\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.010224263183772564\n",
      "Loss on test= 0.010268967598676682\n",
      "acc for Lsat= 0.23535402308098619 \n",
      "acc for Psat= 0.3398792317413879 \n",
      "acc for optim= 0.18014107246843294\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.01056690327823162\n",
      "Loss on test= 0.010988591238856316\n",
      "acc for Lsat= 0.2857028861062891 \n",
      "acc for Psat= 0.29437135178257545 \n",
      "acc for optim= 0.1700076822244965\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.010152783244848251\n",
      "Loss on test= 0.01063521672040224\n",
      "acc for Lsat= 0.2736864420471279 \n",
      "acc for Psat= 0.26219256432061133 \n",
      "acc for optim= 0.1846430233310113\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.010019940324127674\n",
      "Loss on test= 0.01030665636062622\n",
      "acc for Lsat= 0.23413898217542148 \n",
      "acc for Psat= 0.3109824226563875 \n",
      "acc for optim= 0.17398576029321505\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.010317990556359291\n",
      "Loss on test= 0.010382612235844135\n",
      "acc for Lsat= 0.27019287563047867 \n",
      "acc for Psat= 0.30146807208979765 \n",
      "acc for optim= 0.18359428809659173\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.010743530467152596\n",
      "Loss on test= 0.010857237502932549\n",
      "acc for Lsat= 0.23724642641359792 \n",
      "acc for Psat= 0.31151315293469894 \n",
      "acc for optim= 0.17698107616711609\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.010252411477267742\n",
      "Loss on test= 0.010932928882539272\n",
      "acc for Lsat= 0.2521672669807575 \n",
      "acc for Psat= 0.32081702467866235 \n",
      "acc for optim= 0.19138682218869468\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.010740267112851143\n",
      "Loss on test= 0.010790683329105377\n",
      "acc for Lsat= 0.25144240971526044 \n",
      "acc for Psat= 0.2910050944432245 \n",
      "acc for optim= 0.17691560091751288\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.010294951498508453\n",
      "Loss on test= 0.009840290062129498\n",
      "acc for Lsat= 0.23714544136837012 \n",
      "acc for Psat= 0.3241988799898143 \n",
      "acc for optim= 0.19019836297999015\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.01059647649526596\n",
      "Loss on test= 0.010263420641422272\n",
      "acc for Lsat= 0.2796507561697335 \n",
      "acc for Psat= 0.2756893265291551 \n",
      "acc for optim= 0.17512791111634263\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.010049249045550823\n",
      "Loss on test= 0.009742139838635921\n",
      "acc for Lsat= 0.23821837740015817 \n",
      "acc for Psat= 0.28421242486503023 \n",
      "acc for optim= 0.18696392974045403\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.010713616386055946\n",
      "Loss on test= 0.010860169306397438\n",
      "acc for Lsat= 0.22750926970852683 \n",
      "acc for Psat= 0.38354286941552734 \n",
      "acc for optim= 0.18411452334190914\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.010691571049392223\n",
      "Loss on test= 0.01156720332801342\n",
      "acc for Lsat= 0.3262554983688509 \n",
      "acc for Psat= 0.2951362846982414 \n",
      "acc for optim= 0.18194407002463137\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.010726598091423512\n",
      "Loss on test= 0.00948356930166483\n",
      "acc for Lsat= 0.23280419267202151 \n",
      "acc for Psat= 0.2973857691612392 \n",
      "acc for optim= 0.18067670815169648\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.009922507219016552\n",
      "Loss on test= 0.01050691306591034\n",
      "acc for Lsat= 0.24425022867649818 \n",
      "acc for Psat= 0.2863343537995919 \n",
      "acc for optim= 0.1745384916897377\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.009870546869933605\n",
      "Loss on test= 0.009859529323875904\n",
      "acc for Lsat= 0.24590809753548504 \n",
      "acc for Psat= 0.2884578438295992 \n",
      "acc for optim= 0.18478325520835998\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.009903712198138237\n",
      "Loss on test= 0.01024656929075718\n",
      "acc for Lsat= 0.23570280320662376 \n",
      "acc for Psat= 0.30931763439509047 \n",
      "acc for optim= 0.16867880824655593\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.010078909806907177\n",
      "Loss on test= 0.010127865709364414\n",
      "acc for Lsat= 0.26442021579399855 \n",
      "acc for Psat= 0.2950890484291681 \n",
      "acc for optim= 0.18342068440988196\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.010112720541656017\n",
      "Loss on test= 0.009871674701571465\n",
      "acc for Lsat= 0.23084784989289284 \n",
      "acc for Psat= 0.2997246400470455 \n",
      "acc for optim= 0.18693055923811058\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.00987781397998333\n",
      "Loss on test= 0.009925278834998608\n",
      "acc for Lsat= 0.2409273093401901 \n",
      "acc for Psat= 0.29038018948238065 \n",
      "acc for optim= 0.18285265557111613\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.009903554804623127\n",
      "Loss on test= 0.01032449770718813\n",
      "acc for Lsat= 0.21624195407147873 \n",
      "acc for Psat= 0.33251488191151135 \n",
      "acc for optim= 0.17413226844753907\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.01034089457243681\n",
      "Loss on test= 0.009791883639991283\n",
      "acc for Lsat= 0.24007377037825692 \n",
      "acc for Psat= 0.2791743919102324 \n",
      "acc for optim= 0.17727487823031954\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.009701183065772057\n",
      "Loss on test= 0.0096658356487751\n",
      "acc for Lsat= 0.23484203629148495 \n",
      "acc for Psat= 0.29765254096442684 \n",
      "acc for optim= 0.18230508730369832\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.009794400073587894\n",
      "Loss on test= 0.010850920341908932\n",
      "acc for Lsat= 0.2765796995376976 \n",
      "acc for Psat= 0.30255953109804684 \n",
      "acc for optim= 0.1719820800352298\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.009748436510562897\n",
      "Loss on test= 0.00997677817940712\n",
      "acc for Lsat= 0.23325619075940512 \n",
      "acc for Psat= 0.31294747580958193 \n",
      "acc for optim= 0.1807284385587524\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.009895251132547855\n",
      "Loss on test= 0.01037195697426796\n",
      "acc for Lsat= 0.2784167579101867 \n",
      "acc for Psat= 0.29239323884571233 \n",
      "acc for optim= 0.1776155851840559\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.01015637069940567\n",
      "Loss on test= 0.010087534785270691\n",
      "acc for Lsat= 0.24216639600795256 \n",
      "acc for Psat= 0.28463060657393086 \n",
      "acc for optim= 0.18224690788751152\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.010071884840726852\n",
      "Loss on test= 0.010168716311454773\n",
      "acc for Lsat= 0.22852506676242007 \n",
      "acc for Psat= 0.2769844041489017 \n",
      "acc for optim= 0.17962359827539034\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.01006010826677084\n",
      "Loss on test= 0.009571323171257973\n",
      "acc for Lsat= 0.2113393927580005 \n",
      "acc for Psat= 0.3272766719353574 \n",
      "acc for optim= 0.1822913573527994\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.009557882323861122\n",
      "Loss on test= 0.009700380265712738\n",
      "acc for Lsat= 0.22848008526135172 \n",
      "acc for Psat= 0.2619012642346599 \n",
      "acc for optim= 0.1731751805692093\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.009692855179309845\n",
      "Loss on test= 0.010239342227578163\n",
      "acc for Lsat= 0.25921616092425726 \n",
      "acc for Psat= 0.2821083982969474 \n",
      "acc for optim= 0.1748481296485438\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.009765371680259705\n",
      "Loss on test= 0.009119299240410328\n",
      "acc for Lsat= 0.22998468073579237 \n",
      "acc for Psat= 0.2761940217432975 \n",
      "acc for optim= 0.17445316019891194\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.010204417631030083\n",
      "Loss on test= 0.010028463788330555\n",
      "acc for Lsat= 0.26204966209715586 \n",
      "acc for Psat= 0.28570066953811013 \n",
      "acc for optim= 0.17163675643245666\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.009532012976706028\n",
      "Loss on test= 0.00983670074492693\n",
      "acc for Lsat= 0.22212996334860077 \n",
      "acc for Psat= 0.2779540963088653 \n",
      "acc for optim= 0.17559824600647442\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.009668458253145218\n",
      "Loss on test= 0.009308243170380592\n",
      "acc for Lsat= 0.22827898048008383 \n",
      "acc for Psat= 0.2671079833876197 \n",
      "acc for optim= 0.1737793508275629\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.009521481581032276\n",
      "Loss on test= 0.009749982506036758\n",
      "acc for Lsat= 0.23069746185127943 \n",
      "acc for Psat= 0.3154182892260881 \n",
      "acc for optim= 0.17123052344273626\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.009440653026103973\n",
      "Loss on test= 0.009890623390674591\n",
      "acc for Lsat= 0.24333454871619423 \n",
      "acc for Psat= 0.28068007579713594 \n",
      "acc for optim= 0.17850982311422223\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.009855431504547596\n",
      "Loss on test= 0.009465239010751247\n",
      "acc for Lsat= 0.237432117378056 \n",
      "acc for Psat= 0.2986953157433655 \n",
      "acc for optim= 0.1907470047971819\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.010044492781162262\n",
      "Loss on test= 0.009372528642416\n",
      "acc for Lsat= 0.23299534395030336 \n",
      "acc for Psat= 0.2906903009480212 \n",
      "acc for optim= 0.17719837286141055\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.010081362910568714\n",
      "Loss on test= 0.009220586158335209\n",
      "acc for Lsat= 0.22305449139526604 \n",
      "acc for Psat= 0.2773209022691574 \n",
      "acc for optim= 0.18232459473266144\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.00935585517436266\n",
      "Loss on test= 0.009906208142638206\n",
      "acc for Lsat= 0.22381012091561905 \n",
      "acc for Psat= 0.3199487638666068 \n",
      "acc for optim= 0.17214920793461763\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.009590349160134792\n",
      "Loss on test= 0.009491168893873692\n",
      "acc for Lsat= 0.23029738997964258 \n",
      "acc for Psat= 0.283743043624044 \n",
      "acc for optim= 0.18741081517588543\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.009328332729637623\n",
      "Loss on test= 0.009190725162625313\n",
      "acc for Lsat= 0.22182651769243594 \n",
      "acc for Psat= 0.27928603897335297 \n",
      "acc for optim= 0.17700609166766643\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.009475328028202057\n",
      "Loss on test= 0.00868881307542324\n",
      "acc for Lsat= 0.2150383920584195 \n",
      "acc for Psat= 0.2927728889390474 \n",
      "acc for optim= 0.17253524174246784\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.009834777563810349\n",
      "Loss on test= 0.009760504588484764\n",
      "acc for Lsat= 0.2387293309543197 \n",
      "acc for Psat= 0.2548486752238131 \n",
      "acc for optim= 0.16731396217270428\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.00942173134535551\n",
      "Loss on test= 0.009330186061561108\n",
      "acc for Lsat= 0.2115903308176958 \n",
      "acc for Psat= 0.28391013210765215 \n",
      "acc for optim= 0.18861232437661415\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.009168259799480438\n",
      "Loss on test= 0.01027190312743187\n",
      "acc for Lsat= 0.21200290892227566 \n",
      "acc for Psat= 0.32270302371880216 \n",
      "acc for optim= 0.18389925770178386\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.009496698155999184\n",
      "Loss on test= 0.01006392017006874\n",
      "acc for Lsat= 0.2358357622948903 \n",
      "acc for Psat= 0.2760837681943903 \n",
      "acc for optim= 0.17594905937763494\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.009526747278869152\n",
      "Loss on test= 0.009424900636076927\n",
      "acc for Lsat= 0.2386411456283059 \n",
      "acc for Psat= 0.27213234660794605 \n",
      "acc for optim= 0.17283118453751495\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.00958213396370411\n",
      "Loss on test= 0.010444596409797668\n",
      "acc for Lsat= 0.20990890584087882 \n",
      "acc for Psat= 0.3114423067521342 \n",
      "acc for optim= 0.1744758931470003\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.009602281264960766\n",
      "Loss on test= 0.009241322055459023\n",
      "acc for Lsat= 0.21922621629346395 \n",
      "acc for Psat= 0.2649051835465503 \n",
      "acc for optim= 0.16813145453311704\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.009138353168964386\n",
      "Loss on test= 0.00934828445315361\n",
      "acc for Lsat= 0.2529574647487607 \n",
      "acc for Psat= 0.2675411885294936 \n",
      "acc for optim= 0.18405298261299124\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.009584682062268257\n",
      "Loss on test= 0.009040053933858871\n",
      "acc for Lsat= 0.22075324994511902 \n",
      "acc for Psat= 0.27618511562232506 \n",
      "acc for optim= 0.1884857716320373\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.009362174198031425\n",
      "Loss on test= 0.009441480040550232\n",
      "acc for Lsat= 0.2007085198494826 \n",
      "acc for Psat= 0.25756073456894324 \n",
      "acc for optim= 0.16855386395528094\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.009054980240762234\n",
      "Loss on test= 0.009655281901359558\n",
      "acc for Lsat= 0.22337187676552078 \n",
      "acc for Psat= 0.28123750875474307 \n",
      "acc for optim= 0.16948591384877815\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.009058506228029728\n",
      "Loss on test= 0.009412361308932304\n",
      "acc for Lsat= 0.2507090237628487 \n",
      "acc for Psat= 0.2664577935128624 \n",
      "acc for optim= 0.17162116186522622\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.00915435142815113\n",
      "Loss on test= 0.009950568899512291\n",
      "acc for Lsat= 0.22955737386468714 \n",
      "acc for Psat= 0.2785909405321109 \n",
      "acc for optim= 0.18899249827075904\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.009374704211950302\n",
      "Loss on test= 0.009346085600554943\n",
      "acc for Lsat= 0.21905246083435878 \n",
      "acc for Psat= 0.2905480872015343 \n",
      "acc for optim= 0.17635685343801114\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.00954995397478342\n",
      "Loss on test= 0.008991923183202744\n",
      "acc for Lsat= 0.20795449948134873 \n",
      "acc for Psat= 0.2858873228643534 \n",
      "acc for optim= 0.18146976972403117\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.010185468941926956\n",
      "Loss on test= 0.009685775265097618\n",
      "acc for Lsat= 0.21917087905741348 \n",
      "acc for Psat= 0.31321879064332303 \n",
      "acc for optim= 0.17993152653503489\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.009288318455219269\n",
      "Loss on test= 0.009142283350229263\n",
      "acc for Lsat= 0.23708368661720816 \n",
      "acc for Psat= 0.257657401682278 \n",
      "acc for optim= 0.16886070938075923\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.008951078169047832\n",
      "Loss on test= 0.009191431105136871\n",
      "acc for Lsat= 0.20403083654703033 \n",
      "acc for Psat= 0.306828113876494 \n",
      "acc for optim= 0.18075526306150808\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.009096856229007244\n",
      "Loss on test= 0.009105095639824867\n",
      "acc for Lsat= 0.2105966825665992 \n",
      "acc for Psat= 0.2618384859331461 \n",
      "acc for optim= 0.16980952022149232\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.009247508831322193\n",
      "Loss on test= 0.009249674156308174\n",
      "acc for Lsat= 0.2751721254952261 \n",
      "acc for Psat= 0.26930085261945447 \n",
      "acc for optim= 0.17059345033930404\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.008924087509512901\n",
      "Loss on test= 0.009050795808434486\n",
      "acc for Lsat= 0.21241504211345297 \n",
      "acc for Psat= 0.27331828066353164 \n",
      "acc for optim= 0.18042763917352156\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.008899109438061714\n",
      "Loss on test= 0.008146517910063267\n",
      "acc for Lsat= 0.2125868469365004 \n",
      "acc for Psat= 0.25226031276995214 \n",
      "acc for optim= 0.18155472813727888\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.009031719528138638\n",
      "Loss on test= 0.009282859973609447\n",
      "acc for Lsat= 0.20837227967048594 \n",
      "acc for Psat= 0.27298731875536664 \n",
      "acc for optim= 0.1779365239448302\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.00908729899674654\n",
      "Loss on test= 0.008830595761537552\n",
      "acc for Lsat= 0.20902911976146563 \n",
      "acc for Psat= 0.28284108381882794 \n",
      "acc for optim= 0.18627453810896022\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.00927476491779089\n",
      "Loss on test= 0.009537278674542904\n",
      "acc for Lsat= 0.2050360864825937 \n",
      "acc for Psat= 0.2902107009114253 \n",
      "acc for optim= 0.17806603412700006\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.00872119702398777\n",
      "Loss on test= 0.008747538551688194\n",
      "acc for Lsat= 0.1940955318419288 \n",
      "acc for Psat= 0.25667367599797564 \n",
      "acc for optim= 0.16893505010965462\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.008761892095208168\n",
      "Loss on test= 0.008872774429619312\n",
      "acc for Lsat= 0.18368554245869353 \n",
      "acc for Psat= 0.26534386377819386 \n",
      "acc for optim= 0.17818650613461048\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.00873717200011015\n",
      "Loss on test= 0.00936717540025711\n",
      "acc for Lsat= 0.19552904619332687 \n",
      "acc for Psat= 0.27946088101708555 \n",
      "acc for optim= 0.17334075660894727\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.008875259198248386\n",
      "Loss on test= 0.00853538978844881\n",
      "acc for Lsat= 0.2052837545178025 \n",
      "acc for Psat= 0.2842995515173833 \n",
      "acc for optim= 0.17071049788461784\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.008765229023993015\n",
      "Loss on test= 0.009342547506093979\n",
      "acc for Lsat= 0.20424388045078534 \n",
      "acc for Psat= 0.30299796870550944 \n",
      "acc for optim= 0.17383857710504075\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.00901927798986435\n",
      "Loss on test= 0.009303649887442589\n",
      "acc for Lsat= 0.1877980238181457 \n",
      "acc for Psat= 0.2979024678003731 \n",
      "acc for optim= 0.19085712580468878\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.008805532939732075\n",
      "Loss on test= 0.009095330722630024\n",
      "acc for Lsat= 0.19969853856978384 \n",
      "acc for Psat= 0.2801744647023608 \n",
      "acc for optim= 0.16641399108649804\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.008461221121251583\n",
      "Loss on test= 0.008799738250672817\n",
      "acc for Lsat= 0.19666461782558267 \n",
      "acc for Psat= 0.2827927563977593 \n",
      "acc for optim= 0.1814831376885785\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.008570481091737747\n",
      "Loss on test= 0.009512478485703468\n",
      "acc for Lsat= 0.1881719808693192 \n",
      "acc for Psat= 0.2536672621153647 \n",
      "acc for optim= 0.1693587325840486\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.008709456771612167\n",
      "Loss on test= 0.0086490074172616\n",
      "acc for Lsat= 0.17639797487786504 \n",
      "acc for Psat= 0.2730461072894065 \n",
      "acc for optim= 0.19735468168683173\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.008699127472937107\n",
      "Loss on test= 0.008971711620688438\n",
      "acc for Lsat= 0.20879104932671022 \n",
      "acc for Psat= 0.24582757307522313 \n",
      "acc for optim= 0.17319731312415348\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.008654840290546417\n",
      "Loss on test= 0.010021790862083435\n",
      "acc for Lsat= 0.2526388666418997 \n",
      "acc for Psat= 0.25527169405973543 \n",
      "acc for optim= 0.1750668436975625\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.008845177479088306\n",
      "Loss on test= 0.008620199747383595\n",
      "acc for Lsat= 0.2046837312411108 \n",
      "acc for Psat= 0.2626244034020331 \n",
      "acc for optim= 0.17167058960881518\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.008706926368176937\n",
      "Loss on test= 0.008577543310821056\n",
      "acc for Lsat= 0.1891101625958834 \n",
      "acc for Psat= 0.26298103387002686 \n",
      "acc for optim= 0.1751953377338027\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.00853071827441454\n",
      "Loss on test= 0.009399858303368092\n",
      "acc for Lsat= 0.245955461947282 \n",
      "acc for Psat= 0.24899903877097107 \n",
      "acc for optim= 0.168711648700795\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.008613386191427708\n",
      "Loss on test= 0.009300203062593937\n",
      "acc for Lsat= 0.20213307892825813 \n",
      "acc for Psat= 0.2907150076887872 \n",
      "acc for optim= 0.179341884354496\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.008541097864508629\n",
      "Loss on test= 0.008465512655675411\n",
      "acc for Lsat= 0.20219368539275476 \n",
      "acc for Psat= 0.2598070406729184 \n",
      "acc for optim= 0.18766066442993032\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.008327766321599483\n",
      "Loss on test= 0.008435074239969254\n",
      "acc for Lsat= 0.21857976236237478 \n",
      "acc for Psat= 0.25760722898613075 \n",
      "acc for optim= 0.17660469748040447\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.00825390126556158\n",
      "Loss on test= 0.009165659546852112\n",
      "acc for Lsat= 0.19786309826776158 \n",
      "acc for Psat= 0.24345567712648394 \n",
      "acc for optim= 0.17526887480102774\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.008599947206676006\n",
      "Loss on test= 0.009414246305823326\n",
      "acc for Lsat= 0.21070501347925086 \n",
      "acc for Psat= 0.31431932767579407 \n",
      "acc for optim= 0.18111035956787197\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.008735084906220436\n",
      "Loss on test= 0.00834803469479084\n",
      "acc for Lsat= 0.19786625213758247 \n",
      "acc for Psat= 0.2500134354133381 \n",
      "acc for optim= 0.17343188221137687\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.008266790769994259\n",
      "Loss on test= 0.008873621001839638\n",
      "acc for Lsat= 0.2260629006455388 \n",
      "acc for Psat= 0.254074931910853 \n",
      "acc for optim= 0.169616563844329\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.00831801537424326\n",
      "Loss on test= 0.007863100618124008\n",
      "acc for Lsat= 0.17773571109373243 \n",
      "acc for Psat= 0.23460139807787994 \n",
      "acc for optim= 0.17010268821351585\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.008541438728570938\n",
      "Loss on test= 0.0082912752404809\n",
      "acc for Lsat= 0.18497896596867625 \n",
      "acc for Psat= 0.2533992532174346 \n",
      "acc for optim= 0.16653528588908925\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.008565736003220081\n",
      "Loss on test= 0.00895760953426361\n",
      "acc for Lsat= 0.22792045109580047 \n",
      "acc for Psat= 0.24745497182271178 \n",
      "acc for optim= 0.1747716877847828\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.00863595213741064\n",
      "Loss on test= 0.009566329419612885\n",
      "acc for Lsat= 0.25870093642122416 \n",
      "acc for Psat= 0.2569349412342244 \n",
      "acc for optim= 0.18003407341362815\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.008646395057439804\n",
      "Loss on test= 0.009168232791125774\n",
      "acc for Lsat= 0.17992997974530178 \n",
      "acc for Psat= 0.25718884636070644 \n",
      "acc for optim= 0.17434650026867482\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.008709617890417576\n",
      "Loss on test= 0.008816155605018139\n",
      "acc for Lsat= 0.20713061426506493 \n",
      "acc for Psat= 0.251234412973399 \n",
      "acc for optim= 0.17369279286268047\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.008971109054982662\n",
      "Loss on test= 0.010056921280920506\n",
      "acc for Lsat= 0.29335932301458073 \n",
      "acc for Psat= 0.2663047482632022 \n",
      "acc for optim= 0.17066126331337728\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.009050928987562656\n",
      "Loss on test= 0.008963029831647873\n",
      "acc for Lsat= 0.2072469543144925 \n",
      "acc for Psat= 0.2371066760553387 \n",
      "acc for optim= 0.175879559467855\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.008391965180635452\n",
      "Loss on test= 0.008706397376954556\n",
      "acc for Lsat= 0.21225979680920737 \n",
      "acc for Psat= 0.2587210117934454 \n",
      "acc for optim= 0.16960600289835506\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.008203213103115559\n",
      "Loss on test= 0.008630240336060524\n",
      "acc for Lsat= 0.1752903677353626 \n",
      "acc for Psat= 0.2869390750864703 \n",
      "acc for optim= 0.17910174876404297\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.008859717287123203\n",
      "Loss on test= 0.00836056750267744\n",
      "acc for Lsat= 0.1794682425591885 \n",
      "acc for Psat= 0.267370124866854 \n",
      "acc for optim= 0.16737571983075877\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.008061712607741356\n",
      "Loss on test= 0.008206807076931\n",
      "acc for Lsat= 0.1847065834042066 \n",
      "acc for Psat= 0.250391743239856 \n",
      "acc for optim= 0.1672218434583015\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.008292955346405506\n",
      "Loss on test= 0.008140652440488338\n",
      "acc for Lsat= 0.17284610078255552 \n",
      "acc for Psat= 0.27467012425129084 \n",
      "acc for optim= 0.1773626410144356\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.008379412814974785\n",
      "Loss on test= 0.008455196395516396\n",
      "acc for Lsat= 0.1759548223393771 \n",
      "acc for Psat= 0.29693719727298673 \n",
      "acc for optim= 0.1720813505486837\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.008752651512622833\n",
      "Loss on test= 0.00834260880947113\n",
      "acc for Lsat= 0.19124217894686563 \n",
      "acc for Psat= 0.23686361886054352 \n",
      "acc for optim= 0.17669838542516683\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.008464165031909943\n",
      "Loss on test= 0.008268526755273342\n",
      "acc for Lsat= 0.19348837031410202 \n",
      "acc for Psat= 0.23520161761710345 \n",
      "acc for optim= 0.17467042912697228\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.008199004456400871\n",
      "Loss on test= 0.008609464392066002\n",
      "acc for Lsat= 0.19538131181124718 \n",
      "acc for Psat= 0.264864959631268 \n",
      "acc for optim= 0.17684426778243897\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.00805534329265356\n",
      "Loss on test= 0.008552986197173595\n",
      "acc for Lsat= 0.17943189421163658 \n",
      "acc for Psat= 0.2434128048987839 \n",
      "acc for optim= 0.1681870940020245\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.008106179535388947\n",
      "Loss on test= 0.008375314064323902\n",
      "acc for Lsat= 0.2002270093498983 \n",
      "acc for Psat= 0.23713342214806116 \n",
      "acc for optim= 0.17602222205872797\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.008280232548713684\n",
      "Loss on test= 0.008668508380651474\n",
      "acc for Lsat= 0.22606316565833293 \n",
      "acc for Psat= 0.24703896225686106 \n",
      "acc for optim= 0.17034841128849154\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.008299130015075207\n",
      "Loss on test= 0.008458142168819904\n",
      "acc for Lsat= 0.21579223306793752 \n",
      "acc for Psat= 0.22895038800507372 \n",
      "acc for optim= 0.18295613003106523\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.008212137967348099\n",
      "Loss on test= 0.008107449859380722\n",
      "acc for Lsat= 0.1691554174403545 \n",
      "acc for Psat= 0.2276588155704352 \n",
      "acc for optim= 0.17725454866939724\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.008015437051653862\n",
      "Loss on test= 0.008327704854309559\n",
      "acc for Lsat= 0.17449850058442648 \n",
      "acc for Psat= 0.2608963462376237 \n",
      "acc for optim= 0.17736669068835909\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.008568662218749523\n",
      "Loss on test= 0.008668171241879463\n",
      "acc for Lsat= 0.20369408473905767 \n",
      "acc for Psat= 0.24214912041301234 \n",
      "acc for optim= 0.1846856377764001\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.008351998403668404\n",
      "Loss on test= 0.007977369241416454\n",
      "acc for Lsat= 0.16742566851757443 \n",
      "acc for Psat= 0.2102811305350794 \n",
      "acc for optim= 0.17055106496735714\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.007987906225025654\n",
      "Loss on test= 0.008148650638759136\n",
      "acc for Lsat= 0.17284383557386251 \n",
      "acc for Psat= 0.25225050413860733 \n",
      "acc for optim= 0.17597612324430342\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.008000688627362251\n",
      "Loss on test= 0.007907691411674023\n",
      "acc for Lsat= 0.17261383613898745 \n",
      "acc for Psat= 0.2275711135951349 \n",
      "acc for optim= 0.16837437003709352\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.00875310692936182\n",
      "Loss on test= 0.01008019968867302\n",
      "acc for Lsat= 0.2614327939105302 \n",
      "acc for Psat= 0.2534746158454574 \n",
      "acc for optim= 0.1682934401713381\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.008789163082838058\n",
      "Loss on test= 0.008143153972923756\n",
      "acc for Lsat= 0.1732505305435798 \n",
      "acc for Psat= 0.25404921208737996 \n",
      "acc for optim= 0.17614691337469077\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.008011008612811565\n",
      "Loss on test= 0.008310464210808277\n",
      "acc for Lsat= 0.19608726524716444 \n",
      "acc for Psat= 0.24210767604873162 \n",
      "acc for optim= 0.16513109603225973\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.008028469979763031\n",
      "Loss on test= 0.00885014422237873\n",
      "acc for Lsat= 0.21312058132458037 \n",
      "acc for Psat= 0.256829728687031 \n",
      "acc for optim= 0.17096932738342877\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.008390538394451141\n",
      "Loss on test= 0.008814861066639423\n",
      "acc for Lsat= 0.1803003055589412 \n",
      "acc for Psat= 0.27357643225892586 \n",
      "acc for optim= 0.17760074038941073\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.008285416290163994\n",
      "Loss on test= 0.008069994859397411\n",
      "acc for Lsat= 0.1661965041442985 \n",
      "acc for Psat= 0.21821623200446846 \n",
      "acc for optim= 0.17295834902521362\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.008455269038677216\n",
      "Loss on test= 0.00852466281503439\n",
      "acc for Lsat= 0.17505581793571962 \n",
      "acc for Psat= 0.23960487785233134 \n",
      "acc for optim= 0.1681931801987859\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.008388458751142025\n",
      "Loss on test= 0.007729941047728062\n",
      "acc for Lsat= 0.17417445057371633 \n",
      "acc for Psat= 0.2362563912616138 \n",
      "acc for optim= 0.18087811886407262\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.008199280127882957\n",
      "Loss on test= 0.00833809096366167\n",
      "acc for Lsat= 0.18215776095894398 \n",
      "acc for Psat= 0.2485205341222231 \n",
      "acc for optim= 0.1820359666877217\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.008020054548978806\n",
      "Loss on test= 0.007863861508667469\n",
      "acc for Lsat= 0.16960005709591536 \n",
      "acc for Psat= 0.22476320821304988 \n",
      "acc for optim= 0.16801160520648212\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.007968856021761894\n",
      "Loss on test= 0.00802052952349186\n",
      "acc for Lsat= 0.17535514008537773 \n",
      "acc for Psat= 0.2272394246742683 \n",
      "acc for optim= 0.1758189986232193\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.007803063839673996\n",
      "Loss on test= 0.007806827314198017\n",
      "acc for Lsat= 0.16333270833554805 \n",
      "acc for Psat= 0.24799796781224212 \n",
      "acc for optim= 0.16861827329597184\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.008005611598491669\n",
      "Loss on test= 0.008572479709982872\n",
      "acc for Lsat= 0.21555126551504292 \n",
      "acc for Psat= 0.25313229309284835 \n",
      "acc for optim= 0.16492297529397104\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.00789160281419754\n",
      "Loss on test= 0.008387249894440174\n",
      "acc for Lsat= 0.16210829300632976 \n",
      "acc for Psat= 0.24337140240763924 \n",
      "acc for optim= 0.17979587553113438\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.007933915592730045\n",
      "Loss on test= 0.007787703536450863\n",
      "acc for Lsat= 0.1792329981654876 \n",
      "acc for Psat= 0.23597097172672432 \n",
      "acc for optim= 0.16934985381260195\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.007853484712541103\n",
      "Loss on test= 0.007428513839840889\n",
      "acc for Lsat= 0.18921250683769283 \n",
      "acc for Psat= 0.23521111360231944 \n",
      "acc for optim= 0.16800081782846088\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.00782942958176136\n",
      "Loss on test= 0.008118421770632267\n",
      "acc for Lsat= 0.17437355796966977 \n",
      "acc for Psat= 0.2483585418360874 \n",
      "acc for optim= 0.17338593543044645\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.008125686086714268\n",
      "Loss on test= 0.00858492124825716\n",
      "acc for Lsat= 0.1636627265637602 \n",
      "acc for Psat= 0.269368781881624 \n",
      "acc for optim= 0.1667229435826099\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.008320475928485394\n",
      "Loss on test= 0.00809651892632246\n",
      "acc for Lsat= 0.16964034033790576 \n",
      "acc for Psat= 0.2391430192306084 \n",
      "acc for optim= 0.17260031840929957\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.00782719999551773\n",
      "Loss on test= 0.007774644531309605\n",
      "acc for Lsat= 0.1660385286078373 \n",
      "acc for Psat= 0.2398687226802419 \n",
      "acc for optim= 0.17548916428633085\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.008293967694044113\n",
      "Loss on test= 0.00766843231394887\n",
      "acc for Lsat= 0.17152337295969167 \n",
      "acc for Psat= 0.2391450303430493 \n",
      "acc for optim= 0.16868000941729014\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.008074462413787842\n",
      "Loss on test= 0.007565511390566826\n",
      "acc for Lsat= 0.16215511535631014 \n",
      "acc for Psat= 0.23704999875366953 \n",
      "acc for optim= 0.17423224272219207\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.00783390924334526\n",
      "Loss on test= 0.0075339642353355885\n",
      "acc for Lsat= 0.1795055532944954 \n",
      "acc for Psat= 0.22812450410354948 \n",
      "acc for optim= 0.18195553346457607\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.00790594145655632\n",
      "Loss on test= 0.008088937029242516\n",
      "acc for Lsat= 0.19854618499517232 \n",
      "acc for Psat= 0.23731648279155362 \n",
      "acc for optim= 0.1742768832600386\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.007994786836206913\n",
      "Loss on test= 0.008428547531366348\n",
      "acc for Lsat= 0.1874872410543675 \n",
      "acc for Psat= 0.24913463657454438 \n",
      "acc for optim= 0.165826322329677\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.007754995487630367\n",
      "Loss on test= 0.008307138457894325\n",
      "acc for Lsat= 0.16591041202903128 \n",
      "acc for Psat= 0.27777872384900254 \n",
      "acc for optim= 0.17027593982286793\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.007523201871663332\n",
      "Loss on test= 0.007922115735709667\n",
      "acc for Lsat= 0.16347296315861232 \n",
      "acc for Psat= 0.23556197193170805 \n",
      "acc for optim= 0.17195950729070023\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.007662697229534388\n",
      "Loss on test= 0.008234905079007149\n",
      "acc for Lsat= 0.16878463414104772 \n",
      "acc for Psat= 0.24708094051321322 \n",
      "acc for optim= 0.1659462670889027\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.007784280460327864\n",
      "Loss on test= 0.007901804521679878\n",
      "acc for Lsat= 0.18127997170990598 \n",
      "acc for Psat= 0.22761160919499407 \n",
      "acc for optim= 0.17365726625162958\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.007759250234812498\n",
      "Loss on test= 0.00811127107590437\n",
      "acc for Lsat= 0.193812279136477 \n",
      "acc for Psat= 0.2361252605584702 \n",
      "acc for optim= 0.1965890441284943\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.007968909107148647\n",
      "Loss on test= 0.008043671026825905\n",
      "acc for Lsat= 0.1818432572787011 \n",
      "acc for Psat= 0.2617066982852152 \n",
      "acc for optim= 0.17640078853740282\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.007863190956413746\n",
      "Loss on test= 0.008053719997406006\n",
      "acc for Lsat= 0.17391622451415625 \n",
      "acc for Psat= 0.2223246603925135 \n",
      "acc for optim= 0.174167446707174\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.008183741942048073\n",
      "Loss on test= 0.008616470731794834\n",
      "acc for Lsat= 0.20059743385064469 \n",
      "acc for Psat= 0.24692392426112672 \n",
      "acc for optim= 0.17419078816388917\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.008097950369119644\n",
      "Loss on test= 0.00769998412579298\n",
      "acc for Lsat= 0.19422505418259714 \n",
      "acc for Psat= 0.23557934053767254 \n",
      "acc for optim= 0.17819496185040554\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.0077588846907019615\n",
      "Loss on test= 0.008622722700238228\n",
      "acc for Lsat= 0.19851359232435808 \n",
      "acc for Psat= 0.23506412243256597 \n",
      "acc for optim= 0.16894951780292056\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.008192856796085835\n",
      "Loss on test= 0.007818798534572124\n",
      "acc for Lsat= 0.19125395920727406 \n",
      "acc for Psat= 0.21082242621373184 \n",
      "acc for optim= 0.1823787075240083\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.007777438964694738\n",
      "Loss on test= 0.00750441150739789\n",
      "acc for Lsat= 0.16236058186085436 \n",
      "acc for Psat= 0.22201959850310624 \n",
      "acc for optim= 0.1650822903222335\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.007862701080739498\n",
      "Loss on test= 0.00784191396087408\n",
      "acc for Lsat= 0.167439781574226 \n",
      "acc for Psat= 0.26366917577035714 \n",
      "acc for optim= 0.16672001318570315\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.008178574033081532\n",
      "Loss on test= 0.007755003869533539\n",
      "acc for Lsat= 0.1735777857483717 \n",
      "acc for Psat= 0.22658006335739236 \n",
      "acc for optim= 0.17572809158092068\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.007761634420603514\n",
      "Loss on test= 0.007841315120458603\n",
      "acc for Lsat= 0.19178385278605306 \n",
      "acc for Psat= 0.23118364879376935 \n",
      "acc for optim= 0.17799040689007253\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.007424334995448589\n",
      "Loss on test= 0.007877686992287636\n",
      "acc for Lsat= 0.16532233881770406 \n",
      "acc for Psat= 0.24621580985557237 \n",
      "acc for optim= 0.17974819660589306\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.007550602778792381\n",
      "Loss on test= 0.0075709144584834576\n",
      "acc for Lsat= 0.16157864417901519 \n",
      "acc for Psat= 0.22522047329796288 \n",
      "acc for optim= 0.17389843835455296\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.007530471310019493\n",
      "Loss on test= 0.00921783596277237\n",
      "acc for Lsat= 0.23787056470708293 \n",
      "acc for Psat= 0.25239804184152365 \n",
      "acc for optim= 0.16676723923317055\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.007680217735469341\n",
      "Loss on test= 0.007624115329235792\n",
      "acc for Lsat= 0.17100067225050766 \n",
      "acc for Psat= 0.2214990704710913 \n",
      "acc for optim= 0.1673140117711375\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.0075375656597316265\n",
      "Loss on test= 0.00755448779091239\n",
      "acc for Lsat= 0.15826582881340615 \n",
      "acc for Psat= 0.24798476880115797 \n",
      "acc for optim= 0.17733998695188644\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.007880971767008305\n",
      "Loss on test= 0.0077201384119689465\n",
      "acc for Lsat= 0.15470091290842755 \n",
      "acc for Psat= 0.2509327749363807 \n",
      "acc for optim= 0.1783850849122344\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.0077373674139380455\n",
      "Loss on test= 0.007732825353741646\n",
      "acc for Lsat= 0.15968299628405697 \n",
      "acc for Psat= 0.2297599119019651 \n",
      "acc for optim= 0.16875416575144422\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.007753975223749876\n",
      "Loss on test= 0.007751058787107468\n",
      "acc for Lsat= 0.157742042748617 \n",
      "acc for Psat= 0.2218646006790427 \n",
      "acc for optim= 0.1690925360701324\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.007810722105205059\n",
      "Loss on test= 0.00831714179366827\n",
      "acc for Lsat= 0.1681277496241524 \n",
      "acc for Psat= 0.32121467871301984 \n",
      "acc for optim= 0.17694064432047574\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.007866550236940384\n",
      "Loss on test= 0.007666085846722126\n",
      "acc for Lsat= 0.15111912815041864 \n",
      "acc for Psat= 0.2401638445200562 \n",
      "acc for optim= 0.1681194441785133\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.007500919979065657\n",
      "Loss on test= 0.007587405387312174\n",
      "acc for Lsat= 0.15796873195565264 \n",
      "acc for Psat= 0.2221953600674169 \n",
      "acc for optim= 0.16933656510947323\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.007328355684876442\n",
      "Loss on test= 0.008101513609290123\n",
      "acc for Lsat= 0.19771820526551204 \n",
      "acc for Psat= 0.22904869817648432 \n",
      "acc for optim= 0.16734453535212418\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.007898300886154175\n",
      "Loss on test= 0.00846766121685505\n",
      "acc for Lsat= 0.22229120614918282 \n",
      "acc for Psat= 0.21581574982563914 \n",
      "acc for optim= 0.17722594866692717\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.00774986669421196\n",
      "Loss on test= 0.008554966188967228\n",
      "acc for Lsat= 0.1934065614332212 \n",
      "acc for Psat= 0.24978027138796105 \n",
      "acc for optim= 0.16791034204173205\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.008042365312576294\n",
      "Loss on test= 0.008287970907986164\n",
      "acc for Lsat= 0.16221701856930676 \n",
      "acc for Psat= 0.25027549388598985 \n",
      "acc for optim= 0.17163027729131156\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.007985277101397514\n",
      "Loss on test= 0.008183649741113186\n",
      "acc for Lsat= 0.18945400894861794 \n",
      "acc for Psat= 0.23332973177241148 \n",
      "acc for optim= 0.16462322060180815\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.00806309562176466\n",
      "Loss on test= 0.007348530925810337\n",
      "acc for Lsat= 0.1741232508258592 \n",
      "acc for Psat= 0.22167359971216363 \n",
      "acc for optim= 0.1690757353009414\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.007517005316913128\n",
      "Loss on test= 0.007970558479428291\n",
      "acc for Lsat= 0.17230424970089311 \n",
      "acc for Psat= 0.229979149679452 \n",
      "acc for optim= 0.16911534374712328\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.007539193145930767\n",
      "Loss on test= 0.007416038773953915\n",
      "acc for Lsat= 0.15501646268908312 \n",
      "acc for Psat= 0.23229659770545 \n",
      "acc for optim= 0.1781495333605169\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.007442650850862265\n",
      "Loss on test= 0.00799337588250637\n",
      "acc for Lsat= 0.16195603225079705 \n",
      "acc for Psat= 0.25389192372942393 \n",
      "acc for optim= 0.17995773086314895\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.007693805266171694\n",
      "Loss on test= 0.008074238896369934\n",
      "acc for Lsat= 0.16820124587330437 \n",
      "acc for Psat= 0.2421685413621064 \n",
      "acc for optim= 0.17384605719731505\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.007739925291389227\n",
      "Loss on test= 0.0075139207765460014\n",
      "acc for Lsat= 0.1586237678210317 \n",
      "acc for Psat= 0.21849590253673096 \n",
      "acc for optim= 0.16852022279616338\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.0073285759426653385\n",
      "Loss on test= 0.00731676584109664\n",
      "acc for Lsat= 0.17049241840573517 \n",
      "acc for Psat= 0.21970319230299415 \n",
      "acc for optim= 0.16214895190087436\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.00740841357037425\n",
      "Loss on test= 0.007231174502521753\n",
      "acc for Lsat= 0.1673638376264166 \n",
      "acc for Psat= 0.21716520399707873 \n",
      "acc for optim= 0.1764606860221672\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.007237148005515337\n",
      "Loss on test= 0.007528056390583515\n",
      "acc for Lsat= 0.16630639452823498 \n",
      "acc for Psat= 0.22116187527343928 \n",
      "acc for optim= 0.17059718056805503\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.007345124147832394\n",
      "Loss on test= 0.007184392772614956\n",
      "acc for Lsat= 0.16110394837596687 \n",
      "acc for Psat= 0.21254233535630093 \n",
      "acc for optim= 0.17069040852191\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.007378913927823305\n",
      "Loss on test= 0.008220717310905457\n",
      "acc for Lsat= 0.21458414528358452 \n",
      "acc for Psat= 0.22641761185533707 \n",
      "acc for optim= 0.17139272174343304\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.007372343447059393\n",
      "Loss on test= 0.007354806177318096\n",
      "acc for Lsat= 0.1498093406840977 \n",
      "acc for Psat= 0.23684240726445727 \n",
      "acc for optim= 0.1719121113734169\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.007771181408315897\n",
      "Loss on test= 0.00712035084143281\n",
      "acc for Lsat= 0.16811423297307604 \n",
      "acc for Psat= 0.2113340835666153 \n",
      "acc for optim= 0.1768600059719599\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.007625148631632328\n",
      "Loss on test= 0.007568510714918375\n",
      "acc for Lsat= 0.14579774143242724 \n",
      "acc for Psat= 0.22326448428361187 \n",
      "acc for optim= 0.1690848153611532\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.007766188122332096\n",
      "Loss on test= 0.00792522169649601\n",
      "acc for Lsat= 0.16882090727724702 \n",
      "acc for Psat= 0.2458773483214483 \n",
      "acc for optim= 0.1761211425705492\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.007515391334891319\n",
      "Loss on test= 0.007464537862688303\n",
      "acc for Lsat= 0.17688448435684542 \n",
      "acc for Psat= 0.22073575803094442 \n",
      "acc for optim= 0.17818870760360417\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.007504772394895554\n",
      "Loss on test= 0.007755683735013008\n",
      "acc for Lsat= 0.1592114206740351 \n",
      "acc for Psat= 0.23989821998255237 \n",
      "acc for optim= 0.17568699406783217\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.007986774668097496\n",
      "Loss on test= 0.007328479550778866\n",
      "acc for Lsat= 0.15663166925008448 \n",
      "acc for Psat= 0.21755236965475125 \n",
      "acc for optim= 0.17094638777721352\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.007509348448365927\n",
      "Loss on test= 0.0087171271443367\n",
      "acc for Lsat= 0.22468848243890435 \n",
      "acc for Psat= 0.2282416854257069 \n",
      "acc for optim= 0.1677108670669809\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.007885742001235485\n",
      "Loss on test= 0.0077671571634709835\n",
      "acc for Lsat= 0.1652643798376163 \n",
      "acc for Psat= 0.2496958470571396 \n",
      "acc for optim= 0.164188161595391\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.007577922660857439\n",
      "Loss on test= 0.00739323440939188\n",
      "acc for Lsat= 0.1604284553248215 \n",
      "acc for Psat= 0.22271067857493748 \n",
      "acc for optim= 0.17749353838145318\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.00750746950507164\n",
      "Loss on test= 0.007515996694564819\n",
      "acc for Lsat= 0.17471199462837633 \n",
      "acc for Psat= 0.2545846231157673 \n",
      "acc for optim= 0.17498679045938598\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.007254358846694231\n",
      "Loss on test= 0.008667695336043835\n",
      "acc for Lsat= 0.17751924121654844 \n",
      "acc for Psat= 0.30630640745771787 \n",
      "acc for optim= 0.17877817358358034\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.007710728794336319\n",
      "Loss on test= 0.007301471661776304\n",
      "acc for Lsat= 0.1431579325860209 \n",
      "acc for Psat= 0.24047117785340635 \n",
      "acc for optim= 0.16653694988869844\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.007224445231258869\n",
      "Loss on test= 0.00792879518121481\n",
      "acc for Lsat= 0.16996656418258854 \n",
      "acc for Psat= 0.26673104912215667 \n",
      "acc for optim= 0.1675566562409733\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.007438192144036293\n",
      "Loss on test= 0.007452241610735655\n",
      "acc for Lsat= 0.1618116640794953 \n",
      "acc for Psat= 0.21160406266977047 \n",
      "acc for optim= 0.1730565601193686\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.007345580030232668\n",
      "Loss on test= 0.007652125786989927\n",
      "acc for Lsat= 0.15718823999997913 \n",
      "acc for Psat= 0.21914051560580028 \n",
      "acc for optim= 0.16849969591055777\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.007591157220304012\n",
      "Loss on test= 0.007863499224185944\n",
      "acc for Lsat= 0.15078836146192992 \n",
      "acc for Psat= 0.23774874079095457 \n",
      "acc for optim= 0.1984789223507333\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.007570790592581034\n",
      "Loss on test= 0.007291737478226423\n",
      "acc for Lsat= 0.1493507564631039 \n",
      "acc for Psat= 0.23249710972349685 \n",
      "acc for optim= 0.17047968972464506\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.007373850792646408\n",
      "Loss on test= 0.007254164665937424\n",
      "acc for Lsat= 0.15127117508096932 \n",
      "acc for Psat= 0.23283721394742513 \n",
      "acc for optim= 0.17093802602077532\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.007334966212511063\n",
      "Loss on test= 0.007550092879682779\n",
      "acc for Lsat= 0.16660293859879588 \n",
      "acc for Psat= 0.21292256540540178 \n",
      "acc for optim= 0.16837331713484033\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.007432095240801573\n",
      "Loss on test= 0.007087727077305317\n",
      "acc for Lsat= 0.15228186745141126 \n",
      "acc for Psat= 0.22847654422465083 \n",
      "acc for optim= 0.17775957347426763\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.007566331420093775\n",
      "Loss on test= 0.006758196745067835\n",
      "acc for Lsat= 0.14865116560847397 \n",
      "acc for Psat= 0.20922595292358892 \n",
      "acc for optim= 0.1753308068763471\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.007417671848088503\n",
      "Loss on test= 0.007614971604198217\n",
      "acc for Lsat= 0.16125961119030616 \n",
      "acc for Psat= 0.2459837301906412 \n",
      "acc for optim= 0.17618907030165812\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.007302548736333847\n",
      "Loss on test= 0.007629232481122017\n",
      "acc for Lsat= 0.1607348817037623 \n",
      "acc for Psat= 0.20903712014002873 \n",
      "acc for optim= 0.17146825146148723\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.00726426811888814\n",
      "Loss on test= 0.007340495008975267\n",
      "acc for Lsat= 0.2005668443901389 \n",
      "acc for Psat= 0.21864855295594632 \n",
      "acc for optim= 0.16904850392750853\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.0072809262201189995\n",
      "Loss on test= 0.007253234274685383\n",
      "acc for Lsat= 0.16648833312757308 \n",
      "acc for Psat= 0.2216857199827909 \n",
      "acc for optim= 0.17704296443637735\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.007549495901912451\n",
      "Loss on test= 0.007071503903716803\n",
      "acc for Lsat= 0.15881096830413002 \n",
      "acc for Psat= 0.21006511541074016 \n",
      "acc for optim= 0.16988461960903117\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.00738105271011591\n",
      "Loss on test= 0.007202337495982647\n",
      "acc for Lsat= 0.167336420155865 \n",
      "acc for Psat= 0.21795167971868068 \n",
      "acc for optim= 0.16895670122441417\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.007050733081996441\n",
      "Loss on test= 0.007146389689296484\n",
      "acc for Lsat= 0.1434585898225762 \n",
      "acc for Psat= 0.204688011393021 \n",
      "acc for optim= 0.17576489661670977\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.007339976262301207\n",
      "Loss on test= 0.006972075905650854\n",
      "acc for Lsat= 0.1448241332809384 \n",
      "acc for Psat= 0.21275906496000085 \n",
      "acc for optim= 0.16907430737174345\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.0071103814989328384\n",
      "Loss on test= 0.007128747645765543\n",
      "acc for Lsat= 0.1687774714253563 \n",
      "acc for Psat= 0.20761522512013372 \n",
      "acc for optim= 0.17542917350923792\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.007117610890418291\n",
      "Loss on test= 0.007369284518063068\n",
      "acc for Lsat= 0.1590133346251949 \n",
      "acc for Psat= 0.23090406219833656 \n",
      "acc for optim= 0.1709931499697976\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.007186213508248329\n",
      "Loss on test= 0.007802008185535669\n",
      "acc for Lsat= 0.16011707889314541 \n",
      "acc for Psat= 0.2253799331904923 \n",
      "acc for optim= 0.1658361491980621\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.0072565446607768536\n",
      "Loss on test= 0.0075533404015004635\n",
      "acc for Lsat= 0.1503537297649018 \n",
      "acc for Psat= 0.24488211807289878 \n",
      "acc for optim= 0.17073523164907708\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.007121914532035589\n",
      "Loss on test= 0.0077628325670957565\n",
      "acc for Lsat= 0.16348123330804024 \n",
      "acc for Psat= 0.21723455660823085 \n",
      "acc for optim= 0.18235301191669204\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.007096470799297094\n",
      "Loss on test= 0.007659705821424723\n",
      "acc for Lsat= 0.16164693556031026 \n",
      "acc for Psat= 0.2419037138496532 \n",
      "acc for optim= 0.16722139351873624\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.007147828117012978\n",
      "Loss on test= 0.00702747842296958\n",
      "acc for Lsat= 0.1537546204352701 \n",
      "acc for Psat= 0.20196422025317687 \n",
      "acc for optim= 0.17381383003393658\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.007088454905897379\n",
      "Loss on test= 0.006657351739704609\n",
      "acc for Lsat= 0.14675326926762128 \n",
      "acc for Psat= 0.2036215007857528 \n",
      "acc for optim= 0.1686337059413868\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.007096776273101568\n",
      "Loss on test= 0.007181180641055107\n",
      "acc for Lsat= 0.15056004374609738 \n",
      "acc for Psat= 0.24384409756945585 \n",
      "acc for optim= 0.17343795212041554\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.007125169970095158\n",
      "Loss on test= 0.00719772232696414\n",
      "acc for Lsat= 0.1527654220365032 \n",
      "acc for Psat= 0.2135586009846176 \n",
      "acc for optim= 0.17468323494850171\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.007019620854407549\n",
      "Loss on test= 0.007077181711792946\n",
      "acc for Lsat= 0.15510392551683205 \n",
      "acc for Psat= 0.22927171205723473 \n",
      "acc for optim= 0.16815462924588812\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.007029789034277201\n",
      "Loss on test= 0.007158068474382162\n",
      "acc for Lsat= 0.1341931690730161 \n",
      "acc for Psat= 0.2123030227238495 \n",
      "acc for optim= 0.1754873360443673\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.00686832657083869\n",
      "Loss on test= 0.007213663309812546\n",
      "acc for Lsat= 0.15273193373601268 \n",
      "acc for Psat= 0.19844977230359045 \n",
      "acc for optim= 0.1662500156766131\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.007337912917137146\n",
      "Loss on test= 0.007253511343151331\n",
      "acc for Lsat= 0.1773486908427298 \n",
      "acc for Psat= 0.20372152967503418 \n",
      "acc for optim= 0.1660858502515554\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.0072310129180550575\n",
      "Loss on test= 0.007046123035252094\n",
      "acc for Lsat= 0.1475454587090172 \n",
      "acc for Psat= 0.22058615465986706 \n",
      "acc for optim= 0.18044717968960694\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.007035286631435156\n",
      "Loss on test= 0.007753695361316204\n",
      "acc for Lsat= 0.1480906268009897 \n",
      "acc for Psat= 0.24855060390915684 \n",
      "acc for optim= 0.16903549655150552\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.006987227592617273\n",
      "Loss on test= 0.00723871449008584\n",
      "acc for Lsat= 0.13715285906176644 \n",
      "acc for Psat= 0.22697089017959582 \n",
      "acc for optim= 0.17956266325357295\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.006765451282262802\n",
      "Loss on test= 0.007043494377285242\n",
      "acc for Lsat= 0.14955829458606762 \n",
      "acc for Psat= 0.21085029888844647 \n",
      "acc for optim= 0.176103378537133\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.006918419152498245\n",
      "Loss on test= 0.007072796579450369\n",
      "acc for Lsat= 0.15415810251697376 \n",
      "acc for Psat= 0.2056499695931593 \n",
      "acc for optim= 0.1805411714618409\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.007121548056602478\n",
      "Loss on test= 0.007300226483494043\n",
      "acc for Lsat= 0.15076602441164338 \n",
      "acc for Psat= 0.19920974955960913 \n",
      "acc for optim= 0.1656747882655976\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.007019314914941788\n",
      "Loss on test= 0.007154338993132114\n",
      "acc for Lsat= 0.13802090670159906 \n",
      "acc for Psat= 0.21944166159782735 \n",
      "acc for optim= 0.17824036187345416\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.007073504384607077\n",
      "Loss on test= 0.007179885171353817\n",
      "acc for Lsat= 0.15758604877044344 \n",
      "acc for Psat= 0.1979604258179992 \n",
      "acc for optim= 0.17424013039075165\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.006953445728868246\n",
      "Loss on test= 0.0071082953363657\n",
      "acc for Lsat= 0.14536240305072146 \n",
      "acc for Psat= 0.19575444033201878 \n",
      "acc for optim= 0.16972531209938932\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.0069702197797596455\n",
      "Loss on test= 0.0074030677787959576\n",
      "acc for Lsat= 0.1502573190272095 \n",
      "acc for Psat= 0.24081912106005285 \n",
      "acc for optim= 0.17558500223015938\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.007082488387823105\n",
      "Loss on test= 0.007118310313671827\n",
      "acc for Lsat= 0.14705071510650522 \n",
      "acc for Psat= 0.21184604270761279 \n",
      "acc for optim= 0.16784372756326874\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.007042359560728073\n",
      "Loss on test= 0.007268179208040237\n",
      "acc for Lsat= 0.14715719068446462 \n",
      "acc for Psat= 0.22647110229976336 \n",
      "acc for optim= 0.17496125790804964\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.006994226481765509\n",
      "Loss on test= 0.007391500286757946\n",
      "acc for Lsat= 0.18924927474231604 \n",
      "acc for Psat= 0.20502028649049886 \n",
      "acc for optim= 0.17736064239658378\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.006977316457778215\n",
      "Loss on test= 0.006663094274699688\n",
      "acc for Lsat= 0.12958873020299408 \n",
      "acc for Psat= 0.20200877301033107 \n",
      "acc for optim= 0.16792403792169353\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.007024985272437334\n",
      "Loss on test= 0.007716131396591663\n",
      "acc for Lsat= 0.16244518967667662 \n",
      "acc for Psat= 0.22505462774652923 \n",
      "acc for optim= 0.17922735368090406\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.007146018091589212\n",
      "Loss on test= 0.007781730964779854\n",
      "acc for Lsat= 0.19816688509383704 \n",
      "acc for Psat= 0.21632182445584378 \n",
      "acc for optim= 0.16719863617795086\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.007056991569697857\n",
      "Loss on test= 0.006819295696914196\n",
      "acc for Lsat= 0.13930977634498884 \n",
      "acc for Psat= 0.21744509586160593 \n",
      "acc for optim= 0.16655689861417577\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.00696557154878974\n",
      "Loss on test= 0.0067332349717617035\n",
      "acc for Lsat= 0.14884409934401865 \n",
      "acc for Psat= 0.2009612885715772 \n",
      "acc for optim= 0.168468896719443\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.006944036111235619\n",
      "Loss on test= 0.006757393013685942\n",
      "acc for Lsat= 0.1345213946640158 \n",
      "acc for Psat= 0.20783489247283748 \n",
      "acc for optim= 0.17763175565640857\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.006916102487593889\n",
      "Loss on test= 0.00676038209348917\n",
      "acc for Lsat= 0.1436606503868117 \n",
      "acc for Psat= 0.21214363594584495 \n",
      "acc for optim= 0.17011642442170144\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.006978780962526798\n",
      "Loss on test= 0.007490923162549734\n",
      "acc for Lsat= 0.1571514527842393 \n",
      "acc for Psat= 0.2781144552116874 \n",
      "acc for optim= 0.16978275115387667\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.007309598382562399\n",
      "Loss on test= 0.006840449757874012\n",
      "acc for Lsat= 0.14080972088708518 \n",
      "acc for Psat= 0.21368568956991973 \n",
      "acc for optim= 0.17599042799977455\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.00705771055072546\n",
      "Loss on test= 0.007187862880527973\n",
      "acc for Lsat= 0.15907157580949313 \n",
      "acc for Psat= 0.21108603228994244 \n",
      "acc for optim= 0.18881605555400932\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.007113172207027674\n",
      "Loss on test= 0.006907727103680372\n",
      "acc for Lsat= 0.15516189995891969 \n",
      "acc for Psat= 0.18672005235665082 \n",
      "acc for optim= 0.17174872103055963\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.0066618118435144424\n",
      "Loss on test= 0.006700216326862574\n",
      "acc for Lsat= 0.14539533652911102 \n",
      "acc for Psat= 0.2038736522018381 \n",
      "acc for optim= 0.18115520705514182\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.00680337380617857\n",
      "Loss on test= 0.006929631344974041\n",
      "acc for Lsat= 0.14356927560849628 \n",
      "acc for Psat= 0.2047949822240421 \n",
      "acc for optim= 0.17005977898559257\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.007226007524877787\n",
      "Loss on test= 0.007555913180112839\n",
      "acc for Lsat= 0.14612243364555635 \n",
      "acc for Psat= 0.24103614793108824 \n",
      "acc for optim= 0.17634823405859532\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.007481494918465614\n",
      "Loss on test= 0.00728428503498435\n",
      "acc for Lsat= 0.16047658768051454 \n",
      "acc for Psat= 0.24984735750046172 \n",
      "acc for optim= 0.17782715764553506\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.006906071212142706\n",
      "Loss on test= 0.00693922583013773\n",
      "acc for Lsat= 0.14912619310859088 \n",
      "acc for Psat= 0.22525134204605254 \n",
      "acc for optim= 0.17993128380141962\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.007125556468963623\n",
      "Loss on test= 0.006654075812548399\n",
      "acc for Lsat= 0.14840976933781938 \n",
      "acc for Psat= 0.21071525614683492 \n",
      "acc for optim= 0.17241546115739667\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.006834374275058508\n",
      "Loss on test= 0.0069422125816345215\n",
      "acc for Lsat= 0.1335085749391559 \n",
      "acc for Psat= 0.20922843281162362 \n",
      "acc for optim= 0.16928298785264692\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.0072602094151079655\n",
      "Loss on test= 0.006853480823338032\n",
      "acc for Lsat= 0.13997475648215482 \n",
      "acc for Psat= 0.21847621431830655 \n",
      "acc for optim= 0.17622824535850964\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.0070303515531122684\n",
      "Loss on test= 0.007041665259748697\n",
      "acc for Lsat= 0.14473846199072452 \n",
      "acc for Psat= 0.2120477258402487 \n",
      "acc for optim= 0.17947163173242164\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.006913021206855774\n",
      "Loss on test= 0.006874740123748779\n",
      "acc for Lsat= 0.14368423259586938 \n",
      "acc for Psat= 0.22879459021174084 \n",
      "acc for optim= 0.17398714000220836\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.006908112671226263\n",
      "Loss on test= 0.006657672580331564\n",
      "acc for Lsat= 0.14486478780383696 \n",
      "acc for Psat= 0.20421587267166516 \n",
      "acc for optim= 0.1749570594728465\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.006730216089636087\n",
      "Loss on test= 0.007082000840455294\n",
      "acc for Lsat= 0.16266278916894383 \n",
      "acc for Psat= 0.20011399050634135 \n",
      "acc for optim= 0.17128834923052047\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.0066719274036586285\n",
      "Loss on test= 0.006639324594289064\n",
      "acc for Lsat= 0.15317429453441306 \n",
      "acc for Psat= 0.20653043838683516 \n",
      "acc for optim= 0.16657410733558062\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.006893734447658062\n",
      "Loss on test= 0.006745560094714165\n",
      "acc for Lsat= 0.14030876307004145 \n",
      "acc for Psat= 0.19640195516734132 \n",
      "acc for optim= 0.17553266020892094\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.0067891268990933895\n",
      "Loss on test= 0.006970746908336878\n",
      "acc for Lsat= 0.16459624099582937 \n",
      "acc for Psat= 0.23653710337876455 \n",
      "acc for optim= 0.17343330612041158\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.007221724838018417\n",
      "Loss on test= 0.007112761028110981\n",
      "acc for Lsat= 0.14944729742411575 \n",
      "acc for Psat= 0.19918546691573086 \n",
      "acc for optim= 0.18501710666945703\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.006957337260246277\n",
      "Loss on test= 0.007171361707150936\n",
      "acc for Lsat= 0.14945819897184265 \n",
      "acc for Psat= 0.20037266396763231 \n",
      "acc for optim= 0.16813615432108014\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.006753198336809874\n",
      "Loss on test= 0.007405526004731655\n",
      "acc for Lsat= 0.12973040879168785 \n",
      "acc for Psat= 0.2268464838498157 \n",
      "acc for optim= 0.184119528677567\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.006908486597239971\n",
      "Loss on test= 0.007132230792194605\n",
      "acc for Lsat= 0.1498877206828833 \n",
      "acc for Psat= 0.23206889300549724 \n",
      "acc for optim= 0.1703013915043443\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.00695050461217761\n",
      "Loss on test= 0.006457075010985136\n",
      "acc for Lsat= 0.12962801510759556 \n",
      "acc for Psat= 0.19296795717712706 \n",
      "acc for optim= 0.16787652539013023\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.006633123382925987\n",
      "Loss on test= 0.006679119076579809\n",
      "acc for Lsat= 0.1466462041044488 \n",
      "acc for Psat= 0.19336079705484538 \n",
      "acc for optim= 0.16934965311879382\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.00678278598934412\n",
      "Loss on test= 0.007066516671329737\n",
      "acc for Lsat= 0.14021445633477778 \n",
      "acc for Psat= 0.223934620918511 \n",
      "acc for optim= 0.174573600759047\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.006895287428051233\n",
      "Loss on test= 0.006998411845415831\n",
      "acc for Lsat= 0.142645020704672 \n",
      "acc for Psat= 0.22520292063308187 \n",
      "acc for optim= 0.16778747368469007\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.007299844175577164\n",
      "Loss on test= 0.007728853728622198\n",
      "acc for Lsat= 0.20094102599978214 \n",
      "acc for Psat= 0.2229337875812505 \n",
      "acc for optim= 0.1722238054266986\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.006824527867138386\n",
      "Loss on test= 0.007343263365328312\n",
      "acc for Lsat= 0.1457218481271018 \n",
      "acc for Psat= 0.23070806745238007 \n",
      "acc for optim= 0.1688731076002249\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.007055698428303003\n",
      "Loss on test= 0.006741969380527735\n",
      "acc for Lsat= 0.12953763508168678 \n",
      "acc for Psat= 0.21127376961108846 \n",
      "acc for optim= 0.17033925706562367\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.006851076148450375\n",
      "Loss on test= 0.0066269030794501305\n",
      "acc for Lsat= 0.1391005116362263 \n",
      "acc for Psat= 0.21860890746717593 \n",
      "acc for optim= 0.17169545020479943\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.00679618027061224\n",
      "Loss on test= 0.006735094357281923\n",
      "acc for Lsat= 0.14443283402362941 \n",
      "acc for Psat= 0.20231276527526978 \n",
      "acc for optim= 0.1666821882982559\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.00680527463555336\n",
      "Loss on test= 0.006563918199390173\n",
      "acc for Lsat= 0.1314419348943645 \n",
      "acc for Psat= 0.2035282396788495 \n",
      "acc for optim= 0.17017262170014186\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.006710353773087263\n",
      "Loss on test= 0.007189501076936722\n",
      "acc for Lsat= 0.16063253595603857 \n",
      "acc for Psat= 0.20855582615390508 \n",
      "acc for optim= 0.17536989650919144\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.006849289871752262\n",
      "Loss on test= 0.007160491310060024\n",
      "acc for Lsat= 0.13358581656703372 \n",
      "acc for Psat= 0.23230406043365145 \n",
      "acc for optim= 0.18325448259024044\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.00661105802282691\n",
      "Loss on test= 0.006342826411128044\n",
      "acc for Lsat= 0.1413288711699204 \n",
      "acc for Psat= 0.20221333900730856 \n",
      "acc for optim= 0.167911112094943\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.006489292252808809\n",
      "Loss on test= 0.006591860670596361\n",
      "acc for Lsat= 0.13783052415001784 \n",
      "acc for Psat= 0.19543905511838258 \n",
      "acc for optim= 0.17153956278353516\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.006522823125123978\n",
      "Loss on test= 0.006794776301831007\n",
      "acc for Lsat= 0.14504278536244514 \n",
      "acc for Psat= 0.18101389376199614 \n",
      "acc for optim= 0.16858665584397778\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.006631605792790651\n",
      "Loss on test= 0.00663004769012332\n",
      "acc for Lsat= 0.13214173535478138 \n",
      "acc for Psat= 0.20117873373493314 \n",
      "acc for optim= 0.17691467581450548\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.006916496902704239\n",
      "Loss on test= 0.0067619867622852325\n",
      "acc for Lsat= 0.14341084701024825 \n",
      "acc for Psat= 0.19219102048845269 \n",
      "acc for optim= 0.16660581525974447\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.0066965059377253056\n",
      "Loss on test= 0.006835321895778179\n",
      "acc for Lsat= 0.17950641762385006 \n",
      "acc for Psat= 0.18582665340820953 \n",
      "acc for optim= 0.17879927392206466\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.006640924606472254\n",
      "Loss on test= 0.006832357030361891\n",
      "acc for Lsat= 0.13825715453016085 \n",
      "acc for Psat= 0.2296405536393207 \n",
      "acc for optim= 0.1720125841545539\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.0065422337502241135\n",
      "Loss on test= 0.006969013717025518\n",
      "acc for Lsat= 0.184533868722045 \n",
      "acc for Psat= 0.1992821160422716 \n",
      "acc for optim= 0.1754771526712166\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.006598025560379028\n",
      "Loss on test= 0.0064626457169651985\n",
      "acc for Lsat= 0.13269590891217672 \n",
      "acc for Psat= 0.19265945570864337 \n",
      "acc for optim= 0.1714323363120383\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.006748673971742392\n",
      "Loss on test= 0.0066913641057908535\n",
      "acc for Lsat= 0.13426132888230927 \n",
      "acc for Psat= 0.19724230903761042 \n",
      "acc for optim= 0.16542054096931383\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.0068444726057350636\n",
      "Loss on test= 0.00714357802644372\n",
      "acc for Lsat= 0.17060991222201297 \n",
      "acc for Psat= 0.20124565911592562 \n",
      "acc for optim= 0.16585442436641912\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.006403415463864803\n",
      "Loss on test= 0.006816072855144739\n",
      "acc for Lsat= 0.13728641252581272 \n",
      "acc for Psat= 0.20971366905173086 \n",
      "acc for optim= 0.17908417999940965\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.006663406267762184\n",
      "Loss on test= 0.006456495728343725\n",
      "acc for Lsat= 0.13001546273792614 \n",
      "acc for Psat= 0.1908277138631879 \n",
      "acc for optim= 0.17892160016187542\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.006880362518131733\n",
      "Loss on test= 0.006844630930572748\n",
      "acc for Lsat= 0.13552311373240553 \n",
      "acc for Psat= 0.19443909178104102 \n",
      "acc for optim= 0.17793460123318033\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.006875311024487019\n",
      "Loss on test= 0.006618967279791832\n",
      "acc for Lsat= 0.14177815136281424 \n",
      "acc for Psat= 0.1988339312710859 \n",
      "acc for optim= 0.17121927611839743\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.0066089872270822525\n",
      "Loss on test= 0.0066326274536550045\n",
      "acc for Lsat= 0.1404088626118578 \n",
      "acc for Psat= 0.19930309118609404 \n",
      "acc for optim= 0.16902510268502394\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.006570750381797552\n",
      "Loss on test= 0.006743906531482935\n",
      "acc for Lsat= 0.14468183498192466 \n",
      "acc for Psat= 0.20958282083459356 \n",
      "acc for optim= 0.16564487479804116\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.006750947330147028\n",
      "Loss on test= 0.0067090257070958614\n",
      "acc for Lsat= 0.15461630800711793 \n",
      "acc for Psat= 0.19829630476306193 \n",
      "acc for optim= 0.16785201268686326\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.006443307735025883\n",
      "Loss on test= 0.006682158447802067\n",
      "acc for Lsat= 0.13787553516178033 \n",
      "acc for Psat= 0.19776688924891483 \n",
      "acc for optim= 0.17679485174055634\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.006653399672359228\n",
      "Loss on test= 0.0066594937816262245\n",
      "acc for Lsat= 0.14601158228971464 \n",
      "acc for Psat= 0.208654689385455 \n",
      "acc for optim= 0.1770291654204787\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.0067450725473463535\n",
      "Loss on test= 0.007026659324765205\n",
      "acc for Lsat= 0.15059441066743504 \n",
      "acc for Psat= 0.2115041263272901 \n",
      "acc for optim= 0.1682244079660253\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.006405872292816639\n",
      "Loss on test= 0.0067954882979393005\n",
      "acc for Lsat= 0.13486545310808798 \n",
      "acc for Psat= 0.20314982705904922 \n",
      "acc for optim= 0.17573868376849852\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.006576023530215025\n",
      "Loss on test= 0.007190312724560499\n",
      "acc for Lsat= 0.176252809446777 \n",
      "acc for Psat= 0.21054771901843786 \n",
      "acc for optim= 0.16617196360272607\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.006660121958702803\n",
      "Loss on test= 0.0064776926301419735\n",
      "acc for Lsat= 0.13387737329539223 \n",
      "acc for Psat= 0.19845878892354793 \n",
      "acc for optim= 0.16814673566369567\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.006561052054166794\n",
      "Loss on test= 0.006809980608522892\n",
      "acc for Lsat= 0.1358012026769732 \n",
      "acc for Psat= 0.2047078360420356 \n",
      "acc for optim= 0.16803223121688288\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.00653875432908535\n",
      "Loss on test= 0.00660743098706007\n",
      "acc for Lsat= 0.1452275075233145 \n",
      "acc for Psat= 0.20784887278411612 \n",
      "acc for optim= 0.17377560822028867\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.006429900880903006\n",
      "Loss on test= 0.00664964783936739\n",
      "acc for Lsat= 0.1369810533926923 \n",
      "acc for Psat= 0.19584806525813905 \n",
      "acc for optim= 0.16620148245065874\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.006534238811582327\n",
      "Loss on test= 0.006766519043594599\n",
      "acc for Lsat= 0.15119484231104866 \n",
      "acc for Psat= 0.18259885718981497 \n",
      "acc for optim= 0.17073879730894595\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.006587045732885599\n",
      "Loss on test= 0.006779226008802652\n",
      "acc for Lsat= 0.13449267545921256 \n",
      "acc for Psat= 0.19318301722523756 \n",
      "acc for optim= 0.1827237722685134\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.006560381501913071\n",
      "Loss on test= 0.006887323223054409\n",
      "acc for Lsat= 0.15149444723470337 \n",
      "acc for Psat= 0.20339286674798868 \n",
      "acc for optim= 0.16946811569407047\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.006901466753333807\n",
      "Loss on test= 0.0068086981773376465\n",
      "acc for Lsat= 0.12695782504257247 \n",
      "acc for Psat= 0.1945888235625446 \n",
      "acc for optim= 0.16524373929771813\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.006606850773096085\n",
      "Loss on test= 0.006252578925341368\n",
      "acc for Lsat= 0.14705353979032323 \n",
      "acc for Psat= 0.18454355330421193 \n",
      "acc for optim= 0.16666278921420108\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.006547088269144297\n",
      "Loss on test= 0.006795515771955252\n",
      "acc for Lsat= 0.14830966082297745 \n",
      "acc for Psat= 0.19586946067205202 \n",
      "acc for optim= 0.1682465755407434\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.006636480800807476\n",
      "Loss on test= 0.007297808304429054\n",
      "acc for Lsat= 0.15969115232195003 \n",
      "acc for Psat= 0.22982328840628946 \n",
      "acc for optim= 0.17557345821232712\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.006682109087705612\n",
      "Loss on test= 0.007284833118319511\n",
      "acc for Lsat= 0.14852449931085349 \n",
      "acc for Psat= 0.23741990092408694 \n",
      "acc for optim= 0.17458544050344466\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.00651209894567728\n",
      "Loss on test= 0.006619403604418039\n",
      "acc for Lsat= 0.1343639292564468 \n",
      "acc for Psat= 0.21215718431768757 \n",
      "acc for optim= 0.16954884672107967\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.00658382847905159\n",
      "Loss on test= 0.006814497523009777\n",
      "acc for Lsat= 0.1336423643679646 \n",
      "acc for Psat= 0.18812986214195276 \n",
      "acc for optim= 0.17461766279361532\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.006525311153382063\n",
      "Loss on test= 0.006746635306626558\n",
      "acc for Lsat= 0.13606601024366682 \n",
      "acc for Psat= 0.20304530566696682 \n",
      "acc for optim= 0.16856508765202896\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.006495221052318811\n",
      "Loss on test= 0.00635517155751586\n",
      "acc for Lsat= 0.14782207206096515 \n",
      "acc for Psat= 0.19276216307244376 \n",
      "acc for optim= 0.17461312380736352\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.006744156591594219\n",
      "Loss on test= 0.007474678568542004\n",
      "acc for Lsat= 0.157733960773692 \n",
      "acc for Psat= 0.2514484556852187 \n",
      "acc for optim= 0.17916475651184777\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.006663798354566097\n",
      "Loss on test= 0.0064180283807218075\n",
      "acc for Lsat= 0.12464586656789982 \n",
      "acc for Psat= 0.18263537644560454 \n",
      "acc for optim= 0.17562191120639517\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.0064252642914652824\n",
      "Loss on test= 0.006735531147569418\n",
      "acc for Lsat= 0.13979622572367442 \n",
      "acc for Psat= 0.1903515022548507 \n",
      "acc for optim= 0.16867712822096184\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.006648525595664978\n",
      "Loss on test= 0.00621292507275939\n",
      "acc for Lsat= 0.1284030365745621 \n",
      "acc for Psat= 0.18994962958370437 \n",
      "acc for optim= 0.17158593274999057\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.0064668599516153336\n",
      "Loss on test= 0.0063034845516085625\n",
      "acc for Lsat= 0.13507877219691747 \n",
      "acc for Psat= 0.189587775736613 \n",
      "acc for optim= 0.17211078447222905\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.006375537253916264\n",
      "Loss on test= 0.006425999104976654\n",
      "acc for Lsat= 0.13270163895838386 \n",
      "acc for Psat= 0.19739858276507466 \n",
      "acc for optim= 0.1714259796137068\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.006334550213068724\n",
      "Loss on test= 0.006531344726681709\n",
      "acc for Lsat= 0.1253788197275237 \n",
      "acc for Psat= 0.1886664365455225 \n",
      "acc for optim= 0.17179637768237405\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.006660082843154669\n",
      "Loss on test= 0.007153733167797327\n",
      "acc for Lsat= 0.14006095264562032 \n",
      "acc for Psat= 0.21640021598717352 \n",
      "acc for optim= 0.1707559427285486\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.007010464556515217\n",
      "Loss on test= 0.008093669079244137\n",
      "acc for Lsat= 0.185801183684251 \n",
      "acc for Psat= 0.21717730497412785 \n",
      "acc for optim= 0.17551069206210496\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.006666182540357113\n",
      "Loss on test= 0.007023250684142113\n",
      "acc for Lsat= 0.14630616420814674 \n",
      "acc for Psat= 0.21984049984225626 \n",
      "acc for optim= 0.17508353344045818\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.006417545955628157\n",
      "Loss on test= 0.0074318768456578255\n",
      "acc for Lsat= 0.16076859201033633 \n",
      "acc for Psat= 0.19782287219729638 \n",
      "acc for optim= 0.16732434947043412\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.006403648294508457\n",
      "Loss on test= 0.006325364112854004\n",
      "acc for Lsat= 0.14011078124777004 \n",
      "acc for Psat= 0.1861352450560426 \n",
      "acc for optim= 0.17222525703255087\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.006527169141918421\n",
      "Loss on test= 0.007330531254410744\n",
      "acc for Lsat= 0.16658779532086998 \n",
      "acc for Psat= 0.20920996396789387 \n",
      "acc for optim= 0.1740249821759298\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.0066548241302371025\n",
      "Loss on test= 0.006322741974145174\n",
      "acc for Lsat= 0.12857653400258 \n",
      "acc for Psat= 0.1839450571866552 \n",
      "acc for optim= 0.16637186583879204\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.006417795084416866\n",
      "Loss on test= 0.00640251487493515\n",
      "acc for Lsat= 0.1318637838856412 \n",
      "acc for Psat= 0.18748505904325094 \n",
      "acc for optim= 0.165579978369351\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.006345404777675867\n",
      "Loss on test= 0.007219825871288776\n",
      "acc for Lsat= 0.17340667605704102 \n",
      "acc for Psat= 0.1983048852343927 \n",
      "acc for optim= 0.17074837968558879\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.006601008120924234\n",
      "Loss on test= 0.006362098269164562\n",
      "acc for Lsat= 0.12329087090192598 \n",
      "acc for Psat= 0.19286801198098613 \n",
      "acc for optim= 0.1663897496296527\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.006599626038223505\n",
      "Loss on test= 0.0065270233899354935\n",
      "acc for Lsat= 0.12746023910212162 \n",
      "acc for Psat= 0.20104206490725265 \n",
      "acc for optim= 0.17563623823111443\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.006621380336582661\n",
      "Loss on test= 0.006478568539023399\n",
      "acc for Lsat= 0.14917547095776812 \n",
      "acc for Psat= 0.18492965531894132 \n",
      "acc for optim= 0.1678997323016193\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.00658345827832818\n",
      "Loss on test= 0.0062582544051110744\n",
      "acc for Lsat= 0.13568272853720104 \n",
      "acc for Psat= 0.18306031784123736 \n",
      "acc for optim= 0.164635886331608\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.006548810750246048\n",
      "Loss on test= 0.006361109204590321\n",
      "acc for Lsat= 0.13454249495643544 \n",
      "acc for Psat= 0.19298679483767342 \n",
      "acc for optim= 0.17477827054775646\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.006339698564261198\n",
      "Loss on test= 0.006437371484935284\n",
      "acc for Lsat= 0.13858011915077884 \n",
      "acc for Psat= 0.1841629261270518 \n",
      "acc for optim= 0.16645172829373986\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.00653377640992403\n",
      "Loss on test= 0.006313729099929333\n",
      "acc for Lsat= 0.13376727805904454 \n",
      "acc for Psat= 0.18767478123771905 \n",
      "acc for optim= 0.17017341131105315\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.006355229765176773\n",
      "Loss on test= 0.0065564666874706745\n",
      "acc for Lsat= 0.14310163390367764 \n",
      "acc for Psat= 0.18820632036147653 \n",
      "acc for optim= 0.1646552457069029\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.0065210252068936825\n",
      "Loss on test= 0.006394206080585718\n",
      "acc for Lsat= 0.13025611992516378 \n",
      "acc for Psat= 0.1864462624299277 \n",
      "acc for optim= 0.17988034897063845\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.00626373291015625\n",
      "Loss on test= 0.006142851430922747\n",
      "acc for Lsat= 0.1263151377934264 \n",
      "acc for Psat= 0.18190979978639055 \n",
      "acc for optim= 0.17468695533460885\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.006515554618090391\n",
      "Loss on test= 0.006536091677844524\n",
      "acc for Lsat= 0.13865491420565867 \n",
      "acc for Psat= 0.18264889568633186 \n",
      "acc for optim= 0.1684318550965022\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.0065869297832250595\n",
      "Loss on test= 0.006540065165609121\n",
      "acc for Lsat= 0.12467848223781944 \n",
      "acc for Psat= 0.20285763737676363 \n",
      "acc for optim= 0.163479124743832\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.0066027650609612465\n",
      "Loss on test= 0.006437791511416435\n",
      "acc for Lsat= 0.15503228973908778 \n",
      "acc for Psat= 0.19401570974150673 \n",
      "acc for optim= 0.17518942911595553\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.0069361296482384205\n",
      "Loss on test= 0.007148311007767916\n",
      "acc for Lsat= 0.15112170646347836 \n",
      "acc for Psat= 0.23956314062584047 \n",
      "acc for optim= 0.17123519871896908\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.006609042175114155\n",
      "Loss on test= 0.006392751354724169\n",
      "acc for Lsat= 0.1281199874442914 \n",
      "acc for Psat= 0.18380338471625518 \n",
      "acc for optim= 0.17126839894784074\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.006370710674673319\n",
      "Loss on test= 0.0062781632877886295\n",
      "acc for Lsat= 0.12704236219225415 \n",
      "acc for Psat= 0.19322720620353673 \n",
      "acc for optim= 0.16880960023656763\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.00635512312874198\n",
      "Loss on test= 0.006523463409394026\n",
      "acc for Lsat= 0.1397621341767828 \n",
      "acc for Psat= 0.20221172413147467 \n",
      "acc for optim= 0.16503386365218684\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.0064373440109193325\n",
      "Loss on test= 0.006512890569865704\n",
      "acc for Lsat= 0.12379028103444127 \n",
      "acc for Psat= 0.18263179205579846 \n",
      "acc for optim= 0.1672269330341117\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.006530835758894682\n",
      "Loss on test= 0.006606637500226498\n",
      "acc for Lsat= 0.13394809429017776 \n",
      "acc for Psat= 0.2062653923301794 \n",
      "acc for optim= 0.1756264304234768\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.006477289367467165\n",
      "Loss on test= 0.006691960617899895\n",
      "acc for Lsat= 0.14558314500341973 \n",
      "acc for Psat= 0.17045695234402367 \n",
      "acc for optim= 0.18296672575078865\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.00639192434027791\n",
      "Loss on test= 0.0062187169678509235\n",
      "acc for Lsat= 0.12515389919910277 \n",
      "acc for Psat= 0.18757276055308664 \n",
      "acc for optim= 0.16615568825776839\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.006263681221753359\n",
      "Loss on test= 0.006362903863191605\n",
      "acc for Lsat= 0.1477423789326929 \n",
      "acc for Psat= 0.17828696235468472 \n",
      "acc for optim= 0.17116154949451048\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.006125600077211857\n",
      "Loss on test= 0.006276324857026339\n",
      "acc for Lsat= 0.12984661030448577 \n",
      "acc for Psat= 0.1784269460551661 \n",
      "acc for optim= 0.1652535648058433\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.006226153578609228\n",
      "Loss on test= 0.00619533471763134\n",
      "acc for Lsat= 0.12215242071574353 \n",
      "acc for Psat= 0.19207275508351568 \n",
      "acc for optim= 0.17076606583872786\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.0061877090483903885\n",
      "Loss on test= 0.006580247078090906\n",
      "acc for Lsat= 0.1230838839376585 \n",
      "acc for Psat= 0.18920394211257902 \n",
      "acc for optim= 0.166693994280846\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.006438291631639004\n",
      "Loss on test= 0.006698207464069128\n",
      "acc for Lsat= 0.12758919566113036 \n",
      "acc for Psat= 0.2183581801858767 \n",
      "acc for optim= 0.1795285092509427\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.006378639955073595\n",
      "Loss on test= 0.00624932162463665\n",
      "acc for Lsat= 0.12999044174432275 \n",
      "acc for Psat= 0.1952583693599917 \n",
      "acc for optim= 0.16866659190634745\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.0062456135638058186\n",
      "Loss on test= 0.006581593304872513\n",
      "acc for Lsat= 0.13566781488717006 \n",
      "acc for Psat= 0.19586813225565936 \n",
      "acc for optim= 0.17691703113608104\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.006361832842230797\n",
      "Loss on test= 0.006325514521449804\n",
      "acc for Lsat= 0.11851868922835943 \n",
      "acc for Psat= 0.18374365662355166 \n",
      "acc for optim= 0.17594098318855883\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.006265375763177872\n",
      "Loss on test= 0.006884987931698561\n",
      "acc for Lsat= 0.14855499752190332 \n",
      "acc for Psat= 0.21634227299364284 \n",
      "acc for optim= 0.17030909794423654\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.006317287217825651\n",
      "Loss on test= 0.006533931940793991\n",
      "acc for Lsat= 0.13308593527265633 \n",
      "acc for Psat= 0.1835530775562212 \n",
      "acc for optim= 0.16559986745926072\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.0064126611687242985\n",
      "Loss on test= 0.006318254861980677\n",
      "acc for Lsat= 0.12487397023604088 \n",
      "acc for Psat= 0.19218668061541785 \n",
      "acc for optim= 0.16946146447721608\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.0062193190678954124\n",
      "Loss on test= 0.006371676921844482\n",
      "acc for Lsat= 0.12237225811691747 \n",
      "acc for Psat= 0.1814098821794048 \n",
      "acc for optim= 0.16923511867699326\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.0062865521758794785\n",
      "Loss on test= 0.006565816700458527\n",
      "acc for Lsat= 0.13115091072461382 \n",
      "acc for Psat= 0.17583134194943784 \n",
      "acc for optim= 0.16691352290611058\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.00647702207788825\n",
      "Loss on test= 0.006325555965304375\n",
      "acc for Lsat= 0.13715554444115696 \n",
      "acc for Psat= 0.18162273686981723 \n",
      "acc for optim= 0.1686461858440649\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.006407230161130428\n",
      "Loss on test= 0.006383751519024372\n",
      "acc for Lsat= 0.13118838216042925 \n",
      "acc for Psat= 0.1804406915825156 \n",
      "acc for optim= 0.1703523956750507\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.006255189888179302\n",
      "Loss on test= 0.00646473653614521\n",
      "acc for Lsat= 0.13848548262388716 \n",
      "acc for Psat= 0.18253579357125901 \n",
      "acc for optim= 0.16566727901777453\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.006285023409873247\n",
      "Loss on test= 0.006471544504165649\n",
      "acc for Lsat= 0.12835123389428388 \n",
      "acc for Psat= 0.1863229198328603 \n",
      "acc for optim= 0.17367903099801804\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.006141284015029669\n",
      "Loss on test= 0.0065422398038208485\n",
      "acc for Lsat= 0.13081926172260963 \n",
      "acc for Psat= 0.17075678194200467 \n",
      "acc for optim= 0.16736219249729845\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.0063509633764624596\n",
      "Loss on test= 0.006208134815096855\n",
      "acc for Lsat= 0.13171262311988283 \n",
      "acc for Psat= 0.17336378973829375 \n",
      "acc for optim= 0.1750276572168553\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.006111266557127237\n",
      "Loss on test= 0.0062852720730006695\n",
      "acc for Lsat= 0.12829380644628857 \n",
      "acc for Psat= 0.18854406084456304 \n",
      "acc for optim= 0.170225994959568\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.0062059457413852215\n",
      "Loss on test= 0.006141254212707281\n",
      "acc for Lsat= 0.12296483677372069 \n",
      "acc for Psat= 0.17574609307130967 \n",
      "acc for optim= 0.16911029184858442\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.006262828595936298\n",
      "Loss on test= 0.006580736953765154\n",
      "acc for Lsat= 0.12703734909381317 \n",
      "acc for Psat= 0.1957222604018957 \n",
      "acc for optim= 0.17437698572226706\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.00630798377096653\n",
      "Loss on test= 0.006898713298141956\n",
      "acc for Lsat= 0.12453442647686619 \n",
      "acc for Psat= 0.19085530042443802 \n",
      "acc for optim= 0.16932398364509493\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.006348217371851206\n",
      "Loss on test= 0.006506914272904396\n",
      "acc for Lsat= 0.14002755201959557 \n",
      "acc for Psat= 0.1927200427245053 \n",
      "acc for optim= 0.1695305515934927\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.006162857636809349\n",
      "Loss on test= 0.006298078689724207\n",
      "acc for Lsat= 0.13196921025902722 \n",
      "acc for Psat= 0.18195023172852784 \n",
      "acc for optim= 0.16708990124508902\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.006112233269959688\n",
      "Loss on test= 0.00634068064391613\n",
      "acc for Lsat= 0.14006543930264417 \n",
      "acc for Psat= 0.17348949683828568 \n",
      "acc for optim= 0.1781727222558992\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.006149517837911844\n",
      "Loss on test= 0.006324954330921173\n",
      "acc for Lsat= 0.12889139619388468 \n",
      "acc for Psat= 0.1909423002019852 \n",
      "acc for optim= 0.16455368778952106\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.00662584463134408\n",
      "Loss on test= 0.006235978100448847\n",
      "acc for Lsat= 0.12927124539783108 \n",
      "acc for Psat= 0.1850196503828802 \n",
      "acc for optim= 0.16822259294988456\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.006577252876013517\n",
      "Loss on test= 0.006409919820725918\n",
      "acc for Lsat= 0.13353272221000814 \n",
      "acc for Psat= 0.2031968825251317 \n",
      "acc for optim= 0.17174256053742185\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.006263965740799904\n",
      "Loss on test= 0.00634760083630681\n",
      "acc for Lsat= 0.12143989386862125 \n",
      "acc for Psat= 0.19825603367487044 \n",
      "acc for optim= 0.17841111755350958\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.006190753076225519\n",
      "Loss on test= 0.006711332127451897\n",
      "acc for Lsat= 0.1291097074383681 \n",
      "acc for Psat= 0.2037091789470405 \n",
      "acc for optim= 0.17156430225539324\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.006193329114466906\n",
      "Loss on test= 0.006544826086610556\n",
      "acc for Lsat= 0.1328341370350933 \n",
      "acc for Psat= 0.18967897661138056 \n",
      "acc for optim= 0.1774068625167569\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.006350967101752758\n",
      "Loss on test= 0.006527325604110956\n",
      "acc for Lsat= 0.13682099209197346 \n",
      "acc for Psat= 0.18093256293581658 \n",
      "acc for optim= 0.17116599551268705\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.006294168997555971\n",
      "Loss on test= 0.006303622853010893\n",
      "acc for Lsat= 0.12316494631060679 \n",
      "acc for Psat= 0.19592366594086932 \n",
      "acc for optim= 0.17112514434041726\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.006174672394990921\n",
      "Loss on test= 0.005902278237044811\n",
      "acc for Lsat= 0.11964363404016744 \n",
      "acc for Psat= 0.1769482020687507 \n",
      "acc for optim= 0.17123804741080478\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.006263891700655222\n",
      "Loss on test= 0.006171048618853092\n",
      "acc for Lsat= 0.12217514609604936 \n",
      "acc for Psat= 0.17171163835922237 \n",
      "acc for optim= 0.1681407265073299\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.006080156657844782\n",
      "Loss on test= 0.0064607709646224976\n",
      "acc for Lsat= 0.12183376453282796 \n",
      "acc for Psat= 0.18209627140085277 \n",
      "acc for optim= 0.16825191820739624\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.0060762278735637665\n",
      "Loss on test= 0.0064010159112513065\n",
      "acc for Lsat= 0.16250744043463783 \n",
      "acc for Psat= 0.19520242606046628 \n",
      "acc for optim= 0.1681239338722662\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.006222054827958345\n",
      "Loss on test= 0.006257330998778343\n",
      "acc for Lsat= 0.13050737891916395 \n",
      "acc for Psat= 0.17908484435738992 \n",
      "acc for optim= 0.17172782482363824\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.006401741877198219\n",
      "Loss on test= 0.006448959466069937\n",
      "acc for Lsat= 0.13549142593723987 \n",
      "acc for Psat= 0.18769342193932184 \n",
      "acc for optim= 0.16667607790827174\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.006307483185082674\n",
      "Loss on test= 0.006516152527183294\n",
      "acc for Lsat= 0.13296427242017375 \n",
      "acc for Psat= 0.19000405228438763 \n",
      "acc for optim= 0.16612782399878032\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.00698561267927289\n",
      "Loss on test= 0.00733052147552371\n",
      "acc for Lsat= 0.13868555575695732 \n",
      "acc for Psat= 0.23822441352525414 \n",
      "acc for optim= 0.18019675823607767\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.006230978760868311\n",
      "Loss on test= 0.0067227124236524105\n",
      "acc for Lsat= 0.14498770339422343 \n",
      "acc for Psat= 0.17809647656896552 \n",
      "acc for optim= 0.16592777711795517\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.006295070983469486\n",
      "Loss on test= 0.007012215908616781\n",
      "acc for Lsat= 0.1275318520156607 \n",
      "acc for Psat= 0.18135011929435013 \n",
      "acc for optim= 0.20901695533727951\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.006482202559709549\n",
      "Loss on test= 0.0061428905464708805\n",
      "acc for Lsat= 0.12356586763348172 \n",
      "acc for Psat= 0.19544271488828943 \n",
      "acc for optim= 0.16883444122347124\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.006341285537928343\n",
      "Loss on test= 0.006127945613116026\n",
      "acc for Lsat= 0.1311845091496326 \n",
      "acc for Psat= 0.17750358846697545 \n",
      "acc for optim= 0.16778329338086298\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.00652233324944973\n",
      "Loss on test= 0.006319470703601837\n",
      "acc for Lsat= 0.1233206696488196 \n",
      "acc for Psat= 0.1896102854547821 \n",
      "acc for optim= 0.17240518381358189\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.006232712417840958\n",
      "Loss on test= 0.006433215923607349\n",
      "acc for Lsat= 0.13006393958159998 \n",
      "acc for Psat= 0.20187015232521524 \n",
      "acc for optim= 0.1657886570949297\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.0066163926385343075\n",
      "Loss on test= 0.0072238864377141\n",
      "acc for Lsat= 0.1499803543214315 \n",
      "acc for Psat= 0.2641239703833078 \n",
      "acc for optim= 0.16911826823913567\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.007018153555691242\n",
      "Loss on test= 0.007074383553117514\n",
      "acc for Lsat= 0.17294772399696198 \n",
      "acc for Psat= 0.1898673863816421 \n",
      "acc for optim= 0.17244047905409685\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.006552873644977808\n",
      "Loss on test= 0.006688729394227266\n",
      "acc for Lsat= 0.1350802766302533 \n",
      "acc for Psat= 0.19921808694630885 \n",
      "acc for optim= 0.17458300375083863\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.006191436666995287\n",
      "Loss on test= 0.006434472277760506\n",
      "acc for Lsat= 0.14914949324733046 \n",
      "acc for Psat= 0.19319617509805737 \n",
      "acc for optim= 0.16668397857614076\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.006302217952907085\n",
      "Loss on test= 0.006317909341305494\n",
      "acc for Lsat= 0.1381573040424563 \n",
      "acc for Psat= 0.19015301409042976 \n",
      "acc for optim= 0.17368044041457423\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.006081681698560715\n",
      "Loss on test= 0.005907242186367512\n",
      "acc for Lsat= 0.11935114250605398 \n",
      "acc for Psat= 0.172640359417651 \n",
      "acc for optim= 0.17818481100817193\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.0061609395779669285\n",
      "Loss on test= 0.00659332238137722\n",
      "acc for Lsat= 0.14341270126169547 \n",
      "acc for Psat= 0.19097099325257216 \n",
      "acc for optim= 0.1691385181905856\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.0064200181514024734\n",
      "Loss on test= 0.006149449851363897\n",
      "acc for Lsat= 0.12613102236571502 \n",
      "acc for Psat= 0.1841407586489859 \n",
      "acc for optim= 0.16705338228289415\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.006168215069919825\n",
      "Loss on test= 0.0064711603336036205\n",
      "acc for Lsat= 0.12611406063818298 \n",
      "acc for Psat= 0.1840150024135427 \n",
      "acc for optim= 0.16953670538842325\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.006167296320199966\n",
      "Loss on test= 0.006417128723114729\n",
      "acc for Lsat= 0.13533092334320238 \n",
      "acc for Psat= 0.19171757500569928 \n",
      "acc for optim= 0.17086395649695643\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.006225832272320986\n",
      "Loss on test= 0.006424154154956341\n",
      "acc for Lsat= 0.1262329693860453 \n",
      "acc for Psat= 0.1792424425746356 \n",
      "acc for optim= 0.17206841182652735\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.006298446096479893\n",
      "Loss on test= 0.005956615321338177\n",
      "acc for Lsat= 0.1282252047183008 \n",
      "acc for Psat= 0.17625851446206758 \n",
      "acc for optim= 0.16551231861789395\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.006171940825879574\n",
      "Loss on test= 0.006229220423847437\n",
      "acc for Lsat= 0.14063160423963406 \n",
      "acc for Psat= 0.18603728535585892 \n",
      "acc for optim= 0.16563647108528498\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.006107889581471682\n",
      "Loss on test= 0.006450850050896406\n",
      "acc for Lsat= 0.12298904055589102 \n",
      "acc for Psat= 0.2035601035390632 \n",
      "acc for optim= 0.1674516920409317\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.006055214907974005\n",
      "Loss on test= 0.006421956699341536\n",
      "acc for Lsat= 0.11742385928340121 \n",
      "acc for Psat= 0.17065373785747373 \n",
      "acc for optim= 0.1610276359868884\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.006461890414357185\n",
      "Loss on test= 0.0061380560509860516\n",
      "acc for Lsat= 0.11835551276011314 \n",
      "acc for Psat= 0.17810660465712883 \n",
      "acc for optim= 0.17019718167466635\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.006161067634820938\n",
      "Loss on test= 0.0062636202201247215\n",
      "acc for Lsat= 0.1310400319615272 \n",
      "acc for Psat= 0.17521051045922512 \n",
      "acc for optim= 0.17187292314024552\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.006096228491514921\n",
      "Loss on test= 0.006391983944922686\n",
      "acc for Lsat= 0.1297373297886126 \n",
      "acc for Psat= 0.18205629416405752 \n",
      "acc for optim= 0.16946884954995767\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.006121679209172726\n",
      "Loss on test= 0.006701329257339239\n",
      "acc for Lsat= 0.12990721555684717 \n",
      "acc for Psat= 0.20090384468986067 \n",
      "acc for optim= 0.16913834482654017\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.006316808518022299\n",
      "Loss on test= 0.0060805631801486015\n",
      "acc for Lsat= 0.12038324386193798 \n",
      "acc for Psat= 0.1700113776471856 \n",
      "acc for optim= 0.16667321082275374\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.006182705517858267\n",
      "Loss on test= 0.006033958401530981\n",
      "acc for Lsat= 0.11566886234995026 \n",
      "acc for Psat= 0.19722850600560746 \n",
      "acc for optim= 0.17381164995045717\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.006032206118106842\n",
      "Loss on test= 0.0061840941198170185\n",
      "acc for Lsat= 0.13717330081881546 \n",
      "acc for Psat= 0.1927843793410166 \n",
      "acc for optim= 0.16612976200693427\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.005985672120004892\n",
      "Loss on test= 0.006640654057264328\n",
      "acc for Lsat= 0.12436707343373643 \n",
      "acc for Psat= 0.19563820628802106 \n",
      "acc for optim= 0.17261273448014902\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.006080020684748888\n",
      "Loss on test= 0.006079930812120438\n",
      "acc for Lsat= 0.12662906563334242 \n",
      "acc for Psat= 0.1901475243710691 \n",
      "acc for optim= 0.16533042507610327\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.00598875293508172\n",
      "Loss on test= 0.006186727900058031\n",
      "acc for Lsat= 0.1352227778817807 \n",
      "acc for Psat= 0.17942061493099695 \n",
      "acc for optim= 0.17751703736526858\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.006269083358347416\n",
      "Loss on test= 0.006092021707445383\n",
      "acc for Lsat= 0.13573256529599423 \n",
      "acc for Psat= 0.16368531494796068 \n",
      "acc for optim= 0.1649686417289116\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.006118107587099075\n",
      "Loss on test= 0.006411269307136536\n",
      "acc for Lsat= 0.1512799003958699 \n",
      "acc for Psat= 0.1860267523419237 \n",
      "acc for optim= 0.16938015947203353\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.006381515879184008\n",
      "Loss on test= 0.006339897867292166\n",
      "acc for Lsat= 0.1402789057716979 \n",
      "acc for Psat= 0.19777188051473885 \n",
      "acc for optim= 0.16934595247270456\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.006242489907890558\n",
      "Loss on test= 0.006179611198604107\n",
      "acc for Lsat= 0.12694641622879071 \n",
      "acc for Psat= 0.1742139954654716 \n",
      "acc for optim= 0.1653589925577713\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.006161466706544161\n",
      "Loss on test= 0.006079493556171656\n",
      "acc for Lsat= 0.12908780809182743 \n",
      "acc for Psat= 0.1895635786829705 \n",
      "acc for optim= 0.17186370941380044\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.0061339326202869415\n",
      "Loss on test= 0.0059839109890162945\n",
      "acc for Lsat= 0.12615494907677693 \n",
      "acc for Psat= 0.1830584629521606 \n",
      "acc for optim= 0.17438546396796656\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.006091362331062555\n",
      "Loss on test= 0.006342454347759485\n",
      "acc for Lsat= 0.15524342505877203 \n",
      "acc for Psat= 0.18434116825763439 \n",
      "acc for optim= 0.16769753450970146\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.006532044615596533\n",
      "Loss on test= 0.006492651998996735\n",
      "acc for Lsat= 0.1437143691350561 \n",
      "acc for Psat= 0.17475917556313672 \n",
      "acc for optim= 0.1712030850587227\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.0062870364636182785\n",
      "Loss on test= 0.006250952370464802\n",
      "acc for Lsat= 0.12960510210384224 \n",
      "acc for Psat= 0.18934310461662715 \n",
      "acc for optim= 0.16568013491524727\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.006347666960209608\n",
      "Loss on test= 0.006201162468641996\n",
      "acc for Lsat= 0.13409312406351878 \n",
      "acc for Psat= 0.2008501538287886 \n",
      "acc for optim= 0.16560282925402625\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.006366604473441839\n",
      "Loss on test= 0.006534287706017494\n",
      "acc for Lsat= 0.15033781118890566 \n",
      "acc for Psat= 0.19815230358942298 \n",
      "acc for optim= 0.1691751699378762\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.006051967386156321\n",
      "Loss on test= 0.006193671841174364\n",
      "acc for Lsat= 0.11693254790436579 \n",
      "acc for Psat= 0.1801675495071568 \n",
      "acc for optim= 0.16646627855963644\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.006000682711601257\n",
      "Loss on test= 0.006363155785948038\n",
      "acc for Lsat= 0.12315437728948136 \n",
      "acc for Psat= 0.18231362851715735 \n",
      "acc for optim= 0.16769400394634823\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.006031659431755543\n",
      "Loss on test= 0.0063465251587331295\n",
      "acc for Lsat= 0.12257768795449453 \n",
      "acc for Psat= 0.16878620459956928 \n",
      "acc for optim= 0.17165091766248616\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.0061060646548867226\n",
      "Loss on test= 0.006175493821501732\n",
      "acc for Lsat= 0.11962443091997065 \n",
      "acc for Psat= 0.1788362486939248 \n",
      "acc for optim= 0.16499488776930407\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.006100245285779238\n",
      "Loss on test= 0.006162079516798258\n",
      "acc for Lsat= 0.11985548717426797 \n",
      "acc for Psat= 0.20074571446260764 \n",
      "acc for optim= 0.18032802653161106\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.006223340518772602\n",
      "Loss on test= 0.006348921451717615\n",
      "acc for Lsat= 0.13845210315077958 \n",
      "acc for Psat= 0.17672885325044116 \n",
      "acc for optim= 0.16135306206942424\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.0060335188172757626\n",
      "Loss on test= 0.0060888780280947685\n",
      "acc for Lsat= 0.11405677800605583 \n",
      "acc for Psat= 0.18702657730849553 \n",
      "acc for optim= 0.17336742359101837\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.006353077944368124\n",
      "Loss on test= 0.0063656652346253395\n",
      "acc for Lsat= 0.12144117498128498 \n",
      "acc for Psat= 0.1865224761672466 \n",
      "acc for optim= 0.16834234199435544\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.006026760209351778\n",
      "Loss on test= 0.006256333086639643\n",
      "acc for Lsat= 0.1371983612067148 \n",
      "acc for Psat= 0.1687876825680657 \n",
      "acc for optim= 0.17114340015246557\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.006026100367307663\n",
      "Loss on test= 0.005990588106215\n",
      "acc for Lsat= 0.12956019876752622 \n",
      "acc for Psat= 0.1733607698644256 \n",
      "acc for optim= 0.16399222272534766\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.006094065494835377\n",
      "Loss on test= 0.0063087004236876965\n",
      "acc for Lsat= 0.13083438252372592 \n",
      "acc for Psat= 0.19544334200622257 \n",
      "acc for optim= 0.16535772081093653\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.0061651249416172504\n",
      "Loss on test= 0.006583262700587511\n",
      "acc for Lsat= 0.12370265656765597 \n",
      "acc for Psat= 0.2051923240934549 \n",
      "acc for optim= 0.17258340538978087\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.006293410435318947\n",
      "Loss on test= 0.006265685893595219\n",
      "acc for Lsat= 0.13619015854773525 \n",
      "acc for Psat= 0.17578374314030656 \n",
      "acc for optim= 0.1683745236203666\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.0061561851762235165\n",
      "Loss on test= 0.0061855860985815525\n",
      "acc for Lsat= 0.12076304623413406 \n",
      "acc for Psat= 0.17136157504216032 \n",
      "acc for optim= 0.1732925255810433\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.006213226821273565\n",
      "Loss on test= 0.006483179982751608\n",
      "acc for Lsat= 0.14189598532224457 \n",
      "acc for Psat= 0.19743805606504344 \n",
      "acc for optim= 0.16984775435412303\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.006154509726911783\n",
      "Loss on test= 0.006420724093914032\n",
      "acc for Lsat= 0.12538144604901094 \n",
      "acc for Psat= 0.17625773591469232 \n",
      "acc for optim= 0.1637006861099606\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.006044668611139059\n",
      "Loss on test= 0.006118489895015955\n",
      "acc for Lsat= 0.1193712842139428 \n",
      "acc for Psat= 0.17939891503320304 \n",
      "acc for optim= 0.16910240378598934\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.006045530084520578\n",
      "Loss on test= 0.006039927713572979\n",
      "acc for Lsat= 0.12138531017449536 \n",
      "acc for Psat= 0.17163776800134656 \n",
      "acc for optim= 0.16846954995747404\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.005964264273643494\n",
      "Loss on test= 0.006296536419540644\n",
      "acc for Lsat= 0.12726942123899299 \n",
      "acc for Psat= 0.1729676724019039 \n",
      "acc for optim= 0.1757105936050868\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.0059319064021110535\n",
      "Loss on test= 0.006073924247175455\n",
      "acc for Lsat= 0.11596676837959692 \n",
      "acc for Psat= 0.1669856223578225 \n",
      "acc for optim= 0.1671812700460086\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.006094294134527445\n",
      "Loss on test= 0.005844503175467253\n",
      "acc for Lsat= 0.13809533262828327 \n",
      "acc for Psat= 0.16312554909539334 \n",
      "acc for optim= 0.1684271547437183\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.006422288715839386\n",
      "Loss on test= 0.006909550167620182\n",
      "acc for Lsat= 0.13344000408668197 \n",
      "acc for Psat= 0.19380271290149698 \n",
      "acc for optim= 0.17283195176777727\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.006019749213010073\n",
      "Loss on test= 0.006178148556500673\n",
      "acc for Lsat= 0.13068921454533985 \n",
      "acc for Psat= 0.18514788950631408 \n",
      "acc for optim= 0.17135671246088915\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.0059106540866196156\n",
      "Loss on test= 0.006195764057338238\n",
      "acc for Lsat= 0.1270815618540714 \n",
      "acc for Psat= 0.17284118229321935 \n",
      "acc for optim= 0.1807603092841025\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.006015416234731674\n",
      "Loss on test= 0.005778492894023657\n",
      "acc for Lsat= 0.11118879941595633 \n",
      "acc for Psat= 0.16915846532513545 \n",
      "acc for optim= 0.16510659280941803\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.005935031455010176\n",
      "Loss on test= 0.006204704754054546\n",
      "acc for Lsat= 0.13108786080005844 \n",
      "acc for Psat= 0.1833134914490369 \n",
      "acc for optim= 0.16006091240135878\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.006020548287779093\n",
      "Loss on test= 0.006147855892777443\n",
      "acc for Lsat= 0.12045264139463119 \n",
      "acc for Psat= 0.17048164637143035 \n",
      "acc for optim= 0.16786901006589933\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.005873820744454861\n",
      "Loss on test= 0.006394614931195974\n",
      "acc for Lsat= 0.15232398279791548 \n",
      "acc for Psat= 0.18070168737943498 \n",
      "acc for optim= 0.16905712584308719\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.00630831578746438\n",
      "Loss on test= 0.006526497658342123\n",
      "acc for Lsat= 0.1237962549287634 \n",
      "acc for Psat= 0.19433625849706004 \n",
      "acc for optim= 0.16919057493568462\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.006223933305591345\n",
      "Loss on test= 0.00613758061081171\n",
      "acc for Lsat= 0.12375724965233924 \n",
      "acc for Psat= 0.1759950016770548 \n",
      "acc for optim= 0.16392472098940178\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.0059890588745474815\n",
      "Loss on test= 0.006155826151371002\n",
      "acc for Lsat= 0.12860434856495861 \n",
      "acc for Psat= 0.1721613758396612 \n",
      "acc for optim= 0.16754175020213477\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.0061223264783620834\n",
      "Loss on test= 0.006514139007776976\n",
      "acc for Lsat= 0.1124080650769355 \n",
      "acc for Psat= 0.1864424988279761 \n",
      "acc for optim= 0.16943567069609197\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.006220717914402485\n",
      "Loss on test= 0.005891693755984306\n",
      "acc for Lsat= 0.12095798650125289 \n",
      "acc for Psat= 0.16554127497698032 \n",
      "acc for optim= 0.1711843646614422\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.006045832298696041\n",
      "Loss on test= 0.0059435199946165085\n",
      "acc for Lsat= 0.1336980248595471 \n",
      "acc for Psat= 0.16610594950317456 \n",
      "acc for optim= 0.16864061337774555\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.0058983624912798405\n",
      "Loss on test= 0.005793650168925524\n",
      "acc for Lsat= 0.11644962452968734 \n",
      "acc for Psat= 0.16896394608999332 \n",
      "acc for optim= 0.17015722059433167\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.006032906472682953\n",
      "Loss on test= 0.006381439045071602\n",
      "acc for Lsat= 0.1189689986402644 \n",
      "acc for Psat= 0.20330844704118578 \n",
      "acc for optim= 0.1707468172934003\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.006017598789185286\n",
      "Loss on test= 0.006163261830806732\n",
      "acc for Lsat= 0.12432045983604366 \n",
      "acc for Psat= 0.19546313025642342 \n",
      "acc for optim= 0.17202717044391327\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.006314481608569622\n",
      "Loss on test= 0.0065036979503929615\n",
      "acc for Lsat= 0.12588099953938728 \n",
      "acc for Psat= 0.1757414506703483 \n",
      "acc for optim= 0.16536578314028433\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.006118753459304571\n",
      "Loss on test= 0.006180549040436745\n",
      "acc for Lsat= 0.12782158810787714 \n",
      "acc for Psat= 0.17373814074813412 \n",
      "acc for optim= 0.1643759826333612\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.006223011761903763\n",
      "Loss on test= 0.00624663894996047\n",
      "acc for Lsat= 0.12731665253237667 \n",
      "acc for Psat= 0.17405306040077326 \n",
      "acc for optim= 0.1772383114388307\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.006006660871207714\n",
      "Loss on test= 0.0058739581145346165\n",
      "acc for Lsat= 0.12434229358513148 \n",
      "acc for Psat= 0.16926621544381132 \n",
      "acc for optim= 0.1645086751859462\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.005861691664904356\n",
      "Loss on test= 0.005860829260200262\n",
      "acc for Lsat= 0.11942139011630756 \n",
      "acc for Psat= 0.18251246788831604 \n",
      "acc for optim= 0.16960472008620214\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.0059600877575576305\n",
      "Loss on test= 0.006341219879686832\n",
      "acc for Lsat= 0.14169260902437256 \n",
      "acc for Psat= 0.17289895125400476 \n",
      "acc for optim= 0.16930829165357864\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.005832704249769449\n",
      "Loss on test= 0.005799443461000919\n",
      "acc for Lsat= 0.13034712292084952 \n",
      "acc for Psat= 0.17118108210451208 \n",
      "acc for optim= 0.16708496342304185\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.005928686819970608\n",
      "Loss on test= 0.006555058527737856\n",
      "acc for Lsat= 0.11451802888090291 \n",
      "acc for Psat= 0.17926675564479877 \n",
      "acc for optim= 0.18859323494630312\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.0061769140884280205\n",
      "Loss on test= 0.005959128029644489\n",
      "acc for Lsat= 0.12204160537648194 \n",
      "acc for Psat= 0.18214677396340326 \n",
      "acc for optim= 0.167953122047333\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.005857575219124556\n",
      "Loss on test= 0.006054389756172895\n",
      "acc for Lsat= 0.1275683437654791 \n",
      "acc for Psat= 0.1681332771526335 \n",
      "acc for optim= 0.16446735408798968\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005931702442467213\n",
      "Loss on test= 0.0058098724111914635\n",
      "acc for Lsat= 0.1221976354609069 \n",
      "acc for Psat= 0.17706207980547725 \n",
      "acc for optim= 0.16876525474504592\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.005895105190575123\n",
      "Loss on test= 0.00577534968033433\n",
      "acc for Lsat= 0.11022336619356105 \n",
      "acc for Psat= 0.16804778798536604 \n",
      "acc for optim= 0.16615901462933538\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.0058874525129795074\n",
      "Loss on test= 0.0058094230480492115\n",
      "acc for Lsat= 0.11481738357149486 \n",
      "acc for Psat= 0.17765854104790552 \n",
      "acc for optim= 0.1647069620163608\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.005887538194656372\n",
      "Loss on test= 0.006005079485476017\n",
      "acc for Lsat= 0.11274842491154748 \n",
      "acc for Psat= 0.18555645257367506 \n",
      "acc for optim= 0.16380405435897094\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.005837179720401764\n",
      "Loss on test= 0.006083356216549873\n",
      "acc for Lsat= 0.13297710931815468 \n",
      "acc for Psat= 0.17789044188936493 \n",
      "acc for optim= 0.1669026056396605\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.005897467024624348\n",
      "Loss on test= 0.006425159052014351\n",
      "acc for Lsat= 0.15626998916264415 \n",
      "acc for Psat= 0.17321037607406825 \n",
      "acc for optim= 0.1667122441163834\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.006229974329471588\n",
      "Loss on test= 0.006170470733195543\n",
      "acc for Lsat= 0.12031020419350613 \n",
      "acc for Psat= 0.18574247995747026 \n",
      "acc for optim= 0.1644487686834681\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.005960450507700443\n",
      "Loss on test= 0.006288580130785704\n",
      "acc for Lsat= 0.12025647284797349 \n",
      "acc for Psat= 0.1775206202488531 \n",
      "acc for optim= 0.16788751650391212\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.00598053028807044\n",
      "Loss on test= 0.006299050059169531\n",
      "acc for Lsat= 0.1508151736748865 \n",
      "acc for Psat= 0.18086736869323383 \n",
      "acc for optim= 0.16974429600707702\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.006149508059024811\n",
      "Loss on test= 0.006310287397354841\n",
      "acc for Lsat= 0.12905531065425258 \n",
      "acc for Psat= 0.19446998182143402 \n",
      "acc for optim= 0.16504779805935058\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.006040893029421568\n",
      "Loss on test= 0.005837693344801664\n",
      "acc for Lsat= 0.11824712770784129 \n",
      "acc for Psat= 0.1761768892015302 \n",
      "acc for optim= 0.16685756034102933\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.00593206100165844\n",
      "Loss on test= 0.006073011085391045\n",
      "acc for Lsat= 0.12636399209627966 \n",
      "acc for Psat= 0.15988513319983189 \n",
      "acc for optim= 0.16798020087377596\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.0059995586052536964\n",
      "Loss on test= 0.006239090580493212\n",
      "acc for Lsat= 0.12051299874292454 \n",
      "acc for Psat= 0.18313780335537977 \n",
      "acc for optim= 0.16624871629519966\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.006176038179546595\n",
      "Loss on test= 0.005996303632855415\n",
      "acc for Lsat= 0.12245339844073011 \n",
      "acc for Psat= 0.16258170347223436 \n",
      "acc for optim= 0.16338353300509856\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.005916933994740248\n",
      "Loss on test= 0.005950345192104578\n",
      "acc for Lsat= 0.11847025818172591 \n",
      "acc for Psat= 0.15998497741246545 \n",
      "acc for optim= 0.16602423287868323\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.005883560981601477\n",
      "Loss on test= 0.0060677905566990376\n",
      "acc for Lsat= 0.11788927191554575 \n",
      "acc for Psat= 0.17740873271599708 \n",
      "acc for optim= 0.1639657782424537\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.005911912303417921\n",
      "Loss on test= 0.00612895330414176\n",
      "acc for Lsat= 0.1250460262514959 \n",
      "acc for Psat= 0.17906664591774224 \n",
      "acc for optim= 0.16904888433989096\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005897902883589268\n",
      "Loss on test= 0.005961325019598007\n",
      "acc for Lsat= 0.11778198718702942 \n",
      "acc for Psat= 0.1747290289908223 \n",
      "acc for optim= 0.16816732076871188\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.005955686792731285\n",
      "Loss on test= 0.005979312118142843\n",
      "acc for Lsat= 0.12386935665297741 \n",
      "acc for Psat= 0.17393351144464514 \n",
      "acc for optim= 0.16581817497412762\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.00610250374302268\n",
      "Loss on test= 0.006281652953475714\n",
      "acc for Lsat= 0.13104462861464466 \n",
      "acc for Psat= 0.17528470759665454 \n",
      "acc for optim= 0.16724039800425777\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.005943672265857458\n",
      "Loss on test= 0.00593370059505105\n",
      "acc for Lsat= 0.12119315007215403 \n",
      "acc for Psat= 0.1913043381925515 \n",
      "acc for optim= 0.17044782895700827\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.005808016750961542\n",
      "Loss on test= 0.0056821550242602825\n",
      "acc for Lsat= 0.12311945489110823 \n",
      "acc for Psat= 0.17168906439995202 \n",
      "acc for optim= 0.16338852796975148\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.005870380904525518\n",
      "Loss on test= 0.006099008023738861\n",
      "acc for Lsat= 0.12161254098621588 \n",
      "acc for Psat= 0.1719453242730123 \n",
      "acc for optim= 0.16286098769219157\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.005926388781517744\n",
      "Loss on test= 0.006352074909955263\n",
      "acc for Lsat= 0.1208744122300846 \n",
      "acc for Psat= 0.20821444474367545 \n",
      "acc for optim= 0.1657726364922112\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.005916230846196413\n",
      "Loss on test= 0.005847754422575235\n",
      "acc for Lsat= 0.13248345128163605 \n",
      "acc for Psat= 0.16839161609312067 \n",
      "acc for optim= 0.16683405754537414\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.006151662208139896\n",
      "Loss on test= 0.006095698568969965\n",
      "acc for Lsat= 0.11047136849943805 \n",
      "acc for Psat= 0.17141506582855662 \n",
      "acc for optim= 0.16497320278624003\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.006205160636454821\n",
      "Loss on test= 0.006111570633947849\n",
      "acc for Lsat= 0.12741325129428407 \n",
      "acc for Psat= 0.16500407891274066 \n",
      "acc for optim= 0.16798972457252456\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.0058545880019664764\n",
      "Loss on test= 0.005992923863232136\n",
      "acc for Lsat= 0.13817168129129198 \n",
      "acc for Psat= 0.16903107748303964 \n",
      "acc for optim= 0.17340586481834572\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.005820852238684893\n",
      "Loss on test= 0.0061536808498203754\n",
      "acc for Lsat= 0.11200588312031697 \n",
      "acc for Psat= 0.17674019791367165 \n",
      "acc for optim= 0.16766277491478832\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.005843897350132465\n",
      "Loss on test= 0.005761256907135248\n",
      "acc for Lsat= 0.11463538599353931 \n",
      "acc for Psat= 0.1792184346995782 \n",
      "acc for optim= 0.17065262862691982\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.005931522697210312\n",
      "Loss on test= 0.00582838011905551\n",
      "acc for Lsat= 0.11921126199445713 \n",
      "acc for Psat= 0.16460074208215875 \n",
      "acc for optim= 0.1639794798401134\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.00590616837143898\n",
      "Loss on test= 0.0056212530471384525\n",
      "acc for Lsat= 0.1190989011205651 \n",
      "acc for Psat= 0.17954384960427666 \n",
      "acc for optim= 0.17628512805300192\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.005961200688034296\n",
      "Loss on test= 0.0060600838623940945\n",
      "acc for Lsat= 0.11597178219469513 \n",
      "acc for Psat= 0.17576968382392708 \n",
      "acc for optim= 0.1784892328369834\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.0059839882887899876\n",
      "Loss on test= 0.006008610595017672\n",
      "acc for Lsat= 0.1141179863932209 \n",
      "acc for Psat= 0.1821826426601184 \n",
      "acc for optim= 0.1765772013191914\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.005982560571283102\n",
      "Loss on test= 0.006177395116537809\n",
      "acc for Lsat= 0.11550194479718197 \n",
      "acc for Psat= 0.15466396366222446 \n",
      "acc for optim= 0.16656469452474895\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.005864981561899185\n",
      "Loss on test= 0.006391304545104504\n",
      "acc for Lsat= 0.11416392606908041 \n",
      "acc for Psat= 0.18211584357040184 \n",
      "acc for optim= 0.16200065329866373\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.0059290979988873005\n",
      "Loss on test= 0.006147047504782677\n",
      "acc for Lsat= 0.13903334101298634 \n",
      "acc for Psat= 0.1743479432763608 \n",
      "acc for optim= 0.17347604891980106\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.005892815999686718\n",
      "Loss on test= 0.005758901126682758\n",
      "acc for Lsat= 0.1179883753322822 \n",
      "acc for Psat= 0.17182746480663097 \n",
      "acc for optim= 0.16875508494362096\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.006074510980397463\n",
      "Loss on test= 0.005992195103317499\n",
      "acc for Lsat= 0.12539102523392964 \n",
      "acc for Psat= 0.16051731852073586 \n",
      "acc for optim= 0.17209676063577864\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.005949290469288826\n",
      "Loss on test= 0.006185525096952915\n",
      "acc for Lsat= 0.12157621709362453 \n",
      "acc for Psat= 0.16285318504113191 \n",
      "acc for optim= 0.170763456821127\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.0058899568393826485\n",
      "Loss on test= 0.006015549413859844\n",
      "acc for Lsat= 0.12207709567765296 \n",
      "acc for Psat= 0.178888534539461 \n",
      "acc for optim= 0.16761131599038914\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005935709923505783\n",
      "Loss on test= 0.006258643697947264\n",
      "acc for Lsat= 0.12969796033453226 \n",
      "acc for Psat= 0.18742420199202103 \n",
      "acc for optim= 0.16689130052745405\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.005961774382740259\n",
      "Loss on test= 0.0059016249142587185\n",
      "acc for Lsat= 0.11552336432061959 \n",
      "acc for Psat= 0.15923175938479364 \n",
      "acc for optim= 0.18284205348125496\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.005984131246805191\n",
      "Loss on test= 0.006187996361404657\n",
      "acc for Lsat= 0.12146908432692431 \n",
      "acc for Psat= 0.15830159404612384 \n",
      "acc for optim= 0.16398404354955298\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.005952108651399612\n",
      "Loss on test= 0.00604464253410697\n",
      "acc for Lsat= 0.10639889325790824 \n",
      "acc for Psat= 0.1640787826714537 \n",
      "acc for optim= 0.16384585259495638\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.006191881839185953\n",
      "Loss on test= 0.0061278510838747025\n",
      "acc for Lsat= 0.12471999110090798 \n",
      "acc for Psat= 0.18414024913383056 \n",
      "acc for optim= 0.17247239955712437\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.006099245976656675\n",
      "Loss on test= 0.005960163194686174\n",
      "acc for Lsat= 0.12585881361676887 \n",
      "acc for Psat= 0.16225085417522678 \n",
      "acc for optim= 0.168301179655041\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.005942565854638815\n",
      "Loss on test= 0.005790756084024906\n",
      "acc for Lsat= 0.11100286440626872 \n",
      "acc for Psat= 0.16849553735055206 \n",
      "acc for optim= 0.17349962774603006\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.005996834486722946\n",
      "Loss on test= 0.0063269068486988544\n",
      "acc for Lsat= 0.12108430836795722 \n",
      "acc for Psat= 0.16743023117984146 \n",
      "acc for optim= 0.16524194166905126\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.005813423544168472\n",
      "Loss on test= 0.005943760741502047\n",
      "acc for Lsat= 0.11874236217448236 \n",
      "acc for Psat= 0.1619004323613292 \n",
      "acc for optim= 0.1731736248825532\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.0058454289101064205\n",
      "Loss on test= 0.005773815792053938\n",
      "acc for Lsat= 0.10995562229947757 \n",
      "acc for Psat= 0.16215493143342452 \n",
      "acc for optim= 0.16892013143670565\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.005795486271381378\n",
      "Loss on test= 0.0056118411011993885\n",
      "acc for Lsat= 0.11609515610754553 \n",
      "acc for Psat= 0.1641456922290082 \n",
      "acc for optim= 0.1629898166051921\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.005789386108517647\n",
      "Loss on test= 0.006303891073912382\n",
      "acc for Lsat= 0.12337190578762454 \n",
      "acc for Psat= 0.16205437714937623 \n",
      "acc for optim= 0.16175043548856913\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.00590297719463706\n",
      "Loss on test= 0.006024849135428667\n",
      "acc for Lsat= 0.13809788540537418 \n",
      "acc for Psat= 0.15831295674256948 \n",
      "acc for optim= 0.16121667706092185\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.005847699474543333\n",
      "Loss on test= 0.0057267737574875355\n",
      "acc for Lsat= 0.13645205390659268 \n",
      "acc for Psat= 0.16780818588983026 \n",
      "acc for optim= 0.16407679861947908\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.005974546540528536\n",
      "Loss on test= 0.006105449050664902\n",
      "acc for Lsat= 0.12008302751299296 \n",
      "acc for Psat= 0.18395051864570486 \n",
      "acc for optim= 0.1678349019474243\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.006075679790228605\n",
      "Loss on test= 0.00586260249838233\n",
      "acc for Lsat= 0.12357121433809437 \n",
      "acc for Psat= 0.1800500246552818 \n",
      "acc for optim= 0.16755192329514398\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.005751385819166899\n",
      "Loss on test= 0.005686050280928612\n",
      "acc for Lsat= 0.11897494739025354 \n",
      "acc for Psat= 0.16466144901347138 \n",
      "acc for optim= 0.16830708350745546\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.005904453340917826\n",
      "Loss on test= 0.005666591227054596\n",
      "acc for Lsat= 0.11586935248251885 \n",
      "acc for Psat= 0.18608924866608456 \n",
      "acc for optim= 0.17106686214685543\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.00619463762268424\n",
      "Loss on test= 0.006349452305585146\n",
      "acc for Lsat= 0.15255639099652055 \n",
      "acc for Psat= 0.19010557927872837 \n",
      "acc for optim= 0.16461217435819372\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.006306478288024664\n",
      "Loss on test= 0.005817006342113018\n",
      "acc for Lsat= 0.1147550375852842 \n",
      "acc for Psat= 0.16422469676969764 \n",
      "acc for optim= 0.17278531460716767\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.0061280326917767525\n",
      "Loss on test= 0.0062850103713572025\n",
      "acc for Lsat= 0.1252290870633678 \n",
      "acc for Psat= 0.20060718253965182 \n",
      "acc for optim= 0.16714050115292226\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.006134760566055775\n",
      "Loss on test= 0.005899634677916765\n",
      "acc for Lsat= 0.12198940462612144 \n",
      "acc for Psat= 0.1674759616397677 \n",
      "acc for optim= 0.16725911561602638\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.005916089750826359\n",
      "Loss on test= 0.00587289547547698\n",
      "acc for Lsat= 0.11669073790147416 \n",
      "acc for Psat= 0.16827325718617972 \n",
      "acc for optim= 0.16381309553036918\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.006085692439228296\n",
      "Loss on test= 0.005995532032102346\n",
      "acc for Lsat= 0.12358823335474685 \n",
      "acc for Psat= 0.1658897550746956 \n",
      "acc for optim= 0.16086751916953143\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.005934222135692835\n",
      "Loss on test= 0.0058264597319066525\n",
      "acc for Lsat= 0.11341389129921554 \n",
      "acc for Psat= 0.16149789430218753 \n",
      "acc for optim= 0.16841591275973572\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.005927953403443098\n",
      "Loss on test= 0.0063273729756474495\n",
      "acc for Lsat= 0.132962575206408 \n",
      "acc for Psat= 0.1910280361189507 \n",
      "acc for optim= 0.1623441369544732\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.005992472637444735\n",
      "Loss on test= 0.006101684644818306\n",
      "acc for Lsat= 0.11342403418353028 \n",
      "acc for Psat= 0.16084103744228864 \n",
      "acc for optim= 0.16595647928727122\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.00592952873557806\n",
      "Loss on test= 0.005850921384990215\n",
      "acc for Lsat= 0.12717843831027542 \n",
      "acc for Psat= 0.17200219742497555 \n",
      "acc for optim= 0.17202174982702598\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.005817058030515909\n",
      "Loss on test= 0.005740918684750795\n",
      "acc for Lsat= 0.12275066986733144 \n",
      "acc for Psat= 0.17687460458015464 \n",
      "acc for optim= 0.17016111550283558\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.005831538699567318\n",
      "Loss on test= 0.0062188985757529736\n",
      "acc for Lsat= 0.15861842033238546 \n",
      "acc for Psat= 0.17737850945995642 \n",
      "acc for optim= 0.17025627932162024\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.005922615062445402\n",
      "Loss on test= 0.00590518256649375\n",
      "acc for Lsat= 0.11328602759004826 \n",
      "acc for Psat= 0.16756714900524505 \n",
      "acc for optim= 0.17122054352374697\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005945070646703243\n",
      "Loss on test= 0.006001653615385294\n",
      "acc for Lsat= 0.11018671557544499 \n",
      "acc for Psat= 0.1875916995654857 \n",
      "acc for optim= 0.16672483509928743\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.005879128817468882\n",
      "Loss on test= 0.0061186980456113815\n",
      "acc for Lsat= 0.12176186023817856 \n",
      "acc for Psat= 0.16799633309425632 \n",
      "acc for optim= 0.17388390895782346\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005840304307639599\n",
      "Loss on test= 0.005821494851261377\n",
      "acc for Lsat= 0.12906032220603633 \n",
      "acc for Psat= 0.16223292096244246 \n",
      "acc for optim= 0.1683860157705518\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.005989233963191509\n",
      "Loss on test= 0.005823865998536348\n",
      "acc for Lsat= 0.1180723494056823 \n",
      "acc for Psat= 0.16427816691489047 \n",
      "acc for optim= 0.16480022582736392\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.005820939317345619\n",
      "Loss on test= 0.006438714452087879\n",
      "acc for Lsat= 0.12984532471935725 \n",
      "acc for Psat= 0.17714866331496867 \n",
      "acc for optim= 0.1660549157775775\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.006058470346033573\n",
      "Loss on test= 0.005977303255349398\n",
      "acc for Lsat= 0.10899390875459397 \n",
      "acc for Psat= 0.15405572957997965 \n",
      "acc for optim= 0.1674166503377106\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.005984248127788305\n",
      "Loss on test= 0.006234904285520315\n",
      "acc for Lsat= 0.11796102229473528 \n",
      "acc for Psat= 0.16270807103334134 \n",
      "acc for optim= 0.16196685694376356\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.005829839035868645\n",
      "Loss on test= 0.005897819064557552\n",
      "acc for Lsat= 0.12583941677036597 \n",
      "acc for Psat= 0.16330263395424038 \n",
      "acc for optim= 0.16331260112339216\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.00582207040861249\n",
      "Loss on test= 0.0060300217010080814\n",
      "acc for Lsat= 0.10973762194555241 \n",
      "acc for Psat= 0.1755938202707487 \n",
      "acc for optim= 0.16633157418628625\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005834671668708324\n",
      "Loss on test= 0.005997644271701574\n",
      "acc for Lsat= 0.10843868241455631 \n",
      "acc for Psat= 0.1739820743170787 \n",
      "acc for optim= 0.16523981947436886\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.005666762124747038\n",
      "Loss on test= 0.00605926476418972\n",
      "acc for Lsat= 0.121546335095568 \n",
      "acc for Psat= 0.16682008670987497 \n",
      "acc for optim= 0.1778609039817663\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.005782073829323053\n",
      "Loss on test= 0.005891520529985428\n",
      "acc for Lsat= 0.11835071010225236 \n",
      "acc for Psat= 0.17994777344515692 \n",
      "acc for optim= 0.1629968890552059\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.005800903309136629\n",
      "Loss on test= 0.005682929884642363\n",
      "acc for Lsat= 0.11776162872686384 \n",
      "acc for Psat= 0.17474487872125274 \n",
      "acc for optim= 0.1665734420357448\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.00582093745470047\n",
      "Loss on test= 0.0058040618896484375\n",
      "acc for Lsat= 0.11732013209119621 \n",
      "acc for Psat= 0.17097789578853023 \n",
      "acc for optim= 0.1647720810545719\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.006049259565770626\n",
      "Loss on test= 0.005775629077106714\n",
      "acc for Lsat= 0.12477862919528175 \n",
      "acc for Psat= 0.16376922431143956 \n",
      "acc for optim= 0.16458697908357764\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.005725313443690538\n",
      "Loss on test= 0.0056508989073336124\n",
      "acc for Lsat= 0.10862297387801526 \n",
      "acc for Psat= 0.16520201486442554 \n",
      "acc for optim= 0.16472419618701287\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.005759466905146837\n",
      "Loss on test= 0.006053314544260502\n",
      "acc for Lsat= 0.14504511610416435 \n",
      "acc for Psat= 0.1722668156275963 \n",
      "acc for optim= 0.17322947358745197\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.006101271603256464\n",
      "Loss on test= 0.0060042706318199635\n",
      "acc for Lsat= 0.1318700555283293 \n",
      "acc for Psat= 0.19269864041219792 \n",
      "acc for optim= 0.1675532664556994\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005962008144706488\n",
      "Loss on test= 0.005899721756577492\n",
      "acc for Lsat= 0.11886356344395019 \n",
      "acc for Psat= 0.18608201872946764 \n",
      "acc for optim= 0.16160325166836972\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.005760878324508667\n",
      "Loss on test= 0.0055909655056893826\n",
      "acc for Lsat= 0.11590155511382634 \n",
      "acc for Psat= 0.16466092717313882 \n",
      "acc for optim= 0.16849012992485302\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.005612069275230169\n",
      "Loss on test= 0.00578964501619339\n",
      "acc for Lsat= 0.1060414764238836 \n",
      "acc for Psat= 0.1606428816614081 \n",
      "acc for optim= 0.16635530882057217\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.005621570628136396\n",
      "Loss on test= 0.00599448848515749\n",
      "acc for Lsat= 0.12431395234739899 \n",
      "acc for Psat= 0.1752172324594466 \n",
      "acc for optim= 0.17124980061750672\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.006040674168616533\n",
      "Loss on test= 0.005729240365326405\n",
      "acc for Lsat= 0.11786911883019777 \n",
      "acc for Psat= 0.167859680053929 \n",
      "acc for optim= 0.16607298999784886\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.005624949466437101\n",
      "Loss on test= 0.005737594328820705\n",
      "acc for Lsat= 0.11318664979827756 \n",
      "acc for Psat= 0.16684116089891177 \n",
      "acc for optim= 0.1638253605254962\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.006051491014659405\n",
      "Loss on test= 0.006014786660671234\n",
      "acc for Lsat= 0.1195048019433523 \n",
      "acc for Psat= 0.18385948114391304 \n",
      "acc for optim= 0.16447864956461597\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.005748568568378687\n",
      "Loss on test= 0.005509168840944767\n",
      "acc for Lsat= 0.12008113738556858 \n",
      "acc for Psat= 0.15572570159486998 \n",
      "acc for optim= 0.16441929056541207\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.0056144194677472115\n",
      "Loss on test= 0.00595956901088357\n",
      "acc for Lsat= 0.13009183820178952 \n",
      "acc for Psat= 0.16304921079132031 \n",
      "acc for optim= 0.17160097793955198\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.005696622189134359\n",
      "Loss on test= 0.0055961464531719685\n",
      "acc for Lsat= 0.11942227322956692 \n",
      "acc for Psat= 0.1632179322169159 \n",
      "acc for optim= 0.1671030857216121\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.0055986731313169\n",
      "Loss on test= 0.00598554452881217\n",
      "acc for Lsat= 0.11964923866479374 \n",
      "acc for Psat= 0.17240887919615488 \n",
      "acc for optim= 0.16600220293376705\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.005835911259055138\n",
      "Loss on test= 0.006123686209321022\n",
      "acc for Lsat= 0.130576717003203 \n",
      "acc for Psat= 0.16185065172239038 \n",
      "acc for optim= 0.16515542421266954\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.005886286497116089\n",
      "Loss on test= 0.00605841726064682\n",
      "acc for Lsat= 0.11620716700476683 \n",
      "acc for Psat= 0.1816865160631219 \n",
      "acc for optim= 0.16499660109095843\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.005931167863309383\n",
      "Loss on test= 0.006071408279240131\n",
      "acc for Lsat= 0.135001588092822 \n",
      "acc for Psat= 0.18239868238388962 \n",
      "acc for optim= 0.17039277501080996\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.005965281743556261\n",
      "Loss on test= 0.0063604083843529224\n",
      "acc for Lsat= 0.14560166482629397 \n",
      "acc for Psat= 0.17116230221733064 \n",
      "acc for optim= 0.1778982605836653\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.0060560922138392925\n",
      "Loss on test= 0.005941009148955345\n",
      "acc for Lsat= 0.12541176879391502 \n",
      "acc for Psat= 0.17518562370703974 \n",
      "acc for optim= 0.1739132701402284\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.005860016215592623\n",
      "Loss on test= 0.0058321040123701096\n",
      "acc for Lsat= 0.10809608828136284 \n",
      "acc for Psat= 0.17011518861840455 \n",
      "acc for optim= 0.16500763470256405\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.005711967591196299\n",
      "Loss on test= 0.00589605700224638\n",
      "acc for Lsat= 0.12425012636290253 \n",
      "acc for Psat= 0.15614750499701807 \n",
      "acc for optim= 0.16932228308566688\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.005744835827499628\n",
      "Loss on test= 0.005808114539831877\n",
      "acc for Lsat= 0.1087101398722577 \n",
      "acc for Psat= 0.17449498638912653 \n",
      "acc for optim= 0.16531681143018234\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005951539613306522\n",
      "Loss on test= 0.005874499212950468\n",
      "acc for Lsat= 0.1318577231416974 \n",
      "acc for Psat= 0.17410772850751136 \n",
      "acc for optim= 0.17030506806701384\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.005989754572510719\n",
      "Loss on test= 0.005755249876528978\n",
      "acc for Lsat= 0.10992263691612705 \n",
      "acc for Psat= 0.16264643868340203 \n",
      "acc for optim= 0.17095126783887454\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.005754385143518448\n",
      "Loss on test= 0.005887685809284449\n",
      "acc for Lsat= 0.1316582764237545 \n",
      "acc for Psat= 0.1709487685537268 \n",
      "acc for optim= 0.1617084674345844\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.005763152148574591\n",
      "Loss on test= 0.0058613852597773075\n",
      "acc for Lsat= 0.11276591947338406 \n",
      "acc for Psat= 0.15421990275825845 \n",
      "acc for optim= 0.16892770133504323\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.0058830659836530685\n",
      "Loss on test= 0.00561855873093009\n",
      "acc for Lsat= 0.10423604149009652 \n",
      "acc for Psat= 0.15520767737315683 \n",
      "acc for optim= 0.16265343945997301\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.00583587447181344\n",
      "Loss on test= 0.005808865651488304\n",
      "acc for Lsat= 0.13192559268921017 \n",
      "acc for Psat= 0.16169239950316272 \n",
      "acc for optim= 0.1634918401938882\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.0058158873580396175\n",
      "Loss on test= 0.005727219861000776\n",
      "acc for Lsat= 0.10517531159063298 \n",
      "acc for Psat= 0.16660473761746558 \n",
      "acc for optim= 0.17611811883009953\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.005864773411303759\n",
      "Loss on test= 0.005568103864789009\n",
      "acc for Lsat= 0.11313271403019284 \n",
      "acc for Psat= 0.17057824466492338 \n",
      "acc for optim= 0.16125944206322781\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.005637605674564838\n",
      "Loss on test= 0.005831669084727764\n",
      "acc for Lsat= 0.11550096575936894 \n",
      "acc for Psat= 0.16167133345801188 \n",
      "acc for optim= 0.17711063362366986\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.005934686865657568\n",
      "Loss on test= 0.005995319224894047\n",
      "acc for Lsat= 0.13083473888341482 \n",
      "acc for Psat= 0.17723929103640085 \n",
      "acc for optim= 0.17491501636470422\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.005863983184099197\n",
      "Loss on test= 0.0054604168981313705\n",
      "acc for Lsat= 0.11424977313807275 \n",
      "acc for Psat= 0.16576007588084726 \n",
      "acc for optim= 0.16475089953042402\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.005714272148907185\n",
      "Loss on test= 0.005785589572042227\n",
      "acc for Lsat= 0.11269817659411126 \n",
      "acc for Psat= 0.16558887590046553 \n",
      "acc for optim= 0.1754574161770162\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.005862064193934202\n",
      "Loss on test= 0.0059412503615021706\n",
      "acc for Lsat= 0.12733446658770647 \n",
      "acc for Psat= 0.1630070596514309 \n",
      "acc for optim= 0.1668084993735475\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005727131851017475\n",
      "Loss on test= 0.005574875511229038\n",
      "acc for Lsat= 0.11962027320948215 \n",
      "acc for Psat= 0.16313428673109573 \n",
      "acc for optim= 0.16457638868814684\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.005746261682361364\n",
      "Loss on test= 0.006084224209189415\n",
      "acc for Lsat= 0.11961914546859712 \n",
      "acc for Psat= 0.15989709703451907 \n",
      "acc for optim= 0.16081879764779178\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.0059879012405872345\n",
      "Loss on test= 0.006077708210796118\n",
      "acc for Lsat= 0.12554663693987783 \n",
      "acc for Psat= 0.1791757799668188 \n",
      "acc for optim= 0.16775468374033006\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.005763780325651169\n",
      "Loss on test= 0.005782518070191145\n",
      "acc for Lsat= 0.11250373700907379 \n",
      "acc for Psat= 0.18458469387915838 \n",
      "acc for optim= 0.16631807293329937\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.005862453952431679\n",
      "Loss on test= 0.005674841348081827\n",
      "acc for Lsat= 0.11641939211531772 \n",
      "acc for Psat= 0.15599725312711452 \n",
      "acc for optim= 0.163282347058452\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.005618218332529068\n",
      "Loss on test= 0.005733288824558258\n",
      "acc for Lsat= 0.12380479584562881 \n",
      "acc for Psat= 0.1772401309934975 \n",
      "acc for optim= 0.1636399243395096\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.005626088473945856\n",
      "Loss on test= 0.006332840770483017\n",
      "acc for Lsat= 0.13176310341569242 \n",
      "acc for Psat= 0.18309980732627426 \n",
      "acc for optim= 0.16334911057630372\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.005872727371752262\n",
      "Loss on test= 0.006165237631648779\n",
      "acc for Lsat= 0.12529099826215653 \n",
      "acc for Psat= 0.17224715454461614 \n",
      "acc for optim= 0.16346396099204966\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.005666025914251804\n",
      "Loss on test= 0.005890282802283764\n",
      "acc for Lsat= 0.10838357806661972 \n",
      "acc for Psat= 0.16708483173813973 \n",
      "acc for optim= 0.16890896441622613\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.005811692681163549\n",
      "Loss on test= 0.006503833457827568\n",
      "acc for Lsat= 0.16030111150988935 \n",
      "acc for Psat= 0.16386202783827242 \n",
      "acc for optim= 0.16724171419627964\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.006060258951038122\n",
      "Loss on test= 0.0059003280475735664\n",
      "acc for Lsat= 0.1080692819617783 \n",
      "acc for Psat= 0.1653139863359487 \n",
      "acc for optim= 0.1605314348827309\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.005895616952329874\n",
      "Loss on test= 0.006083403714001179\n",
      "acc for Lsat= 0.1125264677046633 \n",
      "acc for Psat= 0.1833447422490084 \n",
      "acc for optim= 0.16570879147774256\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.005697580520063639\n",
      "Loss on test= 0.0059904479421675205\n",
      "acc for Lsat= 0.11560581047180332 \n",
      "acc for Psat= 0.16348949041472421 \n",
      "acc for optim= 0.17966763992169305\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.005871888250112534\n",
      "Loss on test= 0.005697883665561676\n",
      "acc for Lsat= 0.11355715788404513 \n",
      "acc for Psat= 0.16896357317848407 \n",
      "acc for optim= 0.16645707627695455\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005650658626109362\n",
      "Loss on test= 0.005919449031352997\n",
      "acc for Lsat= 0.11724106397564724 \n",
      "acc for Psat= 0.1626682372948995 \n",
      "acc for optim= 0.16453220368389707\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.005671795457601547\n",
      "Loss on test= 0.00573375541716814\n",
      "acc for Lsat= 0.11602547326490183 \n",
      "acc for Psat= 0.16898569228942506 \n",
      "acc for optim= 0.17371187582004396\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.005651254206895828\n",
      "Loss on test= 0.006475319154560566\n",
      "acc for Lsat= 0.15083656236832188 \n",
      "acc for Psat= 0.17925396481115133 \n",
      "acc for optim= 0.17034786189902365\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005954058840870857\n",
      "Loss on test= 0.005742769222706556\n",
      "acc for Lsat= 0.11533075559497308 \n",
      "acc for Psat= 0.15409642964793938 \n",
      "acc for optim= 0.16490794027673916\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005774139426648617\n",
      "Loss on test= 0.005724660586565733\n",
      "acc for Lsat= 0.1147557974908449 \n",
      "acc for Psat= 0.16535339660716802 \n",
      "acc for optim= 0.16632009388283492\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.00601876899600029\n",
      "Loss on test= 0.006238705478608608\n",
      "acc for Lsat= 0.1656161183275037 \n",
      "acc for Psat= 0.18142001077983486 \n",
      "acc for optim= 0.16597709759878707\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.00588381290435791\n",
      "Loss on test= 0.0058062425814569\n",
      "acc for Lsat= 0.1157336146516664 \n",
      "acc for Psat= 0.17921500517735006 \n",
      "acc for optim= 0.17720406102386266\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.005950829014182091\n",
      "Loss on test= 0.005717446096241474\n",
      "acc for Lsat= 0.11610566019363752 \n",
      "acc for Psat= 0.15916384968590433 \n",
      "acc for optim= 0.16544544223791957\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.005812348332256079\n",
      "Loss on test= 0.005814782809466124\n",
      "acc for Lsat= 0.10897045739369099 \n",
      "acc for Psat= 0.19232940386093497 \n",
      "acc for optim= 0.16885906868933612\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.005793665535748005\n",
      "Loss on test= 0.006010378710925579\n",
      "acc for Lsat= 0.1327566444755133 \n",
      "acc for Psat= 0.1683678971568116 \n",
      "acc for optim= 0.16813564978430215\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005861807148903608\n",
      "Loss on test= 0.005722942762076855\n",
      "acc for Lsat= 0.10952394590827139 \n",
      "acc for Psat= 0.16801736990384744 \n",
      "acc for optim= 0.16748261349611976\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.005696173291653395\n",
      "Loss on test= 0.005579514894634485\n",
      "acc for Lsat= 0.11819702254423818 \n",
      "acc for Psat= 0.17310401795672276 \n",
      "acc for optim= 0.16732395604580036\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.005837663076817989\n",
      "Loss on test= 0.005673648323863745\n",
      "acc for Lsat= 0.10665430001205783 \n",
      "acc for Psat= 0.182426502026214 \n",
      "acc for optim= 0.1637820454241198\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.005641074385493994\n",
      "Loss on test= 0.005712401587516069\n",
      "acc for Lsat= 0.11138017752936985 \n",
      "acc for Psat= 0.15964984464084706 \n",
      "acc for optim= 0.16292721371969124\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.0059409127570688725\n",
      "Loss on test= 0.005649501457810402\n",
      "acc for Lsat= 0.10988587331214787 \n",
      "acc for Psat= 0.1575203180732756 \n",
      "acc for optim= 0.16086756879647854\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.005766207817941904\n",
      "Loss on test= 0.00578445615246892\n",
      "acc for Lsat= 0.1142970093251033 \n",
      "acc for Psat= 0.17349303347401548 \n",
      "acc for optim= 0.16690172624343225\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.005854242481291294\n",
      "Loss on test= 0.005578097887337208\n",
      "acc for Lsat= 0.11255936304801221 \n",
      "acc for Psat= 0.15847344350756454 \n",
      "acc for optim= 0.1651209213975464\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.0056104231625795364\n",
      "Loss on test= 0.005891143344342709\n",
      "acc for Lsat= 0.12587032813668908 \n",
      "acc for Psat= 0.15871951008896734 \n",
      "acc for optim= 0.16326178973589334\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.005700675304979086\n",
      "Loss on test= 0.005798643454909325\n",
      "acc for Lsat= 0.1036916511590199 \n",
      "acc for Psat= 0.17305861317062582 \n",
      "acc for optim= 0.164683503802194\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.005671089049428701\n",
      "Loss on test= 0.005767249967902899\n",
      "acc for Lsat= 0.13596615843090223 \n",
      "acc for Psat= 0.16146490790728224 \n",
      "acc for optim= 0.16489023036700853\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.0058023263700306416\n",
      "Loss on test= 0.005755735095590353\n",
      "acc for Lsat= 0.11581528653009995 \n",
      "acc for Psat= 0.15943012165688422 \n",
      "acc for optim= 0.16637571794460718\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.00562743516638875\n",
      "Loss on test= 0.00551831629127264\n",
      "acc for Lsat= 0.11515040334986248 \n",
      "acc for Psat= 0.1570080097835917 \n",
      "acc for optim= 0.168153976539002\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.005682556424289942\n",
      "Loss on test= 0.005627002567052841\n",
      "acc for Lsat= 0.11837365920065487 \n",
      "acc for Psat= 0.15993337833092605 \n",
      "acc for optim= 0.16370181401794684\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.005777833517640829\n",
      "Loss on test= 0.005797446705400944\n",
      "acc for Lsat= 0.12094541276156953 \n",
      "acc for Psat= 0.17438507325779348 \n",
      "acc for optim= 0.16395907079517988\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.005688623990863562\n",
      "Loss on test= 0.0058827875182032585\n",
      "acc for Lsat= 0.12163563454236577 \n",
      "acc for Psat= 0.1594714776655491 \n",
      "acc for optim= 0.16406447615657738\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.005626226309686899\n",
      "Loss on test= 0.0059424941428005695\n",
      "acc for Lsat= 0.11889327187285793 \n",
      "acc for Psat= 0.1661988400745621 \n",
      "acc for optim= 0.16444107647485734\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005556557327508926\n",
      "Loss on test= 0.005459262523800135\n",
      "acc for Lsat= 0.10625278357710576 \n",
      "acc for Psat= 0.14980917556051673 \n",
      "acc for optim= 0.16677986330280356\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.0056832884438335896\n",
      "Loss on test= 0.005439421162009239\n",
      "acc for Lsat= 0.10594562822036489 \n",
      "acc for Psat= 0.16022887287407364 \n",
      "acc for optim= 0.16741026426520753\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.005864041857421398\n",
      "Loss on test= 0.005652470514178276\n",
      "acc for Lsat= 0.11511719342328237 \n",
      "acc for Psat= 0.1682885229737302 \n",
      "acc for optim= 0.1647499776622312\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.006001165136694908\n",
      "Loss on test= 0.0056342557072639465\n",
      "acc for Lsat= 0.1243430478394608 \n",
      "acc for Psat= 0.15014486186447432 \n",
      "acc for optim= 0.1696547186894915\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.005830479320138693\n",
      "Loss on test= 0.005707404110580683\n",
      "acc for Lsat= 0.11192995228034183 \n",
      "acc for Psat= 0.1621849890316544 \n",
      "acc for optim= 0.16135897796404017\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.005723882932215929\n",
      "Loss on test= 0.00571242393925786\n",
      "acc for Lsat= 0.10962102791755397 \n",
      "acc for Psat= 0.16129542388276802 \n",
      "acc for optim= 0.17006788020178745\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.005706058349460363\n",
      "Loss on test= 0.005687067285180092\n",
      "acc for Lsat= 0.11471712717070044 \n",
      "acc for Psat= 0.17563357843657187 \n",
      "acc for optim= 0.169048679714497\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.005596545524895191\n",
      "Loss on test= 0.005796222947537899\n",
      "acc for Lsat= 0.12487908128044896 \n",
      "acc for Psat= 0.17051839041114608 \n",
      "acc for optim= 0.16158272150543682\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.005697098094969988\n",
      "Loss on test= 0.006003381218761206\n",
      "acc for Lsat= 0.1358478727936902 \n",
      "acc for Psat= 0.15299822460184334 \n",
      "acc for optim= 0.17906797556246898\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.0058958097361028194\n",
      "Loss on test= 0.005863169673830271\n",
      "acc for Lsat= 0.12112245551275377 \n",
      "acc for Psat= 0.15538910789601268 \n",
      "acc for optim= 0.17137678890493763\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.0055429027415812016\n",
      "Loss on test= 0.006183191668242216\n",
      "acc for Lsat= 0.13008809994357148 \n",
      "acc for Psat= 0.16242473535837504 \n",
      "acc for optim= 0.17170228569385299\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.00573302898555994\n",
      "Loss on test= 0.005720800720155239\n",
      "acc for Lsat= 0.11077997701048278 \n",
      "acc for Psat= 0.16796221414532173 \n",
      "acc for optim= 0.16352416480651447\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.0056371730752289295\n",
      "Loss on test= 0.005590382497757673\n",
      "acc for Lsat= 0.12221900999606619 \n",
      "acc for Psat= 0.15131644577645234 \n",
      "acc for optim= 0.16344774696394657\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.005724627990275621\n",
      "Loss on test= 0.005630466155707836\n",
      "acc for Lsat= 0.11437377910236113 \n",
      "acc for Psat= 0.16264308298500632 \n",
      "acc for optim= 0.16782498966330348\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.005847177468240261\n",
      "Loss on test= 0.006014526821672916\n",
      "acc for Lsat= 0.1394272103255856 \n",
      "acc for Psat= 0.18611084372812026 \n",
      "acc for optim= 0.1656861068795233\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.005593957379460335\n",
      "Loss on test= 0.006053268909454346\n",
      "acc for Lsat= 0.13141469984699095 \n",
      "acc for Psat= 0.16492928082123007 \n",
      "acc for optim= 0.1692688864344303\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.006067389622330666\n",
      "Loss on test= 0.006389888469129801\n",
      "acc for Lsat= 0.13652554859908303 \n",
      "acc for Psat= 0.21138031850373531 \n",
      "acc for optim= 0.16394452760298894\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.006042377557605505\n",
      "Loss on test= 0.006155575625598431\n",
      "acc for Lsat= 0.15564760082909473 \n",
      "acc for Psat= 0.15900584485341432 \n",
      "acc for optim= 0.16911940427510402\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.005879594478756189\n",
      "Loss on test= 0.005852881353348494\n",
      "acc for Lsat= 0.12014801110116595 \n",
      "acc for Psat= 0.17312128939030683 \n",
      "acc for optim= 0.161609987277385\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.005674288608133793\n",
      "Loss on test= 0.005614877212792635\n",
      "acc for Lsat= 0.10791049115892452 \n",
      "acc for Psat= 0.15135944788840247 \n",
      "acc for optim= 0.162548905346272\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.005609702318906784\n",
      "Loss on test= 0.005583598744124174\n",
      "acc for Lsat= 0.11417762953548131 \n",
      "acc for Psat= 0.16858184664640766 \n",
      "acc for optim= 0.16121122667538804\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.00567824998870492\n",
      "Loss on test= 0.005715970881283283\n",
      "acc for Lsat= 0.11218520834095339 \n",
      "acc for Psat= 0.15995272851904627 \n",
      "acc for optim= 0.1594285076779842\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005575972609221935\n",
      "Loss on test= 0.005595956463366747\n",
      "acc for Lsat= 0.12293241790526686 \n",
      "acc for Psat= 0.15533901369289616 \n",
      "acc for optim= 0.16392293897808632\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.005603061523288488\n",
      "Loss on test= 0.005517595447599888\n",
      "acc for Lsat= 0.10310960519062654 \n",
      "acc for Psat= 0.14439048987647718 \n",
      "acc for optim= 0.16586138799784994\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.005732791963964701\n",
      "Loss on test= 0.005531105678528547\n",
      "acc for Lsat= 0.10831213690815619 \n",
      "acc for Psat= 0.1591810274423207 \n",
      "acc for optim= 0.16157131092965044\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.005668914411216974\n",
      "Loss on test= 0.005659546237438917\n",
      "acc for Lsat= 0.11157942322785636 \n",
      "acc for Psat= 0.16372925385656198 \n",
      "acc for optim= 0.16444664908979306\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.005610520951449871\n",
      "Loss on test= 0.005996406078338623\n",
      "acc for Lsat= 0.12440077408108344 \n",
      "acc for Psat= 0.163538961686238 \n",
      "acc for optim= 0.16804602840125585\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.0056661758571863174\n",
      "Loss on test= 0.0054411557503044605\n",
      "acc for Lsat= 0.10471178900941694 \n",
      "acc for Psat= 0.1479147422320927 \n",
      "acc for optim= 0.16308063126082226\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.005705498158931732\n",
      "Loss on test= 0.00582544319331646\n",
      "acc for Lsat= 0.11373083388064736 \n",
      "acc for Psat= 0.18871981091767856 \n",
      "acc for optim= 0.1644713337207921\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.005848871078342199\n",
      "Loss on test= 0.005785225424915552\n",
      "acc for Lsat= 0.13745699373936765 \n",
      "acc for Psat= 0.16492023177873896 \n",
      "acc for optim= 0.16578751768070474\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.005762767978012562\n",
      "Loss on test= 0.005757772363722324\n",
      "acc for Lsat= 0.13290449242639304 \n",
      "acc for Psat= 0.1612669179370199 \n",
      "acc for optim= 0.17107433571220246\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.00566859869286418\n",
      "Loss on test= 0.005746801849454641\n",
      "acc for Lsat= 0.11079343550011038 \n",
      "acc for Psat= 0.1637503423618811 \n",
      "acc for optim= 0.16534872782073295\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.0055885291658341885\n",
      "Loss on test= 0.005541586317121983\n",
      "acc for Lsat= 0.1086096785249931 \n",
      "acc for Psat= 0.14760314243321282 \n",
      "acc for optim= 0.1621032328654798\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.005515778437256813\n",
      "Loss on test= 0.005544611718505621\n",
      "acc for Lsat= 0.1087564354511906 \n",
      "acc for Psat= 0.1596614286345603 \n",
      "acc for optim= 0.16215592453227146\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.005583714693784714\n",
      "Loss on test= 0.005602184217423201\n",
      "acc for Lsat= 0.11101164647009903 \n",
      "acc for Psat= 0.1555160904063486 \n",
      "acc for optim= 0.1642724669780708\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005714063998311758\n",
      "Loss on test= 0.005505288951098919\n",
      "acc for Lsat= 0.11507746730564355 \n",
      "acc for Psat= 0.15402817279804415 \n",
      "acc for optim= 0.15998536624553977\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005645527504384518\n",
      "Loss on test= 0.005451659671962261\n",
      "acc for Lsat= 0.12583438951401762 \n",
      "acc for Psat= 0.16031313253296428 \n",
      "acc for optim= 0.1668294652827663\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.005598371382802725\n",
      "Loss on test= 0.005617571994662285\n",
      "acc for Lsat= 0.10831662081334405 \n",
      "acc for Psat= 0.16451151000942568 \n",
      "acc for optim= 0.16678392412791868\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.005740620661526918\n",
      "Loss on test= 0.005679063033312559\n",
      "acc for Lsat= 0.10653777262258872 \n",
      "acc for Psat= 0.1511325478871161 \n",
      "acc for optim= 0.1639292446119283\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.005670950282365084\n",
      "Loss on test= 0.006199818104505539\n",
      "acc for Lsat= 0.13451197362220793 \n",
      "acc for Psat= 0.1778446588857175 \n",
      "acc for optim= 0.16851990309274895\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.005812447518110275\n",
      "Loss on test= 0.00554869556799531\n",
      "acc for Lsat= 0.11671797147829312 \n",
      "acc for Psat= 0.15728451782637717 \n",
      "acc for optim= 0.16272800360103074\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.006005112547427416\n",
      "Loss on test= 0.005819603335112333\n",
      "acc for Lsat= 0.13366539581919504 \n",
      "acc for Psat= 0.1534039390822432 \n",
      "acc for optim= 0.17850441263539865\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.005924819968640804\n",
      "Loss on test= 0.005421678069978952\n",
      "acc for Lsat= 0.10971378332524674 \n",
      "acc for Psat= 0.17218621111572469 \n",
      "acc for optim= 0.16955859822258856\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.0057235537096858025\n",
      "Loss on test= 0.005575901363044977\n",
      "acc for Lsat= 0.13447336425904083 \n",
      "acc for Psat= 0.15495521036358992 \n",
      "acc for optim= 0.1608496407985494\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.005759233143180609\n",
      "Loss on test= 0.005805424880236387\n",
      "acc for Lsat= 0.10824431075576973 \n",
      "acc for Psat= 0.16054079017595616 \n",
      "acc for optim= 0.1738031193337913\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005707892589271069\n",
      "Loss on test= 0.00566746573895216\n",
      "acc for Lsat= 0.11363718365705486 \n",
      "acc for Psat= 0.14697884235175554 \n",
      "acc for optim= 0.1633096181872502\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.005680915433913469\n",
      "Loss on test= 0.0057229637168347836\n",
      "acc for Lsat= 0.11597611650575197 \n",
      "acc for Psat= 0.1637655363391344 \n",
      "acc for optim= 0.16022712297696695\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.005587282124906778\n",
      "Loss on test= 0.005580591037869453\n",
      "acc for Lsat= 0.1118282818768765 \n",
      "acc for Psat= 0.15725252879988025 \n",
      "acc for optim= 0.16396691543254624\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.005516341421753168\n",
      "Loss on test= 0.005569075234234333\n",
      "acc for Lsat= 0.10963366069097753 \n",
      "acc for Psat= 0.15329197159553587 \n",
      "acc for optim= 0.1696464712577172\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.005636577494442463\n",
      "Loss on test= 0.005466228350996971\n",
      "acc for Lsat= 0.10595103503244999 \n",
      "acc for Psat= 0.1523829310211334 \n",
      "acc for optim= 0.1635391330893145\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.005515454802662134\n",
      "Loss on test= 0.005631370935589075\n",
      "acc for Lsat= 0.11662544161287917 \n",
      "acc for Psat= 0.16442766270116665 \n",
      "acc for optim= 0.16879281567093427\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.005629284307360649\n",
      "Loss on test= 0.005787733476608992\n",
      "acc for Lsat= 0.11475436009401607 \n",
      "acc for Psat= 0.16003305207109284 \n",
      "acc for optim= 0.1774702902468955\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.005514431744813919\n",
      "Loss on test= 0.005532114300876856\n",
      "acc for Lsat= 0.10630919646197022 \n",
      "acc for Psat= 0.15154960822651078 \n",
      "acc for optim= 0.16488838515392304\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.005593528505414724\n",
      "Loss on test= 0.005755990743637085\n",
      "acc for Lsat= 0.11322915997358929 \n",
      "acc for Psat= 0.15698441297364124 \n",
      "acc for optim= 0.17225466682607107\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.0056583029218018055\n",
      "Loss on test= 0.0054509639739990234\n",
      "acc for Lsat= 0.11466053165625183 \n",
      "acc for Psat= 0.15506994862005594 \n",
      "acc for optim= 0.16415071031637174\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.0055450089275836945\n",
      "Loss on test= 0.005936349742114544\n",
      "acc for Lsat= 0.11111231232172104 \n",
      "acc for Psat= 0.17475528079317096 \n",
      "acc for optim= 0.16261135280365124\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.005676005035638809\n",
      "Loss on test= 0.005812438204884529\n",
      "acc for Lsat= 0.12125266206095221 \n",
      "acc for Psat= 0.15352796999630644 \n",
      "acc for optim= 0.16992621440235903\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.0056111766025424\n",
      "Loss on test= 0.006137578748166561\n",
      "acc for Lsat= 0.14600188087889684 \n",
      "acc for Psat= 0.1654370385371589 \n",
      "acc for optim= 0.1709352715080132\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.005534210707992315\n",
      "Loss on test= 0.00575705012306571\n",
      "acc for Lsat= 0.11338029180975305 \n",
      "acc for Psat= 0.15915209792375035 \n",
      "acc for optim= 0.17219581395339273\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.0058097257278859615\n",
      "Loss on test= 0.006097066681832075\n",
      "acc for Lsat= 0.11612439251385277 \n",
      "acc for Psat= 0.15818548438019697 \n",
      "acc for optim= 0.16463377589605296\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.005699794739484787\n",
      "Loss on test= 0.005755030550062656\n",
      "acc for Lsat= 0.11289069258330257 \n",
      "acc for Psat= 0.1594716585489034 \n",
      "acc for optim= 0.1616209659145711\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.005777978803962469\n",
      "Loss on test= 0.005598445422947407\n",
      "acc for Lsat= 0.11062873002850432 \n",
      "acc for Psat= 0.15925955651147053 \n",
      "acc for optim= 0.16739238094639922\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.005639992188662291\n",
      "Loss on test= 0.00553075922653079\n",
      "acc for Lsat= 0.10686498749045485 \n",
      "acc for Psat= 0.17421455488589788 \n",
      "acc for optim= 0.16574313398627596\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.005775496829301119\n",
      "Loss on test= 0.006009483244270086\n",
      "acc for Lsat= 0.1532359171369781 \n",
      "acc for Psat= 0.16156271626862911 \n",
      "acc for optim= 0.163931702789882\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.00565374968573451\n",
      "Loss on test= 0.005745886825025082\n",
      "acc for Lsat= 0.12555670528343252 \n",
      "acc for Psat= 0.15687756025112617 \n",
      "acc for optim= 0.1620226813825571\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.0054894788190722466\n",
      "Loss on test= 0.005373504478484392\n",
      "acc for Lsat= 0.1172098515836616 \n",
      "acc for Psat= 0.15746833350292305 \n",
      "acc for optim= 0.1634228815634521\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.0056104278191924095\n",
      "Loss on test= 0.0057249232195317745\n",
      "acc for Lsat= 0.13285870400901528 \n",
      "acc for Psat= 0.1628899542204611 \n",
      "acc for optim= 0.1622322009792992\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.005707485135644674\n",
      "Loss on test= 0.00544416019693017\n",
      "acc for Lsat= 0.10289880509242573 \n",
      "acc for Psat= 0.1586057683422975 \n",
      "acc for optim= 0.16119415177672636\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.0056153154000639915\n",
      "Loss on test= 0.0056389677338302135\n",
      "acc for Lsat= 0.11338480026574256 \n",
      "acc for Psat= 0.16312688059755404 \n",
      "acc for optim= 0.15915533174439908\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.0057052914053201675\n",
      "Loss on test= 0.0055208285339176655\n",
      "acc for Lsat= 0.11280899973756253 \n",
      "acc for Psat= 0.14772552672720113 \n",
      "acc for optim= 0.16608345973155164\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005527487490326166\n",
      "Loss on test= 0.005850763060152531\n",
      "acc for Lsat= 0.12511223944799182 \n",
      "acc for Psat= 0.15513398958864855 \n",
      "acc for optim= 0.1746742087884372\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.005654559936374426\n",
      "Loss on test= 0.006347125396132469\n",
      "acc for Lsat= 0.12831565383729301 \n",
      "acc for Psat= 0.17199006312079587 \n",
      "acc for optim= 0.15923066267517955\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.005608016159385443\n",
      "Loss on test= 0.005409225355833769\n",
      "acc for Lsat= 0.11298060539411381 \n",
      "acc for Psat= 0.1657854958897145 \n",
      "acc for optim= 0.1664880528594556\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.005706531926989555\n",
      "Loss on test= 0.005598551593720913\n",
      "acc for Lsat= 0.11493006339760786 \n",
      "acc for Psat= 0.15298826895997156 \n",
      "acc for optim= 0.16985710360274203\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.005721535533666611\n",
      "Loss on test= 0.005713986232876778\n",
      "acc for Lsat= 0.11393751296398821 \n",
      "acc for Psat= 0.15415797450121907 \n",
      "acc for optim= 0.16171603735042359\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.005594450980424881\n",
      "Loss on test= 0.005769895389676094\n",
      "acc for Lsat= 0.11462214943507255 \n",
      "acc for Psat= 0.16144794538362278 \n",
      "acc for optim= 0.16118527763029994\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.00552706141024828\n",
      "Loss on test= 0.0054329438135027885\n",
      "acc for Lsat= 0.10855953578976442 \n",
      "acc for Psat= 0.1631072562794961 \n",
      "acc for optim= 0.16212067010626532\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.0055265529081225395\n",
      "Loss on test= 0.005462139844894409\n",
      "acc for Lsat= 0.12105275629449819 \n",
      "acc for Psat= 0.15485622943570715 \n",
      "acc for optim= 0.16236690578315993\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.00569122051820159\n",
      "Loss on test= 0.005601737182587385\n",
      "acc for Lsat= 0.11232739955611012 \n",
      "acc for Psat= 0.15797611228048777 \n",
      "acc for optim= 0.16143794246080861\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.0054092868231236935\n",
      "Loss on test= 0.0054906681180000305\n",
      "acc for Lsat= 0.11537323305359727 \n",
      "acc for Psat= 0.14958931351220844 \n",
      "acc for optim= 0.16693575054951243\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.005599338561296463\n",
      "Loss on test= 0.0056017483584582806\n",
      "acc for Lsat= 0.1116035851401476 \n",
      "acc for Psat= 0.1525237090829398 \n",
      "acc for optim= 0.1645459721792675\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.005669131875038147\n",
      "Loss on test= 0.005791296251118183\n",
      "acc for Lsat= 0.12489486059505883 \n",
      "acc for Psat= 0.14924135405090055 \n",
      "acc for optim= 0.162663745134176\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.00561594869941473\n",
      "Loss on test= 0.005652523599565029\n",
      "acc for Lsat= 0.10236132448266584 \n",
      "acc for Psat= 0.17266141268398338 \n",
      "acc for optim= 0.16305100849559814\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.005686984397470951\n",
      "Loss on test= 0.005348938517272472\n",
      "acc for Lsat= 0.10206213500453953 \n",
      "acc for Psat= 0.14962965414314247 \n",
      "acc for optim= 0.16586144326012456\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005521439015865326\n",
      "Loss on test= 0.005626462399959564\n",
      "acc for Lsat= 0.12975134455405782 \n",
      "acc for Psat= 0.15580380840824423 \n",
      "acc for optim= 0.16766711398550133\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.005578337237238884\n",
      "Loss on test= 0.005484307650476694\n",
      "acc for Lsat= 0.1116806124694916 \n",
      "acc for Psat= 0.17855729453750993 \n",
      "acc for optim= 0.1637415398287664\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.005375919863581657\n",
      "Loss on test= 0.0057260747998952866\n",
      "acc for Lsat= 0.1320048994074003 \n",
      "acc for Psat= 0.15161451332912562 \n",
      "acc for optim= 0.16647540409301015\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.005629286170005798\n",
      "Loss on test= 0.005951183382421732\n",
      "acc for Lsat= 0.13722051360978307 \n",
      "acc for Psat= 0.15620289796218434 \n",
      "acc for optim= 0.17154692402717145\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.005711992271244526\n",
      "Loss on test= 0.005472849123179913\n",
      "acc for Lsat= 0.107569575792818 \n",
      "acc for Psat= 0.15930298937155385 \n",
      "acc for optim= 0.16957165592435017\n",
      "Fold 2\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.9421107769012451\n",
      "Loss on test= 0.57157963514328\n",
      "acc for Lsat= 6.048896396806388 \n",
      "acc for Psat= 11.529929363552633 \n",
      "acc for optim= 1.2475318807944957\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.5393572449684143\n",
      "Loss on test= 0.5033682584762573\n",
      "acc for Lsat= 12.421218560974552 \n",
      "acc for Psat= 41.93104150207915 \n",
      "acc for optim= 2.539654662184468\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.4594665467739105\n",
      "Loss on test= 0.48962756991386414\n",
      "acc for Lsat= 21.634140383124954 \n",
      "acc for Psat= 22.005045902169808 \n",
      "acc for optim= 3.077000049070685\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.4087694585323334\n",
      "Loss on test= 0.36184218525886536\n",
      "acc for Lsat= 9.716119138379204 \n",
      "acc for Psat= 17.17068087513424 \n",
      "acc for optim= 2.644090814094336\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.3966430723667145\n",
      "Loss on test= 0.3775748312473297\n",
      "acc for Lsat= 9.213245876227832 \n",
      "acc for Psat= 5.477643983644698 \n",
      "acc for optim= 4.678201397086456\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.3645205795764923\n",
      "Loss on test= 0.30066579580307007\n",
      "acc for Lsat= 11.964580499920467 \n",
      "acc for Psat= 4.624502483574434 \n",
      "acc for optim= 1.844414744352164\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.309841513633728\n",
      "Loss on test= 0.31714510917663574\n",
      "acc for Lsat= 5.31730742971696 \n",
      "acc for Psat= 5.478628837012661 \n",
      "acc for optim= 1.7189918992666502\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.29292163252830505\n",
      "Loss on test= 0.26495876908302307\n",
      "acc for Lsat= 7.658069001672777 \n",
      "acc for Psat= 4.324478705110016 \n",
      "acc for optim= 3.64965129147655\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.25851643085479736\n",
      "Loss on test= 0.2737513780593872\n",
      "acc for Lsat= 4.3094981106334815 \n",
      "acc for Psat= 2.6481584099835613 \n",
      "acc for optim= 3.4726959254775145\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.23324111104011536\n",
      "Loss on test= 0.23030701279640198\n",
      "acc for Lsat= 5.608582095998163 \n",
      "acc for Psat= 2.560585049509599 \n",
      "acc for optim= 1.509141289155515\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.21420589089393616\n",
      "Loss on test= 0.20280854403972626\n",
      "acc for Lsat= 2.237610107415192 \n",
      "acc for Psat= 3.80239037372411 \n",
      "acc for optim= 3.0391295950523913\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.18843145668506622\n",
      "Loss on test= 0.18124012649059296\n",
      "acc for Lsat= 3.489567167613721 \n",
      "acc for Psat= 2.1695641108947443 \n",
      "acc for optim= 2.658984383461388\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.16123536229133606\n",
      "Loss on test= 0.1587335169315338\n",
      "acc for Lsat= 2.9989019554077703 \n",
      "acc for Psat= 1.7499279245904118 \n",
      "acc for optim= 3.3149464336558987\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.12905927002429962\n",
      "Loss on test= 0.1314142495393753\n",
      "acc for Lsat= 1.6518029101280263 \n",
      "acc for Psat= 2.4360612959921912 \n",
      "acc for optim= 1.5124256443255895\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.11883750557899475\n",
      "Loss on test= 0.10877552628517151\n",
      "acc for Lsat= 1.649589802319423 \n",
      "acc for Psat= 1.6762701437408984 \n",
      "acc for optim= 2.7267135643125733\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.10268629342317581\n",
      "Loss on test= 0.10055642575025558\n",
      "acc for Lsat= 1.7429132075300693 \n",
      "acc for Psat= 1.0469268873865665 \n",
      "acc for optim= 2.670449329823306\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.08890126645565033\n",
      "Loss on test= 0.0917537659406662\n",
      "acc for Lsat= 1.093164316834756 \n",
      "acc for Psat= 1.078444893169846 \n",
      "acc for optim= 1.2797971789928064\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.07865577936172485\n",
      "Loss on test= 0.07463235408067703\n",
      "acc for Lsat= 1.2435573306905319 \n",
      "acc for Psat= 1.3892706746095478 \n",
      "acc for optim= 1.9013346884508988\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.06810007989406586\n",
      "Loss on test= 0.06851579993963242\n",
      "acc for Lsat= 0.86885551986681 \n",
      "acc for Psat= 1.2373408143543496 \n",
      "acc for optim= 0.7560573213724293\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.062631756067276\n",
      "Loss on test= 0.060578927397727966\n",
      "acc for Lsat= 0.8743643212931331 \n",
      "acc for Psat= 1.0514797277861068 \n",
      "acc for optim= 1.1271790159060746\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.057439666241407394\n",
      "Loss on test= 0.05520084872841835\n",
      "acc for Lsat= 0.9931624456422051 \n",
      "acc for Psat= 0.7683473709794516 \n",
      "acc for optim= 1.3409405860230263\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.055038414895534515\n",
      "Loss on test= 0.05226577818393707\n",
      "acc for Lsat= 0.8149579510087229 \n",
      "acc for Psat= 0.7785391080448076 \n",
      "acc for optim= 0.8824786769068482\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.04885019734501839\n",
      "Loss on test= 0.04930038005113602\n",
      "acc for Lsat= 0.6931274832689244 \n",
      "acc for Psat= 1.0350388898646947 \n",
      "acc for optim= 1.7305584499357596\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.04602374881505966\n",
      "Loss on test= 0.044888198375701904\n",
      "acc for Lsat= 0.7846389275181462 \n",
      "acc for Psat= 0.6327106196109231 \n",
      "acc for optim= 1.1450377703452408\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.0410955473780632\n",
      "Loss on test= 0.04204605147242546\n",
      "acc for Lsat= 0.7062102114314502 \n",
      "acc for Psat= 0.7319411912294281 \n",
      "acc for optim= 16.480182798916363\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.03888554871082306\n",
      "Loss on test= 0.03852308169007301\n",
      "acc for Lsat= 0.8105386527761741 \n",
      "acc for Psat= 0.7107043920735344 \n",
      "acc for optim= 0.617689383397118\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.03725004196166992\n",
      "Loss on test= 0.039364300668239594\n",
      "acc for Lsat= 0.6434006460943704 \n",
      "acc for Psat= 0.8317487152555161 \n",
      "acc for optim= 0.4369846808432477\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.03582482412457466\n",
      "Loss on test= 0.03864254802465439\n",
      "acc for Lsat= 0.587428375432422 \n",
      "acc for Psat= 0.6090855471100785 \n",
      "acc for optim= 0.5525367729085799\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.03506757691502571\n",
      "Loss on test= 0.03990184888243675\n",
      "acc for Lsat= 0.661314103624947 \n",
      "acc for Psat= 0.6080640725677595 \n",
      "acc for optim= 0.6933198284178443\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.03478282690048218\n",
      "Loss on test= 0.03455948829650879\n",
      "acc for Lsat= 0.6033718935560083 \n",
      "acc for Psat= 0.6519145836221444 \n",
      "acc for optim= 3.4422095834483657\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.03135237842798233\n",
      "Loss on test= 0.03250565379858017\n",
      "acc for Lsat= 0.6646999468080262 \n",
      "acc for Psat= 0.6511147260558524 \n",
      "acc for optim= 0.3871826733533502\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.03126643970608711\n",
      "Loss on test= 0.029597176238894463\n",
      "acc for Lsat= 0.5953031705008667 \n",
      "acc for Psat= 0.5900996709580697 \n",
      "acc for optim= 0.43666448621228776\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.030131027102470398\n",
      "Loss on test= 0.03341991454362869\n",
      "acc for Lsat= 0.5336223391602067 \n",
      "acc for Psat= 0.6801225741549609 \n",
      "acc for optim= 0.2892994755938825\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.029191577807068825\n",
      "Loss on test= 0.03164946660399437\n",
      "acc for Lsat= 0.5022685467582149 \n",
      "acc for Psat= 0.6578475998225307 \n",
      "acc for optim= 0.3037468404543541\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.028132952749729156\n",
      "Loss on test= 0.030110836029052734\n",
      "acc for Lsat= 0.656030606115171 \n",
      "acc for Psat= 0.6134724963855194 \n",
      "acc for optim= 0.5273665084556293\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.027771595865488052\n",
      "Loss on test= 0.028057213872671127\n",
      "acc for Lsat= 0.489610708632156 \n",
      "acc for Psat= 0.670362476030179 \n",
      "acc for optim= 0.8366872614746712\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.025404049083590508\n",
      "Loss on test= 0.027863100171089172\n",
      "acc for Lsat= 0.5263050751958921 \n",
      "acc for Psat= 0.5682991134687925 \n",
      "acc for optim= 0.40829988595843947\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.027274778112769127\n",
      "Loss on test= 0.028075044974684715\n",
      "acc for Lsat= 0.49330122293227957 \n",
      "acc for Psat= 0.6065221324097365 \n",
      "acc for optim= 0.375466398708365\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.02554619498550892\n",
      "Loss on test= 0.02852725051343441\n",
      "acc for Lsat= 0.5587791773947617 \n",
      "acc for Psat= 0.578131087148732 \n",
      "acc for optim= 0.3400031134104309\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.025067465379834175\n",
      "Loss on test= 0.025094686076045036\n",
      "acc for Lsat= 0.583960005675279 \n",
      "acc for Psat= 0.53448069414446 \n",
      "acc for optim= 0.3951805350610615\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.024029623717069626\n",
      "Loss on test= 0.02627529948949814\n",
      "acc for Lsat= 0.46821635216159896 \n",
      "acc for Psat= 0.49881108232452914 \n",
      "acc for optim= 0.290230423848796\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.02485056407749653\n",
      "Loss on test= 0.025144431740045547\n",
      "acc for Lsat= 0.5430362038538521 \n",
      "acc for Psat= 0.5295584030430512 \n",
      "acc for optim= 0.3300434684523852\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.023946236819028854\n",
      "Loss on test= 0.027661185711622238\n",
      "acc for Lsat= 0.41750757101879177 \n",
      "acc for Psat= 0.6370301674256995 \n",
      "acc for optim= 0.31246352091201934\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.024256909266114235\n",
      "Loss on test= 0.026898706331849098\n",
      "acc for Lsat= 0.4381689519374246 \n",
      "acc for Psat= 0.6223692848552428 \n",
      "acc for optim= 0.292922999404451\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.023871665820479393\n",
      "Loss on test= 0.024343308061361313\n",
      "acc for Lsat= 0.49066681075350355 \n",
      "acc for Psat= 0.5762213974618086 \n",
      "acc for optim= 0.3762442495139407\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.023511935025453568\n",
      "Loss on test= 0.02459169365465641\n",
      "acc for Lsat= 0.4850827658069525 \n",
      "acc for Psat= 0.5720249827317201 \n",
      "acc for optim= 2.6723239310612787\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.02237384021282196\n",
      "Loss on test= 0.02581910416483879\n",
      "acc for Lsat= 0.4891491035824229 \n",
      "acc for Psat= 0.5338207442585593 \n",
      "acc for optim= 0.3099095776612336\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.021848654374480247\n",
      "Loss on test= 0.02286452054977417\n",
      "acc for Lsat= 0.4940275361185667 \n",
      "acc for Psat= 0.5540094552892009 \n",
      "acc for optim= 0.32231265509255685\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.02243700623512268\n",
      "Loss on test= 0.023293722420930862\n",
      "acc for Lsat= 0.48895710445803825 \n",
      "acc for Psat= 0.5255555091292056 \n",
      "acc for optim= 0.32275998378266907\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.022635215893387794\n",
      "Loss on test= 0.02435617335140705\n",
      "acc for Lsat= 0.4852274235234143 \n",
      "acc for Psat= 0.5315517131671801 \n",
      "acc for optim= 0.3296757410901813\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.02240227349102497\n",
      "Loss on test= 0.024425705894827843\n",
      "acc for Lsat= 0.3863556980011069 \n",
      "acc for Psat= 0.5421768857367342 \n",
      "acc for optim= 0.3928416723572662\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.02301546186208725\n",
      "Loss on test= 0.02546679601073265\n",
      "acc for Lsat= 0.4515761349543322 \n",
      "acc for Psat= 0.5628477290124834 \n",
      "acc for optim= 0.4855960360248384\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.022495117038488388\n",
      "Loss on test= 0.02400616928935051\n",
      "acc for Lsat= 0.38494050234077953 \n",
      "acc for Psat= 0.5111277180328978 \n",
      "acc for optim= 0.2636597067375926\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.02172522433102131\n",
      "Loss on test= 0.02147253416478634\n",
      "acc for Lsat= 0.44774588804520554 \n",
      "acc for Psat= 0.5081898632814881 \n",
      "acc for optim= 0.25490216920435477\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.020488394424319267\n",
      "Loss on test= 0.024290097877383232\n",
      "acc for Lsat= 0.46856020662360953 \n",
      "acc for Psat= 0.4794950264646055 \n",
      "acc for optim= 0.2561992254891634\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.021432042121887207\n",
      "Loss on test= 0.022681118920445442\n",
      "acc for Lsat= 0.4106068480925043 \n",
      "acc for Psat= 0.5503526481625158 \n",
      "acc for optim= 0.2731659753359005\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.020222777500748634\n",
      "Loss on test= 0.021518105641007423\n",
      "acc for Lsat= 0.4369394230845894 \n",
      "acc for Psat= 0.5048647414235322 \n",
      "acc for optim= 0.25696426702769887\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.019805068150162697\n",
      "Loss on test= 0.02529890090227127\n",
      "acc for Lsat= 0.40618914391371935 \n",
      "acc for Psat= 0.6615762645189928 \n",
      "acc for optim= 0.288903199589333\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.02004985511302948\n",
      "Loss on test= 0.02089657448232174\n",
      "acc for Lsat= 0.4364220037634761 \n",
      "acc for Psat= 0.4495646683865473 \n",
      "acc for optim= 0.25386496310963863\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.020532725378870964\n",
      "Loss on test= 0.022043034434318542\n",
      "acc for Lsat= 0.35905568403934407 \n",
      "acc for Psat= 0.59449258231872 \n",
      "acc for optim= 0.24156973104097257\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.021061882376670837\n",
      "Loss on test= 0.023124035447835922\n",
      "acc for Lsat= 0.4574624880581207 \n",
      "acc for Psat= 0.4815298832506193 \n",
      "acc for optim= 0.23739828562562204\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.020553436130285263\n",
      "Loss on test= 0.023075586184859276\n",
      "acc for Lsat= 0.36001487405942373 \n",
      "acc for Psat= 0.5685712082504079 \n",
      "acc for optim= 0.22646411855171086\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.02076035924255848\n",
      "Loss on test= 0.020599626004695892\n",
      "acc for Lsat= 0.42366534393796745 \n",
      "acc for Psat= 0.5155674226509684 \n",
      "acc for optim= 0.26321633941335826\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.01974663697183132\n",
      "Loss on test= 0.020366398617625237\n",
      "acc for Lsat= 0.3940963565573101 \n",
      "acc for Psat= 0.45936402039857255 \n",
      "acc for optim= 0.24098893137016678\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.01921367645263672\n",
      "Loss on test= 0.02225956693291664\n",
      "acc for Lsat= 0.42163188213433733 \n",
      "acc for Psat= 0.553706075668939 \n",
      "acc for optim= 0.24207677671251618\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.018651779741048813\n",
      "Loss on test= 0.02142488583922386\n",
      "acc for Lsat= 0.4036422754131333 \n",
      "acc for Psat= 0.501354859246734 \n",
      "acc for optim= 0.2715101731513199\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.018570227548480034\n",
      "Loss on test= 0.020418930798768997\n",
      "acc for Lsat= 0.42207622615191015 \n",
      "acc for Psat= 0.44304293734131606 \n",
      "acc for optim= 0.26458460865015276\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.01886165700852871\n",
      "Loss on test= 0.02152485027909279\n",
      "acc for Lsat= 0.37537109915786926 \n",
      "acc for Psat= 0.5418294695592596 \n",
      "acc for optim= 0.27653911188807234\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.01891920529305935\n",
      "Loss on test= 0.021896332502365112\n",
      "acc for Lsat= 0.4149287540679546 \n",
      "acc for Psat= 0.43489896194581446 \n",
      "acc for optim= 0.2818234541645742\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.01884271204471588\n",
      "Loss on test= 0.019984520971775055\n",
      "acc for Lsat= 0.4242576389357989 \n",
      "acc for Psat= 0.4721280917036819 \n",
      "acc for optim= 0.2626076667892866\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.018421946093440056\n",
      "Loss on test= 0.02016514353454113\n",
      "acc for Lsat= 0.38104208599046663 \n",
      "acc for Psat= 0.5375629343175821 \n",
      "acc for optim= 0.2380240774411406\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.019452279433608055\n",
      "Loss on test= 0.02293398231267929\n",
      "acc for Lsat= 0.5027870392195591 \n",
      "acc for Psat= 0.4735641098035361 \n",
      "acc for optim= 0.3767334814207012\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.01927976682782173\n",
      "Loss on test= 0.020708158612251282\n",
      "acc for Lsat= 0.3595680083050644 \n",
      "acc for Psat= 0.5113812697122371 \n",
      "acc for optim= 0.23677531536353902\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.018727686256170273\n",
      "Loss on test= 0.02027605101466179\n",
      "acc for Lsat= 0.3816168057982813 \n",
      "acc for Psat= 0.49920139526098817 \n",
      "acc for optim= 0.22972818514264529\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.01780800335109234\n",
      "Loss on test= 0.020372122526168823\n",
      "acc for Lsat= 0.4388674178478903 \n",
      "acc for Psat= 0.4833428389264972 \n",
      "acc for optim= 0.25152781710966265\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.01765040121972561\n",
      "Loss on test= 0.019511966034770012\n",
      "acc for Lsat= 0.3844441000291153 \n",
      "acc for Psat= 0.39742577882920943 \n",
      "acc for optim= 0.21339318024645862\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.01827186532318592\n",
      "Loss on test= 0.022520335391163826\n",
      "acc for Lsat= 0.3749357263323209 \n",
      "acc for Psat= 0.7249132816339969 \n",
      "acc for optim= 0.24320225648714128\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.01938331127166748\n",
      "Loss on test= 0.023795923218131065\n",
      "acc for Lsat= 0.49659510400217827 \n",
      "acc for Psat= 0.4100474773778744 \n",
      "acc for optim= 0.22093090874551383\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.018977055326104164\n",
      "Loss on test= 0.022495679557323456\n",
      "acc for Lsat= 0.38563528716740375 \n",
      "acc for Psat= 0.5622684227128047 \n",
      "acc for optim= 0.23552158534624362\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.018929865211248398\n",
      "Loss on test= 0.02071460895240307\n",
      "acc for Lsat= 0.42459324793418163 \n",
      "acc for Psat= 0.46326284882741525 \n",
      "acc for optim= 0.24480228285274525\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.017651118338108063\n",
      "Loss on test= 0.020032454282045364\n",
      "acc for Lsat= 0.36660442823769107 \n",
      "acc for Psat= 0.47857833495485513 \n",
      "acc for optim= 0.23734199045862328\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.0173784252256155\n",
      "Loss on test= 0.021765751764178276\n",
      "acc for Lsat= 0.4451942799842564 \n",
      "acc for Psat= 0.48846947390356454 \n",
      "acc for optim= 0.29091620785215666\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.017613226547837257\n",
      "Loss on test= 0.02174312435090542\n",
      "acc for Lsat= 0.36073966481239333 \n",
      "acc for Psat= 0.4825647562947533 \n",
      "acc for optim= 0.253949092487125\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.017263347283005714\n",
      "Loss on test= 0.020573528483510017\n",
      "acc for Lsat= 0.30763604096490954 \n",
      "acc for Psat= 0.5983900431196703 \n",
      "acc for optim= 0.3290324973766818\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.017918264493346214\n",
      "Loss on test= 0.019779274240136147\n",
      "acc for Lsat= 0.4715970328716385 \n",
      "acc for Psat= 0.43421686859565434 \n",
      "acc for optim= 0.23815336589349673\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.01738278567790985\n",
      "Loss on test= 0.02017763815820217\n",
      "acc for Lsat= 0.3742767028709971 \n",
      "acc for Psat= 0.5082680361763876 \n",
      "acc for optim= 0.2526298629905009\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.017124490812420845\n",
      "Loss on test= 0.01914840005338192\n",
      "acc for Lsat= 0.3727013699589824 \n",
      "acc for Psat= 0.44116242344937967 \n",
      "acc for optim= 0.2771362881872306\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.01663552224636078\n",
      "Loss on test= 0.018341630697250366\n",
      "acc for Lsat= 0.35103493203358677 \n",
      "acc for Psat= 0.46443346236215755 \n",
      "acc for optim= 0.24405689928145777\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.017200825735926628\n",
      "Loss on test= 0.019039541482925415\n",
      "acc for Lsat= 0.3979225216037751 \n",
      "acc for Psat= 0.41849345411174 \n",
      "acc for optim= 0.23006769859214704\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.016419025138020515\n",
      "Loss on test= 0.016880635172128677\n",
      "acc for Lsat= 0.33383010449939027 \n",
      "acc for Psat= 0.4211881950401663 \n",
      "acc for optim= 0.2535116795853183\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.016648145392537117\n",
      "Loss on test= 0.018011968582868576\n",
      "acc for Lsat= 0.3615489131393465 \n",
      "acc for Psat= 0.44439718792725486 \n",
      "acc for optim= 0.23498289552431695\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.01714719459414482\n",
      "Loss on test= 0.018719911575317383\n",
      "acc for Lsat= 0.36849919226881106 \n",
      "acc for Psat= 0.45790177735019627 \n",
      "acc for optim= 0.23938519005389172\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.01682308502495289\n",
      "Loss on test= 0.017270952463150024\n",
      "acc for Lsat= 0.3296131313604624 \n",
      "acc for Psat= 0.4761207121521914 \n",
      "acc for optim= 0.23807656658803084\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.017688732594251633\n",
      "Loss on test= 0.017665477469563484\n",
      "acc for Lsat= 0.3822763740154679 \n",
      "acc for Psat= 0.4084200377645273 \n",
      "acc for optim= 0.23305519085575677\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.0168545451015234\n",
      "Loss on test= 0.01917031779885292\n",
      "acc for Lsat= 0.32490942704356024 \n",
      "acc for Psat= 0.4748395145050725 \n",
      "acc for optim= 0.28344589792588426\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.016196778044104576\n",
      "Loss on test= 0.01820710301399231\n",
      "acc for Lsat= 0.31858073625079597 \n",
      "acc for Psat= 0.5168222498555347 \n",
      "acc for optim= 0.24379644253506716\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.017260437831282616\n",
      "Loss on test= 0.017013011500239372\n",
      "acc for Lsat= 0.37760274455020504 \n",
      "acc for Psat= 0.42904562757875947 \n",
      "acc for optim= 0.21933328225104315\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.01625441014766693\n",
      "Loss on test= 0.018264519050717354\n",
      "acc for Lsat= 0.3609032930654467 \n",
      "acc for Psat= 0.40116588092830685 \n",
      "acc for optim= 0.22160450296183085\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.01663469895720482\n",
      "Loss on test= 0.0180964432656765\n",
      "acc for Lsat= 0.3509125017704178 \n",
      "acc for Psat= 0.4417568711340553 \n",
      "acc for optim= 0.2453551044533457\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.016076233237981796\n",
      "Loss on test= 0.016728144139051437\n",
      "acc for Lsat= 0.3238259164578709 \n",
      "acc for Psat= 0.4530047848034096 \n",
      "acc for optim= 0.23470498845956564\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.01593795418739319\n",
      "Loss on test= 0.01781320571899414\n",
      "acc for Lsat= 0.37830160105423183 \n",
      "acc for Psat= 0.42618210346375457 \n",
      "acc for optim= 0.21656218281596257\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.0163036547601223\n",
      "Loss on test= 0.017937272787094116\n",
      "acc for Lsat= 0.40098590326316125 \n",
      "acc for Psat= 0.41941489596187287 \n",
      "acc for optim= 0.24692986323753832\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.01601647026836872\n",
      "Loss on test= 0.017648525536060333\n",
      "acc for Lsat= 0.3598165250671603 \n",
      "acc for Psat= 0.4673777501322203 \n",
      "acc for optim= 0.23907716853175992\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.015427401289343834\n",
      "Loss on test= 0.01931966096162796\n",
      "acc for Lsat= 0.3295146534062066 \n",
      "acc for Psat= 0.49747581177419037 \n",
      "acc for optim= 0.2777424557633994\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.016834674403071404\n",
      "Loss on test= 0.01672879420220852\n",
      "acc for Lsat= 0.40020082271547763 \n",
      "acc for Psat= 0.4333104937603993 \n",
      "acc for optim= 0.21418112072766432\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.01675262302160263\n",
      "Loss on test= 0.01804562658071518\n",
      "acc for Lsat= 0.3556443191289971 \n",
      "acc for Psat= 0.41727079348512797 \n",
      "acc for optim= 0.2246207344106625\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.015418884344398975\n",
      "Loss on test= 0.016879623755812645\n",
      "acc for Lsat= 0.3395658179455298 \n",
      "acc for Psat= 0.40908964737526904 \n",
      "acc for optim= 0.22867266073073453\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.015813549980521202\n",
      "Loss on test= 0.0177689827978611\n",
      "acc for Lsat= 0.32220259447466243 \n",
      "acc for Psat= 0.4373284980900133 \n",
      "acc for optim= 0.2355493376624607\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.015409733168780804\n",
      "Loss on test= 0.018446024507284164\n",
      "acc for Lsat= 0.3603013144157877 \n",
      "acc for Psat= 0.471101251894111 \n",
      "acc for optim= 0.21428061944735\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.016057420521974564\n",
      "Loss on test= 0.016958998516201973\n",
      "acc for Lsat= 0.35114174584383806 \n",
      "acc for Psat= 0.4199082973803318 \n",
      "acc for optim= 0.2123265561077042\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.015347217209637165\n",
      "Loss on test= 0.01739230751991272\n",
      "acc for Lsat= 0.33754743066792553 \n",
      "acc for Psat= 0.4637664812463619 \n",
      "acc for optim= 0.23519253264493198\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.015570566989481449\n",
      "Loss on test= 0.017723582684993744\n",
      "acc for Lsat= 0.30858524417507815 \n",
      "acc for Psat= 0.47066618996511866 \n",
      "acc for optim= 0.2234520707516404\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.016411123797297478\n",
      "Loss on test= 0.018119042739272118\n",
      "acc for Lsat= 0.3967389731992011 \n",
      "acc for Psat= 0.38653182983752404 \n",
      "acc for optim= 0.2230697018070763\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.01621386967599392\n",
      "Loss on test= 0.01721073128283024\n",
      "acc for Lsat= 0.3277586937635312 \n",
      "acc for Psat= 0.41053713275972326 \n",
      "acc for optim= 0.2143604147902413\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.015882402658462524\n",
      "Loss on test= 0.01606275513768196\n",
      "acc for Lsat= 0.3403838898961407 \n",
      "acc for Psat= 0.42044182002663966 \n",
      "acc for optim= 0.22703993552518975\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.015326093882322311\n",
      "Loss on test= 0.016145946457982063\n",
      "acc for Lsat= 0.32803463019789325 \n",
      "acc for Psat= 0.4289158926748732 \n",
      "acc for optim= 0.2238989560455839\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.015570931136608124\n",
      "Loss on test= 0.017595335841178894\n",
      "acc for Lsat= 0.3492980973497725 \n",
      "acc for Psat= 0.40695796293722514 \n",
      "acc for optim= 0.22080837269183845\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.015348202548921108\n",
      "Loss on test= 0.0173538438975811\n",
      "acc for Lsat= 0.42736327221496756 \n",
      "acc for Psat= 0.37135432568863286 \n",
      "acc for optim= 0.25807350515419414\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.016169797629117966\n",
      "Loss on test= 0.016915258020162582\n",
      "acc for Lsat= 0.3169363205198425 \n",
      "acc for Psat= 0.4483776773510505 \n",
      "acc for optim= 0.21764496863328828\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.01671745628118515\n",
      "Loss on test= 0.017510730773210526\n",
      "acc for Lsat= 0.331715963811557 \n",
      "acc for Psat= 0.48301340626258515 \n",
      "acc for optim= 0.24165169909522505\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.015848824754357338\n",
      "Loss on test= 0.014871223829686642\n",
      "acc for Lsat= 0.3391152033558732 \n",
      "acc for Psat= 0.3992356116729285 \n",
      "acc for optim= 0.24154627025976927\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.01563985086977482\n",
      "Loss on test= 0.015180126763880253\n",
      "acc for Lsat= 0.35347651317263357 \n",
      "acc for Psat= 0.3873515395007908 \n",
      "acc for optim= 0.22302966414851677\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.01501405704766512\n",
      "Loss on test= 0.016785092651844025\n",
      "acc for Lsat= 0.291686145423965 \n",
      "acc for Psat= 0.4424219774961317 \n",
      "acc for optim= 0.20490788100200794\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.015303048305213451\n",
      "Loss on test= 0.01643151044845581\n",
      "acc for Lsat= 0.32209331789232926 \n",
      "acc for Psat= 0.41058428675436565 \n",
      "acc for optim= 0.23304302244650899\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.015247305855154991\n",
      "Loss on test= 0.017989855259656906\n",
      "acc for Lsat= 0.2935774649754544 \n",
      "acc for Psat= 0.47802066204098376 \n",
      "acc for optim= 0.21072334442873694\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.014723931439220905\n",
      "Loss on test= 0.017094263806939125\n",
      "acc for Lsat= 0.3233221769484304 \n",
      "acc for Psat= 0.4823142205187233 \n",
      "acc for optim= 0.22742073738167212\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.015358473174273968\n",
      "Loss on test= 0.01712237112224102\n",
      "acc for Lsat= 0.33606548190574675 \n",
      "acc for Psat= 0.4067275485714482 \n",
      "acc for optim= 0.22716341104633347\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.014981779269874096\n",
      "Loss on test= 0.016694456338882446\n",
      "acc for Lsat= 0.3568557063841286 \n",
      "acc for Psat= 0.42195082061477257 \n",
      "acc for optim= 0.2332102577217754\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.014585969038307667\n",
      "Loss on test= 0.016645139083266258\n",
      "acc for Lsat= 0.31587107769430717 \n",
      "acc for Psat= 0.4217990326028116 \n",
      "acc for optim= 0.21818372283052814\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.014349722303450108\n",
      "Loss on test= 0.015860361978411674\n",
      "acc for Lsat= 0.3457776040654485 \n",
      "acc for Psat= 0.4005469196870124 \n",
      "acc for optim= 0.21114246454227534\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.014626436866819859\n",
      "Loss on test= 0.015386681072413921\n",
      "acc for Lsat= 0.3311499456003976 \n",
      "acc for Psat= 0.42198507550937076 \n",
      "acc for optim= 0.21746536760907179\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.014638662338256836\n",
      "Loss on test= 0.016997987404465675\n",
      "acc for Lsat= 0.3337906366367541 \n",
      "acc for Psat= 0.40143831985187717 \n",
      "acc for optim= 0.22847691527253167\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.014852248132228851\n",
      "Loss on test= 0.01584967039525509\n",
      "acc for Lsat= 0.3368247810313069 \n",
      "acc for Psat= 0.3863215708886462 \n",
      "acc for optim= 0.22567714835679145\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.0145762013271451\n",
      "Loss on test= 0.016225850209593773\n",
      "acc for Lsat= 0.33165025488690575 \n",
      "acc for Psat= 0.4501129292404732 \n",
      "acc for optim= 0.214861127918207\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.014194176532328129\n",
      "Loss on test= 0.016175486147403717\n",
      "acc for Lsat= 0.3202608713235276 \n",
      "acc for Psat= 0.3738300951301573 \n",
      "acc for optim= 0.20808107531283404\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.01482973713427782\n",
      "Loss on test= 0.01658795401453972\n",
      "acc for Lsat= 0.4474904764238336 \n",
      "acc for Psat= 0.3925319128363815 \n",
      "acc for optim= 0.19678544373252677\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.014682563953101635\n",
      "Loss on test= 0.015282184816896915\n",
      "acc for Lsat= 0.31675484578079555 \n",
      "acc for Psat= 0.41004615589642796 \n",
      "acc for optim= 0.21445894588219203\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.014275463297963142\n",
      "Loss on test= 0.015971537679433823\n",
      "acc for Lsat= 0.29840457791240355 \n",
      "acc for Psat= 0.4104469222444537 \n",
      "acc for optim= 0.2294875567533529\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.01424702350050211\n",
      "Loss on test= 0.015434104017913342\n",
      "acc for Lsat= 0.28794639872354016 \n",
      "acc for Psat= 0.43096957553643733 \n",
      "acc for optim= 0.25660033076284794\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.015185677446424961\n",
      "Loss on test= 0.017079481855034828\n",
      "acc for Lsat= 0.294950146369907 \n",
      "acc for Psat= 0.4645228460950248 \n",
      "acc for optim= 0.21668558166444152\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.015940262004733086\n",
      "Loss on test= 0.01517761405557394\n",
      "acc for Lsat= 0.3594682950202401 \n",
      "acc for Psat= 0.3966362757126115 \n",
      "acc for optim= 0.22615121107515437\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.014916920103132725\n",
      "Loss on test= 0.01670430786907673\n",
      "acc for Lsat= 0.3748576234929469 \n",
      "acc for Psat= 0.3945461849877107 \n",
      "acc for optim= 0.20872227107866895\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.01431787945330143\n",
      "Loss on test= 0.016735093668103218\n",
      "acc for Lsat= 0.32291109392079653 \n",
      "acc for Psat= 0.379685327414213 \n",
      "acc for optim= 0.2402361518045812\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.014155413024127483\n",
      "Loss on test= 0.015438553877174854\n",
      "acc for Lsat= 0.29253331324828136 \n",
      "acc for Psat= 0.4149265367141689 \n",
      "acc for optim= 0.19963951922004894\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.014628992415964603\n",
      "Loss on test= 0.018450254574418068\n",
      "acc for Lsat= 0.30342137511438894 \n",
      "acc for Psat= 0.49517125833497977 \n",
      "acc for optim= 0.23937767900261442\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.013545806519687176\n",
      "Loss on test= 0.015072579495608807\n",
      "acc for Lsat= 0.30409880081031193 \n",
      "acc for Psat= 0.39150523666349063 \n",
      "acc for optim= 0.19742350015385945\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.01343735121190548\n",
      "Loss on test= 0.016906792297959328\n",
      "acc for Lsat= 0.46961820573464186 \n",
      "acc for Psat= 0.3838188036119194 \n",
      "acc for optim= 0.20420625711267348\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.014109677635133266\n",
      "Loss on test= 0.014599506743252277\n",
      "acc for Lsat= 0.3268374121776228 \n",
      "acc for Psat= 0.3790691213362152 \n",
      "acc for optim= 0.22463920783752656\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.01400369219481945\n",
      "Loss on test= 0.015584631823003292\n",
      "acc for Lsat= 0.3102935185416828 \n",
      "acc for Psat= 0.431925780497639 \n",
      "acc for optim= 0.19705718656496174\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.013984129764139652\n",
      "Loss on test= 0.015986675396561623\n",
      "acc for Lsat= 0.35471889905076404 \n",
      "acc for Psat= 0.35290425316919494 \n",
      "acc for optim= 0.21471664637391694\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.013782840222120285\n",
      "Loss on test= 0.0167637187987566\n",
      "acc for Lsat= 0.404345403974042 \n",
      "acc for Psat= 0.39023631281137616 \n",
      "acc for optim= 0.20459337561348817\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.013713681139051914\n",
      "Loss on test= 0.013936552219092846\n",
      "acc for Lsat= 0.2915081217117306 \n",
      "acc for Psat= 0.38317208460530555 \n",
      "acc for optim= 0.21279845502726244\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.013377128168940544\n",
      "Loss on test= 0.015503082424402237\n",
      "acc for Lsat= 0.2712363965700796 \n",
      "acc for Psat= 0.4046002520024902 \n",
      "acc for optim= 0.21617309047330827\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.014041969552636147\n",
      "Loss on test= 0.01594594493508339\n",
      "acc for Lsat= 0.318061655165464 \n",
      "acc for Psat= 0.3846444399855131 \n",
      "acc for optim= 0.2127785558220018\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.014542408287525177\n",
      "Loss on test= 0.01616949401795864\n",
      "acc for Lsat= 0.3997593821687661 \n",
      "acc for Psat= 0.3847599119290936 \n",
      "acc for optim= 0.2055910127182378\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.013977013528347015\n",
      "Loss on test= 0.015036829747259617\n",
      "acc for Lsat= 0.3031536466080217 \n",
      "acc for Psat= 0.39727927132374846 \n",
      "acc for optim= 0.21547272833610093\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.01345136296004057\n",
      "Loss on test= 0.015399436466395855\n",
      "acc for Lsat= 0.2909690607087435 \n",
      "acc for Psat= 0.4155227465663621 \n",
      "acc for optim= 0.20670602997494358\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.013652332127094269\n",
      "Loss on test= 0.01828068308532238\n",
      "acc for Lsat= 0.30968791546340957 \n",
      "acc for Psat= 0.49793802225896205 \n",
      "acc for optim= 0.2458786352693317\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.013771292753517628\n",
      "Loss on test= 0.016555793583393097\n",
      "acc for Lsat= 0.38265203482100135 \n",
      "acc for Psat= 0.3594054322755845 \n",
      "acc for optim= 0.20109412083282321\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.013996812514960766\n",
      "Loss on test= 0.015163675881922245\n",
      "acc for Lsat= 0.29879516444890286 \n",
      "acc for Psat= 0.4099509377831694 \n",
      "acc for optim= 0.20829191894547358\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.013729698024690151\n",
      "Loss on test= 0.01615806296467781\n",
      "acc for Lsat= 0.37893666078329064 \n",
      "acc for Psat= 0.37304958502441093 \n",
      "acc for optim= 0.22597048518749746\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.013551476411521435\n",
      "Loss on test= 0.01375582441687584\n",
      "acc for Lsat= 0.30315827642334625 \n",
      "acc for Psat= 0.3885315144658749 \n",
      "acc for optim= 0.2433062206506981\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.014111972413957119\n",
      "Loss on test= 0.014558341354131699\n",
      "acc for Lsat= 0.2833216887705242 \n",
      "acc for Psat= 0.4088997504079236 \n",
      "acc for optim= 0.21706680881519835\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.014310303144156933\n",
      "Loss on test= 0.016627410426735878\n",
      "acc for Lsat= 0.3783326862313835 \n",
      "acc for Psat= 0.3583587459005365 \n",
      "acc for optim= 0.2045166317584517\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.014034528285264969\n",
      "Loss on test= 0.01487304363399744\n",
      "acc for Lsat= 0.2963296830877536 \n",
      "acc for Psat= 0.4148059020948052 \n",
      "acc for optim= 0.2040804016480153\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.013495338149368763\n",
      "Loss on test= 0.014949199743568897\n",
      "acc for Lsat= 0.27199927548566405 \n",
      "acc for Psat= 0.42216391645952417 \n",
      "acc for optim= 0.21851414316522613\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.013220633380115032\n",
      "Loss on test= 0.015323606319725513\n",
      "acc for Lsat= 0.3044735361181665 \n",
      "acc for Psat= 0.4557532055700412 \n",
      "acc for optim= 0.24196914299623254\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.013976989313960075\n",
      "Loss on test= 0.016116462647914886\n",
      "acc for Lsat= 0.30399936083090695 \n",
      "acc for Psat= 0.4111730372706252 \n",
      "acc for optim= 0.20415272934887735\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.013771751895546913\n",
      "Loss on test= 0.014861696399748325\n",
      "acc for Lsat= 0.31983842055047423 \n",
      "acc for Psat= 0.3571028040497441 \n",
      "acc for optim= 0.22132502688534283\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.013365599326789379\n",
      "Loss on test= 0.013993102125823498\n",
      "acc for Lsat= 0.28147092204843016 \n",
      "acc for Psat= 0.4118915131760799 \n",
      "acc for optim= 0.20757964303048365\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.013351507484912872\n",
      "Loss on test= 0.01561026182025671\n",
      "acc for Lsat= 0.341782370899145 \n",
      "acc for Psat= 0.3735230901377666 \n",
      "acc for optim= 0.22047251089955083\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.013077948242425919\n",
      "Loss on test= 0.015492909587919712\n",
      "acc for Lsat= 0.2627149002490458 \n",
      "acc for Psat= 0.4572843839367222 \n",
      "acc for optim= 0.20477813139272305\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.013636215589940548\n",
      "Loss on test= 0.015033750794827938\n",
      "acc for Lsat= 0.2916000964888136 \n",
      "acc for Psat= 0.3702109626327591 \n",
      "acc for optim= 0.21958446726228284\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.01345277763903141\n",
      "Loss on test= 0.016715459525585175\n",
      "acc for Lsat= 0.2886123093036027 \n",
      "acc for Psat= 0.4406554922351387 \n",
      "acc for optim= 0.219100739698931\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.013151951134204865\n",
      "Loss on test= 0.015438537113368511\n",
      "acc for Lsat= 0.28788827635690795 \n",
      "acc for Psat= 0.4526939957603817 \n",
      "acc for optim= 0.22355146524942765\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.013390295207500458\n",
      "Loss on test= 0.014483055099844933\n",
      "acc for Lsat= 0.3153479765247981 \n",
      "acc for Psat= 0.3628565135307302 \n",
      "acc for optim= 0.20582883990219497\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.012657186947762966\n",
      "Loss on test= 0.015203540213406086\n",
      "acc for Lsat= 0.28564126260725725 \n",
      "acc for Psat= 0.38791024815794584 \n",
      "acc for optim= 0.238922993733443\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.013125956058502197\n",
      "Loss on test= 0.014442969113588333\n",
      "acc for Lsat= 0.26161819565577143 \n",
      "acc for Psat= 0.4310748260106413 \n",
      "acc for optim= 0.20990178268948512\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.012675981968641281\n",
      "Loss on test= 0.013648271560668945\n",
      "acc for Lsat= 0.2796844011345702 \n",
      "acc for Psat= 0.36932103919271203 \n",
      "acc for optim= 0.2075596288128951\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.012976329773664474\n",
      "Loss on test= 0.014174000360071659\n",
      "acc for Lsat= 0.3376801249852744 \n",
      "acc for Psat= 0.3760687463466122 \n",
      "acc for optim= 0.19691411452171254\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.013607580214738846\n",
      "Loss on test= 0.015207664109766483\n",
      "acc for Lsat= 0.3596870801238519 \n",
      "acc for Psat= 0.3656860482312638 \n",
      "acc for optim= 0.20425064546430508\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.013010075315833092\n",
      "Loss on test= 0.01489097811281681\n",
      "acc for Lsat= 0.2927141584268365 \n",
      "acc for Psat= 0.36826757299481744 \n",
      "acc for optim= 0.2150717371690474\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.012979737482964993\n",
      "Loss on test= 0.01437368430197239\n",
      "acc for Lsat= 0.2893946300462483 \n",
      "acc for Psat= 0.33258571635183587 \n",
      "acc for optim= 0.21458416861581076\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.013203095644712448\n",
      "Loss on test= 0.017228635028004646\n",
      "acc for Lsat= 0.2951610373015314 \n",
      "acc for Psat= 0.4928808593658441 \n",
      "acc for optim= 0.20512017780109434\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.012508842162787914\n",
      "Loss on test= 0.014714627526700497\n",
      "acc for Lsat= 0.34001946518214565 \n",
      "acc for Psat= 0.4006755522419258 \n",
      "acc for optim= 0.21223456484526773\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.012769827619194984\n",
      "Loss on test= 0.013833284378051758\n",
      "acc for Lsat= 0.3117765274403831 \n",
      "acc for Psat= 0.4298732872294086 \n",
      "acc for optim= 0.21329748815372335\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.013848607428371906\n",
      "Loss on test= 0.01828732341527939\n",
      "acc for Lsat= 0.27771648521318 \n",
      "acc for Psat= 0.5944335787929516 \n",
      "acc for optim= 0.22867285689522218\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.0133747523650527\n",
      "Loss on test= 0.014546304009854794\n",
      "acc for Lsat= 0.3428536125999951 \n",
      "acc for Psat= 0.3663069016502418 \n",
      "acc for optim= 0.20677340416531897\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.012410368770360947\n",
      "Loss on test= 0.01494455523788929\n",
      "acc for Lsat= 0.27382735253627905 \n",
      "acc for Psat= 0.4249279599293053 \n",
      "acc for optim= 0.21603599268073104\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.012773302383720875\n",
      "Loss on test= 0.014089319854974747\n",
      "acc for Lsat= 0.27032659784025465 \n",
      "acc for Psat= 0.3935843763876521 \n",
      "acc for optim= 0.23970326390932511\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.012711791321635246\n",
      "Loss on test= 0.015179237350821495\n",
      "acc for Lsat= 0.27748431370993193 \n",
      "acc for Psat= 0.3865930335273702 \n",
      "acc for optim= 0.20827874337654165\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.012998632155358791\n",
      "Loss on test= 0.014312507584691048\n",
      "acc for Lsat= 0.28925230229681287 \n",
      "acc for Psat= 0.40133830519688846 \n",
      "acc for optim= 0.2146276693725864\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.013238114304840565\n",
      "Loss on test= 0.013543380424380302\n",
      "acc for Lsat= 0.3067282800510519 \n",
      "acc for Psat= 0.39057510789811006 \n",
      "acc for optim= 0.19787696407916341\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.012613811530172825\n",
      "Loss on test= 0.014418136328458786\n",
      "acc for Lsat= 0.3370212344885363 \n",
      "acc for Psat= 0.34482533808300475 \n",
      "acc for optim= 0.21001632502422482\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.01196343544870615\n",
      "Loss on test= 0.01572798751294613\n",
      "acc for Lsat= 0.2611192242750533 \n",
      "acc for Psat= 0.432086344781596 \n",
      "acc for optim= 0.2196105252587217\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.012324187904596329\n",
      "Loss on test= 0.014413222670555115\n",
      "acc for Lsat= 0.3206355281965099 \n",
      "acc for Psat= 0.3629282874564917 \n",
      "acc for optim= 0.21382372503491776\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.01308857649564743\n",
      "Loss on test= 0.013941521756350994\n",
      "acc for Lsat= 0.32247291151292595 \n",
      "acc for Psat= 0.3506473487845314 \n",
      "acc for optim= 0.2076215565765459\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.012915335595607758\n",
      "Loss on test= 0.014780121855437756\n",
      "acc for Lsat= 0.27624350832775235 \n",
      "acc for Psat= 0.3938689946271306 \n",
      "acc for optim= 0.20614877797905481\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.012915547005832195\n",
      "Loss on test= 0.015394723042845726\n",
      "acc for Lsat= 0.2630254212217059 \n",
      "acc for Psat= 0.4021349661837711 \n",
      "acc for optim= 0.2222325703887445\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.013479339890182018\n",
      "Loss on test= 0.013894322328269482\n",
      "acc for Lsat= 0.3516213789305373 \n",
      "acc for Psat= 0.3832858077506579 \n",
      "acc for optim= 0.18477193291776506\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.01284517627209425\n",
      "Loss on test= 0.014085112139582634\n",
      "acc for Lsat= 0.2881569907492392 \n",
      "acc for Psat= 0.3822072721039247 \n",
      "acc for optim= 0.21106688764474885\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.012556249275803566\n",
      "Loss on test= 0.014496339485049248\n",
      "acc for Lsat= 0.3554561371953192 \n",
      "acc for Psat= 0.331837753389295 \n",
      "acc for optim= 0.2223202023313796\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.012479367665946484\n",
      "Loss on test= 0.01441391371190548\n",
      "acc for Lsat= 0.2709704008586807 \n",
      "acc for Psat= 0.3754281483054148 \n",
      "acc for optim= 0.19192705539446892\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.012219469994306564\n",
      "Loss on test= 0.01370109710842371\n",
      "acc for Lsat= 0.31374810796271935 \n",
      "acc for Psat= 0.331405644831869 \n",
      "acc for optim= 0.20322439965486802\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.012639491818845272\n",
      "Loss on test= 0.013136325404047966\n",
      "acc for Lsat= 0.29828195135593666 \n",
      "acc for Psat= 0.38295100299197854 \n",
      "acc for optim= 0.20779252064494358\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.012435170821845531\n",
      "Loss on test= 0.013719702139496803\n",
      "acc for Lsat= 0.34240879631476207 \n",
      "acc for Psat= 0.3682550810406463 \n",
      "acc for optim= 0.20438753339899327\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.012838699854910374\n",
      "Loss on test= 0.014033984392881393\n",
      "acc for Lsat= 0.2843385635107454 \n",
      "acc for Psat= 0.36330120543543426 \n",
      "acc for optim= 0.20380453134788007\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.012099622748792171\n",
      "Loss on test= 0.014472568407654762\n",
      "acc for Lsat= 0.2665131395207592 \n",
      "acc for Psat= 0.40882717917446754 \n",
      "acc for optim= 0.21691005046080603\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.011959260329604149\n",
      "Loss on test= 0.014679037034511566\n",
      "acc for Lsat= 0.2607980495778139 \n",
      "acc for Psat= 0.41648489463684224 \n",
      "acc for optim= 0.21155062370940572\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.012075603008270264\n",
      "Loss on test= 0.01381558645516634\n",
      "acc for Lsat= 0.27707652915174746 \n",
      "acc for Psat= 0.41801554552561404 \n",
      "acc for optim= 0.20843488949105596\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.012124370783567429\n",
      "Loss on test= 0.015906114131212234\n",
      "acc for Lsat= 0.26370676494489825 \n",
      "acc for Psat= 0.463519215114207 \n",
      "acc for optim= 0.2200347280162827\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.01223044190555811\n",
      "Loss on test= 0.014030328020453453\n",
      "acc for Lsat= 0.30482415903227505 \n",
      "acc for Psat= 0.3534684610174343 \n",
      "acc for optim= 0.20749360488765445\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.011906820349395275\n",
      "Loss on test= 0.013209777884185314\n",
      "acc for Lsat= 0.2728189482431107 \n",
      "acc for Psat= 0.3829264912335045 \n",
      "acc for optim= 0.21050902824995196\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.012255228124558926\n",
      "Loss on test= 0.013399225659668446\n",
      "acc for Lsat= 0.2632845913239352 \n",
      "acc for Psat= 0.3591554980841367 \n",
      "acc for optim= 0.21040076888960824\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.011969136074185371\n",
      "Loss on test= 0.013150440528988838\n",
      "acc for Lsat= 0.2844919355981826 \n",
      "acc for Psat= 0.36558929237405724 \n",
      "acc for optim= 0.1967859790985696\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.012626179493963718\n",
      "Loss on test= 0.013509872369468212\n",
      "acc for Lsat= 0.293886347804604 \n",
      "acc for Psat= 0.34000957720726965 \n",
      "acc for optim= 0.20551842294642828\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.012183249928057194\n",
      "Loss on test= 0.01463484950363636\n",
      "acc for Lsat= 0.27190434346780296 \n",
      "acc for Psat= 0.39617712236704883 \n",
      "acc for optim= 0.20860046208734864\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.01193411834537983\n",
      "Loss on test= 0.013587258756160736\n",
      "acc for Lsat= 0.2746726341663177 \n",
      "acc for Psat= 0.41466034451228995 \n",
      "acc for optim= 0.20857810577601069\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.011844328604638577\n",
      "Loss on test= 0.01805780455470085\n",
      "acc for Lsat= 0.2838694572706732 \n",
      "acc for Psat= 0.5145258830043039 \n",
      "acc for optim= 0.2216674588317629\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.013323956169188023\n",
      "Loss on test= 0.014906393364071846\n",
      "acc for Lsat= 0.26856356973970635 \n",
      "acc for Psat= 0.4369821091201408 \n",
      "acc for optim= 0.20872209665380856\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.013661636970937252\n",
      "Loss on test= 0.01633037067949772\n",
      "acc for Lsat= 0.4057873579885062 \n",
      "acc for Psat= 0.3473302800746358 \n",
      "acc for optim= 0.2036673398942111\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.012301547452807426\n",
      "Loss on test= 0.015041916631162167\n",
      "acc for Lsat= 0.2775101652416099 \n",
      "acc for Psat= 0.41299445661349415 \n",
      "acc for optim= 0.19848429239425822\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.01222996786236763\n",
      "Loss on test= 0.013304886408150196\n",
      "acc for Lsat= 0.30027615391520307 \n",
      "acc for Psat= 0.3573402187516754 \n",
      "acc for optim= 0.20441541129745217\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.012610680423676968\n",
      "Loss on test= 0.014351379126310349\n",
      "acc for Lsat= 0.26724614167088057 \n",
      "acc for Psat= 0.41258241317169647 \n",
      "acc for optim= 0.20298402141811125\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.01206766813993454\n",
      "Loss on test= 0.012846232391893864\n",
      "acc for Lsat= 0.2896085164764962 \n",
      "acc for Psat= 0.3393464109481224 \n",
      "acc for optim= 0.2089582239588364\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.011823120526969433\n",
      "Loss on test= 0.013736585155129433\n",
      "acc for Lsat= 0.2760493256141057 \n",
      "acc for Psat= 0.351176109687249 \n",
      "acc for optim= 0.2013133353930489\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.011915551498532295\n",
      "Loss on test= 0.013853398151695728\n",
      "acc for Lsat= 0.2568650079656682 \n",
      "acc for Psat= 0.36844348019587564 \n",
      "acc for optim= 0.19696206510648276\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.012270570732653141\n",
      "Loss on test= 0.013838758692145348\n",
      "acc for Lsat= 0.2687927754383496 \n",
      "acc for Psat= 0.3849620551777047 \n",
      "acc for optim= 0.1975392367929925\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.012300604954361916\n",
      "Loss on test= 0.0184660442173481\n",
      "acc for Lsat= 0.282262746682013 \n",
      "acc for Psat= 0.5964173926229311 \n",
      "acc for optim= 0.22075864896603004\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.013798967935144901\n",
      "Loss on test= 0.013526501134037971\n",
      "acc for Lsat= 0.3322924822326034 \n",
      "acc for Psat= 0.3298728000573229 \n",
      "acc for optim= 0.20458424169093534\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.01204406563192606\n",
      "Loss on test= 0.013641225174069405\n",
      "acc for Lsat= 0.2600671769086074 \n",
      "acc for Psat= 0.36348124017594446 \n",
      "acc for optim= 0.19690280068017593\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.011548416689038277\n",
      "Loss on test= 0.013199666514992714\n",
      "acc for Lsat= 0.26749916523643863 \n",
      "acc for Psat= 0.350084384842351 \n",
      "acc for optim= 0.20029639761589743\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.011530679650604725\n",
      "Loss on test= 0.01445285975933075\n",
      "acc for Lsat= 0.3044458069223863 \n",
      "acc for Psat= 0.34281575640213574 \n",
      "acc for optim= 0.21266794032871494\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.012493458576500416\n",
      "Loss on test= 0.012916500680148602\n",
      "acc for Lsat= 0.28854124962880806 \n",
      "acc for Psat= 0.39087080096627735 \n",
      "acc for optim= 0.2050414122135211\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.01193711906671524\n",
      "Loss on test= 0.013518523424863815\n",
      "acc for Lsat= 0.26401256223948005 \n",
      "acc for Psat= 0.34158321525752106 \n",
      "acc for optim= 0.20459520159646352\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.011849107220768929\n",
      "Loss on test= 0.012628048658370972\n",
      "acc for Lsat= 0.28652807212558795 \n",
      "acc for Psat= 0.3340679991792107 \n",
      "acc for optim= 0.19296148746601632\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.012211925350129604\n",
      "Loss on test= 0.01375606283545494\n",
      "acc for Lsat= 0.2550311676577867 \n",
      "acc for Psat= 0.38930949263236914 \n",
      "acc for optim= 0.21873954969389062\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.012480548582971096\n",
      "Loss on test= 0.013342661783099174\n",
      "acc for Lsat= 0.3054909763591855 \n",
      "acc for Psat= 0.3187528159076071 \n",
      "acc for optim= 0.21160356959365811\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.01208068709820509\n",
      "Loss on test= 0.013728610239923\n",
      "acc for Lsat= 0.27219985720364853 \n",
      "acc for Psat= 0.341057102697763 \n",
      "acc for optim= 0.19997107802349068\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.011767307296395302\n",
      "Loss on test= 0.01399298757314682\n",
      "acc for Lsat= 0.27741288139753345 \n",
      "acc for Psat= 0.3561709555577034 \n",
      "acc for optim= 0.20557892279275375\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.011537858285009861\n",
      "Loss on test= 0.013974717818200588\n",
      "acc for Lsat= 0.2711600457029842 \n",
      "acc for Psat= 0.3735730690036812 \n",
      "acc for optim= 0.2028522027744534\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.011168566532433033\n",
      "Loss on test= 0.014470917172729969\n",
      "acc for Lsat= 0.2620799328580835 \n",
      "acc for Psat= 0.3769027368583232 \n",
      "acc for optim= 0.19249513427132262\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.012150462716817856\n",
      "Loss on test= 0.013276634737849236\n",
      "acc for Lsat= 0.2596226120717679 \n",
      "acc for Psat= 0.3744874535831686 \n",
      "acc for optim= 0.20468732339921533\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.011377066373825073\n",
      "Loss on test= 0.013448070734739304\n",
      "acc for Lsat= 0.27798909539470096 \n",
      "acc for Psat= 0.33967516754165517 \n",
      "acc for optim= 0.21661661055104314\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.011509262025356293\n",
      "Loss on test= 0.013251477852463722\n",
      "acc for Lsat= 0.2642383138189797 \n",
      "acc for Psat= 0.36215040430692463 \n",
      "acc for optim= 0.19410196659678272\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.011560635641217232\n",
      "Loss on test= 0.013284140266478062\n",
      "acc for Lsat= 0.281050868479675 \n",
      "acc for Psat= 0.3509309261066232 \n",
      "acc for optim= 0.20639705150087312\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.011607606895267963\n",
      "Loss on test= 0.012755041942000389\n",
      "acc for Lsat= 0.27607606937670276 \n",
      "acc for Psat= 0.3386249351743892 \n",
      "acc for optim= 0.1951805648489893\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.011413278989493847\n",
      "Loss on test= 0.013016208074986935\n",
      "acc for Lsat= 0.2712987760007948 \n",
      "acc for Psat= 0.34270727351985125 \n",
      "acc for optim= 0.20086733185942993\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.011283149011433125\n",
      "Loss on test= 0.013090294785797596\n",
      "acc for Lsat= 0.296181745040608 \n",
      "acc for Psat= 0.3402758730764027 \n",
      "acc for optim= 0.20406073737339703\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.011670318432152271\n",
      "Loss on test= 0.014698637649416924\n",
      "acc for Lsat= 0.26661413914218823 \n",
      "acc for Psat= 0.42651903436116473 \n",
      "acc for optim= 0.20708604915506765\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.011417105793952942\n",
      "Loss on test= 0.013057833537459373\n",
      "acc for Lsat= 0.2528524662280393 \n",
      "acc for Psat= 0.3601281969820628 \n",
      "acc for optim= 0.20194475733114814\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.011989551596343517\n",
      "Loss on test= 0.013569300062954426\n",
      "acc for Lsat= 0.2690278864796022 \n",
      "acc for Psat= 0.3957929384518679 \n",
      "acc for optim= 0.20775016124369702\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.01145776454359293\n",
      "Loss on test= 0.013056428171694279\n",
      "acc for Lsat= 0.2490619180515185 \n",
      "acc for Psat= 0.35339566873861605 \n",
      "acc for optim= 0.20606774263354521\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.011357240378856659\n",
      "Loss on test= 0.013882005587220192\n",
      "acc for Lsat= 0.26171607264109914 \n",
      "acc for Psat= 0.40031327262939254 \n",
      "acc for optim= 0.21448429011286715\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.011387255042791367\n",
      "Loss on test= 0.013563581742346287\n",
      "acc for Lsat= 0.3134917946307404 \n",
      "acc for Psat= 0.3475644905131933 \n",
      "acc for optim= 0.20491759029401518\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.011758917942643166\n",
      "Loss on test= 0.01352682989090681\n",
      "acc for Lsat= 0.24708464483890297 \n",
      "acc for Psat= 0.3937061760398383 \n",
      "acc for optim= 0.1943215300949256\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.011101657524704933\n",
      "Loss on test= 0.01336091198027134\n",
      "acc for Lsat= 0.2535201815994082 \n",
      "acc for Psat= 0.36645752669121706 \n",
      "acc for optim= 0.19872656246848605\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.011571943759918213\n",
      "Loss on test= 0.013684757985174656\n",
      "acc for Lsat= 0.26012243319112444 \n",
      "acc for Psat= 0.40496783494214666 \n",
      "acc for optim= 0.21991346101591214\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.011411258019506931\n",
      "Loss on test= 0.012791203334927559\n",
      "acc for Lsat= 0.2670114662284283 \n",
      "acc for Psat= 0.354912533021274 \n",
      "acc for optim= 0.20417284283502266\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.010836559347808361\n",
      "Loss on test= 0.012560048140585423\n",
      "acc for Lsat= 0.2581627788214875 \n",
      "acc for Psat= 0.3289805009839797 \n",
      "acc for optim= 0.2027132038490743\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.011780848726630211\n",
      "Loss on test= 0.013882210478186607\n",
      "acc for Lsat= 0.32936332602293006 \n",
      "acc for Psat= 0.32687792958175715 \n",
      "acc for optim= 0.20413790209489446\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.011171755380928516\n",
      "Loss on test= 0.011912200599908829\n",
      "acc for Lsat= 0.2572483670393578 \n",
      "acc for Psat= 0.32573614172631365 \n",
      "acc for optim= 0.19112920041948814\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.011455808766186237\n",
      "Loss on test= 0.01298152282834053\n",
      "acc for Lsat= 0.25660506646798587 \n",
      "acc for Psat= 0.34682128252146915 \n",
      "acc for optim= 0.20222656247276333\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.011369883082807064\n",
      "Loss on test= 0.013010706752538681\n",
      "acc for Lsat= 0.2520564914701862 \n",
      "acc for Psat= 0.3596137939068187 \n",
      "acc for optim= 0.19773290773111904\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.012051038444042206\n",
      "Loss on test= 0.01362848561257124\n",
      "acc for Lsat= 0.24112014393117656 \n",
      "acc for Psat= 0.38925358411113453 \n",
      "acc for optim= 0.208531591053297\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.01186797209084034\n",
      "Loss on test= 0.012347500771284103\n",
      "acc for Lsat= 0.3001198827783023 \n",
      "acc for Psat= 0.3355104844343972 \n",
      "acc for optim= 0.19207235746796722\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.01124153658747673\n",
      "Loss on test= 0.013029109686613083\n",
      "acc for Lsat= 0.2630603963578422 \n",
      "acc for Psat= 0.37886161941895735 \n",
      "acc for optim= 0.20105770294459355\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.011060859076678753\n",
      "Loss on test= 0.013502088375389576\n",
      "acc for Lsat= 0.3053797369109423 \n",
      "acc for Psat= 0.3243836132460274 \n",
      "acc for optim= 0.2010846413594098\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.01123766414821148\n",
      "Loss on test= 0.013208672404289246\n",
      "acc for Lsat= 0.2526492151176884 \n",
      "acc for Psat= 0.34926161620554724 \n",
      "acc for optim= 0.19589668325568563\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.011270786635577679\n",
      "Loss on test= 0.012518075294792652\n",
      "acc for Lsat= 0.2718303018031096 \n",
      "acc for Psat= 0.3529408799997229 \n",
      "acc for optim= 0.19886872147892704\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.011166916228830814\n",
      "Loss on test= 0.012067519128322601\n",
      "acc for Lsat= 0.2865527235388416 \n",
      "acc for Psat= 0.35595903767751075 \n",
      "acc for optim= 0.200941099959498\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.01103358343243599\n",
      "Loss on test= 0.013294867239892483\n",
      "acc for Lsat= 0.2384996274490117 \n",
      "acc for Psat= 0.3777794806558853 \n",
      "acc for optim= 0.1965490401175024\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.0108504518866539\n",
      "Loss on test= 0.012180265039205551\n",
      "acc for Lsat= 0.2671268485385037 \n",
      "acc for Psat= 0.34116193576817355 \n",
      "acc for optim= 0.1990753751475446\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.01101785246282816\n",
      "Loss on test= 0.0134937958791852\n",
      "acc for Lsat= 0.2527686848619409 \n",
      "acc for Psat= 0.3700852251658452 \n",
      "acc for optim= 0.19678870856704314\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.011512933298945427\n",
      "Loss on test= 0.012661764398217201\n",
      "acc for Lsat= 0.31694052467198186 \n",
      "acc for Psat= 0.34337637623822365 \n",
      "acc for optim= 0.19620703352415444\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.011506708338856697\n",
      "Loss on test= 0.01341811753809452\n",
      "acc for Lsat= 0.24080018993560304 \n",
      "acc for Psat= 0.34911660152971996 \n",
      "acc for optim= 0.19957259042987702\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.011244605295360088\n",
      "Loss on test= 0.012406278401613235\n",
      "acc for Lsat= 0.27647962211788557 \n",
      "acc for Psat= 0.3431558170091562 \n",
      "acc for optim= 0.19159861783397925\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.010717584751546383\n",
      "Loss on test= 0.012676766142249107\n",
      "acc for Lsat= 0.2524337898377436 \n",
      "acc for Psat= 0.3724558752917408 \n",
      "acc for optim= 0.2089814854812544\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.011166934855282307\n",
      "Loss on test= 0.01251605711877346\n",
      "acc for Lsat= 0.24808630631378037 \n",
      "acc for Psat= 0.3796605726572641 \n",
      "acc for optim= 0.2029484039211073\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.010866176337003708\n",
      "Loss on test= 0.012770034372806549\n",
      "acc for Lsat= 0.2758288814991436 \n",
      "acc for Psat= 0.332706371320701 \n",
      "acc for optim= 0.19318671055402406\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.01091985683888197\n",
      "Loss on test= 0.012911939062178135\n",
      "acc for Lsat= 0.25687509297662275 \n",
      "acc for Psat= 0.34481253241928106 \n",
      "acc for optim= 0.2129351281523791\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.010997693985700607\n",
      "Loss on test= 0.012527135200798512\n",
      "acc for Lsat= 0.2659853486380795 \n",
      "acc for Psat= 0.308236615734672 \n",
      "acc for optim= 0.19354939426350914\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.0111008295789361\n",
      "Loss on test= 0.012271039187908173\n",
      "acc for Lsat= 0.26577284662463985 \n",
      "acc for Psat= 0.3377575748253966 \n",
      "acc for optim= 0.1934296047634357\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.010981373488903046\n",
      "Loss on test= 0.0125437555834651\n",
      "acc for Lsat= 0.2890303567680373 \n",
      "acc for Psat= 0.3231060221001531 \n",
      "acc for optim= 0.20815883667229493\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.010796246118843555\n",
      "Loss on test= 0.012224247679114342\n",
      "acc for Lsat= 0.27956806595188566 \n",
      "acc for Psat= 0.319601567352554 \n",
      "acc for optim= 0.19946558843052165\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.010460835881531239\n",
      "Loss on test= 0.012308421544730663\n",
      "acc for Lsat= 0.2834575123144188 \n",
      "acc for Psat= 0.3343766510906052 \n",
      "acc for optim= 0.19921295274955786\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.010689802467823029\n",
      "Loss on test= 0.012410756200551987\n",
      "acc for Lsat= 0.24999488348210533 \n",
      "acc for Psat= 0.3641020355224444 \n",
      "acc for optim= 0.19249291814422403\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.011048653163015842\n",
      "Loss on test= 0.012148327194154263\n",
      "acc for Lsat= 0.27270247389773233 \n",
      "acc for Psat= 0.32142732369263555 \n",
      "acc for optim= 0.20437843981434944\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.010704051703214645\n",
      "Loss on test= 0.012658894062042236\n",
      "acc for Lsat= 0.24915089066593823 \n",
      "acc for Psat= 0.3134684516958628 \n",
      "acc for optim= 0.18866092171324944\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.01068445947021246\n",
      "Loss on test= 0.012881994247436523\n",
      "acc for Lsat= 0.29830271367609384 \n",
      "acc for Psat= 0.31028380745713524 \n",
      "acc for optim= 0.2008442951946809\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.011159460991621017\n",
      "Loss on test= 0.012415655888617039\n",
      "acc for Lsat= 0.2731072325456095 \n",
      "acc for Psat= 0.3141631765626969 \n",
      "acc for optim= 0.19211070005769362\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.010958580300211906\n",
      "Loss on test= 0.01179388165473938\n",
      "acc for Lsat= 0.26112747387702945 \n",
      "acc for Psat= 0.31668270979964686 \n",
      "acc for optim= 0.19782579877229747\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.010868408717215061\n",
      "Loss on test= 0.014773523434996605\n",
      "acc for Lsat= 0.2687277153832051 \n",
      "acc for Psat= 0.4334492964503502 \n",
      "acc for optim= 0.19755106914837253\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.011726956814527512\n",
      "Loss on test= 0.012596914544701576\n",
      "acc for Lsat= 0.3216202379459188 \n",
      "acc for Psat= 0.3162030271935667 \n",
      "acc for optim= 0.2027404727925534\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.011412153951823711\n",
      "Loss on test= 0.012322702445089817\n",
      "acc for Lsat= 0.2641584729481602 \n",
      "acc for Psat= 0.3434772438256029 \n",
      "acc for optim= 0.2027511700525301\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.01074602734297514\n",
      "Loss on test= 0.014617222361266613\n",
      "acc for Lsat= 0.24991680536304312 \n",
      "acc for Psat= 0.42682071989937054 \n",
      "acc for optim= 0.19174450339852303\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.010812269523739815\n",
      "Loss on test= 0.012535739690065384\n",
      "acc for Lsat= 0.2455108106487141 \n",
      "acc for Psat= 0.37009628818565476 \n",
      "acc for optim= 0.19993858392853006\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.010457046329975128\n",
      "Loss on test= 0.01244167611002922\n",
      "acc for Lsat= 0.25770407056788336 \n",
      "acc for Psat= 0.35438991874901615 \n",
      "acc for optim= 0.20068985898507055\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.010478922165930271\n",
      "Loss on test= 0.012446115724742413\n",
      "acc for Lsat= 0.26472139921011023 \n",
      "acc for Psat= 0.31097723303734 \n",
      "acc for optim= 0.1978700643734113\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.01059041265398264\n",
      "Loss on test= 0.01217243354767561\n",
      "acc for Lsat= 0.2366590792277035 \n",
      "acc for Psat= 0.3284331925757657 \n",
      "acc for optim= 0.1902423740303257\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.010821149684488773\n",
      "Loss on test= 0.011941567994654179\n",
      "acc for Lsat= 0.2571371527902139 \n",
      "acc for Psat= 0.32664828808550295 \n",
      "acc for optim= 0.19715663588391868\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.011036437936127186\n",
      "Loss on test= 0.013276354409754276\n",
      "acc for Lsat= 0.30677332014110525 \n",
      "acc for Psat= 0.30850531551924004 \n",
      "acc for optim= 0.19585842801697673\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.011439425870776176\n",
      "Loss on test= 0.012153218500316143\n",
      "acc for Lsat= 0.2546115541945501 \n",
      "acc for Psat= 0.3433843661139788 \n",
      "acc for optim= 0.18851571916476698\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.010815010406076908\n",
      "Loss on test= 0.01223286334425211\n",
      "acc for Lsat= 0.24656554445838894 \n",
      "acc for Psat= 0.34762192693125216 \n",
      "acc for optim= 0.19686401398802125\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.010457250289618969\n",
      "Loss on test= 0.012001559138298035\n",
      "acc for Lsat= 0.28161540550000436 \n",
      "acc for Psat= 0.3295946155589804 \n",
      "acc for optim= 0.19347397727501262\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.010440255515277386\n",
      "Loss on test= 0.011844824999570847\n",
      "acc for Lsat= 0.24618661564690647 \n",
      "acc for Psat= 0.3415220247955625 \n",
      "acc for optim= 0.20356039448981048\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.01037976797670126\n",
      "Loss on test= 0.012757224030792713\n",
      "acc for Lsat= 0.3096544160255911 \n",
      "acc for Psat= 0.3174437692180839 \n",
      "acc for optim= 0.19219617230614736\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.010793311521410942\n",
      "Loss on test= 0.013139184564352036\n",
      "acc for Lsat= 0.257659057050635 \n",
      "acc for Psat= 0.4061400869053417 \n",
      "acc for optim= 0.19632693676375484\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.010759747587144375\n",
      "Loss on test= 0.012312269769608974\n",
      "acc for Lsat= 0.2722207873694306 \n",
      "acc for Psat= 0.3279974877345061 \n",
      "acc for optim= 0.18736902713361495\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.010772323235869408\n",
      "Loss on test= 0.011761434376239777\n",
      "acc for Lsat= 0.26400870261273374 \n",
      "acc for Psat= 0.313812920771975 \n",
      "acc for optim= 0.18942178550767838\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.010374372825026512\n",
      "Loss on test= 0.012135948985815048\n",
      "acc for Lsat= 0.29639777260977224 \n",
      "acc for Psat= 0.3198512908664368 \n",
      "acc for optim= 0.203740200740474\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.01042935810983181\n",
      "Loss on test= 0.012525263242423534\n",
      "acc for Lsat= 0.2508667186704917 \n",
      "acc for Psat= 0.353827080921808 \n",
      "acc for optim= 0.20853587247748273\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.010639277286827564\n",
      "Loss on test= 0.012397793121635914\n",
      "acc for Lsat= 0.3246802206566507 \n",
      "acc for Psat= 0.2978327230045358 \n",
      "acc for optim= 0.19073974241257166\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.011051695793867111\n",
      "Loss on test= 0.01327603030949831\n",
      "acc for Lsat= 0.2345366285875128 \n",
      "acc for Psat= 0.4057413755060249 \n",
      "acc for optim= 0.18943852318143645\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.010961639694869518\n",
      "Loss on test= 0.012370511889457703\n",
      "acc for Lsat= 0.237699937147202 \n",
      "acc for Psat= 0.32957470685913587 \n",
      "acc for optim= 0.1966172066142364\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.01014488935470581\n",
      "Loss on test= 0.011611009016633034\n",
      "acc for Lsat= 0.26434676946558505 \n",
      "acc for Psat= 0.31292282184939896 \n",
      "acc for optim= 0.20618850292934487\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.010085208341479301\n",
      "Loss on test= 0.01209204737097025\n",
      "acc for Lsat= 0.28941585401205244 \n",
      "acc for Psat= 0.3308599156630776 \n",
      "acc for optim= 0.2030363647612142\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.010756544768810272\n",
      "Loss on test= 0.011942905373871326\n",
      "acc for Lsat= 0.2410103611693705 \n",
      "acc for Psat= 0.32605507855525406 \n",
      "acc for optim= 0.19461551306994807\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.010450243018567562\n",
      "Loss on test= 0.012367754243314266\n",
      "acc for Lsat= 0.24963968934025615 \n",
      "acc for Psat= 0.3505037619813536 \n",
      "acc for optim= 0.20798482863264744\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.010092370212078094\n",
      "Loss on test= 0.011718270368874073\n",
      "acc for Lsat= 0.2554353857312644 \n",
      "acc for Psat= 0.32002174740812955 \n",
      "acc for optim= 0.19879774841782008\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.010309065692126751\n",
      "Loss on test= 0.012758452445268631\n",
      "acc for Lsat= 0.23396730907021462 \n",
      "acc for Psat= 0.3931542527153962 \n",
      "acc for optim= 0.19445709565676422\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.010051252320408821\n",
      "Loss on test= 0.011145424097776413\n",
      "acc for Lsat= 0.2538458251498948 \n",
      "acc for Psat= 0.3278554469838422 \n",
      "acc for optim= 0.20317229669091977\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.010231698863208294\n",
      "Loss on test= 0.011936640366911888\n",
      "acc for Lsat= 0.24128349319122405 \n",
      "acc for Psat= 0.3417677447588987 \n",
      "acc for optim= 0.18798423862156327\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.010192560032010078\n",
      "Loss on test= 0.012422808445990086\n",
      "acc for Lsat= 0.2436798685615744 \n",
      "acc for Psat= 0.311398173877466 \n",
      "acc for optim= 0.19277972127275536\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.010085304267704487\n",
      "Loss on test= 0.012057945132255554\n",
      "acc for Lsat= 0.293076883650281 \n",
      "acc for Psat= 0.29773705165870207 \n",
      "acc for optim= 0.19550926645830702\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.010978431440889835\n",
      "Loss on test= 0.012461159378290176\n",
      "acc for Lsat= 0.30142213318597627 \n",
      "acc for Psat= 0.2934192250864062 \n",
      "acc for optim= 0.19486649562364816\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.010133618488907814\n",
      "Loss on test= 0.011477676220238209\n",
      "acc for Lsat= 0.23942304415627527 \n",
      "acc for Psat= 0.3269935729256611 \n",
      "acc for optim= 0.19050120903488574\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.010112262330949306\n",
      "Loss on test= 0.011239892803132534\n",
      "acc for Lsat= 0.27800739677575226 \n",
      "acc for Psat= 0.29870330888327257 \n",
      "acc for optim= 0.19026824355996969\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.009947693906724453\n",
      "Loss on test= 0.011637839488685131\n",
      "acc for Lsat= 0.2624135231709334 \n",
      "acc for Psat= 0.2988963041224869 \n",
      "acc for optim= 0.2064498056645027\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.010527737438678741\n",
      "Loss on test= 0.012164025567471981\n",
      "acc for Lsat= 0.24185196512514046 \n",
      "acc for Psat= 0.3562774456670898 \n",
      "acc for optim= 0.21472291951107075\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.01039569079875946\n",
      "Loss on test= 0.011314639821648598\n",
      "acc for Lsat= 0.24893210128632476 \n",
      "acc for Psat= 0.2990222781946933 \n",
      "acc for optim= 0.18730244942339228\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.010034985840320587\n",
      "Loss on test= 0.011348804458975792\n",
      "acc for Lsat= 0.2507631682253575 \n",
      "acc for Psat= 0.32737324409744534 \n",
      "acc for optim= 0.1891687998895823\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.010181625373661518\n",
      "Loss on test= 0.011757703498005867\n",
      "acc for Lsat= 0.26791591413171234 \n",
      "acc for Psat= 0.3140519269499409 \n",
      "acc for optim= 0.19927149499503807\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.010080630891025066\n",
      "Loss on test= 0.011345806531608105\n",
      "acc for Lsat= 0.2606262661118652 \n",
      "acc for Psat= 0.31558181641358296 \n",
      "acc for optim= 0.1892939240835305\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.010094133205711842\n",
      "Loss on test= 0.012426631525158882\n",
      "acc for Lsat= 0.3051561473210411 \n",
      "acc for Psat= 0.30420977601032656 \n",
      "acc for optim= 0.20092436471305838\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.010670237243175507\n",
      "Loss on test= 0.011641833931207657\n",
      "acc for Lsat= 0.2417937959658416 \n",
      "acc for Psat= 0.31696781208911734 \n",
      "acc for optim= 0.19335787551008743\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.009996726177632809\n",
      "Loss on test= 0.011389216408133507\n",
      "acc for Lsat= 0.2399841710977017 \n",
      "acc for Psat= 0.31511199297823916 \n",
      "acc for optim= 0.19173741795443552\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.010473554953932762\n",
      "Loss on test= 0.011516274884343147\n",
      "acc for Lsat= 0.24260631258712728 \n",
      "acc for Psat= 0.32058217787208204 \n",
      "acc for optim= 0.19767580594555978\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.010181997902691364\n",
      "Loss on test= 0.011698821559548378\n",
      "acc for Lsat= 0.27696183468391167 \n",
      "acc for Psat= 0.2933580198913586 \n",
      "acc for optim= 0.18820786796587108\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.010290605016052723\n",
      "Loss on test= 0.01318559143692255\n",
      "acc for Lsat= 0.24084627987660398 \n",
      "acc for Psat= 0.3730783044042304 \n",
      "acc for optim= 0.19268663044031936\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.01014881581068039\n",
      "Loss on test= 0.011571189388632774\n",
      "acc for Lsat= 0.26552478369007615 \n",
      "acc for Psat= 0.31713120335271505 \n",
      "acc for optim= 0.19767098606688385\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.010007770732045174\n",
      "Loss on test= 0.011637452058494091\n",
      "acc for Lsat= 0.23966472803629807 \n",
      "acc for Psat= 0.35538862271838495 \n",
      "acc for optim= 0.1952232854665773\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.009715080261230469\n",
      "Loss on test= 0.011785413138568401\n",
      "acc for Lsat= 0.24357389896750967 \n",
      "acc for Psat= 0.333588687345115 \n",
      "acc for optim= 0.2083731182761226\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.009973358362913132\n",
      "Loss on test= 0.011565466411411762\n",
      "acc for Lsat= 0.2714161730282531 \n",
      "acc for Psat= 0.28206480116460697 \n",
      "acc for optim= 0.19166681384652023\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.010083764791488647\n",
      "Loss on test= 0.012434250675141811\n",
      "acc for Lsat= 0.23135510660791328 \n",
      "acc for Psat= 0.3291753683690724 \n",
      "acc for optim= 0.1852275057117859\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.010250545106828213\n",
      "Loss on test= 0.011448188684880733\n",
      "acc for Lsat= 0.3254613132967771 \n",
      "acc for Psat= 0.3102739629563026 \n",
      "acc for optim= 0.1923714453899978\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.010412345640361309\n",
      "Loss on test= 0.012148256413638592\n",
      "acc for Lsat= 0.23558665809341128 \n",
      "acc for Psat= 0.34609671911567674 \n",
      "acc for optim= 0.18545355086358983\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.00998551957309246\n",
      "Loss on test= 0.011879862286150455\n",
      "acc for Lsat= 0.24026398814434335 \n",
      "acc for Psat= 0.3405701209876251 \n",
      "acc for optim= 0.19351506499653034\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.010173370130360126\n",
      "Loss on test= 0.01077510230243206\n",
      "acc for Lsat= 0.2368607662643331 \n",
      "acc for Psat= 0.30521832840403895 \n",
      "acc for optim= 0.18759349249798893\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.009783446788787842\n",
      "Loss on test= 0.011727467179298401\n",
      "acc for Lsat= 0.2390793315646226 \n",
      "acc for Psat= 0.3537885758518855 \n",
      "acc for optim= 0.19541496456024007\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.009894237853586674\n",
      "Loss on test= 0.01150440238416195\n",
      "acc for Lsat= 0.22973660882702018 \n",
      "acc for Psat= 0.31047570612989495 \n",
      "acc for optim= 0.19400568751518368\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.010052688419818878\n",
      "Loss on test= 0.010932104662060738\n",
      "acc for Lsat= 0.2450510264241382 \n",
      "acc for Psat= 0.29582248659445776 \n",
      "acc for optim= 0.18191446584702087\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.010410590097308159\n",
      "Loss on test= 0.010888748802244663\n",
      "acc for Lsat= 0.24595263753970456 \n",
      "acc for Psat= 0.30065826860742606 \n",
      "acc for optim= 0.19335949204036593\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.009911490604281425\n",
      "Loss on test= 0.0125508401542902\n",
      "acc for Lsat= 0.24071234940866643 \n",
      "acc for Psat= 0.36128033983208285 \n",
      "acc for optim= 0.22317969296253412\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.010369306430220604\n",
      "Loss on test= 0.012016106396913528\n",
      "acc for Lsat= 0.22892395193215437 \n",
      "acc for Psat= 0.3099975117500176 \n",
      "acc for optim= 0.19117645625885563\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.00980193167924881\n",
      "Loss on test= 0.011458623223006725\n",
      "acc for Lsat= 0.23824706293620496 \n",
      "acc for Psat= 0.2893494807602208 \n",
      "acc for optim= 0.19045521627649087\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.009482934139668941\n",
      "Loss on test= 0.010413836687803268\n",
      "acc for Lsat= 0.23764968825963553 \n",
      "acc for Psat= 0.3182895443774337 \n",
      "acc for optim= 0.18849217339202123\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.009694869630038738\n",
      "Loss on test= 0.011423707008361816\n",
      "acc for Lsat= 0.28409747822002535 \n",
      "acc for Psat= 0.27198021280472295 \n",
      "acc for optim= 0.18492357697451134\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.009978829883038998\n",
      "Loss on test= 0.011464276351034641\n",
      "acc for Lsat= 0.24485705545987765 \n",
      "acc for Psat= 0.2880115985046015 \n",
      "acc for optim= 0.18608996148002524\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.00981335062533617\n",
      "Loss on test= 0.011387744918465614\n",
      "acc for Lsat= 0.25536397430747654 \n",
      "acc for Psat= 0.30053114776249434 \n",
      "acc for optim= 0.18937163574151486\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.00965090375393629\n",
      "Loss on test= 0.011449483223259449\n",
      "acc for Lsat= 0.24776539505797404 \n",
      "acc for Psat= 0.30731705695861083 \n",
      "acc for optim= 0.18825388529935358\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.0096703777089715\n",
      "Loss on test= 0.010728164575994015\n",
      "acc for Lsat= 0.2193969054337071 \n",
      "acc for Psat= 0.28515553490433376 \n",
      "acc for optim= 0.1949828592841604\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.009401227347552776\n",
      "Loss on test= 0.011916263028979301\n",
      "acc for Lsat= 0.29180320523881015 \n",
      "acc for Psat= 0.2806109145122055 \n",
      "acc for optim= 0.19175983342291614\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.00945561658591032\n",
      "Loss on test= 0.011793423444032669\n",
      "acc for Lsat= 0.2958710277295747 \n",
      "acc for Psat= 0.2939332688407818 \n",
      "acc for optim= 0.18914063809269638\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.009779618121683598\n",
      "Loss on test= 0.012041425332427025\n",
      "acc for Lsat= 0.23442869197901314 \n",
      "acc for Psat= 0.35554921135986367 \n",
      "acc for optim= 0.20507344242847664\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.00983408559113741\n",
      "Loss on test= 0.010754573158919811\n",
      "acc for Lsat= 0.22210042088251636 \n",
      "acc for Psat= 0.30095733900442784 \n",
      "acc for optim= 0.1943720129367304\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.00954420119524002\n",
      "Loss on test= 0.010613534599542618\n",
      "acc for Lsat= 0.22848709450753066 \n",
      "acc for Psat= 0.30507407180404106 \n",
      "acc for optim= 0.19287927519149348\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.009546339511871338\n",
      "Loss on test= 0.011708509176969528\n",
      "acc for Lsat= 0.23103007313407156 \n",
      "acc for Psat= 0.3591335566338416 \n",
      "acc for optim= 0.19916442883854993\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.00950741209089756\n",
      "Loss on test= 0.010802858509123325\n",
      "acc for Lsat= 0.24051900570693024 \n",
      "acc for Psat= 0.29207988499468696 \n",
      "acc for optim= 0.18952424617128674\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.0095931775867939\n",
      "Loss on test= 0.011344822123646736\n",
      "acc for Lsat= 0.2276447401808754 \n",
      "acc for Psat= 0.3588059456760183 \n",
      "acc for optim= 0.18475968851172994\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.009757393039762974\n",
      "Loss on test= 0.010899027809500694\n",
      "acc for Lsat= 0.23770799425354297 \n",
      "acc for Psat= 0.2926914808395432 \n",
      "acc for optim= 0.19355877952939654\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.009630643762648106\n",
      "Loss on test= 0.011326915584504604\n",
      "acc for Lsat= 0.2733175689732102 \n",
      "acc for Psat= 0.2874431623105822 \n",
      "acc for optim= 0.19719082130728025\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.00962101761251688\n",
      "Loss on test= 0.011576424352824688\n",
      "acc for Lsat= 0.22845374467608445 \n",
      "acc for Psat= 0.3172014814115608 \n",
      "acc for optim= 0.18643301493196035\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.00975849013775587\n",
      "Loss on test= 0.011453856714069843\n",
      "acc for Lsat= 0.2300835726365787 \n",
      "acc for Psat= 0.27455768913598544 \n",
      "acc for optim= 0.18625397561678453\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.009730584919452667\n",
      "Loss on test= 0.011583134531974792\n",
      "acc for Lsat= 0.2260226837522193 \n",
      "acc for Psat= 0.3193794078477957 \n",
      "acc for optim= 0.1927126691386818\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.009498664177954197\n",
      "Loss on test= 0.012727704830467701\n",
      "acc for Lsat= 0.22800893080356882 \n",
      "acc for Psat= 0.37607823034016513 \n",
      "acc for optim= 0.18811927844689233\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.009522249922156334\n",
      "Loss on test= 0.011350256390869617\n",
      "acc for Lsat= 0.2424581073927756 \n",
      "acc for Psat= 0.2787714270494148 \n",
      "acc for optim= 0.20781400081137394\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.009507933631539345\n",
      "Loss on test= 0.011063829064369202\n",
      "acc for Lsat= 0.23133532737542614 \n",
      "acc for Psat= 0.31828188644745703 \n",
      "acc for optim= 0.19135436452150414\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.009514744393527508\n",
      "Loss on test= 0.010348919779062271\n",
      "acc for Lsat= 0.25440792421962927 \n",
      "acc for Psat= 0.2853391636897475 \n",
      "acc for optim= 0.1943457910702155\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.009511401876807213\n",
      "Loss on test= 0.010609691962599754\n",
      "acc for Lsat= 0.22067579675373006 \n",
      "acc for Psat= 0.29111668790574186 \n",
      "acc for optim= 0.18781324773786962\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.009962184354662895\n",
      "Loss on test= 0.011204374954104424\n",
      "acc for Lsat= 0.23756708493896736 \n",
      "acc for Psat= 0.29147649102732603 \n",
      "acc for optim= 0.18732870907297183\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.009578359313309193\n",
      "Loss on test= 0.011285409331321716\n",
      "acc for Lsat= 0.25386426956675995 \n",
      "acc for Psat= 0.2762959216429531 \n",
      "acc for optim= 0.18723502156137475\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.010056170634925365\n",
      "Loss on test= 0.012624338269233704\n",
      "acc for Lsat= 0.2296243579975625 \n",
      "acc for Psat= 0.38815006636306515 \n",
      "acc for optim= 0.19851946592316258\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.009433375671505928\n",
      "Loss on test= 0.010826349258422852\n",
      "acc for Lsat= 0.23921818420372754 \n",
      "acc for Psat= 0.2923265000061145 \n",
      "acc for optim= 0.19148347741370467\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.009465394541621208\n",
      "Loss on test= 0.010477454401552677\n",
      "acc for Lsat= 0.23864687760509992 \n",
      "acc for Psat= 0.29218516717426957 \n",
      "acc for optim= 0.18493497998998784\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.009375287219882011\n",
      "Loss on test= 0.011579178273677826\n",
      "acc for Lsat= 0.2293021494793671 \n",
      "acc for Psat= 0.33675114126094124 \n",
      "acc for optim= 0.19824242882635656\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.009676236659288406\n",
      "Loss on test= 0.010858089663088322\n",
      "acc for Lsat= 0.24364840487475237 \n",
      "acc for Psat= 0.31106026347009214 \n",
      "acc for optim= 0.18718846827962538\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.009170910343527794\n",
      "Loss on test= 0.01104093249887228\n",
      "acc for Lsat= 0.2269808597692817 \n",
      "acc for Psat= 0.30735227071076027 \n",
      "acc for optim= 0.1930462384145751\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.00931516569107771\n",
      "Loss on test= 0.010731412097811699\n",
      "acc for Lsat= 0.2363253225860201 \n",
      "acc for Psat= 0.2926357304158218 \n",
      "acc for optim= 0.18379448869303372\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.009209602139890194\n",
      "Loss on test= 0.010391224175691605\n",
      "acc for Lsat= 0.24262408456053056 \n",
      "acc for Psat= 0.2717191198765225 \n",
      "acc for optim= 0.18459724576914105\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.009213373996317387\n",
      "Loss on test= 0.010876452550292015\n",
      "acc for Lsat= 0.23102382135599525 \n",
      "acc for Psat= 0.3283107690143437 \n",
      "acc for optim= 0.1946915285929257\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.0094569968059659\n",
      "Loss on test= 0.01102512888610363\n",
      "acc for Lsat= 0.22605693100863514 \n",
      "acc for Psat= 0.3079144142561622 \n",
      "acc for optim= 0.185735072965341\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.0089107109233737\n",
      "Loss on test= 0.010388921946287155\n",
      "acc for Lsat= 0.2578366937145679 \n",
      "acc for Psat= 0.28085802754307027 \n",
      "acc for optim= 0.1870833808769365\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.008963219821453094\n",
      "Loss on test= 0.011241605505347252\n",
      "acc for Lsat= 0.21551252276685773 \n",
      "acc for Psat= 0.3063499252392265 \n",
      "acc for optim= 0.19311916643474014\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.009319968521595001\n",
      "Loss on test= 0.010349980555474758\n",
      "acc for Lsat= 0.2474003500852583 \n",
      "acc for Psat= 0.2781435860233614 \n",
      "acc for optim= 0.18881682444889275\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.009077424183487892\n",
      "Loss on test= 0.010914215818047523\n",
      "acc for Lsat= 0.21347425828178138 \n",
      "acc for Psat= 0.29613312391833263 \n",
      "acc for optim= 0.18943641465680353\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.008961711078882217\n",
      "Loss on test= 0.01027075108140707\n",
      "acc for Lsat= 0.21538661269005388 \n",
      "acc for Psat= 0.28406479530295237 \n",
      "acc for optim= 0.19649129429032924\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.009192136116325855\n",
      "Loss on test= 0.010362697765231133\n",
      "acc for Lsat= 0.21954885857829484 \n",
      "acc for Psat= 0.2974020649885092 \n",
      "acc for optim= 0.1876211283638809\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.009494445286691189\n",
      "Loss on test= 0.011744755320250988\n",
      "acc for Lsat= 0.30453584305989256 \n",
      "acc for Psat= 0.2782824682425033 \n",
      "acc for optim= 0.18667729241128286\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.009310933761298656\n",
      "Loss on test= 0.010903049260377884\n",
      "acc for Lsat= 0.21227490457484335 \n",
      "acc for Psat= 0.2999975582819929 \n",
      "acc for optim= 0.18849216141182518\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.009281223639845848\n",
      "Loss on test= 0.010669535957276821\n",
      "acc for Lsat= 0.24188200016608272 \n",
      "acc for Psat= 0.2720444251632167 \n",
      "acc for optim= 0.19231685655108163\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.009030204266309738\n",
      "Loss on test= 0.011026222258806229\n",
      "acc for Lsat= 0.2157347162294074 \n",
      "acc for Psat= 0.2978787747936597 \n",
      "acc for optim= 0.17993105897069137\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.008892727084457874\n",
      "Loss on test= 0.010345624759793282\n",
      "acc for Lsat= 0.23607906179244606 \n",
      "acc for Psat= 0.26879975626075436 \n",
      "acc for optim= 0.18813638985090153\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.008778564631938934\n",
      "Loss on test= 0.010478452779352665\n",
      "acc for Lsat= 0.22312623302757464 \n",
      "acc for Psat= 0.32541151128149265 \n",
      "acc for optim= 0.18492160543226763\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.008828801102936268\n",
      "Loss on test= 0.010740538127720356\n",
      "acc for Lsat= 0.2368133856739528 \n",
      "acc for Psat= 0.2667294481723582 \n",
      "acc for optim= 0.19775922132730311\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.008720588870346546\n",
      "Loss on test= 0.010673786513507366\n",
      "acc for Lsat= 0.23357749729365349 \n",
      "acc for Psat= 0.29335901009806153 \n",
      "acc for optim= 0.18675776339949987\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.009037068113684654\n",
      "Loss on test= 0.01026520412415266\n",
      "acc for Lsat= 0.21775744781621756 \n",
      "acc for Psat= 0.2920726923131546 \n",
      "acc for optim= 0.18970856377254186\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.00900283269584179\n",
      "Loss on test= 0.01111001055687666\n",
      "acc for Lsat= 0.2755429743902897 \n",
      "acc for Psat= 0.27542324681653063 \n",
      "acc for optim= 0.18292796867919262\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.009705412201583385\n",
      "Loss on test= 0.010376122780144215\n",
      "acc for Lsat= 0.22572425172836882 \n",
      "acc for Psat= 0.2912120838378984 \n",
      "acc for optim= 0.18983494339949716\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.009482847526669502\n",
      "Loss on test= 0.011336255818605423\n",
      "acc for Lsat= 0.2238601658064982 \n",
      "acc for Psat= 0.31770534203914813 \n",
      "acc for optim= 0.20045184710976616\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.009357067756354809\n",
      "Loss on test= 0.010510154999792576\n",
      "acc for Lsat= 0.23213997442586776 \n",
      "acc for Psat= 0.2626129201235017 \n",
      "acc for optim= 0.19146641839895007\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.009038805961608887\n",
      "Loss on test= 0.010714314877986908\n",
      "acc for Lsat= 0.21617343606929942 \n",
      "acc for Psat= 0.32426135795980665 \n",
      "acc for optim= 0.19406676951621193\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.008621074259281158\n",
      "Loss on test= 0.009604758583009243\n",
      "acc for Lsat= 0.2164270680152333 \n",
      "acc for Psat= 0.2690781345079666 \n",
      "acc for optim= 0.18946180600009077\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.008559669367969036\n",
      "Loss on test= 0.010530397295951843\n",
      "acc for Lsat= 0.21112405107871038 \n",
      "acc for Psat= 0.28557817256394724 \n",
      "acc for optim= 0.1934513249336207\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.009256565012037754\n",
      "Loss on test= 0.00969811249524355\n",
      "acc for Lsat= 0.21334127389992638 \n",
      "acc for Psat= 0.2757468016052371 \n",
      "acc for optim= 0.18720042774264192\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.008603878319263458\n",
      "Loss on test= 0.011013778857886791\n",
      "acc for Lsat= 0.20451004024456582 \n",
      "acc for Psat= 0.3152594493391941 \n",
      "acc for optim= 0.19763914300986202\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.008738287724554539\n",
      "Loss on test= 0.01031537912786007\n",
      "acc for Lsat= 0.2072139838150965 \n",
      "acc for Psat= 0.2569332682504791 \n",
      "acc for optim= 0.18842273156514164\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.008517899550497532\n",
      "Loss on test= 0.010185993276536465\n",
      "acc for Lsat= 0.19535965056493787 \n",
      "acc for Psat= 0.2983331064596486 \n",
      "acc for optim= 0.18993839236193438\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.008923222310841084\n",
      "Loss on test= 0.009567581117153168\n",
      "acc for Lsat= 0.22941217189961477 \n",
      "acc for Psat= 0.26992701166867894 \n",
      "acc for optim= 0.1875684106570269\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.008745823055505753\n",
      "Loss on test= 0.01045943982899189\n",
      "acc for Lsat= 0.21638714799160338 \n",
      "acc for Psat= 0.2777927255289329 \n",
      "acc for optim= 0.18442765534446398\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.008588640950620174\n",
      "Loss on test= 0.010255913250148296\n",
      "acc for Lsat= 0.2020928839573989 \n",
      "acc for Psat= 0.27919201701218765 \n",
      "acc for optim= 0.18275418161096782\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.008544172160327435\n",
      "Loss on test= 0.009953679516911507\n",
      "acc for Lsat= 0.20581626654716642 \n",
      "acc for Psat= 0.27028475820711845 \n",
      "acc for optim= 0.18400174954641024\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.008643008768558502\n",
      "Loss on test= 0.010055950842797756\n",
      "acc for Lsat= 0.2069944659072683 \n",
      "acc for Psat= 0.2602078656589743 \n",
      "acc for optim= 0.19075892469432754\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.008354074321687222\n",
      "Loss on test= 0.009516874328255653\n",
      "acc for Lsat= 0.2128027103197481 \n",
      "acc for Psat= 0.255621785970131 \n",
      "acc for optim= 0.18900244126239527\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.008279107511043549\n",
      "Loss on test= 0.010267372243106365\n",
      "acc for Lsat= 0.2171662805182702 \n",
      "acc for Psat= 0.2594474720028265 \n",
      "acc for optim= 0.18927592889323588\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.008995447307825089\n",
      "Loss on test= 0.011276206001639366\n",
      "acc for Lsat= 0.21508747759907162 \n",
      "acc for Psat= 0.32828324674443826 \n",
      "acc for optim= 0.18342261998092196\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.008965963497757912\n",
      "Loss on test= 0.009839849546551704\n",
      "acc for Lsat= 0.2015358198851646 \n",
      "acc for Psat= 0.2662942247273325 \n",
      "acc for optim= 0.18781641096565355\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.008262264542281628\n",
      "Loss on test= 0.00999414175748825\n",
      "acc for Lsat= 0.20496832384929262 \n",
      "acc for Psat= 0.2661171953309472 \n",
      "acc for optim= 0.18893537460698517\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.008119658567011356\n",
      "Loss on test= 0.009465214796364307\n",
      "acc for Lsat= 0.20535006796657201 \n",
      "acc for Psat= 0.26193831397717615 \n",
      "acc for optim= 0.1806607182591727\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.008730647154152393\n",
      "Loss on test= 0.009884667582809925\n",
      "acc for Lsat= 0.22886946399346533 \n",
      "acc for Psat= 0.26792061659034516 \n",
      "acc for optim= 0.20034622083678827\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.008405265398323536\n",
      "Loss on test= 0.009427759796380997\n",
      "acc for Lsat= 0.20369562722781492 \n",
      "acc for Psat= 0.25121103482528934 \n",
      "acc for optim= 0.18139896401029348\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.008215433917939663\n",
      "Loss on test= 0.009774059988558292\n",
      "acc for Lsat= 0.20195676794952994 \n",
      "acc for Psat= 0.2618175063487158 \n",
      "acc for optim= 0.1840294851783526\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.008386749774217606\n",
      "Loss on test= 0.009510962292551994\n",
      "acc for Lsat= 0.19706301505258936 \n",
      "acc for Psat= 0.27660274699273696 \n",
      "acc for optim= 0.18941693149138922\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.008149437606334686\n",
      "Loss on test= 0.009670787490904331\n",
      "acc for Lsat= 0.24727888885496901 \n",
      "acc for Psat= 0.26477209888941394 \n",
      "acc for optim= 0.1904649448354367\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.00886309053748846\n",
      "Loss on test= 0.010050831362605095\n",
      "acc for Lsat= 0.26739360934182 \n",
      "acc for Psat= 0.2573073000581841 \n",
      "acc for optim= 0.1801929942952041\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.008358428254723549\n",
      "Loss on test= 0.009885502979159355\n",
      "acc for Lsat= 0.2144976118335664 \n",
      "acc for Psat= 0.2522087870444945 \n",
      "acc for optim= 0.18576896594498288\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.008372475393116474\n",
      "Loss on test= 0.00972059927880764\n",
      "acc for Lsat= 0.23079391369351102 \n",
      "acc for Psat= 0.25711890229187606 \n",
      "acc for optim= 0.19967275977904972\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.00815106462687254\n",
      "Loss on test= 0.011018805205821991\n",
      "acc for Lsat= 0.19512918276745336 \n",
      "acc for Psat= 0.34255332172525976 \n",
      "acc for optim= 0.19937809699606718\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.008310569450259209\n",
      "Loss on test= 0.009845873340964317\n",
      "acc for Lsat= 0.20080987528529698 \n",
      "acc for Psat= 0.2462979271848461 \n",
      "acc for optim= 0.188292803522165\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.008113684132695198\n",
      "Loss on test= 0.00946437194943428\n",
      "acc for Lsat= 0.20089403563965666 \n",
      "acc for Psat= 0.2513796116038213 \n",
      "acc for optim= 0.1843802297646746\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.00852058082818985\n",
      "Loss on test= 0.011096440255641937\n",
      "acc for Lsat= 0.19778752073211395 \n",
      "acc for Psat= 0.31960882081585695 \n",
      "acc for optim= 0.1859126776575608\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.008132428862154484\n",
      "Loss on test= 0.009332053363323212\n",
      "acc for Lsat= 0.18633357877612022 \n",
      "acc for Psat= 0.23270808738055387 \n",
      "acc for optim= 0.18338385508615976\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.008227230980992317\n",
      "Loss on test= 0.0097389230504632\n",
      "acc for Lsat= 0.1907401132964485 \n",
      "acc for Psat= 0.2853603269326708 \n",
      "acc for optim= 0.18964028813875425\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.008153503760695457\n",
      "Loss on test= 0.009147617034614086\n",
      "acc for Lsat= 0.21539522965798136 \n",
      "acc for Psat= 0.25513602233636573 \n",
      "acc for optim= 0.18619626105567944\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.008021823130548\n",
      "Loss on test= 0.01008326094597578\n",
      "acc for Lsat= 0.23843816629183445 \n",
      "acc for Psat= 0.24904305027312884 \n",
      "acc for optim= 0.18610357786127604\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.008396790362894535\n",
      "Loss on test= 0.009629178792238235\n",
      "acc for Lsat= 0.18996165458638398 \n",
      "acc for Psat= 0.25653626824409786 \n",
      "acc for optim= 0.18875879421358224\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.00803401693701744\n",
      "Loss on test= 0.009183759801089764\n",
      "acc for Lsat= 0.1875756956500039 \n",
      "acc for Psat= 0.2717354741619823 \n",
      "acc for optim= 0.1866465278503342\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.008276017382740974\n",
      "Loss on test= 0.009419444017112255\n",
      "acc for Lsat= 0.18817210395669415 \n",
      "acc for Psat= 0.25934895268260705 \n",
      "acc for optim= 0.1872997644319627\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.007887364365160465\n",
      "Loss on test= 0.00957952719181776\n",
      "acc for Lsat= 0.20963875014520553 \n",
      "acc for Psat= 0.25822111078604076 \n",
      "acc for optim= 0.19223727774157384\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.00785644818097353\n",
      "Loss on test= 0.009650233201682568\n",
      "acc for Lsat= 0.21198180603656708 \n",
      "acc for Psat= 0.2310577218713415 \n",
      "acc for optim= 0.18506570374046458\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.007907834835350513\n",
      "Loss on test= 0.009854434989392757\n",
      "acc for Lsat= 0.16848780401218194 \n",
      "acc for Psat= 0.2650766003415983 \n",
      "acc for optim= 0.18523016928703648\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.0078823771327734\n",
      "Loss on test= 0.00912381336092949\n",
      "acc for Lsat= 0.1766121160778582 \n",
      "acc for Psat= 0.23660604421791112 \n",
      "acc for optim= 0.19041758485459345\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.00777605501934886\n",
      "Loss on test= 0.009228781796991825\n",
      "acc for Lsat= 0.19876426624565235 \n",
      "acc for Psat= 0.23246103157037618 \n",
      "acc for optim= 0.19008284447487755\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.008138462901115417\n",
      "Loss on test= 0.00898375827819109\n",
      "acc for Lsat= 0.1826821013551494 \n",
      "acc for Psat= 0.2273850021828784 \n",
      "acc for optim= 0.1865978408988323\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.00787443295121193\n",
      "Loss on test= 0.009158116765320301\n",
      "acc for Lsat= 0.21309667035449736 \n",
      "acc for Psat= 0.23451116666547023 \n",
      "acc for optim= 0.19030146927783592\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.008041745983064175\n",
      "Loss on test= 0.009278737008571625\n",
      "acc for Lsat= 0.2151162176466912 \n",
      "acc for Psat= 0.23698768239862417 \n",
      "acc for optim= 0.18738300710262862\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.007852920331060886\n",
      "Loss on test= 0.009062504395842552\n",
      "acc for Lsat= 0.19531530761781363 \n",
      "acc for Psat= 0.2520069887270094 \n",
      "acc for optim= 0.19793059048252698\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.007583947386592627\n",
      "Loss on test= 0.008938639424741268\n",
      "acc for Lsat= 0.1837869863217772 \n",
      "acc for Psat= 0.24445776772188618 \n",
      "acc for optim= 0.19077238434810834\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.007616502698510885\n",
      "Loss on test= 0.010412636213004589\n",
      "acc for Lsat= 0.2737808374769048 \n",
      "acc for Psat= 0.24505144257627026 \n",
      "acc for optim= 0.19042965524351677\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.007750380784273148\n",
      "Loss on test= 0.00890134647488594\n",
      "acc for Lsat= 0.17337236799397254 \n",
      "acc for Psat= 0.24684886260975208 \n",
      "acc for optim= 0.1817421215619106\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.007441795896738768\n",
      "Loss on test= 0.009858186356723309\n",
      "acc for Lsat= 0.1683088870062469 \n",
      "acc for Psat= 0.27278201463176066 \n",
      "acc for optim= 0.18672992930333823\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.0074509805999696255\n",
      "Loss on test= 0.009212817996740341\n",
      "acc for Lsat= 0.21015478313445882 \n",
      "acc for Psat= 0.244783901780957 \n",
      "acc for optim= 0.18699609094324546\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.007569401059299707\n",
      "Loss on test= 0.009420061483979225\n",
      "acc for Lsat= 0.21219945051138525 \n",
      "acc for Psat= 0.2484389174054298 \n",
      "acc for optim= 0.18674589450922605\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.007935876958072186\n",
      "Loss on test= 0.009073266759514809\n",
      "acc for Lsat= 0.18891620303799533 \n",
      "acc for Psat= 0.22788485186481774 \n",
      "acc for optim= 0.19161112944405162\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.0076815299689769745\n",
      "Loss on test= 0.008885775692760944\n",
      "acc for Lsat= 0.16698220194469998 \n",
      "acc for Psat= 0.24432061111154915 \n",
      "acc for optim= 0.18513800429590865\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.007574353367090225\n",
      "Loss on test= 0.008762444369494915\n",
      "acc for Lsat= 0.16581494694438223 \n",
      "acc for Psat= 0.24292482595980824 \n",
      "acc for optim= 0.1906492619179787\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.0075727952644228935\n",
      "Loss on test= 0.008973532356321812\n",
      "acc for Lsat= 0.20695571867612228 \n",
      "acc for Psat= 0.22437166368699518 \n",
      "acc for optim= 0.18966351995336359\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.007379746064543724\n",
      "Loss on test= 0.008461111225187778\n",
      "acc for Lsat= 0.17040860503019192 \n",
      "acc for Psat= 0.2201385031331557 \n",
      "acc for optim= 0.18379295610125032\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.007451427634805441\n",
      "Loss on test= 0.008754611946642399\n",
      "acc for Lsat= 0.1761073428448268 \n",
      "acc for Psat= 0.22208503614151473 \n",
      "acc for optim= 0.18521570978211113\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.007462621666491032\n",
      "Loss on test= 0.01034271065145731\n",
      "acc for Lsat= 0.1806760679240609 \n",
      "acc for Psat= 0.3008005139602795 \n",
      "acc for optim= 0.1884741042306052\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.0074486820958554745\n",
      "Loss on test= 0.008954169228672981\n",
      "acc for Lsat= 0.21344463583551948 \n",
      "acc for Psat= 0.22963465306462683 \n",
      "acc for optim= 0.18389776600864982\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.007485490757972002\n",
      "Loss on test= 0.009434254840016365\n",
      "acc for Lsat= 0.16965557659922698 \n",
      "acc for Psat= 0.2609685171911543 \n",
      "acc for optim= 0.19804593440966453\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.007771429140120745\n",
      "Loss on test= 0.009167931973934174\n",
      "acc for Lsat= 0.19221529507981236 \n",
      "acc for Psat= 0.2415086978006592 \n",
      "acc for optim= 0.18340503989777454\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.007929383777081966\n",
      "Loss on test= 0.008739612996578217\n",
      "acc for Lsat= 0.17251748879435408 \n",
      "acc for Psat= 0.2341247429946167 \n",
      "acc for optim= 0.19011485349462443\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.007449755445122719\n",
      "Loss on test= 0.009213315322995186\n",
      "acc for Lsat= 0.16596581240662853 \n",
      "acc for Psat= 0.26267861359244576 \n",
      "acc for optim= 0.1872522120667929\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.007281156722456217\n",
      "Loss on test= 0.008908462710678577\n",
      "acc for Lsat= 0.1632635096918691 \n",
      "acc for Psat= 0.23968115806722357 \n",
      "acc for optim= 0.18194957899568426\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.007016018033027649\n",
      "Loss on test= 0.00830287579447031\n",
      "acc for Lsat= 0.15649777602044884 \n",
      "acc for Psat= 0.2569447271325279 \n",
      "acc for optim= 0.1826618405814008\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.007185237016528845\n",
      "Loss on test= 0.008433829993009567\n",
      "acc for Lsat= 0.15280769721469345 \n",
      "acc for Psat= 0.22871932349359692 \n",
      "acc for optim= 0.18317950688651763\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.006945401430130005\n",
      "Loss on test= 0.008290628902614117\n",
      "acc for Lsat= 0.16366746219313968 \n",
      "acc for Psat= 0.23712305077021262 \n",
      "acc for optim= 0.18626335328696547\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.007371964398771524\n",
      "Loss on test= 0.008645025081932545\n",
      "acc for Lsat= 0.16263427280776072 \n",
      "acc for Psat= 0.22159561103703831 \n",
      "acc for optim= 0.18947108662949766\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.007680515758693218\n",
      "Loss on test= 0.008785108104348183\n",
      "acc for Lsat= 0.19777030960245315 \n",
      "acc for Psat= 0.21063257751725237 \n",
      "acc for optim= 0.1838261527351475\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.007718770299106836\n",
      "Loss on test= 0.009229136630892754\n",
      "acc for Lsat= 0.16365539612967483 \n",
      "acc for Psat= 0.22446905253525837 \n",
      "acc for optim= 0.18785801042709815\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.0071755326353013515\n",
      "Loss on test= 0.009225534275174141\n",
      "acc for Lsat= 0.16384559877042193 \n",
      "acc for Psat= 0.28813497789363013 \n",
      "acc for optim= 0.18558002387293823\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.007393964100629091\n",
      "Loss on test= 0.009489063173532486\n",
      "acc for Lsat= 0.15642431240998908 \n",
      "acc for Psat= 0.2917233589105308 \n",
      "acc for optim= 0.18752123960223036\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.007141170557588339\n",
      "Loss on test= 0.008283560164272785\n",
      "acc for Lsat= 0.16354806655451554 \n",
      "acc for Psat= 0.2209932245425227 \n",
      "acc for optim= 0.1854728659899027\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.0073104556649923325\n",
      "Loss on test= 0.008166380226612091\n",
      "acc for Lsat= 0.1741472770780682 \n",
      "acc for Psat= 0.21464322656833543 \n",
      "acc for optim= 0.17875201684276093\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.006901786662638187\n",
      "Loss on test= 0.008561796508729458\n",
      "acc for Lsat= 0.16361108996440904 \n",
      "acc for Psat= 0.22771828667749572 \n",
      "acc for optim= 0.19865380974000973\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.00718688266351819\n",
      "Loss on test= 0.008472093380987644\n",
      "acc for Lsat= 0.1920341438093896 \n",
      "acc for Psat= 0.21745134530519372 \n",
      "acc for optim= 0.18453991792823118\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.007143598515540361\n",
      "Loss on test= 0.008134149014949799\n",
      "acc for Lsat= 0.17605577943578357 \n",
      "acc for Psat= 0.2113228288424678 \n",
      "acc for optim= 0.18550332286208318\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.007718472741544247\n",
      "Loss on test= 0.008384211920201778\n",
      "acc for Lsat= 0.17063324274872807 \n",
      "acc for Psat= 0.22187020640656654 \n",
      "acc for optim= 0.18486985277711546\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.007177277468144894\n",
      "Loss on test= 0.008646383881568909\n",
      "acc for Lsat= 0.16228243094785186 \n",
      "acc for Psat= 0.22204793112138538 \n",
      "acc for optim= 0.19429546693100821\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.007052725646644831\n",
      "Loss on test= 0.008887404575943947\n",
      "acc for Lsat= 0.22024461075685592 \n",
      "acc for Psat= 0.2329070127751628 \n",
      "acc for optim= 0.18682644670548756\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.00793807115405798\n",
      "Loss on test= 0.008855192922055721\n",
      "acc for Lsat= 0.1846296248603156 \n",
      "acc for Psat= 0.23716138467283895 \n",
      "acc for optim= 0.1844883983657309\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.007173484191298485\n",
      "Loss on test= 0.009932272136211395\n",
      "acc for Lsat= 0.17152490328619416 \n",
      "acc for Psat= 0.3126755562654973 \n",
      "acc for optim= 0.18784238586030788\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.0078041129745543\n",
      "Loss on test= 0.008697276934981346\n",
      "acc for Lsat= 0.14917021968252614 \n",
      "acc for Psat= 0.2293434528465032 \n",
      "acc for optim= 0.19018465242059673\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.007372787222266197\n",
      "Loss on test= 0.00918083731085062\n",
      "acc for Lsat= 0.1544773358390238 \n",
      "acc for Psat= 0.24837056597204316 \n",
      "acc for optim= 0.21979528610815602\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.0073966775089502335\n",
      "Loss on test= 0.008497442118823528\n",
      "acc for Lsat= 0.17038378253621617 \n",
      "acc for Psat= 0.21361134354368472 \n",
      "acc for optim= 0.1977484629999192\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.006969913840293884\n",
      "Loss on test= 0.008202718570828438\n",
      "acc for Lsat= 0.15102278716290743 \n",
      "acc for Psat= 0.2168610480863159 \n",
      "acc for optim= 0.18413861300453122\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.007008795626461506\n",
      "Loss on test= 0.007900253869593143\n",
      "acc for Lsat= 0.14524582363240346 \n",
      "acc for Psat= 0.21631293871119064 \n",
      "acc for optim= 0.1843954888392693\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.0069578103721141815\n",
      "Loss on test= 0.008865517564117908\n",
      "acc for Lsat= 0.15134742860576855 \n",
      "acc for Psat= 0.2532481771124514 \n",
      "acc for optim= 0.18799330588218574\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.007084535900503397\n",
      "Loss on test= 0.008788763545453548\n",
      "acc for Lsat= 0.15883519352339776 \n",
      "acc for Psat= 0.2599143353106007 \n",
      "acc for optim= 0.18306883379812683\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.007032226771116257\n",
      "Loss on test= 0.008666707202792168\n",
      "acc for Lsat= 0.15792273986349953 \n",
      "acc for Psat= 0.23171684923471655 \n",
      "acc for optim= 0.19299884132035644\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.0070539116859436035\n",
      "Loss on test= 0.00825562234967947\n",
      "acc for Lsat= 0.15950938968022899 \n",
      "acc for Psat= 0.2241638359386392 \n",
      "acc for optim= 0.19214227498250203\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.006845599040389061\n",
      "Loss on test= 0.008007821626961231\n",
      "acc for Lsat= 0.1388359400087555 \n",
      "acc for Psat= 0.21852355799165782 \n",
      "acc for optim= 0.18463304863080093\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.006899596657603979\n",
      "Loss on test= 0.008111509494483471\n",
      "acc for Lsat= 0.15072232259695442 \n",
      "acc for Psat= 0.21334124769782647 \n",
      "acc for optim= 0.18377452208133527\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.007183162961155176\n",
      "Loss on test= 0.008870229125022888\n",
      "acc for Lsat= 0.14392594473011322 \n",
      "acc for Psat= 0.2556848456204878 \n",
      "acc for optim= 0.18318707170436863\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.0068115065805613995\n",
      "Loss on test= 0.008109276182949543\n",
      "acc for Lsat= 0.15893195838135718 \n",
      "acc for Psat= 0.21623844565117514 \n",
      "acc for optim= 0.1803522388326127\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.006883487105369568\n",
      "Loss on test= 0.008082486689090729\n",
      "acc for Lsat= 0.14314971437065774 \n",
      "acc for Psat= 0.21443774167415244 \n",
      "acc for optim= 0.18631331700217324\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.006643771193921566\n",
      "Loss on test= 0.007948590442538261\n",
      "acc for Lsat= 0.14907264466671985 \n",
      "acc for Psat= 0.21059382675284233 \n",
      "acc for optim= 0.18218736912692562\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.006889175623655319\n",
      "Loss on test= 0.00784830842167139\n",
      "acc for Lsat= 0.1416696915360253 \n",
      "acc for Psat= 0.206986450644468 \n",
      "acc for optim= 0.18000087746760393\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.006758627016097307\n",
      "Loss on test= 0.007946365512907505\n",
      "acc for Lsat= 0.16282236767447839 \n",
      "acc for Psat= 0.23567159645529967 \n",
      "acc for optim= 0.18606522955009053\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.006680959835648537\n",
      "Loss on test= 0.008123066276311874\n",
      "acc for Lsat= 0.14962853516398528 \n",
      "acc for Psat= 0.19907547823665506 \n",
      "acc for optim= 0.19178247866177509\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.0069081541150808334\n",
      "Loss on test= 0.007816316559910774\n",
      "acc for Lsat= 0.14868587397850697 \n",
      "acc for Psat= 0.20602912696921447 \n",
      "acc for optim= 0.18655831124242223\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.006773755885660648\n",
      "Loss on test= 0.008376088924705982\n",
      "acc for Lsat= 0.1445651265235643 \n",
      "acc for Psat= 0.22266914257134712 \n",
      "acc for optim= 0.18823325564153492\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.006823751609772444\n",
      "Loss on test= 0.00829521007835865\n",
      "acc for Lsat= 0.13802572481556027 \n",
      "acc for Psat= 0.2250504153508774 \n",
      "acc for optim= 0.18577975155465146\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.006632079370319843\n",
      "Loss on test= 0.0077980016358196735\n",
      "acc for Lsat= 0.14710201551477783 \n",
      "acc for Psat= 0.20725268436748395 \n",
      "acc for optim= 0.1890587568537936\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.006825361400842667\n",
      "Loss on test= 0.00831588078290224\n",
      "acc for Lsat= 0.14284774230430697 \n",
      "acc for Psat= 0.21971123468225612 \n",
      "acc for optim= 0.18593298932818458\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.006841124501079321\n",
      "Loss on test= 0.009103670716285706\n",
      "acc for Lsat= 0.16112677724733068 \n",
      "acc for Psat= 0.2870124364609994 \n",
      "acc for optim= 0.18307334701111777\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.0068562268279492855\n",
      "Loss on test= 0.008274110965430737\n",
      "acc for Lsat= 0.14782227034251066 \n",
      "acc for Psat= 0.21243540182999945 \n",
      "acc for optim= 0.19050509200649293\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.006698010955005884\n",
      "Loss on test= 0.008409356698393822\n",
      "acc for Lsat= 0.14722881282196376 \n",
      "acc for Psat= 0.24619447111114356 \n",
      "acc for optim= 0.17994798935506953\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.00679057976230979\n",
      "Loss on test= 0.009973310865461826\n",
      "acc for Lsat= 0.16385159645928857 \n",
      "acc for Psat= 0.2887183790133202 \n",
      "acc for optim= 0.1916374089601418\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.007140741683542728\n",
      "Loss on test= 0.008285569958388805\n",
      "acc for Lsat= 0.15018100450775032 \n",
      "acc for Psat= 0.22960113090780274 \n",
      "acc for optim= 0.18601618502076678\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.0067878104746341705\n",
      "Loss on test= 0.007631282322108746\n",
      "acc for Lsat= 0.1472526911935052 \n",
      "acc for Psat= 0.21167688197709975 \n",
      "acc for optim= 0.1898334090332896\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.006700097117573023\n",
      "Loss on test= 0.008262033574283123\n",
      "acc for Lsat= 0.14050116850086017 \n",
      "acc for Psat= 0.21793482334642494 \n",
      "acc for optim= 0.1866507646796841\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.0066443393006920815\n",
      "Loss on test= 0.010012303479015827\n",
      "acc for Lsat= 0.17014382297064592 \n",
      "acc for Psat= 0.29073999789168714 \n",
      "acc for optim= 0.1990230111743487\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.007020214572548866\n",
      "Loss on test= 0.008310876786708832\n",
      "acc for Lsat= 0.14033154992245506 \n",
      "acc for Psat= 0.2044883854253606 \n",
      "acc for optim= 0.18544714761043685\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.006599013693630695\n",
      "Loss on test= 0.007668732199817896\n",
      "acc for Lsat= 0.14397165236595036 \n",
      "acc for Psat= 0.19807471036231594 \n",
      "acc for optim= 0.18048929083886686\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.006617201026529074\n",
      "Loss on test= 0.007715492509305477\n",
      "acc for Lsat= 0.1368160866865789 \n",
      "acc for Psat= 0.20455252124058362 \n",
      "acc for optim= 0.18161094107258455\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.006420064717531204\n",
      "Loss on test= 0.007731716148555279\n",
      "acc for Lsat= 0.1535168352796561 \n",
      "acc for Psat= 0.20431851080384394 \n",
      "acc for optim= 0.18614560779049596\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.007022269535809755\n",
      "Loss on test= 0.008225774392485619\n",
      "acc for Lsat= 0.1505807552634537 \n",
      "acc for Psat= 0.2107483751385951 \n",
      "acc for optim= 0.18023998012722586\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.006953094154596329\n",
      "Loss on test= 0.008453238755464554\n",
      "acc for Lsat= 0.14878891456252147 \n",
      "acc for Psat= 0.2342622794755354 \n",
      "acc for optim= 0.18547350209135746\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.006844460032880306\n",
      "Loss on test= 0.008642892353236675\n",
      "acc for Lsat= 0.14500818502140622 \n",
      "acc for Psat= 0.26604459641070255 \n",
      "acc for optim= 0.18340715942188557\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.00669822795316577\n",
      "Loss on test= 0.008257545530796051\n",
      "acc for Lsat= 0.1421659148626212 \n",
      "acc for Psat= 0.21962179221038633 \n",
      "acc for optim= 0.19246132186782308\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.006616672500967979\n",
      "Loss on test= 0.00834808312356472\n",
      "acc for Lsat= 0.14927968257393945 \n",
      "acc for Psat= 0.2145225646375341 \n",
      "acc for optim= 0.18367183474981938\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.006513820495456457\n",
      "Loss on test= 0.007471773307770491\n",
      "acc for Lsat= 0.13641744492043792 \n",
      "acc for Psat= 0.21505905187597965 \n",
      "acc for optim= 0.1792554689043853\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.006466297432780266\n",
      "Loss on test= 0.008116515353322029\n",
      "acc for Lsat= 0.19687827384709758 \n",
      "acc for Psat= 0.1980037359519613 \n",
      "acc for optim= 0.18878333477835907\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.00664706202223897\n",
      "Loss on test= 0.007669837214052677\n",
      "acc for Lsat= 0.16657933159916177 \n",
      "acc for Psat= 0.2026889773080404 \n",
      "acc for optim= 0.18168753277584343\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.006520796101540327\n",
      "Loss on test= 0.008075960911810398\n",
      "acc for Lsat= 0.1348863950548253 \n",
      "acc for Psat= 0.20992861190225576 \n",
      "acc for optim= 0.1826863834930181\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.0065237428061664104\n",
      "Loss on test= 0.007667061407119036\n",
      "acc for Lsat= 0.1384278160911632 \n",
      "acc for Psat= 0.21937410103950045 \n",
      "acc for optim= 0.1852296939148899\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.006535341031849384\n",
      "Loss on test= 0.007793900091201067\n",
      "acc for Lsat= 0.13998409139372056 \n",
      "acc for Psat= 0.21884858035234692 \n",
      "acc for optim= 0.18277008411697918\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.006412484683096409\n",
      "Loss on test= 0.007302465382963419\n",
      "acc for Lsat= 0.15476507482133064 \n",
      "acc for Psat= 0.19373543334759954 \n",
      "acc for optim= 0.1882946434176316\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.0065394677221775055\n",
      "Loss on test= 0.00803997740149498\n",
      "acc for Lsat= 0.14809070367590646 \n",
      "acc for Psat= 0.20789712960833787 \n",
      "acc for optim= 0.17932122985798374\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.006762005854398012\n",
      "Loss on test= 0.00792327057570219\n",
      "acc for Lsat= 0.1387240177558163 \n",
      "acc for Psat= 0.20809989931798112 \n",
      "acc for optim= 0.19022211794268712\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.006509202532470226\n",
      "Loss on test= 0.007802401203662157\n",
      "acc for Lsat= 0.1351845284174291 \n",
      "acc for Psat= 0.18907524603073889 \n",
      "acc for optim= 0.18907951876757875\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.006567668169736862\n",
      "Loss on test= 0.008580446243286133\n",
      "acc for Lsat= 0.14214752088997015 \n",
      "acc for Psat= 0.20635032987224436 \n",
      "acc for optim= 0.1887029634841334\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.006567647680640221\n",
      "Loss on test= 0.007656600791960955\n",
      "acc for Lsat= 0.1618678106690798 \n",
      "acc for Psat= 0.19834469563529883 \n",
      "acc for optim= 0.1898392923620712\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.006688194815069437\n",
      "Loss on test= 0.008010856807231903\n",
      "acc for Lsat= 0.1534202675112111 \n",
      "acc for Psat= 0.19701897148995676 \n",
      "acc for optim= 0.1804850651670996\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.006494126748293638\n",
      "Loss on test= 0.008255699649453163\n",
      "acc for Lsat= 0.14817568219292002 \n",
      "acc for Psat= 0.22145835387208215 \n",
      "acc for optim= 0.17905593209031173\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.006901020184159279\n",
      "Loss on test= 0.008080526255071163\n",
      "acc for Lsat= 0.16713746553819578 \n",
      "acc for Psat= 0.19816412161526387 \n",
      "acc for optim= 0.19601599608250656\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.006511482410132885\n",
      "Loss on test= 0.007698762230575085\n",
      "acc for Lsat= 0.13908051582286526 \n",
      "acc for Psat= 0.2205110028984121 \n",
      "acc for optim= 0.1855093054307233\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.006361817009747028\n",
      "Loss on test= 0.0074444180354475975\n",
      "acc for Lsat= 0.13629631375668985 \n",
      "acc for Psat= 0.19978929728559042 \n",
      "acc for optim= 0.1811785389275158\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.006500756833702326\n",
      "Loss on test= 0.007623044308274984\n",
      "acc for Lsat= 0.15910511174002454 \n",
      "acc for Psat= 0.18551184190712505 \n",
      "acc for optim= 0.18455655791197118\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.006435890682041645\n",
      "Loss on test= 0.00782773643732071\n",
      "acc for Lsat= 0.13614017482915014 \n",
      "acc for Psat= 0.2368282691726612 \n",
      "acc for optim= 0.18487979537035307\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.006585098337382078\n",
      "Loss on test= 0.007685728836804628\n",
      "acc for Lsat= 0.13905767575527755 \n",
      "acc for Psat= 0.2048114146362275 \n",
      "acc for optim= 0.1854877770969619\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.006553424522280693\n",
      "Loss on test= 0.007687344681471586\n",
      "acc for Lsat= 0.15329390528220116 \n",
      "acc for Psat= 0.1843917609673824 \n",
      "acc for optim= 0.1890098975673027\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.006670722272247076\n",
      "Loss on test= 0.00755629176273942\n",
      "acc for Lsat= 0.1532433832785869 \n",
      "acc for Psat= 0.20182965426694274 \n",
      "acc for optim= 0.18370359026979516\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.006541356444358826\n",
      "Loss on test= 0.007797460071742535\n",
      "acc for Lsat= 0.14806789647106622 \n",
      "acc for Psat= 0.20291405155974743 \n",
      "acc for optim= 0.1823898229799729\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.006477945018559694\n",
      "Loss on test= 0.007703325245529413\n",
      "acc for Lsat= 0.14570662153395508 \n",
      "acc for Psat= 0.19655575916112866 \n",
      "acc for optim= 0.18203411606668238\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.006604866124689579\n",
      "Loss on test= 0.0074968887493014336\n",
      "acc for Lsat= 0.13323261928031274 \n",
      "acc for Psat= 0.19465806858593046 \n",
      "acc for optim= 0.18800342294294703\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.006239625625312328\n",
      "Loss on test= 0.008023318834602833\n",
      "acc for Lsat= 0.13759728221457163 \n",
      "acc for Psat= 0.23002539074317413 \n",
      "acc for optim= 0.18693596271348084\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.006424833554774523\n",
      "Loss on test= 0.007909244857728481\n",
      "acc for Lsat= 0.13920920105364704 \n",
      "acc for Psat= 0.2406088992944648 \n",
      "acc for optim= 0.18255087021562094\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.006312925834208727\n",
      "Loss on test= 0.007764764595776796\n",
      "acc for Lsat= 0.1307735838198258 \n",
      "acc for Psat= 0.2194194753428255 \n",
      "acc for optim= 0.18119250897182831\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.006607506424188614\n",
      "Loss on test= 0.007883294485509396\n",
      "acc for Lsat= 0.13326360616987143 \n",
      "acc for Psat= 0.21983918180135456 \n",
      "acc for optim= 0.18389032714657258\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.006523996125906706\n",
      "Loss on test= 0.007491493597626686\n",
      "acc for Lsat= 0.15263137413028352 \n",
      "acc for Psat= 0.1993926705075176 \n",
      "acc for optim= 0.18379780355482236\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.006506138946861029\n",
      "Loss on test= 0.007832074537873268\n",
      "acc for Lsat= 0.16020027667904335 \n",
      "acc for Psat= 0.18622764133016137 \n",
      "acc for optim= 0.17837320409170068\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.006855342537164688\n",
      "Loss on test= 0.007901947014033794\n",
      "acc for Lsat= 0.19205784055206143 \n",
      "acc for Psat= 0.206845542664244 \n",
      "acc for optim= 0.18762022793108937\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.006967728957533836\n",
      "Loss on test= 0.007808424532413483\n",
      "acc for Lsat= 0.13704335331901865 \n",
      "acc for Psat= 0.1995871858346839 \n",
      "acc for optim= 0.1896845450384127\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.006459469441324472\n",
      "Loss on test= 0.007262479513883591\n",
      "acc for Lsat= 0.12856298569877744 \n",
      "acc for Psat= 0.1995296871328547 \n",
      "acc for optim= 0.1841398196688592\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.006401135120540857\n",
      "Loss on test= 0.0074060834012925625\n",
      "acc for Lsat= 0.1394928686973258 \n",
      "acc for Psat= 0.1857305287770499 \n",
      "acc for optim= 0.18456968147586086\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.006381274200975895\n",
      "Loss on test= 0.00776958791539073\n",
      "acc for Lsat= 0.13574519128824986 \n",
      "acc for Psat= 0.19529071164111342 \n",
      "acc for optim= 0.19010273202567643\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.0063671208918094635\n",
      "Loss on test= 0.007278783712536097\n",
      "acc for Lsat= 0.13889944796824852 \n",
      "acc for Psat= 0.1947235061966608 \n",
      "acc for optim= 0.1844052942560174\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.006275362800806761\n",
      "Loss on test= 0.007606375962495804\n",
      "acc for Lsat= 0.13002339429953577 \n",
      "acc for Psat= 0.20794244621366315 \n",
      "acc for optim= 0.17824559917239272\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.006411213427782059\n",
      "Loss on test= 0.0077475993894040585\n",
      "acc for Lsat= 0.12406786174530704 \n",
      "acc for Psat= 0.2176020621045609 \n",
      "acc for optim= 0.17954265685241538\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.006270568817853928\n",
      "Loss on test= 0.00798055250197649\n",
      "acc for Lsat= 0.14177503526671725 \n",
      "acc for Psat= 0.20817221349234633 \n",
      "acc for optim= 0.1919500257226163\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.006255812477320433\n",
      "Loss on test= 0.00751503836363554\n",
      "acc for Lsat= 0.14258365216389662 \n",
      "acc for Psat= 0.20217654124493295 \n",
      "acc for optim= 0.19180942432973785\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.006515314802527428\n",
      "Loss on test= 0.007560432888567448\n",
      "acc for Lsat= 0.1427207443942009 \n",
      "acc for Psat= 0.18616446508432902 \n",
      "acc for optim= 0.1826181939982603\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.006447996012866497\n",
      "Loss on test= 0.008258454501628876\n",
      "acc for Lsat= 0.18869854007349707 \n",
      "acc for Psat= 0.20570410277719633 \n",
      "acc for optim= 0.18239151555679053\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.00661832420155406\n",
      "Loss on test= 0.007748235948383808\n",
      "acc for Lsat= 0.13727604646182218 \n",
      "acc for Psat= 0.24655653927569604 \n",
      "acc for optim= 0.17977789747208198\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.0063876137137413025\n",
      "Loss on test= 0.007513265125453472\n",
      "acc for Lsat= 0.12921569615128967 \n",
      "acc for Psat= 0.18301176791656698 \n",
      "acc for optim= 0.18648485325330338\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.006424296647310257\n",
      "Loss on test= 0.008228877559304237\n",
      "acc for Lsat= 0.16472502066146164 \n",
      "acc for Psat= 0.18773498790569892 \n",
      "acc for optim= 0.1840613041961144\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.006683518178761005\n",
      "Loss on test= 0.007643606048077345\n",
      "acc for Lsat= 0.16481343312802524 \n",
      "acc for Psat= 0.1885140327001716 \n",
      "acc for optim= 0.18425416106765624\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.00638239411637187\n",
      "Loss on test= 0.008076794445514679\n",
      "acc for Lsat= 0.13563417060757618 \n",
      "acc for Psat= 0.2216139285529435 \n",
      "acc for optim= 0.1874051974123545\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.006256529130041599\n",
      "Loss on test= 0.007243792060762644\n",
      "acc for Lsat= 0.1336472753000389 \n",
      "acc for Psat= 0.19895967949206178 \n",
      "acc for optim= 0.18102236530762025\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.006290326360613108\n",
      "Loss on test= 0.007783384528011084\n",
      "acc for Lsat= 0.14355103997602142 \n",
      "acc for Psat= 0.20525067067609523 \n",
      "acc for optim= 0.1825587251679846\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.006314731668680906\n",
      "Loss on test= 0.007653347682207823\n",
      "acc for Lsat= 0.15099009767259672 \n",
      "acc for Psat= 0.18636039292402062 \n",
      "acc for optim= 0.17821809409636175\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.006413793656975031\n",
      "Loss on test= 0.007774156518280506\n",
      "acc for Lsat= 0.13769275668341466 \n",
      "acc for Psat= 0.18846890651223697 \n",
      "acc for optim= 0.1832704871139376\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.00635655177757144\n",
      "Loss on test= 0.007344583980739117\n",
      "acc for Lsat= 0.14044471059404148 \n",
      "acc for Psat= 0.1906771538885575 \n",
      "acc for optim= 0.18333667775034365\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.006407344713807106\n",
      "Loss on test= 0.007588967215269804\n",
      "acc for Lsat= 0.1305213893764311 \n",
      "acc for Psat= 0.19404733543558758 \n",
      "acc for optim= 0.18306366101839827\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.0062958127819001675\n",
      "Loss on test= 0.007514575961977243\n",
      "acc for Lsat= 0.12847089589254088 \n",
      "acc for Psat= 0.21014820577427698 \n",
      "acc for optim= 0.1825624817214014\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.006431335583329201\n",
      "Loss on test= 0.007885976694524288\n",
      "acc for Lsat= 0.1635596630736915 \n",
      "acc for Psat= 0.1894227301989402 \n",
      "acc for optim= 0.1861515174221839\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.006257990375161171\n",
      "Loss on test= 0.007519046310335398\n",
      "acc for Lsat= 0.13230099040437554 \n",
      "acc for Psat= 0.18978404549754388 \n",
      "acc for optim= 0.1833512835425633\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.006413547787815332\n",
      "Loss on test= 0.007984520867466927\n",
      "acc for Lsat= 0.13561434953668583 \n",
      "acc for Psat= 0.23959036965911887 \n",
      "acc for optim= 0.18788141255838028\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.00627993093803525\n",
      "Loss on test= 0.00739828497171402\n",
      "acc for Lsat= 0.12879378006697595 \n",
      "acc for Psat= 0.19299391661499268 \n",
      "acc for optim= 0.18034961463520113\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.00631302734836936\n",
      "Loss on test= 0.007996409200131893\n",
      "acc for Lsat= 0.12875078950546104 \n",
      "acc for Psat= 0.21596326828551576 \n",
      "acc for optim= 0.1898787881724471\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.006587858311831951\n",
      "Loss on test= 0.008284001611173153\n",
      "acc for Lsat= 0.1435749195311596 \n",
      "acc for Psat= 0.19879880165870026 \n",
      "acc for optim= 0.2083658909687074\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.006287415511906147\n",
      "Loss on test= 0.007713733706623316\n",
      "acc for Lsat= 0.12962816987235143 \n",
      "acc for Psat= 0.1892611497287116 \n",
      "acc for optim= 0.18259976015739282\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.006230196449905634\n",
      "Loss on test= 0.007880675606429577\n",
      "acc for Lsat= 0.1289368154887327 \n",
      "acc for Psat= 0.20847829379223137 \n",
      "acc for optim= 0.18381181163685806\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.006165101658552885\n",
      "Loss on test= 0.008355904370546341\n",
      "acc for Lsat= 0.13170525204495298 \n",
      "acc for Psat= 0.24664540993590717 \n",
      "acc for optim= 0.19130522059689659\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.006488667335361242\n",
      "Loss on test= 0.0074395714327692986\n",
      "acc for Lsat= 0.1415307818281911 \n",
      "acc for Psat= 0.1836974779328778 \n",
      "acc for optim= 0.18842547670607707\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.006400330923497677\n",
      "Loss on test= 0.007682249415665865\n",
      "acc for Lsat= 0.14717146234943357 \n",
      "acc for Psat= 0.1835396005794177 \n",
      "acc for optim= 0.1805858629804051\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.006418167147785425\n",
      "Loss on test= 0.00753631629049778\n",
      "acc for Lsat= 0.14924645436946554 \n",
      "acc for Psat= 0.1993030664393823 \n",
      "acc for optim= 0.18129321200733003\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.006271268706768751\n",
      "Loss on test= 0.007695815060287714\n",
      "acc for Lsat= 0.13378835247036674 \n",
      "acc for Psat= 0.20822171476764786 \n",
      "acc for optim= 0.1839173351974652\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.006142859812825918\n",
      "Loss on test= 0.007874968461692333\n",
      "acc for Lsat= 0.13202830846028127 \n",
      "acc for Psat= 0.21818767572299264 \n",
      "acc for optim= 0.18514995321648048\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.00610879622399807\n",
      "Loss on test= 0.007216051686555147\n",
      "acc for Lsat= 0.12466420634528559 \n",
      "acc for Psat= 0.18790621661409623 \n",
      "acc for optim= 0.1842596893844972\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.00626396993175149\n",
      "Loss on test= 0.007941588759422302\n",
      "acc for Lsat= 0.14414028846737426 \n",
      "acc for Psat= 0.21032386314323662 \n",
      "acc for optim= 0.17900863552307095\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.006299781147390604\n",
      "Loss on test= 0.007634405978024006\n",
      "acc for Lsat= 0.1428839072384132 \n",
      "acc for Psat= 0.18594510541564935 \n",
      "acc for optim= 0.18589285252666152\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.006144978106021881\n",
      "Loss on test= 0.007638451177626848\n",
      "acc for Lsat= 0.12986673244361285 \n",
      "acc for Psat= 0.21455455667789983 \n",
      "acc for optim= 0.1790456473321978\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.0061222855001688\n",
      "Loss on test= 0.007343880366533995\n",
      "acc for Lsat= 0.13842186561708553 \n",
      "acc for Psat= 0.17976926900725654 \n",
      "acc for optim= 0.1804882214263843\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.006185238249599934\n",
      "Loss on test= 0.0073907519690692425\n",
      "acc for Lsat= 0.1492195810835649 \n",
      "acc for Psat= 0.18462027078022722 \n",
      "acc for optim= 0.183660886944602\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.006187549326568842\n",
      "Loss on test= 0.007619427517056465\n",
      "acc for Lsat= 0.14148205614607856 \n",
      "acc for Psat= 0.21279450215474385 \n",
      "acc for optim= 0.18369051564651592\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.006127199623733759\n",
      "Loss on test= 0.007280096877366304\n",
      "acc for Lsat= 0.13685232227849278 \n",
      "acc for Psat= 0.20388903532561065 \n",
      "acc for optim= 0.1865718871342164\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.006131403148174286\n",
      "Loss on test= 0.0072923884727060795\n",
      "acc for Lsat= 0.13480151619689815 \n",
      "acc for Psat= 0.18104458721653507 \n",
      "acc for optim= 0.18272159158599655\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.006170971784740686\n",
      "Loss on test= 0.00823421124368906\n",
      "acc for Lsat= 0.13747080215024826 \n",
      "acc for Psat= 0.21389761529674098 \n",
      "acc for optim= 0.1817755976700593\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.006243611220270395\n",
      "Loss on test= 0.007472885772585869\n",
      "acc for Lsat= 0.12943419372754147 \n",
      "acc for Psat= 0.17055698719608747 \n",
      "acc for optim= 0.17950241651271573\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.006178228184580803\n",
      "Loss on test= 0.007347819861024618\n",
      "acc for Lsat= 0.12986730381109393 \n",
      "acc for Psat= 0.17953325764338424 \n",
      "acc for optim= 0.18171356869424926\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.006200603675097227\n",
      "Loss on test= 0.009096061810851097\n",
      "acc for Lsat= 0.1598867626319564 \n",
      "acc for Psat= 0.2681474552853222 \n",
      "acc for optim= 0.18532993402746994\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.0064475927501916885\n",
      "Loss on test= 0.007181717082858086\n",
      "acc for Lsat= 0.14424854899295275 \n",
      "acc for Psat= 0.184462146337594 \n",
      "acc for optim= 0.17570937515051196\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.006035319063812494\n",
      "Loss on test= 0.0075464448891580105\n",
      "acc for Lsat= 0.1289158807363443 \n",
      "acc for Psat= 0.20309210971518532 \n",
      "acc for optim= 0.17945986014564294\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.006184876896440983\n",
      "Loss on test= 0.008199714124202728\n",
      "acc for Lsat= 0.12549772825602573 \n",
      "acc for Psat= 0.205973968644488 \n",
      "acc for optim= 0.18839830650678188\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.006193055305629969\n",
      "Loss on test= 0.00726989796385169\n",
      "acc for Lsat= 0.1278526560577243 \n",
      "acc for Psat= 0.1920557008109156 \n",
      "acc for optim= 0.18213406032756776\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.006141746416687965\n",
      "Loss on test= 0.007475115824490786\n",
      "acc for Lsat= 0.11941875576716533 \n",
      "acc for Psat= 0.1858757206722461 \n",
      "acc for optim= 0.18624911499304092\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.006249158177524805\n",
      "Loss on test= 0.007643287070095539\n",
      "acc for Lsat= 0.12265804544432359 \n",
      "acc for Psat= 0.2200809546334927 \n",
      "acc for optim= 0.18633425371474396\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.00645554531365633\n",
      "Loss on test= 0.007596640381962061\n",
      "acc for Lsat= 0.13397947008520164 \n",
      "acc for Psat= 0.187850529587465 \n",
      "acc for optim= 0.18068559872866702\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.005964132957160473\n",
      "Loss on test= 0.007160842418670654\n",
      "acc for Lsat= 0.12199219569275384 \n",
      "acc for Psat= 0.17832483105558897 \n",
      "acc for optim= 0.1793456477035589\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.006239400710910559\n",
      "Loss on test= 0.007416333071887493\n",
      "acc for Lsat= 0.13075755504797673 \n",
      "acc for Psat= 0.1992720713322932 \n",
      "acc for optim= 0.17901071392721812\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.00612554419785738\n",
      "Loss on test= 0.0072513301856815815\n",
      "acc for Lsat= 0.12134346391441206 \n",
      "acc for Psat= 0.19002536039074217 \n",
      "acc for optim= 0.1803362732792487\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.006259105168282986\n",
      "Loss on test= 0.007029513828456402\n",
      "acc for Lsat= 0.11799852062039143 \n",
      "acc for Psat= 0.1721992035159142 \n",
      "acc for optim= 0.18300752625027844\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.006002482026815414\n",
      "Loss on test= 0.007558845914900303\n",
      "acc for Lsat= 0.1220370131457064 \n",
      "acc for Psat= 0.1882592124857183 \n",
      "acc for optim= 0.19359975893166848\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.006041007116436958\n",
      "Loss on test= 0.008170591667294502\n",
      "acc for Lsat= 0.11705741733955644 \n",
      "acc for Psat= 0.23347239778691753 \n",
      "acc for optim= 0.19381252844795124\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.006194183137267828\n",
      "Loss on test= 0.007496783975511789\n",
      "acc for Lsat= 0.16119181918652062 \n",
      "acc for Psat= 0.18988914327456843 \n",
      "acc for optim= 0.17895656938678775\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.006288884673267603\n",
      "Loss on test= 0.008618146181106567\n",
      "acc for Lsat= 0.14307403906344474 \n",
      "acc for Psat= 0.2531892193708061 \n",
      "acc for optim= 0.18725616387849653\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.006485689431428909\n",
      "Loss on test= 0.0074966116808354855\n",
      "acc for Lsat= 0.1192822152696789 \n",
      "acc for Psat= 0.1855387077098508 \n",
      "acc for optim= 0.18105214343617065\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.005915746092796326\n",
      "Loss on test= 0.007583210710436106\n",
      "acc for Lsat= 0.12988037473366382 \n",
      "acc for Psat= 0.21253902497512564 \n",
      "acc for optim= 0.17986243777124547\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.006193122360855341\n",
      "Loss on test= 0.007187442388385534\n",
      "acc for Lsat= 0.12471364964457697 \n",
      "acc for Psat= 0.1822520196901924 \n",
      "acc for optim= 0.18740534101694672\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.006051976233720779\n",
      "Loss on test= 0.007524908985942602\n",
      "acc for Lsat= 0.1183412013260012 \n",
      "acc for Psat= 0.19754491184171089 \n",
      "acc for optim= 0.1816298189044303\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.006128727458417416\n",
      "Loss on test= 0.007238611113280058\n",
      "acc for Lsat= 0.14126995029717462 \n",
      "acc for Psat= 0.17550930830947362 \n",
      "acc for optim= 0.18604917257766215\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.006041268352419138\n",
      "Loss on test= 0.007535497657954693\n",
      "acc for Lsat= 0.1293752491485459 \n",
      "acc for Psat= 0.20809871360973842 \n",
      "acc for optim= 0.18382665420619093\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.006144223269075155\n",
      "Loss on test= 0.007561224512755871\n",
      "acc for Lsat= 0.12700579015559876 \n",
      "acc for Psat= 0.20381839408219093 \n",
      "acc for optim= 0.18333655125241274\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.006036102771759033\n",
      "Loss on test= 0.007619492709636688\n",
      "acc for Lsat= 0.13230163307156165 \n",
      "acc for Psat= 0.20883397844079662 \n",
      "acc for optim= 0.18531637349352004\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.006059932988137007\n",
      "Loss on test= 0.007074542343616486\n",
      "acc for Lsat= 0.12932480804856578 \n",
      "acc for Psat= 0.18779810390298882 \n",
      "acc for optim= 0.18007179068012488\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.005871578585356474\n",
      "Loss on test= 0.0071869296953082085\n",
      "acc for Lsat= 0.12868206190005121 \n",
      "acc for Psat= 0.17808735372917098 \n",
      "acc for optim= 0.17849500725483144\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.006185480393469334\n",
      "Loss on test= 0.007566036190837622\n",
      "acc for Lsat= 0.13191314997542625 \n",
      "acc for Psat= 0.21062255626256465 \n",
      "acc for optim= 0.1825884075896947\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.006227885372936726\n",
      "Loss on test= 0.008286094292998314\n",
      "acc for Lsat= 0.14214768737912056 \n",
      "acc for Psat= 0.23069231195188114 \n",
      "acc for optim= 0.18524416833384452\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.006044043693691492\n",
      "Loss on test= 0.007252836599946022\n",
      "acc for Lsat= 0.12566848686873452 \n",
      "acc for Psat= 0.1917610825440607 \n",
      "acc for optim= 0.18142960015167184\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.005970214493572712\n",
      "Loss on test= 0.007052051834762096\n",
      "acc for Lsat= 0.12011112722560742 \n",
      "acc for Psat= 0.18234186633074118 \n",
      "acc for optim= 0.18445819753931672\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.006133388262242079\n",
      "Loss on test= 0.0076072257943451405\n",
      "acc for Lsat= 0.12763996818171722 \n",
      "acc for Psat= 0.19978146074749562 \n",
      "acc for optim= 0.18750990004136348\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.005876454059034586\n",
      "Loss on test= 0.007012376096099615\n",
      "acc for Lsat= 0.12097014632893882 \n",
      "acc for Psat= 0.17184553614650802 \n",
      "acc for optim= 0.18335652716239173\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.006125019863247871\n",
      "Loss on test= 0.0070405942387878895\n",
      "acc for Lsat= 0.11717556268165542 \n",
      "acc for Psat= 0.17864158126522434 \n",
      "acc for optim= 0.17893960051283964\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.005917497910559177\n",
      "Loss on test= 0.006953915115445852\n",
      "acc for Lsat= 0.13222171570924804 \n",
      "acc for Psat= 0.1693386120066714 \n",
      "acc for optim= 0.18099477053842625\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.005961311981081963\n",
      "Loss on test= 0.007565327454358339\n",
      "acc for Lsat= 0.13574982901470345 \n",
      "acc for Psat= 0.204652220490774 \n",
      "acc for optim= 0.17871033071903208\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.006022211164236069\n",
      "Loss on test= 0.007130447309464216\n",
      "acc for Lsat= 0.11328597015597404 \n",
      "acc for Psat= 0.1724510824703454 \n",
      "acc for optim= 0.17827809403486852\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.006014597602188587\n",
      "Loss on test= 0.007518650498241186\n",
      "acc for Lsat= 0.13225800553433098 \n",
      "acc for Psat= 0.21271204465321372 \n",
      "acc for optim= 0.17894420346183815\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.005849107634276152\n",
      "Loss on test= 0.0073601980693638325\n",
      "acc for Lsat= 0.12194986835375193 \n",
      "acc for Psat= 0.20636301682050642 \n",
      "acc for optim= 0.1843424217271653\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.006203534081578255\n",
      "Loss on test= 0.00782457273453474\n",
      "acc for Lsat= 0.13261349577860038 \n",
      "acc for Psat= 0.22030032669057176 \n",
      "acc for optim= 0.18068928632360562\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.006157614756375551\n",
      "Loss on test= 0.007349743042141199\n",
      "acc for Lsat= 0.12862840864733083 \n",
      "acc for Psat= 0.1789930435762791 \n",
      "acc for optim= 0.19040462829100244\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.005916467402130365\n",
      "Loss on test= 0.006985060404986143\n",
      "acc for Lsat= 0.12758641016635747 \n",
      "acc for Psat= 0.18321872607747217 \n",
      "acc for optim= 0.18268649341420362\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.005980128422379494\n",
      "Loss on test= 0.007283766753971577\n",
      "acc for Lsat= 0.15013536842790828 \n",
      "acc for Psat= 0.16153369308822957 \n",
      "acc for optim= 0.18173390019738517\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.005779841914772987\n",
      "Loss on test= 0.007089697755873203\n",
      "acc for Lsat= 0.11979937807975787 \n",
      "acc for Psat= 0.17483944682877534 \n",
      "acc for optim= 0.18435403173930967\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.005859247874468565\n",
      "Loss on test= 0.00743119278922677\n",
      "acc for Lsat= 0.12471229227545287 \n",
      "acc for Psat= 0.1912664496362472 \n",
      "acc for optim= 0.18016900743296482\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.0059545934200286865\n",
      "Loss on test= 0.007721327245235443\n",
      "acc for Lsat= 0.147555904023623 \n",
      "acc for Psat= 0.21460150695030106 \n",
      "acc for optim= 0.18056039387974543\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.006018325686454773\n",
      "Loss on test= 0.007196500431746244\n",
      "acc for Lsat= 0.12320810880049288 \n",
      "acc for Psat= 0.18293673050740492 \n",
      "acc for optim= 0.1814076147554285\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.005633397493511438\n",
      "Loss on test= 0.007259177975356579\n",
      "acc for Lsat= 0.11821714664585818 \n",
      "acc for Psat= 0.20856491945210723 \n",
      "acc for optim= 0.18166403890093016\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.005980087909847498\n",
      "Loss on test= 0.00737104844301939\n",
      "acc for Lsat= 0.12305530390703762 \n",
      "acc for Psat= 0.21139882431728169 \n",
      "acc for optim= 0.1827442085180036\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.006026600021868944\n",
      "Loss on test= 0.007156883366405964\n",
      "acc for Lsat= 0.11814648780312603 \n",
      "acc for Psat= 0.17894245294076894 \n",
      "acc for optim= 0.18258895959722912\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.005908063147217035\n",
      "Loss on test= 0.007313006557524204\n",
      "acc for Lsat= 0.1220661887298873 \n",
      "acc for Psat= 0.21535394802363905 \n",
      "acc for optim= 0.18389742972322967\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.006230936851352453\n",
      "Loss on test= 0.00703993858769536\n",
      "acc for Lsat= 0.11386813127417653 \n",
      "acc for Psat= 0.18892581930518842 \n",
      "acc for optim= 0.18193996528783385\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.005848560482263565\n",
      "Loss on test= 0.007341815158724785\n",
      "acc for Lsat= 0.11367130930159113 \n",
      "acc for Psat= 0.18758955149009912 \n",
      "acc for optim= 0.1805700837517302\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.005861102137714624\n",
      "Loss on test= 0.007155144587159157\n",
      "acc for Lsat= 0.11704500920353206 \n",
      "acc for Psat= 0.1887898037869466 \n",
      "acc for optim= 0.17806359594278792\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.005727106239646673\n",
      "Loss on test= 0.0069568222388625145\n",
      "acc for Lsat= 0.11552325165531649 \n",
      "acc for Psat= 0.17358187476123488 \n",
      "acc for optim= 0.1743623114383612\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.005845514126121998\n",
      "Loss on test= 0.0070715174078941345\n",
      "acc for Lsat= 0.11817328700055589 \n",
      "acc for Psat= 0.17622712178497849 \n",
      "acc for optim= 0.1800795115677583\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.005850703455507755\n",
      "Loss on test= 0.007398922927677631\n",
      "acc for Lsat= 0.12556319699266366 \n",
      "acc for Psat= 0.18526007212416074 \n",
      "acc for optim= 0.181181596010582\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.005807726643979549\n",
      "Loss on test= 0.0072496612556278706\n",
      "acc for Lsat= 0.11461287830850878 \n",
      "acc for Psat= 0.1824829105250034 \n",
      "acc for optim= 0.18165704443133626\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.005908327177166939\n",
      "Loss on test= 0.006975248921662569\n",
      "acc for Lsat= 0.12363546153072683 \n",
      "acc for Psat= 0.1820981001383127 \n",
      "acc for optim= 0.18270666876019645\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.005819867365062237\n",
      "Loss on test= 0.00725212786346674\n",
      "acc for Lsat= 0.11817683153384605 \n",
      "acc for Psat= 0.1783246278922692 \n",
      "acc for optim= 0.18318780873390073\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.005810463801026344\n",
      "Loss on test= 0.00700618140399456\n",
      "acc for Lsat= 0.12009058717253415 \n",
      "acc for Psat= 0.17045698636099366 \n",
      "acc for optim= 0.17931929851280026\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.005984801799058914\n",
      "Loss on test= 0.0071688503958284855\n",
      "acc for Lsat= 0.12114338880614063 \n",
      "acc for Psat= 0.1752466584246675 \n",
      "acc for optim= 0.18173592870506755\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.006009813863784075\n",
      "Loss on test= 0.007354334462434053\n",
      "acc for Lsat= 0.13644823732588643 \n",
      "acc for Psat= 0.16676408998259953 \n",
      "acc for optim= 0.1910443885800133\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.005920526571571827\n",
      "Loss on test= 0.0068666678853333\n",
      "acc for Lsat= 0.13289332950385083 \n",
      "acc for Psat= 0.17096112265740837 \n",
      "acc for optim= 0.18634051821395956\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.005764508154243231\n",
      "Loss on test= 0.007011230103671551\n",
      "acc for Lsat= 0.11373656073672808 \n",
      "acc for Psat= 0.1858199252212118 \n",
      "acc for optim= 0.18126273671864387\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.0058108433149755\n",
      "Loss on test= 0.006931218784302473\n",
      "acc for Lsat= 0.1178646209636763 \n",
      "acc for Psat= 0.1837207152958227 \n",
      "acc for optim= 0.1873589817606026\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.005800966173410416\n",
      "Loss on test= 0.0071877529844641685\n",
      "acc for Lsat= 0.11320112030726533 \n",
      "acc for Psat= 0.16746347006001333 \n",
      "acc for optim= 0.1781998782548849\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.00586746959015727\n",
      "Loss on test= 0.007174327503889799\n",
      "acc for Lsat= 0.11722391470126191 \n",
      "acc for Psat= 0.18093722694637207 \n",
      "acc for optim= 0.18340591543631957\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.006014049984514713\n",
      "Loss on test= 0.007189447060227394\n",
      "acc for Lsat= 0.12349708371078344 \n",
      "acc for Psat= 0.17716212468272913 \n",
      "acc for optim= 0.18024538017493183\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.006016695871949196\n",
      "Loss on test= 0.007427216973155737\n",
      "acc for Lsat= 0.1282130481012172 \n",
      "acc for Psat= 0.191724295447096 \n",
      "acc for optim= 0.18081569015172333\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.005813478492200375\n",
      "Loss on test= 0.007288637105375528\n",
      "acc for Lsat= 0.11291564340093385 \n",
      "acc for Psat= 0.22100032548258094 \n",
      "acc for optim= 0.19353806702250997\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.005723857786506414\n",
      "Loss on test= 0.007184563670307398\n",
      "acc for Lsat= 0.12973490918159006 \n",
      "acc for Psat= 0.16936710333342292 \n",
      "acc for optim= 0.18035626402864158\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.005896598566323519\n",
      "Loss on test= 0.007350651081651449\n",
      "acc for Lsat= 0.12792877850478288 \n",
      "acc for Psat= 0.184784031772496 \n",
      "acc for optim= 0.18461043274264494\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.005844159051775932\n",
      "Loss on test= 0.007630786392837763\n",
      "acc for Lsat= 0.1215903612248587 \n",
      "acc for Psat= 0.18758042667173572 \n",
      "acc for optim= 0.18085780765309087\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.005801355466246605\n",
      "Loss on test= 0.007588439621031284\n",
      "acc for Lsat= 0.11482315051254713 \n",
      "acc for Psat= 0.1989516276894515 \n",
      "acc for optim= 0.17964164570612656\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.005763316061347723\n",
      "Loss on test= 0.007398911286145449\n",
      "acc for Lsat= 0.11123478104656061 \n",
      "acc for Psat= 0.19003724156799442 \n",
      "acc for optim= 0.18488990019800808\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.006139759439975023\n",
      "Loss on test= 0.007132187020033598\n",
      "acc for Lsat= 0.12222397650691925 \n",
      "acc for Psat= 0.1718718985363454 \n",
      "acc for optim= 0.18054776558828717\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.005854370072484016\n",
      "Loss on test= 0.007113081403076649\n",
      "acc for Lsat= 0.12181391759077087 \n",
      "acc for Psat= 0.18602760042129965 \n",
      "acc for optim= 0.18360355510840481\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.00576750747859478\n",
      "Loss on test= 0.007565455045551062\n",
      "acc for Lsat= 0.11645987714726633 \n",
      "acc for Psat= 0.1811767108305798 \n",
      "acc for optim= 0.1879217306225139\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.005911441054195166\n",
      "Loss on test= 0.007043901365250349\n",
      "acc for Lsat= 0.12434048845249424 \n",
      "acc for Psat= 0.16046375667503918 \n",
      "acc for optim= 0.1801949909196402\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.005810190457850695\n",
      "Loss on test= 0.00684755714610219\n",
      "acc for Lsat= 0.12254778118084367 \n",
      "acc for Psat= 0.1699111873537848 \n",
      "acc for optim= 0.18835612645607153\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.005908661987632513\n",
      "Loss on test= 0.0070381020195782185\n",
      "acc for Lsat= 0.11695373489783378 \n",
      "acc for Psat= 0.17505981390029382 \n",
      "acc for optim= 0.1858644858106886\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.005709080491214991\n",
      "Loss on test= 0.007402531802654266\n",
      "acc for Lsat= 0.10928945126451671 \n",
      "acc for Psat= 0.18808207584506081 \n",
      "acc for optim= 0.19008390114342202\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.005780925042927265\n",
      "Loss on test= 0.007167471572756767\n",
      "acc for Lsat= 0.11454129496931693 \n",
      "acc for Psat= 0.1724593099583266 \n",
      "acc for optim= 0.18590935618802276\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.0056449295952916145\n",
      "Loss on test= 0.007035116199404001\n",
      "acc for Lsat= 0.1141392856525026 \n",
      "acc for Psat= 0.17399771347393383 \n",
      "acc for optim= 0.1837998230039375\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.005696143954992294\n",
      "Loss on test= 0.0070061697624623775\n",
      "acc for Lsat= 0.13304807113131942 \n",
      "acc for Psat= 0.17782974471894605 \n",
      "acc for optim= 0.18600313062071674\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.0058694761246442795\n",
      "Loss on test= 0.007663641590625048\n",
      "acc for Lsat= 0.11951673036949344 \n",
      "acc for Psat= 0.21754966895615152 \n",
      "acc for optim= 0.19191422588994247\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.006180210504680872\n",
      "Loss on test= 0.007887259125709534\n",
      "acc for Lsat= 0.13459375644526664 \n",
      "acc for Psat= 0.23507291824903773 \n",
      "acc for optim= 0.1924308627246835\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.006116454489529133\n",
      "Loss on test= 0.00706954812631011\n",
      "acc for Lsat= 0.13216871144155645 \n",
      "acc for Psat= 0.18943440492856442 \n",
      "acc for optim= 0.18192374199315964\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.005927947349846363\n",
      "Loss on test= 0.006827578414231539\n",
      "acc for Lsat= 0.11869198548575279 \n",
      "acc for Psat= 0.1717793140905505 \n",
      "acc for optim= 0.1777140454360051\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.005766745191067457\n",
      "Loss on test= 0.0069734519347548485\n",
      "acc for Lsat= 0.12008826410051002 \n",
      "acc for Psat= 0.17343173827268057 \n",
      "acc for optim= 0.18242258689802052\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.005647181998938322\n",
      "Loss on test= 0.007071580272167921\n",
      "acc for Lsat= 0.12900004467899243 \n",
      "acc for Psat= 0.1810222017843075 \n",
      "acc for optim= 0.1833260598545953\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.005743052810430527\n",
      "Loss on test= 0.007240320555865765\n",
      "acc for Lsat= 0.11358591931118123 \n",
      "acc for Psat= 0.18729574564703572 \n",
      "acc for optim= 0.19437669831067733\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.005890911445021629\n",
      "Loss on test= 0.006929669063538313\n",
      "acc for Lsat= 0.11724467754813943 \n",
      "acc for Psat= 0.16103472767438665 \n",
      "acc for optim= 0.1835901683266825\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.0057795182801783085\n",
      "Loss on test= 0.007024260703474283\n",
      "acc for Lsat= 0.11723218372675104 \n",
      "acc for Psat= 0.16776347148813353 \n",
      "acc for optim= 0.179605498850956\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.005751521792262793\n",
      "Loss on test= 0.007043818477541208\n",
      "acc for Lsat= 0.11324284873700054 \n",
      "acc for Psat= 0.17245836488822336 \n",
      "acc for optim= 0.1805115644652884\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.0058509353548288345\n",
      "Loss on test= 0.006860090419650078\n",
      "acc for Lsat= 0.1216124579120849 \n",
      "acc for Psat= 0.15524709788803956 \n",
      "acc for optim= 0.1820978063254655\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.005687880329787731\n",
      "Loss on test= 0.007230763323605061\n",
      "acc for Lsat= 0.11415803792270536 \n",
      "acc for Psat= 0.1691127486788114 \n",
      "acc for optim= 0.1837132791518564\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.005705695599317551\n",
      "Loss on test= 0.007195477373898029\n",
      "acc for Lsat= 0.11997097127282727 \n",
      "acc for Psat= 0.18359174219870977 \n",
      "acc for optim= 0.18257386405103543\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.005652053747326136\n",
      "Loss on test= 0.007390378508716822\n",
      "acc for Lsat= 0.12450580763785134 \n",
      "acc for Psat= 0.19140483122366178 \n",
      "acc for optim= 0.17740859057746117\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.00559244817122817\n",
      "Loss on test= 0.007135909050703049\n",
      "acc for Lsat= 0.10516298957903732 \n",
      "acc for Psat= 0.18343117295149272 \n",
      "acc for optim= 0.1873140420477186\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.005862009711563587\n",
      "Loss on test= 0.007105102296918631\n",
      "acc for Lsat= 0.11381810816002955 \n",
      "acc for Psat= 0.1830899771147587 \n",
      "acc for optim= 0.1802413259165651\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.00596984988078475\n",
      "Loss on test= 0.007042675279080868\n",
      "acc for Lsat= 0.10727039649133518 \n",
      "acc for Psat= 0.1704358589568811 \n",
      "acc for optim= 0.18492755620280985\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.00561995804309845\n",
      "Loss on test= 0.007150811143219471\n",
      "acc for Lsat= 0.11959408818150936 \n",
      "acc for Psat= 0.18002251401176672 \n",
      "acc for optim= 0.18158565522173523\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.005728843621909618\n",
      "Loss on test= 0.007080211769789457\n",
      "acc for Lsat= 0.11071508832262496 \n",
      "acc for Psat= 0.18082475701796924 \n",
      "acc for optim= 0.18443678793104284\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.005826909560710192\n",
      "Loss on test= 0.007055021822452545\n",
      "acc for Lsat= 0.12938880638752398 \n",
      "acc for Psat= 0.16604521312842122 \n",
      "acc for optim= 0.1801480340970581\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.005917116068303585\n",
      "Loss on test= 0.006918176542967558\n",
      "acc for Lsat= 0.11202059681764277 \n",
      "acc for Psat= 0.15534965431347578 \n",
      "acc for optim= 0.1759681468078319\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.0058432393707334995\n",
      "Loss on test= 0.00687214732170105\n",
      "acc for Lsat= 0.12139394023934319 \n",
      "acc for Psat= 0.17651673007600727 \n",
      "acc for optim= 0.18697276607142427\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.005638381000608206\n",
      "Loss on test= 0.006994801573455334\n",
      "acc for Lsat= 0.12365442367115827 \n",
      "acc for Psat= 0.16643749895150461 \n",
      "acc for optim= 0.180748829438803\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.005709236953407526\n",
      "Loss on test= 0.007449158001691103\n",
      "acc for Lsat= 0.11786479884437073 \n",
      "acc for Psat= 0.1850339370033219 \n",
      "acc for optim= 0.18127475093466716\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.005729562137275934\n",
      "Loss on test= 0.006907305214554071\n",
      "acc for Lsat= 0.11293687191111432 \n",
      "acc for Psat= 0.17964068813425665 \n",
      "acc for optim= 0.1874948198273086\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.0057304855436086655\n",
      "Loss on test= 0.006987518630921841\n",
      "acc for Lsat= 0.14410568781216637 \n",
      "acc for Psat= 0.1629965080913747 \n",
      "acc for optim= 0.17909205069785505\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.005981122609227896\n",
      "Loss on test= 0.006815366446971893\n",
      "acc for Lsat= 0.11963274029737993 \n",
      "acc for Psat= 0.15720844754046207 \n",
      "acc for optim= 0.1824190298243716\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.005715666804462671\n",
      "Loss on test= 0.006788745056837797\n",
      "acc for Lsat= 0.11346490737383105 \n",
      "acc for Psat= 0.17056868855163615 \n",
      "acc for optim= 0.1786593239895238\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.005637180060148239\n",
      "Loss on test= 0.006763329263776541\n",
      "acc for Lsat= 0.11588256524063999 \n",
      "acc for Psat= 0.15696402060210538 \n",
      "acc for optim= 0.18098662975594257\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.005835176445543766\n",
      "Loss on test= 0.006964939646422863\n",
      "acc for Lsat= 0.11048721738840155 \n",
      "acc for Psat= 0.1945935574575914 \n",
      "acc for optim= 0.18089839859562376\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.005855959840118885\n",
      "Loss on test= 0.007119304500520229\n",
      "acc for Lsat= 0.11758159434238395 \n",
      "acc for Psat= 0.1765778390305255 \n",
      "acc for optim= 0.181145366089343\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.005887292325496674\n",
      "Loss on test= 0.00699059059843421\n",
      "acc for Lsat= 0.10900840077787556 \n",
      "acc for Psat= 0.1691635175288743 \n",
      "acc for optim= 0.18381949213319268\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.005740870721638203\n",
      "Loss on test= 0.006947995629161596\n",
      "acc for Lsat= 0.13835921032384518 \n",
      "acc for Psat= 0.16502905953392336 \n",
      "acc for optim= 0.183917618097857\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.005755776539444923\n",
      "Loss on test= 0.007961932569742203\n",
      "acc for Lsat= 0.12918902634722856 \n",
      "acc for Psat= 0.26060643876317535 \n",
      "acc for optim= 0.182900968945162\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.0057375445030629635\n",
      "Loss on test= 0.006577441934496164\n",
      "acc for Lsat= 0.1176977002622988 \n",
      "acc for Psat= 0.16593614963042186 \n",
      "acc for optim= 0.18460059623042047\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.005695660598576069\n",
      "Loss on test= 0.0072795734740793705\n",
      "acc for Lsat= 0.11125560591494217 \n",
      "acc for Psat= 0.1945617342877282 \n",
      "acc for optim= 0.18429448070349502\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.005721427965909243\n",
      "Loss on test= 0.007245570421218872\n",
      "acc for Lsat= 0.11086371371060817 \n",
      "acc for Psat= 0.17603780902592572 \n",
      "acc for optim= 0.1871784191949897\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.0057221814058721066\n",
      "Loss on test= 0.006816367618739605\n",
      "acc for Lsat= 0.11220562899806946 \n",
      "acc for Psat= 0.1577603472639591 \n",
      "acc for optim= 0.1813021062661318\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.005755373742431402\n",
      "Loss on test= 0.00713655911386013\n",
      "acc for Lsat= 0.10976370739474471 \n",
      "acc for Psat= 0.169440972803804 \n",
      "acc for optim= 0.18430429385684752\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.0057030231691896915\n",
      "Loss on test= 0.007050031796097755\n",
      "acc for Lsat= 0.11369387392600451 \n",
      "acc for Psat= 0.17126685126286983 \n",
      "acc for optim= 0.18355161780109974\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.005584053695201874\n",
      "Loss on test= 0.0068755922839045525\n",
      "acc for Lsat= 0.11160527082442108 \n",
      "acc for Psat= 0.1825072885248291 \n",
      "acc for optim= 0.1806117785285145\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.005743552464991808\n",
      "Loss on test= 0.006589151918888092\n",
      "acc for Lsat= 0.1104630810655795 \n",
      "acc for Psat= 0.16606131747972244 \n",
      "acc for optim= 0.1773483222122367\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.005605968181043863\n",
      "Loss on test= 0.0070060845464468\n",
      "acc for Lsat= 0.13723586586446973 \n",
      "acc for Psat= 0.1623893593983863 \n",
      "acc for optim= 0.18204093234482963\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.00571049191057682\n",
      "Loss on test= 0.00734261330217123\n",
      "acc for Lsat= 0.11856567668970407 \n",
      "acc for Psat= 0.189108929481864 \n",
      "acc for optim= 0.1928376885466482\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.005721386522054672\n",
      "Loss on test= 0.007133854553103447\n",
      "acc for Lsat= 0.11184981075938275 \n",
      "acc for Psat= 0.18739200924126734 \n",
      "acc for optim= 0.18054026556500183\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.005726680625230074\n",
      "Loss on test= 0.006659680046141148\n",
      "acc for Lsat= 0.11433229872066453 \n",
      "acc for Psat= 0.15382803384272847 \n",
      "acc for optim= 0.1819686023376857\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.005653806496411562\n",
      "Loss on test= 0.00700725894421339\n",
      "acc for Lsat= 0.11645660753640334 \n",
      "acc for Psat= 0.17722472940599923 \n",
      "acc for optim= 0.17800024676142964\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.005582692567259073\n",
      "Loss on test= 0.006837429013103247\n",
      "acc for Lsat= 0.14664210503890382 \n",
      "acc for Psat= 0.15848820614470194 \n",
      "acc for optim= 0.1808143267550583\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.00589905958622694\n",
      "Loss on test= 0.007108143996447325\n",
      "acc for Lsat= 0.11986598124555736 \n",
      "acc for Psat= 0.17255120704617552 \n",
      "acc for optim= 0.1872083512909641\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005649893544614315\n",
      "Loss on test= 0.007099494803696871\n",
      "acc for Lsat= 0.10777951417804689 \n",
      "acc for Psat= 0.18400816597135097 \n",
      "acc for optim= 0.18274098250460796\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.005718137137591839\n",
      "Loss on test= 0.006648428738117218\n",
      "acc for Lsat= 0.10828411463503348 \n",
      "acc for Psat= 0.1572185150324839 \n",
      "acc for optim= 0.17931931466404963\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.005596413742750883\n",
      "Loss on test= 0.006881984416395426\n",
      "acc for Lsat= 0.11256305874495239 \n",
      "acc for Psat= 0.16327672757924538 \n",
      "acc for optim= 0.17668640747295875\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.005605896003544331\n",
      "Loss on test= 0.006916762795299292\n",
      "acc for Lsat= 0.11468032307102721 \n",
      "acc for Psat= 0.1609202559684982 \n",
      "acc for optim= 0.17769789304180153\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.0055993483401834965\n",
      "Loss on test= 0.006739231292158365\n",
      "acc for Lsat= 0.12232550217044805 \n",
      "acc for Psat= 0.15118133551240553 \n",
      "acc for optim= 0.1818005809827072\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.005633637309074402\n",
      "Loss on test= 0.006883382797241211\n",
      "acc for Lsat= 0.10982729865252229 \n",
      "acc for Psat= 0.19121764781664605 \n",
      "acc for optim= 0.18811263320645052\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.005659608636051416\n",
      "Loss on test= 0.00707143684849143\n",
      "acc for Lsat= 0.11548816486764416 \n",
      "acc for Psat= 0.19070630052954438 \n",
      "acc for optim= 0.1844409550572596\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.0055637238547205925\n",
      "Loss on test= 0.006913335062563419\n",
      "acc for Lsat= 0.10485328228196522 \n",
      "acc for Psat= 0.1459338989406132 \n",
      "acc for optim= 0.18061303389471062\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.005712870508432388\n",
      "Loss on test= 0.006777286529541016\n",
      "acc for Lsat= 0.1136342229966996 \n",
      "acc for Psat= 0.15148667208209313 \n",
      "acc for optim= 0.17964699138758225\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.005500745493918657\n",
      "Loss on test= 0.006577634252607822\n",
      "acc for Lsat= 0.10792397888754085 \n",
      "acc for Psat= 0.16253227266212422 \n",
      "acc for optim= 0.1803243535374546\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.005740318447351456\n",
      "Loss on test= 0.007139255758374929\n",
      "acc for Lsat= 0.13265557221795363 \n",
      "acc for Psat= 0.17779323579673695 \n",
      "acc for optim= 0.18119526913663297\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.005879143252968788\n",
      "Loss on test= 0.007387304678559303\n",
      "acc for Lsat= 0.10775860830068956 \n",
      "acc for Psat= 0.18504827595933346 \n",
      "acc for optim= 0.1833709545395765\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.005598361138254404\n",
      "Loss on test= 0.006460548844188452\n",
      "acc for Lsat= 0.11977441017116025 \n",
      "acc for Psat= 0.15269968011656404 \n",
      "acc for optim= 0.18203520058533113\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.005570619832724333\n",
      "Loss on test= 0.0066012851893901825\n",
      "acc for Lsat= 0.1215146221480068 \n",
      "acc for Psat= 0.17443276249960527 \n",
      "acc for optim= 0.18046371144196569\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.005584565922617912\n",
      "Loss on test= 0.006585852708667517\n",
      "acc for Lsat= 0.1069631014982627 \n",
      "acc for Psat= 0.14951013179027517 \n",
      "acc for optim= 0.187363336718959\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.005491218995302916\n",
      "Loss on test= 0.007188980467617512\n",
      "acc for Lsat= 0.11424478853587061 \n",
      "acc for Psat= 0.18157484186979894 \n",
      "acc for optim= 0.18708902532130564\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.005593331530690193\n",
      "Loss on test= 0.00697579188272357\n",
      "acc for Lsat= 0.10425908302528802 \n",
      "acc for Psat= 0.1567055587334294 \n",
      "acc for optim= 0.19223971825065106\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005744385067373514\n",
      "Loss on test= 0.00700993649661541\n",
      "acc for Lsat= 0.12259673216190217 \n",
      "acc for Psat= 0.17510168337911317 \n",
      "acc for optim= 0.1806429252936977\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.00576431630179286\n",
      "Loss on test= 0.00712122768163681\n",
      "acc for Lsat= 0.1154243383035046 \n",
      "acc for Psat= 0.1973774067804255 \n",
      "acc for optim= 0.1813314242002938\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.005605852697044611\n",
      "Loss on test= 0.007035084068775177\n",
      "acc for Lsat= 0.12167256527007683 \n",
      "acc for Psat= 0.17393161393890813 \n",
      "acc for optim= 0.18696162894814955\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.005581485107541084\n",
      "Loss on test= 0.007059082854539156\n",
      "acc for Lsat= 0.10931411377187893 \n",
      "acc for Psat= 0.18014496600065016 \n",
      "acc for optim= 0.18329615071407052\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.005545555613934994\n",
      "Loss on test= 0.007004174869507551\n",
      "acc for Lsat= 0.1107548303841975 \n",
      "acc for Psat= 0.17014069141068094 \n",
      "acc for optim= 0.1890254806983762\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.00551624083891511\n",
      "Loss on test= 0.006738712079823017\n",
      "acc for Lsat= 0.11892473309203647 \n",
      "acc for Psat= 0.15817688712519845 \n",
      "acc for optim= 0.17784811329368716\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.0055602132342755795\n",
      "Loss on test= 0.0068266731686890125\n",
      "acc for Lsat= 0.10341659468620716 \n",
      "acc for Psat= 0.16665708670916501 \n",
      "acc for optim= 0.17787584783729618\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.005522912833839655\n",
      "Loss on test= 0.006983231753110886\n",
      "acc for Lsat= 0.10815367687327297 \n",
      "acc for Psat= 0.20056353170169844 \n",
      "acc for optim= 0.182858883673042\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.0055662523955106735\n",
      "Loss on test= 0.0066946386359632015\n",
      "acc for Lsat= 0.1121045737333613 \n",
      "acc for Psat= 0.17431532967109478 \n",
      "acc for optim= 0.18026674234558437\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.0055314009077847\n",
      "Loss on test= 0.006746732164174318\n",
      "acc for Lsat= 0.10892684973884104 \n",
      "acc for Psat= 0.16262987058311212 \n",
      "acc for optim= 0.1846415758140014\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.005491567775607109\n",
      "Loss on test= 0.007107526063919067\n",
      "acc for Lsat= 0.11188284598599263 \n",
      "acc for Psat= 0.1690365049916845 \n",
      "acc for optim= 0.17992744477984113\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.005571664310991764\n",
      "Loss on test= 0.006593053694814444\n",
      "acc for Lsat= 0.09888099923036124 \n",
      "acc for Psat= 0.13769649624744587 \n",
      "acc for optim= 0.18019160559492162\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.005459584295749664\n",
      "Loss on test= 0.006804545409977436\n",
      "acc for Lsat= 0.11355350742520091 \n",
      "acc for Psat= 0.1520742338844512 \n",
      "acc for optim= 0.18084025425567332\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.005537789314985275\n",
      "Loss on test= 0.006977562326937914\n",
      "acc for Lsat= 0.11600838942017985 \n",
      "acc for Psat= 0.18057529714310108 \n",
      "acc for optim= 0.178484019033636\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.005436124745756388\n",
      "Loss on test= 0.006718051619827747\n",
      "acc for Lsat= 0.11716331329670218 \n",
      "acc for Psat= 0.1713291587823831 \n",
      "acc for optim= 0.18077319561160873\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.005430768243968487\n",
      "Loss on test= 0.007199670188128948\n",
      "acc for Lsat= 0.10820276256138617 \n",
      "acc for Psat= 0.17291824201920708 \n",
      "acc for optim= 0.17965818203157216\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.005681146867573261\n",
      "Loss on test= 0.006650085095316172\n",
      "acc for Lsat= 0.12978029758682094 \n",
      "acc for Psat= 0.15231406912563536 \n",
      "acc for optim= 0.17909210729762767\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.005553927272558212\n",
      "Loss on test= 0.006794990040361881\n",
      "acc for Lsat= 0.11679688212294619 \n",
      "acc for Psat= 0.14699477672036518 \n",
      "acc for optim= 0.18141729629703174\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.005625790450721979\n",
      "Loss on test= 0.006800624076277018\n",
      "acc for Lsat= 0.10635228274544273 \n",
      "acc for Psat= 0.1663606408101505 \n",
      "acc for optim= 0.1794574613972194\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.005571654066443443\n",
      "Loss on test= 0.007084836717694998\n",
      "acc for Lsat= 0.10985316701250691 \n",
      "acc for Psat= 0.1680357839308075 \n",
      "acc for optim= 0.1830754734841616\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.005616680718958378\n",
      "Loss on test= 0.006958469282835722\n",
      "acc for Lsat= 0.10977149510431813 \n",
      "acc for Psat= 0.20318488267681412 \n",
      "acc for optim= 0.1782867357436083\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.00573252746835351\n",
      "Loss on test= 0.006832628510892391\n",
      "acc for Lsat= 0.10715987762090957 \n",
      "acc for Psat= 0.16239240564519186 \n",
      "acc for optim= 0.1823680205026805\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.005499474238604307\n",
      "Loss on test= 0.006591777317225933\n",
      "acc for Lsat= 0.10918270805268548 \n",
      "acc for Psat= 0.14831583508576668 \n",
      "acc for optim= 0.17954267267093718\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.0053621199913322926\n",
      "Loss on test= 0.006485921796411276\n",
      "acc for Lsat= 0.1061243827300525 \n",
      "acc for Psat= 0.16285573653245544 \n",
      "acc for optim= 0.1801962427774482\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005464655812829733\n",
      "Loss on test= 0.006319024134427309\n",
      "acc for Lsat= 0.11062753102679208 \n",
      "acc for Psat= 0.15303642661318598 \n",
      "acc for optim= 0.1803508147497416\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.005428312812000513\n",
      "Loss on test= 0.007309474516659975\n",
      "acc for Lsat= 0.11422965753568073 \n",
      "acc for Psat= 0.19614894473026553 \n",
      "acc for optim= 0.17509565290360163\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.005555047187954187\n",
      "Loss on test= 0.006917200516909361\n",
      "acc for Lsat= 0.11907155111190593 \n",
      "acc for Psat= 0.1511164213817038 \n",
      "acc for optim= 0.17827965462657705\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.005586626008152962\n",
      "Loss on test= 0.0068535893224179745\n",
      "acc for Lsat= 0.10844290505347827 \n",
      "acc for Psat= 0.14185427003138937 \n",
      "acc for optim= 0.17950237247203257\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.005588314961642027\n",
      "Loss on test= 0.006836114916950464\n",
      "acc for Lsat= 0.10516277852553144 \n",
      "acc for Psat= 0.16485533952702 \n",
      "acc for optim= 0.18585611730530807\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.005397094879299402\n",
      "Loss on test= 0.006742698140442371\n",
      "acc for Lsat= 0.10946015309879864 \n",
      "acc for Psat= 0.16581340723299748 \n",
      "acc for optim= 0.1831793423908813\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.005493359174579382\n",
      "Loss on test= 0.006537658628076315\n",
      "acc for Lsat= 0.1037402106349701 \n",
      "acc for Psat= 0.16068907888429013 \n",
      "acc for optim= 0.17998747680512434\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.005533540155738592\n",
      "Loss on test= 0.0067291827872395515\n",
      "acc for Lsat= 0.10281920686267423 \n",
      "acc for Psat= 0.16711800622539846 \n",
      "acc for optim= 0.17591350821296786\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.005679302383214235\n",
      "Loss on test= 0.006889032199978828\n",
      "acc for Lsat= 0.10435785895419572 \n",
      "acc for Psat= 0.16398513126281417 \n",
      "acc for optim= 0.1811517809885388\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.005405702628195286\n",
      "Loss on test= 0.006978610996156931\n",
      "acc for Lsat= 0.10905443900156643 \n",
      "acc for Psat= 0.19358631055542533 \n",
      "acc for optim= 0.1782317908844168\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.005550590343773365\n",
      "Loss on test= 0.0066445693373680115\n",
      "acc for Lsat= 0.1084586018417188 \n",
      "acc for Psat= 0.16493288881335771 \n",
      "acc for optim= 0.1786112306994304\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.005662059411406517\n",
      "Loss on test= 0.006828384008258581\n",
      "acc for Lsat= 0.1074947537147366 \n",
      "acc for Psat= 0.17999480570909548 \n",
      "acc for optim= 0.17930593461288308\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.005680289585143328\n",
      "Loss on test= 0.007372143212705851\n",
      "acc for Lsat= 0.16074243459710535 \n",
      "acc for Psat= 0.1589719461260609 \n",
      "acc for optim= 0.18344244684448238\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.005890883971005678\n",
      "Loss on test= 0.007034914568066597\n",
      "acc for Lsat= 0.1156585073609873 \n",
      "acc for Psat= 0.1834340657959409 \n",
      "acc for optim= 0.18260354211717542\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.005457297898828983\n",
      "Loss on test= 0.006891071796417236\n",
      "acc for Lsat= 0.1146927679807492 \n",
      "acc for Psat= 0.1722224333038006 \n",
      "acc for optim= 0.1800760266857184\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.005644607823342085\n",
      "Loss on test= 0.006885550916194916\n",
      "acc for Lsat= 0.10812272364448192 \n",
      "acc for Psat= 0.15786802417652152 \n",
      "acc for optim= 0.1812289409811124\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.005656920839101076\n",
      "Loss on test= 0.006960361264646053\n",
      "acc for Lsat= 0.11873611875922212 \n",
      "acc for Psat= 0.16716079453338328 \n",
      "acc for optim= 0.17920992615307949\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.005627315491437912\n",
      "Loss on test= 0.006705736741423607\n",
      "acc for Lsat= 0.11626435550263252 \n",
      "acc for Psat= 0.1457507983841178 \n",
      "acc for optim= 0.18467768069397583\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.005456272978335619\n",
      "Loss on test= 0.007267363835126162\n",
      "acc for Lsat= 0.1178474190571767 \n",
      "acc for Psat= 0.17547528775509597 \n",
      "acc for optim= 0.18002420682097256\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.005529065616428852\n",
      "Loss on test= 0.006623302586376667\n",
      "acc for Lsat= 0.11262645291751412 \n",
      "acc for Psat= 0.16067217411300344 \n",
      "acc for optim= 0.18177143612622268\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.005421570502221584\n",
      "Loss on test= 0.00696173869073391\n",
      "acc for Lsat= 0.10871195098998153 \n",
      "acc for Psat= 0.17709271343601113 \n",
      "acc for optim= 0.17601122751806839\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.005512289237231016\n",
      "Loss on test= 0.006612233817577362\n",
      "acc for Lsat= 0.10208070435603715 \n",
      "acc for Psat= 0.16026339238286144 \n",
      "acc for optim= 0.17874469969162443\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.005519450642168522\n",
      "Loss on test= 0.006944280117750168\n",
      "acc for Lsat= 0.10314100537623351 \n",
      "acc for Psat= 0.18810679880285486 \n",
      "acc for optim= 0.1772842460584727\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.005380226764827967\n",
      "Loss on test= 0.006837690249085426\n",
      "acc for Lsat= 0.10446619700756068 \n",
      "acc for Psat= 0.15397040409791501 \n",
      "acc for optim= 0.18338570533214316\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.005731067154556513\n",
      "Loss on test= 0.006872395984828472\n",
      "acc for Lsat= 0.1096428119963339 \n",
      "acc for Psat= 0.17945061500363776 \n",
      "acc for optim= 0.1792493467373542\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.005603546276688576\n",
      "Loss on test= 0.006742071360349655\n",
      "acc for Lsat= 0.1228396907160975 \n",
      "acc for Psat= 0.15008089209535486 \n",
      "acc for optim= 0.1802063759147328\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.0053098248317837715\n",
      "Loss on test= 0.006675696931779385\n",
      "acc for Lsat= 0.10428446616453978 \n",
      "acc for Psat= 0.15756004406874716 \n",
      "acc for optim= 0.1799511922319554\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.005295088980346918\n",
      "Loss on test= 0.006282298360019922\n",
      "acc for Lsat= 0.1054907715383829 \n",
      "acc for Psat= 0.14794271863052386 \n",
      "acc for optim= 0.17938310750105302\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.005390718579292297\n",
      "Loss on test= 0.007108430378139019\n",
      "acc for Lsat= 0.12700777289157142 \n",
      "acc for Psat= 0.19398127181842495 \n",
      "acc for optim= 0.1802489273171444\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.005424670409411192\n",
      "Loss on test= 0.00698649138212204\n",
      "acc for Lsat= 0.1034017048728561 \n",
      "acc for Psat= 0.1637947357997512 \n",
      "acc for optim= 0.1907836912243904\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.005504639353603125\n",
      "Loss on test= 0.006781116593629122\n",
      "acc for Lsat= 0.11880022217440922 \n",
      "acc for Psat= 0.17150657611587983 \n",
      "acc for optim= 0.1831593586241463\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005615497939288616\n",
      "Loss on test= 0.006947891786694527\n",
      "acc for Lsat= 0.12147760242419896 \n",
      "acc for Psat= 0.155799948309888 \n",
      "acc for optim= 0.1795780238293495\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.005631413776427507\n",
      "Loss on test= 0.006628940347582102\n",
      "acc for Lsat= 0.09850158220374519 \n",
      "acc for Psat= 0.16217107448962476 \n",
      "acc for optim= 0.1785904849569527\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005413574166595936\n",
      "Loss on test= 0.006655220873653889\n",
      "acc for Lsat= 0.11081171713846522 \n",
      "acc for Psat= 0.1606369276906244 \n",
      "acc for optim= 0.17529899556118195\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.0056017362512648106\n",
      "Loss on test= 0.0066679297015070915\n",
      "acc for Lsat= 0.11399494443144617 \n",
      "acc for Psat= 0.13965670533759073 \n",
      "acc for optim= 0.1805983888275109\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.00543558644130826\n",
      "Loss on test= 0.006411093752831221\n",
      "acc for Lsat= 0.11307733439871054 \n",
      "acc for Psat= 0.1673281381863981 \n",
      "acc for optim= 0.18163228868660233\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.005395081359893084\n",
      "Loss on test= 0.006811473984271288\n",
      "acc for Lsat= 0.11704093407535913 \n",
      "acc for Psat= 0.14518862537924843 \n",
      "acc for optim= 0.1776931452423137\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.005475207697600126\n",
      "Loss on test= 0.0068166786804795265\n",
      "acc for Lsat= 0.11238930485037477 \n",
      "acc for Psat= 0.1625789210980607 \n",
      "acc for optim= 0.18842273277422883\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.005652100779116154\n",
      "Loss on test= 0.006753919180482626\n",
      "acc for Lsat= 0.11467730097010152 \n",
      "acc for Psat= 0.1713927928451724 \n",
      "acc for optim= 0.17938539045398766\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.005409770179539919\n",
      "Loss on test= 0.006475871428847313\n",
      "acc for Lsat= 0.10128260344764213 \n",
      "acc for Psat= 0.14211148201849103 \n",
      "acc for optim= 0.18325880278968504\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005401685833930969\n",
      "Loss on test= 0.006764623802155256\n",
      "acc for Lsat= 0.10090716717270364 \n",
      "acc for Psat= 0.1447672877926576 \n",
      "acc for optim= 0.1787834659412142\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.005445017013698816\n",
      "Loss on test= 0.006411103531718254\n",
      "acc for Lsat= 0.11094455883938133 \n",
      "acc for Psat= 0.14816833600186352 \n",
      "acc for optim= 0.18176952716060663\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.005451831966638565\n",
      "Loss on test= 0.006534902844578028\n",
      "acc for Lsat= 0.10910186215649545 \n",
      "acc for Psat= 0.15401144888297447 \n",
      "acc for optim= 0.17919231011753278\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.005336645059287548\n",
      "Loss on test= 0.006526078097522259\n",
      "acc for Lsat= 0.10910380630279227 \n",
      "acc for Psat= 0.14477915229194016 \n",
      "acc for optim= 0.1765096352881645\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.005348798353224993\n",
      "Loss on test= 0.006743754725903273\n",
      "acc for Lsat= 0.11192630782574811 \n",
      "acc for Psat= 0.19307460146838157 \n",
      "acc for optim= 0.1818829711647423\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.0056078447960317135\n",
      "Loss on test= 0.006901554763317108\n",
      "acc for Lsat= 0.11999291939109508 \n",
      "acc for Psat= 0.1562163406472521 \n",
      "acc for optim= 0.17986892749546757\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.00571472430601716\n",
      "Loss on test= 0.006608054041862488\n",
      "acc for Lsat= 0.11524297796033253 \n",
      "acc for Psat= 0.1537796285969356 \n",
      "acc for optim= 0.17577084305427176\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.005531003698706627\n",
      "Loss on test= 0.006764284800738096\n",
      "acc for Lsat= 0.10716054894598799 \n",
      "acc for Psat= 0.14929460076461043 \n",
      "acc for optim= 0.19209064189130545\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.005531901493668556\n",
      "Loss on test= 0.006744427606463432\n",
      "acc for Lsat= 0.10355513024291754 \n",
      "acc for Psat= 0.15971818363972046 \n",
      "acc for optim= 0.18337066328594293\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005404286552220583\n",
      "Loss on test= 0.0068954890593886375\n",
      "acc for Lsat= 0.11615363624681581 \n",
      "acc for Psat= 0.17677424985378967 \n",
      "acc for optim= 0.1777606845009015\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.005447903648018837\n",
      "Loss on test= 0.006797798443585634\n",
      "acc for Lsat= 0.10347512297340546 \n",
      "acc for Psat= 0.1636949931970149 \n",
      "acc for optim= 0.18248261847595523\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.0054264971986413\n",
      "Loss on test= 0.0065436288714408875\n",
      "acc for Lsat= 0.10365328641251541 \n",
      "acc for Psat= 0.1466039620220702 \n",
      "acc for optim= 0.18682214650634152\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.005401692818850279\n",
      "Loss on test= 0.006631199736148119\n",
      "acc for Lsat= 0.10618772756051102 \n",
      "acc for Psat= 0.16022427831744976 \n",
      "acc for optim= 0.18302272431606684\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.005381682422012091\n",
      "Loss on test= 0.006590719800442457\n",
      "acc for Lsat= 0.09493808237766643 \n",
      "acc for Psat= 0.1597983701028932 \n",
      "acc for optim= 0.18526118184485854\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.00528611708432436\n",
      "Loss on test= 0.006679054349660873\n",
      "acc for Lsat= 0.12649278629199928 \n",
      "acc for Psat= 0.15485539389671454 \n",
      "acc for optim= 0.17815786469283332\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.0053293402306735516\n",
      "Loss on test= 0.006622420158237219\n",
      "acc for Lsat= 0.10155139853009747 \n",
      "acc for Psat= 0.15463156977352197 \n",
      "acc for optim= 0.17708677404860626\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.0055647133849561214\n",
      "Loss on test= 0.006499545183032751\n",
      "acc for Lsat= 0.1100042503070703 \n",
      "acc for Psat= 0.14789691045351336 \n",
      "acc for optim= 0.18220492278900613\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.005416743457317352\n",
      "Loss on test= 0.006607778370380402\n",
      "acc for Lsat= 0.11494466853545836 \n",
      "acc for Psat= 0.15615887372070966 \n",
      "acc for optim= 0.1795940344419324\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.005344314035028219\n",
      "Loss on test= 0.006927614100277424\n",
      "acc for Lsat= 0.12407626278306723 \n",
      "acc for Psat= 0.17917864731749136 \n",
      "acc for optim= 0.17957790329740886\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.005517822690308094\n",
      "Loss on test= 0.006459513213485479\n",
      "acc for Lsat= 0.0997754391726237 \n",
      "acc for Psat= 0.14568656377672892 \n",
      "acc for optim= 0.17506322528896742\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.005468939896672964\n",
      "Loss on test= 0.0065749939531087875\n",
      "acc for Lsat= 0.10929143382118373 \n",
      "acc for Psat= 0.1394268328201449 \n",
      "acc for optim= 0.18013881982423718\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.005522793158888817\n",
      "Loss on test= 0.006531469523906708\n",
      "acc for Lsat= 0.12175429227598314 \n",
      "acc for Psat= 0.14468488713877425 \n",
      "acc for optim= 0.1804478372930159\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.005540148820728064\n",
      "Loss on test= 0.006822850089520216\n",
      "acc for Lsat= 0.10473962912785921 \n",
      "acc for Psat= 0.17245227863394255 \n",
      "acc for optim= 0.1828371470363817\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.005638455506414175\n",
      "Loss on test= 0.006825701799243689\n",
      "acc for Lsat= 0.11437277088574578 \n",
      "acc for Psat= 0.16285387517427807 \n",
      "acc for optim= 0.18010148111578608\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.005477886646986008\n",
      "Loss on test= 0.006813946645706892\n",
      "acc for Lsat= 0.11088285845122496 \n",
      "acc for Psat= 0.14374541505948574 \n",
      "acc for optim= 0.1818631652827576\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.0054429927840828896\n",
      "Loss on test= 0.006940457504242659\n",
      "acc for Lsat= 0.11184294219173033 \n",
      "acc for Psat= 0.1943462199289226 \n",
      "acc for optim= 0.179740072404014\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.00549710588529706\n",
      "Loss on test= 0.006668506655842066\n",
      "acc for Lsat= 0.10640514803260984 \n",
      "acc for Psat= 0.15916874993520133 \n",
      "acc for optim= 0.18890138746497245\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.005527259316295385\n",
      "Loss on test= 0.00689472071826458\n",
      "acc for Lsat= 0.11491699896332402 \n",
      "acc for Psat= 0.1663414045021479 \n",
      "acc for optim= 0.18334016621362959\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005689138080924749\n",
      "Loss on test= 0.007300751283764839\n",
      "acc for Lsat= 0.1336428126048083 \n",
      "acc for Psat= 0.17507045979210809 \n",
      "acc for optim= 0.18237360828838112\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.0056433468125760555\n",
      "Loss on test= 0.007308903615921736\n",
      "acc for Lsat= 0.11213122032288969 \n",
      "acc for Psat= 0.1897377460680562 \n",
      "acc for optim= 0.1925008982080554\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.005475489888340235\n",
      "Loss on test= 0.006630513351410627\n",
      "acc for Lsat= 0.10348738206517442 \n",
      "acc for Psat= 0.14225870635631066 \n",
      "acc for optim= 0.19666554815784046\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.00539070600643754\n",
      "Loss on test= 0.0065306974574923515\n",
      "acc for Lsat= 0.10343399614164908 \n",
      "acc for Psat= 0.15555621756897922 \n",
      "acc for optim= 0.18445588473755256\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.005237808916717768\n",
      "Loss on test= 0.0067025115713477135\n",
      "acc for Lsat= 0.1053120543267043 \n",
      "acc for Psat= 0.13413823407687675 \n",
      "acc for optim= 0.18108451130408226\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.005390208214521408\n",
      "Loss on test= 0.006616608705371618\n",
      "acc for Lsat= 0.10693475637865935 \n",
      "acc for Psat= 0.16230447701712586 \n",
      "acc for optim= 0.1819977575426959\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.005329563282430172\n",
      "Loss on test= 0.006581869442015886\n",
      "acc for Lsat= 0.10023436484619663 \n",
      "acc for Psat= 0.14835496539937496 \n",
      "acc for optim= 0.18204877438138528\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.005467512644827366\n",
      "Loss on test= 0.006520901340991259\n",
      "acc for Lsat= 0.10883658081393212 \n",
      "acc for Psat= 0.1398440089303492 \n",
      "acc for optim= 0.17820023185265962\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.005321982782334089\n",
      "Loss on test= 0.006667416542768478\n",
      "acc for Lsat= 0.10157881361374166 \n",
      "acc for Psat= 0.16226188816880174 \n",
      "acc for optim= 0.1815179907635079\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.00536178657785058\n",
      "Loss on test= 0.006591995246708393\n",
      "acc for Lsat= 0.10223966454312275 \n",
      "acc for Psat= 0.15382600494194776 \n",
      "acc for optim= 0.18281855988725265\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.00543587701395154\n",
      "Loss on test= 0.006562362425029278\n",
      "acc for Lsat= 0.10141681953452486 \n",
      "acc for Psat= 0.1554658185517395 \n",
      "acc for optim= 0.1791471228881238\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.005412737373262644\n",
      "Loss on test= 0.006822863128036261\n",
      "acc for Lsat= 0.11651767692426408 \n",
      "acc for Psat= 0.14531953213323456 \n",
      "acc for optim= 0.18500433001915823\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.005507952068001032\n",
      "Loss on test= 0.006714130751788616\n",
      "acc for Lsat= 0.09871670341050737 \n",
      "acc for Psat= 0.15929477005062614 \n",
      "acc for optim= 0.17995761613368616\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005312488880008459\n",
      "Loss on test= 0.0065697431564331055\n",
      "acc for Lsat= 0.09920421317521097 \n",
      "acc for Psat= 0.15730294471015097 \n",
      "acc for optim= 0.17857157122017345\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.005276549141854048\n",
      "Loss on test= 0.0065790931694209576\n",
      "acc for Lsat= 0.10835381964347648 \n",
      "acc for Psat= 0.15229034942033626 \n",
      "acc for optim= 0.18752512038194918\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.005369293969124556\n",
      "Loss on test= 0.006694864481687546\n",
      "acc for Lsat= 0.10502632394520726 \n",
      "acc for Psat= 0.13859393705865228 \n",
      "acc for optim= 0.1805316562831895\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.005425600800663233\n",
      "Loss on test= 0.006843169219791889\n",
      "acc for Lsat= 0.12026040818499176 \n",
      "acc for Psat= 0.17017597551819416 \n",
      "acc for optim= 0.1802112282426065\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.005366350058466196\n",
      "Loss on test= 0.006729118525981903\n",
      "acc for Lsat= 0.09914744945772758 \n",
      "acc for Psat= 0.15298999070521835 \n",
      "acc for optim= 0.1878275834198969\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.005482960492372513\n",
      "Loss on test= 0.0069124894216656685\n",
      "acc for Lsat= 0.12145403870090377 \n",
      "acc for Psat= 0.15027919028452252 \n",
      "acc for optim= 0.19164746230652216\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.005405712872743607\n",
      "Loss on test= 0.006835289765149355\n",
      "acc for Lsat= 0.12023864635591815 \n",
      "acc for Psat= 0.16242279121188158 \n",
      "acc for optim= 0.18136959442828712\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.0054488047026097775\n",
      "Loss on test= 0.006698349956423044\n",
      "acc for Lsat= 0.10581172238891816 \n",
      "acc for Psat= 0.14459309748899368 \n",
      "acc for optim= 0.18085641185973292\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.005450848024338484\n",
      "Loss on test= 0.00647510914131999\n",
      "acc for Lsat= 0.108635699898563 \n",
      "acc for Psat= 0.13976616192155997 \n",
      "acc for optim= 0.17743434681464398\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.005476510617882013\n",
      "Loss on test= 0.006741140969097614\n",
      "acc for Lsat= 0.10515060415567663 \n",
      "acc for Psat= 0.14905680669058663 \n",
      "acc for optim= 0.180621208417555\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.005415104329586029\n",
      "Loss on test= 0.00673692487180233\n",
      "acc for Lsat= 0.10273861716121098 \n",
      "acc for Psat= 0.14151254249264714 \n",
      "acc for optim= 0.18160742448860737\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.005396412219852209\n",
      "Loss on test= 0.006777695845812559\n",
      "acc for Lsat= 0.1088551132535842 \n",
      "acc for Psat= 0.17204629335228183 \n",
      "acc for optim= 0.1796990479857856\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.005283928941935301\n",
      "Loss on test= 0.006681916769593954\n",
      "acc for Lsat= 0.11474102225295954 \n",
      "acc for Psat= 0.15023505374896606 \n",
      "acc for optim= 0.1914383479405031\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.005342709831893444\n",
      "Loss on test= 0.006678298581391573\n",
      "acc for Lsat= 0.10163342470220438 \n",
      "acc for Psat= 0.14204532018256205 \n",
      "acc for optim= 0.19164596816502838\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005450497381389141\n",
      "Loss on test= 0.006782038137316704\n",
      "acc for Lsat= 0.10230166207003168 \n",
      "acc for Psat= 0.14819599672741665 \n",
      "acc for optim= 0.18055566634221404\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.005518879741430283\n",
      "Loss on test= 0.006452615838497877\n",
      "acc for Lsat= 0.10424200752822799 \n",
      "acc for Psat= 0.14496694749391895 \n",
      "acc for optim= 0.18034381618801146\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.0054438174702227116\n",
      "Loss on test= 0.006666860543191433\n",
      "acc for Lsat= 0.10031651676183322 \n",
      "acc for Psat= 0.16642243657210004 \n",
      "acc for optim= 0.17932085117334626\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005327800288796425\n",
      "Loss on test= 0.006641523912549019\n",
      "acc for Lsat= 0.10765473652773418 \n",
      "acc for Psat= 0.15503294131839712 \n",
      "acc for optim= 0.17751011437212583\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005346694961190224\n",
      "Loss on test= 0.006583493668586016\n",
      "acc for Lsat= 0.11161428397207528 \n",
      "acc for Psat= 0.1580882956648664 \n",
      "acc for optim= 0.17930050350716212\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.005351867061108351\n",
      "Loss on test= 0.006624786648899317\n",
      "acc for Lsat= 0.10654600170955991 \n",
      "acc for Psat= 0.14359351723652328 \n",
      "acc for optim= 0.1792281232109589\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.005353845190256834\n",
      "Loss on test= 0.006610241252928972\n",
      "acc for Lsat= 0.09875617564832306 \n",
      "acc for Psat= 0.15101574972957038 \n",
      "acc for optim= 0.18268463909697782\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.00539468415081501\n",
      "Loss on test= 0.006321537774056196\n",
      "acc for Lsat= 0.10277779112289569 \n",
      "acc for Psat= 0.1450944289935177 \n",
      "acc for optim= 0.18555775666361632\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.00541304424405098\n",
      "Loss on test= 0.00643807090818882\n",
      "acc for Lsat= 0.10273857478042939 \n",
      "acc for Psat= 0.14371777054632706 \n",
      "acc for optim= 0.1784712945453656\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.005259338766336441\n",
      "Loss on test= 0.0064208670519292355\n",
      "acc for Lsat= 0.10012585185629448 \n",
      "acc for Psat= 0.14661245818589688 \n",
      "acc for optim= 0.18638980712519795\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005354202352464199\n",
      "Loss on test= 0.006541160400956869\n",
      "acc for Lsat= 0.10780599456169561 \n",
      "acc for Psat= 0.1485803446457548 \n",
      "acc for optim= 0.1796536517512003\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.005458729341626167\n",
      "Loss on test= 0.006282937712967396\n",
      "acc for Lsat= 0.1068291374167775 \n",
      "acc for Psat= 0.14815552258772408 \n",
      "acc for optim= 0.17990566650110554\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.005322216544300318\n",
      "Loss on test= 0.00663027074187994\n",
      "acc for Lsat= 0.10682475969303129 \n",
      "acc for Psat= 0.1693484793281088 \n",
      "acc for optim= 0.17937110749079618\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.005428988952189684\n",
      "Loss on test= 0.006769300438463688\n",
      "acc for Lsat= 0.10577507900558664 \n",
      "acc for Psat= 0.1591099575125554 \n",
      "acc for optim= 0.1878729502636447\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.005266334395855665\n",
      "Loss on test= 0.006393722724169493\n",
      "acc for Lsat= 0.12622115904751635 \n",
      "acc for Psat= 0.14419655812938847 \n",
      "acc for optim= 0.17914257639967143\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.005366021767258644\n",
      "Loss on test= 0.006404434330761433\n",
      "acc for Lsat= 0.10576132067866195 \n",
      "acc for Psat= 0.13676604165772693 \n",
      "acc for optim= 0.17973262610757956\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.00542069599032402\n",
      "Loss on test= 0.007135970983654261\n",
      "acc for Lsat= 0.1092651145781683 \n",
      "acc for Psat= 0.19307720455509372 \n",
      "acc for optim= 0.18333708492128928\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.0053751119412481785\n",
      "Loss on test= 0.006412697955965996\n",
      "acc for Lsat= 0.10478172652122068 \n",
      "acc for Psat= 0.1389211211770433 \n",
      "acc for optim= 0.18187020494007958\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.005299607757478952\n",
      "Loss on test= 0.006647186353802681\n",
      "acc for Lsat= 0.10343344601966925 \n",
      "acc for Psat= 0.16208752002392038 \n",
      "acc for optim= 0.1815668386085678\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.005358604714274406\n",
      "Loss on test= 0.006616129539906979\n",
      "acc for Lsat= 0.11145409805593207 \n",
      "acc for Psat= 0.1607018095288564 \n",
      "acc for optim= 0.18081007791027554\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.005429750308394432\n",
      "Loss on test= 0.006874798331409693\n",
      "acc for Lsat= 0.12838959826645757 \n",
      "acc for Psat= 0.154973224864571 \n",
      "acc for optim= 0.18052717589386236\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.005415877792984247\n",
      "Loss on test= 0.0068046934902668\n",
      "acc for Lsat= 0.11229584503223884 \n",
      "acc for Psat= 0.16519187406339444 \n",
      "acc for optim= 0.1862176508484727\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.0053200386464595795\n",
      "Loss on test= 0.006390540860593319\n",
      "acc for Lsat= 0.10946532786274966 \n",
      "acc for Psat= 0.14833038790896574 \n",
      "acc for optim= 0.1794631789443146\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.005260820966213942\n",
      "Loss on test= 0.0064739142544567585\n",
      "acc for Lsat= 0.09706706555565738 \n",
      "acc for Psat= 0.14258051027521818 \n",
      "acc for optim= 0.18237543875049497\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.005157729145139456\n",
      "Loss on test= 0.006309774238616228\n",
      "acc for Lsat= 0.09901010764153054 \n",
      "acc for Psat= 0.1504863366770414 \n",
      "acc for optim= 0.18250403527044173\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.005345899611711502\n",
      "Loss on test= 0.0065590133890509605\n",
      "acc for Lsat= 0.1004128060985012 \n",
      "acc for Psat= 0.1546803670638764 \n",
      "acc for optim= 0.18710117295936593\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005370409693568945\n",
      "Loss on test= 0.00643862085416913\n",
      "acc for Lsat= 0.10140152024227113 \n",
      "acc for Psat= 0.1486046250376259 \n",
      "acc for optim= 0.17873987307492015\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.005263540893793106\n",
      "Loss on test= 0.006395108066499233\n",
      "acc for Lsat= 0.10767621280605011 \n",
      "acc for Psat= 0.1576938319760941 \n",
      "acc for optim= 0.18106965172596942\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.005287792067974806\n",
      "Loss on test= 0.00651312991976738\n",
      "acc for Lsat= 0.11501103010566628 \n",
      "acc for Psat= 0.1419280573083253 \n",
      "acc for optim= 0.1849329078121062\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.0051909214816987514\n",
      "Loss on test= 0.006842891685664654\n",
      "acc for Lsat= 0.103144077912008 \n",
      "acc for Psat= 0.16025315051727965 \n",
      "acc for optim= 0.1865273643733589\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.005216347519308329\n",
      "Loss on test= 0.006441470701247454\n",
      "acc for Lsat= 0.1086347346277467 \n",
      "acc for Psat= 0.14827889554883744 \n",
      "acc for optim= 0.18210007199003658\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.005450695753097534\n",
      "Loss on test= 0.006566294934600592\n",
      "acc for Lsat= 0.11580593087804832 \n",
      "acc for Psat= 0.16450038621110866 \n",
      "acc for optim= 0.18267526509102813\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.005284149199724197\n",
      "Loss on test= 0.0067634969018399715\n",
      "acc for Lsat= 0.10450344987790182 \n",
      "acc for Psat= 0.18331500183184463 \n",
      "acc for optim= 0.18558366192863449\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.005150726530700922\n",
      "Loss on test= 0.006499916315078735\n",
      "acc for Lsat= 0.10260816069736343 \n",
      "acc for Psat= 0.13408346612885833 \n",
      "acc for optim= 0.17790232791240496\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.005222485400736332\n",
      "Loss on test= 0.006441506091505289\n",
      "acc for Lsat= 0.10058183003747144 \n",
      "acc for Psat= 0.14374561592263194 \n",
      "acc for optim= 0.17702220772588514\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.005195921286940575\n",
      "Loss on test= 0.006553946528583765\n",
      "acc for Lsat= 0.10902910350272872 \n",
      "acc for Psat= 0.13693330159141034 \n",
      "acc for optim= 0.17991124920160007\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.005365703254938126\n",
      "Loss on test= 0.006312877871096134\n",
      "acc for Lsat= 0.10390883368244111 \n",
      "acc for Psat= 0.1372349081677778 \n",
      "acc for optim= 0.17749025637356902\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.005289904307574034\n",
      "Loss on test= 0.006794992368668318\n",
      "acc for Lsat= 0.1236935432998753 \n",
      "acc for Psat= 0.14259236662513325 \n",
      "acc for optim= 0.18403202923710105\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.005427930969744921\n",
      "Loss on test= 0.006417521741241217\n",
      "acc for Lsat= 0.0988060343667245 \n",
      "acc for Psat= 0.1544428210666386 \n",
      "acc for optim= 0.17673162567489026\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.005197667982429266\n",
      "Loss on test= 0.0062408181838691235\n",
      "acc for Lsat= 0.10466104193796669 \n",
      "acc for Psat= 0.15227666421894873 \n",
      "acc for optim= 0.18415695277006897\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.005086949560791254\n",
      "Loss on test= 0.006488657556474209\n",
      "acc for Lsat= 0.11854750612415169 \n",
      "acc for Psat= 0.14691076833627745 \n",
      "acc for optim= 0.1814361648910169\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.005394525360316038\n",
      "Loss on test= 0.006680609658360481\n",
      "acc for Lsat= 0.10435147145403174 \n",
      "acc for Psat= 0.1594215253732998 \n",
      "acc for optim= 0.18489649910633169\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.005388009361922741\n",
      "Loss on test= 0.006391096394509077\n",
      "acc for Lsat= 0.10153821078386721 \n",
      "acc for Psat= 0.14574495316363126 \n",
      "acc for optim= 0.17532583884029598\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.005318290088325739\n",
      "Loss on test= 0.006219317205250263\n",
      "acc for Lsat= 0.10445598633865498 \n",
      "acc for Psat= 0.1448335568675985 \n",
      "acc for optim= 0.17643229439311875\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.005367425736039877\n",
      "Loss on test= 0.0064480905421078205\n",
      "acc for Lsat= 0.1193656254539304 \n",
      "acc for Psat= 0.1334178087787665 \n",
      "acc for optim= 0.1817250183061382\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.005296061281114817\n",
      "Loss on test= 0.006109931506216526\n",
      "acc for Lsat= 0.09442743522664092 \n",
      "acc for Psat= 0.1473528838494629 \n",
      "acc for optim= 0.18015087801118293\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.005225127097219229\n",
      "Loss on test= 0.006760176736861467\n",
      "acc for Lsat= 0.11650890396511485 \n",
      "acc for Psat= 0.143975390799283 \n",
      "acc for optim= 0.1772484321724757\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.005438303109258413\n",
      "Loss on test= 0.006447901017963886\n",
      "acc for Lsat= 0.10720830965913813 \n",
      "acc for Psat= 0.15800192415037992 \n",
      "acc for optim= 0.17517528495109463\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005192113108932972\n",
      "Loss on test= 0.006211875472217798\n",
      "acc for Lsat= 0.09446152710222884 \n",
      "acc for Psat= 0.13866922419254332 \n",
      "acc for optim= 0.18092061675928858\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.005234759300947189\n",
      "Loss on test= 0.0064988876692950726\n",
      "acc for Lsat= 0.10911514127469304 \n",
      "acc for Psat= 0.17649566860298463 \n",
      "acc for optim= 0.18020104315537783\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.005309368949383497\n",
      "Loss on test= 0.006530210841447115\n",
      "acc for Lsat= 0.10525631445639069 \n",
      "acc for Psat= 0.14258873467017996 \n",
      "acc for optim= 0.17971505592789538\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.005148844327777624\n",
      "Loss on test= 0.006454349961131811\n",
      "acc for Lsat= 0.11002102302992736 \n",
      "acc for Psat= 0.14371151578194946 \n",
      "acc for optim= 0.17883719440283743\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.005132400896400213\n",
      "Loss on test= 0.0062814136035740376\n",
      "acc for Lsat= 0.1179159288786232 \n",
      "acc for Psat= 0.13519772373134353 \n",
      "acc for optim= 0.17911023354630545\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.005218180827796459\n",
      "Loss on test= 0.006352700293064117\n",
      "acc for Lsat= 0.10226575398878227 \n",
      "acc for Psat= 0.15351653301272686 \n",
      "acc for optim= 0.1794186613329362\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.00537943746894598\n",
      "Loss on test= 0.006366796791553497\n",
      "acc for Lsat= 0.09925278720490767 \n",
      "acc for Psat= 0.1404113880516151 \n",
      "acc for optim= 0.17691903056166247\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.005260729696601629\n",
      "Loss on test= 0.006513005122542381\n",
      "acc for Lsat= 0.10982583740111 \n",
      "acc for Psat= 0.15270872102268482 \n",
      "acc for optim= 0.1797537281051297\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.005191100295633078\n",
      "Loss on test= 0.006455900613218546\n",
      "acc for Lsat= 0.09700517395430251 \n",
      "acc for Psat= 0.14754301994587485 \n",
      "acc for optim= 0.17822955950986077\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.005197552032768726\n",
      "Loss on test= 0.006522278301417828\n",
      "acc for Lsat= 0.09641447218389756 \n",
      "acc for Psat= 0.16108256740148677 \n",
      "acc for optim= 0.17644026339729788\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.0053158411756157875\n",
      "Loss on test= 0.006668989546597004\n",
      "acc for Lsat= 0.10036139450027337 \n",
      "acc for Psat= 0.17517507722132486 \n",
      "acc for optim= 0.17792986830357443\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.00522821256890893\n",
      "Loss on test= 0.006505925208330154\n",
      "acc for Lsat= 0.10302336274130416 \n",
      "acc for Psat= 0.16302262393976372 \n",
      "acc for optim= 0.17765269586419202\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.005234800279140472\n",
      "Loss on test= 0.006509303115308285\n",
      "acc for Lsat= 0.10094772768708346 \n",
      "acc for Psat= 0.13703642787515638 \n",
      "acc for optim= 0.17762728470453923\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005225148051977158\n",
      "Loss on test= 0.006209465209394693\n",
      "acc for Lsat= 0.10460620863277409 \n",
      "acc for Psat= 0.1572671640279635 \n",
      "acc for optim= 0.18208363596780858\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005166380666196346\n",
      "Loss on test= 0.006376458797603846\n",
      "acc for Lsat= 0.10174061881735798 \n",
      "acc for Psat= 0.1520320376966501 \n",
      "acc for optim= 0.18515823005302967\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.005154165904968977\n",
      "Loss on test= 0.00671637337654829\n",
      "acc for Lsat= 0.10260112999186596 \n",
      "acc for Psat= 0.15194072751433554 \n",
      "acc for optim= 0.18562147977039833\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.0051976884715259075\n",
      "Loss on test= 0.0064919488504529\n",
      "acc for Lsat= 0.11160088865830944 \n",
      "acc for Psat= 0.1444854606139612 \n",
      "acc for optim= 0.17648822668903646\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.005336666479706764\n",
      "Loss on test= 0.006290124729275703\n",
      "acc for Lsat= 0.0949469519238502 \n",
      "acc for Psat= 0.1418460069541185 \n",
      "acc for optim= 0.1789514771316553\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.005250192247331142\n",
      "Loss on test= 0.006356677506119013\n",
      "acc for Lsat= 0.10629658103229107 \n",
      "acc for Psat= 0.14719162409361358 \n",
      "acc for optim= 0.17904699694692092\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.005284901242703199\n",
      "Loss on test= 0.006501720752567053\n",
      "acc for Lsat= 0.1092545235823235 \n",
      "acc for Psat= 0.14784711635002168 \n",
      "acc for optim= 0.1842105800181319\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.00533596146851778\n",
      "Loss on test= 0.006895179860293865\n",
      "acc for Lsat= 0.1166437503365946 \n",
      "acc for Psat= 0.1975235134277436 \n",
      "acc for optim= 0.18349446306048647\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.005201111081987619\n",
      "Loss on test= 0.0062861694023013115\n",
      "acc for Lsat= 0.10452734810717851 \n",
      "acc for Psat= 0.14287731287441677 \n",
      "acc for optim= 0.1779851201077887\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.0052161323837935925\n",
      "Loss on test= 0.006189974956214428\n",
      "acc for Lsat= 0.09333333500369524 \n",
      "acc for Psat= 0.14747252858598056 \n",
      "acc for optim= 0.17957775660663075\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005118813831359148\n",
      "Loss on test= 0.006646429654210806\n",
      "acc for Lsat= 0.09542048971903765 \n",
      "acc for Psat= 0.14362958495995198 \n",
      "acc for optim= 0.18021030346013456\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.005227311514317989\n",
      "Loss on test= 0.006350744515657425\n",
      "acc for Lsat= 0.09821211285786892 \n",
      "acc for Psat= 0.15228559312055115 \n",
      "acc for optim= 0.18040713979290385\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.005316103342920542\n",
      "Loss on test= 0.006493614055216312\n",
      "acc for Lsat= 0.10064276202457542 \n",
      "acc for Psat= 0.15337687019383658 \n",
      "acc for optim= 0.18043789281324968\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.005389535333961248\n",
      "Loss on test= 0.006847734563052654\n",
      "acc for Lsat= 0.11767361214859537 \n",
      "acc for Psat= 0.16072563646633392 \n",
      "acc for optim= 0.17998686840626368\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.005263046827167273\n",
      "Loss on test= 0.00677290465682745\n",
      "acc for Lsat= 0.12359259224742984 \n",
      "acc for Psat= 0.15837849158836165 \n",
      "acc for optim= 0.18542583016411252\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.005594372749328613\n",
      "Loss on test= 0.006371779832988977\n",
      "acc for Lsat= 0.12359224100047769 \n",
      "acc for Psat= 0.15053623291228055 \n",
      "acc for optim= 0.17889722918413542\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.005564602557569742\n",
      "Loss on test= 0.006384243257343769\n",
      "acc for Lsat= 0.10789196473588408 \n",
      "acc for Psat= 0.13776274057965712 \n",
      "acc for optim= 0.1802049354871112\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.00528956763446331\n",
      "Loss on test= 0.0062315817922353745\n",
      "acc for Lsat= 0.10158518935900615 \n",
      "acc for Psat= 0.14648259479435108 \n",
      "acc for optim= 0.17709138223585183\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.005160137545317411\n",
      "Loss on test= 0.00642843171954155\n",
      "acc for Lsat= 0.10323400292160127 \n",
      "acc for Psat= 0.16135560503096566 \n",
      "acc for optim= 0.1894794100694157\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.005397570785135031\n",
      "Loss on test= 0.006364593282341957\n",
      "acc for Lsat= 0.09888993725626033 \n",
      "acc for Psat= 0.14367193876293297 \n",
      "acc for optim= 0.1800897107443873\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.005250614136457443\n",
      "Loss on test= 0.006289932876825333\n",
      "acc for Lsat= 0.09320665851730056 \n",
      "acc for Psat= 0.1423885701609637 \n",
      "acc for optim= 0.17658781636340348\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.005271723959594965\n",
      "Loss on test= 0.006619137711822987\n",
      "acc for Lsat= 0.10073501465297807 \n",
      "acc for Psat= 0.14852244574187254 \n",
      "acc for optim= 0.18066640160897215\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.005085659679025412\n",
      "Loss on test= 0.006265772972255945\n",
      "acc for Lsat= 0.09954204126453889 \n",
      "acc for Psat= 0.14512169713391296 \n",
      "acc for optim= 0.1823009294827431\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.005205904599279165\n",
      "Loss on test= 0.006246746983379126\n",
      "acc for Lsat= 0.1008202106081503 \n",
      "acc for Psat= 0.1552400035949865 \n",
      "acc for optim= 0.1760272195718465\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.005108600948005915\n",
      "Loss on test= 0.006311299744993448\n",
      "acc for Lsat= 0.10487159727002822 \n",
      "acc for Psat= 0.13530064074286594 \n",
      "acc for optim= 0.178369889829097\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.005114136729389429\n",
      "Loss on test= 0.006181481294333935\n",
      "acc for Lsat= 0.11748431111737846 \n",
      "acc for Psat= 0.1450622768726454 \n",
      "acc for optim= 0.17887912215067175\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.005351137835532427\n",
      "Loss on test= 0.00640873471274972\n",
      "acc for Lsat= 0.09842989169732932 \n",
      "acc for Psat= 0.16373185475350585 \n",
      "acc for optim= 0.18081455937294164\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.0052970037795603275\n",
      "Loss on test= 0.006849558558315039\n",
      "acc for Lsat= 0.13086912881880305 \n",
      "acc for Psat= 0.17969317891677478 \n",
      "acc for optim= 0.1792683664829678\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.005327168852090836\n",
      "Loss on test= 0.0061949146911501884\n",
      "acc for Lsat= 0.09835179341363884 \n",
      "acc for Psat= 0.13164014993565837 \n",
      "acc for optim= 0.1746923948812764\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.005190073046833277\n",
      "Loss on test= 0.0061292340978980064\n",
      "acc for Lsat= 0.09924560059718371 \n",
      "acc for Psat= 0.13665290321286366 \n",
      "acc for optim= 0.1752506132430131\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.005214887671172619\n",
      "Loss on test= 0.0065068649128079414\n",
      "acc for Lsat= 0.10553904836470375 \n",
      "acc for Psat= 0.13542592071275608 \n",
      "acc for optim= 0.17887683709203564\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.005135997664183378\n",
      "Loss on test= 0.006253579631447792\n",
      "acc for Lsat= 0.10222059975270699 \n",
      "acc for Psat= 0.14095817537698266 \n",
      "acc for optim= 0.17891060030347403\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.005188299808651209\n",
      "Loss on test= 0.006404896266758442\n",
      "acc for Lsat= 0.1162183122246092 \n",
      "acc for Psat= 0.14384792060337606 \n",
      "acc for optim= 0.1829535578588646\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.005352253094315529\n",
      "Loss on test= 0.006417311728000641\n",
      "acc for Lsat= 0.10813738266202759 \n",
      "acc for Psat= 0.14317815107185466 \n",
      "acc for optim= 0.17999675135620605\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.005147135350853205\n",
      "Loss on test= 0.0062736584804952145\n",
      "acc for Lsat= 0.10622227978724 \n",
      "acc for Psat= 0.14828756560962428 \n",
      "acc for optim= 0.17850904896978456\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005193219054490328\n",
      "Loss on test= 0.006209724582731724\n",
      "acc for Lsat= 0.09994665267751426 \n",
      "acc for Psat= 0.14108075647743898 \n",
      "acc for optim= 0.17701904858797599\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.005134596023708582\n",
      "Loss on test= 0.006443764083087444\n",
      "acc for Lsat= 0.10966216171603978 \n",
      "acc for Psat= 0.1325962786789672 \n",
      "acc for optim= 0.18289273416480314\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.00516138831153512\n",
      "Loss on test= 0.006443082354962826\n",
      "acc for Lsat= 0.10656190373009776 \n",
      "acc for Psat= 0.14307681451090676 \n",
      "acc for optim= 0.1775864359194718\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.005291447043418884\n",
      "Loss on test= 0.006245365832000971\n",
      "acc for Lsat= 0.10225328288386762 \n",
      "acc for Psat= 0.13437702577416408 \n",
      "acc for optim= 0.17674365229993635\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.005243121180683374\n",
      "Loss on test= 0.00659647211432457\n",
      "acc for Lsat= 0.09584045253064392 \n",
      "acc for Psat= 0.15483172587040384 \n",
      "acc for optim= 0.17940318428422009\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.005114630330353975\n",
      "Loss on test= 0.0062888916581869125\n",
      "acc for Lsat= 0.10134633143575597 \n",
      "acc for Psat= 0.1464127581103959 \n",
      "acc for optim= 0.1779383448494529\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.0052111949771642685\n",
      "Loss on test= 0.006350493058562279\n",
      "acc for Lsat= 0.09790597593893983 \n",
      "acc for Psat= 0.15149475762902168 \n",
      "acc for optim= 0.1818469904918537\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.005291060544550419\n",
      "Loss on test= 0.006438167300075293\n",
      "acc for Lsat= 0.10684898670965717 \n",
      "acc for Psat= 0.14186298917362317 \n",
      "acc for optim= 0.17854261864920626\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.0051892660558223724\n",
      "Loss on test= 0.006299655884504318\n",
      "acc for Lsat= 0.09755949474571468 \n",
      "acc for Psat= 0.13854571198385815 \n",
      "acc for optim= 0.18034423275290662\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.0051117814145982265\n",
      "Loss on test= 0.006595529615879059\n",
      "acc for Lsat= 0.10376710801195972 \n",
      "acc for Psat= 0.1630693792331668 \n",
      "acc for optim= 0.17736376372207863\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.005084430333226919\n",
      "Loss on test= 0.0063417465426027775\n",
      "acc for Lsat= 0.0935655801104199 \n",
      "acc for Psat= 0.14328604420916236 \n",
      "acc for optim= 0.17607488553590342\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.005110006779432297\n",
      "Loss on test= 0.006250925827771425\n",
      "acc for Lsat= 0.09999280129321395 \n",
      "acc for Psat= 0.13584159789024852 \n",
      "acc for optim= 0.17792651597089906\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.005207918584346771\n",
      "Loss on test= 0.006391539704054594\n",
      "acc for Lsat= 0.09880586481518254 \n",
      "acc for Psat= 0.13757419886698355 \n",
      "acc for optim= 0.17803100159516042\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.005228729452937841\n",
      "Loss on test= 0.006566209718585014\n",
      "acc for Lsat= 0.10007931704898805 \n",
      "acc for Psat= 0.16506077092907542 \n",
      "acc for optim= 0.17965315671274248\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005078124348074198\n",
      "Loss on test= 0.006378762423992157\n",
      "acc for Lsat= 0.10473016774584401 \n",
      "acc for Psat= 0.13510404677081905 \n",
      "acc for optim= 0.1749994813053982\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.005179248284548521\n",
      "Loss on test= 0.006607915740460157\n",
      "acc for Lsat= 0.12096084307334398 \n",
      "acc for Psat= 0.13473340801568623 \n",
      "acc for optim= 0.18682684400290955\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.005255717784166336\n",
      "Loss on test= 0.0061941808089613914\n",
      "acc for Lsat= 0.10204359298340687 \n",
      "acc for Psat= 0.13512930443436277 \n",
      "acc for optim= 0.17930109910663009\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.005148689728230238\n",
      "Loss on test= 0.006254500709474087\n",
      "acc for Lsat= 0.09419771506115983 \n",
      "acc for Psat= 0.12876717467251847 \n",
      "acc for optim= 0.1814334050082048\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.005046115256845951\n",
      "Loss on test= 0.006356154568493366\n",
      "acc for Lsat= 0.13802723405486275 \n",
      "acc for Psat= 0.14035934365824074 \n",
      "acc for optim= 0.17962315488153222\n",
      "Fold 3\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.8910942077636719\n",
      "Loss on test= 0.38617774844169617\n",
      "acc for Lsat= 10.89848307604631 \n",
      "acc for Psat= 15.863694721178428 \n",
      "acc for optim= 1.648621679047849\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.3610028326511383\n",
      "Loss on test= 0.34545812010765076\n",
      "acc for Lsat= 10.22102993753789 \n",
      "acc for Psat= 2.319837792538975 \n",
      "acc for optim= 3.6162220514841565\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.29431772232055664\n",
      "Loss on test= 0.2860229015350342\n",
      "acc for Lsat= 3.3873134574166976 \n",
      "acc for Psat= 2.946300393462848 \n",
      "acc for optim= 2.5542397762843834\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.2764008641242981\n",
      "Loss on test= 0.24000956118106842\n",
      "acc for Lsat= 9.194246600333262 \n",
      "acc for Psat= 2.9518013685293547 \n",
      "acc for optim= 6.118666637262543\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.2311059981584549\n",
      "Loss on test= 0.21013128757476807\n",
      "acc for Lsat= 5.916302097089568 \n",
      "acc for Psat= 2.4749517699442425 \n",
      "acc for optim= 2.0726252411282937\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.19938066601753235\n",
      "Loss on test= 0.17352071404457092\n",
      "acc for Lsat= 3.227568609426443 \n",
      "acc for Psat= 2.3750874298432767 \n",
      "acc for optim= 2.857554519615577\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.1731385737657547\n",
      "Loss on test= 0.15028244256973267\n",
      "acc for Lsat= 2.053177710572994 \n",
      "acc for Psat= 1.6788725871215198 \n",
      "acc for optim= 2.0026532612175436\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.1521517038345337\n",
      "Loss on test= 0.12638205289840698\n",
      "acc for Lsat= 2.0200036515047572 \n",
      "acc for Psat= 1.7127190226353894 \n",
      "acc for optim= 1.8981806316877663\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.13093750178813934\n",
      "Loss on test= 0.11419545114040375\n",
      "acc for Lsat= 2.5025632485567995 \n",
      "acc for Psat= 1.5133913045747496 \n",
      "acc for optim= 1.5963879357382333\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.11241855472326279\n",
      "Loss on test= 0.10589643567800522\n",
      "acc for Lsat= 1.1903108012963974 \n",
      "acc for Psat= 1.3148421154426713 \n",
      "acc for optim= 1.4111520580717716\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.10216522216796875\n",
      "Loss on test= 0.08619105815887451\n",
      "acc for Lsat= 1.2988069124922559 \n",
      "acc for Psat= 1.0784883556739628 \n",
      "acc for optim= 2.0455077505565087\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.08505722135305405\n",
      "Loss on test= 0.08247674256563187\n",
      "acc for Lsat= 1.0078974006055679 \n",
      "acc for Psat= 1.1267958579693507 \n",
      "acc for optim= 1.5602543098856758\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.07643183320760727\n",
      "Loss on test= 0.07681172341108322\n",
      "acc for Lsat= 1.2783856870405175 \n",
      "acc for Psat= 1.0759417328753862 \n",
      "acc for optim= 1.3542542075840567\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.07020491361618042\n",
      "Loss on test= 0.07396288216114044\n",
      "acc for Lsat= 0.9694133006764664 \n",
      "acc for Psat= 0.8833986666034656 \n",
      "acc for optim= 1.7341946363795195\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.06856207549571991\n",
      "Loss on test= 0.06072765961289406\n",
      "acc for Lsat= 0.7524363483157562 \n",
      "acc for Psat= 0.9414087925934173 \n",
      "acc for optim= 1.4360194171619967\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.06048467755317688\n",
      "Loss on test= 0.060740161687135696\n",
      "acc for Lsat= 0.8215263836106248 \n",
      "acc for Psat= 0.843063983200999 \n",
      "acc for optim= 3.540985097583994\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.0568145215511322\n",
      "Loss on test= 0.051309335976839066\n",
      "acc for Lsat= 1.0001178152506818 \n",
      "acc for Psat= 0.9395348779504963 \n",
      "acc for optim= 1.4075945782314119\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.055162303149700165\n",
      "Loss on test= 0.05100112408399582\n",
      "acc for Lsat= 0.9406715697983306 \n",
      "acc for Psat= 0.7643010183591459 \n",
      "acc for optim= 0.6971448391006955\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.048503000289201736\n",
      "Loss on test= 0.045671068131923676\n",
      "acc for Lsat= 0.7475309283028174 \n",
      "acc for Psat= 0.7444839007998904 \n",
      "acc for optim= 0.7456146847728854\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.047424957156181335\n",
      "Loss on test= 0.045811787247657776\n",
      "acc for Lsat= 0.6971241235625245 \n",
      "acc for Psat= 0.7365776915166125 \n",
      "acc for optim= 7.937456293619943\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.043639540672302246\n",
      "Loss on test= 0.041132234036922455\n",
      "acc for Lsat= 0.7251638223871752 \n",
      "acc for Psat= 0.7350474702512115 \n",
      "acc for optim= 0.6433167047451551\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.04277170076966286\n",
      "Loss on test= 0.03845246881246567\n",
      "acc for Lsat= 0.5905037108821342 \n",
      "acc for Psat= 0.6440379468132615 \n",
      "acc for optim= 0.7139192818816613\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.04027177393436432\n",
      "Loss on test= 0.03696511313319206\n",
      "acc for Lsat= 0.8172267774761831 \n",
      "acc for Psat= 0.6785048733487398 \n",
      "acc for optim= 0.38460604982439595\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.04015102982521057\n",
      "Loss on test= 0.03556164354085922\n",
      "acc for Lsat= 0.5601032832948132 \n",
      "acc for Psat= 0.6315821078275582 \n",
      "acc for optim= 0.6970575577359194\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.03690819442272186\n",
      "Loss on test= 0.03504466265439987\n",
      "acc for Lsat= 0.6395017430618897 \n",
      "acc for Psat= 0.7237293151713832 \n",
      "acc for optim= 5.38383780365891\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.03456643968820572\n",
      "Loss on test= 0.03408809006214142\n",
      "acc for Lsat= 0.6082224146839753 \n",
      "acc for Psat= 0.6354819016654605 \n",
      "acc for optim= 0.44480119650423244\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.034277547150850296\n",
      "Loss on test= 0.030815711244940758\n",
      "acc for Lsat= 0.5589363803470356 \n",
      "acc for Psat= 0.5484077682470072 \n",
      "acc for optim= 0.5858815405844251\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.033514413982629776\n",
      "Loss on test= 0.030059797689318657\n",
      "acc for Lsat= 0.5631289506375136 \n",
      "acc for Psat= 0.6068477384086126 \n",
      "acc for optim= 0.47013480440669025\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.03309548646211624\n",
      "Loss on test= 0.03218197077512741\n",
      "acc for Lsat= 0.46790128549155025 \n",
      "acc for Psat= 0.6654694321889995 \n",
      "acc for optim= 0.7067145637034579\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.0341588519513607\n",
      "Loss on test= 0.030259696766734123\n",
      "acc for Lsat= 0.5235887195702015 \n",
      "acc for Psat= 0.5096919835888076 \n",
      "acc for optim= 0.5454341058876043\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.032690100371837616\n",
      "Loss on test= 0.03152875974774361\n",
      "acc for Lsat= 0.662949211322435 \n",
      "acc for Psat= 0.5713348644895706 \n",
      "acc for optim= 0.39162906666515973\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.030864235013723373\n",
      "Loss on test= 0.02809732034802437\n",
      "acc for Lsat= 0.47128241969039664 \n",
      "acc for Psat= 0.71354110024215 \n",
      "acc for optim= 3.4521172607566917\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.029724102467298508\n",
      "Loss on test= 0.02491374872624874\n",
      "acc for Lsat= 0.46755221069198905 \n",
      "acc for Psat= 0.5777543658661326 \n",
      "acc for optim= 0.38135119528620587\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.02874762751162052\n",
      "Loss on test= 0.028202123939990997\n",
      "acc for Lsat= 0.5030303037319509 \n",
      "acc for Psat= 0.5038536848674208 \n",
      "acc for optim= 2.3510186727804907\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.028876524418592453\n",
      "Loss on test= 0.02614547684788704\n",
      "acc for Lsat= 0.5311081147454978 \n",
      "acc for Psat= 0.5524499068454355 \n",
      "acc for optim= 0.446459132538498\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.027756530791521072\n",
      "Loss on test= 0.027018528431653976\n",
      "acc for Lsat= 0.5310272065359419 \n",
      "acc for Psat= 0.44475473877438976 \n",
      "acc for optim= 0.3285666087326103\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.02812875248491764\n",
      "Loss on test= 0.028143176808953285\n",
      "acc for Lsat= 0.446632552693749 \n",
      "acc for Psat= 0.48314826950081624 \n",
      "acc for optim= 0.4597175882883823\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.027401378378272057\n",
      "Loss on test= 0.02425183169543743\n",
      "acc for Lsat= 0.462527843165279 \n",
      "acc for Psat= 0.5634659494527433 \n",
      "acc for optim= 0.32280998922746024\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.025869913399219513\n",
      "Loss on test= 0.024518495425581932\n",
      "acc for Lsat= 0.47413125116695853 \n",
      "acc for Psat= 0.5719642038638995 \n",
      "acc for optim= 0.45104708481104916\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.025588983669877052\n",
      "Loss on test= 0.02351953089237213\n",
      "acc for Lsat= 0.454142664109256 \n",
      "acc for Psat= 0.5250013698575974 \n",
      "acc for optim= 0.3865668656356787\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.02638065814971924\n",
      "Loss on test= 0.026753129437565804\n",
      "acc for Lsat= 0.4395963545334903 \n",
      "acc for Psat= 0.4818998142342222 \n",
      "acc for optim= 0.3292277011598737\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.02596108615398407\n",
      "Loss on test= 0.023524049669504166\n",
      "acc for Lsat= 0.3906383716058445 \n",
      "acc for Psat= 0.5813300982385093 \n",
      "acc for optim= 0.322499301236373\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.025188611820340157\n",
      "Loss on test= 0.022682087495923042\n",
      "acc for Lsat= 0.4743315044018075 \n",
      "acc for Psat= 0.513106872154576 \n",
      "acc for optim= 0.29405510760369835\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.02506849728524685\n",
      "Loss on test= 0.024299515411257744\n",
      "acc for Lsat= 0.4071589677965873 \n",
      "acc for Psat= 0.5475651606503635 \n",
      "acc for optim= 0.2634677526374297\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.023421701043844223\n",
      "Loss on test= 0.02365233190357685\n",
      "acc for Lsat= 0.4903421636668468 \n",
      "acc for Psat= 0.49384054666183685 \n",
      "acc for optim= 0.3153483016000324\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.023993639275431633\n",
      "Loss on test= 0.023037245497107506\n",
      "acc for Lsat= 0.4708887203309427 \n",
      "acc for Psat= 0.4392354218830037 \n",
      "acc for optim= 0.2729986886566818\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.023842856287956238\n",
      "Loss on test= 0.024169187992811203\n",
      "acc for Lsat= 0.41830866981979703 \n",
      "acc for Psat= 0.4873856185350215 \n",
      "acc for optim= 0.2477987775564543\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.022355591878294945\n",
      "Loss on test= 0.02093486115336418\n",
      "acc for Lsat= 0.4188254985767983 \n",
      "acc for Psat= 0.4933262868435122 \n",
      "acc for optim= 0.3929951682126754\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.022908233106136322\n",
      "Loss on test= 0.020767679437994957\n",
      "acc for Lsat= 0.41440041736078037 \n",
      "acc for Psat= 0.4813539051785876 \n",
      "acc for optim= 0.3040782461010511\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.02209077775478363\n",
      "Loss on test= 0.022217152640223503\n",
      "acc for Lsat= 0.41925022249248484 \n",
      "acc for Psat= 0.4241168127974143 \n",
      "acc for optim= 0.24232647856194023\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.022746693342924118\n",
      "Loss on test= 0.01995227113366127\n",
      "acc for Lsat= 0.37415144039708115 \n",
      "acc for Psat= 0.46396668285966813 \n",
      "acc for optim= 0.30149089471937307\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.02228393778204918\n",
      "Loss on test= 0.019907599315047264\n",
      "acc for Lsat= 0.37343747092322827 \n",
      "acc for Psat= 0.4202891727343101 \n",
      "acc for optim= 0.4207066356505714\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.022682780399918556\n",
      "Loss on test= 0.02422618679702282\n",
      "acc for Lsat= 0.46133564583834485 \n",
      "acc for Psat= 0.42057049259735346 \n",
      "acc for optim= 0.23387923178410888\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.02242129109799862\n",
      "Loss on test= 0.02222250960767269\n",
      "acc for Lsat= 0.41238482978125734 \n",
      "acc for Psat= 0.4445957977525698 \n",
      "acc for optim= 0.2512460912941999\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.021922053769230843\n",
      "Loss on test= 0.020155027508735657\n",
      "acc for Lsat= 0.4212823102102816 \n",
      "acc for Psat= 0.43232646727001584 \n",
      "acc for optim= 0.2780256622376131\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.02065437100827694\n",
      "Loss on test= 0.01946979947388172\n",
      "acc for Lsat= 0.4078741099410517 \n",
      "acc for Psat= 0.41858301793321073 \n",
      "acc for optim= 0.40272782267149176\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.020730767399072647\n",
      "Loss on test= 0.01935182325541973\n",
      "acc for Lsat= 0.4076284830902099 \n",
      "acc for Psat= 0.43803098997002077 \n",
      "acc for optim= 0.2852525480986908\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.020444676280021667\n",
      "Loss on test= 0.019832491874694824\n",
      "acc for Lsat= 0.4936282064260701 \n",
      "acc for Psat= 0.4115929223276121 \n",
      "acc for optim= 0.2462105452174689\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.020493045449256897\n",
      "Loss on test= 0.017923850566148758\n",
      "acc for Lsat= 0.37291772337050283 \n",
      "acc for Psat= 0.4371288905623825 \n",
      "acc for optim= 0.25240062362344534\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.020328575745224953\n",
      "Loss on test= 0.018708068877458572\n",
      "acc for Lsat= 0.34688769407571146 \n",
      "acc for Psat= 0.4581128230095822 \n",
      "acc for optim= 0.41161797711676035\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.020198015496134758\n",
      "Loss on test= 0.017650049179792404\n",
      "acc for Lsat= 0.3784347140640052 \n",
      "acc for Psat= 0.4100264049523724 \n",
      "acc for optim= 0.2634367332339271\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.019703185185790062\n",
      "Loss on test= 0.0194906834512949\n",
      "acc for Lsat= 0.34293198111511114 \n",
      "acc for Psat= 0.4042732460452621 \n",
      "acc for optim= 0.21695138072789485\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.01841418258845806\n",
      "Loss on test= 0.01808347925543785\n",
      "acc for Lsat= 0.3589279083562606 \n",
      "acc for Psat= 0.40426664292494563 \n",
      "acc for optim= 0.2239039873996729\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.018650323152542114\n",
      "Loss on test= 0.02006665989756584\n",
      "acc for Lsat= 0.33255196302087753 \n",
      "acc for Psat= 0.39449184920404395 \n",
      "acc for optim= 0.23325228172895573\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.018756257370114326\n",
      "Loss on test= 0.01807902380824089\n",
      "acc for Lsat= 0.3743792632413789 \n",
      "acc for Psat= 0.4283995233122983 \n",
      "acc for optim= 0.2445803941615383\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.018904652446508408\n",
      "Loss on test= 0.020403999835252762\n",
      "acc for Lsat= 0.4650983939644829 \n",
      "acc for Psat= 0.3733242545259182 \n",
      "acc for optim= 0.22366496892032414\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.019692687317728996\n",
      "Loss on test= 0.01843097433447838\n",
      "acc for Lsat= 0.3768949257324137 \n",
      "acc for Psat= 0.42156132850544276 \n",
      "acc for optim= 0.23156487821727972\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.018416816368699074\n",
      "Loss on test= 0.017568212002515793\n",
      "acc for Lsat= 0.32388175127267166 \n",
      "acc for Psat= 0.4118216977237623 \n",
      "acc for optim= 0.23104722526221774\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.017831921577453613\n",
      "Loss on test= 0.019511030986905098\n",
      "acc for Lsat= 0.32342966883722535 \n",
      "acc for Psat= 0.45571363782368574 \n",
      "acc for optim= 0.2397303970409101\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.018504228442907333\n",
      "Loss on test= 0.01744481734931469\n",
      "acc for Lsat= 0.407576926711699 \n",
      "acc for Psat= 0.3886887098826166 \n",
      "acc for optim= 0.23801869286379204\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.018454188480973244\n",
      "Loss on test= 0.01673138327896595\n",
      "acc for Lsat= 0.34670907554509295 \n",
      "acc for Psat= 0.40582460543232257 \n",
      "acc for optim= 0.26003048970144577\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.01754632033407688\n",
      "Loss on test= 0.01592567004263401\n",
      "acc for Lsat= 0.32621412537677363 \n",
      "acc for Psat= 0.4000675856203432 \n",
      "acc for optim= 0.24871635395956637\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.017764192074537277\n",
      "Loss on test= 0.016614077612757683\n",
      "acc for Lsat= 0.3409139424762248 \n",
      "acc for Psat= 0.4019507936648773 \n",
      "acc for optim= 0.2311188703901575\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.016999633982777596\n",
      "Loss on test= 0.016118137165904045\n",
      "acc for Lsat= 0.3715389741347108 \n",
      "acc for Psat= 0.38222000646104837 \n",
      "acc for optim= 0.24738587495109665\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.017442718148231506\n",
      "Loss on test= 0.016319671645760536\n",
      "acc for Lsat= 0.3204533397259405 \n",
      "acc for Psat= 0.39562394685816726 \n",
      "acc for optim= 0.25714536275385447\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.01711461693048477\n",
      "Loss on test= 0.014713838696479797\n",
      "acc for Lsat= 0.352860356796481 \n",
      "acc for Psat= 0.3705769977925622 \n",
      "acc for optim= 0.249290934398871\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.016744012013077736\n",
      "Loss on test= 0.01547408290207386\n",
      "acc for Lsat= 0.33593140155583545 \n",
      "acc for Psat= 0.38335576619637496 \n",
      "acc for optim= 0.2384027387452079\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.016309410333633423\n",
      "Loss on test= 0.016003981232643127\n",
      "acc for Lsat= 0.38719773596597873 \n",
      "acc for Psat= 0.37428635003586375 \n",
      "acc for optim= 0.24658583228734346\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.016904225572943687\n",
      "Loss on test= 0.01691240631043911\n",
      "acc for Lsat= 0.30696924217241955 \n",
      "acc for Psat= 0.40009501475415654 \n",
      "acc for optim= 0.2997036739160329\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.01673743687570095\n",
      "Loss on test= 0.015749452635645866\n",
      "acc for Lsat= 0.34371074136720997 \n",
      "acc for Psat= 0.3587012628039874 \n",
      "acc for optim= 0.22823090340288882\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.016112739220261574\n",
      "Loss on test= 0.015113788656890392\n",
      "acc for Lsat= 0.37573556237259403 \n",
      "acc for Psat= 0.34821193979862713 \n",
      "acc for optim= 0.2444661306610608\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.015872297808527946\n",
      "Loss on test= 0.015846967697143555\n",
      "acc for Lsat= 0.3202895482103781 \n",
      "acc for Psat= 0.3380228991173263 \n",
      "acc for optim= 0.22678718317183666\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.016277838498353958\n",
      "Loss on test= 0.014802113175392151\n",
      "acc for Lsat= 0.31605315614320423 \n",
      "acc for Psat= 0.41976887189446493 \n",
      "acc for optim= 0.21776229190554414\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.015919441357254982\n",
      "Loss on test= 0.015681030228734016\n",
      "acc for Lsat= 0.34054195198680376 \n",
      "acc for Psat= 0.3736736987976238 \n",
      "acc for optim= 0.23126805996975777\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.01574689708650112\n",
      "Loss on test= 0.01628909632563591\n",
      "acc for Lsat= 0.375086649844102 \n",
      "acc for Psat= 0.33529069732793615 \n",
      "acc for optim= 0.2384632887795404\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.015444168820977211\n",
      "Loss on test= 0.014483915641903877\n",
      "acc for Lsat= 0.332371652097995 \n",
      "acc for Psat= 0.3493061688672783 \n",
      "acc for optim= 0.2296285085135792\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.015117684379220009\n",
      "Loss on test= 0.014942948706448078\n",
      "acc for Lsat= 0.2966188860780283 \n",
      "acc for Psat= 0.37790297230586056 \n",
      "acc for optim= 0.22954216501927255\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.015008112415671349\n",
      "Loss on test= 0.015174475498497486\n",
      "acc for Lsat= 0.3324502527987509 \n",
      "acc for Psat= 0.3333447616043142 \n",
      "acc for optim= 0.20528720278778909\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.015474610030651093\n",
      "Loss on test= 0.01623006910085678\n",
      "acc for Lsat= 0.37742564564010733 \n",
      "acc for Psat= 0.34348716600052775 \n",
      "acc for optim= 0.21693621762883472\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.01581154204905033\n",
      "Loss on test= 0.015139165334403515\n",
      "acc for Lsat= 0.2997655782764431 \n",
      "acc for Psat= 0.39268216271371736 \n",
      "acc for optim= 0.25518086075385943\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.015547151677310467\n",
      "Loss on test= 0.014900085516273975\n",
      "acc for Lsat= 0.32538056046846703 \n",
      "acc for Psat= 0.3865375675865122 \n",
      "acc for optim= 0.2554897298499831\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.015482242219150066\n",
      "Loss on test= 0.01547661330550909\n",
      "acc for Lsat= 0.29279238019461373 \n",
      "acc for Psat= 0.4256767112764882 \n",
      "acc for optim= 0.2548588156398084\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.015058865770697594\n",
      "Loss on test= 0.013737700879573822\n",
      "acc for Lsat= 0.3082427957387817 \n",
      "acc for Psat= 0.3360082212679412 \n",
      "acc for optim= 0.20951851818638198\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.015049847774207592\n",
      "Loss on test= 0.015552820637822151\n",
      "acc for Lsat= 0.3423285528040504 \n",
      "acc for Psat= 0.3703296746141466 \n",
      "acc for optim= 0.2359890713882664\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.015316651202738285\n",
      "Loss on test= 0.014917144551873207\n",
      "acc for Lsat= 0.29594360115447055 \n",
      "acc for Psat= 0.34473136794907544 \n",
      "acc for optim= 0.21908023301551333\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.014579685404896736\n",
      "Loss on test= 0.01482368353754282\n",
      "acc for Lsat= 0.36589928965961893 \n",
      "acc for Psat= 0.32025959882122224 \n",
      "acc for optim= 0.2572221975478405\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.014748631045222282\n",
      "Loss on test= 0.014315113425254822\n",
      "acc for Lsat= 0.2988342696704864 \n",
      "acc for Psat= 0.33946525965737584 \n",
      "acc for optim= 0.22872454277822307\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.014375968836247921\n",
      "Loss on test= 0.01443824265152216\n",
      "acc for Lsat= 0.31641036609122436 \n",
      "acc for Psat= 0.34921887027244464 \n",
      "acc for optim= 0.22946161027180464\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.014368013478815556\n",
      "Loss on test= 0.015758508816361427\n",
      "acc for Lsat= 0.30466795495374605 \n",
      "acc for Psat= 0.3711194486343113 \n",
      "acc for optim= 0.22869263507340834\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.015024753287434578\n",
      "Loss on test= 0.015057328157126904\n",
      "acc for Lsat= 0.35921910039591287 \n",
      "acc for Psat= 0.31471530140284765 \n",
      "acc for optim= 0.21004816846440205\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.01493601594120264\n",
      "Loss on test= 0.013592795468866825\n",
      "acc for Lsat= 0.28387957184109053 \n",
      "acc for Psat= 0.37793781177390123 \n",
      "acc for optim= 0.21987946664582547\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.015043261460959911\n",
      "Loss on test= 0.014507251791656017\n",
      "acc for Lsat= 0.32405617511382867 \n",
      "acc for Psat= 0.36657037476627896 \n",
      "acc for optim= 0.20108177385368067\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.014958826825022697\n",
      "Loss on test= 0.015456698834896088\n",
      "acc for Lsat= 0.3723018066177394 \n",
      "acc for Psat= 0.30931791413230886 \n",
      "acc for optim= 0.208382042354945\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.015003036707639694\n",
      "Loss on test= 0.013523397035896778\n",
      "acc for Lsat= 0.3163973814996614 \n",
      "acc for Psat= 0.3301464784095957 \n",
      "acc for optim= 0.21396862296165095\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.014282364398241043\n",
      "Loss on test= 0.014842000789940357\n",
      "acc for Lsat= 0.31430317127524177 \n",
      "acc for Psat= 0.33381901328716224 \n",
      "acc for optim= 0.2052239390560882\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.014573340304195881\n",
      "Loss on test= 0.014886942692101002\n",
      "acc for Lsat= 0.26817743300155084 \n",
      "acc for Psat= 0.4123397037525334 \n",
      "acc for optim= 0.25706416046297226\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.015034765005111694\n",
      "Loss on test= 0.015072358772158623\n",
      "acc for Lsat= 0.31406178632951687 \n",
      "acc for Psat= 0.3374915020939551 \n",
      "acc for optim= 0.25816134590186757\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.01540686096996069\n",
      "Loss on test= 0.015100240707397461\n",
      "acc for Lsat= 0.337976408320026 \n",
      "acc for Psat= 0.34170054706644165 \n",
      "acc for optim= 0.19800871617986263\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.014944402500987053\n",
      "Loss on test= 0.014472413808107376\n",
      "acc for Lsat= 0.29243119569680953 \n",
      "acc for Psat= 0.3906984607047225 \n",
      "acc for optim= 0.22413262998216432\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.014445059932768345\n",
      "Loss on test= 0.013407215476036072\n",
      "acc for Lsat= 0.3168670104839948 \n",
      "acc for Psat= 0.32926352098985334 \n",
      "acc for optim= 0.19911182017952073\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.014662432484328747\n",
      "Loss on test= 0.014440849423408508\n",
      "acc for Lsat= 0.29993625270966534 \n",
      "acc for Psat= 0.32978005465623494 \n",
      "acc for optim= 0.2269725012958797\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.01419375091791153\n",
      "Loss on test= 0.0141457449644804\n",
      "acc for Lsat= 0.3001518726653287 \n",
      "acc for Psat= 0.34552494022913427 \n",
      "acc for optim= 0.21584084608046986\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.013861656188964844\n",
      "Loss on test= 0.014100390486419201\n",
      "acc for Lsat= 0.32850068565250473 \n",
      "acc for Psat= 0.37169397121220216 \n",
      "acc for optim= 0.2139652517362265\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.013896229676902294\n",
      "Loss on test= 0.013127622194588184\n",
      "acc for Lsat= 0.30249361679100706 \n",
      "acc for Psat= 0.3604272619362549 \n",
      "acc for optim= 0.20766309210078338\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.014107937924563885\n",
      "Loss on test= 0.01327603217214346\n",
      "acc for Lsat= 0.29433458192609063 \n",
      "acc for Psat= 0.38207441784844204 \n",
      "acc for optim= 0.21388084036644195\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.013958054594695568\n",
      "Loss on test= 0.013899588957428932\n",
      "acc for Lsat= 0.32006929230300485 \n",
      "acc for Psat= 0.32246916027223643 \n",
      "acc for optim= 0.21025437360839458\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.014585676603019238\n",
      "Loss on test= 0.01345664169639349\n",
      "acc for Lsat= 0.35261916899046786 \n",
      "acc for Psat= 0.3240386312969054 \n",
      "acc for optim= 0.20954101985144252\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.013568318448960781\n",
      "Loss on test= 0.014373701997101307\n",
      "acc for Lsat= 0.2891499434135275 \n",
      "acc for Psat= 0.3541516764435565 \n",
      "acc for optim= 0.20130558719471525\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.013706464320421219\n",
      "Loss on test= 0.013765028677880764\n",
      "acc for Lsat= 0.28802107773230384 \n",
      "acc for Psat= 0.34458404589177744 \n",
      "acc for optim= 0.2235769844408276\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.013720860704779625\n",
      "Loss on test= 0.014296747744083405\n",
      "acc for Lsat= 0.34414289015222566 \n",
      "acc for Psat= 0.3190892160979471 \n",
      "acc for optim= 0.2285839343277395\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.014077759347856045\n",
      "Loss on test= 0.012760945595800877\n",
      "acc for Lsat= 0.2770767692159712 \n",
      "acc for Psat= 0.31617739759373786 \n",
      "acc for optim= 0.19764233136673873\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.013491220772266388\n",
      "Loss on test= 0.012756682932376862\n",
      "acc for Lsat= 0.28327923309690367 \n",
      "acc for Psat= 0.36194508213938625 \n",
      "acc for optim= 0.23451537091637578\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.013536714017391205\n",
      "Loss on test= 0.013033537194132805\n",
      "acc for Lsat= 0.34638478720650734 \n",
      "acc for Psat= 0.3121159082102413 \n",
      "acc for optim= 0.2144686593197253\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.013148484751582146\n",
      "Loss on test= 0.013423015363514423\n",
      "acc for Lsat= 0.2851131916846695 \n",
      "acc for Psat= 0.34943358757064324 \n",
      "acc for optim= 0.1915338367788708\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.01300464291125536\n",
      "Loss on test= 0.012399989180266857\n",
      "acc for Lsat= 0.29077262666165504 \n",
      "acc for Psat= 0.33425494339049644 \n",
      "acc for optim= 0.21238970396839127\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.013273635879158974\n",
      "Loss on test= 0.01385127566754818\n",
      "acc for Lsat= 0.3046320102820991 \n",
      "acc for Psat= 0.34270505417923747 \n",
      "acc for optim= 0.20784233579950132\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.01416692603379488\n",
      "Loss on test= 0.013041581958532333\n",
      "acc for Lsat= 0.2606096885244148 \n",
      "acc for Psat= 0.34782163065790733 \n",
      "acc for optim= 0.2085571351323066\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.014827159233391285\n",
      "Loss on test= 0.017164411023259163\n",
      "acc for Lsat= 0.5106874705047262 \n",
      "acc for Psat= 0.33694423726331946 \n",
      "acc for optim= 0.21127786119924732\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.01382360141724348\n",
      "Loss on test= 0.013179185800254345\n",
      "acc for Lsat= 0.26486779128125004 \n",
      "acc for Psat= 0.3491649091423873 \n",
      "acc for optim= 0.20988290178679195\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.01333585660904646\n",
      "Loss on test= 0.01355760172009468\n",
      "acc for Lsat= 0.30043763343486274 \n",
      "acc for Psat= 0.3393405815008304 \n",
      "acc for optim= 0.20451964650987361\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.013050904497504234\n",
      "Loss on test= 0.012760850600898266\n",
      "acc for Lsat= 0.2933344033998445 \n",
      "acc for Psat= 0.3325136836112408 \n",
      "acc for optim= 0.2175096314383916\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.013111596927046776\n",
      "Loss on test= 0.013084731064736843\n",
      "acc for Lsat= 0.3113413388881954 \n",
      "acc for Psat= 0.33545866928997803 \n",
      "acc for optim= 0.2256014373177439\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.012822609394788742\n",
      "Loss on test= 0.012588128447532654\n",
      "acc for Lsat= 0.2872084002233228 \n",
      "acc for Psat= 0.3303994556716478 \n",
      "acc for optim= 0.2056112276430311\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.013425265438854694\n",
      "Loss on test= 0.012274318374693394\n",
      "acc for Lsat= 0.29303755652880364 \n",
      "acc for Psat= 0.318096472259935 \n",
      "acc for optim= 0.20980132966242554\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.012601531110703945\n",
      "Loss on test= 0.012396296486258507\n",
      "acc for Lsat= 0.27526738108854015 \n",
      "acc for Psat= 0.3538648332207624 \n",
      "acc for optim= 0.2091947691556384\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.013271559029817581\n",
      "Loss on test= 0.015783600509166718\n",
      "acc for Lsat= 0.4320511439538087 \n",
      "acc for Psat= 0.3005823897527424 \n",
      "acc for optim= 0.20030800361800594\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.013056375086307526\n",
      "Loss on test= 0.012807896360754967\n",
      "acc for Lsat= 0.27513345870633005 \n",
      "acc for Psat= 0.33085511139624696 \n",
      "acc for optim= 0.2126919515611843\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.012778179720044136\n",
      "Loss on test= 0.013367417268455029\n",
      "acc for Lsat= 0.28410949250875905 \n",
      "acc for Psat= 0.3322928488115714 \n",
      "acc for optim= 0.2079039925967565\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.012768087908625603\n",
      "Loss on test= 0.0130873192101717\n",
      "acc for Lsat= 0.3290904014969341 \n",
      "acc for Psat= 0.3136323396862969 \n",
      "acc for optim= 0.2047314024669971\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.012961527332663536\n",
      "Loss on test= 0.012895219959318638\n",
      "acc for Lsat= 0.2716089944437585 \n",
      "acc for Psat= 0.356233209637975 \n",
      "acc for optim= 0.2105836915202294\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.013496744446456432\n",
      "Loss on test= 0.012812098488211632\n",
      "acc for Lsat= 0.29479919665735344 \n",
      "acc for Psat= 0.28872123210395156 \n",
      "acc for optim= 0.20063753053772096\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.01287029217928648\n",
      "Loss on test= 0.013294169679284096\n",
      "acc for Lsat= 0.32648340051427777 \n",
      "acc for Psat= 0.3002280006777083 \n",
      "acc for optim= 0.22468984767328948\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.013253359124064445\n",
      "Loss on test= 0.012795302085578442\n",
      "acc for Lsat= 0.2660429349381121 \n",
      "acc for Psat= 0.31914812531141323 \n",
      "acc for optim= 0.22064280310194198\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.012998819351196289\n",
      "Loss on test= 0.012225660495460033\n",
      "acc for Lsat= 0.28644901958653685 \n",
      "acc for Psat= 0.32346835951997294 \n",
      "acc for optim= 0.2120666543444197\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.012336383573710918\n",
      "Loss on test= 0.012655774131417274\n",
      "acc for Lsat= 0.2699278745193796 \n",
      "acc for Psat= 0.34471127753636827 \n",
      "acc for optim= 0.2039253842852525\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.012589220888912678\n",
      "Loss on test= 0.01246205996721983\n",
      "acc for Lsat= 0.26148463609058886 \n",
      "acc for Psat= 0.31025657130443063 \n",
      "acc for optim= 0.2039697106227175\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.0137251615524292\n",
      "Loss on test= 0.012389305047690868\n",
      "acc for Lsat= 0.28015937913929717 \n",
      "acc for Psat= 0.3159904701027994 \n",
      "acc for optim= 0.19083698939003452\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.012771603651344776\n",
      "Loss on test= 0.01288079097867012\n",
      "acc for Lsat= 0.31569255073476155 \n",
      "acc for Psat= 0.30063633386861194 \n",
      "acc for optim= 0.20370524381242167\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.012752048671245575\n",
      "Loss on test= 0.012859552167356014\n",
      "acc for Lsat= 0.2974600097104731 \n",
      "acc for Psat= 0.31225852913583463 \n",
      "acc for optim= 0.23443769848892917\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.012564982287585735\n",
      "Loss on test= 0.012265880592167377\n",
      "acc for Lsat= 0.26512030848833684 \n",
      "acc for Psat= 0.2860223688002333 \n",
      "acc for optim= 0.19344138795693996\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.012300673872232437\n",
      "Loss on test= 0.01260313019156456\n",
      "acc for Lsat= 0.2624269994599131 \n",
      "acc for Psat= 0.3388203057575329 \n",
      "acc for optim= 0.2461338427670558\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.012459449470043182\n",
      "Loss on test= 0.012927070260047913\n",
      "acc for Lsat= 0.27672841477937793 \n",
      "acc for Psat= 0.3621334023582922 \n",
      "acc for optim= 0.20523331764726774\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.01314372569322586\n",
      "Loss on test= 0.012266105972230434\n",
      "acc for Lsat= 0.29543724643283625 \n",
      "acc for Psat= 0.323412969739175 \n",
      "acc for optim= 0.20427403964660354\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.013206851668655872\n",
      "Loss on test= 0.01271180808544159\n",
      "acc for Lsat= 0.3184058165018025 \n",
      "acc for Psat= 0.30447874586644574 \n",
      "acc for optim= 0.1999433324652617\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.012171991169452667\n",
      "Loss on test= 0.01171171199530363\n",
      "acc for Lsat= 0.2823137402844401 \n",
      "acc for Psat= 0.31686061661243786 \n",
      "acc for optim= 0.1961716894761225\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.012423218227922916\n",
      "Loss on test= 0.0119773605838418\n",
      "acc for Lsat= 0.27098185816784454 \n",
      "acc for Psat= 0.30680645327162426 \n",
      "acc for optim= 0.20284920023098224\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.012378690764307976\n",
      "Loss on test= 0.01258025225251913\n",
      "acc for Lsat= 0.27158727159749596 \n",
      "acc for Psat= 0.3134974656144722 \n",
      "acc for optim= 0.2086819962488654\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.012152516283094883\n",
      "Loss on test= 0.012023848481476307\n",
      "acc for Lsat= 0.26725254383927677 \n",
      "acc for Psat= 0.2851045973790885 \n",
      "acc for optim= 0.19366154064285895\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.012679021805524826\n",
      "Loss on test= 0.012207780964672565\n",
      "acc for Lsat= 0.24427778196931704 \n",
      "acc for Psat= 0.35511973792784596 \n",
      "acc for optim= 0.2181489834489381\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.012391372583806515\n",
      "Loss on test= 0.011459995992481709\n",
      "acc for Lsat= 0.27282709995051846 \n",
      "acc for Psat= 0.3132867051195668 \n",
      "acc for optim= 0.1926652374275216\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.012204582802951336\n",
      "Loss on test= 0.012060659937560558\n",
      "acc for Lsat= 0.25489822651473554 \n",
      "acc for Psat= 0.34284229479011186 \n",
      "acc for optim= 0.20133971392602393\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.011776121333241463\n",
      "Loss on test= 0.011857926845550537\n",
      "acc for Lsat= 0.3176206772402873 \n",
      "acc for Psat= 0.29041471137188146 \n",
      "acc for optim= 0.19569330670197518\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.012199154123663902\n",
      "Loss on test= 0.011809137649834156\n",
      "acc for Lsat= 0.2524012773493588 \n",
      "acc for Psat= 0.30544963143659737 \n",
      "acc for optim= 0.2112648341351667\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.011949579231441021\n",
      "Loss on test= 0.011953433975577354\n",
      "acc for Lsat= 0.26902351595035234 \n",
      "acc for Psat= 0.2938040512340809 \n",
      "acc for optim= 0.18731223463190552\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.011658111587166786\n",
      "Loss on test= 0.011496329680085182\n",
      "acc for Lsat= 0.2693630667636171 \n",
      "acc for Psat= 0.2941889757230702 \n",
      "acc for optim= 0.19841999063931792\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.011700940318405628\n",
      "Loss on test= 0.011387101374566555\n",
      "acc for Lsat= 0.31816129508779095 \n",
      "acc for Psat= 0.31604399161320496 \n",
      "acc for optim= 0.19866991633424166\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.011938107199966908\n",
      "Loss on test= 0.01246948167681694\n",
      "acc for Lsat= 0.24638223043340887 \n",
      "acc for Psat= 0.3251845921876756 \n",
      "acc for optim= 0.18617000245482102\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.011803902685642242\n",
      "Loss on test= 0.011634926311671734\n",
      "acc for Lsat= 0.27508966532076484 \n",
      "acc for Psat= 0.31577528725579584 \n",
      "acc for optim= 0.20634604211718888\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.012162460945546627\n",
      "Loss on test= 0.012952848337590694\n",
      "acc for Lsat= 0.36424057042097197 \n",
      "acc for Psat= 0.30827345248060833 \n",
      "acc for optim= 0.19673022351041772\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.012019213289022446\n",
      "Loss on test= 0.011576555669307709\n",
      "acc for Lsat= 0.26368818741261874 \n",
      "acc for Psat= 0.3107110046183005 \n",
      "acc for optim= 0.2092319365741836\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.011786667630076408\n",
      "Loss on test= 0.011172058992087841\n",
      "acc for Lsat= 0.26563664278587196 \n",
      "acc for Psat= 0.3172347973221976 \n",
      "acc for optim= 0.1947426206921542\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.011607751250267029\n",
      "Loss on test= 0.012293647974729538\n",
      "acc for Lsat= 0.2547450547228092 \n",
      "acc for Psat= 0.39034769186971086 \n",
      "acc for optim= 0.21381243210186854\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.012365815229713917\n",
      "Loss on test= 0.012517821975052357\n",
      "acc for Lsat= 0.2654609273587404 \n",
      "acc for Psat= 0.3902865327684324 \n",
      "acc for optim= 0.20408814874669612\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.012852756306529045\n",
      "Loss on test= 0.01228637620806694\n",
      "acc for Lsat= 0.25266464799288596 \n",
      "acc for Psat= 0.3699430452161815 \n",
      "acc for optim= 0.20157244852964287\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.011767219752073288\n",
      "Loss on test= 0.011088191531598568\n",
      "acc for Lsat= 0.25359663642105973 \n",
      "acc for Psat= 0.29321849776268305 \n",
      "acc for optim= 0.19718178454776708\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.011561288498342037\n",
      "Loss on test= 0.011365807615220547\n",
      "acc for Lsat= 0.26782789403148705 \n",
      "acc for Psat= 0.3103077749126749 \n",
      "acc for optim= 0.20415747062690717\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.011693664826452732\n",
      "Loss on test= 0.011246273294091225\n",
      "acc for Lsat= 0.2683764393349938 \n",
      "acc for Psat= 0.2743469660030363 \n",
      "acc for optim= 0.20048002481131777\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.011349978856742382\n",
      "Loss on test= 0.011196366511285305\n",
      "acc for Lsat= 0.22443554240748495 \n",
      "acc for Psat= 0.3338203547865379 \n",
      "acc for optim= 0.19764210447858596\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.011666732840240002\n",
      "Loss on test= 0.011080539785325527\n",
      "acc for Lsat= 0.2744693605109697 \n",
      "acc for Psat= 0.30029956449111894 \n",
      "acc for optim= 0.20607243912554868\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.01196723897010088\n",
      "Loss on test= 0.011144822463393211\n",
      "acc for Lsat= 0.2395200161010163 \n",
      "acc for Psat= 0.3015538641341393 \n",
      "acc for optim= 0.20102929561997715\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.011502262204885483\n",
      "Loss on test= 0.010933303274214268\n",
      "acc for Lsat= 0.2644340407610257 \n",
      "acc for Psat= 0.29811910943700803 \n",
      "acc for optim= 0.1903019455970246\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.011668398976325989\n",
      "Loss on test= 0.012700085528194904\n",
      "acc for Lsat= 0.2603694733068649 \n",
      "acc for Psat= 0.34576207545752685 \n",
      "acc for optim= 0.20458469045272953\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.012053330428898335\n",
      "Loss on test= 0.012825028039515018\n",
      "acc for Lsat= 0.25058696115730844 \n",
      "acc for Psat= 0.37242409586375486 \n",
      "acc for optim= 0.2087275620313547\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.012317108921706676\n",
      "Loss on test= 0.011330216191709042\n",
      "acc for Lsat= 0.2570169674983009 \n",
      "acc for Psat= 0.28904531484196827 \n",
      "acc for optim= 0.20262835340425325\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.012287046760320663\n",
      "Loss on test= 0.010415216907858849\n",
      "acc for Lsat= 0.24322981059958693 \n",
      "acc for Psat= 0.3090973643383886 \n",
      "acc for optim= 0.1894989756362299\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.011657276190817356\n",
      "Loss on test= 0.011281314305961132\n",
      "acc for Lsat= 0.3009089958817935 \n",
      "acc for Psat= 0.28095021346716503 \n",
      "acc for optim= 0.20165063591982313\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.011835925281047821\n",
      "Loss on test= 0.012818601913750172\n",
      "acc for Lsat= 0.3227008966364952 \n",
      "acc for Psat= 0.28176416797646814 \n",
      "acc for optim= 0.19017494077254654\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.011470148339867592\n",
      "Loss on test= 0.011268224567174911\n",
      "acc for Lsat= 0.21327278351334925 \n",
      "acc for Psat= 0.3062095721869736 \n",
      "acc for optim= 0.21036871947981617\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.011192929930984974\n",
      "Loss on test= 0.011319381184875965\n",
      "acc for Lsat= 0.24084513834158489 \n",
      "acc for Psat= 0.3073917392388024 \n",
      "acc for optim= 0.20399411296239123\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.011160602793097496\n",
      "Loss on test= 0.010782544501125813\n",
      "acc for Lsat= 0.24975542391274683 \n",
      "acc for Psat= 0.29063635312746017 \n",
      "acc for optim= 0.18875188101574658\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.011124581098556519\n",
      "Loss on test= 0.011024774983525276\n",
      "acc for Lsat= 0.2531244028129574 \n",
      "acc for Psat= 0.2663544172411659 \n",
      "acc for optim= 0.19089969578478327\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.011640392243862152\n",
      "Loss on test= 0.011128827929496765\n",
      "acc for Lsat= 0.24943524149401472 \n",
      "acc for Psat= 0.31605294786355886 \n",
      "acc for optim= 0.20536206736122384\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.011460937559604645\n",
      "Loss on test= 0.011408517137169838\n",
      "acc for Lsat= 0.27264075595657405 \n",
      "acc for Psat= 0.27688615965913366 \n",
      "acc for optim= 0.18762217783168544\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.011167090386152267\n",
      "Loss on test= 0.01120123453438282\n",
      "acc for Lsat= 0.3073034769622609 \n",
      "acc for Psat= 0.2868944460845071 \n",
      "acc for optim= 0.21335990586423478\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.011236431077122688\n",
      "Loss on test= 0.010980646125972271\n",
      "acc for Lsat= 0.2603560685175408 \n",
      "acc for Psat= 0.28294161031088744 \n",
      "acc for optim= 0.180714291182478\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.011274210177361965\n",
      "Loss on test= 0.011333897709846497\n",
      "acc for Lsat= 0.23836628004485377 \n",
      "acc for Psat= 0.3087641561120305 \n",
      "acc for optim= 0.20767717733208366\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.011114994063973427\n",
      "Loss on test= 0.011420699767768383\n",
      "acc for Lsat= 0.28419589344815216 \n",
      "acc for Psat= 0.2800117609138372 \n",
      "acc for optim= 0.19331005193227022\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.011514313519001007\n",
      "Loss on test= 0.010740751400589943\n",
      "acc for Lsat= 0.23736775201595683 \n",
      "acc for Psat= 0.26945135586956404 \n",
      "acc for optim= 0.19978902388283057\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.01092443149536848\n",
      "Loss on test= 0.010986195877194405\n",
      "acc for Lsat= 0.26517831257429814 \n",
      "acc for Psat= 0.28776272166401584 \n",
      "acc for optim= 0.20873879111349122\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.011060379445552826\n",
      "Loss on test= 0.011025488376617432\n",
      "acc for Lsat= 0.2664366671730956 \n",
      "acc for Psat= 0.26777492854287976 \n",
      "acc for optim= 0.20699245097057428\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.011105097830295563\n",
      "Loss on test= 0.010676019825041294\n",
      "acc for Lsat= 0.25301521578354685 \n",
      "acc for Psat= 0.2920062633652501 \n",
      "acc for optim= 0.18242791887707818\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.011247514747083187\n",
      "Loss on test= 0.012887367978692055\n",
      "acc for Lsat= 0.25199239813269203 \n",
      "acc for Psat= 0.3933478090164843 \n",
      "acc for optim= 0.20191935288764667\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.011614474467933178\n",
      "Loss on test= 0.011100471019744873\n",
      "acc for Lsat= 0.23729598885423714 \n",
      "acc for Psat= 0.31229541073057715 \n",
      "acc for optim= 0.18912162371408478\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.011226192116737366\n",
      "Loss on test= 0.010107073001563549\n",
      "acc for Lsat= 0.24235346522060797 \n",
      "acc for Psat= 0.2882479707192475 \n",
      "acc for optim= 0.1909555100039044\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.010745507664978504\n",
      "Loss on test= 0.01043881569057703\n",
      "acc for Lsat= 0.27614762650891617 \n",
      "acc for Psat= 0.2727178574950321 \n",
      "acc for optim= 0.19199094285510443\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.010932818986475468\n",
      "Loss on test= 0.010730862617492676\n",
      "acc for Lsat= 0.282614954763778 \n",
      "acc for Psat= 0.26472845265399536 \n",
      "acc for optim= 0.20329028791309464\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.010806122794747353\n",
      "Loss on test= 0.010634670034050941\n",
      "acc for Lsat= 0.24663626879545691 \n",
      "acc for Psat= 0.2875720757406639 \n",
      "acc for optim= 0.1902105931695415\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.01061619445681572\n",
      "Loss on test= 0.01140732504427433\n",
      "acc for Lsat= 0.23826877524796244 \n",
      "acc for Psat= 0.34332684605111796 \n",
      "acc for optim= 0.18793005046373346\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.011815380305051804\n",
      "Loss on test= 0.01164214313030243\n",
      "acc for Lsat= 0.22952957235581897 \n",
      "acc for Psat= 0.3945319605928317 \n",
      "acc for optim= 0.19869728329357148\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.011468307115137577\n",
      "Loss on test= 0.01093970239162445\n",
      "acc for Lsat= 0.2575960974791087 \n",
      "acc for Psat= 0.2741699343564137 \n",
      "acc for optim= 0.20285886931186897\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.010689581744372845\n",
      "Loss on test= 0.010556865483522415\n",
      "acc for Lsat= 0.24634623226066232 \n",
      "acc for Psat= 0.2881861153132254 \n",
      "acc for optim= 0.1868920549402262\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.010918248444795609\n",
      "Loss on test= 0.010441601276397705\n",
      "acc for Lsat= 0.23514882704939982 \n",
      "acc for Psat= 0.27091480660168893 \n",
      "acc for optim= 0.17988610896508042\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.010829762555658817\n",
      "Loss on test= 0.011742877773940563\n",
      "acc for Lsat= 0.24037930418067058 \n",
      "acc for Psat= 0.34671411051228485 \n",
      "acc for optim= 0.21420737403300213\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.011081494390964508\n",
      "Loss on test= 0.011590231209993362\n",
      "acc for Lsat= 0.23152769231957201 \n",
      "acc for Psat= 0.331411706477288 \n",
      "acc for optim= 0.20233731311816736\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.010932104662060738\n",
      "Loss on test= 0.012005524709820747\n",
      "acc for Lsat= 0.22952463764176098 \n",
      "acc for Psat= 0.37294219182001903 \n",
      "acc for optim= 0.1994168702098545\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.011282114312052727\n",
      "Loss on test= 0.012535668909549713\n",
      "acc for Lsat= 0.24511567678466137 \n",
      "acc for Psat= 0.4075258978047861 \n",
      "acc for optim= 0.19103854118018077\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.01162270549684763\n",
      "Loss on test= 0.009681661613285542\n",
      "acc for Lsat= 0.26902627947660024 \n",
      "acc for Psat= 0.28564889467245824 \n",
      "acc for optim= 0.1872086646127738\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.010967391543090343\n",
      "Loss on test= 0.01130540668964386\n",
      "acc for Lsat= 0.299035710498936 \n",
      "acc for Psat= 0.26390224592398376 \n",
      "acc for optim= 0.19238365210775235\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.010699321515858173\n",
      "Loss on test= 0.010689247399568558\n",
      "acc for Lsat= 0.2236764025775129 \n",
      "acc for Psat= 0.25005659701668803 \n",
      "acc for optim= 0.18761135787290922\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.010793672874569893\n",
      "Loss on test= 0.010156666859984398\n",
      "acc for Lsat= 0.2396888679146729 \n",
      "acc for Psat= 0.26194523401598513 \n",
      "acc for optim= 0.18968854150679781\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.01061964500695467\n",
      "Loss on test= 0.010340644046664238\n",
      "acc for Lsat= 0.2298864901243399 \n",
      "acc for Psat= 0.2973439031480371 \n",
      "acc for optim= 0.20145232361765747\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.01042412780225277\n",
      "Loss on test= 0.010537812486290932\n",
      "acc for Lsat= 0.25835604336178813 \n",
      "acc for Psat= 0.26870381121310905 \n",
      "acc for optim= 0.19549445127258142\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.010386432521045208\n",
      "Loss on test= 0.010192007757723331\n",
      "acc for Lsat= 0.25061087194282317 \n",
      "acc for Psat= 0.2603921911838886 \n",
      "acc for optim= 0.1902198410619324\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.010376556776463985\n",
      "Loss on test= 0.01044311560690403\n",
      "acc for Lsat= 0.24311046283165105 \n",
      "acc for Psat= 0.2620330431138329 \n",
      "acc for optim= 0.21257592707626974\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.010934029705822468\n",
      "Loss on test= 0.010755662806332111\n",
      "acc for Lsat= 0.25316342396537356 \n",
      "acc for Psat= 0.2683413404797525 \n",
      "acc for optim= 0.20025364634234025\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.010756591334939003\n",
      "Loss on test= 0.010320935398340225\n",
      "acc for Lsat= 0.27128614600145295 \n",
      "acc for Psat= 0.26680380094645395 \n",
      "acc for optim= 0.19615048776196656\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.010979714803397655\n",
      "Loss on test= 0.010399052873253822\n",
      "acc for Lsat= 0.2535765956756124 \n",
      "acc for Psat= 0.2773960551691031 \n",
      "acc for optim= 0.20003386012221863\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.011291449889540672\n",
      "Loss on test= 0.009998909197747707\n",
      "acc for Lsat= 0.23378373469018401 \n",
      "acc for Psat= 0.28692490162762085 \n",
      "acc for optim= 0.1899327699673056\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.010281386785209179\n",
      "Loss on test= 0.010028895922005177\n",
      "acc for Lsat= 0.23942956269752705 \n",
      "acc for Psat= 0.26601058771327213 \n",
      "acc for optim= 0.1995217344796205\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.010599100030958652\n",
      "Loss on test= 0.010020324029028416\n",
      "acc for Lsat= 0.22330409546683203 \n",
      "acc for Psat= 0.29519000763104636 \n",
      "acc for optim= 0.18801910757099757\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.010127374902367592\n",
      "Loss on test= 0.010122716426849365\n",
      "acc for Lsat= 0.22975425130819013 \n",
      "acc for Psat= 0.3049405916315516 \n",
      "acc for optim= 0.1986072283130803\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.010392088443040848\n",
      "Loss on test= 0.010130482725799084\n",
      "acc for Lsat= 0.2221815741543872 \n",
      "acc for Psat= 0.25346599605718684 \n",
      "acc for optim= 0.1881936752332557\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.010257648304104805\n",
      "Loss on test= 0.010580820962786674\n",
      "acc for Lsat= 0.21412230827106238 \n",
      "acc for Psat= 0.2975802124622262 \n",
      "acc for optim= 0.19553466976602166\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.010943000204861164\n",
      "Loss on test= 0.009852370247244835\n",
      "acc for Lsat= 0.23335373290700698 \n",
      "acc for Psat= 0.2647006342748731 \n",
      "acc for optim= 0.2031089316699984\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.010460379533469677\n",
      "Loss on test= 0.00975735578685999\n",
      "acc for Lsat= 0.23679921996389985 \n",
      "acc for Psat= 0.2678330628896711 \n",
      "acc for optim= 0.18856636990976522\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.010568913072347641\n",
      "Loss on test= 0.010037006810307503\n",
      "acc for Lsat= 0.22816423233382158 \n",
      "acc for Psat= 0.2870576324616244 \n",
      "acc for optim= 0.18651352119008693\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.010418894700706005\n",
      "Loss on test= 0.010299930348992348\n",
      "acc for Lsat= 0.2502522122577412 \n",
      "acc for Psat= 0.24797263676127596 \n",
      "acc for optim= 0.18813797001004443\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.010237477719783783\n",
      "Loss on test= 0.010003693401813507\n",
      "acc for Lsat= 0.26453355241274285 \n",
      "acc for Psat= 0.2559673765704124 \n",
      "acc for optim= 0.18310121870112\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.010315949097275734\n",
      "Loss on test= 0.010054185055196285\n",
      "acc for Lsat= 0.21893036342216138 \n",
      "acc for Psat= 0.3225747428603771 \n",
      "acc for optim= 0.19613855185063486\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.010217193514108658\n",
      "Loss on test= 0.01028594933450222\n",
      "acc for Lsat= 0.23576476306393365 \n",
      "acc for Psat= 0.2504912515098506 \n",
      "acc for optim= 0.17829680043345236\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.010116029530763626\n",
      "Loss on test= 0.00946230161935091\n",
      "acc for Lsat= 0.2341053293564835 \n",
      "acc for Psat= 0.2712278594763857 \n",
      "acc for optim= 0.18611895532455025\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.009946486912667751\n",
      "Loss on test= 0.009698571637272835\n",
      "acc for Lsat= 0.220390311352251 \n",
      "acc for Psat= 0.2800703767952163 \n",
      "acc for optim= 0.1945012858447405\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.010029347613453865\n",
      "Loss on test= 0.009673732332885265\n",
      "acc for Lsat= 0.2252926592553047 \n",
      "acc for Psat= 0.2675633095700382 \n",
      "acc for optim= 0.19184303406438777\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.010105998255312443\n",
      "Loss on test= 0.009684636257588863\n",
      "acc for Lsat= 0.215665440877028 \n",
      "acc for Psat= 0.2845681736350368 \n",
      "acc for optim= 0.19085894489575908\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.009948331862688065\n",
      "Loss on test= 0.009748962707817554\n",
      "acc for Lsat= 0.21964000351176396 \n",
      "acc for Psat= 0.2799359803126159 \n",
      "acc for optim= 0.21399049455853733\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.009975780732929707\n",
      "Loss on test= 0.010009470395743847\n",
      "acc for Lsat= 0.20082347408626103 \n",
      "acc for Psat= 0.2906544047440597 \n",
      "acc for optim= 0.18279555289916824\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.009985319338738918\n",
      "Loss on test= 0.009568276815116405\n",
      "acc for Lsat= 0.21022683832740546 \n",
      "acc for Psat= 0.28771722513743414 \n",
      "acc for optim= 0.18417242925966706\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.009676499292254448\n",
      "Loss on test= 0.009554299525916576\n",
      "acc for Lsat= 0.2109625999544585 \n",
      "acc for Psat= 0.25004612477671284 \n",
      "acc for optim= 0.19130218959990825\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.00989274401217699\n",
      "Loss on test= 0.010865655727684498\n",
      "acc for Lsat= 0.30127767266979366 \n",
      "acc for Psat= 0.24149883347276832 \n",
      "acc for optim= 0.22150128388288115\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.009923509322106838\n",
      "Loss on test= 0.009139027446508408\n",
      "acc for Lsat= 0.23734688372634402 \n",
      "acc for Psat= 0.26344487113513154 \n",
      "acc for optim= 0.19549880655894586\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.009553728625178337\n",
      "Loss on test= 0.009242287836968899\n",
      "acc for Lsat= 0.22934424170297635 \n",
      "acc for Psat= 0.2672467920142603 \n",
      "acc for optim= 0.19478835691218074\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.009780136868357658\n",
      "Loss on test= 0.010189642198383808\n",
      "acc for Lsat= 0.21894744734871327 \n",
      "acc for Psat= 0.27425463071385575 \n",
      "acc for optim= 0.21609955169992032\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.009706626646220684\n",
      "Loss on test= 0.009503573179244995\n",
      "acc for Lsat= 0.21115508111708206 \n",
      "acc for Psat= 0.2618154286151981 \n",
      "acc for optim= 0.18276046892660325\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.009711994789540768\n",
      "Loss on test= 0.010202253237366676\n",
      "acc for Lsat= 0.2497304071443363 \n",
      "acc for Psat= 0.23623412641864963 \n",
      "acc for optim= 0.18922868077454433\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.0099162757396698\n",
      "Loss on test= 0.009379256516695023\n",
      "acc for Lsat= 0.23773039393661846 \n",
      "acc for Psat= 0.2511989700299612 \n",
      "acc for optim= 0.19340919677680987\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.010166730731725693\n",
      "Loss on test= 0.009672089479863644\n",
      "acc for Lsat= 0.210514670930393 \n",
      "acc for Psat= 0.24878061438593668 \n",
      "acc for optim= 0.17505743813416227\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.00955964345484972\n",
      "Loss on test= 0.010329420678317547\n",
      "acc for Lsat= 0.19469740257733753 \n",
      "acc for Psat= 0.3218531304084683 \n",
      "acc for optim= 0.18993424106903714\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.010085754096508026\n",
      "Loss on test= 0.00898132473230362\n",
      "acc for Lsat= 0.2060105838937562 \n",
      "acc for Psat= 0.27326338631266134 \n",
      "acc for optim= 0.18895151184767964\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.009650125168263912\n",
      "Loss on test= 0.009227994829416275\n",
      "acc for Lsat= 0.2406601802873853 \n",
      "acc for Psat= 0.2582795418331099 \n",
      "acc for optim= 0.1866657937050174\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.009737400338053703\n",
      "Loss on test= 0.00939888134598732\n",
      "acc for Lsat= 0.23731960572056138 \n",
      "acc for Psat= 0.24820203613543945 \n",
      "acc for optim= 0.18570407362327584\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.009635783731937408\n",
      "Loss on test= 0.011789090931415558\n",
      "acc for Lsat= 0.3613914467608796 \n",
      "acc for Psat= 0.2622523794640516 \n",
      "acc for optim= 0.19219963761625458\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.01000884734094143\n",
      "Loss on test= 0.009564432315528393\n",
      "acc for Lsat= 0.2068025403246252 \n",
      "acc for Psat= 0.25097916749891247 \n",
      "acc for optim= 0.18582042913240493\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.009625352919101715\n",
      "Loss on test= 0.008877424523234367\n",
      "acc for Lsat= 0.20874908318384425 \n",
      "acc for Psat= 0.2614811515641737 \n",
      "acc for optim= 0.2012343041892195\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.009711913764476776\n",
      "Loss on test= 0.009779440239071846\n",
      "acc for Lsat= 0.19801146212164503 \n",
      "acc for Psat= 0.27663728766522067 \n",
      "acc for optim= 0.18739544923458173\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.009625696577131748\n",
      "Loss on test= 0.008770585060119629\n",
      "acc for Lsat= 0.20743074086026722 \n",
      "acc for Psat= 0.25855171824081774 \n",
      "acc for optim= 0.1767243167241513\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.009671280160546303\n",
      "Loss on test= 0.00961454026401043\n",
      "acc for Lsat= 0.26892471932749046 \n",
      "acc for Psat= 0.22324520071482323 \n",
      "acc for optim= 0.20441729472489945\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.009881194680929184\n",
      "Loss on test= 0.009846684522926807\n",
      "acc for Lsat= 0.26373332383008274 \n",
      "acc for Psat= 0.23143097484481168 \n",
      "acc for optim= 0.18543222178453328\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.009489270858466625\n",
      "Loss on test= 0.008935864083468914\n",
      "acc for Lsat= 0.20427537142392327 \n",
      "acc for Psat= 0.25239819353462095 \n",
      "acc for optim= 0.20614396972283627\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.009410742670297623\n",
      "Loss on test= 0.009195168502628803\n",
      "acc for Lsat= 0.21694783358740294 \n",
      "acc for Psat= 0.2521769439734124 \n",
      "acc for optim= 0.17682952916161535\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.009479023516178131\n",
      "Loss on test= 0.008962267078459263\n",
      "acc for Lsat= 0.20916910607303255 \n",
      "acc for Psat= 0.24915684809211353 \n",
      "acc for optim= 0.19567831711783829\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.00975362304598093\n",
      "Loss on test= 0.009701685979962349\n",
      "acc for Lsat= 0.24723421650658664 \n",
      "acc for Psat= 0.24963430179254706 \n",
      "acc for optim= 0.19020798641006853\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.010028325021266937\n",
      "Loss on test= 0.009053078480064869\n",
      "acc for Lsat= 0.21582767409995848 \n",
      "acc for Psat= 0.2555400272438026 \n",
      "acc for optim= 0.1962659094113258\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.009375824593007565\n",
      "Loss on test= 0.009111317805945873\n",
      "acc for Lsat= 0.23698103504186194 \n",
      "acc for Psat= 0.2446191413363571 \n",
      "acc for optim= 0.18818657688884619\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.009865021333098412\n",
      "Loss on test= 0.009253463707864285\n",
      "acc for Lsat= 0.24201871917545292 \n",
      "acc for Psat= 0.23901357447470514 \n",
      "acc for optim= 0.19967125763021712\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.009372882544994354\n",
      "Loss on test= 0.010764147154986858\n",
      "acc for Lsat= 0.2528266487464665 \n",
      "acc for Psat= 0.25895643866985935 \n",
      "acc for optim= 0.1882528197437185\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.009573590941727161\n",
      "Loss on test= 0.00858411192893982\n",
      "acc for Lsat= 0.19187653790556175 \n",
      "acc for Psat= 0.24256071249594144 \n",
      "acc for optim= 0.1913159337014509\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.009320086799561977\n",
      "Loss on test= 0.008932352066040039\n",
      "acc for Lsat= 0.22558449658744567 \n",
      "acc for Psat= 0.23701356488143918 \n",
      "acc for optim= 0.1884215375301554\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.00911620445549488\n",
      "Loss on test= 0.009058757685124874\n",
      "acc for Lsat= 0.20983168469322394 \n",
      "acc for Psat= 0.23192630866636849 \n",
      "acc for optim= 0.18937184627606798\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.009246432222425938\n",
      "Loss on test= 0.008692792616784573\n",
      "acc for Lsat= 0.19641922990833977 \n",
      "acc for Psat= 0.25302537202367453 \n",
      "acc for optim= 0.19629621170335323\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.009187709540128708\n",
      "Loss on test= 0.009010281413793564\n",
      "acc for Lsat= 0.2022305474216606 \n",
      "acc for Psat= 0.24433399231674155 \n",
      "acc for optim= 0.17271450760410909\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.00953264907002449\n",
      "Loss on test= 0.008671998977661133\n",
      "acc for Lsat= 0.1979669917774437 \n",
      "acc for Psat= 0.24036829033079934 \n",
      "acc for optim= 0.18169509563272554\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.008839920163154602\n",
      "Loss on test= 0.008879301138222218\n",
      "acc for Lsat= 0.19933743590238895 \n",
      "acc for Psat= 0.26808384514800776 \n",
      "acc for optim= 0.18566984386101515\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.009059485048055649\n",
      "Loss on test= 0.009283489547669888\n",
      "acc for Lsat= 0.23173786887648906 \n",
      "acc for Psat= 0.23137645265150414 \n",
      "acc for optim= 0.18619313203888285\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.009338262490928173\n",
      "Loss on test= 0.00886516459286213\n",
      "acc for Lsat= 0.24605648805752295 \n",
      "acc for Psat= 0.2478668883091273 \n",
      "acc for optim= 0.19844158915632737\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.009957512840628624\n",
      "Loss on test= 0.009747299365699291\n",
      "acc for Lsat= 0.24003778355600425 \n",
      "acc for Psat= 0.23795646602033033 \n",
      "acc for optim= 0.18638587423059083\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.009636811912059784\n",
      "Loss on test= 0.008682558313012123\n",
      "acc for Lsat= 0.22493035788175877 \n",
      "acc for Psat= 0.23908567990056817 \n",
      "acc for optim= 0.19221314889010327\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.009697658009827137\n",
      "Loss on test= 0.009568615816533566\n",
      "acc for Lsat= 0.1900554126092371 \n",
      "acc for Psat= 0.22870679952265582 \n",
      "acc for optim= 0.18990572590956692\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.00928610097616911\n",
      "Loss on test= 0.008665749803185463\n",
      "acc for Lsat= 0.19362344635560844 \n",
      "acc for Psat= 0.21872748430610658 \n",
      "acc for optim= 0.19210758850975843\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.008989806286990643\n",
      "Loss on test= 0.008289894089102745\n",
      "acc for Lsat= 0.20092657399820038 \n",
      "acc for Psat= 0.22062374062915222 \n",
      "acc for optim= 0.1780438484290514\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.009230416268110275\n",
      "Loss on test= 0.008163360878825188\n",
      "acc for Lsat= 0.1744481506375942 \n",
      "acc for Psat= 0.24335335869998104 \n",
      "acc for optim= 0.19430919421948428\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.009151327423751354\n",
      "Loss on test= 0.009136280976235867\n",
      "acc for Lsat= 0.22462913218520486 \n",
      "acc for Psat= 0.22462059269191986 \n",
      "acc for optim= 0.19527047222564342\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.009011588990688324\n",
      "Loss on test= 0.008841042406857014\n",
      "acc for Lsat= 0.19498725059678987 \n",
      "acc for Psat= 0.22597238568532457 \n",
      "acc for optim= 0.18524037976631252\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.008668744005262852\n",
      "Loss on test= 0.008843421936035156\n",
      "acc for Lsat= 0.18767186357089904 \n",
      "acc for Psat= 0.245049927892585 \n",
      "acc for optim= 0.18558605236191666\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.00886222068220377\n",
      "Loss on test= 0.008693990297615528\n",
      "acc for Lsat= 0.20481233375825025 \n",
      "acc for Psat= 0.24056913358091717 \n",
      "acc for optim= 0.18338630845922838\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.009210101328790188\n",
      "Loss on test= 0.008868568576872349\n",
      "acc for Lsat= 0.19183337093135058 \n",
      "acc for Psat= 0.26119543941761525 \n",
      "acc for optim= 0.18835324011790264\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.009277028031647205\n",
      "Loss on test= 0.008218678645789623\n",
      "acc for Lsat= 0.1803291599016292 \n",
      "acc for Psat= 0.21863097854975422 \n",
      "acc for optim= 0.1817716552293466\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.008721768856048584\n",
      "Loss on test= 0.00807039812207222\n",
      "acc for Lsat= 0.17933460080215857 \n",
      "acc for Psat= 0.23270330396533953 \n",
      "acc for optim= 0.18627832440395994\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.009070388972759247\n",
      "Loss on test= 0.009083651937544346\n",
      "acc for Lsat= 0.2573010522832487 \n",
      "acc for Psat= 0.23525444069044268 \n",
      "acc for optim= 0.18779824951677773\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.009217416867613792\n",
      "Loss on test= 0.008691275492310524\n",
      "acc for Lsat= 0.20219480790743743 \n",
      "acc for Psat= 0.22095261643187622 \n",
      "acc for optim= 0.1759867234544111\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.008565432392060757\n",
      "Loss on test= 0.008488776162266731\n",
      "acc for Lsat= 0.19893078133227882 \n",
      "acc for Psat= 0.22663295238119127 \n",
      "acc for optim= 0.18410465914476426\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.00854078121483326\n",
      "Loss on test= 0.00851314328610897\n",
      "acc for Lsat= 0.19186894498643842 \n",
      "acc for Psat= 0.23049350515577463 \n",
      "acc for optim= 0.1787966453412082\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.0084626954048872\n",
      "Loss on test= 0.008984535001218319\n",
      "acc for Lsat= 0.19726261170809586 \n",
      "acc for Psat= 0.2670863085651355 \n",
      "acc for optim= 0.18600347673133444\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.008675812743604183\n",
      "Loss on test= 0.00834402535110712\n",
      "acc for Lsat= 0.187710665262342 \n",
      "acc for Psat= 0.22926527288006116 \n",
      "acc for optim= 0.18985929140408925\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.008389048278331757\n",
      "Loss on test= 0.008843325078487396\n",
      "acc for Lsat= 0.19896370558991613 \n",
      "acc for Psat= 0.22916131630484882 \n",
      "acc for optim= 0.20327747904387228\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.008725868538022041\n",
      "Loss on test= 0.009192785248160362\n",
      "acc for Lsat= 0.17739742334044814 \n",
      "acc for Psat= 0.2751418495119307 \n",
      "acc for optim= 0.1822349332981724\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.008774311281740665\n",
      "Loss on test= 0.008483773097395897\n",
      "acc for Lsat= 0.1730857655827549 \n",
      "acc for Psat= 0.217043840344657 \n",
      "acc for optim= 0.19004690493700863\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.008277150802314281\n",
      "Loss on test= 0.007986453361809254\n",
      "acc for Lsat= 0.18475097802513266 \n",
      "acc for Psat= 0.22897122418893362 \n",
      "acc for optim= 0.18948563725634077\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.008237635716795921\n",
      "Loss on test= 0.008073708973824978\n",
      "acc for Lsat= 0.19051565084545646 \n",
      "acc for Psat= 0.21128049568112664 \n",
      "acc for optim= 0.1806425719399625\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.008283550851047039\n",
      "Loss on test= 0.007951900362968445\n",
      "acc for Lsat= 0.19660024332876452 \n",
      "acc for Psat= 0.2320713274632392 \n",
      "acc for optim= 0.1819038909309932\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.008812128566205502\n",
      "Loss on test= 0.008955561555922031\n",
      "acc for Lsat= 0.19784324998800987 \n",
      "acc for Psat= 0.29757652957207914 \n",
      "acc for optim= 0.1892522013159406\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.008805109187960625\n",
      "Loss on test= 0.00817418284714222\n",
      "acc for Lsat= 0.19386096842434788 \n",
      "acc for Psat= 0.21698236664677686 \n",
      "acc for optim= 0.18411905527407085\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.00867691170424223\n",
      "Loss on test= 0.009873923845589161\n",
      "acc for Lsat= 0.2481066808356224 \n",
      "acc for Psat= 0.23668927550543967 \n",
      "acc for optim= 0.18204812986014812\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.009524301625788212\n",
      "Loss on test= 0.0090903639793396\n",
      "acc for Lsat= 0.18624781253527398 \n",
      "acc for Psat= 0.2866602741115777 \n",
      "acc for optim= 0.1975717202274953\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.008839117363095284\n",
      "Loss on test= 0.00827694684267044\n",
      "acc for Lsat= 0.17974274400984466 \n",
      "acc for Psat= 0.22274138369912916 \n",
      "acc for optim= 0.18055497392452782\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.008670513518154621\n",
      "Loss on test= 0.00832989253103733\n",
      "acc for Lsat= 0.18419363277044376 \n",
      "acc for Psat= 0.22538509131590143 \n",
      "acc for optim= 0.20523776412188158\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.008702822960913181\n",
      "Loss on test= 0.008701417595148087\n",
      "acc for Lsat= 0.16634528907653057 \n",
      "acc for Psat= 0.24095052167885533 \n",
      "acc for optim= 0.19656549898039932\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.008479392156004906\n",
      "Loss on test= 0.008901706896722317\n",
      "acc for Lsat= 0.18252027086753123 \n",
      "acc for Psat= 0.2506985111740997 \n",
      "acc for optim= 0.18585125853762194\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.008413600735366344\n",
      "Loss on test= 0.00782708264887333\n",
      "acc for Lsat= 0.19418913766708715 \n",
      "acc for Psat= 0.22380693509075097 \n",
      "acc for optim= 0.18768125278310854\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.008255296386778355\n",
      "Loss on test= 0.007285141386091709\n",
      "acc for Lsat= 0.17687160269407606 \n",
      "acc for Psat= 0.22506031310144495 \n",
      "acc for optim= 0.1893900128788782\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.008682511746883392\n",
      "Loss on test= 0.00923265889286995\n",
      "acc for Lsat= 0.1885657259923834 \n",
      "acc for Psat= 0.27992180604377537 \n",
      "acc for optim= 0.18853719774228553\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.009586939588189125\n",
      "Loss on test= 0.008151407353579998\n",
      "acc for Lsat= 0.16933265707779652 \n",
      "acc for Psat= 0.21266060094800393 \n",
      "acc for optim= 0.17836977288105707\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.00922930147498846\n",
      "Loss on test= 0.008188948035240173\n",
      "acc for Lsat= 0.16734712850381117 \n",
      "acc for Psat= 0.2401146110278205 \n",
      "acc for optim= 0.19155898550446648\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.008587750606238842\n",
      "Loss on test= 0.007727120537310839\n",
      "acc for Lsat= 0.17661338271205454 \n",
      "acc for Psat= 0.2189793101282998 \n",
      "acc for optim= 0.18490270371006085\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.008689853362739086\n",
      "Loss on test= 0.008963151834905148\n",
      "acc for Lsat= 0.17672106583140212 \n",
      "acc for Psat= 0.22772284426261918 \n",
      "acc for optim= 0.17880631213759174\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.008655327372252941\n",
      "Loss on test= 0.007405023090541363\n",
      "acc for Lsat= 0.18659044930560365 \n",
      "acc for Psat= 0.20787236425629188 \n",
      "acc for optim= 0.18883227558104113\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.008381767198443413\n",
      "Loss on test= 0.007582264952361584\n",
      "acc for Lsat= 0.17259582155526693 \n",
      "acc for Psat= 0.2222356136043763 \n",
      "acc for optim= 0.19017968480703357\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.00832741241902113\n",
      "Loss on test= 0.0074643236584961414\n",
      "acc for Lsat= 0.15524276239414797 \n",
      "acc for Psat= 0.2247584217972896 \n",
      "acc for optim= 0.1799010623331383\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.008370806463062763\n",
      "Loss on test= 0.008356464095413685\n",
      "acc for Lsat= 0.2391140531613633 \n",
      "acc for Psat= 0.22025461813176958 \n",
      "acc for optim= 0.19388597656821682\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.00841858796775341\n",
      "Loss on test= 0.007765201386064291\n",
      "acc for Lsat= 0.15883996913436096 \n",
      "acc for Psat= 0.21610287895384464 \n",
      "acc for optim= 0.1791909333055751\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.008140846155583858\n",
      "Loss on test= 0.00857746321707964\n",
      "acc for Lsat= 0.18705907009398043 \n",
      "acc for Psat= 0.22323659753680192 \n",
      "acc for optim= 0.18348639789513294\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.008340306580066681\n",
      "Loss on test= 0.008853121660649776\n",
      "acc for Lsat= 0.23613010189335518 \n",
      "acc for Psat= 0.21785967041501567 \n",
      "acc for optim= 0.17364305236126687\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.008361279033124447\n",
      "Loss on test= 0.008039625361561775\n",
      "acc for Lsat= 0.19709277246029405 \n",
      "acc for Psat= 0.2241920265860736 \n",
      "acc for optim= 0.1883779601799639\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.007945817895233631\n",
      "Loss on test= 0.007914029061794281\n",
      "acc for Lsat= 0.16926268053577734 \n",
      "acc for Psat= 0.2211255175378741 \n",
      "acc for optim= 0.1793729302798228\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.008160032331943512\n",
      "Loss on test= 0.007401119917631149\n",
      "acc for Lsat= 0.1639202709146146 \n",
      "acc for Psat= 0.21407085267207082 \n",
      "acc for optim= 0.18282670653118388\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.008052151650190353\n",
      "Loss on test= 0.00792574230581522\n",
      "acc for Lsat= 0.15309819237695224 \n",
      "acc for Psat= 0.23080151647536695 \n",
      "acc for optim= 0.19173631646727035\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.008154787123203278\n",
      "Loss on test= 0.007760265376418829\n",
      "acc for Lsat= 0.17082894381294594 \n",
      "acc for Psat= 0.19944163132973897 \n",
      "acc for optim= 0.17856686181275527\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.008258145302534103\n",
      "Loss on test= 0.00875393208116293\n",
      "acc for Lsat= 0.2211951421458916 \n",
      "acc for Psat= 0.22902555238751293 \n",
      "acc for optim= 0.1828433351152312\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.008482743054628372\n",
      "Loss on test= 0.008200818672776222\n",
      "acc for Lsat= 0.18330140688576158 \n",
      "acc for Psat= 0.21314251729792297 \n",
      "acc for optim= 0.18392872113130382\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.00802521500736475\n",
      "Loss on test= 0.007509502116590738\n",
      "acc for Lsat= 0.17365280638992123 \n",
      "acc for Psat= 0.20767816976286987 \n",
      "acc for optim= 0.17772142021243093\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.00782517809420824\n",
      "Loss on test= 0.0075434609316289425\n",
      "acc for Lsat= 0.14656212457658832 \n",
      "acc for Psat= 0.22260964969540806 \n",
      "acc for optim= 0.17903049677615118\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.00792001374065876\n",
      "Loss on test= 0.008112648501992226\n",
      "acc for Lsat= 0.17712548955711788 \n",
      "acc for Psat= 0.2426601119344972 \n",
      "acc for optim= 0.18047605014352658\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.008181966841220856\n",
      "Loss on test= 0.008272412233054638\n",
      "acc for Lsat= 0.16449854700516192 \n",
      "acc for Psat= 0.2356557636383489 \n",
      "acc for optim= 0.18673258598718767\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.00857518333941698\n",
      "Loss on test= 0.009224271401762962\n",
      "acc for Lsat= 0.16374354326241725 \n",
      "acc for Psat= 0.24663805783682227 \n",
      "acc for optim= 0.1972541767166616\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.008226659148931503\n",
      "Loss on test= 0.007844721898436546\n",
      "acc for Lsat= 0.14983663118256438 \n",
      "acc for Psat= 0.2404137046510555 \n",
      "acc for optim= 0.18272054072696012\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.008328917436301708\n",
      "Loss on test= 0.007656495086848736\n",
      "acc for Lsat= 0.16519548026376837 \n",
      "acc for Psat= 0.21147423771971435 \n",
      "acc for optim= 0.19141218360203532\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.008229248225688934\n",
      "Loss on test= 0.007841361686587334\n",
      "acc for Lsat= 0.14450659929413656 \n",
      "acc for Psat= 0.20471757770635146 \n",
      "acc for optim= 0.2050548369270227\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.007770182099193335\n",
      "Loss on test= 0.007937127724289894\n",
      "acc for Lsat= 0.15979189045980535 \n",
      "acc for Psat= 0.21852893121949574 \n",
      "acc for optim= 0.17815379193780245\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.008164825849235058\n",
      "Loss on test= 0.007588348817080259\n",
      "acc for Lsat= 0.1517975844874584 \n",
      "acc for Psat= 0.27549265337418893 \n",
      "acc for optim= 0.18399195878711563\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.007793472148478031\n",
      "Loss on test= 0.007713756058365107\n",
      "acc for Lsat= 0.17452315298910312 \n",
      "acc for Psat= 0.2168884284808489 \n",
      "acc for optim= 0.2038649230650933\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.007910048589110374\n",
      "Loss on test= 0.007790382020175457\n",
      "acc for Lsat= 0.15989844110643003 \n",
      "acc for Psat= 0.2128616488150107 \n",
      "acc for optim= 0.18722972019286072\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.007673679385334253\n",
      "Loss on test= 0.007553327828645706\n",
      "acc for Lsat= 0.14734317710394249 \n",
      "acc for Psat= 0.21888750728155443 \n",
      "acc for optim= 0.18084778904449195\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.007927746511995792\n",
      "Loss on test= 0.007145966403186321\n",
      "acc for Lsat= 0.1688165676680148 \n",
      "acc for Psat= 0.21713636849282822 \n",
      "acc for optim= 0.1828017691416765\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.007785238791257143\n",
      "Loss on test= 0.008833416737616062\n",
      "acc for Lsat= 0.17750876323564602 \n",
      "acc for Psat= 0.2965031561750063 \n",
      "acc for optim= 0.18649806619450338\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.008164464496076107\n",
      "Loss on test= 0.00745871989056468\n",
      "acc for Lsat= 0.14652465312886037 \n",
      "acc for Psat= 0.205424171897952 \n",
      "acc for optim= 0.1803965363970083\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.0077975038439035416\n",
      "Loss on test= 0.007420076057314873\n",
      "acc for Lsat= 0.15652000437861519 \n",
      "acc for Psat= 0.2138189108746529 \n",
      "acc for optim= 0.17940035032734158\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.008110954426229\n",
      "Loss on test= 0.00845811702311039\n",
      "acc for Lsat= 0.20263450731943375 \n",
      "acc for Psat= 0.22290024957446558 \n",
      "acc for optim= 0.18702634434000198\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.008603298105299473\n",
      "Loss on test= 0.009586945176124573\n",
      "acc for Lsat= 0.24412807435539827 \n",
      "acc for Psat= 0.22818051258493782 \n",
      "acc for optim= 0.18675769828110492\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.009061327204108238\n",
      "Loss on test= 0.008723999373614788\n",
      "acc for Lsat= 0.21490399198916527 \n",
      "acc for Psat= 0.22563225428756276 \n",
      "acc for optim= 0.17873021727024713\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.008144727908074856\n",
      "Loss on test= 0.007707185111939907\n",
      "acc for Lsat= 0.16354995469594763 \n",
      "acc for Psat= 0.2432724987618811 \n",
      "acc for optim= 0.18760818097861548\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.007896660827100277\n",
      "Loss on test= 0.007061412092298269\n",
      "acc for Lsat= 0.1526408520599157 \n",
      "acc for Psat= 0.19915292277447233 \n",
      "acc for optim= 0.1788499702522893\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.007643408607691526\n",
      "Loss on test= 0.007291077170521021\n",
      "acc for Lsat= 0.19296039452657734 \n",
      "acc for Psat= 0.19910424115799263 \n",
      "acc for optim= 0.18081888887831452\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.00802637543529272\n",
      "Loss on test= 0.007275564596056938\n",
      "acc for Lsat= 0.17028969857917242 \n",
      "acc for Psat= 0.21237449560905244 \n",
      "acc for optim= 0.18362179853461016\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.008013118989765644\n",
      "Loss on test= 0.008090212941169739\n",
      "acc for Lsat= 0.17443023945700564 \n",
      "acc for Psat= 0.20381462433237374 \n",
      "acc for optim= 0.1880547399058422\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.008174307644367218\n",
      "Loss on test= 0.007921569049358368\n",
      "acc for Lsat= 0.19652463416580734 \n",
      "acc for Psat= 0.2059147667762748 \n",
      "acc for optim= 0.18489889978140914\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.007884806953370571\n",
      "Loss on test= 0.007672698237001896\n",
      "acc for Lsat= 0.17170765794848242 \n",
      "acc for Psat= 0.2059806683688736 \n",
      "acc for optim= 0.1854941015673732\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.0075736031867563725\n",
      "Loss on test= 0.007455003447830677\n",
      "acc for Lsat= 0.14614614659933214 \n",
      "acc for Psat= 0.1958189403167863 \n",
      "acc for optim= 0.17937141023820594\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.007575821131467819\n",
      "Loss on test= 0.0073913224041461945\n",
      "acc for Lsat= 0.1542885944719593 \n",
      "acc for Psat= 0.19464209775744806 \n",
      "acc for optim= 0.17356891024443227\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.007648642174899578\n",
      "Loss on test= 0.00751706724986434\n",
      "acc for Lsat= 0.16749483112692581 \n",
      "acc for Psat= 0.2352733233018552 \n",
      "acc for optim= 0.19349904848196595\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.007986127398908138\n",
      "Loss on test= 0.007514936849474907\n",
      "acc for Lsat= 0.16193750531277368 \n",
      "acc for Psat= 0.20213820904019805 \n",
      "acc for optim= 0.18316555811661356\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.007834465242922306\n",
      "Loss on test= 0.0073906658217310905\n",
      "acc for Lsat= 0.1525785194737821 \n",
      "acc for Psat= 0.20882680792419706 \n",
      "acc for optim= 0.17871258748955615\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.008077987469732761\n",
      "Loss on test= 0.007579045370221138\n",
      "acc for Lsat= 0.14564595077752382 \n",
      "acc for Psat= 0.20235630342260166 \n",
      "acc for optim= 0.17778132743869782\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.007836363278329372\n",
      "Loss on test= 0.008428228087723255\n",
      "acc for Lsat= 0.21208545184187666 \n",
      "acc for Psat= 0.2103653518379852 \n",
      "acc for optim= 0.18532205622564968\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.008024122565984726\n",
      "Loss on test= 0.007904273457825184\n",
      "acc for Lsat= 0.17849004360505205 \n",
      "acc for Psat= 0.21352446873503583 \n",
      "acc for optim= 0.18987645797687946\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.007475544698536396\n",
      "Loss on test= 0.007921721786260605\n",
      "acc for Lsat= 0.16823004940001615 \n",
      "acc for Psat= 0.19936250537677944 \n",
      "acc for optim= 0.18353120170146164\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.007683161646127701\n",
      "Loss on test= 0.008100839331746101\n",
      "acc for Lsat= 0.18984190012702742 \n",
      "acc for Psat= 0.20448766588206863 \n",
      "acc for optim= 0.179814609615966\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.007684709969907999\n",
      "Loss on test= 0.007422858849167824\n",
      "acc for Lsat= 0.159466597426807 \n",
      "acc for Psat= 0.21597477367887788 \n",
      "acc for optim= 0.17896214803968669\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.007738998159766197\n",
      "Loss on test= 0.007118308916687965\n",
      "acc for Lsat= 0.16141367024691725 \n",
      "acc for Psat= 0.2010653512402191 \n",
      "acc for optim= 0.18014223175280653\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.00759627390652895\n",
      "Loss on test= 0.0076332190074026585\n",
      "acc for Lsat= 0.16714969082799191 \n",
      "acc for Psat= 0.20491666007905765 \n",
      "acc for optim= 0.18240219256423754\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.007999591529369354\n",
      "Loss on test= 0.007543507497757673\n",
      "acc for Lsat= 0.13551222124688383 \n",
      "acc for Psat= 0.19981703112625837 \n",
      "acc for optim= 0.1879535093590872\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.0078092231415212154\n",
      "Loss on test= 0.007246972527354956\n",
      "acc for Lsat= 0.14834386881950587 \n",
      "acc for Psat= 0.2004191160742045 \n",
      "acc for optim= 0.18040708831874844\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.007618871983140707\n",
      "Loss on test= 0.008122527971863747\n",
      "acc for Lsat= 0.14859580417317841 \n",
      "acc for Psat= 0.2700988140745353 \n",
      "acc for optim= 0.18289209964230493\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.0077810343354940414\n",
      "Loss on test= 0.007545791566371918\n",
      "acc for Lsat= 0.15227312634315976 \n",
      "acc for Psat= 0.2238385034121362 \n",
      "acc for optim= 0.1798052421648675\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.0076479981653392315\n",
      "Loss on test= 0.007640997413545847\n",
      "acc for Lsat= 0.17859295507042663 \n",
      "acc for Psat= 0.21164027551138723 \n",
      "acc for optim= 0.17642447719432264\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.007412442937493324\n",
      "Loss on test= 0.007236198056489229\n",
      "acc for Lsat= 0.15153769010047088 \n",
      "acc for Psat= 0.1963406840608317 \n",
      "acc for optim= 0.185469598625\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.007526406552642584\n",
      "Loss on test= 0.007597701158374548\n",
      "acc for Lsat= 0.1689382287974228 \n",
      "acc for Psat= 0.19692469328780332 \n",
      "acc for optim= 0.1777653841445745\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.007460795808583498\n",
      "Loss on test= 0.007068706676363945\n",
      "acc for Lsat= 0.14428041359516666 \n",
      "acc for Psat= 0.20485620625156634 \n",
      "acc for optim= 0.1877000140587837\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.007763651665300131\n",
      "Loss on test= 0.007370243780314922\n",
      "acc for Lsat= 0.15268135121201537 \n",
      "acc for Psat= 0.20325251617661608 \n",
      "acc for optim= 0.1843382195179033\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.007855658419430256\n",
      "Loss on test= 0.00759399076923728\n",
      "acc for Lsat= 0.1515096368191833 \n",
      "acc for Psat= 0.19651495663374835 \n",
      "acc for optim= 0.18356861119979373\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.007819214835762978\n",
      "Loss on test= 0.008628156036138535\n",
      "acc for Lsat= 0.21902784237455628 \n",
      "acc for Psat= 0.2004821333338859 \n",
      "acc for optim= 0.17271918323004265\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.007916158065199852\n",
      "Loss on test= 0.009040596894919872\n",
      "acc for Lsat= 0.2618133879652698 \n",
      "acc for Psat= 0.236578255210613 \n",
      "acc for optim= 0.17628637279346082\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.0083348099142313\n",
      "Loss on test= 0.008265646174550056\n",
      "acc for Lsat= 0.20083603146171347 \n",
      "acc for Psat= 0.2052690973279233 \n",
      "acc for optim= 0.18401504730669282\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.008264108560979366\n",
      "Loss on test= 0.007819190621376038\n",
      "acc for Lsat= 0.18091508016378438 \n",
      "acc for Psat= 0.2066908104840164 \n",
      "acc for optim= 0.18051250888439008\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.008068826980888844\n",
      "Loss on test= 0.007195635233074427\n",
      "acc for Lsat= 0.15422530123062125 \n",
      "acc for Psat= 0.20078966205314705 \n",
      "acc for optim= 0.1763518149242815\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.007633359171450138\n",
      "Loss on test= 0.007328786421567202\n",
      "acc for Lsat= 0.1426578601639375 \n",
      "acc for Psat= 0.192849042881642 \n",
      "acc for optim= 0.17358839775929605\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.007361247204244137\n",
      "Loss on test= 0.007147316355258226\n",
      "acc for Lsat= 0.14813708836174702 \n",
      "acc for Psat= 0.2113713889390252 \n",
      "acc for optim= 0.1786504677037482\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.007326579187065363\n",
      "Loss on test= 0.00739199249073863\n",
      "acc for Lsat= 0.1444640592275686 \n",
      "acc for Psat= 0.20282768540278698 \n",
      "acc for optim= 0.17660855237822082\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.007409302983433008\n",
      "Loss on test= 0.00796238798648119\n",
      "acc for Lsat= 0.16643814146497077 \n",
      "acc for Psat= 0.19686262611900462 \n",
      "acc for optim= 0.17456625149989613\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.007536302320659161\n",
      "Loss on test= 0.007570241112262011\n",
      "acc for Lsat= 0.2156704326767008 \n",
      "acc for Psat= 0.18995438555312166 \n",
      "acc for optim= 0.18556155228351773\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.007248342968523502\n",
      "Loss on test= 0.0068955752067267895\n",
      "acc for Lsat= 0.13694173159446282 \n",
      "acc for Psat= 0.19315304647819642 \n",
      "acc for optim= 0.17774704006867093\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.007280046120285988\n",
      "Loss on test= 0.007199292071163654\n",
      "acc for Lsat= 0.15759020307293237 \n",
      "acc for Psat= 0.18817947942109123 \n",
      "acc for optim= 0.17629647760268935\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.007726773619651794\n",
      "Loss on test= 0.007551272865384817\n",
      "acc for Lsat= 0.16932499599234024 \n",
      "acc for Psat= 0.1916087202860925 \n",
      "acc for optim= 0.1828206363432007\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.007271831855177879\n",
      "Loss on test= 0.0073628053069114685\n",
      "acc for Lsat= 0.14730478207707778 \n",
      "acc for Psat= 0.1897759535947714 \n",
      "acc for optim= 0.17453775421489734\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.007393199950456619\n",
      "Loss on test= 0.006963058840483427\n",
      "acc for Lsat= 0.14044006101038256 \n",
      "acc for Psat= 0.21453477848145003 \n",
      "acc for optim= 0.18601148024007105\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.007268332410603762\n",
      "Loss on test= 0.0072455327026546\n",
      "acc for Lsat= 0.1502712000224533 \n",
      "acc for Psat= 0.19073876388653377 \n",
      "acc for optim= 0.19367257119360934\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.007597273215651512\n",
      "Loss on test= 0.007336603477597237\n",
      "acc for Lsat= 0.13705151865645815 \n",
      "acc for Psat= 0.19187642050619125 \n",
      "acc for optim= 0.1747793025364371\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.007674164604395628\n",
      "Loss on test= 0.0075612906366586685\n",
      "acc for Lsat= 0.18145204645918203 \n",
      "acc for Psat= 0.19589953582947822 \n",
      "acc for optim= 0.19399330659969663\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.008007428608834743\n",
      "Loss on test= 0.007215060293674469\n",
      "acc for Lsat= 0.1516198907693866 \n",
      "acc for Psat= 0.20000216633402365 \n",
      "acc for optim= 0.17629371469041663\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.007112154737114906\n",
      "Loss on test= 0.006940703839063644\n",
      "acc for Lsat= 0.13549439639722846 \n",
      "acc for Psat= 0.1924632264205217 \n",
      "acc for optim= 0.18390726954987405\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.007214383687824011\n",
      "Loss on test= 0.007314346730709076\n",
      "acc for Lsat= 0.14374273686317374 \n",
      "acc for Psat= 0.1863705971991294 \n",
      "acc for optim= 0.19176430936017455\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.007423589937388897\n",
      "Loss on test= 0.007205617614090443\n",
      "acc for Lsat= 0.14388473989615827 \n",
      "acc for Psat= 0.19441901419948507 \n",
      "acc for optim= 0.18144181140067647\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.0074258665554225445\n",
      "Loss on test= 0.006896187551319599\n",
      "acc for Lsat= 0.13834742000363878 \n",
      "acc for Psat= 0.19353640720411833 \n",
      "acc for optim= 0.195250570322969\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.007237624377012253\n",
      "Loss on test= 0.007674645632505417\n",
      "acc for Lsat= 0.16604572392444006 \n",
      "acc for Psat= 0.20112093989941845 \n",
      "acc for optim= 0.18558556167880777\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.007414412219077349\n",
      "Loss on test= 0.006937969475984573\n",
      "acc for Lsat= 0.1481052555851125 \n",
      "acc for Psat= 0.20351229537344487 \n",
      "acc for optim= 0.17746267276320518\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.0075038764625787735\n",
      "Loss on test= 0.007059209980070591\n",
      "acc for Lsat= 0.13498485135858426 \n",
      "acc for Psat= 0.20619641935489788 \n",
      "acc for optim= 0.17579227820980933\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.007395828142762184\n",
      "Loss on test= 0.008093306794762611\n",
      "acc for Lsat= 0.13729405946356268 \n",
      "acc for Psat= 0.2495265146485385 \n",
      "acc for optim= 0.19344459970797462\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.007537227589637041\n",
      "Loss on test= 0.007400887086987495\n",
      "acc for Lsat= 0.1558767435351517 \n",
      "acc for Psat= 0.19423678359649982 \n",
      "acc for optim= 0.17773028726003612\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.007276374846696854\n",
      "Loss on test= 0.00755331153050065\n",
      "acc for Lsat= 0.17894664087106246 \n",
      "acc for Psat= 0.20463566017814924 \n",
      "acc for optim= 0.17903845601422536\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.0072439853101968765\n",
      "Loss on test= 0.006654196418821812\n",
      "acc for Lsat= 0.16049975503576847 \n",
      "acc for Psat= 0.18575795951206553 \n",
      "acc for optim= 0.18304909757235027\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.007178293075412512\n",
      "Loss on test= 0.007150500081479549\n",
      "acc for Lsat= 0.13855120184126538 \n",
      "acc for Psat= 0.20105640263343072 \n",
      "acc for optim= 0.17716288870606395\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.007370360661298037\n",
      "Loss on test= 0.0068183219991624355\n",
      "acc for Lsat= 0.15190140394150983 \n",
      "acc for Psat= 0.2147565497588083 \n",
      "acc for optim= 0.1812182303478334\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.00763164134696126\n",
      "Loss on test= 0.007123663555830717\n",
      "acc for Lsat= 0.14454423131969266 \n",
      "acc for Psat= 0.1952895011042553 \n",
      "acc for optim= 0.17661516258566415\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.007327954284846783\n",
      "Loss on test= 0.007497349288314581\n",
      "acc for Lsat= 0.1534661997219381 \n",
      "acc for Psat= 0.1884198458066896 \n",
      "acc for optim= 0.1838078116673608\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.0073683918453752995\n",
      "Loss on test= 0.006839243229478598\n",
      "acc for Lsat= 0.1283054722681865 \n",
      "acc for Psat= 0.18484718994767643 \n",
      "acc for optim= 0.175732656497948\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.006929832976311445\n",
      "Loss on test= 0.007091249339282513\n",
      "acc for Lsat= 0.14247295296637102 \n",
      "acc for Psat= 0.19462302392600356 \n",
      "acc for optim= 0.17389196491795528\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.007308411877602339\n",
      "Loss on test= 0.007284053135663271\n",
      "acc for Lsat= 0.13818676653229617 \n",
      "acc for Psat= 0.17691875778522492 \n",
      "acc for optim= 0.17951151419519856\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.0074209957383573055\n",
      "Loss on test= 0.00747471721842885\n",
      "acc for Lsat= 0.15934546037351538 \n",
      "acc for Psat= 0.22057851622938304 \n",
      "acc for optim= 0.17051820409845253\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.007184736896306276\n",
      "Loss on test= 0.006977861747145653\n",
      "acc for Lsat= 0.15827772101673307 \n",
      "acc for Psat= 0.1790069060811515 \n",
      "acc for optim= 0.17515599372406565\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.007494841702282429\n",
      "Loss on test= 0.006913776509463787\n",
      "acc for Lsat= 0.14042142479494843 \n",
      "acc for Psat= 0.20853491859580153 \n",
      "acc for optim= 0.18819067490792535\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.007332906126976013\n",
      "Loss on test= 0.0072950818575918674\n",
      "acc for Lsat= 0.15032169739186896 \n",
      "acc for Psat= 0.20620658153308574 \n",
      "acc for optim= 0.1836968049030622\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.007499985862523317\n",
      "Loss on test= 0.007007083389908075\n",
      "acc for Lsat= 0.14387778054151568 \n",
      "acc for Psat= 0.1939330789625544 \n",
      "acc for optim= 0.1842403839971765\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.00735712144523859\n",
      "Loss on test= 0.007970425300300121\n",
      "acc for Lsat= 0.19419638752446486 \n",
      "acc for Psat= 0.20140809246938285 \n",
      "acc for optim= 0.1802710319988782\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.007389125879853964\n",
      "Loss on test= 0.0070985048078000546\n",
      "acc for Lsat= 0.13831483520634474 \n",
      "acc for Psat= 0.1869031743165554 \n",
      "acc for optim= 0.1796067800110118\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.007350543513894081\n",
      "Loss on test= 0.006685101892799139\n",
      "acc for Lsat= 0.1547453018783189 \n",
      "acc for Psat= 0.18686955288010082 \n",
      "acc for optim= 0.1742487890653531\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.007118683308362961\n",
      "Loss on test= 0.006804052274674177\n",
      "acc for Lsat= 0.14042036822895562 \n",
      "acc for Psat= 0.19172980604049075 \n",
      "acc for optim= 0.1785984735171361\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.006887350231409073\n",
      "Loss on test= 0.006704506929963827\n",
      "acc for Lsat= 0.12747677220456377 \n",
      "acc for Psat= 0.19596923967057248 \n",
      "acc for optim= 0.17530312348326088\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.007138078100979328\n",
      "Loss on test= 0.006925033405423164\n",
      "acc for Lsat= 0.15290922069821258 \n",
      "acc for Psat= 0.18610880578175104 \n",
      "acc for optim= 0.17826332450794005\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.006875340826809406\n",
      "Loss on test= 0.006501241121441126\n",
      "acc for Lsat= 0.1330414469136756 \n",
      "acc for Psat= 0.18427406386183212 \n",
      "acc for optim= 0.18135812386046038\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.00716762850061059\n",
      "Loss on test= 0.006823644507676363\n",
      "acc for Lsat= 0.14580696757036857 \n",
      "acc for Psat= 0.18004974427084736 \n",
      "acc for optim= 0.1761898617197231\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.0069837202318012714\n",
      "Loss on test= 0.0071880873292684555\n",
      "acc for Lsat= 0.13451968255606983 \n",
      "acc for Psat= 0.21378945855716713 \n",
      "acc for optim= 0.1763852620650731\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.007651695981621742\n",
      "Loss on test= 0.008567518554627895\n",
      "acc for Lsat= 0.18720289283629502 \n",
      "acc for Psat= 0.2864014291726808 \n",
      "acc for optim= 0.17490041151265628\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.007641864474862814\n",
      "Loss on test= 0.0077634453773498535\n",
      "acc for Lsat= 0.17889762629449643 \n",
      "acc for Psat= 0.1923692577999916 \n",
      "acc for optim= 0.19804846619140212\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.007231330499053001\n",
      "Loss on test= 0.006888396106660366\n",
      "acc for Lsat= 0.13205015352542507 \n",
      "acc for Psat= 0.19293841116740548 \n",
      "acc for optim= 0.1799549966670236\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.007018025033175945\n",
      "Loss on test= 0.007259021047502756\n",
      "acc for Lsat= 0.1595691844386545 \n",
      "acc for Psat= 0.19493076701060952 \n",
      "acc for optim= 0.17520326120687957\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.007222810760140419\n",
      "Loss on test= 0.006758627947419882\n",
      "acc for Lsat= 0.1322291456202259 \n",
      "acc for Psat= 0.19853817389780856 \n",
      "acc for optim= 0.1785991801632524\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.0071900165639817715\n",
      "Loss on test= 0.007297934032976627\n",
      "acc for Lsat= 0.13661419217906595 \n",
      "acc for Psat= 0.22829038894564588 \n",
      "acc for optim= 0.18330287973741005\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.007266882341355085\n",
      "Loss on test= 0.006659687962383032\n",
      "acc for Lsat= 0.13467604607221556 \n",
      "acc for Psat= 0.18115348079769517 \n",
      "acc for optim= 0.17881455601663393\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.006944411899894476\n",
      "Loss on test= 0.00679283682256937\n",
      "acc for Lsat= 0.13527549196245475 \n",
      "acc for Psat= 0.20741539989764557 \n",
      "acc for optim= 0.1806809100983849\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.006961050909012556\n",
      "Loss on test= 0.006427197717130184\n",
      "acc for Lsat= 0.13341501697908137 \n",
      "acc for Psat= 0.17428441662227792 \n",
      "acc for optim= 0.17761358748179487\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.007085677236318588\n",
      "Loss on test= 0.006769214291125536\n",
      "acc for Lsat= 0.12943677003184692 \n",
      "acc for Psat= 0.20048647386686974 \n",
      "acc for optim= 0.17897536167347916\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.007190971169620752\n",
      "Loss on test= 0.006286975461989641\n",
      "acc for Lsat= 0.1303981538677928 \n",
      "acc for Psat= 0.1891662367891734 \n",
      "acc for optim= 0.1875731973180066\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.007189637515693903\n",
      "Loss on test= 0.0070875948294997215\n",
      "acc for Lsat= 0.13929158989877405 \n",
      "acc for Psat= 0.21849660898226067 \n",
      "acc for optim= 0.17853780740060265\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.007464147638529539\n",
      "Loss on test= 0.006708602420985699\n",
      "acc for Lsat= 0.1324243271317116 \n",
      "acc for Psat= 0.2045985524511117 \n",
      "acc for optim= 0.18170028935954277\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.006899407133460045\n",
      "Loss on test= 0.00695899548009038\n",
      "acc for Lsat= 0.1304692739828858 \n",
      "acc for Psat= 0.2107564616542584 \n",
      "acc for optim= 0.18836982721964468\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.007202721666544676\n",
      "Loss on test= 0.006878737825900316\n",
      "acc for Lsat= 0.13977314345046998 \n",
      "acc for Psat= 0.19437769433844132 \n",
      "acc for optim= 0.17640042462377048\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.007117772474884987\n",
      "Loss on test= 0.007768718060106039\n",
      "acc for Lsat= 0.1503390629452927 \n",
      "acc for Psat= 0.2387172581095886 \n",
      "acc for optim= 0.1866657551078075\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.007013323251157999\n",
      "Loss on test= 0.006914301309734583\n",
      "acc for Lsat= 0.13482236970505895 \n",
      "acc for Psat= 0.20392036880248515 \n",
      "acc for optim= 0.17657067653930722\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.007132417988032103\n",
      "Loss on test= 0.007103288546204567\n",
      "acc for Lsat= 0.14659593792143946 \n",
      "acc for Psat= 0.21575246588602298 \n",
      "acc for optim= 0.17703562770691714\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.007315177004784346\n",
      "Loss on test= 0.006941447500139475\n",
      "acc for Lsat= 0.14050162386229204 \n",
      "acc for Psat= 0.21515784598061047 \n",
      "acc for optim= 0.17562609147107405\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.007069291081279516\n",
      "Loss on test= 0.006309421267360449\n",
      "acc for Lsat= 0.11861855093613141 \n",
      "acc for Psat= 0.17058435624086407 \n",
      "acc for optim= 0.17319852405725633\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.007003264967352152\n",
      "Loss on test= 0.006535757333040237\n",
      "acc for Lsat= 0.15219264620761375 \n",
      "acc for Psat= 0.18680533530690857 \n",
      "acc for optim= 0.18166585733900786\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.006996338255703449\n",
      "Loss on test= 0.007659904193133116\n",
      "acc for Lsat= 0.1657183322673223 \n",
      "acc for Psat= 0.19753782329177272 \n",
      "acc for optim= 0.17505425508834133\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.007296836469322443\n",
      "Loss on test= 0.006991337053477764\n",
      "acc for Lsat= 0.15116401409810548 \n",
      "acc for Psat= 0.1845133746435356 \n",
      "acc for optim= 0.17360560239427975\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.007015748880803585\n",
      "Loss on test= 0.0065566860139369965\n",
      "acc for Lsat= 0.11957637214702019 \n",
      "acc for Psat= 0.17294851720491253 \n",
      "acc for optim= 0.18072823571990868\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.006751399952918291\n",
      "Loss on test= 0.007261882070451975\n",
      "acc for Lsat= 0.1566610140787023 \n",
      "acc for Psat= 0.18335364864135437 \n",
      "acc for optim= 0.17169053548956514\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.006924417335540056\n",
      "Loss on test= 0.006499678827822208\n",
      "acc for Lsat= 0.12999536961755487 \n",
      "acc for Psat= 0.19911973395092236 \n",
      "acc for optim= 0.17099174644445647\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.006982876919209957\n",
      "Loss on test= 0.006566386669874191\n",
      "acc for Lsat= 0.12746539048434036 \n",
      "acc for Psat= 0.18549459475636124 \n",
      "acc for optim= 0.180626690878558\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.0068759070709347725\n",
      "Loss on test= 0.007136900909245014\n",
      "acc for Lsat= 0.15551604247947753 \n",
      "acc for Psat= 0.18670809213654138 \n",
      "acc for optim= 0.17909698480660743\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.006937994156032801\n",
      "Loss on test= 0.006802213378250599\n",
      "acc for Lsat= 0.16711778863454302 \n",
      "acc for Psat= 0.18448007673912406 \n",
      "acc for optim= 0.17787777872198038\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.007238978054374456\n",
      "Loss on test= 0.006876977626234293\n",
      "acc for Lsat= 0.15628822408882262 \n",
      "acc for Psat= 0.18212152735449727 \n",
      "acc for optim= 0.18267373242446952\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.007015416398644447\n",
      "Loss on test= 0.007085329852998257\n",
      "acc for Lsat= 0.13851639934944468 \n",
      "acc for Psat= 0.20829961777859796 \n",
      "acc for optim= 0.18141711035678856\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.007079852279275656\n",
      "Loss on test= 0.006718121934682131\n",
      "acc for Lsat= 0.12164856126332164 \n",
      "acc for Psat= 0.20567198676754078 \n",
      "acc for optim= 0.17629983343668276\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.006937602534890175\n",
      "Loss on test= 0.006800037808716297\n",
      "acc for Lsat= 0.13435139844713795 \n",
      "acc for Psat= 0.19107521550629186 \n",
      "acc for optim= 0.1745010966907422\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.006763897370547056\n",
      "Loss on test= 0.0069269416853785515\n",
      "acc for Lsat= 0.13552950009486536 \n",
      "acc for Psat= 0.17180578241267713 \n",
      "acc for optim= 0.18305970972633567\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.006886045448482037\n",
      "Loss on test= 0.006946741137653589\n",
      "acc for Lsat= 0.1359389190601104 \n",
      "acc for Psat= 0.18139988001840301 \n",
      "acc for optim= 0.17266814182786785\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.0072477348148822784\n",
      "Loss on test= 0.006559931673109531\n",
      "acc for Lsat= 0.14068878752573255 \n",
      "acc for Psat= 0.1881744957816507 \n",
      "acc for optim= 0.1751292970805701\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.007304625120013952\n",
      "Loss on test= 0.007216508500277996\n",
      "acc for Lsat= 0.14625238827303857 \n",
      "acc for Psat= 0.20668188093947498 \n",
      "acc for optim= 0.17683554751400496\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.0068513210862874985\n",
      "Loss on test= 0.0065766251645982265\n",
      "acc for Lsat= 0.13158794736365373 \n",
      "acc for Psat= 0.19933327799200826 \n",
      "acc for optim= 0.18377402577725416\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.006897962186485529\n",
      "Loss on test= 0.00658617215231061\n",
      "acc for Lsat= 0.13467700070799077 \n",
      "acc for Psat= 0.19442105319428044 \n",
      "acc for optim= 0.18440545249629664\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.007023631129413843\n",
      "Loss on test= 0.007378040812909603\n",
      "acc for Lsat= 0.16912202550471145 \n",
      "acc for Psat= 0.20164211730966722 \n",
      "acc for optim= 0.17585281328767352\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.007137578446418047\n",
      "Loss on test= 0.006972807459533215\n",
      "acc for Lsat= 0.1225480389691035 \n",
      "acc for Psat= 0.19035248782185246 \n",
      "acc for optim= 0.18547344162377427\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.006794204004108906\n",
      "Loss on test= 0.0071114287711679935\n",
      "acc for Lsat= 0.14896361116080772 \n",
      "acc for Psat= 0.20336015518035777 \n",
      "acc for optim= 0.1753992995143415\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.006898640654981136\n",
      "Loss on test= 0.006660107988864183\n",
      "acc for Lsat= 0.12679504503525882 \n",
      "acc for Psat= 0.1751838759424769 \n",
      "acc for optim= 0.17749518554783944\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.006815866567194462\n",
      "Loss on test= 0.006036326289176941\n",
      "acc for Lsat= 0.11514137780771283 \n",
      "acc for Psat= 0.17611816424225155 \n",
      "acc for optim= 0.18267801331947683\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.006741838064044714\n",
      "Loss on test= 0.0062940982170403\n",
      "acc for Lsat= 0.12711916007990381 \n",
      "acc for Psat= 0.18000962590456374 \n",
      "acc for optim= 0.17649790391186723\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.0069907791912555695\n",
      "Loss on test= 0.006379236467182636\n",
      "acc for Lsat= 0.12273233133758343 \n",
      "acc for Psat= 0.18240509959483658 \n",
      "acc for optim= 0.1773829737605804\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.006638491526246071\n",
      "Loss on test= 0.006371031515300274\n",
      "acc for Lsat= 0.12543110605022506 \n",
      "acc for Psat= 0.17919783811600143 \n",
      "acc for optim= 0.1870268582613396\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.0067350189201533794\n",
      "Loss on test= 0.006571614649146795\n",
      "acc for Lsat= 0.13803810360577945 \n",
      "acc for Psat= 0.1710952903019977 \n",
      "acc for optim= 0.18741096284832787\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.006685501430183649\n",
      "Loss on test= 0.006865153554826975\n",
      "acc for Lsat= 0.14349509698772758 \n",
      "acc for Psat= 0.19524136746288087 \n",
      "acc for optim= 0.17849077021836351\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.007028848864138126\n",
      "Loss on test= 0.006704953499138355\n",
      "acc for Lsat= 0.14233527158063913 \n",
      "acc for Psat= 0.21076019097061952 \n",
      "acc for optim= 0.17663067386436868\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.006836393848061562\n",
      "Loss on test= 0.006460940930992365\n",
      "acc for Lsat= 0.123968194648065 \n",
      "acc for Psat= 0.16906972191955483 \n",
      "acc for optim= 0.187581957975478\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.00646287202835083\n",
      "Loss on test= 0.006764729507267475\n",
      "acc for Lsat= 0.1411770172836023 \n",
      "acc for Psat= 0.1795590594564773 \n",
      "acc for optim= 0.1793787380227366\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.0070869168266654015\n",
      "Loss on test= 0.006318349391222\n",
      "acc for Lsat= 0.11627620345569921 \n",
      "acc for Psat= 0.17031616433244356 \n",
      "acc for optim= 0.1734269241516469\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.0067100124433636665\n",
      "Loss on test= 0.006846444681286812\n",
      "acc for Lsat= 0.13053037332704392 \n",
      "acc for Psat= 0.20592312156706513 \n",
      "acc for optim= 0.18144415174626644\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.006672483403235674\n",
      "Loss on test= 0.006466287188231945\n",
      "acc for Lsat= 0.11575197833775058 \n",
      "acc for Psat= 0.17216861711396533 \n",
      "acc for optim= 0.18758210888021543\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.006670976988971233\n",
      "Loss on test= 0.006618304178118706\n",
      "acc for Lsat= 0.11715975090073943 \n",
      "acc for Psat= 0.17906741391084938 \n",
      "acc for optim= 0.17497486113004285\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.00691958237439394\n",
      "Loss on test= 0.006723650265485048\n",
      "acc for Lsat= 0.11992967298794759 \n",
      "acc for Psat= 0.20648167517690644 \n",
      "acc for optim= 0.1852022072593713\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.007154271937906742\n",
      "Loss on test= 0.0066035445779562\n",
      "acc for Lsat= 0.12353150072998982 \n",
      "acc for Psat= 0.18275545483197062 \n",
      "acc for optim= 0.17741373519596448\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.006751923821866512\n",
      "Loss on test= 0.006393189541995525\n",
      "acc for Lsat= 0.11222750872685858 \n",
      "acc for Psat= 0.17302475578096188 \n",
      "acc for optim= 0.1721948368665196\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.006612117402255535\n",
      "Loss on test= 0.006516850087791681\n",
      "acc for Lsat= 0.12213209324427471 \n",
      "acc for Psat= 0.18842383954875372 \n",
      "acc for optim= 0.1810905276876371\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.006577400490641594\n",
      "Loss on test= 0.006398321595042944\n",
      "acc for Lsat= 0.1392237171350791 \n",
      "acc for Psat= 0.1773721998756259 \n",
      "acc for optim= 0.1737021925293595\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.006788775324821472\n",
      "Loss on test= 0.0065755159594118595\n",
      "acc for Lsat= 0.12851573823035004 \n",
      "acc for Psat= 0.16990186525819465 \n",
      "acc for optim= 0.1803614973449274\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.006553763523697853\n",
      "Loss on test= 0.00635045301169157\n",
      "acc for Lsat= 0.1091318219491891 \n",
      "acc for Psat= 0.18769104594901218 \n",
      "acc for optim= 0.17305340272660769\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.006786270532757044\n",
      "Loss on test= 0.006778656039386988\n",
      "acc for Lsat= 0.13997507893706113 \n",
      "acc for Psat= 0.18554370518540964 \n",
      "acc for optim= 0.18037374909161716\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.006720970384776592\n",
      "Loss on test= 0.0064821732230484486\n",
      "acc for Lsat= 0.13082507326042694 \n",
      "acc for Psat= 0.18712624693619767 \n",
      "acc for optim= 0.1730717309498711\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.0065274895168840885\n",
      "Loss on test= 0.006483785808086395\n",
      "acc for Lsat= 0.11672315685742383 \n",
      "acc for Psat= 0.17786141785674428 \n",
      "acc for optim= 0.17752195730320858\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.0067270901054143906\n",
      "Loss on test= 0.006406229920685291\n",
      "acc for Lsat= 0.1263475339038524 \n",
      "acc for Psat= 0.1749701054361287 \n",
      "acc for optim= 0.17925625471754167\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.006819218397140503\n",
      "Loss on test= 0.006745562423020601\n",
      "acc for Lsat= 0.13300168764348003 \n",
      "acc for Psat= 0.20828268938380093 \n",
      "acc for optim= 0.18041514959595834\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.006795534864068031\n",
      "Loss on test= 0.00622127391397953\n",
      "acc for Lsat= 0.14343086531762556 \n",
      "acc for Psat= 0.17471868710969363 \n",
      "acc for optim= 0.17633209313892104\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.006502066273242235\n",
      "Loss on test= 0.00659069512039423\n",
      "acc for Lsat= 0.12717024766449891 \n",
      "acc for Psat= 0.18047071278438986 \n",
      "acc for optim= 0.17965760892685786\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.006662191357463598\n",
      "Loss on test= 0.006473071873188019\n",
      "acc for Lsat= 0.12248713895835839 \n",
      "acc for Psat= 0.17686779224783783 \n",
      "acc for optim= 0.1742164783155769\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.00653954828158021\n",
      "Loss on test= 0.006242281757295132\n",
      "acc for Lsat= 0.12249364396120654 \n",
      "acc for Psat= 0.1755934435678756 \n",
      "acc for optim= 0.18455708257455183\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.006616717204451561\n",
      "Loss on test= 0.006382311694324017\n",
      "acc for Lsat= 0.11729803622064709 \n",
      "acc for Psat= 0.1753461465121143 \n",
      "acc for optim= 0.17281630326013672\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.0065805865451693535\n",
      "Loss on test= 0.0063491263426840305\n",
      "acc for Lsat= 0.12692495852757388 \n",
      "acc for Psat= 0.17802690788379846 \n",
      "acc for optim= 0.1774283401557261\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.006532199215143919\n",
      "Loss on test= 0.0061607351526618\n",
      "acc for Lsat= 0.11536289573603033 \n",
      "acc for Psat= 0.17216411579047908 \n",
      "acc for optim= 0.1750003966959854\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.006501385476440191\n",
      "Loss on test= 0.006400915328413248\n",
      "acc for Lsat= 0.12509897552133004 \n",
      "acc for Psat= 0.18691279057251498 \n",
      "acc for optim= 0.17848385736657735\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.006908159703016281\n",
      "Loss on test= 0.0061683920212090015\n",
      "acc for Lsat= 0.11481964286468684 \n",
      "acc for Psat= 0.17674501883448102 \n",
      "acc for optim= 0.17847032231322765\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.00655518239364028\n",
      "Loss on test= 0.006486100144684315\n",
      "acc for Lsat= 0.11691455494213654 \n",
      "acc for Psat= 0.17509465583311426 \n",
      "acc for optim= 0.18344391789498724\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.006541024427860975\n",
      "Loss on test= 0.006051554810255766\n",
      "acc for Lsat= 0.1140647614644164 \n",
      "acc for Psat= 0.17308100612599692 \n",
      "acc for optim= 0.17828806146354584\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.0064839464612305164\n",
      "Loss on test= 0.006766517646610737\n",
      "acc for Lsat= 0.13078877033390077 \n",
      "acc for Psat= 0.18402984091418959 \n",
      "acc for optim= 0.1747738846822874\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.006723830010741949\n",
      "Loss on test= 0.006644606590270996\n",
      "acc for Lsat= 0.11409031095998315 \n",
      "acc for Psat= 0.1792753034253995 \n",
      "acc for optim= 0.18888236931151542\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.006609693169593811\n",
      "Loss on test= 0.006257319822907448\n",
      "acc for Lsat= 0.11507175544397182 \n",
      "acc for Psat= 0.165515264341249 \n",
      "acc for optim= 0.17518774232165604\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.0065487758256495\n",
      "Loss on test= 0.006255769636482\n",
      "acc for Lsat= 0.10989373399044436 \n",
      "acc for Psat= 0.16399468577445667 \n",
      "acc for optim= 0.18140607012586818\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.006381217855960131\n",
      "Loss on test= 0.006514633074402809\n",
      "acc for Lsat= 0.12410706417584741 \n",
      "acc for Psat= 0.1773459742784129 \n",
      "acc for optim= 0.19027986125921242\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.006548912264406681\n",
      "Loss on test= 0.006032959558069706\n",
      "acc for Lsat= 0.1122242387558111 \n",
      "acc for Psat= 0.1657459334166708 \n",
      "acc for optim= 0.17857052640234494\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.006476244423538446\n",
      "Loss on test= 0.0060636424459517\n",
      "acc for Lsat= 0.11176412506638617 \n",
      "acc for Psat= 0.16568405259749852 \n",
      "acc for optim= 0.1739109838578057\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.006604284048080444\n",
      "Loss on test= 0.006359113845974207\n",
      "acc for Lsat= 0.12619495829553548 \n",
      "acc for Psat= 0.1686575044032243 \n",
      "acc for optim= 0.17958913665328557\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.006413649767637253\n",
      "Loss on test= 0.006366571877151728\n",
      "acc for Lsat= 0.12488839856582917 \n",
      "acc for Psat= 0.17721412245225873 \n",
      "acc for optim= 0.17263430688920356\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.006427917629480362\n",
      "Loss on test= 0.006270456127822399\n",
      "acc for Lsat= 0.12381629315451712 \n",
      "acc for Psat= 0.1794834775137133 \n",
      "acc for optim= 0.17482499905069032\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.0065012481063604355\n",
      "Loss on test= 0.006198064424097538\n",
      "acc for Lsat= 0.11426067412006936 \n",
      "acc for Psat= 0.16093800187966711 \n",
      "acc for optim= 0.17515956160157756\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.006606035400182009\n",
      "Loss on test= 0.006269258912652731\n",
      "acc for Lsat= 0.11968267027987167 \n",
      "acc for Psat= 0.1666852396622228 \n",
      "acc for optim= 0.1716495351718402\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.00681641697883606\n",
      "Loss on test= 0.006526756566017866\n",
      "acc for Lsat= 0.1166411311563983 \n",
      "acc for Psat= 0.19579117641384639 \n",
      "acc for optim= 0.18667163266375586\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.007073901128023863\n",
      "Loss on test= 0.0067762588150799274\n",
      "acc for Lsat= 0.12157263849784047 \n",
      "acc for Psat= 0.2011862716431465 \n",
      "acc for optim= 0.17813178856062764\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.006385767366737127\n",
      "Loss on test= 0.006671851500868797\n",
      "acc for Lsat= 0.1248675466130088 \n",
      "acc for Psat= 0.19538550533321244 \n",
      "acc for optim= 0.186024054976155\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.006536097265779972\n",
      "Loss on test= 0.005971812643110752\n",
      "acc for Lsat= 0.1086615979456346 \n",
      "acc for Psat= 0.17194873157820217 \n",
      "acc for optim= 0.18242508314319453\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.00655249273404479\n",
      "Loss on test= 0.0062310947105288506\n",
      "acc for Lsat= 0.11348805632922056 \n",
      "acc for Psat= 0.16845553943641936 \n",
      "acc for optim= 0.18306825584354433\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.006582139991223812\n",
      "Loss on test= 0.006196566857397556\n",
      "acc for Lsat= 0.11683283653837861 \n",
      "acc for Psat= 0.17218966935966032 \n",
      "acc for optim= 0.17852042831489942\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.0063524567522108555\n",
      "Loss on test= 0.006076671648770571\n",
      "acc for Lsat= 0.11082921218936413 \n",
      "acc for Psat= 0.16073534259910072 \n",
      "acc for optim= 0.1703735190576235\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.006507668178528547\n",
      "Loss on test= 0.0061050462536513805\n",
      "acc for Lsat= 0.1203134560776537 \n",
      "acc for Psat= 0.18102633172826688 \n",
      "acc for optim= 0.1735174723131373\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.0063893538899719715\n",
      "Loss on test= 0.006088833324611187\n",
      "acc for Lsat= 0.11729925789129354 \n",
      "acc for Psat= 0.1737482594469937 \n",
      "acc for optim= 0.17847666945119664\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.0065687778405845165\n",
      "Loss on test= 0.006189625710248947\n",
      "acc for Lsat= 0.12001787370089104 \n",
      "acc for Psat= 0.1659760387068476 \n",
      "acc for optim= 0.17433230832948293\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.0066632237285375595\n",
      "Loss on test= 0.00650298735126853\n",
      "acc for Lsat= 0.13390708863320272 \n",
      "acc for Psat= 0.17055272322313858 \n",
      "acc for optim= 0.1725588873818983\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.0069448938593268394\n",
      "Loss on test= 0.006117800250649452\n",
      "acc for Lsat= 0.1299803483746694 \n",
      "acc for Psat= 0.16347604105588265 \n",
      "acc for optim= 0.17819723840492205\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.0066400375217199326\n",
      "Loss on test= 0.006148994900286198\n",
      "acc for Lsat= 0.11062639455765846 \n",
      "acc for Psat= 0.16674084222727656 \n",
      "acc for optim= 0.17657945391324206\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.0063547114841639996\n",
      "Loss on test= 0.006125592160969973\n",
      "acc for Lsat= 0.11306570332837165 \n",
      "acc for Psat= 0.19431987718161434 \n",
      "acc for optim= 0.1765597251403567\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.006390454713255167\n",
      "Loss on test= 0.006101042963564396\n",
      "acc for Lsat= 0.10766440057144595 \n",
      "acc for Psat= 0.16781495998745682 \n",
      "acc for optim= 0.17766419374045753\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.00642136437818408\n",
      "Loss on test= 0.005946263205260038\n",
      "acc for Lsat= 0.10716953916149528 \n",
      "acc for Psat= 0.15517801860265978 \n",
      "acc for optim= 0.17398672591315442\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.00648828549310565\n",
      "Loss on test= 0.006455911323428154\n",
      "acc for Lsat= 0.11834021975173036 \n",
      "acc for Psat= 0.1915740888342387 \n",
      "acc for optim= 0.18647581437284858\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.006573077291250229\n",
      "Loss on test= 0.006120689213275909\n",
      "acc for Lsat= 0.1149749350502011 \n",
      "acc for Psat= 0.19294069172905734 \n",
      "acc for optim= 0.1847738167158929\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.0065581900998950005\n",
      "Loss on test= 0.00598236545920372\n",
      "acc for Lsat= 0.1036683344353003 \n",
      "acc for Psat= 0.16449090657614934 \n",
      "acc for optim= 0.1729991027923584\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.006466352380812168\n",
      "Loss on test= 0.006060096900910139\n",
      "acc for Lsat= 0.11812949259404598 \n",
      "acc for Psat= 0.17016986965127462 \n",
      "acc for optim= 0.17443664339525394\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.006899956148117781\n",
      "Loss on test= 0.006852228194475174\n",
      "acc for Lsat= 0.14420869843279188 \n",
      "acc for Psat= 0.20805925388501506 \n",
      "acc for optim= 0.17286040469912836\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.006683857645839453\n",
      "Loss on test= 0.006355352699756622\n",
      "acc for Lsat= 0.16201733184322153 \n",
      "acc for Psat= 0.17523221239055084 \n",
      "acc for optim= 0.1809741349930551\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.00640525808557868\n",
      "Loss on test= 0.006162384059280157\n",
      "acc for Lsat= 0.11052530619860124 \n",
      "acc for Psat= 0.175322560099114 \n",
      "acc for optim= 0.17691234561356692\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.006536160130053759\n",
      "Loss on test= 0.005995051469653845\n",
      "acc for Lsat= 0.10846877046129226 \n",
      "acc for Psat= 0.16774837298922846 \n",
      "acc for optim= 0.1721587615321442\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.0065271491184830666\n",
      "Loss on test= 0.006892165634781122\n",
      "acc for Lsat= 0.15306418637461885 \n",
      "acc for Psat= 0.17050629749035187 \n",
      "acc for optim= 0.18490159408876836\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.006442748475819826\n",
      "Loss on test= 0.0060326093807816505\n",
      "acc for Lsat= 0.11248455531091855 \n",
      "acc for Psat= 0.15924687122335585 \n",
      "acc for optim= 0.1735347789404423\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.00644680205732584\n",
      "Loss on test= 0.005933557171374559\n",
      "acc for Lsat= 0.10422063724970054 \n",
      "acc for Psat= 0.1624696391419904 \n",
      "acc for optim= 0.17822690375289704\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.006457874551415443\n",
      "Loss on test= 0.006089968141168356\n",
      "acc for Lsat= 0.11613240325685772 \n",
      "acc for Psat= 0.17933000531047583 \n",
      "acc for optim= 0.17680625146926646\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.006287208292633295\n",
      "Loss on test= 0.0060831885784864426\n",
      "acc for Lsat= 0.12048019971270323 \n",
      "acc for Psat= 0.17448245118007558 \n",
      "acc for optim= 0.17658323913240787\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.0063382904045283794\n",
      "Loss on test= 0.006031723693013191\n",
      "acc for Lsat= 0.11465061234795595 \n",
      "acc for Psat= 0.18336257714828527 \n",
      "acc for optim= 0.17767920523702568\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.006369439419358969\n",
      "Loss on test= 0.0061656152829527855\n",
      "acc for Lsat= 0.11747471722668018 \n",
      "acc for Psat= 0.1756601420116518 \n",
      "acc for optim= 0.18482845935668102\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.006362146232277155\n",
      "Loss on test= 0.006424067076295614\n",
      "acc for Lsat= 0.1299750174791702 \n",
      "acc for Psat= 0.18509085891049393 \n",
      "acc for optim= 0.1758848734937822\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.006461223587393761\n",
      "Loss on test= 0.006256002467125654\n",
      "acc for Lsat= 0.11670495956668919 \n",
      "acc for Psat= 0.16055460776373046 \n",
      "acc for optim= 0.18546434334220485\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.006526414304971695\n",
      "Loss on test= 0.006097499281167984\n",
      "acc for Lsat= 0.11472813691668578 \n",
      "acc for Psat= 0.17912023834946308 \n",
      "acc for optim= 0.17807102219520507\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.0066009871661663055\n",
      "Loss on test= 0.006032908800989389\n",
      "acc for Lsat= 0.10512541874246577 \n",
      "acc for Psat= 0.16234117844519583 \n",
      "acc for optim= 0.17507227058662023\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.00631316564977169\n",
      "Loss on test= 0.00602192897349596\n",
      "acc for Lsat= 0.11049029260014911 \n",
      "acc for Psat= 0.1644070375763034 \n",
      "acc for optim= 0.17466646615916082\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.006452022586017847\n",
      "Loss on test= 0.006914047058671713\n",
      "acc for Lsat= 0.1274824990400088 \n",
      "acc for Psat= 0.2065824430834697 \n",
      "acc for optim= 0.19127845794758508\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.006379805505275726\n",
      "Loss on test= 0.005963601637631655\n",
      "acc for Lsat= 0.10987374795739605 \n",
      "acc for Psat= 0.1629093051741792 \n",
      "acc for optim= 0.17975983479098775\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.006382625084370375\n",
      "Loss on test= 0.0061927540227770805\n",
      "acc for Lsat= 0.12121388844860957 \n",
      "acc for Psat= 0.16998095500312538 \n",
      "acc for optim= 0.1833091889979236\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.00642523355782032\n",
      "Loss on test= 0.006960927043110132\n",
      "acc for Lsat= 0.16566490429859432 \n",
      "acc for Psat= 0.19462122384111108 \n",
      "acc for optim= 0.17747317362286472\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.006808137986809015\n",
      "Loss on test= 0.006117427721619606\n",
      "acc for Lsat= 0.10672841741476273 \n",
      "acc for Psat= 0.17069108105125771 \n",
      "acc for optim= 0.179113846636323\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.006861638743430376\n",
      "Loss on test= 0.006133391987532377\n",
      "acc for Lsat= 0.10743053209495662 \n",
      "acc for Psat= 0.1706872126553601 \n",
      "acc for optim= 0.17554115597001352\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.006269278936088085\n",
      "Loss on test= 0.006216386798769236\n",
      "acc for Lsat= 0.1190088796735123 \n",
      "acc for Psat= 0.1635875352317148 \n",
      "acc for optim= 0.1763807530935107\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.006307636387646198\n",
      "Loss on test= 0.006214358378201723\n",
      "acc for Lsat= 0.1117340266900027 \n",
      "acc for Psat= 0.16962319436786216 \n",
      "acc for optim= 0.1761776174210575\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.006428779102861881\n",
      "Loss on test= 0.005962343420833349\n",
      "acc for Lsat= 0.09659731017549152 \n",
      "acc for Psat= 0.15552788759531402 \n",
      "acc for optim= 0.17893639866235536\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.0064970045350492\n",
      "Loss on test= 0.006433652248233557\n",
      "acc for Lsat= 0.11123035533619013 \n",
      "acc for Psat= 0.16419972036139271 \n",
      "acc for optim= 0.17616589166219282\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.006324556190520525\n",
      "Loss on test= 0.006203262601047754\n",
      "acc for Lsat= 0.1129555587301454 \n",
      "acc for Psat= 0.16703254802662224 \n",
      "acc for optim= 0.1786615948472113\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.006411516573280096\n",
      "Loss on test= 0.005950654856860638\n",
      "acc for Lsat= 0.10998462268006168 \n",
      "acc for Psat= 0.16029054625063066 \n",
      "acc for optim= 0.18024037182279956\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.006291949190199375\n",
      "Loss on test= 0.005744782742112875\n",
      "acc for Lsat= 0.10798642628356607 \n",
      "acc for Psat= 0.16256922869949966 \n",
      "acc for optim= 0.18295406010646903\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.0063412426970899105\n",
      "Loss on test= 0.006196696311235428\n",
      "acc for Lsat= 0.12984025975979543 \n",
      "acc for Psat= 0.16616112112525436 \n",
      "acc for optim= 0.17175145336482642\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.006314859259873629\n",
      "Loss on test= 0.006159366108477116\n",
      "acc for Lsat= 0.1220058256434198 \n",
      "acc for Psat= 0.15082496856563454 \n",
      "acc for optim= 0.18141209533181657\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.006360646802932024\n",
      "Loss on test= 0.006230340804904699\n",
      "acc for Lsat= 0.1227114684069592 \n",
      "acc for Psat= 0.15687783937618086 \n",
      "acc for optim= 0.18102257822386958\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.006423593033105135\n",
      "Loss on test= 0.006325257010757923\n",
      "acc for Lsat= 0.10550705091699873 \n",
      "acc for Psat= 0.16727883652168424 \n",
      "acc for optim= 0.17808506593280835\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.006356571801006794\n",
      "Loss on test= 0.006586237344890833\n",
      "acc for Lsat= 0.14605694966165764 \n",
      "acc for Psat= 0.16809096605543714 \n",
      "acc for optim= 0.17323585687011694\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.006257043685764074\n",
      "Loss on test= 0.006072992458939552\n",
      "acc for Lsat= 0.11814275868223253 \n",
      "acc for Psat= 0.15376817413961535 \n",
      "acc for optim= 0.17638241092720056\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.006279315333813429\n",
      "Loss on test= 0.006062137894332409\n",
      "acc for Lsat= 0.11916660619238895 \n",
      "acc for Psat= 0.1638058100290584 \n",
      "acc for optim= 0.17708158496365334\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.006388030480593443\n",
      "Loss on test= 0.006235835142433643\n",
      "acc for Lsat= 0.10942571177356758 \n",
      "acc for Psat= 0.1754878143700488 \n",
      "acc for optim= 0.17793696540851472\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.006243289913982153\n",
      "Loss on test= 0.0058249738067388535\n",
      "acc for Lsat= 0.1229119753177017 \n",
      "acc for Psat= 0.16135279483972448 \n",
      "acc for optim= 0.17246119682936664\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.006256958935409784\n",
      "Loss on test= 0.006136455573141575\n",
      "acc for Lsat= 0.11002112839203718 \n",
      "acc for Psat= 0.16427514827424491 \n",
      "acc for optim= 0.1813932091694418\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.006361260078847408\n",
      "Loss on test= 0.006207835860550404\n",
      "acc for Lsat= 0.10374558356695185 \n",
      "acc for Psat= 0.17640218975695363 \n",
      "acc for optim= 0.18671052035623123\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.006347572896629572\n",
      "Loss on test= 0.005958866328001022\n",
      "acc for Lsat= 0.11831584571014851 \n",
      "acc for Psat= 0.17005738365933948 \n",
      "acc for optim= 0.17705940275816437\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.006176432594656944\n",
      "Loss on test= 0.006055121310055256\n",
      "acc for Lsat= 0.10633874168923137 \n",
      "acc for Psat= 0.17948944505101158 \n",
      "acc for optim= 0.17769449963413314\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.0062182629480957985\n",
      "Loss on test= 0.005841487552970648\n",
      "acc for Lsat= 0.102692086840276 \n",
      "acc for Psat= 0.18155169505641694 \n",
      "acc for optim= 0.1744394322461606\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.006172494031488895\n",
      "Loss on test= 0.005891897715628147\n",
      "acc for Lsat= 0.10637171761423028 \n",
      "acc for Psat= 0.15355812183387005 \n",
      "acc for optim= 0.17296709188510273\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.00618352834135294\n",
      "Loss on test= 0.006148777902126312\n",
      "acc for Lsat= 0.10352559048309608 \n",
      "acc for Psat= 0.15967933140967255 \n",
      "acc for optim= 0.17328644123571812\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.006397116929292679\n",
      "Loss on test= 0.006083372980356216\n",
      "acc for Lsat= 0.1067859507972104 \n",
      "acc for Psat= 0.15535987861064338 \n",
      "acc for optim= 0.17536991478551203\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.006298637483268976\n",
      "Loss on test= 0.006484012119472027\n",
      "acc for Lsat= 0.11384685251647858 \n",
      "acc for Psat= 0.1723559354361134 \n",
      "acc for optim= 0.17653104555702648\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.00620399322360754\n",
      "Loss on test= 0.0063217030838131905\n",
      "acc for Lsat= 0.13231314186838505 \n",
      "acc for Psat= 0.17071919557939336 \n",
      "acc for optim= 0.18821045587105187\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.006359437480568886\n",
      "Loss on test= 0.006497015245258808\n",
      "acc for Lsat= 0.13802753045928437 \n",
      "acc for Psat= 0.20161838225494894 \n",
      "acc for optim= 0.17319733685407473\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.006373146548867226\n",
      "Loss on test= 0.005934570450335741\n",
      "acc for Lsat= 0.10658229692199785 \n",
      "acc for Psat= 0.1598743083990042 \n",
      "acc for optim= 0.17905841278669057\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.006281115114688873\n",
      "Loss on test= 0.005852182395756245\n",
      "acc for Lsat= 0.10544730737213999 \n",
      "acc for Psat= 0.15268737606537477 \n",
      "acc for optim= 0.18486234555933373\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.0062727732583880424\n",
      "Loss on test= 0.0063230739906430244\n",
      "acc for Lsat= 0.13194014165334944 \n",
      "acc for Psat= 0.17661379070439678 \n",
      "acc for optim= 0.17496914268107305\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.00634206086397171\n",
      "Loss on test= 0.005823961924761534\n",
      "acc for Lsat= 0.10731451173735361 \n",
      "acc for Psat= 0.15728442308908278 \n",
      "acc for optim= 0.1769215554969206\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.006117829121649265\n",
      "Loss on test= 0.006023322697728872\n",
      "acc for Lsat= 0.11423442347999348 \n",
      "acc for Psat= 0.15879991912102875 \n",
      "acc for optim= 0.18043438307168996\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.006194600835442543\n",
      "Loss on test= 0.005780841689556837\n",
      "acc for Lsat= 0.0948304017065557 \n",
      "acc for Psat= 0.14926940800796729 \n",
      "acc for optim= 0.16901753677686085\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.006198019254952669\n",
      "Loss on test= 0.005804590415209532\n",
      "acc for Lsat= 0.10997140397454575 \n",
      "acc for Psat= 0.155491864912054 \n",
      "acc for optim= 0.17955675710301286\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.006270251236855984\n",
      "Loss on test= 0.0059230211190879345\n",
      "acc for Lsat= 0.1108906557907864 \n",
      "acc for Psat= 0.17405022023012862 \n",
      "acc for optim= 0.17733334468062525\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.006018044892698526\n",
      "Loss on test= 0.005851538386195898\n",
      "acc for Lsat= 0.10697084097298126 \n",
      "acc for Psat= 0.1689965837592624 \n",
      "acc for optim= 0.1739198532049085\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.005980109330266714\n",
      "Loss on test= 0.005949567537754774\n",
      "acc for Lsat= 0.10385137613537006 \n",
      "acc for Psat= 0.15592832495029732 \n",
      "acc for optim= 0.1734522597990518\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.0061078923754394054\n",
      "Loss on test= 0.006313581019639969\n",
      "acc for Lsat= 0.10727112774809545 \n",
      "acc for Psat= 0.1620221590545387 \n",
      "acc for optim= 0.1918689071344734\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.0067018065601587296\n",
      "Loss on test= 0.006013363599777222\n",
      "acc for Lsat= 0.11228369623244656 \n",
      "acc for Psat= 0.1755830829196556 \n",
      "acc for optim= 0.17970608441290195\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.006319718901067972\n",
      "Loss on test= 0.005733695346862078\n",
      "acc for Lsat= 0.11026312641459643 \n",
      "acc for Psat= 0.1581503286275924 \n",
      "acc for optim= 0.1755186099959443\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.006057660561054945\n",
      "Loss on test= 0.006391508504748344\n",
      "acc for Lsat= 0.12084332627804346 \n",
      "acc for Psat= 0.17384354983771635 \n",
      "acc for optim= 0.17600290712898886\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.006250566337257624\n",
      "Loss on test= 0.006952701602131128\n",
      "acc for Lsat= 0.19595137152292236 \n",
      "acc for Psat= 0.17930612578606384 \n",
      "acc for optim= 0.1788262542717889\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.006688426248729229\n",
      "Loss on test= 0.0060233925469219685\n",
      "acc for Lsat= 0.11017102863373825 \n",
      "acc for Psat= 0.1619637158561287 \n",
      "acc for optim= 0.17510596574651868\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.006240360904484987\n",
      "Loss on test= 0.006019338965415955\n",
      "acc for Lsat= 0.10354347291187779 \n",
      "acc for Psat= 0.15089996527702268 \n",
      "acc for optim= 0.18410849313934435\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.006122344173491001\n",
      "Loss on test= 0.005799977108836174\n",
      "acc for Lsat= 0.10997098582553204 \n",
      "acc for Psat= 0.1499850168451352 \n",
      "acc for optim= 0.1729413039991758\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.006220262497663498\n",
      "Loss on test= 0.005973719991743565\n",
      "acc for Lsat= 0.10761355091622013 \n",
      "acc for Psat= 0.16178660631035077 \n",
      "acc for optim= 0.17926642400522502\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.0059545752592384815\n",
      "Loss on test= 0.005897898692637682\n",
      "acc for Lsat= 0.09750773384773827 \n",
      "acc for Psat= 0.1426638061750202 \n",
      "acc for optim= 0.17922781077622613\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.006053488235920668\n",
      "Loss on test= 0.005964102689176798\n",
      "acc for Lsat= 0.09846206208572225 \n",
      "acc for Psat= 0.16216600794900474 \n",
      "acc for optim= 0.1835298587293191\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.006158269010484219\n",
      "Loss on test= 0.006022910587489605\n",
      "acc for Lsat= 0.11634882674174937 \n",
      "acc for Psat= 0.16645875074293046 \n",
      "acc for optim= 0.17335941411481662\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.006070796865969896\n",
      "Loss on test= 0.006110163871198893\n",
      "acc for Lsat= 0.11386800005857367 \n",
      "acc for Psat= 0.19617395091218232 \n",
      "acc for optim= 0.17677572509804834\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.006296833045780659\n",
      "Loss on test= 0.006154610775411129\n",
      "acc for Lsat= 0.10793111427975001 \n",
      "acc for Psat= 0.15557623674504686 \n",
      "acc for optim= 0.17313986982638174\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.006190980784595013\n",
      "Loss on test= 0.006611062679439783\n",
      "acc for Lsat= 0.14581898372105914 \n",
      "acc for Psat= 0.17470411123704743 \n",
      "acc for optim= 0.1744003653722167\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.006234873551875353\n",
      "Loss on test= 0.006051206961274147\n",
      "acc for Lsat= 0.10369942184553184 \n",
      "acc for Psat= 0.17137935144962063 \n",
      "acc for optim= 0.17420314603274362\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.006065238267183304\n",
      "Loss on test= 0.007023538462817669\n",
      "acc for Lsat= 0.1860997819819966 \n",
      "acc for Psat= 0.1794284318583212 \n",
      "acc for optim= 0.17529715654971958\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.0062250904738903046\n",
      "Loss on test= 0.005969093646854162\n",
      "acc for Lsat= 0.12801087750011828 \n",
      "acc for Psat= 0.15561104616171104 \n",
      "acc for optim= 0.17949544022062705\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.006210632156580687\n",
      "Loss on test= 0.006248306483030319\n",
      "acc for Lsat= 0.1265944281618136 \n",
      "acc for Psat= 0.15604518570615108 \n",
      "acc for optim= 0.17506236578432238\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.006180262193083763\n",
      "Loss on test= 0.006070647854357958\n",
      "acc for Lsat= 0.10977305150575105 \n",
      "acc for Psat= 0.16762489096495178 \n",
      "acc for optim= 0.1832579375097978\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.006080598570406437\n",
      "Loss on test= 0.00587190967053175\n",
      "acc for Lsat= 0.1117274422722403 \n",
      "acc for Psat= 0.15754374180628597 \n",
      "acc for optim= 0.173615256547802\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.0062362803146243095\n",
      "Loss on test= 0.005928815808147192\n",
      "acc for Lsat= 0.1160700997193458 \n",
      "acc for Psat= 0.15878699437126745 \n",
      "acc for optim= 0.17195337040175218\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.00600782223045826\n",
      "Loss on test= 0.006285329815000296\n",
      "acc for Lsat= 0.10812119747752272 \n",
      "acc for Psat= 0.18711550687943157 \n",
      "acc for optim= 0.17556332545771855\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.006066066678613424\n",
      "Loss on test= 0.00577330868691206\n",
      "acc for Lsat= 0.10330413794368674 \n",
      "acc for Psat= 0.14937487724622572 \n",
      "acc for optim= 0.1844019401705245\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.005932485219091177\n",
      "Loss on test= 0.005881049204617739\n",
      "acc for Lsat= 0.10522393881183234 \n",
      "acc for Psat= 0.16931671614352004 \n",
      "acc for optim= 0.17505250209880516\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.005963359959423542\n",
      "Loss on test= 0.005709176417440176\n",
      "acc for Lsat= 0.10778694784666358 \n",
      "acc for Psat= 0.15117275199264515 \n",
      "acc for optim= 0.17325658125982218\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.006033959332853556\n",
      "Loss on test= 0.005750979296863079\n",
      "acc for Lsat= 0.10230467682344464 \n",
      "acc for Psat= 0.15514070753567 \n",
      "acc for optim= 0.18159845101389865\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.005906118080019951\n",
      "Loss on test= 0.005675028078258038\n",
      "acc for Lsat= 0.10551491913581747 \n",
      "acc for Psat= 0.1525201496422449 \n",
      "acc for optim= 0.16750321723363437\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.006227313540875912\n",
      "Loss on test= 0.0058703236281871796\n",
      "acc for Lsat= 0.10098334150105173 \n",
      "acc for Psat= 0.1556852476897876 \n",
      "acc for optim= 0.17748477354178102\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.006023014895617962\n",
      "Loss on test= 0.0061662630178034306\n",
      "acc for Lsat= 0.13224149941900554 \n",
      "acc for Psat= 0.15949751376605048 \n",
      "acc for optim= 0.18049548882511254\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.006052869372069836\n",
      "Loss on test= 0.005867328029125929\n",
      "acc for Lsat= 0.0965615171446336 \n",
      "acc for Psat= 0.14692977411480546 \n",
      "acc for optim= 0.17477259188839328\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.006089288741350174\n",
      "Loss on test= 0.005771281663328409\n",
      "acc for Lsat= 0.09170412213653263 \n",
      "acc for Psat= 0.14697317966513496 \n",
      "acc for optim= 0.17071493045502417\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.006089481059461832\n",
      "Loss on test= 0.005902094766497612\n",
      "acc for Lsat= 0.10790694372072057 \n",
      "acc for Psat= 0.1592955804658846 \n",
      "acc for optim= 0.17046325381749272\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.006165186874568462\n",
      "Loss on test= 0.005788311827927828\n",
      "acc for Lsat= 0.10644086510001216 \n",
      "acc for Psat= 0.15069430390134142 \n",
      "acc for optim= 0.1784512727771889\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.006108456291258335\n",
      "Loss on test= 0.0059055304154753685\n",
      "acc for Lsat= 0.1087932338643281 \n",
      "acc for Psat= 0.1478004678781233 \n",
      "acc for optim= 0.17996751132178926\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.0060508414171636105\n",
      "Loss on test= 0.0056847776286304\n",
      "acc for Lsat= 0.0934250828935104 \n",
      "acc for Psat= 0.15501995801212223 \n",
      "acc for optim= 0.17799854877946042\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.006080535240471363\n",
      "Loss on test= 0.006335452664643526\n",
      "acc for Lsat= 0.11361648737943757 \n",
      "acc for Psat= 0.1654863367490376 \n",
      "acc for optim= 0.17261984554824192\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.006134367082268\n",
      "Loss on test= 0.006060312502086163\n",
      "acc for Lsat= 0.12381656651738208 \n",
      "acc for Psat= 0.15626068769661533 \n",
      "acc for optim= 0.18154607638909412\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.006023820955306292\n",
      "Loss on test= 0.006125697400420904\n",
      "acc for Lsat= 0.11589811106453429 \n",
      "acc for Psat= 0.15209075670842337 \n",
      "acc for optim= 0.18065335023031268\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.006159354001283646\n",
      "Loss on test= 0.005646621808409691\n",
      "acc for Lsat= 0.11417671286186748 \n",
      "acc for Psat= 0.151833231002407 \n",
      "acc for optim= 0.17375893586820992\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.0061858356930315495\n",
      "Loss on test= 0.006209296174347401\n",
      "acc for Lsat= 0.14228486440446728 \n",
      "acc for Psat= 0.15943886950549926 \n",
      "acc for optim= 0.17808195205843486\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.0062942965887486935\n",
      "Loss on test= 0.005824744701385498\n",
      "acc for Lsat= 0.11299084586671843 \n",
      "acc for Psat= 0.15753907021890218 \n",
      "acc for optim= 0.17459097766471599\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.0061440235003829\n",
      "Loss on test= 0.006006459705531597\n",
      "acc for Lsat= 0.10205311387166935 \n",
      "acc for Psat= 0.16296159219534792 \n",
      "acc for optim= 0.1789133075441429\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.006257548462599516\n",
      "Loss on test= 0.005983020178973675\n",
      "acc for Lsat= 0.1046316985540781 \n",
      "acc for Psat= 0.18614330307261567 \n",
      "acc for optim= 0.17775818821659461\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.006345454603433609\n",
      "Loss on test= 0.005848495755344629\n",
      "acc for Lsat= 0.09896175420864303 \n",
      "acc for Psat= 0.15440734737097267 \n",
      "acc for optim= 0.17577440637113476\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.005995873361825943\n",
      "Loss on test= 0.005861430428922176\n",
      "acc for Lsat= 0.10438289067639522 \n",
      "acc for Psat= 0.1636994228666063 \n",
      "acc for optim= 0.17724664242819385\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.005890246480703354\n",
      "Loss on test= 0.005720813758671284\n",
      "acc for Lsat= 0.09629620233475156 \n",
      "acc for Psat= 0.15811111232599345 \n",
      "acc for optim= 0.17929017406650755\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.005832573398947716\n",
      "Loss on test= 0.005696489010006189\n",
      "acc for Lsat= 0.09791304877462853 \n",
      "acc for Psat= 0.15190036798525694 \n",
      "acc for optim= 0.17508334678063261\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.00613286392763257\n",
      "Loss on test= 0.006160283926874399\n",
      "acc for Lsat= 0.12478986074170648 \n",
      "acc for Psat= 0.1550045916592353 \n",
      "acc for optim= 0.1900452934209465\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.006466635502874851\n",
      "Loss on test= 0.0059652854688465595\n",
      "acc for Lsat= 0.10294474236355666 \n",
      "acc for Psat= 0.153465753729924 \n",
      "acc for optim= 0.17185877906897962\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.006049361079931259\n",
      "Loss on test= 0.00587252713739872\n",
      "acc for Lsat= 0.10990587507439085 \n",
      "acc for Psat= 0.1696649308259775 \n",
      "acc for optim= 0.17291186972343475\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.006107124499976635\n",
      "Loss on test= 0.005671480670571327\n",
      "acc for Lsat= 0.09651780338451833 \n",
      "acc for Psat= 0.1504080849526626 \n",
      "acc for optim= 0.18353394139093498\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.006006209645420313\n",
      "Loss on test= 0.005763007327914238\n",
      "acc for Lsat= 0.09465743893009415 \n",
      "acc for Psat= 0.13446267886595437 \n",
      "acc for optim= 0.18020688940108615\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.006157930940389633\n",
      "Loss on test= 0.005793133284896612\n",
      "acc for Lsat= 0.09114702843126489 \n",
      "acc for Psat= 0.15408848837132855 \n",
      "acc for optim= 0.1770632177299499\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.006145297084003687\n",
      "Loss on test= 0.0061390940099954605\n",
      "acc for Lsat= 0.10926773521429356 \n",
      "acc for Psat= 0.17994179657890108 \n",
      "acc for optim= 0.17306071378698107\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.006098341196775436\n",
      "Loss on test= 0.006572657730430365\n",
      "acc for Lsat= 0.10434958799885714 \n",
      "acc for Psat= 0.20146789890163377 \n",
      "acc for optim= 0.1952019748898385\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.005991608370095491\n",
      "Loss on test= 0.005769267678260803\n",
      "acc for Lsat= 0.11207018153878823 \n",
      "acc for Psat= 0.15066501443908312 \n",
      "acc for optim= 0.17823877705165148\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.005858204793184996\n",
      "Loss on test= 0.006175224669277668\n",
      "acc for Lsat= 0.10526767451655532 \n",
      "acc for Psat= 0.18508209509751838 \n",
      "acc for optim= 0.1842478896986093\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.0060739656910300255\n",
      "Loss on test= 0.005836266092956066\n",
      "acc for Lsat= 0.09537303133333193 \n",
      "acc for Psat= 0.15806093239174318 \n",
      "acc for optim= 0.17220864035904948\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.00599261000752449\n",
      "Loss on test= 0.005565982777625322\n",
      "acc for Lsat= 0.0975397605628353 \n",
      "acc for Psat= 0.15446288606334427 \n",
      "acc for optim= 0.17209907474760847\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.006038669962435961\n",
      "Loss on test= 0.00570890586823225\n",
      "acc for Lsat= 0.10616088613755277 \n",
      "acc for Psat= 0.14565624213915923 \n",
      "acc for optim= 0.17283779312227224\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.006106910761445761\n",
      "Loss on test= 0.005886180326342583\n",
      "acc for Lsat= 0.10454125712725407 \n",
      "acc for Psat= 0.16030433127260138 \n",
      "acc for optim= 0.17632729683238133\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.006298440508544445\n",
      "Loss on test= 0.005965485703200102\n",
      "acc for Lsat= 0.1005431497620963 \n",
      "acc for Psat= 0.1537892476990237 \n",
      "acc for optim= 0.1725518384496477\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.005997221916913986\n",
      "Loss on test= 0.005732660181820393\n",
      "acc for Lsat= 0.10418051066055242 \n",
      "acc for Psat= 0.1433990742679197 \n",
      "acc for optim= 0.17665988765794602\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.005982459057122469\n",
      "Loss on test= 0.005734363105148077\n",
      "acc for Lsat= 0.1055748769472671 \n",
      "acc for Psat= 0.1546263016706861 \n",
      "acc for optim= 0.1736696530197888\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.0059032258577644825\n",
      "Loss on test= 0.005590180400758982\n",
      "acc for Lsat= 0.10577111263803483 \n",
      "acc for Psat= 0.16957761904603325 \n",
      "acc for optim= 0.17376079239191902\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.005966753698885441\n",
      "Loss on test= 0.005971667356789112\n",
      "acc for Lsat= 0.10137999603633747 \n",
      "acc for Psat= 0.16176293715329235 \n",
      "acc for optim= 0.17625555948148217\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.006088695023208857\n",
      "Loss on test= 0.005685069132596254\n",
      "acc for Lsat= 0.10048016662475878 \n",
      "acc for Psat= 0.1571499178456646 \n",
      "acc for optim= 0.17090153625660506\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.006130597088485956\n",
      "Loss on test= 0.006139091216027737\n",
      "acc for Lsat= 0.12743108963823524 \n",
      "acc for Psat= 0.1614642741604601 \n",
      "acc for optim= 0.17030361777830655\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.006061985623091459\n",
      "Loss on test= 0.005988298449665308\n",
      "acc for Lsat= 0.11034076532500016 \n",
      "acc for Psat= 0.16365225170149053 \n",
      "acc for optim= 0.18037875600964834\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.006000978406518698\n",
      "Loss on test= 0.00566414138302207\n",
      "acc for Lsat= 0.09503578376028894 \n",
      "acc for Psat= 0.14672224419474653 \n",
      "acc for optim= 0.17181284538944325\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.005944958422333002\n",
      "Loss on test= 0.005663855466991663\n",
      "acc for Lsat= 0.09875200651082638 \n",
      "acc for Psat= 0.15662153973873402 \n",
      "acc for optim= 0.17391874566532647\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.006041946820914745\n",
      "Loss on test= 0.005661880597472191\n",
      "acc for Lsat= 0.10406505352438143 \n",
      "acc for Psat= 0.14649433953338695 \n",
      "acc for optim= 0.17236855329089873\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.005921193864196539\n",
      "Loss on test= 0.0055848355405032635\n",
      "acc for Lsat= 0.10314887539091099 \n",
      "acc for Psat= 0.15332517159530087 \n",
      "acc for optim= 0.18244368917141793\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.005802462808787823\n",
      "Loss on test= 0.005880330223590136\n",
      "acc for Lsat= 0.11298436039539189 \n",
      "acc for Psat= 0.1474822637719626 \n",
      "acc for optim= 0.17274857997246137\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.005854133516550064\n",
      "Loss on test= 0.0055661932565271854\n",
      "acc for Lsat= 0.09782264947813707 \n",
      "acc for Psat= 0.1499706689718477 \n",
      "acc for optim= 0.17763912367769769\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.005897709634155035\n",
      "Loss on test= 0.0056776017881929874\n",
      "acc for Lsat= 0.09791273181744563 \n",
      "acc for Psat= 0.14852841878589085 \n",
      "acc for optim= 0.17867433296133467\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.005819155368953943\n",
      "Loss on test= 0.005802731029689312\n",
      "acc for Lsat= 0.11618131390620161 \n",
      "acc for Psat= 0.15364078129897354 \n",
      "acc for optim= 0.17697328512302782\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.005795691628009081\n",
      "Loss on test= 0.005757645238190889\n",
      "acc for Lsat= 0.09230304930788652 \n",
      "acc for Psat= 0.1460014519682748 \n",
      "acc for optim= 0.17535258498140296\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.005862521938979626\n",
      "Loss on test= 0.005867555271834135\n",
      "acc for Lsat= 0.09417157666944517 \n",
      "acc for Psat= 0.13857170519013134 \n",
      "acc for optim= 0.1739048101271446\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.005846905056387186\n",
      "Loss on test= 0.005701018497347832\n",
      "acc for Lsat= 0.11125299414817237 \n",
      "acc for Psat= 0.1497254772908196 \n",
      "acc for optim= 0.17122114238992328\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.005948702339082956\n",
      "Loss on test= 0.005407721269875765\n",
      "acc for Lsat= 0.0960365757875135 \n",
      "acc for Psat= 0.14768595572260548 \n",
      "acc for optim= 0.17671681984412882\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.005860933568328619\n",
      "Loss on test= 0.005410988815128803\n",
      "acc for Lsat= 0.1021086189694698 \n",
      "acc for Psat= 0.1332751066345097 \n",
      "acc for optim= 0.16775967285384713\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.006058232858777046\n",
      "Loss on test= 0.005992716643959284\n",
      "acc for Lsat= 0.14795243180924444 \n",
      "acc for Psat= 0.15545122304718315 \n",
      "acc for optim= 0.17740252389422814\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.005986925680190325\n",
      "Loss on test= 0.006079690996557474\n",
      "acc for Lsat= 0.11472345767327083 \n",
      "acc for Psat= 0.15357042067394966 \n",
      "acc for optim= 0.1795070224960344\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.006015485618263483\n",
      "Loss on test= 0.005719772074371576\n",
      "acc for Lsat= 0.0955148857622073 \n",
      "acc for Psat= 0.14047192479948362 \n",
      "acc for optim= 0.17303240005222087\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.005802032072097063\n",
      "Loss on test= 0.005815937649458647\n",
      "acc for Lsat= 0.10597670686400158 \n",
      "acc for Psat= 0.15612239905198835 \n",
      "acc for optim= 0.1762694225619418\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.006044378504157066\n",
      "Loss on test= 0.006131279282271862\n",
      "acc for Lsat= 0.11199594565511467 \n",
      "acc for Psat= 0.17633042880609268 \n",
      "acc for optim= 0.1743381333571223\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.005938147660344839\n",
      "Loss on test= 0.005708356387913227\n",
      "acc for Lsat= 0.09947470258859464 \n",
      "acc for Psat= 0.150187493093875 \n",
      "acc for optim= 0.17879288411141542\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.005840090569108725\n",
      "Loss on test= 0.005753615405410528\n",
      "acc for Lsat= 0.10686877743987187 \n",
      "acc for Psat= 0.14761593643104148 \n",
      "acc for optim= 0.1777516515779319\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.005904177203774452\n",
      "Loss on test= 0.0062651424668729305\n",
      "acc for Lsat= 0.13572548276194563 \n",
      "acc for Psat= 0.16245471863736827 \n",
      "acc for optim= 0.17989303878936413\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.006006849929690361\n",
      "Loss on test= 0.005659898277372122\n",
      "acc for Lsat= 0.09273822405639048 \n",
      "acc for Psat= 0.15117027265266705 \n",
      "acc for optim= 0.17542174263685043\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.006020679138600826\n",
      "Loss on test= 0.006879402790218592\n",
      "acc for Lsat= 0.1344838533261429 \n",
      "acc for Psat= 0.22492387179502388 \n",
      "acc for optim= 0.17529497508940653\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.006204334553331137\n",
      "Loss on test= 0.00567004457116127\n",
      "acc for Lsat= 0.11580286752015692 \n",
      "acc for Psat= 0.1491605583515421 \n",
      "acc for optim= 0.1753083535090932\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.005927304737269878\n",
      "Loss on test= 0.005577544216066599\n",
      "acc for Lsat= 0.10200223298518206 \n",
      "acc for Psat= 0.14865566478260303 \n",
      "acc for optim= 0.1722883623373786\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.005815295968204737\n",
      "Loss on test= 0.0056988950818777084\n",
      "acc for Lsat= 0.09599612667020788 \n",
      "acc for Psat= 0.15125681696431334 \n",
      "acc for optim= 0.1766746746647727\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.005786579102277756\n",
      "Loss on test= 0.005698531866073608\n",
      "acc for Lsat= 0.09909894196351997 \n",
      "acc for Psat= 0.14570093678173943 \n",
      "acc for optim= 0.17356815281812954\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.005843374412506819\n",
      "Loss on test= 0.005774457938969135\n",
      "acc for Lsat= 0.10467012690546776 \n",
      "acc for Psat= 0.14264788907186468 \n",
      "acc for optim= 0.18320829430012964\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.005810008384287357\n",
      "Loss on test= 0.005585536360740662\n",
      "acc for Lsat= 0.09638056299504447 \n",
      "acc for Psat= 0.15329798855502205 \n",
      "acc for optim= 0.17162852951677193\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.0058961589820683\n",
      "Loss on test= 0.005958955734968185\n",
      "acc for Lsat= 0.10267324614029054 \n",
      "acc for Psat= 0.16108178668051748 \n",
      "acc for optim= 0.18423431348905117\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.005867201369255781\n",
      "Loss on test= 0.006088340654969215\n",
      "acc for Lsat= 0.1056897411049372 \n",
      "acc for Psat= 0.15098443604455422 \n",
      "acc for optim= 0.17342345903159948\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.005947936326265335\n",
      "Loss on test= 0.005815382115542889\n",
      "acc for Lsat= 0.1055764614390461 \n",
      "acc for Psat= 0.14365769687655966 \n",
      "acc for optim= 0.17790964535797194\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.005832246039062738\n",
      "Loss on test= 0.005703313276171684\n",
      "acc for Lsat= 0.10137465329858428 \n",
      "acc for Psat= 0.14499058168701448 \n",
      "acc for optim= 0.18121323319634963\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.005767297465354204\n",
      "Loss on test= 0.00559272849932313\n",
      "acc for Lsat= 0.11069192203293013 \n",
      "acc for Psat= 0.16441183575763127 \n",
      "acc for optim= 0.17431767994767633\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.0058917091228067875\n",
      "Loss on test= 0.005640638992190361\n",
      "acc for Lsat= 0.1287423794864161 \n",
      "acc for Psat= 0.1389321189629275 \n",
      "acc for optim= 0.17998039041550648\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.005892760120332241\n",
      "Loss on test= 0.005760018713772297\n",
      "acc for Lsat= 0.09936868407139382 \n",
      "acc for Psat= 0.14302166311126957 \n",
      "acc for optim= 0.1817740025175767\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.0059753297828137875\n",
      "Loss on test= 0.005587736610323191\n",
      "acc for Lsat= 0.10551306012604146 \n",
      "acc for Psat= 0.14722244695491787 \n",
      "acc for optim= 0.16777660219825496\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.006026595365256071\n",
      "Loss on test= 0.0059717572294175625\n",
      "acc for Lsat= 0.10081793245017007 \n",
      "acc for Psat= 0.1660562861875774 \n",
      "acc for optim= 0.18441286958516906\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.0058099315501749516\n",
      "Loss on test= 0.0057766372337937355\n",
      "acc for Lsat= 0.09743644654116833 \n",
      "acc for Psat= 0.1663454006806746 \n",
      "acc for optim= 0.174983769856988\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.005982693750411272\n",
      "Loss on test= 0.005827772431075573\n",
      "acc for Lsat= 0.11640911609211381 \n",
      "acc for Psat= 0.1547897852052867 \n",
      "acc for optim= 0.17166680742731252\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.005814616102725267\n",
      "Loss on test= 0.006090150680392981\n",
      "acc for Lsat= 0.125231416707204 \n",
      "acc for Psat= 0.15387316096599238 \n",
      "acc for optim= 0.17074431598440562\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.006075644865632057\n",
      "Loss on test= 0.005604516714811325\n",
      "acc for Lsat= 0.10706473488224563 \n",
      "acc for Psat= 0.13592751138659534 \n",
      "acc for optim= 0.17312226652993068\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.005822163540869951\n",
      "Loss on test= 0.005642239470034838\n",
      "acc for Lsat= 0.09587007638023155 \n",
      "acc for Psat= 0.15098048566338745 \n",
      "acc for optim= 0.17616608611555223\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.006002457812428474\n",
      "Loss on test= 0.006183499004691839\n",
      "acc for Lsat= 0.10641140477634287 \n",
      "acc for Psat= 0.17870475957543758 \n",
      "acc for optim= 0.18556484533080556\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.0061072902753949165\n",
      "Loss on test= 0.005567706190049648\n",
      "acc for Lsat= 0.1002165446387497 \n",
      "acc for Psat= 0.14615778011707212 \n",
      "acc for optim= 0.1750217702682602\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.005820282269269228\n",
      "Loss on test= 0.005808401387184858\n",
      "acc for Lsat= 0.10769589744882684 \n",
      "acc for Psat= 0.14505564012968633 \n",
      "acc for optim= 0.17375182085300833\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.005704786162823439\n",
      "Loss on test= 0.006216613110154867\n",
      "acc for Lsat= 0.10532005935381775 \n",
      "acc for Psat= 0.17836615059865368 \n",
      "acc for optim= 0.19284918090144512\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.0057146898470819\n",
      "Loss on test= 0.005630068480968475\n",
      "acc for Lsat= 0.09501975156082473 \n",
      "acc for Psat= 0.1394427357696947 \n",
      "acc for optim= 0.17956303833508738\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.005887182895094156\n",
      "Loss on test= 0.005790941417217255\n",
      "acc for Lsat= 0.1082691539021579 \n",
      "acc for Psat= 0.16282273239807724 \n",
      "acc for optim= 0.17164279310934552\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.005794546101242304\n",
      "Loss on test= 0.005885523743927479\n",
      "acc for Lsat= 0.1013629308647462 \n",
      "acc for Psat= 0.16977793803613242 \n",
      "acc for optim= 0.1817419009594478\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.005820789840072393\n",
      "Loss on test= 0.005950729362666607\n",
      "acc for Lsat= 0.10385511949759864 \n",
      "acc for Psat= 0.16603579765265947 \n",
      "acc for optim= 0.1885936126790192\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.005815577227622271\n",
      "Loss on test= 0.0054070414043962955\n",
      "acc for Lsat= 0.09851141178404686 \n",
      "acc for Psat= 0.1545077340175536 \n",
      "acc for optim= 0.16988833438448933\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.0059218271635472775\n",
      "Loss on test= 0.0060274056158959866\n",
      "acc for Lsat= 0.09916576992789586 \n",
      "acc for Psat= 0.1742552467940432 \n",
      "acc for optim= 0.18542627852159943\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.005905732978135347\n",
      "Loss on test= 0.005647351499646902\n",
      "acc for Lsat= 0.09512615865458281 \n",
      "acc for Psat= 0.15440175445621354 \n",
      "acc for optim= 0.17292720699382746\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.005675425287336111\n",
      "Loss on test= 0.005653128493577242\n",
      "acc for Lsat= 0.09279151368439892 \n",
      "acc for Psat= 0.1444563941348787 \n",
      "acc for optim= 0.1768831076439489\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.005680268630385399\n",
      "Loss on test= 0.0059801386669278145\n",
      "acc for Lsat= 0.0951803664787361 \n",
      "acc for Psat= 0.18713592988304398 \n",
      "acc for optim= 0.1793040990215141\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.0061155990697443485\n",
      "Loss on test= 0.00578814884647727\n",
      "acc for Lsat= 0.09472622059863747 \n",
      "acc for Psat= 0.14730046476973724 \n",
      "acc for optim= 0.17506251611288265\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.005713044200092554\n",
      "Loss on test= 0.005738688632845879\n",
      "acc for Lsat= 0.09746784576967961 \n",
      "acc for Psat= 0.15456322120056987 \n",
      "acc for optim= 0.17964669968932867\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.005899934563785791\n",
      "Loss on test= 0.005784183740615845\n",
      "acc for Lsat= 0.11192795335857128 \n",
      "acc for Psat= 0.1592667464432747 \n",
      "acc for optim= 0.17258461237557837\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.005887604784220457\n",
      "Loss on test= 0.005573092494159937\n",
      "acc for Lsat= 0.10658309665175054 \n",
      "acc for Psat= 0.14122033033984466 \n",
      "acc for optim= 0.17470872122971373\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.0059468005783855915\n",
      "Loss on test= 0.005982204340398312\n",
      "acc for Lsat= 0.10358624034368993 \n",
      "acc for Psat= 0.17259108147698352 \n",
      "acc for optim= 0.17880999199602426\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.0057971724309027195\n",
      "Loss on test= 0.005727712064981461\n",
      "acc for Lsat= 0.09485555398517849 \n",
      "acc for Psat= 0.14915149239252945 \n",
      "acc for optim= 0.17452722003893517\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.005929966457188129\n",
      "Loss on test= 0.005708330310881138\n",
      "acc for Lsat= 0.09759681676513464 \n",
      "acc for Psat= 0.15723883700963376 \n",
      "acc for optim= 0.1797319948220959\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.006087088491767645\n",
      "Loss on test= 0.005847492255270481\n",
      "acc for Lsat= 0.09910615919570036 \n",
      "acc for Psat= 0.1629129351148967 \n",
      "acc for optim= 0.1866080382881321\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.005878277588635683\n",
      "Loss on test= 0.0059868632815778255\n",
      "acc for Lsat= 0.10753751019601131 \n",
      "acc for Psat= 0.15994433386407075 \n",
      "acc for optim= 0.1733010757259861\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.005912231747061014\n",
      "Loss on test= 0.005566872656345367\n",
      "acc for Lsat= 0.10182773684381745 \n",
      "acc for Psat= 0.1540981952474721 \n",
      "acc for optim= 0.17772959615738088\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.005805740598589182\n",
      "Loss on test= 0.005579237826168537\n",
      "acc for Lsat= 0.09427970480582853 \n",
      "acc for Psat= 0.14729171951900777 \n",
      "acc for optim= 0.18229115726569797\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.005790994968265295\n",
      "Loss on test= 0.005756845232099295\n",
      "acc for Lsat= 0.09121750657111595 \n",
      "acc for Psat= 0.14355223819548527 \n",
      "acc for optim= 0.17523167416535168\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.005882284138351679\n",
      "Loss on test= 0.005403193179517984\n",
      "acc for Lsat= 0.09489847949707592 \n",
      "acc for Psat= 0.13614269542823249 \n",
      "acc for optim= 0.17841402584815877\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.005806797184050083\n",
      "Loss on test= 0.005479582119733095\n",
      "acc for Lsat= 0.10234170596664331 \n",
      "acc for Psat= 0.15202560865007989 \n",
      "acc for optim= 0.17532396627899977\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005699625704437494\n",
      "Loss on test= 0.005569041706621647\n",
      "acc for Lsat= 0.09889100304949475 \n",
      "acc for Psat= 0.1518548989394755 \n",
      "acc for optim= 0.17431091237065974\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.005792543292045593\n",
      "Loss on test= 0.005535111762583256\n",
      "acc for Lsat= 0.08820291246563618 \n",
      "acc for Psat= 0.1411892078957297 \n",
      "acc for optim= 0.1746616590401548\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.005703035742044449\n",
      "Loss on test= 0.005626370199024677\n",
      "acc for Lsat= 0.10089583957931215 \n",
      "acc for Psat= 0.14740424115302017 \n",
      "acc for optim= 0.17301733850438944\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.00589254405349493\n",
      "Loss on test= 0.005917553324252367\n",
      "acc for Lsat= 0.11981018217960121 \n",
      "acc for Psat= 0.1673228071413669 \n",
      "acc for optim= 0.1729626432017933\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.0058595845475792885\n",
      "Loss on test= 0.005765106063336134\n",
      "acc for Lsat= 0.10572492696598135 \n",
      "acc for Psat= 0.1682193426889638 \n",
      "acc for optim= 0.1764868305387633\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.0057298000901937485\n",
      "Loss on test= 0.005408071912825108\n",
      "acc for Lsat= 0.09980539145824976 \n",
      "acc for Psat= 0.1471526201553265 \n",
      "acc for optim= 0.1776644681195722\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.00571369007229805\n",
      "Loss on test= 0.005633087363094091\n",
      "acc for Lsat= 0.09715191782998846 \n",
      "acc for Psat= 0.14983520048239418 \n",
      "acc for optim= 0.1742428756634409\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.005825652275234461\n",
      "Loss on test= 0.0055008819326758385\n",
      "acc for Lsat= 0.10066786380239874 \n",
      "acc for Psat= 0.14545576658408232 \n",
      "acc for optim= 0.1746082738697894\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.005851371679455042\n",
      "Loss on test= 0.006618240848183632\n",
      "acc for Lsat= 0.13797625091880233 \n",
      "acc for Psat= 0.23956129095038065 \n",
      "acc for optim= 0.1775833653125635\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.005908140446990728\n",
      "Loss on test= 0.005482769571244717\n",
      "acc for Lsat= 0.10318783984513248 \n",
      "acc for Psat= 0.15784687851604806 \n",
      "acc for optim= 0.17480677906899694\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.005816171877086163\n",
      "Loss on test= 0.005355877336114645\n",
      "acc for Lsat= 0.09525598947441943 \n",
      "acc for Psat= 0.1402808221465986 \n",
      "acc for optim= 0.17483483921822315\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.0056425342336297035\n",
      "Loss on test= 0.005557176191359758\n",
      "acc for Lsat= 0.11434955837801287 \n",
      "acc for Psat= 0.15289313582399847 \n",
      "acc for optim= 0.1753131124046745\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.0055655017495155334\n",
      "Loss on test= 0.005539874546229839\n",
      "acc for Lsat= 0.0957473505202231 \n",
      "acc for Psat= 0.15762840686032153 \n",
      "acc for optim= 0.17252516266465112\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.005754086188971996\n",
      "Loss on test= 0.00595057662576437\n",
      "acc for Lsat= 0.11456744612742359 \n",
      "acc for Psat= 0.1593335465397497 \n",
      "acc for optim= 0.1705320735951269\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.0059336512349545956\n",
      "Loss on test= 0.005793843884021044\n",
      "acc for Lsat= 0.11634710411925807 \n",
      "acc for Psat= 0.14985409194963034 \n",
      "acc for optim= 0.1784202419012955\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.005920678377151489\n",
      "Loss on test= 0.0057404725812375546\n",
      "acc for Lsat= 0.09543454222045045 \n",
      "acc for Psat= 0.15603797375759412 \n",
      "acc for optim= 0.17726248515002127\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.0057312618009746075\n",
      "Loss on test= 0.005692112725228071\n",
      "acc for Lsat= 0.10380027192784198 \n",
      "acc for Psat= 0.15619585495497212 \n",
      "acc for optim= 0.18060695558715206\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005887503270059824\n",
      "Loss on test= 0.005757063627243042\n",
      "acc for Lsat= 0.09855801510924278 \n",
      "acc for Psat= 0.14557041486613023 \n",
      "acc for optim= 0.17349814371789615\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.005824298597872257\n",
      "Loss on test= 0.005543015897274017\n",
      "acc for Lsat= 0.09672007552167948 \n",
      "acc for Psat= 0.14151782080291406 \n",
      "acc for optim= 0.18088101117526192\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.005811599083244801\n",
      "Loss on test= 0.006162425968796015\n",
      "acc for Lsat= 0.1275688014288175 \n",
      "acc for Psat= 0.1829391319778232 \n",
      "acc for optim= 0.17652566989383214\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.005771195981651545\n",
      "Loss on test= 0.0058249300345778465\n",
      "acc for Lsat= 0.09727984675795154 \n",
      "acc for Psat= 0.15549305509681732 \n",
      "acc for optim= 0.1844892476046634\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.005687728524208069\n",
      "Loss on test= 0.005581851117312908\n",
      "acc for Lsat= 0.10416651649850521 \n",
      "acc for Psat= 0.14927039101638837 \n",
      "acc for optim= 0.17397916861306373\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.005721285007894039\n",
      "Loss on test= 0.005838867276906967\n",
      "acc for Lsat= 0.10385640118761945 \n",
      "acc for Psat= 0.14465928133840616 \n",
      "acc for optim= 0.17935554795061565\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.005908536724746227\n",
      "Loss on test= 0.005817205645143986\n",
      "acc for Lsat= 0.10301395704909982 \n",
      "acc for Psat= 0.1474770625842408 \n",
      "acc for optim= 0.17575788678997825\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.006109968759119511\n",
      "Loss on test= 0.006560785695910454\n",
      "acc for Lsat= 0.12688708091996345 \n",
      "acc for Psat= 0.19535090760611049 \n",
      "acc for optim= 0.1829178914904824\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.005960555747151375\n",
      "Loss on test= 0.005825042258948088\n",
      "acc for Lsat= 0.11334151693862057 \n",
      "acc for Psat= 0.15613341321236598 \n",
      "acc for optim= 0.1739168715994802\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.005987472832202911\n",
      "Loss on test= 0.005773049779236317\n",
      "acc for Lsat= 0.13109280334410378 \n",
      "acc for Psat= 0.14325857149437857 \n",
      "acc for optim= 0.17993002297156932\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.005827564280480146\n",
      "Loss on test= 0.005727679468691349\n",
      "acc for Lsat= 0.10229241332303532 \n",
      "acc for Psat= 0.14636596589706322 \n",
      "acc for optim= 0.18015985541412216\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.00574516924098134\n",
      "Loss on test= 0.005575484596192837\n",
      "acc for Lsat= 0.09395658320072225 \n",
      "acc for Psat= 0.14201183660633113 \n",
      "acc for optim= 0.17401364044525433\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.005719820037484169\n",
      "Loss on test= 0.00543595664203167\n",
      "acc for Lsat= 0.09117791897905762 \n",
      "acc for Psat= 0.14367089439651495 \n",
      "acc for optim= 0.1741364089035857\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.005698810331523418\n",
      "Loss on test= 0.005462860222905874\n",
      "acc for Lsat= 0.10511837066764128 \n",
      "acc for Psat= 0.1416991536562155 \n",
      "acc for optim= 0.1786697399873299\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.005733157508075237\n",
      "Loss on test= 0.005775409284979105\n",
      "acc for Lsat= 0.11111899908239654 \n",
      "acc for Psat= 0.14880801932658133 \n",
      "acc for optim= 0.17270718065230686\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.005667123943567276\n",
      "Loss on test= 0.006306793075054884\n",
      "acc for Lsat= 0.11573466958184694 \n",
      "acc for Psat= 0.1797691583625557 \n",
      "acc for optim= 0.1854543793879448\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.005719375796616077\n",
      "Loss on test= 0.005785627290606499\n",
      "acc for Lsat= 0.09908839094321199 \n",
      "acc for Psat= 0.16030391648707115 \n",
      "acc for optim= 0.18075561234405\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.005891048349440098\n",
      "Loss on test= 0.005513875279575586\n",
      "acc for Lsat= 0.09667878232407069 \n",
      "acc for Psat= 0.1442136097818572 \n",
      "acc for optim= 0.1719732445113255\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.005730625241994858\n",
      "Loss on test= 0.005749140400439501\n",
      "acc for Lsat= 0.11171455605464772 \n",
      "acc for Psat= 0.15805788348724664 \n",
      "acc for optim= 0.17952438020399092\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.005724279675632715\n",
      "Loss on test= 0.00567010510712862\n",
      "acc for Lsat= 0.09175374985814513 \n",
      "acc for Psat= 0.1462009449763025 \n",
      "acc for optim= 0.18140148486850807\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.005739751737564802\n",
      "Loss on test= 0.005935811437666416\n",
      "acc for Lsat= 0.1186235193086464 \n",
      "acc for Psat= 0.15997199960869496 \n",
      "acc for optim= 0.17189466517408397\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.005833134986460209\n",
      "Loss on test= 0.005513735581189394\n",
      "acc for Lsat= 0.11875192257040809 \n",
      "acc for Psat= 0.14805221787783257 \n",
      "acc for optim= 0.17368429345141695\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.005884449928998947\n",
      "Loss on test= 0.005756256636232138\n",
      "acc for Lsat= 0.11809705652135685 \n",
      "acc for Psat= 0.14613578812753297 \n",
      "acc for optim= 0.17156460510041388\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.0056756120175123215\n",
      "Loss on test= 0.005700339563190937\n",
      "acc for Lsat= 0.10640944121749615 \n",
      "acc for Psat= 0.1359805900483971 \n",
      "acc for optim= 0.1725858204800052\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005679745227098465\n",
      "Loss on test= 0.005638792645186186\n",
      "acc for Lsat= 0.09811797999832747 \n",
      "acc for Psat= 0.1365013767161243 \n",
      "acc for optim= 0.17274859484930588\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.005628292914479971\n",
      "Loss on test= 0.005621509160846472\n",
      "acc for Lsat= 0.09301324542468285 \n",
      "acc for Psat= 0.14119942315124176 \n",
      "acc for optim= 0.17143016382947648\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.005717941094189882\n",
      "Loss on test= 0.005837461445480585\n",
      "acc for Lsat= 0.09819025257653462 \n",
      "acc for Psat= 0.14341910768180732 \n",
      "acc for optim= 0.1762366839841864\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.00572006544098258\n",
      "Loss on test= 0.005567663349211216\n",
      "acc for Lsat= 0.09095789876404081 \n",
      "acc for Psat= 0.15307265086183278 \n",
      "acc for optim= 0.17560476670808606\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.0057109505869448185\n",
      "Loss on test= 0.005633567459881306\n",
      "acc for Lsat= 0.10456715542878138 \n",
      "acc for Psat= 0.13807778307307525 \n",
      "acc for optim= 0.17885308190307114\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.005549707915633917\n",
      "Loss on test= 0.005709062330424786\n",
      "acc for Lsat= 0.09495702508278604 \n",
      "acc for Psat= 0.13497592186054996 \n",
      "acc for optim= 0.171674188167418\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.005685623735189438\n",
      "Loss on test= 0.00551915168762207\n",
      "acc for Lsat= 0.093942011046877 \n",
      "acc for Psat= 0.14227829196792102 \n",
      "acc for optim= 0.17523829906752547\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.005677946377545595\n",
      "Loss on test= 0.005941225681453943\n",
      "acc for Lsat= 0.10865991778523862 \n",
      "acc for Psat= 0.14714404947399334 \n",
      "acc for optim= 0.1885720933685268\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.005810212809592485\n",
      "Loss on test= 0.005455176346004009\n",
      "acc for Lsat= 0.09850815542418982 \n",
      "acc for Psat= 0.14189979659076435 \n",
      "acc for optim= 0.17425719058558792\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.005622283089905977\n",
      "Loss on test= 0.005486233625560999\n",
      "acc for Lsat= 0.10476561923039569 \n",
      "acc for Psat= 0.14762154388567117 \n",
      "acc for optim= 0.174356108232255\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.00567649258300662\n",
      "Loss on test= 0.005556477699428797\n",
      "acc for Lsat= 0.09448618839343072 \n",
      "acc for Psat= 0.14209102009143051 \n",
      "acc for optim= 0.18200583058107342\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.005606417544186115\n",
      "Loss on test= 0.005506579764187336\n",
      "acc for Lsat= 0.10995763369253443 \n",
      "acc for Psat= 0.14175939406969346 \n",
      "acc for optim= 0.17685861299931374\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.005617552902549505\n",
      "Loss on test= 0.005650426261126995\n",
      "acc for Lsat= 0.10009994417054553 \n",
      "acc for Psat= 0.13457978524038972 \n",
      "acc for optim= 0.17664955239077343\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.005759497173130512\n",
      "Loss on test= 0.005594356916844845\n",
      "acc for Lsat= 0.1092517574874659 \n",
      "acc for Psat= 0.14260721606395335 \n",
      "acc for optim= 0.17129411701067954\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.005666838958859444\n",
      "Loss on test= 0.00550425797700882\n",
      "acc for Lsat= 0.09853543389117231 \n",
      "acc for Psat= 0.14865602190115465 \n",
      "acc for optim= 0.1778825766258509\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.005715312901884317\n",
      "Loss on test= 0.005829338915646076\n",
      "acc for Lsat= 0.10512395749272499 \n",
      "acc for Psat= 0.13799332923144594 \n",
      "acc for optim= 0.17095656619986166\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.0057569947093725204\n",
      "Loss on test= 0.005531281232833862\n",
      "acc for Lsat= 0.10229010259226433 \n",
      "acc for Psat= 0.16030289841059917 \n",
      "acc for optim= 0.17595026278561549\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.005538725759834051\n",
      "Loss on test= 0.0054877218790352345\n",
      "acc for Lsat= 0.09515472522724776 \n",
      "acc for Psat= 0.13751144035140406 \n",
      "acc for optim= 0.17175800050520323\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.005586773622781038\n",
      "Loss on test= 0.005467941518872976\n",
      "acc for Lsat= 0.08803989362570212 \n",
      "acc for Psat= 0.14585317195372693 \n",
      "acc for optim= 0.1738746474643326\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.005676937289535999\n",
      "Loss on test= 0.005476606544107199\n",
      "acc for Lsat= 0.09838269759711693 \n",
      "acc for Psat= 0.13957457025429215 \n",
      "acc for optim= 0.17203072271056313\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.0055741132237017155\n",
      "Loss on test= 0.00578482449054718\n",
      "acc for Lsat= 0.10426119454150712 \n",
      "acc for Psat= 0.14194125594096133 \n",
      "acc for optim= 0.17058458995130865\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.005785800516605377\n",
      "Loss on test= 0.005501659121364355\n",
      "acc for Lsat= 0.0891647654608843 \n",
      "acc for Psat= 0.14199608131309868 \n",
      "acc for optim= 0.1721751458960195\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.0057209026999771595\n",
      "Loss on test= 0.005660629365593195\n",
      "acc for Lsat= 0.11655146579515359 \n",
      "acc for Psat= 0.14439477295781142 \n",
      "acc for optim= 0.1685287100589375\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.005699801724404097\n",
      "Loss on test= 0.00575207220390439\n",
      "acc for Lsat= 0.11723007674240885 \n",
      "acc for Psat= 0.1411455547737156 \n",
      "acc for optim= 0.17663589941533958\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.005658274982124567\n",
      "Loss on test= 0.006061393301934004\n",
      "acc for Lsat= 0.10450237958473342 \n",
      "acc for Psat= 0.17077239115039716 \n",
      "acc for optim= 0.17664885068744124\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.0056742592714726925\n",
      "Loss on test= 0.0056270030327141285\n",
      "acc for Lsat= 0.09187788813464116 \n",
      "acc for Psat= 0.15251271410528028 \n",
      "acc for optim= 0.1763662472658325\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.005723373498767614\n",
      "Loss on test= 0.005976085551083088\n",
      "acc for Lsat= 0.11574569859046302 \n",
      "acc for Psat= 0.16531381686463892 \n",
      "acc for optim= 0.17412619418865763\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.005687067285180092\n",
      "Loss on test= 0.005379069596529007\n",
      "acc for Lsat= 0.09637762827136416 \n",
      "acc for Psat= 0.142032504348884 \n",
      "acc for optim= 0.17600622546249084\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.0056699239648878574\n",
      "Loss on test= 0.005744523368775845\n",
      "acc for Lsat= 0.09266675676931177 \n",
      "acc for Psat= 0.14872400799366595 \n",
      "acc for optim= 0.18230647803107244\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.0057217637076973915\n",
      "Loss on test= 0.005419053137302399\n",
      "acc for Lsat= 0.09730861425054467 \n",
      "acc for Psat= 0.13479009295937233 \n",
      "acc for optim= 0.17065999594067122\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.005637274123728275\n",
      "Loss on test= 0.0054807341657578945\n",
      "acc for Lsat= 0.09138831906366741 \n",
      "acc for Psat= 0.13852799920907174 \n",
      "acc for optim= 0.1720923403212313\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005636276211589575\n",
      "Loss on test= 0.005970173515379429\n",
      "acc for Lsat= 0.11185019589845831 \n",
      "acc for Psat= 0.16559657963060434 \n",
      "acc for optim= 0.17227457109067865\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.005570450332015753\n",
      "Loss on test= 0.005602162331342697\n",
      "acc for Lsat= 0.096556263210447 \n",
      "acc for Psat= 0.13555147896489428 \n",
      "acc for optim= 0.18212263505075818\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005617569666355848\n",
      "Loss on test= 0.005604657810181379\n",
      "acc for Lsat= 0.11441450315013188 \n",
      "acc for Psat= 0.1414072461431371 \n",
      "acc for optim= 0.17153662127640093\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.005793065298348665\n",
      "Loss on test= 0.006511256564408541\n",
      "acc for Lsat= 0.13357927848276607 \n",
      "acc for Psat= 0.1860542405826178 \n",
      "acc for optim= 0.17133195679426116\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.005926079116761684\n",
      "Loss on test= 0.005965413525700569\n",
      "acc for Lsat= 0.10528105331724037 \n",
      "acc for Psat= 0.15923612168980245 \n",
      "acc for optim= 0.17892401978511968\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.005792570300400257\n",
      "Loss on test= 0.005740473512560129\n",
      "acc for Lsat= 0.09519435816449963 \n",
      "acc for Psat= 0.14622140014221627 \n",
      "acc for optim= 0.17757139965495397\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.005684250500053167\n",
      "Loss on test= 0.005407928489148617\n",
      "acc for Lsat= 0.095120590873931 \n",
      "acc for Psat= 0.13909013353455718 \n",
      "acc for optim= 0.18026811606093385\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.005639623384922743\n",
      "Loss on test= 0.005649833474308252\n",
      "acc for Lsat= 0.09669234525161399 \n",
      "acc for Psat= 0.1547776381508762 \n",
      "acc for optim= 0.173904979407313\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.005715660285204649\n",
      "Loss on test= 0.005914940033107996\n",
      "acc for Lsat= 0.11507681652673872 \n",
      "acc for Psat= 0.14571338953553364 \n",
      "acc for optim= 0.17731007834427637\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005466619040817022\n",
      "Loss on test= 0.005880285520106554\n",
      "acc for Lsat= 0.10808547299679835 \n",
      "acc for Psat= 0.16421483135137177 \n",
      "acc for optim= 0.17103089534577667\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.005676083732396364\n",
      "Loss on test= 0.005877619609236717\n",
      "acc for Lsat= 0.13200347004906665 \n",
      "acc for Psat= 0.14687988789299541 \n",
      "acc for optim= 0.17299343069533132\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.005852130241692066\n",
      "Loss on test= 0.005594590678811073\n",
      "acc for Lsat= 0.10407147855113254 \n",
      "acc for Psat= 0.13319885476183216 \n",
      "acc for optim= 0.17404058636059966\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.005683109164237976\n",
      "Loss on test= 0.005277116782963276\n",
      "acc for Lsat= 0.10569269943541282 \n",
      "acc for Psat= 0.1342632948308656 \n",
      "acc for optim= 0.16998059073424931\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.005620235577225685\n",
      "Loss on test= 0.005545534659177065\n",
      "acc for Lsat= 0.09182663447761631 \n",
      "acc for Psat= 0.14126794257459255 \n",
      "acc for optim= 0.18014592542022\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.005655603017657995\n",
      "Loss on test= 0.0053526670671999454\n",
      "acc for Lsat= 0.09105411292487564 \n",
      "acc for Psat= 0.14967572729172487 \n",
      "acc for optim= 0.1795510194590099\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.005584883037954569\n",
      "Loss on test= 0.005658363923430443\n",
      "acc for Lsat= 0.0972431013925981 \n",
      "acc for Psat= 0.15244943293264196 \n",
      "acc for optim= 0.17647667484660004\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.005672709550708532\n",
      "Loss on test= 0.005685498006641865\n",
      "acc for Lsat= 0.1011304311907372 \n",
      "acc for Psat= 0.141917802561398 \n",
      "acc for optim= 0.1814157068055883\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.005601908080279827\n",
      "Loss on test= 0.005560355260968208\n",
      "acc for Lsat= 0.09702387101562046 \n",
      "acc for Psat= 0.14069158265399007 \n",
      "acc for optim= 0.1765132936494853\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005591419991105795\n",
      "Loss on test= 0.00572859775274992\n",
      "acc for Lsat= 0.10727052775532561 \n",
      "acc for Psat= 0.1477919826346978 \n",
      "acc for optim= 0.1788792403574523\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.005782763939350843\n",
      "Loss on test= 0.005446758586913347\n",
      "acc for Lsat= 0.09950056695575964 \n",
      "acc for Psat= 0.14069762708410005 \n",
      "acc for optim= 0.16894161770933597\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.005648265592753887\n",
      "Loss on test= 0.005679629277437925\n",
      "acc for Lsat= 0.08794589868724674 \n",
      "acc for Psat= 0.13464569436768511 \n",
      "acc for optim= 0.170946448520644\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.005734334699809551\n",
      "Loss on test= 0.005327065475285053\n",
      "acc for Lsat= 0.09517989321181164 \n",
      "acc for Psat= 0.13725402304899526 \n",
      "acc for optim= 0.1788534778411949\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.005614922381937504\n",
      "Loss on test= 0.005633579101413488\n",
      "acc for Lsat= 0.09721467198198445 \n",
      "acc for Psat= 0.14960222173387003 \n",
      "acc for optim= 0.1746616470128002\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.0055569615215063095\n",
      "Loss on test= 0.00549909146502614\n",
      "acc for Lsat= 0.08945229057676565 \n",
      "acc for Psat= 0.14798741081825495 \n",
      "acc for optim= 0.17641285053439396\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.005776602309197187\n",
      "Loss on test= 0.0065874201245605946\n",
      "acc for Lsat= 0.1406288652140427 \n",
      "acc for Psat= 0.1860150164901751 \n",
      "acc for optim= 0.1682508781320664\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.005917894653975964\n",
      "Loss on test= 0.006016275379806757\n",
      "acc for Lsat= 0.09383005564295427 \n",
      "acc for Psat= 0.16682664070086084 \n",
      "acc for optim= 0.1865906106013918\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.005664735566824675\n",
      "Loss on test= 0.005537421442568302\n",
      "acc for Lsat= 0.09554490019375383 \n",
      "acc for Psat= 0.1388499331707764 \n",
      "acc for optim= 0.18379436117342068\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.005663497839123011\n",
      "Loss on test= 0.0057815490290522575\n",
      "acc for Lsat= 0.1007512819613456 \n",
      "acc for Psat= 0.17336768583265585 \n",
      "acc for optim= 0.17268487174166963\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.005540038459002972\n",
      "Loss on test= 0.0057078092359006405\n",
      "acc for Lsat= 0.10162085328731238 \n",
      "acc for Psat= 0.13682283241300988 \n",
      "acc for optim= 0.18464052945224418\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.005385214928537607\n",
      "Loss on test= 0.005620024632662535\n",
      "acc for Lsat= 0.09636245194989798 \n",
      "acc for Psat= 0.14214409810758938 \n",
      "acc for optim= 0.1701823805761779\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.00556622538715601\n",
      "Loss on test= 0.0055872490629553795\n",
      "acc for Lsat= 0.09150517463854772 \n",
      "acc for Psat= 0.13718139971584803 \n",
      "acc for optim= 0.17684554563979996\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.005571983754634857\n",
      "Loss on test= 0.005306439008563757\n",
      "acc for Lsat= 0.09761129354046716 \n",
      "acc for Psat= 0.1399613048966244 \n",
      "acc for optim= 0.1731419118193141\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.005764462985098362\n",
      "Loss on test= 0.005361600313335657\n",
      "acc for Lsat= 0.10172320143406191 \n",
      "acc for Psat= 0.14210213239612346 \n",
      "acc for optim= 0.1742232850394086\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.005582673940807581\n",
      "Loss on test= 0.005778184626251459\n",
      "acc for Lsat= 0.13189350447823558 \n",
      "acc for Psat= 0.14454241313757626 \n",
      "acc for optim= 0.17449679190286663\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.0059794895350933075\n",
      "Loss on test= 0.005867685191333294\n",
      "acc for Lsat= 0.10911563625622138 \n",
      "acc for Psat= 0.17066857934893248 \n",
      "acc for optim= 0.1783410010516122\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.005620389245450497\n",
      "Loss on test= 0.005505856592208147\n",
      "acc for Lsat= 0.10088566829949126 \n",
      "acc for Psat= 0.14078683347002338 \n",
      "acc for optim= 0.18212561389810691\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.005484118591994047\n",
      "Loss on test= 0.005861838348209858\n",
      "acc for Lsat= 0.11263684886496875 \n",
      "acc for Psat= 0.1440907811029811 \n",
      "acc for optim= 0.18248293338448904\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005617098417133093\n",
      "Loss on test= 0.005807722918689251\n",
      "acc for Lsat= 0.10244103279072422 \n",
      "acc for Psat= 0.1695862009832667 \n",
      "acc for optim= 0.181051614311228\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.005665937438607216\n",
      "Loss on test= 0.005516745150089264\n",
      "acc for Lsat= 0.08567701599302358 \n",
      "acc for Psat= 0.15004698749677375 \n",
      "acc for optim= 0.1731988597809529\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.0057345000095665455\n",
      "Loss on test= 0.005759365390986204\n",
      "acc for Lsat= 0.12174144510267856 \n",
      "acc for Psat= 0.14058946800721084 \n",
      "acc for optim= 0.1845352343804267\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.005417149048298597\n",
      "Loss on test= 0.00548871885985136\n",
      "acc for Lsat= 0.09473151924179841 \n",
      "acc for Psat= 0.12813794361087227 \n",
      "acc for optim= 0.1727679710301517\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.00551295280456543\n",
      "Loss on test= 0.005512769799679518\n",
      "acc for Lsat= 0.09521832548657708 \n",
      "acc for Psat= 0.13407099524645033 \n",
      "acc for optim= 0.17294601816762667\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.005560482852160931\n",
      "Loss on test= 0.005546354688704014\n",
      "acc for Lsat= 0.09762039940137215 \n",
      "acc for Psat= 0.14090384828238245 \n",
      "acc for optim= 0.17078657301120787\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.005577843636274338\n",
      "Loss on test= 0.005430509801954031\n",
      "acc for Lsat= 0.09343677111738126 \n",
      "acc for Psat= 0.12259140771877626 \n",
      "acc for optim= 0.1721532423980534\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.005622419063001871\n",
      "Loss on test= 0.005390421953052282\n",
      "acc for Lsat= 0.09240148353942582 \n",
      "acc for Psat= 0.14935494525460288 \n",
      "acc for optim= 0.17276473556144945\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.005612466484308243\n",
      "Loss on test= 0.0055431583896279335\n",
      "acc for Lsat= 0.09484827787988202 \n",
      "acc for Psat= 0.13580635073275196 \n",
      "acc for optim= 0.17352802617116705\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.005471335258334875\n",
      "Loss on test= 0.00562574528157711\n",
      "acc for Lsat= 0.09915130998106671 \n",
      "acc for Psat= 0.1460953068286668 \n",
      "acc for optim= 0.17384825231400444\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.005695093888789415\n",
      "Loss on test= 0.006107845809310675\n",
      "acc for Lsat= 0.09400804300133353 \n",
      "acc for Psat= 0.15191123994009104 \n",
      "acc for optim= 0.19320580362713174\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.005512853153049946\n",
      "Loss on test= 0.00552653893828392\n",
      "acc for Lsat= 0.09056144357885854 \n",
      "acc for Psat= 0.15030761071698548 \n",
      "acc for optim= 0.17510271751942472\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.0056570847518742085\n",
      "Loss on test= 0.005886246915906668\n",
      "acc for Lsat= 0.10997254314722611 \n",
      "acc for Psat= 0.16867964044856332 \n",
      "acc for optim= 0.17833560368015586\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005769483279436827\n",
      "Loss on test= 0.005473727360367775\n",
      "acc for Lsat= 0.09981544769579086 \n",
      "acc for Psat= 0.15085881152048683 \n",
      "acc for optim= 0.174743882927106\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.0056441230699419975\n",
      "Loss on test= 0.005381869152188301\n",
      "acc for Lsat= 0.08896582206904674 \n",
      "acc for Psat= 0.14389694215355417 \n",
      "acc for optim= 0.17474515312347352\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.005658277776092291\n",
      "Loss on test= 0.005762019660323858\n",
      "acc for Lsat= 0.11268882253456025 \n",
      "acc for Psat= 0.1495472633084589 \n",
      "acc for optim= 0.17428181001466597\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.005772738251835108\n",
      "Loss on test= 0.005488698370754719\n",
      "acc for Lsat= 0.10017393933565079 \n",
      "acc for Psat= 0.14232667076961464 \n",
      "acc for optim= 0.17530812761258466\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.005891220178455114\n",
      "Loss on test= 0.005633921828120947\n",
      "acc for Lsat= 0.09355645864844839 \n",
      "acc for Psat= 0.14152604255748982 \n",
      "acc for optim= 0.17198201471399296\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.0056843385100364685\n",
      "Loss on test= 0.005775799509137869\n",
      "acc for Lsat= 0.11948482609338769 \n",
      "acc for Psat= 0.13726900261158212 \n",
      "acc for optim= 0.18042033373651706\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.005488412454724312\n",
      "Loss on test= 0.005400572903454304\n",
      "acc for Lsat= 0.09138865743217459 \n",
      "acc for Psat= 0.15029739380554166 \n",
      "acc for optim= 0.17070217512514932\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.005526766646653414\n",
      "Loss on test= 0.005584951024502516\n",
      "acc for Lsat= 0.10921846763498301 \n",
      "acc for Psat= 0.14293513897369062 \n",
      "acc for optim= 0.17674970995584452\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.0055591873824596405\n",
      "Loss on test= 0.005567202344536781\n",
      "acc for Lsat= 0.10080280070080236 \n",
      "acc for Psat= 0.1537574143353472 \n",
      "acc for optim= 0.17050517024039732\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.005528509616851807\n",
      "Loss on test= 0.005494419950991869\n",
      "acc for Lsat= 0.09855549247090126 \n",
      "acc for Psat= 0.13765941996948763 \n",
      "acc for optim= 0.17625113782265248\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.005352006293833256\n",
      "Loss on test= 0.005326118785887957\n",
      "acc for Lsat= 0.08923649908546075 \n",
      "acc for Psat= 0.14432980007974971 \n",
      "acc for optim= 0.17346096675012362\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.005658041685819626\n",
      "Loss on test= 0.0058885482139885426\n",
      "acc for Lsat= 0.09374040356527297 \n",
      "acc for Psat= 0.13004910314373627 \n",
      "acc for optim= 0.1974491381195155\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.005506424233317375\n",
      "Loss on test= 0.005433668382465839\n",
      "acc for Lsat= 0.10795116465237083 \n",
      "acc for Psat= 0.13442480782907443 \n",
      "acc for optim= 0.16910907874684986\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.005618823692202568\n",
      "Loss on test= 0.0055116512812674046\n",
      "acc for Lsat= 0.09620685235249521 \n",
      "acc for Psat= 0.14518490478135268 \n",
      "acc for optim= 0.173052177901342\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005531537812203169\n",
      "Loss on test= 0.005939126014709473\n",
      "acc for Lsat= 0.12845034278772702 \n",
      "acc for Psat= 0.1657584207964339 \n",
      "acc for optim= 0.1731015224937142\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.005497980862855911\n",
      "Loss on test= 0.005546184256672859\n",
      "acc for Lsat= 0.09456441422836989 \n",
      "acc for Psat= 0.1379312578005861 \n",
      "acc for optim= 0.17947018018870997\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.005605607759207487\n",
      "Loss on test= 0.005407304968684912\n",
      "acc for Lsat= 0.09471517050740265 \n",
      "acc for Psat= 0.14391917682644054 \n",
      "acc for optim= 0.17559583166412512\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005617173388600349\n",
      "Loss on test= 0.005475903395563364\n",
      "acc for Lsat= 0.09979537667862354 \n",
      "acc for Psat= 0.15577349945822397 \n",
      "acc for optim= 0.1778652953295465\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005594099406152964\n",
      "Loss on test= 0.005897794384509325\n",
      "acc for Lsat= 0.10105254269945214 \n",
      "acc for Psat= 0.1592868973954889 \n",
      "acc for optim= 0.1878012725599645\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.00569623289629817\n",
      "Loss on test= 0.005425147246569395\n",
      "acc for Lsat= 0.09625905567706984 \n",
      "acc for Psat= 0.14108479953122427 \n",
      "acc for optim= 0.17118444897327256\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.005558929406106472\n",
      "Loss on test= 0.005776748526841402\n",
      "acc for Lsat= 0.09853541803995786 \n",
      "acc for Psat= 0.13970087888427205 \n",
      "acc for optim= 0.17187786815427258\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.005509893409907818\n",
      "Loss on test= 0.005547269247472286\n",
      "acc for Lsat= 0.10796642959618062 \n",
      "acc for Psat= 0.1406724940086959 \n",
      "acc for optim= 0.16913480693049654\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.00566102797165513\n",
      "Loss on test= 0.005471519660204649\n",
      "acc for Lsat= 0.09525811717380625 \n",
      "acc for Psat= 0.14322752054254492 \n",
      "acc for optim= 0.18680827448647383\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.005576105322688818\n",
      "Loss on test= 0.005602383054792881\n",
      "acc for Lsat= 0.09802620933255271 \n",
      "acc for Psat= 0.139425916461757 \n",
      "acc for optim= 0.1793502120472604\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005485002417117357\n",
      "Loss on test= 0.005694039631634951\n",
      "acc for Lsat= 0.10969289093997292 \n",
      "acc for Psat= 0.14325467492390825 \n",
      "acc for optim= 0.1705789258034988\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.00549284229055047\n",
      "Loss on test= 0.005487553775310516\n",
      "acc for Lsat= 0.09874368036636608 \n",
      "acc for Psat= 0.13708787204981293 \n",
      "acc for optim= 0.17194418995711966\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.00550618814304471\n",
      "Loss on test= 0.005468728486448526\n",
      "acc for Lsat= 0.10106585734772396 \n",
      "acc for Psat= 0.13291131664204472 \n",
      "acc for optim= 0.17436811635569618\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.0055000134743750095\n",
      "Loss on test= 0.0056048049591481686\n",
      "acc for Lsat= 0.11404431737940507 \n",
      "acc for Psat= 0.13728560813497342 \n",
      "acc for optim= 0.17827796708553326\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.005568499211221933\n",
      "Loss on test= 0.0056203980930149555\n",
      "acc for Lsat= 0.09116549584399075 \n",
      "acc for Psat= 0.1460525567115936 \n",
      "acc for optim= 0.17478986980468353\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.0054772174917161465\n",
      "Loss on test= 0.005611402448266745\n",
      "acc for Lsat= 0.10241245983407016 \n",
      "acc for Psat= 0.17182316644568738 \n",
      "acc for optim= 0.17399579224139736\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.005686142481863499\n",
      "Loss on test= 0.005777094047516584\n",
      "acc for Lsat= 0.10830119432604399 \n",
      "acc for Psat= 0.15448115764160616 \n",
      "acc for optim= 0.17430186454077704\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.005712206941097975\n",
      "Loss on test= 0.005397002212703228\n",
      "acc for Lsat= 0.09029210924150853 \n",
      "acc for Psat= 0.1280481293183461 \n",
      "acc for optim= 0.17461486204784532\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.005358053836971521\n",
      "Loss on test= 0.005529098212718964\n",
      "acc for Lsat= 0.09498369529486612 \n",
      "acc for Psat= 0.1408809456227794 \n",
      "acc for optim= 0.17720592584589975\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.005376792978495359\n",
      "Loss on test= 0.005566679872572422\n",
      "acc for Lsat= 0.1049767676398718 \n",
      "acc for Psat= 0.13263207268195204 \n",
      "acc for optim= 0.1808532615655536\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.005407023709267378\n",
      "Loss on test= 0.005460330750793219\n",
      "acc for Lsat= 0.09833099055076427 \n",
      "acc for Psat= 0.14956270685306172 \n",
      "acc for optim= 0.18014383215317187\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.005660759285092354\n",
      "Loss on test= 0.006091098301112652\n",
      "acc for Lsat= 0.09740638571349484 \n",
      "acc for Psat= 0.154725559324819 \n",
      "acc for optim= 0.1968484528999299\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.0056525529362261295\n",
      "Loss on test= 0.00531539972871542\n",
      "acc for Lsat= 0.0859044017942742 \n",
      "acc for Psat= 0.1321934659002157 \n",
      "acc for optim= 0.1757609663509848\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.005483176559209824\n",
      "Loss on test= 0.00526910275220871\n",
      "acc for Lsat= 0.09535029091681724 \n",
      "acc for Psat= 0.12994176851281883 \n",
      "acc for optim= 0.1702873271631049\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.00544365867972374\n",
      "Loss on test= 0.005462162662297487\n",
      "acc for Lsat= 0.09933510749583915 \n",
      "acc for Psat= 0.14221895187849426 \n",
      "acc for optim= 0.17613734180465168\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.0055554951541125774\n",
      "Loss on test= 0.00556938024237752\n",
      "acc for Lsat= 0.10151158216428263 \n",
      "acc for Psat= 0.1508192034765474 \n",
      "acc for optim= 0.17883102772238263\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005518736317753792\n",
      "Loss on test= 0.005343097262084484\n",
      "acc for Lsat= 0.10103204167790937 \n",
      "acc for Psat= 0.14119388726760154 \n",
      "acc for optim= 0.17189450202980927\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.005508632864803076\n",
      "Loss on test= 0.005326451268047094\n",
      "acc for Lsat= 0.09933975256225912 \n",
      "acc for Psat= 0.1372883718388432 \n",
      "acc for optim= 0.17398078679314102\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.005424457602202892\n",
      "Loss on test= 0.00543120177462697\n",
      "acc for Lsat= 0.0962632084098201 \n",
      "acc for Psat= 0.1553202052924167 \n",
      "acc for optim= 0.1750128055772055\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.005389989819377661\n",
      "Loss on test= 0.00538153201341629\n",
      "acc for Lsat= 0.09050765140082641 \n",
      "acc for Psat= 0.1385211626158363 \n",
      "acc for optim= 0.17458306637913543\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.005451698321849108\n",
      "Loss on test= 0.005542796570807695\n",
      "acc for Lsat= 0.09951747881663127 \n",
      "acc for Psat= 0.14068056879222166 \n",
      "acc for optim= 0.17665850499493851\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.005316048860549927\n",
      "Loss on test= 0.00543054798617959\n",
      "acc for Lsat= 0.0938506456519905 \n",
      "acc for Psat= 0.13826669255492585 \n",
      "acc for optim= 0.17640629997461205\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.005329279229044914\n",
      "Loss on test= 0.0055288090370595455\n",
      "acc for Lsat= 0.09706881841115368 \n",
      "acc for Psat= 0.13905575791746694 \n",
      "acc for optim= 0.18358560843154084\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.0054463851265609264\n",
      "Loss on test= 0.0054758270271122456\n",
      "acc for Lsat= 0.09402923442706418 \n",
      "acc for Psat= 0.12557619896196648 \n",
      "acc for optim= 0.17058267955537695\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.00549228023737669\n",
      "Loss on test= 0.005594016518443823\n",
      "acc for Lsat= 0.09422258734451355 \n",
      "acc for Psat= 0.13427564460773675 \n",
      "acc for optim= 0.1710156927442153\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.005720718298107386\n",
      "Loss on test= 0.00609339727088809\n",
      "acc for Lsat= 0.10020671078657599 \n",
      "acc for Psat= 0.17461113895247715 \n",
      "acc for optim= 0.1913326984608461\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.00569869065657258\n",
      "Loss on test= 0.0054505872540175915\n",
      "acc for Lsat= 0.09442457560559174 \n",
      "acc for Psat= 0.14451932428562794 \n",
      "acc for optim= 0.17749995925279674\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.005381809081882238\n",
      "Loss on test= 0.005292065907269716\n",
      "acc for Lsat= 0.09694010593355759 \n",
      "acc for Psat= 0.13386068958277828 \n",
      "acc for optim= 0.177044614424262\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.005580441560596228\n",
      "Loss on test= 0.005604064092040062\n",
      "acc for Lsat= 0.10236639336417776 \n",
      "acc for Psat= 0.14151666404673913 \n",
      "acc for optim= 0.17444878389112609\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.005465382244437933\n",
      "Loss on test= 0.005602417979389429\n",
      "acc for Lsat= 0.10264480952409448 \n",
      "acc for Psat= 0.15342309181987485 \n",
      "acc for optim= 0.18019789483239307\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.005457151681184769\n",
      "Loss on test= 0.005338190123438835\n",
      "acc for Lsat= 0.09285986542389199 \n",
      "acc for Psat= 0.13207226534079283 \n",
      "acc for optim= 0.1713624526502728\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.005505128297954798\n",
      "Loss on test= 0.005620487034320831\n",
      "acc for Lsat= 0.09750636037731326 \n",
      "acc for Psat= 0.15573846070942268 \n",
      "acc for optim= 0.17758356818268187\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.005425896495580673\n",
      "Loss on test= 0.00546661764383316\n",
      "acc for Lsat= 0.09354266841546632 \n",
      "acc for Psat= 0.13458426167120263 \n",
      "acc for optim= 0.16996547837393214\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.005450241733342409\n",
      "Loss on test= 0.005754404701292515\n",
      "acc for Lsat= 0.09382908543547445 \n",
      "acc for Psat= 0.15147991374829575 \n",
      "acc for optim= 0.17216759620265368\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.005376114044338465\n",
      "Loss on test= 0.005614344961941242\n",
      "acc for Lsat= 0.09773202335742787 \n",
      "acc for Psat= 0.1387803984295002 \n",
      "acc for optim= 0.17184168042935985\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.005487028509378433\n",
      "Loss on test= 0.005708792246878147\n",
      "acc for Lsat= 0.11766723999313104 \n",
      "acc for Psat= 0.13478521238347813 \n",
      "acc for optim= 0.17528453609643416\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.005723993759602308\n",
      "Loss on test= 0.005564279854297638\n",
      "acc for Lsat= 0.09774713786346428 \n",
      "acc for Psat= 0.13193412573624252 \n",
      "acc for optim= 0.17165017883825065\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.0054747178219258785\n",
      "Loss on test= 0.005364348646253347\n",
      "acc for Lsat= 0.10899173440171776 \n",
      "acc for Psat= 0.13058204580256888 \n",
      "acc for optim= 0.17148146452539526\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005528888665139675\n",
      "Loss on test= 0.005731635726988316\n",
      "acc for Lsat= 0.10191140966639363 \n",
      "acc for Psat= 0.15262000081202132 \n",
      "acc for optim= 0.1833210765003428\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.005590755958110094\n",
      "Loss on test= 0.005257843993604183\n",
      "acc for Lsat= 0.08863624001635283 \n",
      "acc for Psat= 0.13982859201860265 \n",
      "acc for optim= 0.17409841616943203\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.005501396954059601\n",
      "Loss on test= 0.005624021869152784\n",
      "acc for Lsat= 0.12050632408716262 \n",
      "acc for Psat= 0.1602783312379403 \n",
      "acc for optim= 0.17182783031563992\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.0056216176599264145\n",
      "Loss on test= 0.0054061743430793285\n",
      "acc for Lsat= 0.09278682991083927 \n",
      "acc for Psat= 0.13550622847892432 \n",
      "acc for optim= 0.17156121577218564\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.00549499923363328\n",
      "Loss on test= 0.00544578256085515\n",
      "acc for Lsat= 0.10484098468795482 \n",
      "acc for Psat= 0.13906879426719349 \n",
      "acc for optim= 0.17198929035952756\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.005476112011820078\n",
      "Loss on test= 0.005636940710246563\n",
      "acc for Lsat= 0.09730503663465513 \n",
      "acc for Psat= 0.16826340661901742 \n",
      "acc for optim= 0.17619623455381794\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.005483771208673716\n",
      "Loss on test= 0.005507608409970999\n",
      "acc for Lsat= 0.08821974810259259 \n",
      "acc for Psat= 0.13421919305157545 \n",
      "acc for optim= 0.1701538629249872\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.005402576178312302\n",
      "Loss on test= 0.005428835283964872\n",
      "acc for Lsat= 0.09122102456933283 \n",
      "acc for Psat= 0.13460744988854434 \n",
      "acc for optim= 0.17847719284160318\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.005374884698539972\n",
      "Loss on test= 0.005375301465392113\n",
      "acc for Lsat= 0.0963613140504426 \n",
      "acc for Psat= 0.14131944831555104 \n",
      "acc for optim= 0.17374022536013572\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.005391894839704037\n",
      "Loss on test= 0.005381216295063496\n",
      "acc for Lsat= 0.09047842635413257 \n",
      "acc for Psat= 0.12415227839724016 \n",
      "acc for optim= 0.17643336675197085\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.005339066497981548\n",
      "Loss on test= 0.005193217657506466\n",
      "acc for Lsat= 0.08758489878242914 \n",
      "acc for Psat= 0.13182251679274878 \n",
      "acc for optim= 0.17187002330064313\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.005432561971247196\n",
      "Loss on test= 0.005307486280798912\n",
      "acc for Lsat= 0.1001039573208333 \n",
      "acc for Psat= 0.1511863113801401 \n",
      "acc for optim= 0.17001502139130417\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.005452433135360479\n",
      "Loss on test= 0.005438551306724548\n",
      "acc for Lsat= 0.09549166106051023 \n",
      "acc for Psat= 0.14353897874325167 \n",
      "acc for optim= 0.1857529274972409\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005483204964548349\n",
      "Loss on test= 0.005627410486340523\n",
      "acc for Lsat= 0.1007689799643157 \n",
      "acc for Psat= 0.13775551535572222 \n",
      "acc for optim= 0.18226912207712695\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005587304476648569\n",
      "Loss on test= 0.005184579640626907\n",
      "acc for Lsat= 0.09225754881245431 \n",
      "acc for Psat= 0.13488169173974343 \n",
      "acc for optim= 0.17282009165973175\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.005345053505152464\n",
      "Loss on test= 0.005496842786669731\n",
      "acc for Lsat= 0.09604773388776733 \n",
      "acc for Psat= 0.13126183095812086 \n",
      "acc for optim= 0.17208913233441087\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.005511923227459192\n",
      "Loss on test= 0.005509256850928068\n",
      "acc for Lsat= 0.09600575674326015 \n",
      "acc for Psat= 0.1369906945668894 \n",
      "acc for optim= 0.17361092961486113\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.005460711196064949\n",
      "Loss on test= 0.005486480891704559\n",
      "acc for Lsat= 0.09333427621413648 \n",
      "acc for Psat= 0.14052340093090804 \n",
      "acc for optim= 0.17867155901842272\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.005625682417303324\n",
      "Loss on test= 0.005825362633913755\n",
      "acc for Lsat= 0.10452048279517298 \n",
      "acc for Psat= 0.15315629557164503 \n",
      "acc for optim= 0.17758173403696698\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.005534898489713669\n",
      "Loss on test= 0.0055879647843539715\n",
      "acc for Lsat= 0.10320594159162971 \n",
      "acc for Psat= 0.1340468761688523 \n",
      "acc for optim= 0.17733293357446814\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.005395052954554558\n",
      "Loss on test= 0.00543255265802145\n",
      "acc for Lsat= 0.0871469698023567 \n",
      "acc for Psat= 0.1342836844831598 \n",
      "acc for optim= 0.16789157950001568\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.00549091724678874\n",
      "Loss on test= 0.005467383656650782\n",
      "acc for Lsat= 0.08824159139913791 \n",
      "acc for Psat= 0.1292304023699143 \n",
      "acc for optim= 0.17363891220845068\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.005331235006451607\n",
      "Loss on test= 0.005386736243963242\n",
      "acc for Lsat= 0.10268629825460832 \n",
      "acc for Psat= 0.13247401025492345 \n",
      "acc for optim= 0.16941734121103985\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005233659874647856\n",
      "Loss on test= 0.005213949363678694\n",
      "acc for Lsat= 0.08861134580975222 \n",
      "acc for Psat= 0.13086224487503656 \n",
      "acc for optim= 0.17426722481180862\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.0053499555215239525\n",
      "Loss on test= 0.005384495947510004\n",
      "acc for Lsat= 0.10980603760312865 \n",
      "acc for Psat= 0.13659289381718515 \n",
      "acc for optim= 0.1754900031419065\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.005309192929416895\n",
      "Loss on test= 0.005379919894039631\n",
      "acc for Lsat= 0.092060950146579 \n",
      "acc for Psat= 0.14114419650571575 \n",
      "acc for optim= 0.17317580796362883\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.00554052134975791\n",
      "Loss on test= 0.005411546211689711\n",
      "acc for Lsat= 0.09536212694345866 \n",
      "acc for Psat= 0.1392479795749013 \n",
      "acc for optim= 0.175232841177628\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.005518019199371338\n",
      "Loss on test= 0.005486722104251385\n",
      "acc for Lsat= 0.0986923235515516 \n",
      "acc for Psat= 0.14038872454870757 \n",
      "acc for optim= 0.1772929268068716\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.005341674201190472\n",
      "Loss on test= 0.005523270461708307\n",
      "acc for Lsat= 0.09713348762043834 \n",
      "acc for Psat= 0.132565035055548 \n",
      "acc for optim= 0.1829313505315096\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.0053654820658266544\n",
      "Loss on test= 0.005566600244492292\n",
      "acc for Lsat= 0.10860192605827793 \n",
      "acc for Psat= 0.14323892175122416 \n",
      "acc for optim= 0.16996538575905426\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.005311513785272837\n",
      "Loss on test= 0.00530371954664588\n",
      "acc for Lsat= 0.09533310530359568 \n",
      "acc for Psat= 0.14117346382222054 \n",
      "acc for optim= 0.17377124379571476\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.005289033520966768\n",
      "Loss on test= 0.0055760727263987064\n",
      "acc for Lsat= 0.09612192932753887 \n",
      "acc for Psat= 0.1373096307412394 \n",
      "acc for optim= 0.1709005067965041\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.0052773309871554375\n",
      "Loss on test= 0.005469383206218481\n",
      "acc for Lsat= 0.09066996876739526 \n",
      "acc for Psat= 0.12907881433528853 \n",
      "acc for optim= 0.17564702636524532\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.0054152533411979675\n",
      "Loss on test= 0.005634291563183069\n",
      "acc for Lsat= 0.0952293070361004 \n",
      "acc for Psat= 0.13339617571752593 \n",
      "acc for optim= 0.17255490423210446\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.005482905078679323\n",
      "Loss on test= 0.005300032906234264\n",
      "acc for Lsat= 0.10298378058595935 \n",
      "acc for Psat= 0.1481875535123313 \n",
      "acc for optim= 0.1726789702762609\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.005478100385516882\n",
      "Loss on test= 0.00545602198690176\n",
      "acc for Lsat= 0.09676829643482247 \n",
      "acc for Psat= 0.1499172521375963 \n",
      "acc for optim= 0.17030108242053413\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.005441433284431696\n",
      "Loss on test= 0.005343864671885967\n",
      "acc for Lsat= 0.11006684804601104 \n",
      "acc for Psat= 0.1364144609650228 \n",
      "acc for optim= 0.17775271513852892\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.005462112370878458\n",
      "Loss on test= 0.005911250598728657\n",
      "acc for Lsat= 0.12639358124923436 \n",
      "acc for Psat= 0.15221233924888578 \n",
      "acc for optim= 0.17112491462172033\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.0054009584710001945\n",
      "Loss on test= 0.005570239387452602\n",
      "acc for Lsat= 0.09564493128159116 \n",
      "acc for Psat= 0.1324412156790385 \n",
      "acc for optim= 0.17533775088995263\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.005376714747399092\n",
      "Loss on test= 0.005273664370179176\n",
      "acc for Lsat= 0.09017763698493182 \n",
      "acc for Psat= 0.1301269891403511 \n",
      "acc for optim= 0.17391141842617308\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.00526504497975111\n",
      "Loss on test= 0.005349395330995321\n",
      "acc for Lsat= 0.09360643746588942 \n",
      "acc for Psat= 0.13195930227320296 \n",
      "acc for optim= 0.17049203498474427\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.005519813392311335\n",
      "Loss on test= 0.0058115157298743725\n",
      "acc for Lsat= 0.13974116687657787 \n",
      "acc for Psat= 0.14373930601200177 \n",
      "acc for optim= 0.17174142421926436\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.005368083715438843\n",
      "Loss on test= 0.005680914036929607\n",
      "acc for Lsat= 0.09167451857147908 \n",
      "acc for Psat= 0.1423302507050598 \n",
      "acc for optim= 0.17983684751674742\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.0053372676484286785\n",
      "Loss on test= 0.005209602415561676\n",
      "acc for Lsat= 0.08951682368697712 \n",
      "acc for Psat= 0.1308287699430366 \n",
      "acc for optim= 0.17338536551255243\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.0053322226740419865\n",
      "Loss on test= 0.005326863378286362\n",
      "acc for Lsat= 0.09364248573173599 \n",
      "acc for Psat= 0.13664747922440576 \n",
      "acc for optim= 0.1721328002222927\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.005549467168748379\n",
      "Loss on test= 0.00532835628837347\n",
      "acc for Lsat= 0.09450965025393383 \n",
      "acc for Psat= 0.135346786537903 \n",
      "acc for optim= 0.17013946749500827\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.005205635912716389\n",
      "Loss on test= 0.005332854110747576\n",
      "acc for Lsat= 0.09235351284095904 \n",
      "acc for Psat= 0.14440283978576582 \n",
      "acc for optim= 0.17789264625517298\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.005415516905486584\n",
      "Loss on test= 0.005240389611572027\n",
      "acc for Lsat= 0.08950901942778335 \n",
      "acc for Psat= 0.12812212059223974 \n",
      "acc for optim= 0.17821760097246403\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005358095280826092\n",
      "Loss on test= 0.005295886658132076\n",
      "acc for Lsat= 0.09515666704818786 \n",
      "acc for Psat= 0.1381553547216754 \n",
      "acc for optim= 0.16459419899242553\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.005453084595501423\n",
      "Loss on test= 0.005462481174618006\n",
      "acc for Lsat= 0.09049453768745258 \n",
      "acc for Psat= 0.13556985289206086 \n",
      "acc for optim= 0.17637167468342954\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.005498574580997229\n",
      "Loss on test= 0.0055952174589037895\n",
      "acc for Lsat= 0.1080450271177609 \n",
      "acc for Psat= 0.13194798800297478 \n",
      "acc for optim= 0.17264110721943499\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.005332629662007093\n",
      "Loss on test= 0.005293865688145161\n",
      "acc for Lsat= 0.10102293029312687 \n",
      "acc for Psat= 0.13882141289557054 \n",
      "acc for optim= 0.16925472108650375\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.005353657528758049\n",
      "Loss on test= 0.005349390208721161\n",
      "acc for Lsat= 0.10225916137042569 \n",
      "acc for Psat= 0.14129274663561797 \n",
      "acc for optim= 0.17601692537298091\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.005312134511768818\n",
      "Loss on test= 0.0054323263466358185\n",
      "acc for Lsat= 0.11762508685264825 \n",
      "acc for Psat= 0.1304413272252065 \n",
      "acc for optim= 0.17761278234782465\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.005439371801912785\n",
      "Loss on test= 0.006002251524478197\n",
      "acc for Lsat= 0.11259627383652834 \n",
      "acc for Psat= 0.15341879981900314 \n",
      "acc for optim= 0.17023083383281953\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.005528126377612352\n",
      "Loss on test= 0.0056378478184342384\n",
      "acc for Lsat= 0.11405172148442944 \n",
      "acc for Psat= 0.155199423081531 \n",
      "acc for optim= 0.17057805249311747\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.0055256979539990425\n",
      "Loss on test= 0.005241124890744686\n",
      "acc for Lsat= 0.09234389962423577 \n",
      "acc for Psat= 0.12876965933340928 \n",
      "acc for optim= 0.16975231363431778\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.005407831631600857\n",
      "Loss on test= 0.0052130091935396194\n",
      "acc for Lsat= 0.09593251221392436 \n",
      "acc for Psat= 0.13356404071709146 \n",
      "acc for optim= 0.17577674651181804\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.005267261993139982\n",
      "Loss on test= 0.00544885266572237\n",
      "acc for Lsat= 0.10088590494716128 \n",
      "acc for Psat= 0.13649988992885384 \n",
      "acc for optim= 0.17145575163001037\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.00534687889739871\n",
      "Loss on test= 0.005365610122680664\n",
      "acc for Lsat= 0.09306948010281131 \n",
      "acc for Psat= 0.13402399288827074 \n",
      "acc for optim= 0.1733451453715994\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.005324069876223803\n",
      "Loss on test= 0.0054170554503798485\n",
      "acc for Lsat= 0.1057003739349327 \n",
      "acc for Psat= 0.1497322369321262 \n",
      "acc for optim= 0.16570122682286317\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.005468531511723995\n",
      "Loss on test= 0.005328863859176636\n",
      "acc for Lsat= 0.10291683260033638 \n",
      "acc for Psat= 0.14576053534590364 \n",
      "acc for optim= 0.17809307667886135\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005388383287936449\n",
      "Loss on test= 0.0053593129850924015\n",
      "acc for Lsat= 0.11020865356801329 \n",
      "acc for Psat= 0.13198589598579094 \n",
      "acc for optim= 0.17171211376773646\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.005240255501121283\n",
      "Loss on test= 0.0054247379302978516\n",
      "acc for Lsat= 0.09500304261726686 \n",
      "acc for Psat= 0.13855314084466464 \n",
      "acc for optim= 0.17323014130768669\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.005365372635424137\n",
      "Loss on test= 0.005186724476516247\n",
      "acc for Lsat= 0.10762211049252467 \n",
      "acc for Psat= 0.15116441472894843 \n",
      "acc for optim= 0.16884647649448123\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.005188523326069117\n",
      "Loss on test= 0.005610150285065174\n",
      "acc for Lsat= 0.09134882623972795 \n",
      "acc for Psat= 0.14648159879190545 \n",
      "acc for optim= 0.17596784738880406\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.005389960017055273\n",
      "Loss on test= 0.005405344534665346\n",
      "acc for Lsat= 0.08744304336397436 \n",
      "acc for Psat= 0.13597020595232215 \n",
      "acc for optim= 0.17270681232656823\n",
      "Fold 4\n",
      "Epoch:1/1000\n",
      "Loss on train= 1.064165472984314\n",
      "Loss on test= 0.5844829678535461\n",
      "acc for Lsat= 32.0586954938575 \n",
      "acc for Psat= 112.44455726620131 \n",
      "acc for optim= 2.6071877768829568\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.5092655420303345\n",
      "Loss on test= 0.4522351324558258\n",
      "acc for Lsat= 6.697000779360973 \n",
      "acc for Psat= 17.644907966756314 \n",
      "acc for optim= 3.381025214491839\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.4395465850830078\n",
      "Loss on test= 0.4074046015739441\n",
      "acc for Lsat= 11.14396981469582 \n",
      "acc for Psat= 31.629494282851198 \n",
      "acc for optim= 5.886572524416732\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.37619709968566895\n",
      "Loss on test= 0.36137139797210693\n",
      "acc for Lsat= 4.147682033740361 \n",
      "acc for Psat= 5.768726200035244 \n",
      "acc for optim= 410.74939882518987\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.365330308675766\n",
      "Loss on test= 0.296657919883728\n",
      "acc for Lsat= 3.8067938000313006 \n",
      "acc for Psat= 18.31783745906983 \n",
      "acc for optim= 3.14534041259636\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.32343533635139465\n",
      "Loss on test= 0.26098957657814026\n",
      "acc for Lsat= 7.694567213814652 \n",
      "acc for Psat= 11.446907132303947 \n",
      "acc for optim= 5.190897548130739\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.2935691177845001\n",
      "Loss on test= 0.27494972944259644\n",
      "acc for Lsat= 7.030851609215166 \n",
      "acc for Psat= 9.308627728660705 \n",
      "acc for optim= 4.1976069996945204\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.2474791407585144\n",
      "Loss on test= 0.22007803618907928\n",
      "acc for Lsat= 5.384135407176989 \n",
      "acc for Psat= 5.678988505016409 \n",
      "acc for optim= 1.9521561517613009\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.2231755554676056\n",
      "Loss on test= 0.19285112619400024\n",
      "acc for Lsat= 2.285707028231873 \n",
      "acc for Psat= 5.800586119563181 \n",
      "acc for optim= 2.5220681483707095\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.17689843475818634\n",
      "Loss on test= 0.16138432919979095\n",
      "acc for Lsat= 2.9352430243468275 \n",
      "acc for Psat= 7.735585136096799 \n",
      "acc for optim= 3.279071973186817\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.1559520661830902\n",
      "Loss on test= 0.1258469969034195\n",
      "acc for Lsat= 1.7074630484472633 \n",
      "acc for Psat= 2.8525590040670656 \n",
      "acc for optim= 7.486270638045696\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.13141773641109467\n",
      "Loss on test= 0.1221214234828949\n",
      "acc for Lsat= 1.8860385476279613 \n",
      "acc for Psat= 1.5163082575578497 \n",
      "acc for optim= 0.7807876490846251\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.11663231998682022\n",
      "Loss on test= 0.11288344115018845\n",
      "acc for Lsat= 1.37361378772609 \n",
      "acc for Psat= 3.1775703329216953 \n",
      "acc for optim= 6.14342760378487\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.10690651088953018\n",
      "Loss on test= 0.0925288200378418\n",
      "acc for Lsat= 1.0652395614857055 \n",
      "acc for Psat= 2.073301307561279 \n",
      "acc for optim= 1.4915443707023106\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.09424059092998505\n",
      "Loss on test= 0.0873669907450676\n",
      "acc for Lsat= 1.442444759840303 \n",
      "acc for Psat= 1.71705586298619 \n",
      "acc for optim= 5.740972063121287\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.07982758432626724\n",
      "Loss on test= 0.08085210621356964\n",
      "acc for Lsat= 1.0473571513927733 \n",
      "acc for Psat= 1.0123591781656787 \n",
      "acc for optim= 1.5220031389397115\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.08138615638017654\n",
      "Loss on test= 0.06944732367992401\n",
      "acc for Lsat= 0.978734724317218 \n",
      "acc for Psat= 1.2154585532906994 \n",
      "acc for optim= 0.8723545262001682\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.06739196181297302\n",
      "Loss on test= 0.06887228786945343\n",
      "acc for Lsat= 1.3537021671796243 \n",
      "acc for Psat= 0.9543689159083344 \n",
      "acc for optim= 2.9691649464122647\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.06122143194079399\n",
      "Loss on test= 0.05285955220460892\n",
      "acc for Lsat= 0.9682996463914704 \n",
      "acc for Psat= 0.9793051335499685 \n",
      "acc for optim= 0.5018130598348737\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.055263444781303406\n",
      "Loss on test= 0.053614623844623566\n",
      "acc for Lsat= 0.6302754957987172 \n",
      "acc for Psat= 0.9302601760966748 \n",
      "acc for optim= 0.606102818033636\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.04767828434705734\n",
      "Loss on test= 0.04722372815012932\n",
      "acc for Lsat= 0.8322797117092509 \n",
      "acc for Psat= 0.8830361579595184 \n",
      "acc for optim= 0.4159735646962135\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.048006437718868256\n",
      "Loss on test= 0.04542989283800125\n",
      "acc for Lsat= 0.8736053004521072 \n",
      "acc for Psat= 0.7680105212839899 \n",
      "acc for optim= 0.41723464954977957\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.0468396358191967\n",
      "Loss on test= 0.04594889655709267\n",
      "acc for Lsat= 0.6377617093007634 \n",
      "acc for Psat= 0.966116062102358 \n",
      "acc for optim= 1.757557219247148\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.042099423706531525\n",
      "Loss on test= 0.04305242374539375\n",
      "acc for Lsat= 0.616868587660704 \n",
      "acc for Psat= 0.9813724156694071 \n",
      "acc for optim= 0.5966557917948907\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.041666340082883835\n",
      "Loss on test= 0.04311176389455795\n",
      "acc for Lsat= 1.0414690099955684 \n",
      "acc for Psat= 0.8700369704273652 \n",
      "acc for optim= 0.4240235338129915\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.04059157520532608\n",
      "Loss on test= 0.03906317055225372\n",
      "acc for Lsat= 0.7283504628842304 \n",
      "acc for Psat= 0.6277815889601747 \n",
      "acc for optim= 0.6577789175763256\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.035920362919569016\n",
      "Loss on test= 0.038085829466581345\n",
      "acc for Lsat= 0.6644664760211723 \n",
      "acc for Psat= 0.648241460416938 \n",
      "acc for optim= 0.3144938797930671\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.03507053479552269\n",
      "Loss on test= 0.03528674691915512\n",
      "acc for Lsat= 0.8020809809755962 \n",
      "acc for Psat= 0.7649523374338232 \n",
      "acc for optim= 0.40665104142327263\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.03478316590189934\n",
      "Loss on test= 0.03448323905467987\n",
      "acc for Lsat= 0.6681078460049419 \n",
      "acc for Psat= 0.7591357092542976 \n",
      "acc for optim= 0.6164138432685757\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.0329192578792572\n",
      "Loss on test= 0.03387882187962532\n",
      "acc for Lsat= 0.7453846806484098 \n",
      "acc for Psat= 0.687190390604637 \n",
      "acc for optim= 0.5487361561032673\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.03202284127473831\n",
      "Loss on test= 0.03224816918373108\n",
      "acc for Lsat= 0.759934878255228 \n",
      "acc for Psat= 0.7147741339364517 \n",
      "acc for optim= 0.2797849650672327\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.03280053287744522\n",
      "Loss on test= 0.0314626581966877\n",
      "acc for Lsat= 0.5381763656324757 \n",
      "acc for Psat= 0.6594595793214614 \n",
      "acc for optim= 0.25293558349320033\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.03084568865597248\n",
      "Loss on test= 0.029018454253673553\n",
      "acc for Lsat= 0.5292936783993404 \n",
      "acc for Psat= 0.6013649462571217 \n",
      "acc for optim= 0.29974374599732\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.029501184821128845\n",
      "Loss on test= 0.028903013095259666\n",
      "acc for Lsat= 0.5555933722195757 \n",
      "acc for Psat= 0.6208328491311231 \n",
      "acc for optim= 0.265324957377448\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.02811921015381813\n",
      "Loss on test= 0.03132958710193634\n",
      "acc for Lsat= 0.5902851496853022 \n",
      "acc for Psat= 0.576904313217194 \n",
      "acc for optim= 0.2824189299079916\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.02930554561316967\n",
      "Loss on test= 0.025400543585419655\n",
      "acc for Lsat= 0.532382398308884 \n",
      "acc for Psat= 0.6427566486110319 \n",
      "acc for optim= 0.269361994835718\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.02884046733379364\n",
      "Loss on test= 0.02720099501311779\n",
      "acc for Lsat= 0.4854526818405272 \n",
      "acc for Psat= 0.647600625983024 \n",
      "acc for optim= 0.3057591152157968\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.02693403698503971\n",
      "Loss on test= 0.024842558428645134\n",
      "acc for Lsat= 0.5068551368879255 \n",
      "acc for Psat= 0.6386421888553839 \n",
      "acc for optim= 0.25429161393421473\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.025980526581406593\n",
      "Loss on test= 0.028724223375320435\n",
      "acc for Lsat= 0.48439181651377333 \n",
      "acc for Psat= 0.5090619072611475 \n",
      "acc for optim= 0.25227792151575135\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.025585457682609558\n",
      "Loss on test= 0.026578396558761597\n",
      "acc for Lsat= 0.5419008701281053 \n",
      "acc for Psat= 0.6198802565392012 \n",
      "acc for optim= 0.25184485765301456\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.026141947135329247\n",
      "Loss on test= 0.024569720029830933\n",
      "acc for Lsat= 0.43281214628714715 \n",
      "acc for Psat= 0.6143192017657015 \n",
      "acc for optim= 0.2871710084415296\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.02542349137365818\n",
      "Loss on test= 0.0244272630661726\n",
      "acc for Lsat= 0.4586587505898048 \n",
      "acc for Psat= 0.5568939320675437 \n",
      "acc for optim= 0.30988979036801784\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.025447145104408264\n",
      "Loss on test= 0.024005226790905\n",
      "acc for Lsat= 0.47716260692765433 \n",
      "acc for Psat= 0.46323612343199 \n",
      "acc for optim= 0.33637733093849886\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.02429390512406826\n",
      "Loss on test= 0.024386970326304436\n",
      "acc for Lsat= 0.4830812436663797 \n",
      "acc for Psat= 0.6008578268153321 \n",
      "acc for optim= 0.27437025822566924\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.02375689707696438\n",
      "Loss on test= 0.024733157828450203\n",
      "acc for Lsat= 0.41035207139715124 \n",
      "acc for Psat= 0.5084357450085353 \n",
      "acc for optim= 0.25199908812499267\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.023167287930846214\n",
      "Loss on test= 0.023748056963086128\n",
      "acc for Lsat= 0.3785785702592064 \n",
      "acc for Psat= 0.6084796291991527 \n",
      "acc for optim= 0.26060589339318246\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.022968176752328873\n",
      "Loss on test= 0.022758375853300095\n",
      "acc for Lsat= 0.39945770290875304 \n",
      "acc for Psat= 0.5881846411447859 \n",
      "acc for optim= 0.2821078570229253\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.0231184009462595\n",
      "Loss on test= 0.023325448855757713\n",
      "acc for Lsat= 0.365134279934864 \n",
      "acc for Psat= 0.5732102828738248 \n",
      "acc for optim= 0.22801530005112663\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.023187711834907532\n",
      "Loss on test= 0.02084573730826378\n",
      "acc for Lsat= 0.4350466309064162 \n",
      "acc for Psat= 0.5294834272713775 \n",
      "acc for optim= 0.24040109283649488\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.02175767719745636\n",
      "Loss on test= 0.022986818104982376\n",
      "acc for Lsat= 0.4137615311095991 \n",
      "acc for Psat= 0.494230195345055 \n",
      "acc for optim= 0.2823197576065935\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.021698174998164177\n",
      "Loss on test= 0.020491506904363632\n",
      "acc for Lsat= 0.513890216407064 \n",
      "acc for Psat= 0.4850207058867405 \n",
      "acc for optim= 0.22561621381867775\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.021338818594813347\n",
      "Loss on test= 0.022723913192749023\n",
      "acc for Lsat= 0.43230498519580973 \n",
      "acc for Psat= 0.4356150203148482 \n",
      "acc for optim= 0.24938077035610173\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.02187780663371086\n",
      "Loss on test= 0.019547997042536736\n",
      "acc for Lsat= 0.38488562362004275 \n",
      "acc for Psat= 0.4840368338124323 \n",
      "acc for optim= 0.2391449286520042\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.021033769473433495\n",
      "Loss on test= 0.021249180659651756\n",
      "acc for Lsat= 0.47744345640043123 \n",
      "acc for Psat= 0.4626582936821128 \n",
      "acc for optim= 0.24161581523563852\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.021097278222441673\n",
      "Loss on test= 0.020070478320121765\n",
      "acc for Lsat= 0.4019376862738313 \n",
      "acc for Psat= 0.43584797430427186 \n",
      "acc for optim= 0.21671518403557433\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.020005708560347557\n",
      "Loss on test= 0.021700197830796242\n",
      "acc for Lsat= 0.554593940529181 \n",
      "acc for Psat= 0.489670300503742 \n",
      "acc for optim= 0.21629987922150995\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.02058473415672779\n",
      "Loss on test= 0.021618304774165154\n",
      "acc for Lsat= 0.4391745965333177 \n",
      "acc for Psat= 0.4668922750153453 \n",
      "acc for optim= 0.2990901886634576\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.020272865891456604\n",
      "Loss on test= 0.0205086562782526\n",
      "acc for Lsat= 0.4457255384343601 \n",
      "acc for Psat= 0.4883558107083789 \n",
      "acc for optim= 0.22743760477090758\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.020587582141160965\n",
      "Loss on test= 0.02178448624908924\n",
      "acc for Lsat= 0.4197998029322244 \n",
      "acc for Psat= 0.4768153196318717 \n",
      "acc for optim= 0.22501248748606462\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.02043546922504902\n",
      "Loss on test= 0.020509595051407814\n",
      "acc for Lsat= 0.519911280652269 \n",
      "acc for Psat= 0.4285950071109157 \n",
      "acc for optim= 0.24086076957570873\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.01983882486820221\n",
      "Loss on test= 0.019028685986995697\n",
      "acc for Lsat= 0.37090588575527955 \n",
      "acc for Psat= 0.47467967320856563 \n",
      "acc for optim= 0.21961959077998472\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.019654199481010437\n",
      "Loss on test= 0.0188958290964365\n",
      "acc for Lsat= 0.3759676811373415 \n",
      "acc for Psat= 0.45863224419205123 \n",
      "acc for optim= 0.24821130688852044\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.019294708967208862\n",
      "Loss on test= 0.020211046561598778\n",
      "acc for Lsat= 0.3728208889885069 \n",
      "acc for Psat= 0.47247304413657903 \n",
      "acc for optim= 0.2193509739484619\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.01915155164897442\n",
      "Loss on test= 0.018816187977790833\n",
      "acc for Lsat= 0.42534488912684 \n",
      "acc for Psat= 0.4170811099558361 \n",
      "acc for optim= 0.22067864140952936\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.01897015981376171\n",
      "Loss on test= 0.02034749649465084\n",
      "acc for Lsat= 0.42716104031943186 \n",
      "acc for Psat= 0.4782693452000023 \n",
      "acc for optim= 0.24305186981203136\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.01897938922047615\n",
      "Loss on test= 0.01821761392056942\n",
      "acc for Lsat= 0.3779259418606179 \n",
      "acc for Psat= 0.4774923506028171 \n",
      "acc for optim= 0.21784294249576036\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.018610702827572823\n",
      "Loss on test= 0.01931678131222725\n",
      "acc for Lsat= 0.3626546376645156 \n",
      "acc for Psat= 0.5329816486329356 \n",
      "acc for optim= 0.24267037889866688\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.018712177872657776\n",
      "Loss on test= 0.017534732818603516\n",
      "acc for Lsat= 0.37059133197495564 \n",
      "acc for Psat= 0.4453301507384969 \n",
      "acc for optim= 0.21455709560503336\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.0180681012570858\n",
      "Loss on test= 0.018285494297742844\n",
      "acc for Lsat= 0.37758610169151546 \n",
      "acc for Psat= 0.39441447459052376 \n",
      "acc for optim= 0.2633649295067526\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.0182010680437088\n",
      "Loss on test= 0.019451873376965523\n",
      "acc for Lsat= 0.5089200500419916 \n",
      "acc for Psat= 0.43022115515132836 \n",
      "acc for optim= 0.21299895035293515\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.017851468175649643\n",
      "Loss on test= 0.018932828679680824\n",
      "acc for Lsat= 0.3606468865253044 \n",
      "acc for Psat= 0.42456887723135484 \n",
      "acc for optim= 0.22203326545658875\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.018503814935684204\n",
      "Loss on test= 0.019323842599987984\n",
      "acc for Lsat= 0.3384728701537431 \n",
      "acc for Psat= 0.5280922429946431 \n",
      "acc for optim= 0.23357294668440354\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.017743825912475586\n",
      "Loss on test= 0.0186318326741457\n",
      "acc for Lsat= 0.3813710761055149 \n",
      "acc for Psat= 0.4538537148878645 \n",
      "acc for optim= 0.21747362803036005\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.01788315549492836\n",
      "Loss on test= 0.018513444811105728\n",
      "acc for Lsat= 0.41200897689889865 \n",
      "acc for Psat= 0.43136326438980177 \n",
      "acc for optim= 0.2244574539829439\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.01802557334303856\n",
      "Loss on test= 0.019523153081536293\n",
      "acc for Lsat= 0.3422520652600577 \n",
      "acc for Psat= 0.5741829459124396 \n",
      "acc for optim= 0.22487354958414202\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.017092382535338402\n",
      "Loss on test= 0.017215073108673096\n",
      "acc for Lsat= 0.4149143234241598 \n",
      "acc for Psat= 0.45559528280235195 \n",
      "acc for optim= 0.23053809648676227\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.017505262047052383\n",
      "Loss on test= 0.01834023930132389\n",
      "acc for Lsat= 0.3555595098225387 \n",
      "acc for Psat= 0.45303439311809035 \n",
      "acc for optim= 0.23211071056996574\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.017006201669573784\n",
      "Loss on test= 0.017588479444384575\n",
      "acc for Lsat= 0.386744422843598 \n",
      "acc for Psat= 0.3715055310042501 \n",
      "acc for optim= 0.20679047938776077\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.017245426774024963\n",
      "Loss on test= 0.017671165987849236\n",
      "acc for Lsat= 0.47584540647615026 \n",
      "acc for Psat= 0.3924638285105765 \n",
      "acc for optim= 0.2035374987570174\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.01735532656311989\n",
      "Loss on test= 0.016676103696227074\n",
      "acc for Lsat= 0.3555818467418273 \n",
      "acc for Psat= 0.4284974099117224 \n",
      "acc for optim= 0.2370631038732402\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.01782250963151455\n",
      "Loss on test= 0.019638409838080406\n",
      "acc for Lsat= 0.4455002147241848 \n",
      "acc for Psat= 0.39566790508979466 \n",
      "acc for optim= 0.22848277200545133\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.017534350976347923\n",
      "Loss on test= 0.01988030970096588\n",
      "acc for Lsat= 0.3199718507416578 \n",
      "acc for Psat= 0.561821932976002 \n",
      "acc for optim= 0.24221013026977448\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.017277175560593605\n",
      "Loss on test= 0.018028108403086662\n",
      "acc for Lsat= 0.4125552857271081 \n",
      "acc for Psat= 0.42157209266254025 \n",
      "acc for optim= 0.21645268850084362\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.016635021194815636\n",
      "Loss on test= 0.016424013301730156\n",
      "acc for Lsat= 0.31166815489760247 \n",
      "acc for Psat= 0.42001910212629073 \n",
      "acc for optim= 0.2263767972186985\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.016146276146173477\n",
      "Loss on test= 0.016936952248215675\n",
      "acc for Lsat= 0.33864698119420633 \n",
      "acc for Psat= 0.44406479102483876 \n",
      "acc for optim= 0.21529088428045773\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.016103245317935944\n",
      "Loss on test= 0.018515998497605324\n",
      "acc for Lsat= 0.31622636567654144 \n",
      "acc for Psat= 0.5087657385148132 \n",
      "acc for optim= 0.22869506451290264\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.01708073541522026\n",
      "Loss on test= 0.017853375524282455\n",
      "acc for Lsat= 0.38975407595540135 \n",
      "acc for Psat= 0.43797786426227037 \n",
      "acc for optim= 0.2190784973432479\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.016636498272418976\n",
      "Loss on test= 0.01660040020942688\n",
      "acc for Lsat= 0.361494088517321 \n",
      "acc for Psat= 0.37934154409339427 \n",
      "acc for optim= 0.20869889262217298\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.016035746783018112\n",
      "Loss on test= 0.01650506816804409\n",
      "acc for Lsat= 0.36581515394956676 \n",
      "acc for Psat= 0.39839148700883853 \n",
      "acc for optim= 0.215846049778692\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.016126828268170357\n",
      "Loss on test= 0.016514977440238\n",
      "acc for Lsat= 0.36243853846748164 \n",
      "acc for Psat= 0.41039576678933276 \n",
      "acc for optim= 0.24514081227661755\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.015963459387421608\n",
      "Loss on test= 0.015412963926792145\n",
      "acc for Lsat= 0.3353490746128562 \n",
      "acc for Psat= 0.3825235746718701 \n",
      "acc for optim= 0.2194465283696568\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.016121750697493553\n",
      "Loss on test= 0.016456974670290947\n",
      "acc for Lsat= 0.4114421471792928 \n",
      "acc for Psat= 0.3749648983888422 \n",
      "acc for optim= 0.21425130144839263\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.016986191272735596\n",
      "Loss on test= 0.016309184953570366\n",
      "acc for Lsat= 0.3458983723846629 \n",
      "acc for Psat= 0.46267181732754753 \n",
      "acc for optim= 0.22985238598197907\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.01748151332139969\n",
      "Loss on test= 0.016822654753923416\n",
      "acc for Lsat= 0.3661740539356361 \n",
      "acc for Psat= 0.5235302460685095 \n",
      "acc for optim= 0.21245297133242963\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.016458164900541306\n",
      "Loss on test= 0.017992528155446053\n",
      "acc for Lsat= 0.4963445182531015 \n",
      "acc for Psat= 0.403377314026403 \n",
      "acc for optim= 0.2055927922066641\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.016072172671556473\n",
      "Loss on test= 0.016911081969738007\n",
      "acc for Lsat= 0.3190069450179549 \n",
      "acc for Psat= 0.4340621031835719 \n",
      "acc for optim= 0.2288394583229092\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.015728238970041275\n",
      "Loss on test= 0.01572209782898426\n",
      "acc for Lsat= 0.3020334715303663 \n",
      "acc for Psat= 0.4379482146298353 \n",
      "acc for optim= 0.21410791284418068\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.015483340248465538\n",
      "Loss on test= 0.01615726947784424\n",
      "acc for Lsat= 0.3426050043956304 \n",
      "acc for Psat= 0.38811921222826934 \n",
      "acc for optim= 0.21943334882795368\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.015263907611370087\n",
      "Loss on test= 0.018711982294917107\n",
      "acc for Lsat= 0.3211234399727923 \n",
      "acc for Psat= 0.36243736164619433 \n",
      "acc for optim= 0.21288869355575535\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.015803968533873558\n",
      "Loss on test= 0.01573760062456131\n",
      "acc for Lsat= 0.3372625722833028 \n",
      "acc for Psat= 0.4143404142328723 \n",
      "acc for optim= 0.2270089920977527\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.016247853636741638\n",
      "Loss on test= 0.019618172198534012\n",
      "acc for Lsat= 0.5835581800614867 \n",
      "acc for Psat= 0.387915210522388 \n",
      "acc for optim= 0.20185648662162428\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.016064073890447617\n",
      "Loss on test= 0.01591530814766884\n",
      "acc for Lsat= 0.33141557927514 \n",
      "acc for Psat= 0.5068832586953618 \n",
      "acc for optim= 0.22130890753249186\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.015727486461400986\n",
      "Loss on test= 0.01749591715633869\n",
      "acc for Lsat= 0.41042170476921946 \n",
      "acc for Psat= 0.5844890258410266 \n",
      "acc for optim= 0.23826728428743868\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.015723178163170815\n",
      "Loss on test= 0.015984172001481056\n",
      "acc for Lsat= 0.38900740285533025 \n",
      "acc for Psat= 0.37442029027324925 \n",
      "acc for optim= 0.2343967427541675\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.015118385665118694\n",
      "Loss on test= 0.016553092747926712\n",
      "acc for Lsat= 0.3091426925360842 \n",
      "acc for Psat= 0.5055069106519285 \n",
      "acc for optim= 0.22867915049711293\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.015750745311379433\n",
      "Loss on test= 0.01869230903685093\n",
      "acc for Lsat= 0.4184010302367922 \n",
      "acc for Psat= 0.40649218754599037 \n",
      "acc for optim= 0.21976886434571793\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.015450844541192055\n",
      "Loss on test= 0.016535954549908638\n",
      "acc for Lsat= 0.31470969266445387 \n",
      "acc for Psat= 0.40551973905727406 \n",
      "acc for optim= 0.21336326007676198\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.01590651273727417\n",
      "Loss on test= 0.01706455647945404\n",
      "acc for Lsat= 0.4175877882328161 \n",
      "acc for Psat= 0.38974569790691416 \n",
      "acc for optim= 0.20426971343604727\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.015097242780029774\n",
      "Loss on test= 0.015031666494905949\n",
      "acc for Lsat= 0.3149444107328089 \n",
      "acc for Psat= 0.4531479882182769 \n",
      "acc for optim= 0.21352897609687863\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.014753713272511959\n",
      "Loss on test= 0.015693265944719315\n",
      "acc for Lsat= 0.3453965430994317 \n",
      "acc for Psat= 0.3843896038176624 \n",
      "acc for optim= 0.207719205440741\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.015519770793616772\n",
      "Loss on test= 0.015714824199676514\n",
      "acc for Lsat= 0.31899466091213197 \n",
      "acc for Psat= 0.4005634933804489 \n",
      "acc for optim= 0.21070848699860475\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.014957544393837452\n",
      "Loss on test= 0.015433598309755325\n",
      "acc for Lsat= 0.30905004240009254 \n",
      "acc for Psat= 0.3760582888509718 \n",
      "acc for optim= 0.22937943993708138\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.014951550401747227\n",
      "Loss on test= 0.016998017206788063\n",
      "acc for Lsat= 0.3550971870442752 \n",
      "acc for Psat= 0.5702864504434999 \n",
      "acc for optim= 0.22850332479307278\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.015116519294679165\n",
      "Loss on test= 0.015137029811739922\n",
      "acc for Lsat= 0.4134150691278518 \n",
      "acc for Psat= 0.3639595836402559 \n",
      "acc for optim= 0.22323676629221645\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.014662094414234161\n",
      "Loss on test= 0.015186483971774578\n",
      "acc for Lsat= 0.29253380748205754 \n",
      "acc for Psat= 0.36747670253680553 \n",
      "acc for optim= 0.22072338923376142\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.014025934040546417\n",
      "Loss on test= 0.01608443260192871\n",
      "acc for Lsat= 0.3083055144656887 \n",
      "acc for Psat= 0.3734225276623604 \n",
      "acc for optim= 0.21256044901580223\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.01442553848028183\n",
      "Loss on test= 0.015096399933099747\n",
      "acc for Lsat= 0.35119184899510425 \n",
      "acc for Psat= 0.39691171379888907 \n",
      "acc for optim= 0.22034479550249572\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.014999449253082275\n",
      "Loss on test= 0.014633093029260635\n",
      "acc for Lsat= 0.3357439094747738 \n",
      "acc for Psat= 0.4084084996362877 \n",
      "acc for optim= 0.20651433825249213\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.01400055829435587\n",
      "Loss on test= 0.015436111018061638\n",
      "acc for Lsat= 0.3060843757196602 \n",
      "acc for Psat= 0.3799551289947074 \n",
      "acc for optim= 0.20788503358867397\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.014578064903616905\n",
      "Loss on test= 0.015099667012691498\n",
      "acc for Lsat= 0.366363698804963 \n",
      "acc for Psat= 0.37496631541029507 \n",
      "acc for optim= 0.2063806183404931\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.014690124429762363\n",
      "Loss on test= 0.016149073839187622\n",
      "acc for Lsat= 0.3031133215379275 \n",
      "acc for Psat= 0.43710434809523774 \n",
      "acc for optim= 0.21386130292405534\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.014665672555565834\n",
      "Loss on test= 0.014732014387845993\n",
      "acc for Lsat= 0.328746888403485 \n",
      "acc for Psat= 0.3907101272725413 \n",
      "acc for optim= 0.21271796289511258\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.014401912689208984\n",
      "Loss on test= 0.01509833987802267\n",
      "acc for Lsat= 0.46969555549298386 \n",
      "acc for Psat= 0.36038431587469344 \n",
      "acc for optim= 0.21132733031546452\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.014701366424560547\n",
      "Loss on test= 0.015948396176099777\n",
      "acc for Lsat= 0.3118754729083456 \n",
      "acc for Psat= 0.5725792974923467 \n",
      "acc for optim= 0.22468336459801444\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.01425743568688631\n",
      "Loss on test= 0.014407268725335598\n",
      "acc for Lsat= 0.32864148039403224 \n",
      "acc for Psat= 0.3944921682101464 \n",
      "acc for optim= 0.2129972557929766\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.01411791518330574\n",
      "Loss on test= 0.015800582244992256\n",
      "acc for Lsat= 0.41782800823047356 \n",
      "acc for Psat= 0.42946291008863496 \n",
      "acc for optim= 0.2073851374532112\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.01470416784286499\n",
      "Loss on test= 0.01475137285888195\n",
      "acc for Lsat= 0.3110536369951316 \n",
      "acc for Psat= 0.3808247328415746 \n",
      "acc for optim= 0.20929093271449864\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.014570322819054127\n",
      "Loss on test= 0.014265722595155239\n",
      "acc for Lsat= 0.3419508356396486 \n",
      "acc for Psat= 0.3745477825636831 \n",
      "acc for optim= 0.2273059565427625\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.014555650763213634\n",
      "Loss on test= 0.015349014662206173\n",
      "acc for Lsat= 0.32515006636920685 \n",
      "acc for Psat= 0.36100751136325776 \n",
      "acc for optim= 0.20045815667696376\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.014129524119198322\n",
      "Loss on test= 0.015903061255812645\n",
      "acc for Lsat= 0.38252372903563714 \n",
      "acc for Psat= 0.3577053425495349 \n",
      "acc for optim= 0.21494716760404314\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.014447285793721676\n",
      "Loss on test= 0.016225753352046013\n",
      "acc for Lsat= 0.2912349857895704 \n",
      "acc for Psat= 0.4649297830699259 \n",
      "acc for optim= 0.2021960994327831\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.014012104831635952\n",
      "Loss on test= 0.014222781173884869\n",
      "acc for Lsat= 0.27841052311752623 \n",
      "acc for Psat= 0.4156489649662084 \n",
      "acc for optim= 0.22718934239467647\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.013683873228728771\n",
      "Loss on test= 0.014482209458947182\n",
      "acc for Lsat= 0.32782804022359857 \n",
      "acc for Psat= 0.3953820250124507 \n",
      "acc for optim= 0.21393333288378436\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.013694306835532188\n",
      "Loss on test= 0.013831505551934242\n",
      "acc for Lsat= 0.30142722010094913 \n",
      "acc for Psat= 0.37476867882906917 \n",
      "acc for optim= 0.20825470000429935\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.01367812231183052\n",
      "Loss on test= 0.015292116440832615\n",
      "acc for Lsat= 0.3129434463590843 \n",
      "acc for Psat= 0.37695617589771563 \n",
      "acc for optim= 0.18785915615326548\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.014144005253911018\n",
      "Loss on test= 0.01393267884850502\n",
      "acc for Lsat= 0.3362980073906255 \n",
      "acc for Psat= 0.32334411075036673 \n",
      "acc for optim= 0.2148040997206998\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.014125521294772625\n",
      "Loss on test= 0.014738716185092926\n",
      "acc for Lsat= 0.3127577728135637 \n",
      "acc for Psat= 0.390067739742163 \n",
      "acc for optim= 0.20308310424907422\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.013891847804188728\n",
      "Loss on test= 0.01423694472759962\n",
      "acc for Lsat= 0.3607403009994635 \n",
      "acc for Psat= 0.35766902875085993 \n",
      "acc for optim= 0.20807615629903897\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.014193546026945114\n",
      "Loss on test= 0.01452585682272911\n",
      "acc for Lsat= 0.3160603187195217 \n",
      "acc for Psat= 0.37704316027088064 \n",
      "acc for optim= 0.20887976376980077\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.013461709022521973\n",
      "Loss on test= 0.01385760772973299\n",
      "acc for Lsat= 0.34199022039664106 \n",
      "acc for Psat= 0.36055501653164673 \n",
      "acc for optim= 0.20095310522152135\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.013834641315042973\n",
      "Loss on test= 0.013917220756411552\n",
      "acc for Lsat= 0.3336499452322912 \n",
      "acc for Psat= 0.34265782440367754 \n",
      "acc for optim= 0.19555695742727383\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.0137338200584054\n",
      "Loss on test= 0.014294968917965889\n",
      "acc for Lsat= 0.30183201391490594 \n",
      "acc for Psat= 0.4008172344230745 \n",
      "acc for optim= 0.21157362003341895\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.014206505380570889\n",
      "Loss on test= 0.01409081183373928\n",
      "acc for Lsat= 0.32331396646387056 \n",
      "acc for Psat= 0.3631978166913787 \n",
      "acc for optim= 0.2067966703648012\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.013781783170998096\n",
      "Loss on test= 0.01490293350070715\n",
      "acc for Lsat= 0.3218743930337459 \n",
      "acc for Psat= 0.3768510772882822 \n",
      "acc for optim= 0.20338507241890388\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.013589749112725258\n",
      "Loss on test= 0.014134149067103863\n",
      "acc for Lsat= 0.2944544499657019 \n",
      "acc for Psat= 0.4155867218370396 \n",
      "acc for optim= 0.20889703979122026\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.013837113045156002\n",
      "Loss on test= 0.014129609800875187\n",
      "acc for Lsat= 0.352295935515006 \n",
      "acc for Psat= 0.37634008621554693 \n",
      "acc for optim= 0.20798509353905525\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.013940485194325447\n",
      "Loss on test= 0.014627432450652122\n",
      "acc for Lsat= 0.3265540390035509 \n",
      "acc for Psat= 0.42654114001905674 \n",
      "acc for optim= 0.21892455733393798\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.01359795592725277\n",
      "Loss on test= 0.014285018667578697\n",
      "acc for Lsat= 0.3029425615307913 \n",
      "acc for Psat= 0.3580775450237844 \n",
      "acc for optim= 0.1939508290916156\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.013751831836998463\n",
      "Loss on test= 0.013217570260167122\n",
      "acc for Lsat= 0.2976864983868074 \n",
      "acc for Psat= 0.44141420364345274 \n",
      "acc for optim= 0.2063469405988439\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.013815106824040413\n",
      "Loss on test= 0.014162471517920494\n",
      "acc for Lsat= 0.30003418221934447 \n",
      "acc for Psat= 0.39267633760937315 \n",
      "acc for optim= 0.2062140738109667\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.01355799101293087\n",
      "Loss on test= 0.015242144465446472\n",
      "acc for Lsat= 0.40874179466659 \n",
      "acc for Psat= 0.3581800040548252 \n",
      "acc for optim= 0.19979913143922473\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.013947196304798126\n",
      "Loss on test= 0.015275713987648487\n",
      "acc for Lsat= 0.31532722990566586 \n",
      "acc for Psat= 0.48915587092680557 \n",
      "acc for optim= 0.2093566381516064\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.014256429858505726\n",
      "Loss on test= 0.01373448595404625\n",
      "acc for Lsat= 0.30501907309076776 \n",
      "acc for Psat= 0.39634268947958007 \n",
      "acc for optim= 0.19918378875425677\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.013469618745148182\n",
      "Loss on test= 0.015629520639777184\n",
      "acc for Lsat= 0.3994047538327888 \n",
      "acc for Psat= 0.3790091839792031 \n",
      "acc for optim= 0.20914069021465193\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.013616836629807949\n",
      "Loss on test= 0.014310081489384174\n",
      "acc for Lsat= 0.3033376736841731 \n",
      "acc for Psat= 0.4101244490359661 \n",
      "acc for optim= 0.2018237226855834\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.013090848922729492\n",
      "Loss on test= 0.014371567405760288\n",
      "acc for Lsat= 0.371157343346764 \n",
      "acc for Psat= 0.32984985758190993 \n",
      "acc for optim= 0.20439298860667104\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.012720960192382336\n",
      "Loss on test= 0.013496611267328262\n",
      "acc for Lsat= 0.29759122395881676 \n",
      "acc for Psat= 0.4295533450552014 \n",
      "acc for optim= 0.20361357286182702\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.013457417488098145\n",
      "Loss on test= 0.014062066562473774\n",
      "acc for Lsat= 0.3175578775734647 \n",
      "acc for Psat= 0.4186601807132074 \n",
      "acc for optim= 0.20956882505900443\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.013736859895288944\n",
      "Loss on test= 0.013606986030936241\n",
      "acc for Lsat= 0.2966460092299983 \n",
      "acc for Psat= 0.3762033965542434 \n",
      "acc for optim= 0.30380446399283606\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.01281973347067833\n",
      "Loss on test= 0.013562946580350399\n",
      "acc for Lsat= 0.34614622290718144 \n",
      "acc for Psat= 0.35141496091897795 \n",
      "acc for optim= 0.20099405227980194\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.01366212498396635\n",
      "Loss on test= 0.013392787426710129\n",
      "acc for Lsat= 0.30818747845792993 \n",
      "acc for Psat= 0.40166174795563536 \n",
      "acc for optim= 0.2099704880533249\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.013280879706144333\n",
      "Loss on test= 0.013736823573708534\n",
      "acc for Lsat= 0.2861624320707838 \n",
      "acc for Psat= 0.38708690661469763 \n",
      "acc for optim= 0.20469522148021105\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.013217861764132977\n",
      "Loss on test= 0.013915671035647392\n",
      "acc for Lsat= 0.39414637596141927 \n",
      "acc for Psat= 0.3632475398008938 \n",
      "acc for optim= 0.20554823638431607\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.013418520800769329\n",
      "Loss on test= 0.014722009189426899\n",
      "acc for Lsat= 0.41491780948775625 \n",
      "acc for Psat= 0.3446493089589215 \n",
      "acc for optim= 0.19404431561093047\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.013541623018682003\n",
      "Loss on test= 0.013422411866486073\n",
      "acc for Lsat= 0.31438816025714716 \n",
      "acc for Psat= 0.3683683061913266 \n",
      "acc for optim= 0.20164154787100316\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.013116242364048958\n",
      "Loss on test= 0.014842263422906399\n",
      "acc for Lsat= 0.283709429785754 \n",
      "acc for Psat= 0.4266821301205562 \n",
      "acc for optim= 0.20321018458973314\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.013371623121201992\n",
      "Loss on test= 0.01341684628278017\n",
      "acc for Lsat= 0.3281467573487552 \n",
      "acc for Psat= 0.35359534395246484 \n",
      "acc for optim= 0.1931879327408702\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.013102756813168526\n",
      "Loss on test= 0.014458921737968922\n",
      "acc for Lsat= 0.30900960320188364 \n",
      "acc for Psat= 0.40754648477210337 \n",
      "acc for optim= 0.20135585342575577\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.012892164289951324\n",
      "Loss on test= 0.013306478038430214\n",
      "acc for Lsat= 0.2938216129448454 \n",
      "acc for Psat= 0.38084216625036393 \n",
      "acc for optim= 0.19914049223361135\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.013085203245282173\n",
      "Loss on test= 0.014232841320335865\n",
      "acc for Lsat= 0.3486888706644783 \n",
      "acc for Psat= 0.33731541097320683 \n",
      "acc for optim= 0.1954866969999416\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.013071563094854355\n",
      "Loss on test= 0.01357262209057808\n",
      "acc for Lsat= 0.3165689331087649 \n",
      "acc for Psat= 0.3467646849316274 \n",
      "acc for optim= 0.21135342995773032\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.013195972889661789\n",
      "Loss on test= 0.01439298503100872\n",
      "acc for Lsat= 0.3970740463037883 \n",
      "acc for Psat= 0.34220699719515174 \n",
      "acc for optim= 0.19624798034468816\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.01364295743405819\n",
      "Loss on test= 0.01608855091035366\n",
      "acc for Lsat= 0.2942381188378833 \n",
      "acc for Psat= 0.5276460915283187 \n",
      "acc for optim= 0.22097700954371838\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.013304178602993488\n",
      "Loss on test= 0.013135490007698536\n",
      "acc for Lsat= 0.32583141301305707 \n",
      "acc for Psat= 0.34855243567978283 \n",
      "acc for optim= 0.21036003948058743\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.013234414160251617\n",
      "Loss on test= 0.013206112198531628\n",
      "acc for Lsat= 0.2911007409601479 \n",
      "acc for Psat= 0.38282068368740463 \n",
      "acc for optim= 0.201046896962342\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.01293229404836893\n",
      "Loss on test= 0.013259829953312874\n",
      "acc for Lsat= 0.3164293617053379 \n",
      "acc for Psat= 0.36348830422188305 \n",
      "acc for optim= 0.20815747006044322\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.012862463481724262\n",
      "Loss on test= 0.013041536323726177\n",
      "acc for Lsat= 0.2824627301129481 \n",
      "acc for Psat= 0.39615910020861395 \n",
      "acc for optim= 0.21196779147588107\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.0130424490198493\n",
      "Loss on test= 0.014165233820676804\n",
      "acc for Lsat= 0.34479355930061256 \n",
      "acc for Psat= 0.3552261806695684 \n",
      "acc for optim= 0.20787174451450827\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.013265769928693771\n",
      "Loss on test= 0.01339538674801588\n",
      "acc for Lsat= 0.3033016777598941 \n",
      "acc for Psat= 0.3423731667306227 \n",
      "acc for optim= 0.20741571510695173\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.013033960945904255\n",
      "Loss on test= 0.016339365392923355\n",
      "acc for Lsat= 0.3824319580068019 \n",
      "acc for Psat= 0.37248999302470553 \n",
      "acc for optim= 0.1974680626173378\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.013254545629024506\n",
      "Loss on test= 0.013754374347627163\n",
      "acc for Lsat= 0.2808876302694468 \n",
      "acc for Psat= 0.37011790034798525 \n",
      "acc for optim= 0.2004580647051232\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.012957547791302204\n",
      "Loss on test= 0.01409144140779972\n",
      "acc for Lsat= 0.3020272151711774 \n",
      "acc for Psat= 0.368440284631278 \n",
      "acc for optim= 0.19359935920923865\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.012941540218889713\n",
      "Loss on test= 0.013189109042286873\n",
      "acc for Lsat= 0.28844272424907397 \n",
      "acc for Psat= 0.3534498549439328 \n",
      "acc for optim= 0.19512995715116188\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.012258961796760559\n",
      "Loss on test= 0.013819359242916107\n",
      "acc for Lsat= 0.2926971864378445 \n",
      "acc for Psat= 0.33757833102434825 \n",
      "acc for optim= 0.20323697867698265\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.01262169424444437\n",
      "Loss on test= 0.013939122669398785\n",
      "acc for Lsat= 0.333523763010859 \n",
      "acc for Psat= 0.36454118192400403 \n",
      "acc for optim= 0.20042591251714495\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.0129081467166543\n",
      "Loss on test= 0.0137688759714365\n",
      "acc for Lsat= 0.29054143749021316 \n",
      "acc for Psat= 0.45686186340478613 \n",
      "acc for optim= 0.20553798268225068\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.012985079549252987\n",
      "Loss on test= 0.013452348299324512\n",
      "acc for Lsat= 0.30393427041090526 \n",
      "acc for Psat= 0.3406704488050899 \n",
      "acc for optim= 0.1949681014233942\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.01271806750446558\n",
      "Loss on test= 0.01442322414368391\n",
      "acc for Lsat= 0.36073125373238596 \n",
      "acc for Psat= 0.34930104359552167 \n",
      "acc for optim= 0.1992849707276528\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.012971760705113411\n",
      "Loss on test= 0.014138241298496723\n",
      "acc for Lsat= 0.26740389228824507 \n",
      "acc for Psat= 0.37018463089417136 \n",
      "acc for optim= 0.21249583633407138\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.013137263245880604\n",
      "Loss on test= 0.0147435637190938\n",
      "acc for Lsat= 0.3918259701519698 \n",
      "acc for Psat= 0.3351859869162581 \n",
      "acc for optim= 0.1986271093993875\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.013411187566816807\n",
      "Loss on test= 0.013952253386378288\n",
      "acc for Lsat= 0.29922459203265356 \n",
      "acc for Psat= 0.379182781188934 \n",
      "acc for optim= 0.19294034899035437\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.013076352886855602\n",
      "Loss on test= 0.014395111240446568\n",
      "acc for Lsat= 0.274597897679652 \n",
      "acc for Psat= 0.43768034316992666 \n",
      "acc for optim= 0.219007194941481\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.013577126897871494\n",
      "Loss on test= 0.015297843143343925\n",
      "acc for Lsat= 0.3651660624860056 \n",
      "acc for Psat= 0.343082341193253 \n",
      "acc for optim= 0.19870785766731905\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.01286142785102129\n",
      "Loss on test= 0.012773040682077408\n",
      "acc for Lsat= 0.32824240403282895 \n",
      "acc for Psat= 0.3584264815937196 \n",
      "acc for optim= 0.20419959674959623\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.01261091697961092\n",
      "Loss on test= 0.013978967443108559\n",
      "acc for Lsat= 0.2734863577379902 \n",
      "acc for Psat= 0.45272459655943503 \n",
      "acc for optim= 0.21802649995024204\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.013097804971039295\n",
      "Loss on test= 0.013422041200101376\n",
      "acc for Lsat= 0.2950691185072395 \n",
      "acc for Psat= 0.37345372792254705 \n",
      "acc for optim= 0.20846233274937118\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.012479917146265507\n",
      "Loss on test= 0.013058403506875038\n",
      "acc for Lsat= 0.29132999906417084 \n",
      "acc for Psat= 0.3673838749440423 \n",
      "acc for optim= 0.20020428902136847\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.012007255107164383\n",
      "Loss on test= 0.013764932751655579\n",
      "acc for Lsat= 0.3043694751886997 \n",
      "acc for Psat= 0.3766312925476381 \n",
      "acc for optim= 0.20243360108852848\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.012393984012305737\n",
      "Loss on test= 0.013796832412481308\n",
      "acc for Lsat= 0.27740499397328383 \n",
      "acc for Psat= 0.3529601237835261 \n",
      "acc for optim= 0.19415014624010418\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.01256501954048872\n",
      "Loss on test= 0.013570423237979412\n",
      "acc for Lsat= 0.2917172657141015 \n",
      "acc for Psat= 0.3645219949146456 \n",
      "acc for optim= 0.21186065237231338\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.013125653378665447\n",
      "Loss on test= 0.01403395552188158\n",
      "acc for Lsat= 0.33758357694674684 \n",
      "acc for Psat= 0.33295828624584434 \n",
      "acc for optim= 0.20100930928831962\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.012790486216545105\n",
      "Loss on test= 0.013399088755249977\n",
      "acc for Lsat= 0.2939440057553175 \n",
      "acc for Psat= 0.35729453206767103 \n",
      "acc for optim= 0.1905509333963572\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.012554578483104706\n",
      "Loss on test= 0.013554959557950497\n",
      "acc for Lsat= 0.28896599704072484 \n",
      "acc for Psat= 0.3587066876462887 \n",
      "acc for optim= 0.1926875877207331\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.012397595681250095\n",
      "Loss on test= 0.014326338656246662\n",
      "acc for Lsat= 0.2820265117460056 \n",
      "acc for Psat= 0.4112225718618484 \n",
      "acc for optim= 0.1974104420919871\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.011888266541063786\n",
      "Loss on test= 0.013744080439209938\n",
      "acc for Lsat= 0.36252296097823217 \n",
      "acc for Psat= 0.330864404612913 \n",
      "acc for optim= 0.19632666236115304\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.012518118135631084\n",
      "Loss on test= 0.012734705582261086\n",
      "acc for Lsat= 0.33012097927240647 \n",
      "acc for Psat= 0.34027380416739256 \n",
      "acc for optim= 0.1980129688436628\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.012324291281402111\n",
      "Loss on test= 0.01272253692150116\n",
      "acc for Lsat= 0.2627742473771485 \n",
      "acc for Psat= 0.37810902252739825 \n",
      "acc for optim= 0.19499646667925943\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.01185479387640953\n",
      "Loss on test= 0.013301383703947067\n",
      "acc for Lsat= 0.27408435327497255 \n",
      "acc for Psat= 0.3812954546132509 \n",
      "acc for optim= 0.20936525521825092\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.012391031719744205\n",
      "Loss on test= 0.013102463446557522\n",
      "acc for Lsat= 0.28215436682374867 \n",
      "acc for Psat= 0.37427455192035364 \n",
      "acc for optim= 0.20436269140289468\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.011881418526172638\n",
      "Loss on test= 0.01292623020708561\n",
      "acc for Lsat= 0.2976018246366506 \n",
      "acc for Psat= 0.3625875770498218 \n",
      "acc for optim= 0.2012767868043345\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.012414204888045788\n",
      "Loss on test= 0.012880434282124043\n",
      "acc for Lsat= 0.27567128161486787 \n",
      "acc for Psat= 0.4115398546619454 \n",
      "acc for optim= 0.20696664302876516\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.012951115146279335\n",
      "Loss on test= 0.013777241110801697\n",
      "acc for Lsat= 0.32781497541165316 \n",
      "acc for Psat= 0.3274783855787875 \n",
      "acc for optim= 0.19331678930894988\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.011956950649619102\n",
      "Loss on test= 0.012783067300915718\n",
      "acc for Lsat= 0.34876802938438106 \n",
      "acc for Psat= 0.3609964929645365 \n",
      "acc for optim= 0.19740159040304353\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.011839407496154308\n",
      "Loss on test= 0.013741305097937584\n",
      "acc for Lsat= 0.32562991970550953 \n",
      "acc for Psat= 0.34540766287751173 \n",
      "acc for optim= 0.20906034127216805\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.01189614087343216\n",
      "Loss on test= 0.013157710433006287\n",
      "acc for Lsat= 0.3490005364882244 \n",
      "acc for Psat= 0.3250406856826197 \n",
      "acc for optim= 0.19465696536576002\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.011961678974330425\n",
      "Loss on test= 0.013040337711572647\n",
      "acc for Lsat= 0.295280749834952 \n",
      "acc for Psat= 0.3285738030264494 \n",
      "acc for optim= 0.19737427355760923\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.011763688176870346\n",
      "Loss on test= 0.012506548315286636\n",
      "acc for Lsat= 0.30795863196308837 \n",
      "acc for Psat= 0.35007587197617035 \n",
      "acc for optim= 0.20381868303386885\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.01213680487126112\n",
      "Loss on test= 0.01284837070852518\n",
      "acc for Lsat= 0.34295673307959174 \n",
      "acc for Psat= 0.3245408885596663 \n",
      "acc for optim= 0.2066101217441846\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.012637398205697536\n",
      "Loss on test= 0.012899191118776798\n",
      "acc for Lsat= 0.28777476697900595 \n",
      "acc for Psat= 0.39642826981592383 \n",
      "acc for optim= 0.20874297477417417\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.012762683443725109\n",
      "Loss on test= 0.012752980925142765\n",
      "acc for Lsat= 0.2749351398760572 \n",
      "acc for Psat= 0.36823226745095655 \n",
      "acc for optim= 0.2007297124337866\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.011927055194973946\n",
      "Loss on test= 0.012870457023382187\n",
      "acc for Lsat= 0.3137902957300744 \n",
      "acc for Psat= 0.3302370755499814 \n",
      "acc for optim= 0.19215948720788267\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.012046249583363533\n",
      "Loss on test= 0.013662961311638355\n",
      "acc for Lsat= 0.2757113485949466 \n",
      "acc for Psat= 0.40696281290021596 \n",
      "acc for optim= 0.21323580391824204\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.012302299030125141\n",
      "Loss on test= 0.01349067036062479\n",
      "acc for Lsat= 0.2949226462869037 \n",
      "acc for Psat= 0.33730181781268315 \n",
      "acc for optim= 0.20109687887668623\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.011609132401645184\n",
      "Loss on test= 0.012051363475620747\n",
      "acc for Lsat= 0.262688730153919 \n",
      "acc for Psat= 0.344948144396767 \n",
      "acc for optim= 0.1955251853098555\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.011835698038339615\n",
      "Loss on test= 0.012389503419399261\n",
      "acc for Lsat= 0.30935972036334264 \n",
      "acc for Psat= 0.3409916200728214 \n",
      "acc for optim= 0.19830716324813202\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.011477645486593246\n",
      "Loss on test= 0.0123716089874506\n",
      "acc for Lsat= 0.3086856147559514 \n",
      "acc for Psat= 0.3514717997451363 \n",
      "acc for optim= 0.19347331798839937\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.011738386936485767\n",
      "Loss on test= 0.012321812100708485\n",
      "acc for Lsat= 0.2750488149434426 \n",
      "acc for Psat= 0.3338918947387405 \n",
      "acc for optim= 0.2038867895340396\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.011775806546211243\n",
      "Loss on test= 0.012715893797576427\n",
      "acc for Lsat= 0.31697400352552635 \n",
      "acc for Psat= 0.35906497846627716 \n",
      "acc for optim= 0.19943130922989882\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.01195538230240345\n",
      "Loss on test= 0.013324012979865074\n",
      "acc for Lsat= 0.261674160971558 \n",
      "acc for Psat= 0.4091653461144086 \n",
      "acc for optim= 0.2085424518559562\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.012586228549480438\n",
      "Loss on test= 0.01292868610471487\n",
      "acc for Lsat= 0.30716791306936964 \n",
      "acc for Psat= 0.37128757532745776 \n",
      "acc for optim= 0.20072252033187887\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.011835925281047821\n",
      "Loss on test= 0.012507283128798008\n",
      "acc for Lsat= 0.27341510762690213 \n",
      "acc for Psat= 0.33482366005655667 \n",
      "acc for optim= 0.20396149837491778\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.012107506394386292\n",
      "Loss on test= 0.01188828144222498\n",
      "acc for Lsat= 0.2830737987722485 \n",
      "acc for Psat= 0.3445780824026647 \n",
      "acc for optim= 0.1946111117505171\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.011352677829563618\n",
      "Loss on test= 0.012724014930427074\n",
      "acc for Lsat= 0.3065956264759439 \n",
      "acc for Psat= 0.32980855259835595 \n",
      "acc for optim= 0.2053939445477964\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.011872577480971813\n",
      "Loss on test= 0.012967398390173912\n",
      "acc for Lsat= 0.30393930018652937 \n",
      "acc for Psat= 0.31245999140869446 \n",
      "acc for optim= 0.1942438068296257\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.012256487272679806\n",
      "Loss on test= 0.012494179420173168\n",
      "acc for Lsat= 0.2632788558930278 \n",
      "acc for Psat= 0.35640116605232786 \n",
      "acc for optim= 0.19378813477079668\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.012429513037204742\n",
      "Loss on test= 0.013954504393041134\n",
      "acc for Lsat= 0.2684324002786181 \n",
      "acc for Psat= 0.36054465291857235 \n",
      "acc for optim= 0.21862002868815703\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.011979668401181698\n",
      "Loss on test= 0.012440408580005169\n",
      "acc for Lsat= 0.28377822987848145 \n",
      "acc for Psat= 0.341605558371206 \n",
      "acc for optim= 0.19408369634667808\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.012107196263968945\n",
      "Loss on test= 0.012360656633973122\n",
      "acc for Lsat= 0.283998391414423 \n",
      "acc for Psat= 0.3234036521989273 \n",
      "acc for optim= 0.18852026291396878\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.012168806977570057\n",
      "Loss on test= 0.012823369354009628\n",
      "acc for Lsat= 0.2597686154586955 \n",
      "acc for Psat= 0.37561099041822427 \n",
      "acc for optim= 0.19921277774837895\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.011234012432396412\n",
      "Loss on test= 0.012329843826591969\n",
      "acc for Lsat= 0.26917013973689863 \n",
      "acc for Psat= 0.33675236953776394 \n",
      "acc for optim= 0.20039935677463339\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.01153756957501173\n",
      "Loss on test= 0.01166248694062233\n",
      "acc for Lsat= 0.28343082031131267 \n",
      "acc for Psat= 0.33995988836250035 \n",
      "acc for optim= 0.19668328691890613\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.011356714181602001\n",
      "Loss on test= 0.012202962301671505\n",
      "acc for Lsat= 0.2710240329757358 \n",
      "acc for Psat= 0.33149312160743205 \n",
      "acc for optim= 0.2004846644955939\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.011379397474229336\n",
      "Loss on test= 0.0127260135486722\n",
      "acc for Lsat= 0.2726139080886905 \n",
      "acc for Psat= 0.33705337475131836 \n",
      "acc for optim= 0.20604770200176015\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.01155841164290905\n",
      "Loss on test= 0.011875446885824203\n",
      "acc for Lsat= 0.3043464613611168 \n",
      "acc for Psat= 0.33253335317921656 \n",
      "acc for optim= 0.19414092059643637\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.011155622079968452\n",
      "Loss on test= 0.012346590869128704\n",
      "acc for Lsat= 0.29040163153282217 \n",
      "acc for Psat= 0.3422341387175382 \n",
      "acc for optim= 0.19177807518467857\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.01155636366456747\n",
      "Loss on test= 0.01273635309189558\n",
      "acc for Lsat= 0.26359838778798067 \n",
      "acc for Psat= 0.3617063892114045 \n",
      "acc for optim= 0.20893258455789937\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.01163081917911768\n",
      "Loss on test= 0.012643998488783836\n",
      "acc for Lsat= 0.2834745039455467 \n",
      "acc for Psat= 0.33051088721510274 \n",
      "acc for optim= 0.21403840861406737\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.011531658470630646\n",
      "Loss on test= 0.012209698557853699\n",
      "acc for Lsat= 0.2869173235258377 \n",
      "acc for Psat= 0.32157640741049387 \n",
      "acc for optim= 0.193566446427753\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.011695599183440208\n",
      "Loss on test= 0.01216050237417221\n",
      "acc for Lsat= 0.30457324690871396 \n",
      "acc for Psat= 0.31321853762288027 \n",
      "acc for optim= 0.19328026363104614\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.011508612893521786\n",
      "Loss on test= 0.012421022169291973\n",
      "acc for Lsat= 0.2907483834034694 \n",
      "acc for Psat= 0.32187424535859954 \n",
      "acc for optim= 0.1926062899744736\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.011666580103337765\n",
      "Loss on test= 0.01238946057856083\n",
      "acc for Lsat= 0.2608388969407266 \n",
      "acc for Psat= 0.3257483885610929 \n",
      "acc for optim= 0.21730588803247147\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.01146658044308424\n",
      "Loss on test= 0.01233433187007904\n",
      "acc for Lsat= 0.287664817394437 \n",
      "acc for Psat= 0.37018092402817077 \n",
      "acc for optim= 0.19768327388570667\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.011788914911448956\n",
      "Loss on test= 0.012311471626162529\n",
      "acc for Lsat= 0.29408878199693217 \n",
      "acc for Psat= 0.31143314542635847 \n",
      "acc for optim= 0.1988079302418801\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.011544344015419483\n",
      "Loss on test= 0.011954925954341888\n",
      "acc for Lsat= 0.26848845346830785 \n",
      "acc for Psat= 0.35247535566579885 \n",
      "acc for optim= 0.20252640866552563\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.011616775766015053\n",
      "Loss on test= 0.013396123424172401\n",
      "acc for Lsat= 0.30016846237688427 \n",
      "acc for Psat= 0.32440864266135505 \n",
      "acc for optim= 0.19625816112848288\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.011370229534804821\n",
      "Loss on test= 0.01245860569179058\n",
      "acc for Lsat= 0.24277326516764602 \n",
      "acc for Psat= 0.3630246435334541 \n",
      "acc for optim= 0.20436709108380946\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.011130111292004585\n",
      "Loss on test= 0.01175688486546278\n",
      "acc for Lsat= 0.2929620440847577 \n",
      "acc for Psat= 0.3082408220225015 \n",
      "acc for optim= 0.19407943070502762\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.011349902488291264\n",
      "Loss on test= 0.012770721688866615\n",
      "acc for Lsat= 0.26913441439565094 \n",
      "acc for Psat= 0.3829721744774803 \n",
      "acc for optim= 0.20338778203527122\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.011318565346300602\n",
      "Loss on test= 0.011899425648152828\n",
      "acc for Lsat= 0.31583129388014347 \n",
      "acc for Psat= 0.3200858785374392 \n",
      "acc for optim= 0.207073119687659\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.011667978949844837\n",
      "Loss on test= 0.011978402733802795\n",
      "acc for Lsat= 0.29795239339059537 \n",
      "acc for Psat= 0.3145407502664524 \n",
      "acc for optim= 0.19443595983407372\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.011065734550356865\n",
      "Loss on test= 0.012304605916142464\n",
      "acc for Lsat= 0.29364670320363667 \n",
      "acc for Psat= 0.32107672543458426 \n",
      "acc for optim= 0.1902991825264581\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.011025073938071728\n",
      "Loss on test= 0.011990999802947044\n",
      "acc for Lsat= 0.2779229121861627 \n",
      "acc for Psat= 0.3195341685574464 \n",
      "acc for optim= 0.1936083456560949\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.011401817202568054\n",
      "Loss on test= 0.012345443479716778\n",
      "acc for Lsat= 0.31625539324842383 \n",
      "acc for Psat= 0.315830482304296 \n",
      "acc for optim= 0.1855467017183499\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.011339237913489342\n",
      "Loss on test= 0.01161503978073597\n",
      "acc for Lsat= 0.274129539409989 \n",
      "acc for Psat= 0.31214573905752924 \n",
      "acc for optim= 0.19901355149832434\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.01128754485398531\n",
      "Loss on test= 0.013672013767063618\n",
      "acc for Lsat= 0.26177831738125346 \n",
      "acc for Psat= 0.41048063685239694 \n",
      "acc for optim= 0.20407268267405704\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.011644461192190647\n",
      "Loss on test= 0.011643501929938793\n",
      "acc for Lsat= 0.3146744706535026 \n",
      "acc for Psat= 0.3310260993306214 \n",
      "acc for optim= 0.19573857752028917\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.011293631047010422\n",
      "Loss on test= 0.012039393186569214\n",
      "acc for Lsat= 0.27875318053938336 \n",
      "acc for Psat= 0.33627062186624734 \n",
      "acc for optim= 0.19099548384593693\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.010907613672316074\n",
      "Loss on test= 0.011736015789210796\n",
      "acc for Lsat= 0.268053923993058 \n",
      "acc for Psat= 0.33927957622044896 \n",
      "acc for optim= 0.19990163071850328\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.011018258519470692\n",
      "Loss on test= 0.011886254884302616\n",
      "acc for Lsat= 0.265972325386404 \n",
      "acc for Psat= 0.34426466900466135 \n",
      "acc for optim= 0.19993308209538824\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.011026936583220959\n",
      "Loss on test= 0.011990216560661793\n",
      "acc for Lsat= 0.28518068067038455 \n",
      "acc for Psat= 0.3260033153116662 \n",
      "acc for optim= 0.1945950024350463\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.010964078828692436\n",
      "Loss on test= 0.011794346384704113\n",
      "acc for Lsat= 0.28619731541835497 \n",
      "acc for Psat= 0.31938520051315555 \n",
      "acc for optim= 0.1893158977445391\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.01129382848739624\n",
      "Loss on test= 0.013531320728361607\n",
      "acc for Lsat= 0.2955418847677474 \n",
      "acc for Psat= 0.3573253674596246 \n",
      "acc for optim= 0.19650461458395757\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.011381357908248901\n",
      "Loss on test= 0.011646290309727192\n",
      "acc for Lsat= 0.2746121013394283 \n",
      "acc for Psat= 0.3728999099332361 \n",
      "acc for optim= 0.20294978409750714\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.011320643126964569\n",
      "Loss on test= 0.012705730274319649\n",
      "acc for Lsat= 0.315393665634769 \n",
      "acc for Psat= 0.31824818863439047 \n",
      "acc for optim= 0.19080554202318545\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.011270091868937016\n",
      "Loss on test= 0.011782826855778694\n",
      "acc for Lsat= 0.2905687129430196 \n",
      "acc for Psat= 0.31418929998462036 \n",
      "acc for optim= 0.19207222380115324\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.012208518572151661\n",
      "Loss on test= 0.012061847373843193\n",
      "acc for Lsat= 0.2734529495414913 \n",
      "acc for Psat= 0.3880876167531824 \n",
      "acc for optim= 0.19969531576446792\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.011484801769256592\n",
      "Loss on test= 0.012217056006193161\n",
      "acc for Lsat= 0.3018547386431286 \n",
      "acc for Psat= 0.3113332362664624 \n",
      "acc for optim= 0.19746139858191758\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.011508726514875889\n",
      "Loss on test= 0.012001549825072289\n",
      "acc for Lsat= 0.2719477744288491 \n",
      "acc for Psat= 0.33069171765197786 \n",
      "acc for optim= 0.1945065609667123\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.01108416635543108\n",
      "Loss on test= 0.012352168560028076\n",
      "acc for Lsat= 0.29380879045296554 \n",
      "acc for Psat= 0.3097074127294331 \n",
      "acc for optim= 0.1972746032658285\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.010881703346967697\n",
      "Loss on test= 0.012156064622104168\n",
      "acc for Lsat= 0.2623506740939737 \n",
      "acc for Psat= 0.32330436851328626 \n",
      "acc for optim= 0.19157316395226312\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.010886155068874359\n",
      "Loss on test= 0.011780301108956337\n",
      "acc for Lsat= 0.2728343706623638 \n",
      "acc for Psat= 0.30777219273649453 \n",
      "acc for optim= 0.19925310437680013\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.010926954448223114\n",
      "Loss on test= 0.01120574027299881\n",
      "acc for Lsat= 0.28333650792485454 \n",
      "acc for Psat= 0.34053087829653195 \n",
      "acc for optim= 0.19237610042801936\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.010735428892076015\n",
      "Loss on test= 0.01158909872174263\n",
      "acc for Lsat= 0.2442289884304439 \n",
      "acc for Psat= 0.34996709580780194 \n",
      "acc for optim= 0.20051184465197408\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.0107553256675601\n",
      "Loss on test= 0.012216039933264256\n",
      "acc for Lsat= 0.26309017203889323 \n",
      "acc for Psat= 0.34160874646890127 \n",
      "acc for optim= 0.19653841752910553\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.010744784958660603\n",
      "Loss on test= 0.011926913633942604\n",
      "acc for Lsat= 0.27594649164333335 \n",
      "acc for Psat= 0.31292068758606595 \n",
      "acc for optim= 0.19731307952158228\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.01087157428264618\n",
      "Loss on test= 0.013330411165952682\n",
      "acc for Lsat= 0.34966763714800364 \n",
      "acc for Psat= 0.33374611212088523 \n",
      "acc for optim= 0.1928685202539192\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.01162185613065958\n",
      "Loss on test= 0.013194017112255096\n",
      "acc for Lsat= 0.2741287848756828 \n",
      "acc for Psat= 0.4517241058591124 \n",
      "acc for optim= 0.19840099582565804\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.010986698791384697\n",
      "Loss on test= 0.012064940296113491\n",
      "acc for Lsat= 0.30926772069525776 \n",
      "acc for Psat= 0.3398012838246162 \n",
      "acc for optim= 0.19485476659433884\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.011299525387585163\n",
      "Loss on test= 0.011965923942625523\n",
      "acc for Lsat= 0.2585626146832805 \n",
      "acc for Psat= 0.3447926069099127 \n",
      "acc for optim= 0.2004165263001719\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.010720320977270603\n",
      "Loss on test= 0.011231567710638046\n",
      "acc for Lsat= 0.27078058210207856 \n",
      "acc for Psat= 0.29874195800653686 \n",
      "acc for optim= 0.19187367437061276\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.010899476706981659\n",
      "Loss on test= 0.011856606230139732\n",
      "acc for Lsat= 0.29658883261947416 \n",
      "acc for Psat= 0.3169524741673298 \n",
      "acc for optim= 0.19515419618472005\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.010628290474414825\n",
      "Loss on test= 0.012059829197824001\n",
      "acc for Lsat= 0.24725721775030252 \n",
      "acc for Psat= 0.3785312733077287 \n",
      "acc for optim= 0.20126922019738452\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.011402484960854053\n",
      "Loss on test= 0.012607226148247719\n",
      "acc for Lsat= 0.30478128760517614 \n",
      "acc for Psat= 0.30306036644253403 \n",
      "acc for optim= 0.1882375767110372\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.010842399671673775\n",
      "Loss on test= 0.012555691413581371\n",
      "acc for Lsat= 0.2445705440092039 \n",
      "acc for Psat= 0.3837257358052837 \n",
      "acc for optim= 0.19658534179679182\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.010665168054401875\n",
      "Loss on test= 0.011495590209960938\n",
      "acc for Lsat= 0.30746050533127495 \n",
      "acc for Psat= 0.3056016574783653 \n",
      "acc for optim= 0.18778361409754693\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.010742414742708206\n",
      "Loss on test= 0.011401074007153511\n",
      "acc for Lsat= 0.2613974819207608 \n",
      "acc for Psat= 0.29949855039248596 \n",
      "acc for optim= 0.19546039998602135\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.010740366764366627\n",
      "Loss on test= 0.011643677018582821\n",
      "acc for Lsat= 0.2949526996305665 \n",
      "acc for Psat= 0.3082720097445417 \n",
      "acc for optim= 0.19270724355305288\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.01087589655071497\n",
      "Loss on test= 0.012137873098254204\n",
      "acc for Lsat= 0.26640282611510513 \n",
      "acc for Psat= 0.3081230639944241 \n",
      "acc for optim= 0.19387529549390278\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.010403278283774853\n",
      "Loss on test= 0.011932033114135265\n",
      "acc for Lsat= 0.27413650109952575 \n",
      "acc for Psat= 0.3209167587425524 \n",
      "acc for optim= 0.20365161723940045\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.011455075815320015\n",
      "Loss on test= 0.01279129646718502\n",
      "acc for Lsat= 0.23560210850956612 \n",
      "acc for Psat= 0.3662532540219144 \n",
      "acc for optim= 0.1989054695477043\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.010838184505701065\n",
      "Loss on test= 0.01136760413646698\n",
      "acc for Lsat= 0.27303541746703164 \n",
      "acc for Psat= 0.325602759120237 \n",
      "acc for optim= 0.1947312028544705\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.010691100731492043\n",
      "Loss on test= 0.01345799770206213\n",
      "acc for Lsat= 0.244602718609983 \n",
      "acc for Psat= 0.41980389027456705 \n",
      "acc for optim= 0.19268589508784636\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.010636702179908752\n",
      "Loss on test= 0.011323310434818268\n",
      "acc for Lsat= 0.24630697652213024 \n",
      "acc for Psat= 0.333881112634412 \n",
      "acc for optim= 0.19776867249743804\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.010600050911307335\n",
      "Loss on test= 0.011818548664450645\n",
      "acc for Lsat= 0.2899910192759676 \n",
      "acc for Psat= 0.3117533005979321 \n",
      "acc for optim= 0.20638084402575307\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.010723533108830452\n",
      "Loss on test= 0.012361183762550354\n",
      "acc for Lsat= 0.24966037108036265 \n",
      "acc for Psat= 0.3092508199506729 \n",
      "acc for optim= 0.19378250027384147\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.010849383659660816\n",
      "Loss on test= 0.012739119119942188\n",
      "acc for Lsat= 0.3280612286367073 \n",
      "acc for Psat= 0.33067256631408315 \n",
      "acc for optim= 0.19894750930826696\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.010806785896420479\n",
      "Loss on test= 0.012136816047132015\n",
      "acc for Lsat= 0.24910825256547714 \n",
      "acc for Psat= 0.34912582318419655 \n",
      "acc for optim= 0.20004150992876069\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.010405216366052628\n",
      "Loss on test= 0.011312835849821568\n",
      "acc for Lsat= 0.26873181783407374 \n",
      "acc for Psat= 0.30570453078080145 \n",
      "acc for optim= 0.20013710319531006\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.01058101188391447\n",
      "Loss on test= 0.011027115397155285\n",
      "acc for Lsat= 0.25861995345582506 \n",
      "acc for Psat= 0.3098166165086818 \n",
      "acc for optim= 0.19969599350431078\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.01067550852894783\n",
      "Loss on test= 0.011377224698662758\n",
      "acc for Lsat= 0.24097131883605175 \n",
      "acc for Psat= 0.34537513872537356 \n",
      "acc for optim= 0.18803449866125546\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.010416236706078053\n",
      "Loss on test= 0.011122274212539196\n",
      "acc for Lsat= 0.27352401340180515 \n",
      "acc for Psat= 0.29723855272311844 \n",
      "acc for optim= 0.19670355706290826\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.01047609280794859\n",
      "Loss on test= 0.011190836317837238\n",
      "acc for Lsat= 0.23785228041791973 \n",
      "acc for Psat= 0.29193922473509576 \n",
      "acc for optim= 0.1949767050603908\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.010130723007023335\n",
      "Loss on test= 0.010448631830513477\n",
      "acc for Lsat= 0.26299975454251556 \n",
      "acc for Psat= 0.31239199715885146 \n",
      "acc for optim= 0.20008250811578537\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.010099244304001331\n",
      "Loss on test= 0.01364593580365181\n",
      "acc for Lsat= 0.25492031210986266 \n",
      "acc for Psat= 0.4050376902313154 \n",
      "acc for optim= 0.19765929045270486\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.010592116042971611\n",
      "Loss on test= 0.011388223618268967\n",
      "acc for Lsat= 0.27011493792407554 \n",
      "acc for Psat= 0.2931767251402316 \n",
      "acc for optim= 0.19477839749153056\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.010544892400503159\n",
      "Loss on test= 0.01056548859924078\n",
      "acc for Lsat= 0.24354086170205846 \n",
      "acc for Psat= 0.325256376949452 \n",
      "acc for optim= 0.20005220366599402\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.010141613893210888\n",
      "Loss on test= 0.011414984241127968\n",
      "acc for Lsat= 0.25424934910276803 \n",
      "acc for Psat= 0.3269796659800262 \n",
      "acc for optim= 0.1999547390827305\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.010392975993454456\n",
      "Loss on test= 0.011394878849387169\n",
      "acc for Lsat= 0.2548842811068155 \n",
      "acc for Psat= 0.3178577194323864 \n",
      "acc for optim= 0.19806423561955877\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.010431649163365364\n",
      "Loss on test= 0.012039617635309696\n",
      "acc for Lsat= 0.32313207169814584 \n",
      "acc for Psat= 0.32169375387560206 \n",
      "acc for optim= 0.19554330645848028\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.010696636512875557\n",
      "Loss on test= 0.010852163657546043\n",
      "acc for Lsat= 0.2577715317146047 \n",
      "acc for Psat= 0.3069819715589826 \n",
      "acc for optim= 0.19368223457894526\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.010135313495993614\n",
      "Loss on test= 0.010687858797609806\n",
      "acc for Lsat= 0.2777220160169236 \n",
      "acc for Psat= 0.28860850357906764 \n",
      "acc for optim= 0.1958773031598891\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.010137110017240047\n",
      "Loss on test= 0.011249941773712635\n",
      "acc for Lsat= 0.2292443887264518 \n",
      "acc for Psat= 0.34032159716652305 \n",
      "acc for optim= 0.1927205222032294\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.009998450987040997\n",
      "Loss on test= 0.011106550693511963\n",
      "acc for Lsat= 0.2426862665703772 \n",
      "acc for Psat= 0.3139910327982098 \n",
      "acc for optim= 0.19619356518543665\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.010098598897457123\n",
      "Loss on test= 0.010325941257178783\n",
      "acc for Lsat= 0.2500809625584028 \n",
      "acc for Psat= 0.310033805227077 \n",
      "acc for optim= 0.19089877332781552\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.010191851295530796\n",
      "Loss on test= 0.010986083187162876\n",
      "acc for Lsat= 0.26786439315824156 \n",
      "acc for Psat= 0.30094888289986066 \n",
      "acc for optim= 0.19021873973031542\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.010114609263837337\n",
      "Loss on test= 0.011118867434561253\n",
      "acc for Lsat= 0.285469093710236 \n",
      "acc for Psat= 0.30183796236717075 \n",
      "acc for optim= 0.1931461637149049\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.010368471965193748\n",
      "Loss on test= 0.010837164707481861\n",
      "acc for Lsat= 0.23103099924196 \n",
      "acc for Psat= 0.3172118444061788 \n",
      "acc for optim= 0.20543425061426918\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.010382535867393017\n",
      "Loss on test= 0.010920984670519829\n",
      "acc for Lsat= 0.24416455814689225 \n",
      "acc for Psat= 0.3428284607550784 \n",
      "acc for optim= 0.20097459675024446\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.009983842261135578\n",
      "Loss on test= 0.011319592595100403\n",
      "acc for Lsat= 0.24844568250370463 \n",
      "acc for Psat= 0.3254409617653142 \n",
      "acc for optim= 0.1902768684347983\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.010129358619451523\n",
      "Loss on test= 0.010703036561608315\n",
      "acc for Lsat= 0.24295533169060946 \n",
      "acc for Psat= 0.315803848736372 \n",
      "acc for optim= 0.19223148381452365\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.010087543167173862\n",
      "Loss on test= 0.011136533692479134\n",
      "acc for Lsat= 0.2247986674794103 \n",
      "acc for Psat= 0.3381370197532453 \n",
      "acc for optim= 0.19425311402104656\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.010427005589008331\n",
      "Loss on test= 0.01136817503720522\n",
      "acc for Lsat= 0.2567039797634336 \n",
      "acc for Psat= 0.2827547287918089 \n",
      "acc for optim= 0.19747917700049192\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.010094495490193367\n",
      "Loss on test= 0.010491660796105862\n",
      "acc for Lsat= 0.24936530222200687 \n",
      "acc for Psat= 0.30747316769702593 \n",
      "acc for optim= 0.19286260520434675\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.009822030551731586\n",
      "Loss on test= 0.010768404230475426\n",
      "acc for Lsat= 0.22023500251600273 \n",
      "acc for Psat= 0.3454488600782005 \n",
      "acc for optim= 0.1961867570339441\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.009774286299943924\n",
      "Loss on test= 0.010825511999428272\n",
      "acc for Lsat= 0.2551801538789437 \n",
      "acc for Psat= 0.3074820938050201 \n",
      "acc for optim= 0.19681791760769948\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.010042239911854267\n",
      "Loss on test= 0.010251736268401146\n",
      "acc for Lsat= 0.22798945157449674 \n",
      "acc for Psat= 0.3169750247630086 \n",
      "acc for optim= 0.19280469814170706\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.009845416992902756\n",
      "Loss on test= 0.01154303178191185\n",
      "acc for Lsat= 0.3319580828772667 \n",
      "acc for Psat= 0.30302891491383716 \n",
      "acc for optim= 0.1940788571476308\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.010190856643021107\n",
      "Loss on test= 0.012657199054956436\n",
      "acc for Lsat= 0.24933661845148133 \n",
      "acc for Psat= 0.4231884366591977 \n",
      "acc for optim= 0.19805431409829022\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.009899424389004707\n",
      "Loss on test= 0.010289737023413181\n",
      "acc for Lsat= 0.22244251632631906 \n",
      "acc for Psat= 0.2991739068175603 \n",
      "acc for optim= 0.1924403286228315\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.009525753557682037\n",
      "Loss on test= 0.010638147592544556\n",
      "acc for Lsat= 0.27762209253804127 \n",
      "acc for Psat= 0.28055647644843607 \n",
      "acc for optim= 0.1875131102329957\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.009794664569199085\n",
      "Loss on test= 0.010679837316274643\n",
      "acc for Lsat= 0.26353434718987195 \n",
      "acc for Psat= 0.2982916207645856 \n",
      "acc for optim= 0.18913029930263292\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.010032950900495052\n",
      "Loss on test= 0.010226317681372166\n",
      "acc for Lsat= 0.2304730359370493 \n",
      "acc for Psat= 0.29008200641004117 \n",
      "acc for optim= 0.1882813656128427\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.009750096127390862\n",
      "Loss on test= 0.011849064379930496\n",
      "acc for Lsat= 0.2300550311583966 \n",
      "acc for Psat= 0.37645453185462896 \n",
      "acc for optim= 0.20403835437068787\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.00970537681132555\n",
      "Loss on test= 0.010519537143409252\n",
      "acc for Lsat= 0.24366556537161405 \n",
      "acc for Psat= 0.29868317534281824 \n",
      "acc for optim= 0.19385827234981587\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.00963020883500576\n",
      "Loss on test= 0.009934929199516773\n",
      "acc for Lsat= 0.23345439831098555 \n",
      "acc for Psat= 0.31181796745836066 \n",
      "acc for optim= 0.19255524161918722\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.009660006500780582\n",
      "Loss on test= 0.010249454528093338\n",
      "acc for Lsat= 0.23437213490684075 \n",
      "acc for Psat= 0.29233030972072566 \n",
      "acc for optim= 0.1947385056881939\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.009816574864089489\n",
      "Loss on test= 0.011166495271027088\n",
      "acc for Lsat= 0.21208221710961928 \n",
      "acc for Psat= 0.3110911555767588 \n",
      "acc for optim= 0.19066775257729082\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.00951521284878254\n",
      "Loss on test= 0.010018274188041687\n",
      "acc for Lsat= 0.26057347839909 \n",
      "acc for Psat= 0.2911938361263015 \n",
      "acc for optim= 0.18947829570911504\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.009617079980671406\n",
      "Loss on test= 0.010236968286335468\n",
      "acc for Lsat= 0.2535661100756025 \n",
      "acc for Psat= 0.2740057171869085 \n",
      "acc for optim= 0.18972005550529356\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.009585981257259846\n",
      "Loss on test= 0.010479435324668884\n",
      "acc for Lsat= 0.23198835492842812 \n",
      "acc for Psat= 0.29738523834463637 \n",
      "acc for optim= 0.19498145574338244\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.009447566233575344\n",
      "Loss on test= 0.010562273673713207\n",
      "acc for Lsat= 0.22701947676172052 \n",
      "acc for Psat= 0.3289427050287879 \n",
      "acc for optim= 0.2008089899684057\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.009587233886122704\n",
      "Loss on test= 0.011269825510680676\n",
      "acc for Lsat= 0.27663192986809104 \n",
      "acc for Psat= 0.2895642640604008 \n",
      "acc for optim= 0.196430471389298\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.009505830705165863\n",
      "Loss on test= 0.010200689546763897\n",
      "acc for Lsat= 0.2270590648140815 \n",
      "acc for Psat= 0.27776635706627656 \n",
      "acc for optim= 0.19262480484935254\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.010204978287220001\n",
      "Loss on test= 0.009940559044480324\n",
      "acc for Lsat= 0.25113330945345835 \n",
      "acc for Psat= 0.2848313912462972 \n",
      "acc for optim= 0.1984262523777992\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.010086484253406525\n",
      "Loss on test= 0.012101634405553341\n",
      "acc for Lsat= 0.23553527577904468 \n",
      "acc for Psat= 0.38010412056039944 \n",
      "acc for optim= 0.19183666656140672\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.0100844856351614\n",
      "Loss on test= 0.010984504595398903\n",
      "acc for Lsat= 0.30132554612842993 \n",
      "acc for Psat= 0.2904151415112554 \n",
      "acc for optim= 0.1923772395443725\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.009609837085008621\n",
      "Loss on test= 0.010834325104951859\n",
      "acc for Lsat= 0.21465696272246754 \n",
      "acc for Psat= 0.3188521500792499 \n",
      "acc for optim= 0.19181288195722043\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.009554511867463589\n",
      "Loss on test= 0.010470741428434849\n",
      "acc for Lsat= 0.2768933524033904 \n",
      "acc for Psat= 0.27983612581502293 \n",
      "acc for optim= 0.19805318993049031\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.009416114538908005\n",
      "Loss on test= 0.011204920709133148\n",
      "acc for Lsat= 0.2997869768422223 \n",
      "acc for Psat= 0.2941917816912079 \n",
      "acc for optim= 0.1960176642436685\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.009336373768746853\n",
      "Loss on test= 0.011453690007328987\n",
      "acc for Lsat= 0.2697087945341844 \n",
      "acc for Psat= 0.30270535143830096 \n",
      "acc for optim= 0.18659794679311942\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.009859141893684864\n",
      "Loss on test= 0.010341365821659565\n",
      "acc for Lsat= 0.21462505861347528 \n",
      "acc for Psat= 0.28193829393716735 \n",
      "acc for optim= 0.194003195073959\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.010215270332992077\n",
      "Loss on test= 0.010087245143949986\n",
      "acc for Lsat= 0.21123702274033693 \n",
      "acc for Psat= 0.283685849847766 \n",
      "acc for optim= 0.19485854318770943\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.009389087557792664\n",
      "Loss on test= 0.010328022763133049\n",
      "acc for Lsat= 0.2655937964174538 \n",
      "acc for Psat= 0.276753132083163 \n",
      "acc for optim= 0.19730256066336674\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.00941872876137495\n",
      "Loss on test= 0.010207184590399265\n",
      "acc for Lsat= 0.2102576126854802 \n",
      "acc for Psat= 0.28868334983731936 \n",
      "acc for optim= 0.19465613109059632\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.009275072254240513\n",
      "Loss on test= 0.010439961217343807\n",
      "acc for Lsat= 0.23720506658286764 \n",
      "acc for Psat= 0.28667164696113057 \n",
      "acc for optim= 0.19410273711617118\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.009159636683762074\n",
      "Loss on test= 0.010282007046043873\n",
      "acc for Lsat= 0.21699829076002258 \n",
      "acc for Psat= 0.31727104264698297 \n",
      "acc for optim= 0.19599033023018206\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.009326644241809845\n",
      "Loss on test= 0.00980403833091259\n",
      "acc for Lsat= 0.21351769256776804 \n",
      "acc for Psat= 0.2899702432904805 \n",
      "acc for optim= 0.19291175930049723\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.009266972541809082\n",
      "Loss on test= 0.009907230734825134\n",
      "acc for Lsat= 0.20420261813961663 \n",
      "acc for Psat= 0.267726992886998 \n",
      "acc for optim= 0.19278953540767385\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.009152623824775219\n",
      "Loss on test= 0.010548613965511322\n",
      "acc for Lsat= 0.21596631221315898 \n",
      "acc for Psat= 0.3241380467063848 \n",
      "acc for optim= 0.1866425718597728\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.008916404098272324\n",
      "Loss on test= 0.009209412150084972\n",
      "acc for Lsat= 0.21033587651893598 \n",
      "acc for Psat= 0.2771572173278892 \n",
      "acc for optim= 0.189136703769101\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.00927268248051405\n",
      "Loss on test= 0.009545152075588703\n",
      "acc for Lsat= 0.2048030949899348 \n",
      "acc for Psat= 0.286783737335419 \n",
      "acc for optim= 0.18936488251956934\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.009365403093397617\n",
      "Loss on test= 0.010299683548510075\n",
      "acc for Lsat= 0.2572212874511024 \n",
      "acc for Psat= 0.28360856129699175 \n",
      "acc for optim= 0.19285182529711165\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.009623675607144833\n",
      "Loss on test= 0.010631601326167583\n",
      "acc for Lsat= 0.20048531692953328 \n",
      "acc for Psat= 0.3399909286027478 \n",
      "acc for optim= 0.1900695993453327\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.008886530064046383\n",
      "Loss on test= 0.009596798568964005\n",
      "acc for Lsat= 0.19755206832642952 \n",
      "acc for Psat= 0.28388729841756416 \n",
      "acc for optim= 0.19434990412067948\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.008770463988184929\n",
      "Loss on test= 0.009295177645981312\n",
      "acc for Lsat= 0.22023159212148055 \n",
      "acc for Psat= 0.2913447930776464 \n",
      "acc for optim= 0.19128812069971604\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.008735192939639091\n",
      "Loss on test= 0.010231869295239449\n",
      "acc for Lsat= 0.21901145952988127 \n",
      "acc for Psat= 0.2649080970472455 \n",
      "acc for optim= 0.18981587298283656\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.008718795143067837\n",
      "Loss on test= 0.009933257475495338\n",
      "acc for Lsat= 0.22085323823833009 \n",
      "acc for Psat= 0.2489607500296237 \n",
      "acc for optim= 0.1902794784093842\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.008844206109642982\n",
      "Loss on test= 0.009856559336185455\n",
      "acc for Lsat= 0.2644746986507262 \n",
      "acc for Psat= 0.26135274324828844 \n",
      "acc for optim= 0.19087122674426535\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.009108244441449642\n",
      "Loss on test= 0.010420272126793861\n",
      "acc for Lsat= 0.23053943506611912 \n",
      "acc for Psat= 0.2793999992356623 \n",
      "acc for optim= 0.19742787578139245\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.00922656524926424\n",
      "Loss on test= 0.009659504517912865\n",
      "acc for Lsat= 0.21710001298797088 \n",
      "acc for Psat= 0.26236119028928095 \n",
      "acc for optim= 0.18896600405993946\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.00895295012742281\n",
      "Loss on test= 0.009086414240300655\n",
      "acc for Lsat= 0.21684446695482276 \n",
      "acc for Psat= 0.2799231553083676 \n",
      "acc for optim= 0.19569286924554427\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.008552735671401024\n",
      "Loss on test= 0.009026444517076015\n",
      "acc for Lsat= 0.19262759663741089 \n",
      "acc for Psat= 0.2612944823613853 \n",
      "acc for optim= 0.18886888591559664\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.008706269785761833\n",
      "Loss on test= 0.008968480862677097\n",
      "acc for Lsat= 0.19960206196363386 \n",
      "acc for Psat= 0.26408182024130616 \n",
      "acc for optim= 0.1955713554143094\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.009017854928970337\n",
      "Loss on test= 0.009351427666842937\n",
      "acc for Lsat= 0.22131525631364737 \n",
      "acc for Psat= 0.2593111572469887 \n",
      "acc for optim= 0.19088703555659065\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.009144437499344349\n",
      "Loss on test= 0.010010736994445324\n",
      "acc for Lsat= 0.249046047402206 \n",
      "acc for Psat= 0.26527578073492386 \n",
      "acc for optim= 0.19106095338950557\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.008785012178122997\n",
      "Loss on test= 0.009346441365778446\n",
      "acc for Lsat= 0.21307134613508005 \n",
      "acc for Psat= 0.25247244438336613 \n",
      "acc for optim= 0.18935118729151892\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.008842002600431442\n",
      "Loss on test= 0.009309359826147556\n",
      "acc for Lsat= 0.2093934488189375 \n",
      "acc for Psat= 0.2611539589614384 \n",
      "acc for optim= 0.1926433213635834\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.008792690932750702\n",
      "Loss on test= 0.009320637211203575\n",
      "acc for Lsat= 0.199468564388037 \n",
      "acc for Psat= 0.2757491988261274 \n",
      "acc for optim= 0.19933321732615522\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.008782194927334785\n",
      "Loss on test= 0.009455976076424122\n",
      "acc for Lsat= 0.20791969527449142 \n",
      "acc for Psat= 0.27887176507246714 \n",
      "acc for optim= 0.1939497878441683\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.00893833115696907\n",
      "Loss on test= 0.00979649554938078\n",
      "acc for Lsat= 0.227736866856749 \n",
      "acc for Psat= 0.27690309270385755 \n",
      "acc for optim= 0.18892830200048913\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.00900559313595295\n",
      "Loss on test= 0.009501091204583645\n",
      "acc for Lsat= 0.20281000179430964 \n",
      "acc for Psat= 0.2574428725719544 \n",
      "acc for optim= 0.18996392374990406\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.009214770048856735\n",
      "Loss on test= 0.00960233248770237\n",
      "acc for Lsat= 0.2193247540234478 \n",
      "acc for Psat= 0.26706327682119524 \n",
      "acc for optim= 0.19079950379759916\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.008972386829555035\n",
      "Loss on test= 0.009748979471623898\n",
      "acc for Lsat= 0.2211246443817996 \n",
      "acc for Psat= 0.27303329603593146 \n",
      "acc for optim= 0.18612502930714195\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.008482636883854866\n",
      "Loss on test= 0.008847089484333992\n",
      "acc for Lsat= 0.19387293311671316 \n",
      "acc for Psat= 0.24499342602152988 \n",
      "acc for optim= 0.19071807701226515\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.008604349568486214\n",
      "Loss on test= 0.009408514946699142\n",
      "acc for Lsat= 0.1921462027023301 \n",
      "acc for Psat= 0.2530847400543083 \n",
      "acc for optim= 0.1911352927390908\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.008552595973014832\n",
      "Loss on test= 0.009421269409358501\n",
      "acc for Lsat= 0.21832984258307497 \n",
      "acc for Psat= 0.26481347021119195 \n",
      "acc for optim= 0.19199189984175138\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.008751476183533669\n",
      "Loss on test= 0.00927137490361929\n",
      "acc for Lsat= 0.2324540301491947 \n",
      "acc for Psat= 0.25671627261751406 \n",
      "acc for optim= 0.18990065748766938\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.008471870794892311\n",
      "Loss on test= 0.009295163676142693\n",
      "acc for Lsat= 0.20483825897335428 \n",
      "acc for Psat= 0.24588301246748834 \n",
      "acc for optim= 0.1918961898283325\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.008752962574362755\n",
      "Loss on test= 0.011270901188254356\n",
      "acc for Lsat= 0.30666513708726867 \n",
      "acc for Psat= 0.2884136925174578 \n",
      "acc for optim= 0.19106883701563157\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.009428279474377632\n",
      "Loss on test= 0.01047678105533123\n",
      "acc for Lsat= 0.2373681944445707 \n",
      "acc for Psat= 0.27297363188935797 \n",
      "acc for optim= 0.1918142720863437\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.008537258952856064\n",
      "Loss on test= 0.00930206011980772\n",
      "acc for Lsat= 0.19089032880367232 \n",
      "acc for Psat= 0.2599883939849836 \n",
      "acc for optim= 0.1894708661699976\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.008388198912143707\n",
      "Loss on test= 0.00896292645484209\n",
      "acc for Lsat= 0.17591723273334217 \n",
      "acc for Psat= 0.27113567096042773 \n",
      "acc for optim= 0.19117295274171173\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.008428557775914669\n",
      "Loss on test= 0.009434005245566368\n",
      "acc for Lsat= 0.2191296299582039 \n",
      "acc for Psat= 0.261477830299063 \n",
      "acc for optim= 0.1895109169703131\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.008841990493237972\n",
      "Loss on test= 0.010045716539025307\n",
      "acc for Lsat= 0.2609415576735046 \n",
      "acc for Psat= 0.25161089277502763 \n",
      "acc for optim= 0.1841353875407131\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.008717035874724388\n",
      "Loss on test= 0.009107920341193676\n",
      "acc for Lsat= 0.19188563964239988 \n",
      "acc for Psat= 0.2638810319943799 \n",
      "acc for optim= 0.19113562243355037\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.008113485760986805\n",
      "Loss on test= 0.008809360675513744\n",
      "acc for Lsat= 0.18840242227865067 \n",
      "acc for Psat= 0.24672008497657008 \n",
      "acc for optim= 0.1933805735996528\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.008436097763478756\n",
      "Loss on test= 0.008687646128237247\n",
      "acc for Lsat= 0.18110631581402156 \n",
      "acc for Psat= 0.24168269121104755 \n",
      "acc for optim= 0.1895463397188389\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.008688324131071568\n",
      "Loss on test= 0.00896548107266426\n",
      "acc for Lsat= 0.1793702808330685 \n",
      "acc for Psat= 0.25357895158545896 \n",
      "acc for optim= 0.1925059667583146\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.008652773685753345\n",
      "Loss on test= 0.009304782375693321\n",
      "acc for Lsat= 0.19313721311454715 \n",
      "acc for Psat= 0.26646946501096935 \n",
      "acc for optim= 0.18818552708575767\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.008300837129354477\n",
      "Loss on test= 0.008506824262440205\n",
      "acc for Lsat= 0.18824334302248522 \n",
      "acc for Psat= 0.2729426093215512 \n",
      "acc for optim= 0.18924756054400713\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.008147379383444786\n",
      "Loss on test= 0.009168187156319618\n",
      "acc for Lsat= 0.18027816514084996 \n",
      "acc for Psat= 0.2579418561445719 \n",
      "acc for optim= 0.19008452793413372\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.008199966512620449\n",
      "Loss on test= 0.008445408195257187\n",
      "acc for Lsat= 0.18144843778606407 \n",
      "acc for Psat= 0.2360972608058128 \n",
      "acc for optim= 0.1908416102940808\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.008797019720077515\n",
      "Loss on test= 0.009677362628281116\n",
      "acc for Lsat= 0.21430158543031164 \n",
      "acc for Psat= 0.247638237174141 \n",
      "acc for optim= 0.19551320232032496\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.008739568293094635\n",
      "Loss on test= 0.009440599009394646\n",
      "acc for Lsat= 0.19733176901826407 \n",
      "acc for Psat= 0.27021815949292677 \n",
      "acc for optim= 0.18865956121373675\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.008265605196356773\n",
      "Loss on test= 0.00963752344250679\n",
      "acc for Lsat= 0.22257268106575892 \n",
      "acc for Psat= 0.24286836268210382 \n",
      "acc for optim= 0.19000104010922006\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.008074797689914703\n",
      "Loss on test= 0.008695707656443119\n",
      "acc for Lsat= 0.17817871708020167 \n",
      "acc for Psat= 0.2610768745342628 \n",
      "acc for optim= 0.1886921740244017\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.008435790427029133\n",
      "Loss on test= 0.008995834738016129\n",
      "acc for Lsat= 0.19796874151703575 \n",
      "acc for Psat= 0.24245424422426023 \n",
      "acc for optim= 0.19178518445806805\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.00828668475151062\n",
      "Loss on test= 0.010343911126255989\n",
      "acc for Lsat= 0.31420414596858964 \n",
      "acc for Psat= 0.26218329078983516 \n",
      "acc for optim= 0.19162545563292066\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.008678960613906384\n",
      "Loss on test= 0.009949764236807823\n",
      "acc for Lsat= 0.18679576374691081 \n",
      "acc for Psat= 0.2902336075392275 \n",
      "acc for optim= 0.19330287728194348\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.008634580299258232\n",
      "Loss on test= 0.00950282160192728\n",
      "acc for Lsat= 0.2167601871553563 \n",
      "acc for Psat= 0.2520323041761101 \n",
      "acc for optim= 0.1915132735586077\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.008463851176202297\n",
      "Loss on test= 0.00905741099268198\n",
      "acc for Lsat= 0.16896390703343944 \n",
      "acc for Psat= 0.2632605652663089 \n",
      "acc for optim= 0.19019335258761547\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.008504106663167477\n",
      "Loss on test= 0.009763441979885101\n",
      "acc for Lsat= 0.21370657768676285 \n",
      "acc for Psat= 0.2562040164504307 \n",
      "acc for optim= 0.2033507680998072\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.00828759465366602\n",
      "Loss on test= 0.009300729259848595\n",
      "acc for Lsat= 0.21368754995322936 \n",
      "acc for Psat= 0.26935993633771826 \n",
      "acc for optim= 0.1912236300191285\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.008245525881648064\n",
      "Loss on test= 0.009754166007041931\n",
      "acc for Lsat= 0.17596662069066754 \n",
      "acc for Psat= 0.2717126826490228 \n",
      "acc for optim= 0.18624601073797503\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.008556155487895012\n",
      "Loss on test= 0.009248215705156326\n",
      "acc for Lsat= 0.2333527551853803 \n",
      "acc for Psat= 0.24486038177840513 \n",
      "acc for optim= 0.18893614358318234\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.00866053719073534\n",
      "Loss on test= 0.00892646424472332\n",
      "acc for Lsat= 0.1774888564238633 \n",
      "acc for Psat= 0.27317620117758673 \n",
      "acc for optim= 0.18964533525050264\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.00839366763830185\n",
      "Loss on test= 0.009559293277561665\n",
      "acc for Lsat= 0.17826201969040306 \n",
      "acc for Psat= 0.3020907707490354 \n",
      "acc for optim= 0.19253288613863578\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.007993105798959732\n",
      "Loss on test= 0.008591764606535435\n",
      "acc for Lsat= 0.1711347398996696 \n",
      "acc for Psat= 0.23588408536837763 \n",
      "acc for optim= 0.18727351930824257\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.007904033176600933\n",
      "Loss on test= 0.008645624853670597\n",
      "acc for Lsat= 0.1797775026108276 \n",
      "acc for Psat= 0.24674878468519906 \n",
      "acc for optim= 0.19649600012328577\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.008101514540612698\n",
      "Loss on test= 0.008595948107540607\n",
      "acc for Lsat= 0.17285605027683307 \n",
      "acc for Psat= 0.26554735622532366 \n",
      "acc for optim= 0.18746207144038243\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.008590989746153355\n",
      "Loss on test= 0.009515718556940556\n",
      "acc for Lsat= 0.1905278749865239 \n",
      "acc for Psat= 0.2679655677983081 \n",
      "acc for optim= 0.19332920001138396\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.008242549374699593\n",
      "Loss on test= 0.008716627955436707\n",
      "acc for Lsat= 0.1688312462383938 \n",
      "acc for Psat= 0.2620210388374068 \n",
      "acc for optim= 0.18772618557921159\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.008352942764759064\n",
      "Loss on test= 0.008710266090929508\n",
      "acc for Lsat= 0.17010592273436487 \n",
      "acc for Psat= 0.25172922549540383 \n",
      "acc for optim= 0.18955315774326517\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.008099607191979885\n",
      "Loss on test= 0.008527296595275402\n",
      "acc for Lsat= 0.15982992523857173 \n",
      "acc for Psat= 0.2297880514214174 \n",
      "acc for optim= 0.19001351194841648\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.00796856265515089\n",
      "Loss on test= 0.008246170356869698\n",
      "acc for Lsat= 0.18921197497174208 \n",
      "acc for Psat= 0.24057040254961434 \n",
      "acc for optim= 0.1886659155138782\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.008213470689952374\n",
      "Loss on test= 0.008868526667356491\n",
      "acc for Lsat= 0.16656473993301718 \n",
      "acc for Psat= 0.2406199192606633 \n",
      "acc for optim= 0.1904665291510134\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.00804939866065979\n",
      "Loss on test= 0.008758257143199444\n",
      "acc for Lsat= 0.20019835326387989 \n",
      "acc for Psat= 0.24405670058498602 \n",
      "acc for optim= 0.19152717955178042\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.0078033884055912495\n",
      "Loss on test= 0.00855701882392168\n",
      "acc for Lsat= 0.17146423746104317 \n",
      "acc for Psat= 0.23389773212199322 \n",
      "acc for optim= 0.19149773292765776\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.007952366024255753\n",
      "Loss on test= 0.009007842279970646\n",
      "acc for Lsat= 0.1951549194231661 \n",
      "acc for Psat= 0.24242265214018738 \n",
      "acc for optim= 0.19313411563211344\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.008409233763813972\n",
      "Loss on test= 0.008698705583810806\n",
      "acc for Lsat= 0.2089000638209384 \n",
      "acc for Psat= 0.24469150499852904 \n",
      "acc for optim= 0.19602040395280662\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.008615427650511265\n",
      "Loss on test= 0.009351160377264023\n",
      "acc for Lsat= 0.1691942155593023 \n",
      "acc for Psat= 0.26459611539817035 \n",
      "acc for optim= 0.21047652313683177\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.008052201010286808\n",
      "Loss on test= 0.008944661356508732\n",
      "acc for Lsat= 0.17329624511051628 \n",
      "acc for Psat= 0.2652662457706331 \n",
      "acc for optim= 0.1884845402113373\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.008250049315392971\n",
      "Loss on test= 0.00826567504554987\n",
      "acc for Lsat= 0.16762161676534387 \n",
      "acc for Psat= 0.2445500363902357 \n",
      "acc for optim= 0.1907689797059189\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.007957576774060726\n",
      "Loss on test= 0.009049270302057266\n",
      "acc for Lsat= 0.18449991791472817 \n",
      "acc for Psat= 0.24772804893625625 \n",
      "acc for optim= 0.18848107444795756\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.008136609569191933\n",
      "Loss on test= 0.008379330858588219\n",
      "acc for Lsat= 0.17961934258130133 \n",
      "acc for Psat= 0.25703365270348166 \n",
      "acc for optim= 0.19375429041070133\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.007856735028326511\n",
      "Loss on test= 0.008401752449572086\n",
      "acc for Lsat= 0.16454821316477358 \n",
      "acc for Psat= 0.2416701357791238 \n",
      "acc for optim= 0.19409033353912417\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.008041535504162312\n",
      "Loss on test= 0.009192312136292458\n",
      "acc for Lsat= 0.1770949041972533 \n",
      "acc for Psat= 0.2848801300113681 \n",
      "acc for optim= 0.19322011727618282\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.008283896371722221\n",
      "Loss on test= 0.008381756953895092\n",
      "acc for Lsat= 0.16487694258594765 \n",
      "acc for Psat= 0.23306812467057467 \n",
      "acc for optim= 0.18473797151759877\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.008251580409705639\n",
      "Loss on test= 0.008689673617482185\n",
      "acc for Lsat= 0.168193913116812 \n",
      "acc for Psat= 0.277315048348887 \n",
      "acc for optim= 0.1893348012861286\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.007746742106974125\n",
      "Loss on test= 0.008896837010979652\n",
      "acc for Lsat= 0.20090746999453954 \n",
      "acc for Psat= 0.24745044085972728 \n",
      "acc for optim= 0.19068036362416416\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.008143501356244087\n",
      "Loss on test= 0.008544765412807465\n",
      "acc for Lsat= 0.16944319823350934 \n",
      "acc for Psat= 0.25487370449947183 \n",
      "acc for optim= 0.18773771505732076\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.0077917082235217094\n",
      "Loss on test= 0.008210545405745506\n",
      "acc for Lsat= 0.1516976580033598 \n",
      "acc for Psat= 0.23809946490124473 \n",
      "acc for optim= 0.18536995068363368\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.007872410118579865\n",
      "Loss on test= 0.008270667865872383\n",
      "acc for Lsat= 0.1871455433992614 \n",
      "acc for Psat= 0.23057910571590065 \n",
      "acc for optim= 0.18909530343984984\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.007800800260156393\n",
      "Loss on test= 0.008919855579733849\n",
      "acc for Lsat= 0.16989762584243845 \n",
      "acc for Psat= 0.256783272978233 \n",
      "acc for optim= 0.18854136412296243\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.007885067723691463\n",
      "Loss on test= 0.008863351307809353\n",
      "acc for Lsat= 0.17310769694278702 \n",
      "acc for Psat= 0.23743103437378965 \n",
      "acc for optim= 0.18950938470496456\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.007840119302272797\n",
      "Loss on test= 0.008238705806434155\n",
      "acc for Lsat= 0.159617562861181 \n",
      "acc for Psat= 0.2715411136917504 \n",
      "acc for optim= 0.191068560186289\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.007891872897744179\n",
      "Loss on test= 0.008268115110695362\n",
      "acc for Lsat= 0.15690025059282905 \n",
      "acc for Psat= 0.2384310364637664 \n",
      "acc for optim= 0.1942554198478221\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.008073766715824604\n",
      "Loss on test= 0.008522320538759232\n",
      "acc for Lsat= 0.16323844342794572 \n",
      "acc for Psat= 0.24197941414874818 \n",
      "acc for optim= 0.19131964319594036\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.008058727718889713\n",
      "Loss on test= 0.008570102974772453\n",
      "acc for Lsat= 0.17350212932403855 \n",
      "acc for Psat= 0.24865776340900353 \n",
      "acc for optim= 0.1905096528722867\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.007837009616196156\n",
      "Loss on test= 0.008395317941904068\n",
      "acc for Lsat= 0.16853995164500382 \n",
      "acc for Psat= 0.23160197706169425 \n",
      "acc for optim= 0.19249750843281052\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.007849066518247128\n",
      "Loss on test= 0.009867655113339424\n",
      "acc for Lsat= 0.18650754236010914 \n",
      "acc for Psat= 0.31070375948419915 \n",
      "acc for optim= 0.19401593966717515\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.008040282875299454\n",
      "Loss on test= 0.008301730267703533\n",
      "acc for Lsat= 0.163287663336706 \n",
      "acc for Psat= 0.23969974724781964 \n",
      "acc for optim= 0.18893815383981327\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.007713356986641884\n",
      "Loss on test= 0.009586886502802372\n",
      "acc for Lsat= 0.1997145934842961 \n",
      "acc for Psat= 0.24599416349681977 \n",
      "acc for optim= 0.18998513804841866\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.007930224761366844\n",
      "Loss on test= 0.008364752866327763\n",
      "acc for Lsat= 0.16963259415835538 \n",
      "acc for Psat= 0.24727604642317305 \n",
      "acc for optim= 0.18820402287324337\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.0079905204474926\n",
      "Loss on test= 0.008284430019557476\n",
      "acc for Lsat= 0.1712978440940591 \n",
      "acc for Psat= 0.24268860065185927 \n",
      "acc for optim= 0.19093533741889168\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.0081053851172328\n",
      "Loss on test= 0.008430500514805317\n",
      "acc for Lsat= 0.17182080503836325 \n",
      "acc for Psat= 0.24205080218293792 \n",
      "acc for optim= 0.19242321451555827\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.007911331951618195\n",
      "Loss on test= 0.008161994628608227\n",
      "acc for Lsat= 0.17435581547004012 \n",
      "acc for Psat= 0.247042831240366 \n",
      "acc for optim= 0.18807155244989238\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.007651847321540117\n",
      "Loss on test= 0.008341535925865173\n",
      "acc for Lsat= 0.1598939624175703 \n",
      "acc for Psat= 0.23960840059334185 \n",
      "acc for optim= 0.18891266947557106\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.007652775850147009\n",
      "Loss on test= 0.008193301036953926\n",
      "acc for Lsat= 0.15841418507905572 \n",
      "acc for Psat= 0.23770800857046442 \n",
      "acc for optim= 0.2025512257564146\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.0079245800152421\n",
      "Loss on test= 0.00886320136487484\n",
      "acc for Lsat= 0.20168414287036285 \n",
      "acc for Psat= 0.2379919183318585 \n",
      "acc for optim= 0.18819040640428775\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.007724084425717592\n",
      "Loss on test= 0.008742216043174267\n",
      "acc for Lsat= 0.16750315914671504 \n",
      "acc for Psat= 0.2894126147915125 \n",
      "acc for optim= 0.18663219722440919\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.007928328588604927\n",
      "Loss on test= 0.00994630716741085\n",
      "acc for Lsat= 0.25209840948219925 \n",
      "acc for Psat= 0.2507623368960717 \n",
      "acc for optim= 0.189144289518653\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.008041920140385628\n",
      "Loss on test= 0.008425098843872547\n",
      "acc for Lsat= 0.169831397324349 \n",
      "acc for Psat= 0.25143615491027516 \n",
      "acc for optim= 0.1930445331448494\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.007834835909307003\n",
      "Loss on test= 0.007913715206086636\n",
      "acc for Lsat= 0.1642766905723555 \n",
      "acc for Psat= 0.23111236477632555 \n",
      "acc for optim= 0.19045914097935296\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.007578251417726278\n",
      "Loss on test= 0.008646862581372261\n",
      "acc for Lsat= 0.2130750129146838 \n",
      "acc for Psat= 0.23013530362230675 \n",
      "acc for optim= 0.1869863868109737\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.007728928234428167\n",
      "Loss on test= 0.008036856539547443\n",
      "acc for Lsat= 0.15356446381593816 \n",
      "acc for Psat= 0.23220606610443242 \n",
      "acc for optim= 0.18829710300613786\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.00776117667555809\n",
      "Loss on test= 0.008351299911737442\n",
      "acc for Lsat= 0.223278366989394 \n",
      "acc for Psat= 0.23351057531230301 \n",
      "acc for optim= 0.19126926735574473\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.0076850769110023975\n",
      "Loss on test= 0.0079545509070158\n",
      "acc for Lsat= 0.15428256775438157 \n",
      "acc for Psat= 0.23505960354826105 \n",
      "acc for optim= 0.19458431590877856\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.007687651086598635\n",
      "Loss on test= 0.00818555150181055\n",
      "acc for Lsat= 0.16988782443552958 \n",
      "acc for Psat= 0.2308424181592764 \n",
      "acc for optim= 0.20272111463880818\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.008191187866032124\n",
      "Loss on test= 0.010671304538846016\n",
      "acc for Lsat= 0.24710404607498818 \n",
      "acc for Psat= 0.26056426536996624 \n",
      "acc for optim= 0.19174573354364446\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.008043238893151283\n",
      "Loss on test= 0.008243647404015064\n",
      "acc for Lsat= 0.16045514837099512 \n",
      "acc for Psat= 0.2266682038867116 \n",
      "acc for optim= 0.1927464712628264\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.007660597562789917\n",
      "Loss on test= 0.008311155252158642\n",
      "acc for Lsat= 0.17451303406945756 \n",
      "acc for Psat= 0.2249967714412157 \n",
      "acc for optim= 0.19373318097613929\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.007857893593609333\n",
      "Loss on test= 0.008533378131687641\n",
      "acc for Lsat= 0.1514023906465563 \n",
      "acc for Psat= 0.2503172028054168 \n",
      "acc for optim= 0.19085877695387526\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.007739846594631672\n",
      "Loss on test= 0.007874161005020142\n",
      "acc for Lsat= 0.19042600833415999 \n",
      "acc for Psat= 0.2293123513068044 \n",
      "acc for optim= 0.19195059190875524\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.0072625139728188515\n",
      "Loss on test= 0.008345460519194603\n",
      "acc for Lsat= 0.1954142153874666 \n",
      "acc for Psat= 0.22490066480519533 \n",
      "acc for optim= 0.18967618836762307\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.007592139299958944\n",
      "Loss on test= 0.00819864310324192\n",
      "acc for Lsat= 0.15810357163561117 \n",
      "acc for Psat= 0.228688892186698 \n",
      "acc for optim= 0.18813338580681327\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.007813255302608013\n",
      "Loss on test= 0.008544744923710823\n",
      "acc for Lsat= 0.16360559360509797 \n",
      "acc for Psat= 0.22403000088367686 \n",
      "acc for optim= 0.1896868525894919\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.007690533064305782\n",
      "Loss on test= 0.007957504130899906\n",
      "acc for Lsat= 0.15356934050489784 \n",
      "acc for Psat= 0.2521562201735513 \n",
      "acc for optim= 0.1863028011729192\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.00772467814385891\n",
      "Loss on test= 0.00791154894977808\n",
      "acc for Lsat= 0.1585052240296972 \n",
      "acc for Psat= 0.2333960782542252 \n",
      "acc for optim= 0.19473074781637625\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.007278155535459518\n",
      "Loss on test= 0.00805104710161686\n",
      "acc for Lsat= 0.150925787892521 \n",
      "acc for Psat= 0.23424324015256906 \n",
      "acc for optim= 0.18709405202409127\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.007427469827234745\n",
      "Loss on test= 0.007958914153277874\n",
      "acc for Lsat= 0.15542562411482125 \n",
      "acc for Psat= 0.23139298363349628 \n",
      "acc for optim= 0.19001181380244325\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.00739038223400712\n",
      "Loss on test= 0.007852514274418354\n",
      "acc for Lsat= 0.1608526563865559 \n",
      "acc for Psat= 0.22885056361878556 \n",
      "acc for optim= 0.18585021443573782\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.007471079006791115\n",
      "Loss on test= 0.008058115839958191\n",
      "acc for Lsat= 0.20542369632921936 \n",
      "acc for Psat= 0.23203922879356714 \n",
      "acc for optim= 0.1924405635233868\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.007630584295839071\n",
      "Loss on test= 0.00782050658017397\n",
      "acc for Lsat= 0.14956283020246947 \n",
      "acc for Psat= 0.22751968522710297 \n",
      "acc for optim= 0.1851011741302279\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.00744613679125905\n",
      "Loss on test= 0.00806422159075737\n",
      "acc for Lsat= 0.14327557908305805 \n",
      "acc for Psat= 0.2255262322220448 \n",
      "acc for optim= 0.19060341584475748\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.007440411020070314\n",
      "Loss on test= 0.007794005796313286\n",
      "acc for Lsat= 0.15084675816772664 \n",
      "acc for Psat= 0.2245337270464547 \n",
      "acc for optim= 0.18807246303913416\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.007213200442492962\n",
      "Loss on test= 0.007703508250415325\n",
      "acc for Lsat= 0.17665805885858513 \n",
      "acc for Psat= 0.22456744640953116 \n",
      "acc for optim= 0.1918863512975214\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.007964104413986206\n",
      "Loss on test= 0.007650856859982014\n",
      "acc for Lsat= 0.15565801829998727 \n",
      "acc for Psat= 0.2369985249712733 \n",
      "acc for optim= 0.19159274601622964\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.007159516215324402\n",
      "Loss on test= 0.008362202905118465\n",
      "acc for Lsat= 0.14217290513664232 \n",
      "acc for Psat= 0.22008512331219232 \n",
      "acc for optim= 0.1917683425873858\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.00743495486676693\n",
      "Loss on test= 0.007557552307844162\n",
      "acc for Lsat= 0.158170083080689 \n",
      "acc for Psat= 0.21873629199581046 \n",
      "acc for optim= 0.19187803524609254\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.0073259384371340275\n",
      "Loss on test= 0.007723020389676094\n",
      "acc for Lsat= 0.16395894386181606 \n",
      "acc for Psat= 0.22605394520724076 \n",
      "acc for optim= 0.18743371578701143\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.007599680218845606\n",
      "Loss on test= 0.007833002135157585\n",
      "acc for Lsat= 0.1482171759244011 \n",
      "acc for Psat= 0.21991798318285383 \n",
      "acc for optim= 0.1940718654101098\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.007349730469286442\n",
      "Loss on test= 0.008203372359275818\n",
      "acc for Lsat= 0.14762927654373925 \n",
      "acc for Psat= 0.21624879431604044 \n",
      "acc for optim= 0.1899746400197949\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.0074388557113707066\n",
      "Loss on test= 0.007955818437039852\n",
      "acc for Lsat= 0.14454170687452927 \n",
      "acc for Psat= 0.24214403454774386 \n",
      "acc for optim= 0.19473425251301188\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.00751480320468545\n",
      "Loss on test= 0.008451632224023342\n",
      "acc for Lsat= 0.1552067281791588 \n",
      "acc for Psat= 0.2218270031585849 \n",
      "acc for optim= 0.18696505632465846\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.007448228541761637\n",
      "Loss on test= 0.00792799424380064\n",
      "acc for Lsat= 0.16091064784288048 \n",
      "acc for Psat= 0.2417934631356164 \n",
      "acc for optim= 0.1941465988623079\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.007300652097910643\n",
      "Loss on test= 0.008258877322077751\n",
      "acc for Lsat= 0.15576004933462026 \n",
      "acc for Psat= 0.23076042155572715 \n",
      "acc for optim= 0.18722354926678628\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.007408620323985815\n",
      "Loss on test= 0.008454435504972935\n",
      "acc for Lsat= 0.1519571513742719 \n",
      "acc for Psat= 0.2533978975525069 \n",
      "acc for optim= 0.19105217791149845\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.007554556243121624\n",
      "Loss on test= 0.007916516624391079\n",
      "acc for Lsat= 0.15964777512812903 \n",
      "acc for Psat= 0.22503537742965352 \n",
      "acc for optim= 0.18721737819460277\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.0072919270023703575\n",
      "Loss on test= 0.007564933504909277\n",
      "acc for Lsat= 0.18244878069507084 \n",
      "acc for Psat= 0.21905076555058994 \n",
      "acc for optim= 0.1884171056912778\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.007500793784856796\n",
      "Loss on test= 0.007768614683300257\n",
      "acc for Lsat= 0.16207698596259137 \n",
      "acc for Psat= 0.22500144401060793 \n",
      "acc for optim= 0.1926611616442175\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.007205892354249954\n",
      "Loss on test= 0.0077936360612511635\n",
      "acc for Lsat= 0.17625967862015288 \n",
      "acc for Psat= 0.21456147300656037 \n",
      "acc for optim= 0.18445087206251826\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.007521092891693115\n",
      "Loss on test= 0.00769514637067914\n",
      "acc for Lsat= 0.1410287606201097 \n",
      "acc for Psat= 0.23545992949260147 \n",
      "acc for optim= 0.18945123585777962\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.0076741804368793964\n",
      "Loss on test= 0.0077538322657346725\n",
      "acc for Lsat= 0.14569884121659482 \n",
      "acc for Psat= 0.22928546433241856 \n",
      "acc for optim= 0.18955755003215116\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.007324044592678547\n",
      "Loss on test= 0.00781369861215353\n",
      "acc for Lsat= 0.1520611340935977 \n",
      "acc for Psat= 0.2104866624478647 \n",
      "acc for optim= 0.1910617301146959\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.00705404719337821\n",
      "Loss on test= 0.00726555660367012\n",
      "acc for Lsat= 0.14465119538048432 \n",
      "acc for Psat= 0.21005766211050828 \n",
      "acc for optim= 0.18774581887614536\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.007165716029703617\n",
      "Loss on test= 0.007928802631795406\n",
      "acc for Lsat= 0.1519151457642029 \n",
      "acc for Psat= 0.21280012849358074 \n",
      "acc for optim= 0.19064552900286996\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.007081236690282822\n",
      "Loss on test= 0.007584043312817812\n",
      "acc for Lsat= 0.1321346690471015 \n",
      "acc for Psat= 0.2319096159465246 \n",
      "acc for optim= 0.19187080026293532\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.007120401598513126\n",
      "Loss on test= 0.0077924951910972595\n",
      "acc for Lsat= 0.15176195912283366 \n",
      "acc for Psat= 0.22140817749282546 \n",
      "acc for optim= 0.19112336832119114\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.007219420280307531\n",
      "Loss on test= 0.008367637172341347\n",
      "acc for Lsat= 0.18281226608028314 \n",
      "acc for Psat= 0.22999607294784524 \n",
      "acc for optim= 0.18863016557962337\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.007421945221722126\n",
      "Loss on test= 0.008804339915513992\n",
      "acc for Lsat= 0.1618217445637227 \n",
      "acc for Psat= 0.27198270226196924 \n",
      "acc for optim= 0.19114556792487133\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.007584784179925919\n",
      "Loss on test= 0.008094558492302895\n",
      "acc for Lsat= 0.17796048963665836 \n",
      "acc for Psat= 0.21573423773362585 \n",
      "acc for optim= 0.1912669143114671\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.007260957732796669\n",
      "Loss on test= 0.007619469426572323\n",
      "acc for Lsat= 0.1583630475949109 \n",
      "acc for Psat= 0.2035143753802569 \n",
      "acc for optim= 0.18927176176362695\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.007425262127071619\n",
      "Loss on test= 0.0077187661081552505\n",
      "acc for Lsat= 0.18404538775811907 \n",
      "acc for Psat= 0.22927866013944023 \n",
      "acc for optim= 0.20394002991520824\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.007463260553777218\n",
      "Loss on test= 0.008306107483804226\n",
      "acc for Lsat= 0.17452874031418153 \n",
      "acc for Psat= 0.21902761634290172 \n",
      "acc for optim= 0.18921944991612888\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.007094200700521469\n",
      "Loss on test= 0.00750122033059597\n",
      "acc for Lsat= 0.1367136695435211 \n",
      "acc for Psat= 0.19991500066582277 \n",
      "acc for optim= 0.18968792236921364\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.007261577993631363\n",
      "Loss on test= 0.007902220822870731\n",
      "acc for Lsat= 0.14853767695328585 \n",
      "acc for Psat= 0.24425572499544737 \n",
      "acc for optim= 0.18818015394444465\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.007030936423689127\n",
      "Loss on test= 0.007409426849335432\n",
      "acc for Lsat= 0.16609519956369154 \n",
      "acc for Psat= 0.20930439565701228 \n",
      "acc for optim= 0.18518563277629674\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.007089344318956137\n",
      "Loss on test= 0.007676023989915848\n",
      "acc for Lsat= 0.15449638763990103 \n",
      "acc for Psat= 0.2106493859909942 \n",
      "acc for optim= 0.1920136489446835\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.00715901842340827\n",
      "Loss on test= 0.00787823460996151\n",
      "acc for Lsat= 0.15017997638032948 \n",
      "acc for Psat= 0.20161762556322296 \n",
      "acc for optim= 0.18804286341882953\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.007334514055401087\n",
      "Loss on test= 0.007891982793807983\n",
      "acc for Lsat= 0.1422467528841603 \n",
      "acc for Psat= 0.23433250696964664 \n",
      "acc for optim= 0.18893626644362607\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.0070978677831590176\n",
      "Loss on test= 0.007490551099181175\n",
      "acc for Lsat= 0.14540967462311824 \n",
      "acc for Psat= 0.21636286217757073 \n",
      "acc for optim= 0.1887201981711818\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.0069851018488407135\n",
      "Loss on test= 0.007291826885193586\n",
      "acc for Lsat= 0.14882848009381486 \n",
      "acc for Psat= 0.22300974400624565 \n",
      "acc for optim= 0.18426711145287766\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.007376793306320906\n",
      "Loss on test= 0.007700339425355196\n",
      "acc for Lsat= 0.1667863274531162 \n",
      "acc for Psat= 0.2239452631431443 \n",
      "acc for optim= 0.18875138504144334\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.00703992648050189\n",
      "Loss on test= 0.008051648736000061\n",
      "acc for Lsat= 0.16982561616050834 \n",
      "acc for Psat= 0.21702070330738443 \n",
      "acc for optim= 0.1829523186016878\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.007233807351440191\n",
      "Loss on test= 0.0075087291188538074\n",
      "acc for Lsat= 0.1795689040020964 \n",
      "acc for Psat= 0.2114086151036522 \n",
      "acc for optim= 0.19215111358711068\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.007266591303050518\n",
      "Loss on test= 0.007310270331799984\n",
      "acc for Lsat= 0.16403722071643986 \n",
      "acc for Psat= 0.20973978473252705 \n",
      "acc for optim= 0.188241936905625\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.007166888564825058\n",
      "Loss on test= 0.0075098443776369095\n",
      "acc for Lsat= 0.13683258377234261 \n",
      "acc for Psat= 0.2071165913835717 \n",
      "acc for optim= 0.1889363126013671\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.00710706040263176\n",
      "Loss on test= 0.007866457104682922\n",
      "acc for Lsat= 0.13930170435117828 \n",
      "acc for Psat= 0.21039726581049664 \n",
      "acc for optim= 0.18782126642499125\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.007280868943780661\n",
      "Loss on test= 0.008269347250461578\n",
      "acc for Lsat= 0.2147826935491852 \n",
      "acc for Psat= 0.22200726179289632 \n",
      "acc for optim= 0.18819842801147732\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.007418239023536444\n",
      "Loss on test= 0.00769073236733675\n",
      "acc for Lsat= 0.15579185112418034 \n",
      "acc for Psat= 0.20706196644931804 \n",
      "acc for optim= 0.1835645518608421\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.007174049504101276\n",
      "Loss on test= 0.007557629141956568\n",
      "acc for Lsat= 0.13758140635075727 \n",
      "acc for Psat= 0.22020768562789592 \n",
      "acc for optim= 0.1890863070370255\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.007220465689897537\n",
      "Loss on test= 0.00787370279431343\n",
      "acc for Lsat= 0.16651680082341536 \n",
      "acc for Psat= 0.20555668214424136 \n",
      "acc for optim= 0.18827606829408733\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.0072591169737279415\n",
      "Loss on test= 0.00750062195584178\n",
      "acc for Lsat= 0.14048089549040113 \n",
      "acc for Psat= 0.21935873404514938 \n",
      "acc for optim= 0.18643792217905708\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.007034629583358765\n",
      "Loss on test= 0.008041724562644958\n",
      "acc for Lsat= 0.14334474523442425 \n",
      "acc for Psat= 0.2432371257314485 \n",
      "acc for optim= 0.18795976855727606\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.0074080112390220165\n",
      "Loss on test= 0.007988017983734608\n",
      "acc for Lsat= 0.1916862039298222 \n",
      "acc for Psat= 0.21538461377290455 \n",
      "acc for optim= 0.18531409969880377\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.007198324427008629\n",
      "Loss on test= 0.00760650634765625\n",
      "acc for Lsat= 0.14630127917936644 \n",
      "acc for Psat= 0.23891844802592704 \n",
      "acc for optim= 0.19072935449248934\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.0072244093753397465\n",
      "Loss on test= 0.007280763704329729\n",
      "acc for Lsat= 0.1463195956701482 \n",
      "acc for Psat= 0.2016558458002495 \n",
      "acc for optim= 0.1883969747963223\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.006790198851376772\n",
      "Loss on test= 0.007654355838894844\n",
      "acc for Lsat= 0.14967473493782785 \n",
      "acc for Psat= 0.22134284273903865 \n",
      "acc for optim= 0.19007489438287872\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.006841921713203192\n",
      "Loss on test= 0.007203525863587856\n",
      "acc for Lsat= 0.13535970555843763 \n",
      "acc for Psat= 0.20827168522653763 \n",
      "acc for optim= 0.18865504336183123\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.007051190827041864\n",
      "Loss on test= 0.007360808085650206\n",
      "acc for Lsat= 0.13209602645184607 \n",
      "acc for Psat= 0.21346808265455341 \n",
      "acc for optim= 0.18672886296328856\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.007020333781838417\n",
      "Loss on test= 0.007366020232439041\n",
      "acc for Lsat= 0.16153299840614735 \n",
      "acc for Psat= 0.21619273570045275 \n",
      "acc for optim= 0.1917880996501284\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.006902092602103949\n",
      "Loss on test= 0.007292142603546381\n",
      "acc for Lsat= 0.13892142927687853 \n",
      "acc for Psat= 0.2055412150919044 \n",
      "acc for optim= 0.18721048808416724\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.007268642075359821\n",
      "Loss on test= 0.007482518907636404\n",
      "acc for Lsat= 0.1413825530388921 \n",
      "acc for Psat= 0.19953528891936592 \n",
      "acc for optim= 0.18618705947901126\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.006860206834971905\n",
      "Loss on test= 0.00733304163441062\n",
      "acc for Lsat= 0.13585749513200623 \n",
      "acc for Psat= 0.23882970854921606 \n",
      "acc for optim= 0.18836094842904336\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.006975722033530474\n",
      "Loss on test= 0.007168518379330635\n",
      "acc for Lsat= 0.15361354452307763 \n",
      "acc for Psat= 0.2035486359008418 \n",
      "acc for optim= 0.1840283129792157\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.007581790909171104\n",
      "Loss on test= 0.007198141422122717\n",
      "acc for Lsat= 0.13828773679631776 \n",
      "acc for Psat= 0.2060800585942972 \n",
      "acc for optim= 0.18757010535714594\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.0073005808517336845\n",
      "Loss on test= 0.007318592630326748\n",
      "acc for Lsat= 0.15373778193432716 \n",
      "acc for Psat= 0.205574173383915 \n",
      "acc for optim= 0.1884103008650945\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.00707686971873045\n",
      "Loss on test= 0.007583313621580601\n",
      "acc for Lsat= 0.1398761168751957 \n",
      "acc for Psat= 0.22564326652413788 \n",
      "acc for optim= 0.19683285738417022\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.006972466595470905\n",
      "Loss on test= 0.007260218728333712\n",
      "acc for Lsat= 0.1424445772993479 \n",
      "acc for Psat= 0.2190990917106565 \n",
      "acc for optim= 0.18921482055353606\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.006932409945875406\n",
      "Loss on test= 0.007127774879336357\n",
      "acc for Lsat= 0.14781056730331527 \n",
      "acc for Psat= 0.20042147773248772 \n",
      "acc for optim= 0.1846157108035137\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.006936419289559126\n",
      "Loss on test= 0.007234536111354828\n",
      "acc for Lsat= 0.13232978605319168 \n",
      "acc for Psat= 0.20998995011905208 \n",
      "acc for optim= 0.19341957759516426\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.007067392580211163\n",
      "Loss on test= 0.007437577936798334\n",
      "acc for Lsat= 0.14016419836843852 \n",
      "acc for Psat= 0.20358909581114562 \n",
      "acc for optim= 0.19052057049171905\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.006921670865267515\n",
      "Loss on test= 0.007026122882962227\n",
      "acc for Lsat= 0.13577862422696213 \n",
      "acc for Psat= 0.20378107545395716 \n",
      "acc for optim= 0.19650214253783202\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.006855203304439783\n",
      "Loss on test= 0.00699084997177124\n",
      "acc for Lsat= 0.15228067927465244 \n",
      "acc for Psat= 0.21071841437180802 \n",
      "acc for optim= 0.18544916395387337\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.006539408583194017\n",
      "Loss on test= 0.007179004140198231\n",
      "acc for Lsat= 0.14386680342357902 \n",
      "acc for Psat= 0.20570838012350282 \n",
      "acc for optim= 0.19787055635577025\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.006886858027428389\n",
      "Loss on test= 0.006898076739162207\n",
      "acc for Lsat= 0.14056029971741096 \n",
      "acc for Psat= 0.18654011040918114 \n",
      "acc for optim= 0.18435429149414287\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.00679751206189394\n",
      "Loss on test= 0.00742793083190918\n",
      "acc for Lsat= 0.14248689811486387 \n",
      "acc for Psat= 0.23652326444799482 \n",
      "acc for optim= 0.18640960439783205\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.007095989305526018\n",
      "Loss on test= 0.007813158445060253\n",
      "acc for Lsat= 0.1645066375710571 \n",
      "acc for Psat= 0.2020911887312478 \n",
      "acc for optim= 0.1888460016717373\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.006982135120779276\n",
      "Loss on test= 0.007175706326961517\n",
      "acc for Lsat= 0.13607675297904231 \n",
      "acc for Psat= 0.21754618601964368 \n",
      "acc for optim= 0.18884657032105825\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.006958534941077232\n",
      "Loss on test= 0.0072410148568451405\n",
      "acc for Lsat= 0.13496948915279652 \n",
      "acc for Psat= 0.21088007857773894 \n",
      "acc for optim= 0.18923487879549833\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.007042223121970892\n",
      "Loss on test= 0.007227448280900717\n",
      "acc for Lsat= 0.14606585845300485 \n",
      "acc for Psat= 0.2089080544225195 \n",
      "acc for optim= 0.18706654985687016\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.006959675345569849\n",
      "Loss on test= 0.007428047712892294\n",
      "acc for Lsat= 0.14226319537005652 \n",
      "acc for Psat= 0.21760898475981408 \n",
      "acc for optim= 0.19064040766475168\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.006733761169016361\n",
      "Loss on test= 0.00731708062812686\n",
      "acc for Lsat= 0.13374129555037095 \n",
      "acc for Psat= 0.21667187503963586 \n",
      "acc for optim= 0.1836204333094936\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.006814002990722656\n",
      "Loss on test= 0.007296188268810511\n",
      "acc for Lsat= 0.15607913217477412 \n",
      "acc for Psat= 0.2137509859583932 \n",
      "acc for optim= 0.19605947345376448\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.0068635656498372555\n",
      "Loss on test= 0.0071794125251472\n",
      "acc for Lsat= 0.13364899684903148 \n",
      "acc for Psat= 0.20737701847011103 \n",
      "acc for optim= 0.18732285054006384\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.006909841205924749\n",
      "Loss on test= 0.007415898144245148\n",
      "acc for Lsat= 0.13388796687133828 \n",
      "acc for Psat= 0.2067189461897608 \n",
      "acc for optim= 0.18844295221788343\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.007033971603959799\n",
      "Loss on test= 0.007337289862334728\n",
      "acc for Lsat= 0.1432156151820252 \n",
      "acc for Psat= 0.20723041421985505 \n",
      "acc for optim= 0.18758431420743316\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.0070895482785999775\n",
      "Loss on test= 0.007183157838881016\n",
      "acc for Lsat= 0.1578437717127255 \n",
      "acc for Psat= 0.20563377915272754 \n",
      "acc for optim= 0.18999116345111286\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.006627863273024559\n",
      "Loss on test= 0.006893388461321592\n",
      "acc for Lsat= 0.1321036408387315 \n",
      "acc for Psat= 0.2046121254498831 \n",
      "acc for optim= 0.19336432147994512\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.006830144673585892\n",
      "Loss on test= 0.007204943336546421\n",
      "acc for Lsat= 0.13243886226838505 \n",
      "acc for Psat= 0.2026311518287961 \n",
      "acc for optim= 0.18444223138288401\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.006877079606056213\n",
      "Loss on test= 0.0074791149236261845\n",
      "acc for Lsat= 0.13689222666184955 \n",
      "acc for Psat= 0.2367153137506771 \n",
      "acc for optim= 0.19159655708829854\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.00685860775411129\n",
      "Loss on test= 0.006672527175396681\n",
      "acc for Lsat= 0.13061455052229576 \n",
      "acc for Psat= 0.20685639060148614 \n",
      "acc for optim= 0.18918195384606873\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.006600642576813698\n",
      "Loss on test= 0.006918159779161215\n",
      "acc for Lsat= 0.13149160970803947 \n",
      "acc for Psat= 0.19720722237488608 \n",
      "acc for optim= 0.18613495755149367\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.0065674446523189545\n",
      "Loss on test= 0.006904703564941883\n",
      "acc for Lsat= 0.1232380179165842 \n",
      "acc for Psat= 0.2009661983450044 \n",
      "acc for optim= 0.18616383311116905\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.0067007895559072495\n",
      "Loss on test= 0.007386979181319475\n",
      "acc for Lsat= 0.1311784258711693 \n",
      "acc for Psat= 0.20960857593780854 \n",
      "acc for optim= 0.18588453869145\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.006646205671131611\n",
      "Loss on test= 0.007286002393811941\n",
      "acc for Lsat= 0.17079999037771296 \n",
      "acc for Psat= 0.19716420031171938 \n",
      "acc for optim= 0.18707203933287953\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.006679864134639502\n",
      "Loss on test= 0.007210941053926945\n",
      "acc for Lsat= 0.1743910087678012 \n",
      "acc for Psat= 0.20393456704944066 \n",
      "acc for optim= 0.1875098383768361\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.0068461415357887745\n",
      "Loss on test= 0.006870071403682232\n",
      "acc for Lsat= 0.13669842046196257 \n",
      "acc for Psat= 0.20931250167966545 \n",
      "acc for optim= 0.18713859388309\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.006679323967546225\n",
      "Loss on test= 0.006726686842739582\n",
      "acc for Lsat= 0.13805851642078976 \n",
      "acc for Psat= 0.19536760639085834 \n",
      "acc for optim= 0.19327346541772508\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.00670357421040535\n",
      "Loss on test= 0.007200159598141909\n",
      "acc for Lsat= 0.1359757010934511 \n",
      "acc for Psat= 0.19480304168521528 \n",
      "acc for optim= 0.18670024804463833\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.006716206669807434\n",
      "Loss on test= 0.00678196782246232\n",
      "acc for Lsat= 0.13975600330790305 \n",
      "acc for Psat= 0.20649881472471296 \n",
      "acc for optim= 0.19068082956702612\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.006871671881526709\n",
      "Loss on test= 0.007058983668684959\n",
      "acc for Lsat= 0.15134236332960427 \n",
      "acc for Psat= 0.1955748253735569 \n",
      "acc for optim= 0.1864662686148099\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.006837909109890461\n",
      "Loss on test= 0.006905758753418922\n",
      "acc for Lsat= 0.1424074720367522 \n",
      "acc for Psat= 0.20792603505813875 \n",
      "acc for optim= 0.1941403675682031\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.00700451759621501\n",
      "Loss on test= 0.007448080461472273\n",
      "acc for Lsat= 0.1424281500963057 \n",
      "acc for Psat= 0.22063968864047737 \n",
      "acc for optim= 0.1843343756434577\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.007158275693655014\n",
      "Loss on test= 0.0078440485522151\n",
      "acc for Lsat= 0.17881115209547102 \n",
      "acc for Psat= 0.20594742086187406 \n",
      "acc for optim= 0.18603286523481272\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.007171478122472763\n",
      "Loss on test= 0.007700526155531406\n",
      "acc for Lsat= 0.14835236058609774 \n",
      "acc for Psat= 0.2534746083541462 \n",
      "acc for optim= 0.18746121556732515\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.007319942116737366\n",
      "Loss on test= 0.00742492638528347\n",
      "acc for Lsat= 0.1779021028365556 \n",
      "acc for Psat= 0.2024689533954606 \n",
      "acc for optim= 0.18630921550927293\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.007078090216964483\n",
      "Loss on test= 0.00717880530282855\n",
      "acc for Lsat= 0.15296018837329325 \n",
      "acc for Psat= 0.19841752019695108 \n",
      "acc for optim= 0.18851721536230873\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.006932288408279419\n",
      "Loss on test= 0.007237967569380999\n",
      "acc for Lsat= 0.1498434050664474 \n",
      "acc for Psat= 0.19061281924004217 \n",
      "acc for optim= 0.18070197786171874\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.006717455107718706\n",
      "Loss on test= 0.007136973086744547\n",
      "acc for Lsat= 0.12796854724827525 \n",
      "acc for Psat= 0.2041985882184432 \n",
      "acc for optim= 0.18982757433558298\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.006920151878148317\n",
      "Loss on test= 0.006832987070083618\n",
      "acc for Lsat= 0.1297137598806797 \n",
      "acc for Psat= 0.1892218691134838 \n",
      "acc for optim= 0.18546292693310926\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.006798002403229475\n",
      "Loss on test= 0.007169216871261597\n",
      "acc for Lsat= 0.1524890332175592 \n",
      "acc for Psat= 0.18515132140404406 \n",
      "acc for optim= 0.1913076340845421\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.006759262178093195\n",
      "Loss on test= 0.007046304177492857\n",
      "acc for Lsat= 0.13610775987389562 \n",
      "acc for Psat= 0.19723485107218997 \n",
      "acc for optim= 0.1935096914979088\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.006699065677821636\n",
      "Loss on test= 0.007152744103223085\n",
      "acc for Lsat= 0.13665598585459912 \n",
      "acc for Psat= 0.21654061942496589 \n",
      "acc for optim= 0.18941237820832316\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.006606079172343016\n",
      "Loss on test= 0.007369921077042818\n",
      "acc for Lsat= 0.1307155274101181 \n",
      "acc for Psat= 0.23575082951464463 \n",
      "acc for optim= 0.18414567493557507\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.006828873418271542\n",
      "Loss on test= 0.007291445974260569\n",
      "acc for Lsat= 0.18389296763210017 \n",
      "acc for Psat= 0.19697505550150685 \n",
      "acc for optim= 0.18781432941535525\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.00692560151219368\n",
      "Loss on test= 0.0072068581357598305\n",
      "acc for Lsat= 0.14618887157913943 \n",
      "acc for Psat= 0.20809219652024646 \n",
      "acc for optim= 0.18511736919705024\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.006701961159706116\n",
      "Loss on test= 0.006708766333758831\n",
      "acc for Lsat= 0.12759863287627357 \n",
      "acc for Psat= 0.17995154698626328 \n",
      "acc for optim= 0.1856796088014144\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.0066044386476278305\n",
      "Loss on test= 0.006877083331346512\n",
      "acc for Lsat= 0.13198349432334638 \n",
      "acc for Psat= 0.20451343050690657 \n",
      "acc for optim= 0.19167242290820247\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.006727070547640324\n",
      "Loss on test= 0.007059566676616669\n",
      "acc for Lsat= 0.13519578285028017 \n",
      "acc for Psat= 0.18187920959270915 \n",
      "acc for optim= 0.18803425892494144\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.00664224848151207\n",
      "Loss on test= 0.007111294195055962\n",
      "acc for Lsat= 0.12520541117142736 \n",
      "acc for Psat= 0.18637403362781452 \n",
      "acc for optim= 0.18721341737782005\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.006688838824629784\n",
      "Loss on test= 0.00719553092494607\n",
      "acc for Lsat= 0.15273305928127917 \n",
      "acc for Psat= 0.18767617222053828 \n",
      "acc for optim= 0.18511129868951487\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.006543651223182678\n",
      "Loss on test= 0.006894030142575502\n",
      "acc for Lsat= 0.15756907325959293 \n",
      "acc for Psat= 0.18231655921035045 \n",
      "acc for optim= 0.18661372957334654\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.006547337397933006\n",
      "Loss on test= 0.0074946582317352295\n",
      "acc for Lsat= 0.15347090475198283 \n",
      "acc for Psat= 0.19403634828907074 \n",
      "acc for optim= 0.18681379572415216\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.006710343528538942\n",
      "Loss on test= 0.007168213836848736\n",
      "acc for Lsat= 0.12186491176052604 \n",
      "acc for Psat= 0.21738537033279254 \n",
      "acc for optim= 0.18964230304393553\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.006664606276899576\n",
      "Loss on test= 0.006878504063934088\n",
      "acc for Lsat= 0.13192088089921084 \n",
      "acc for Psat= 0.1922516385600682 \n",
      "acc for optim= 0.18203221856065038\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.006738942116498947\n",
      "Loss on test= 0.006791241466999054\n",
      "acc for Lsat= 0.14646628350168908 \n",
      "acc for Psat= 0.19114284560468198 \n",
      "acc for optim= 0.18720264962335145\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.006524188909679651\n",
      "Loss on test= 0.006596860941499472\n",
      "acc for Lsat= 0.11868515133500222 \n",
      "acc for Psat= 0.19739041484835734 \n",
      "acc for optim= 0.1908826150988839\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.006584479007869959\n",
      "Loss on test= 0.006704303435981274\n",
      "acc for Lsat= 0.12232834555362461 \n",
      "acc for Psat= 0.18270070548641268 \n",
      "acc for optim= 0.19060913440665211\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.006702754180878401\n",
      "Loss on test= 0.007476937025785446\n",
      "acc for Lsat= 0.13185532520148283 \n",
      "acc for Psat= 0.2013600733849622 \n",
      "acc for optim= 0.18931764361027367\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.006569699849933386\n",
      "Loss on test= 0.006970175076276064\n",
      "acc for Lsat= 0.1300326647188568 \n",
      "acc for Psat= 0.23185872535956348 \n",
      "acc for optim= 0.18679914738478712\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.006642557214945555\n",
      "Loss on test= 0.006647409405559301\n",
      "acc for Lsat= 0.1393313518248662 \n",
      "acc for Psat= 0.1819290294191199 \n",
      "acc for optim= 0.18681129083686115\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.006264524068683386\n",
      "Loss on test= 0.006559885106980801\n",
      "acc for Lsat= 0.12234733439706631 \n",
      "acc for Psat= 0.17661012248362493 \n",
      "acc for optim= 0.18397684996779315\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.006662116385996342\n",
      "Loss on test= 0.007693073246628046\n",
      "acc for Lsat= 0.18349851970305206 \n",
      "acc for Psat= 0.2085814072541669 \n",
      "acc for optim= 0.18874263892054866\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.006928551942110062\n",
      "Loss on test= 0.007398247718811035\n",
      "acc for Lsat= 0.12845439989531943 \n",
      "acc for Psat= 0.23049962344796499 \n",
      "acc for optim= 0.19118165253304462\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.006683733314275742\n",
      "Loss on test= 0.007527974899858236\n",
      "acc for Lsat= 0.17896097951342124 \n",
      "acc for Psat= 0.21484081813655762 \n",
      "acc for optim= 0.1885038077475533\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.006566746160387993\n",
      "Loss on test= 0.007130261044949293\n",
      "acc for Lsat= 0.1296047813004554 \n",
      "acc for Psat= 0.2166819474357023 \n",
      "acc for optim= 0.18609299681306643\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.006594614591449499\n",
      "Loss on test= 0.006898493971675634\n",
      "acc for Lsat= 0.1523478793143924 \n",
      "acc for Psat= 0.18600630579483649 \n",
      "acc for optim= 0.18646811795376897\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.0066726598888635635\n",
      "Loss on test= 0.0065584504045546055\n",
      "acc for Lsat= 0.11729622517934232 \n",
      "acc for Psat= 0.18289002221422992 \n",
      "acc for optim= 0.19080229521165853\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.00638061948120594\n",
      "Loss on test= 0.006700687110424042\n",
      "acc for Lsat= 0.12116446629166554 \n",
      "acc for Psat= 0.18462176435130803 \n",
      "acc for optim= 0.18810545173835488\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.006388214882463217\n",
      "Loss on test= 0.0067424289882183075\n",
      "acc for Lsat= 0.1270069064312092 \n",
      "acc for Psat= 0.18490021803528006 \n",
      "acc for optim= 0.18662021322293063\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.006277216598391533\n",
      "Loss on test= 0.006606371607631445\n",
      "acc for Lsat= 0.11214589493150974 \n",
      "acc for Psat= 0.185860516991729 \n",
      "acc for optim= 0.18955252097301226\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.006277360953390598\n",
      "Loss on test= 0.006824911572039127\n",
      "acc for Lsat= 0.12261443590899501 \n",
      "acc for Psat= 0.17703162409007572 \n",
      "acc for optim= 0.18404820404267977\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.006680068094283342\n",
      "Loss on test= 0.006609973963350058\n",
      "acc for Lsat= 0.1246013737195549 \n",
      "acc for Psat= 0.17421627403992052 \n",
      "acc for optim= 0.185689145675939\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.006749552208930254\n",
      "Loss on test= 0.006843141745775938\n",
      "acc for Lsat= 0.12593329754914473 \n",
      "acc for Psat= 0.20173864533756608 \n",
      "acc for optim= 0.18715561779036588\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.006652334704995155\n",
      "Loss on test= 0.0070502725429832935\n",
      "acc for Lsat= 0.13261610866715814 \n",
      "acc for Psat= 0.18709272120759124 \n",
      "acc for optim= 0.18674486097837428\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.006492279004305601\n",
      "Loss on test= 0.007054074201732874\n",
      "acc for Lsat= 0.12352375954857986 \n",
      "acc for Psat= 0.19354026378612224 \n",
      "acc for optim= 0.19097605500516962\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.0064175911247730255\n",
      "Loss on test= 0.006555688567459583\n",
      "acc for Lsat= 0.13060605271390602 \n",
      "acc for Psat= 0.18894591024331317 \n",
      "acc for optim= 0.18591569719648907\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.006451243534684181\n",
      "Loss on test= 0.007085921708494425\n",
      "acc for Lsat= 0.13016907564451685 \n",
      "acc for Psat= 0.21181496866041483 \n",
      "acc for optim= 0.1913233638731342\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.006389570888131857\n",
      "Loss on test= 0.007003737613558769\n",
      "acc for Lsat= 0.11000549982988583 \n",
      "acc for Psat= 0.18641493527291067 \n",
      "acc for optim= 0.18741808740781601\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.006471447646617889\n",
      "Loss on test= 0.00650019571185112\n",
      "acc for Lsat= 0.13206839226674943 \n",
      "acc for Psat= 0.17683357332969143 \n",
      "acc for optim= 0.18530618056915094\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.0063359541818499565\n",
      "Loss on test= 0.0069886548444628716\n",
      "acc for Lsat= 0.124196302486313 \n",
      "acc for Psat= 0.19100879121499412 \n",
      "acc for optim= 0.19657125962879257\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.006606802344322205\n",
      "Loss on test= 0.006821898277848959\n",
      "acc for Lsat= 0.13098019447253947 \n",
      "acc for Psat= 0.18700882725150567 \n",
      "acc for optim= 0.1863557109393917\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.0063977972604334354\n",
      "Loss on test= 0.007123115006834269\n",
      "acc for Lsat= 0.12308309717922679 \n",
      "acc for Psat= 0.18814575787222862 \n",
      "acc for optim= 0.18468147311658548\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.006494232919067144\n",
      "Loss on test= 0.007118945010006428\n",
      "acc for Lsat= 0.12410984890693971 \n",
      "acc for Psat= 0.21391405093596108 \n",
      "acc for optim= 0.19436814352976964\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.00633302703499794\n",
      "Loss on test= 0.006715813651680946\n",
      "acc for Lsat= 0.12436899676455092 \n",
      "acc for Psat= 0.17989194151143878 \n",
      "acc for optim= 0.18797301350482362\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.0065199327655136585\n",
      "Loss on test= 0.007073594257235527\n",
      "acc for Lsat= 0.14284556463285666 \n",
      "acc for Psat= 0.1939362949897996 \n",
      "acc for optim= 0.18621040567233796\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.0064338999800384045\n",
      "Loss on test= 0.006615085527300835\n",
      "acc for Lsat= 0.14484601847043205 \n",
      "acc for Psat= 0.17499105931553482 \n",
      "acc for optim= 0.1901667904037183\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.0064394730143249035\n",
      "Loss on test= 0.006647993810474873\n",
      "acc for Lsat= 0.11432352306793611 \n",
      "acc for Psat= 0.1912265615748913 \n",
      "acc for optim= 0.186372386627792\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.006334059871733189\n",
      "Loss on test= 0.006504138000309467\n",
      "acc for Lsat= 0.13199065081976555 \n",
      "acc for Psat= 0.18221901257670284 \n",
      "acc for optim= 0.18513993339768825\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.006402737461030483\n",
      "Loss on test= 0.0068789077922701836\n",
      "acc for Lsat= 0.11654129625989103 \n",
      "acc for Psat= 0.1889464412762774 \n",
      "acc for optim= 0.1870611383426483\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.006386008113622665\n",
      "Loss on test= 0.006587638054043055\n",
      "acc for Lsat= 0.12413277869025577 \n",
      "acc for Psat= 0.17752571918056156 \n",
      "acc for optim= 0.18641089655382628\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.0062302881851792336\n",
      "Loss on test= 0.006885905750095844\n",
      "acc for Lsat= 0.13388361544757327 \n",
      "acc for Psat= 0.18090242250189084 \n",
      "acc for optim= 0.18698120848244257\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.006531816441565752\n",
      "Loss on test= 0.0065881311893463135\n",
      "acc for Lsat= 0.11533181591437676 \n",
      "acc for Psat= 0.1923716131069169 \n",
      "acc for optim= 0.18880728915561074\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.00635278457775712\n",
      "Loss on test= 0.007119989022612572\n",
      "acc for Lsat= 0.15836715164039414 \n",
      "acc for Psat= 0.185523020970396 \n",
      "acc for optim= 0.18720407131262914\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.006417015567421913\n",
      "Loss on test= 0.007138690445572138\n",
      "acc for Lsat= 0.11615253354967855 \n",
      "acc for Psat= 0.21309259009777215 \n",
      "acc for optim= 0.18511970737725622\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.006397407501935959\n",
      "Loss on test= 0.006573142018169165\n",
      "acc for Lsat= 0.12479819945607183 \n",
      "acc for Psat= 0.19170430794582824 \n",
      "acc for optim= 0.18915703451509486\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.006443332880735397\n",
      "Loss on test= 0.00671364227309823\n",
      "acc for Lsat= 0.12277352885300659 \n",
      "acc for Psat= 0.19361932276719804 \n",
      "acc for optim= 0.18831206177443116\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.006377093028277159\n",
      "Loss on test= 0.006434156559407711\n",
      "acc for Lsat= 0.12328611338665342 \n",
      "acc for Psat= 0.18232046598267196 \n",
      "acc for optim= 0.18771910191375157\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.006260566879063845\n",
      "Loss on test= 0.006704128347337246\n",
      "acc for Lsat= 0.11842089431514535 \n",
      "acc for Psat= 0.1875511347740964 \n",
      "acc for optim= 0.18708212803903734\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.006373292300850153\n",
      "Loss on test= 0.007003988604992628\n",
      "acc for Lsat= 0.12737862700494687 \n",
      "acc for Psat= 0.18061427926295437 \n",
      "acc for optim= 0.18686454513029988\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.006302087102085352\n",
      "Loss on test= 0.006844734773039818\n",
      "acc for Lsat= 0.11614546015905058 \n",
      "acc for Psat= 0.1966939395100092 \n",
      "acc for optim= 0.18629159723609887\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.00639951229095459\n",
      "Loss on test= 0.007054746150970459\n",
      "acc for Lsat= 0.15254493818478343 \n",
      "acc for Psat= 0.177629884422483 \n",
      "acc for optim= 0.19725433443686965\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.006499987095594406\n",
      "Loss on test= 0.006475844886153936\n",
      "acc for Lsat= 0.11681040463744884 \n",
      "acc for Psat= 0.17889516458711335 \n",
      "acc for optim= 0.1867560285096949\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.006321109365671873\n",
      "Loss on test= 0.006358707323670387\n",
      "acc for Lsat= 0.11341034672521935 \n",
      "acc for Psat= 0.17833000899414353 \n",
      "acc for optim= 0.18732647131617194\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.0062941149808466434\n",
      "Loss on test= 0.0067141177132725716\n",
      "acc for Lsat= 0.12222719588631613 \n",
      "acc for Psat= 0.173526412964723 \n",
      "acc for optim= 0.18864380162300973\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.0062087769620120525\n",
      "Loss on test= 0.0066809034906327724\n",
      "acc for Lsat= 0.11213209266554407 \n",
      "acc for Psat= 0.1869126831401986 \n",
      "acc for optim= 0.19143929401124715\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.006371693219989538\n",
      "Loss on test= 0.006193871609866619\n",
      "acc for Lsat= 0.11558744657538621 \n",
      "acc for Psat= 0.17275191662692296 \n",
      "acc for optim= 0.18604403755209106\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.0064389766193926334\n",
      "Loss on test= 0.006692100316286087\n",
      "acc for Lsat= 0.13562052439630026 \n",
      "acc for Psat= 0.1969660023651896 \n",
      "acc for optim= 0.18497985207972847\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.006326179951429367\n",
      "Loss on test= 0.006312467157840729\n",
      "acc for Lsat= 0.12007899147264087 \n",
      "acc for Psat= 0.17199210532310866 \n",
      "acc for optim= 0.18976833543038574\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.006016310770064592\n",
      "Loss on test= 0.006420112680643797\n",
      "acc for Lsat= 0.1237560453735421 \n",
      "acc for Psat= 0.18966560379989017 \n",
      "acc for optim= 0.19299524870188475\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.006358034443110228\n",
      "Loss on test= 0.00651222188025713\n",
      "acc for Lsat= 0.11647415639595853 \n",
      "acc for Psat= 0.17762159832346772 \n",
      "acc for optim= 0.1847946208890298\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.006233237683773041\n",
      "Loss on test= 0.006781761534512043\n",
      "acc for Lsat= 0.12155765462685432 \n",
      "acc for Psat= 0.16698930240336513 \n",
      "acc for optim= 0.1838692095402744\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.006432514172047377\n",
      "Loss on test= 0.0068768905475735664\n",
      "acc for Lsat= 0.11236274133704216 \n",
      "acc for Psat= 0.18410778428251678 \n",
      "acc for optim= 0.18792793540030067\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.006083449348807335\n",
      "Loss on test= 0.006976307835429907\n",
      "acc for Lsat= 0.14408856887068297 \n",
      "acc for Psat= 0.18221644407949988 \n",
      "acc for optim= 0.18752719632664447\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.006268696393817663\n",
      "Loss on test= 0.006717477925121784\n",
      "acc for Lsat= 0.11366951415373085 \n",
      "acc for Psat= 0.18510732065860303 \n",
      "acc for optim= 0.18412773860158316\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.006292049307376146\n",
      "Loss on test= 0.006953462492674589\n",
      "acc for Lsat= 0.11469506913439349 \n",
      "acc for Psat= 0.18308313825449707 \n",
      "acc for optim= 0.19117777291260585\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.006235218141227961\n",
      "Loss on test= 0.006790543906390667\n",
      "acc for Lsat= 0.15987988815111356 \n",
      "acc for Psat= 0.1965968048483577 \n",
      "acc for optim= 0.1875366181051799\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.006386641878634691\n",
      "Loss on test= 0.006713493261486292\n",
      "acc for Lsat= 0.11840735997287305 \n",
      "acc for Psat= 0.18020975392347602 \n",
      "acc for optim= 0.18497836949919055\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.006328893825411797\n",
      "Loss on test= 0.0066984668374061584\n",
      "acc for Lsat= 0.10989687051797109 \n",
      "acc for Psat= 0.17163339937640656 \n",
      "acc for optim= 0.18911675421337792\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.006116893608123064\n",
      "Loss on test= 0.006847168318927288\n",
      "acc for Lsat= 0.11860178554284298 \n",
      "acc for Psat= 0.19270367628396834 \n",
      "acc for optim= 0.18532602507066503\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.006429234053939581\n",
      "Loss on test= 0.006707127671688795\n",
      "acc for Lsat= 0.13472267662630633 \n",
      "acc for Psat= 0.21321710017730003 \n",
      "acc for optim= 0.18890394398594917\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.006228331476449966\n",
      "Loss on test= 0.006705382838845253\n",
      "acc for Lsat= 0.11382157645388165 \n",
      "acc for Psat= 0.188976327313277 \n",
      "acc for optim= 0.18356875954223878\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.00639902800321579\n",
      "Loss on test= 0.006621638312935829\n",
      "acc for Lsat= 0.11891444397298147 \n",
      "acc for Psat= 0.17677882545025125 \n",
      "acc for optim= 0.19968277992036845\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.006241666618734598\n",
      "Loss on test= 0.006446778774261475\n",
      "acc for Lsat= 0.10811925260717593 \n",
      "acc for Psat= 0.17263686225310634 \n",
      "acc for optim= 0.186412168414225\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.00621455954387784\n",
      "Loss on test= 0.006768759805709124\n",
      "acc for Lsat= 0.10800599628104514 \n",
      "acc for Psat= 0.18239823223691043 \n",
      "acc for optim= 0.18973352343065827\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.00625211326405406\n",
      "Loss on test= 0.006953873205929995\n",
      "acc for Lsat= 0.1573001956491459 \n",
      "acc for Psat= 0.19803416453509567 \n",
      "acc for optim= 0.18666593002116488\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.006245618686079979\n",
      "Loss on test= 0.0064047412015497684\n",
      "acc for Lsat= 0.11453017902916858 \n",
      "acc for Psat= 0.17700474627054064 \n",
      "acc for optim= 0.18216491949656424\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.006118586286902428\n",
      "Loss on test= 0.00642910972237587\n",
      "acc for Lsat= 0.13153949717213828 \n",
      "acc for Psat= 0.17337696844943157 \n",
      "acc for optim= 0.18496453558642267\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.006453794427216053\n",
      "Loss on test= 0.006536100525408983\n",
      "acc for Lsat= 0.1151181056607252 \n",
      "acc for Psat= 0.16513156945025864 \n",
      "acc for optim= 0.18557211904860466\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.0061693014577031136\n",
      "Loss on test= 0.006274125073105097\n",
      "acc for Lsat= 0.12144048860932959 \n",
      "acc for Psat= 0.18059163133580727 \n",
      "acc for optim= 0.18383384136226644\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.006260896101593971\n",
      "Loss on test= 0.0067762588150799274\n",
      "acc for Lsat= 0.12215711689547075 \n",
      "acc for Psat= 0.17797599485276952 \n",
      "acc for optim= 0.18619484194533545\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.006340984720736742\n",
      "Loss on test= 0.006580356974154711\n",
      "acc for Lsat= 0.1279294991901544 \n",
      "acc for Psat= 0.18159832884329435 \n",
      "acc for optim= 0.18711310961215705\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.0062545547261834145\n",
      "Loss on test= 0.006422895006835461\n",
      "acc for Lsat= 0.11545844337524613 \n",
      "acc for Psat= 0.1584356909824655 \n",
      "acc for optim= 0.18586783574180635\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.00619079265743494\n",
      "Loss on test= 0.006653684191405773\n",
      "acc for Lsat= 0.11885559746872025 \n",
      "acc for Psat= 0.18665628116326155 \n",
      "acc for optim= 0.18505552876964382\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.006197591312229633\n",
      "Loss on test= 0.006332747638225555\n",
      "acc for Lsat= 0.12566932242574497 \n",
      "acc for Psat= 0.1785540208460392 \n",
      "acc for optim= 0.18389375059153257\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.006059369537979364\n",
      "Loss on test= 0.006433175411075354\n",
      "acc for Lsat= 0.11444660025810319 \n",
      "acc for Psat= 0.17709547128607803 \n",
      "acc for optim= 0.18885972935134526\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.006027002353221178\n",
      "Loss on test= 0.006795974913984537\n",
      "acc for Lsat= 0.12171395587734583 \n",
      "acc for Psat= 0.2158093165655029 \n",
      "acc for optim= 0.18964182879220037\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.006289152894169092\n",
      "Loss on test= 0.0066704885102808475\n",
      "acc for Lsat= 0.11805306493093863 \n",
      "acc for Psat= 0.18494919503290155 \n",
      "acc for optim= 0.18911548094852274\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.006213632877916098\n",
      "Loss on test= 0.006433544214814901\n",
      "acc for Lsat= 0.13841550051718612 \n",
      "acc for Psat= 0.17459908297009738 \n",
      "acc for optim= 0.18351266859413906\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.006124683655798435\n",
      "Loss on test= 0.006694106385111809\n",
      "acc for Lsat= 0.1348358219287105 \n",
      "acc for Psat= 0.18123506062186828 \n",
      "acc for optim= 0.18374009483916262\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.00635652057826519\n",
      "Loss on test= 0.006862306967377663\n",
      "acc for Lsat= 0.12774045472867107 \n",
      "acc for Psat= 0.19583823107161544 \n",
      "acc for optim= 0.1839131744514767\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.00612121494486928\n",
      "Loss on test= 0.006670284550637007\n",
      "acc for Lsat= 0.13737985057004326 \n",
      "acc for Psat= 0.17039105411193403 \n",
      "acc for optim= 0.18870941444623207\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.006215013097971678\n",
      "Loss on test= 0.0067074717953801155\n",
      "acc for Lsat= 0.11944178286186699 \n",
      "acc for Psat= 0.18422594183662236 \n",
      "acc for optim= 0.18563811959874993\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.006253273691982031\n",
      "Loss on test= 0.0066073681227862835\n",
      "acc for Lsat= 0.11302524623976284 \n",
      "acc for Psat= 0.17869597513104177 \n",
      "acc for optim= 0.18690284775456767\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.006076023448258638\n",
      "Loss on test= 0.006341300904750824\n",
      "acc for Lsat= 0.1269766033003327 \n",
      "acc for Psat= 0.15236328129695548 \n",
      "acc for optim= 0.1890446132468217\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.006072698626667261\n",
      "Loss on test= 0.006272190250456333\n",
      "acc for Lsat= 0.11357866532066632 \n",
      "acc for Psat= 0.1754930489765389 \n",
      "acc for optim= 0.18866465737978552\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.005985597614198923\n",
      "Loss on test= 0.006485603749752045\n",
      "acc for Lsat= 0.12030008578949491 \n",
      "acc for Psat= 0.18181223519983375 \n",
      "acc for optim= 0.18695554225996602\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.006079287268221378\n",
      "Loss on test= 0.0069329882971942425\n",
      "acc for Lsat= 0.16436647342728777 \n",
      "acc for Psat= 0.18961870547374585 \n",
      "acc for optim= 0.19052602514597852\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.006674098316580057\n",
      "Loss on test= 0.006775000598281622\n",
      "acc for Lsat= 0.11279276532858037 \n",
      "acc for Psat= 0.19538421024933356 \n",
      "acc for optim= 0.18608378422330232\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.006332429125905037\n",
      "Loss on test= 0.00677399942651391\n",
      "acc for Lsat= 0.14680140183230145 \n",
      "acc for Psat= 0.18362889733091564 \n",
      "acc for optim= 0.1852204348820738\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.006212943699210882\n",
      "Loss on test= 0.006193079520016909\n",
      "acc for Lsat= 0.11029190107719104 \n",
      "acc for Psat= 0.17163573493628456 \n",
      "acc for optim= 0.18550559503598157\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.006200824398547411\n",
      "Loss on test= 0.00614846171811223\n",
      "acc for Lsat= 0.10650633104730356 \n",
      "acc for Psat= 0.15865441616089712 \n",
      "acc for optim= 0.19020218471052577\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.00607497850432992\n",
      "Loss on test= 0.006320018321275711\n",
      "acc for Lsat= 0.11432537882875123 \n",
      "acc for Psat= 0.16104080523910927 \n",
      "acc for optim= 0.19317722190012196\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.006193721201270819\n",
      "Loss on test= 0.006488070357590914\n",
      "acc for Lsat= 0.11721009137968272 \n",
      "acc for Psat= 0.1714340982759274 \n",
      "acc for optim= 0.18996052342353742\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.006090804934501648\n",
      "Loss on test= 0.0065005202777683735\n",
      "acc for Lsat= 0.10848958383417699 \n",
      "acc for Psat= 0.17124037847045387 \n",
      "acc for optim= 0.18422205324772087\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.0061714909970760345\n",
      "Loss on test= 0.006640941835939884\n",
      "acc for Lsat= 0.12063919622714575 \n",
      "acc for Psat= 0.17806361914797988 \n",
      "acc for optim= 0.18558753750885199\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.00630376348271966\n",
      "Loss on test= 0.006330152042210102\n",
      "acc for Lsat= 0.11208305010419477 \n",
      "acc for Psat= 0.18203440741785312 \n",
      "acc for optim= 0.18797021800084032\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.0060293120332062244\n",
      "Loss on test= 0.006350444629788399\n",
      "acc for Lsat= 0.10936037332715853 \n",
      "acc for Psat= 0.16133334593079682 \n",
      "acc for optim= 0.18363820194437225\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.0058457497507333755\n",
      "Loss on test= 0.006462248507887125\n",
      "acc for Lsat= 0.1192632174430843 \n",
      "acc for Psat= 0.16790493152252198 \n",
      "acc for optim= 0.19088303070826884\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.006053134799003601\n",
      "Loss on test= 0.0061024390161037445\n",
      "acc for Lsat= 0.111841159000874 \n",
      "acc for Psat= 0.161835711204239 \n",
      "acc for optim= 0.18510451385977708\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.006118617486208677\n",
      "Loss on test= 0.006277598440647125\n",
      "acc for Lsat= 0.10776254809732908 \n",
      "acc for Psat= 0.15920304305984392 \n",
      "acc for optim= 0.1880172946076601\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.006136083509773016\n",
      "Loss on test= 0.00631705392152071\n",
      "acc for Lsat= 0.11285493860515163 \n",
      "acc for Psat= 0.17076476223116294 \n",
      "acc for optim= 0.18375850287329004\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.0062378281727433205\n",
      "Loss on test= 0.0061522843316197395\n",
      "acc for Lsat= 0.10854022039633049 \n",
      "acc for Psat= 0.1819104027353869 \n",
      "acc for optim= 0.1862724694585415\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.00597539683803916\n",
      "Loss on test= 0.0062885042279958725\n",
      "acc for Lsat= 0.11446631877687823 \n",
      "acc for Psat= 0.1573718737313725 \n",
      "acc for optim= 0.1805915833876399\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.006023106165230274\n",
      "Loss on test= 0.0063902935944497585\n",
      "acc for Lsat= 0.11908097388122524 \n",
      "acc for Psat= 0.16246633883251027 \n",
      "acc for optim= 0.18695498518138412\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.006026399787515402\n",
      "Loss on test= 0.006130523979663849\n",
      "acc for Lsat= 0.11657948964902726 \n",
      "acc for Psat= 0.163084933625509 \n",
      "acc for optim= 0.1847651798608068\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.006025643553584814\n",
      "Loss on test= 0.006048473995178938\n",
      "acc for Lsat= 0.10106294950173833 \n",
      "acc for Psat= 0.15809126558046094 \n",
      "acc for optim= 0.18569479355544508\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.006075703538954258\n",
      "Loss on test= 0.0062632085755467415\n",
      "acc for Lsat= 0.12025410926105758 \n",
      "acc for Psat= 0.16236556691276477 \n",
      "acc for optim= 0.18322945227240828\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.006070462521165609\n",
      "Loss on test= 0.00617215596139431\n",
      "acc for Lsat= 0.10411267733624717 \n",
      "acc for Psat= 0.15995246564905855 \n",
      "acc for optim= 0.18582457451545475\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.0060337078757584095\n",
      "Loss on test= 0.006288982927799225\n",
      "acc for Lsat= 0.1092094556410843 \n",
      "acc for Psat= 0.15711049247191702 \n",
      "acc for optim= 0.18944452686338156\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.006136764772236347\n",
      "Loss on test= 0.006336523685604334\n",
      "acc for Lsat= 0.12264179357923756 \n",
      "acc for Psat= 0.1652055975701424 \n",
      "acc for optim= 0.1849596656095339\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.006054057739675045\n",
      "Loss on test= 0.006620176136493683\n",
      "acc for Lsat= 0.10206173923380275 \n",
      "acc for Psat= 0.16597524218456317 \n",
      "acc for optim= 0.1880862221178146\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.006384212523698807\n",
      "Loss on test= 0.006368495523929596\n",
      "acc for Lsat= 0.10390293331678353 \n",
      "acc for Psat= 0.16826665007028094 \n",
      "acc for optim= 0.18492180529535068\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.00601674010977149\n",
      "Loss on test= 0.0064402176067233086\n",
      "acc for Lsat= 0.13255202579848874 \n",
      "acc for Psat= 0.17476512185876836 \n",
      "acc for optim= 0.18496362258706908\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.005934464745223522\n",
      "Loss on test= 0.0062647415325045586\n",
      "acc for Lsat= 0.10747785028183283 \n",
      "acc for Psat= 0.18518097723190785 \n",
      "acc for optim= 0.1843877555630398\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.0061428360641002655\n",
      "Loss on test= 0.006583372596651316\n",
      "acc for Lsat= 0.12640255850301646 \n",
      "acc for Psat= 0.16795619053064492 \n",
      "acc for optim= 0.18432986404651594\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.006034906022250652\n",
      "Loss on test= 0.0061335451900959015\n",
      "acc for Lsat= 0.10626159401962885 \n",
      "acc for Psat= 0.1561586424614762 \n",
      "acc for optim= 0.18559364465869982\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.00588392186909914\n",
      "Loss on test= 0.006195231806486845\n",
      "acc for Lsat= 0.10195106375455931 \n",
      "acc for Psat= 0.16881736780790968 \n",
      "acc for optim= 0.18591908198062368\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.0060532852075994015\n",
      "Loss on test= 0.006180788390338421\n",
      "acc for Lsat= 0.10696263738960575 \n",
      "acc for Psat= 0.1710495354558146 \n",
      "acc for optim= 0.18499197434780276\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.005935054738074541\n",
      "Loss on test= 0.006302830763161182\n",
      "acc for Lsat= 0.10933672943414226 \n",
      "acc for Psat= 0.159805966132218 \n",
      "acc for optim= 0.19018007258725717\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.006083434913307428\n",
      "Loss on test= 0.007001225836575031\n",
      "acc for Lsat= 0.16562875420129639 \n",
      "acc for Psat= 0.17919281738825185 \n",
      "acc for optim= 0.18505346284586563\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.006209712941199541\n",
      "Loss on test= 0.006356050260365009\n",
      "acc for Lsat= 0.10777084758032092 \n",
      "acc for Psat= 0.17253393131761333 \n",
      "acc for optim= 0.1895092566925529\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.00583373848348856\n",
      "Loss on test= 0.006405224092304707\n",
      "acc for Lsat= 0.10836782894993785 \n",
      "acc for Psat= 0.18170240134104215 \n",
      "acc for optim= 0.1907505348844515\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.005910237319767475\n",
      "Loss on test= 0.00636093458160758\n",
      "acc for Lsat= 0.15847533010654277 \n",
      "acc for Psat= 0.1588381915243116 \n",
      "acc for optim= 0.1873735702899491\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.006157306954264641\n",
      "Loss on test= 0.006509034428745508\n",
      "acc for Lsat= 0.11056484432330418 \n",
      "acc for Psat= 0.19165767138917078 \n",
      "acc for optim= 0.18747850640215188\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.0061060101725161076\n",
      "Loss on test= 0.006336360238492489\n",
      "acc for Lsat= 0.10467415830675778 \n",
      "acc for Psat= 0.16162815916263876 \n",
      "acc for optim= 0.18674804974265546\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.005972374230623245\n",
      "Loss on test= 0.006578073371201754\n",
      "acc for Lsat= 0.10966808899696401 \n",
      "acc for Psat= 0.1669644255659502 \n",
      "acc for optim= 0.19086333887094656\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005874212831258774\n",
      "Loss on test= 0.006152025423943996\n",
      "acc for Lsat= 0.11550524702849814 \n",
      "acc for Psat= 0.16014548603689527 \n",
      "acc for optim= 0.18602769906863467\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.005848708096891642\n",
      "Loss on test= 0.006910656113177538\n",
      "acc for Lsat= 0.1326036381529726 \n",
      "acc for Psat= 0.17480377583214668 \n",
      "acc for optim= 0.18879378993045287\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.006098141893744469\n",
      "Loss on test= 0.006125239189714193\n",
      "acc for Lsat= 0.1030223133244805 \n",
      "acc for Psat= 0.16608856773185637 \n",
      "acc for optim= 0.18359056939300136\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.005909265018999577\n",
      "Loss on test= 0.006392969284206629\n",
      "acc for Lsat= 0.11379069736112551 \n",
      "acc for Psat= 0.18667520081126476 \n",
      "acc for optim= 0.18718908238303344\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.005968576297163963\n",
      "Loss on test= 0.006362677086144686\n",
      "acc for Lsat= 0.1427134386746754 \n",
      "acc for Psat= 0.16623204997528307 \n",
      "acc for optim= 0.18687003484022147\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.005896127317100763\n",
      "Loss on test= 0.006293317303061485\n",
      "acc for Lsat= 0.11844680804603519 \n",
      "acc for Psat= 0.18599482533042916 \n",
      "acc for optim= 0.18251683309240066\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.005872704088687897\n",
      "Loss on test= 0.00600920245051384\n",
      "acc for Lsat= 0.10738564797518209 \n",
      "acc for Psat= 0.17117045804764996 \n",
      "acc for optim= 0.18673824419764404\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.005902973935008049\n",
      "Loss on test= 0.006070142611861229\n",
      "acc for Lsat= 0.10195434084921176 \n",
      "acc for Psat= 0.152019694068381 \n",
      "acc for optim= 0.18888863268689052\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.0057884808629751205\n",
      "Loss on test= 0.006027380935847759\n",
      "acc for Lsat= 0.11434808327278399 \n",
      "acc for Psat= 0.16452381639115826 \n",
      "acc for optim= 0.19114760360369817\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.005890064872801304\n",
      "Loss on test= 0.00601085415109992\n",
      "acc for Lsat= 0.10114340827302029 \n",
      "acc for Psat= 0.16309729105941606 \n",
      "acc for optim= 0.18344579030707717\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.005895085167139769\n",
      "Loss on test= 0.006408620625734329\n",
      "acc for Lsat= 0.1040149885898368 \n",
      "acc for Psat= 0.17609916245822427 \n",
      "acc for optim= 0.18740660124643221\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.005854116752743721\n",
      "Loss on test= 0.0062429639510810375\n",
      "acc for Lsat= 0.11021161747850931 \n",
      "acc for Psat= 0.16614278156714282 \n",
      "acc for optim= 0.18793086544718715\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.005980467889457941\n",
      "Loss on test= 0.006282885558903217\n",
      "acc for Lsat= 0.10984143273969027 \n",
      "acc for Psat= 0.18581251439467747 \n",
      "acc for optim= 0.18673037353909347\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.005978698376566172\n",
      "Loss on test= 0.006813187152147293\n",
      "acc for Lsat= 0.1085916912616085 \n",
      "acc for Psat= 0.15618956626024777 \n",
      "acc for optim= 0.1877160472260486\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.00634041428565979\n",
      "Loss on test= 0.00624368479475379\n",
      "acc for Lsat= 0.11483870778681955 \n",
      "acc for Psat= 0.16124879252955096 \n",
      "acc for optim= 0.18674701276806346\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.0059890141710639\n",
      "Loss on test= 0.0062502711080014706\n",
      "acc for Lsat= 0.11033845324316251 \n",
      "acc for Psat= 0.1687391822413554 \n",
      "acc for optim= 0.18997960419474602\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.00583262974396348\n",
      "Loss on test= 0.005974219646304846\n",
      "acc for Lsat= 0.110901316700423 \n",
      "acc for Psat= 0.16437239156869976 \n",
      "acc for optim= 0.18470455068431013\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005983686540275812\n",
      "Loss on test= 0.0066297100856900215\n",
      "acc for Lsat= 0.12240645586609537 \n",
      "acc for Psat= 0.1705067132495822 \n",
      "acc for optim= 0.18740981431049453\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.006068623624742031\n",
      "Loss on test= 0.006023146212100983\n",
      "acc for Lsat= 0.10339857814801075 \n",
      "acc for Psat= 0.1512780676202965 \n",
      "acc for optim= 0.1830807498459959\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.005687635391950607\n",
      "Loss on test= 0.006086059380322695\n",
      "acc for Lsat= 0.1254106130188636 \n",
      "acc for Psat= 0.16438442254454727 \n",
      "acc for optim= 0.18705929941859575\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.005768916103988886\n",
      "Loss on test= 0.006008954718708992\n",
      "acc for Lsat= 0.10977085861314491 \n",
      "acc for Psat= 0.15349064412293956 \n",
      "acc for optim= 0.1859478505247279\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.005846362095326185\n",
      "Loss on test= 0.005969370249658823\n",
      "acc for Lsat= 0.10852124134908081 \n",
      "acc for Psat= 0.1676706320187706 \n",
      "acc for optim= 0.1849357130640537\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.0059705390594899654\n",
      "Loss on test= 0.006013862788677216\n",
      "acc for Lsat= 0.1031808497604829 \n",
      "acc for Psat= 0.15350709701669984 \n",
      "acc for optim= 0.19242161828515236\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.005865939427167177\n",
      "Loss on test= 0.006162645295262337\n",
      "acc for Lsat= 0.10547580395271054 \n",
      "acc for Psat= 0.15476864405453042 \n",
      "acc for optim= 0.18994443870001673\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.005907331593334675\n",
      "Loss on test= 0.005978238303214312\n",
      "acc for Lsat= 0.10143446254961738 \n",
      "acc for Psat= 0.16074719258196293 \n",
      "acc for optim= 0.18860638566626664\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.005651119630783796\n",
      "Loss on test= 0.00620729336515069\n",
      "acc for Lsat= 0.10464912372727003 \n",
      "acc for Psat= 0.1765790903993695 \n",
      "acc for optim= 0.18301064370363648\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.00596535112708807\n",
      "Loss on test= 0.006328245159238577\n",
      "acc for Lsat= 0.1378000756368557 \n",
      "acc for Psat= 0.16856751997068853 \n",
      "acc for optim= 0.18770948710664162\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.0060124751180410385\n",
      "Loss on test= 0.0062395986169576645\n",
      "acc for Lsat= 0.11529650399795689 \n",
      "acc for Psat= 0.18233241778255654 \n",
      "acc for optim= 0.18689328385517\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.0057717966847121716\n",
      "Loss on test= 0.006026554852724075\n",
      "acc for Lsat= 0.10701032070200371 \n",
      "acc for Psat= 0.16272010037229503 \n",
      "acc for optim= 0.18790550999334743\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.005712222773581743\n",
      "Loss on test= 0.006106214132159948\n",
      "acc for Lsat= 0.10431686512507636 \n",
      "acc for Psat= 0.17061966506087237 \n",
      "acc for optim= 0.18630690892038998\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.0060243504121899605\n",
      "Loss on test= 0.0066798897460103035\n",
      "acc for Lsat= 0.12002956118384325 \n",
      "acc for Psat= 0.18954218833518885 \n",
      "acc for optim= 0.18736896642902237\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.005980242975056171\n",
      "Loss on test= 0.00615733303129673\n",
      "acc for Lsat= 0.11517226569926176 \n",
      "acc for Psat= 0.1525315555499637 \n",
      "acc for optim= 0.18604192575416212\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.00588440615683794\n",
      "Loss on test= 0.005962784867733717\n",
      "acc for Lsat= 0.10337932236615342 \n",
      "acc for Psat= 0.1742697669660383 \n",
      "acc for optim= 0.1934042835316693\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.00568670267239213\n",
      "Loss on test= 0.0061335996724665165\n",
      "acc for Lsat= 0.11254979426643934 \n",
      "acc for Psat= 0.14504768717184513 \n",
      "acc for optim= 0.18756682789338613\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.006031474564224482\n",
      "Loss on test= 0.00632032286375761\n",
      "acc for Lsat= 0.11613782943616546 \n",
      "acc for Psat= 0.1777748202945765 \n",
      "acc for optim= 0.18464928699103364\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.005906108766794205\n",
      "Loss on test= 0.006104234606027603\n",
      "acc for Lsat= 0.12155403981582699 \n",
      "acc for Psat= 0.1574981184011621 \n",
      "acc for optim= 0.1815769766936019\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.005779505241662264\n",
      "Loss on test= 0.005920956842601299\n",
      "acc for Lsat= 0.10562418346927262 \n",
      "acc for Psat= 0.1552653792223282 \n",
      "acc for optim= 0.18459576612174813\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.005687430500984192\n",
      "Loss on test= 0.005892693065106869\n",
      "acc for Lsat= 0.10130601256620335 \n",
      "acc for Psat= 0.15594885632157998 \n",
      "acc for optim= 0.18564990270926893\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.005937822163105011\n",
      "Loss on test= 0.005995647981762886\n",
      "acc for Lsat= 0.1021991156375333 \n",
      "acc for Psat= 0.15849806205369532 \n",
      "acc for optim= 0.1865815094222214\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.005681689828634262\n",
      "Loss on test= 0.006172369234263897\n",
      "acc for Lsat= 0.10333900074958266 \n",
      "acc for Psat= 0.17245908927686066 \n",
      "acc for optim= 0.18777333206899866\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.005984347313642502\n",
      "Loss on test= 0.006170184817165136\n",
      "acc for Lsat= 0.13307037837414 \n",
      "acc for Psat= 0.1533715698131198 \n",
      "acc for optim= 0.18649501195712317\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005858537275344133\n",
      "Loss on test= 0.006404751446098089\n",
      "acc for Lsat= 0.11345499079868966 \n",
      "acc for Psat= 0.19430332756835283 \n",
      "acc for optim= 0.18564851504256571\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.005825744476169348\n",
      "Loss on test= 0.006289349403232336\n",
      "acc for Lsat= 0.13775809774968464 \n",
      "acc for Psat= 0.15832041334274313 \n",
      "acc for optim= 0.19046075429906598\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.005764821078628302\n",
      "Loss on test= 0.006119723431766033\n",
      "acc for Lsat= 0.10412132877909981 \n",
      "acc for Psat= 0.1582097256106027 \n",
      "acc for optim= 0.1863372220402714\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.005753343924880028\n",
      "Loss on test= 0.006728523410856724\n",
      "acc for Lsat= 0.10499303619596774 \n",
      "acc for Psat= 0.16547022625407506 \n",
      "acc for optim= 0.18818577555489233\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.005722825415432453\n",
      "Loss on test= 0.006146584637463093\n",
      "acc for Lsat= 0.10319580871795109 \n",
      "acc for Psat= 0.1572428760953674 \n",
      "acc for optim= 0.18529689908393412\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.005694080144166946\n",
      "Loss on test= 0.00618580961599946\n",
      "acc for Lsat= 0.10201962011158046 \n",
      "acc for Psat= 0.17445676120916834 \n",
      "acc for optim= 0.18613738558889129\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.005749606527388096\n",
      "Loss on test= 0.006356666795909405\n",
      "acc for Lsat= 0.11142928541183308 \n",
      "acc for Psat= 0.1678383262997896 \n",
      "acc for optim= 0.18630860813238934\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.005836131516844034\n",
      "Loss on test= 0.005811245646327734\n",
      "acc for Lsat= 0.10608957717969944 \n",
      "acc for Psat= 0.16210866577426172 \n",
      "acc for optim= 0.18415625402516328\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.0057226261124014854\n",
      "Loss on test= 0.005848022643476725\n",
      "acc for Lsat= 0.11190251076776483 \n",
      "acc for Psat= 0.15543277529965005 \n",
      "acc for optim= 0.18144396735658883\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.0059107509441673756\n",
      "Loss on test= 0.00606851140037179\n",
      "acc for Lsat= 0.1011271894507494 \n",
      "acc for Psat= 0.15225591147011713 \n",
      "acc for optim= 0.19081287840664438\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.0058800526894629\n",
      "Loss on test= 0.006005496717989445\n",
      "acc for Lsat= 0.1099245386722032 \n",
      "acc for Psat= 0.15201666896310242 \n",
      "acc for optim= 0.18832082508418574\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.005693202838301659\n",
      "Loss on test= 0.006079399026930332\n",
      "acc for Lsat= 0.11822869502115331 \n",
      "acc for Psat= 0.15203095741934383 \n",
      "acc for optim= 0.18557046521252502\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.005621280521154404\n",
      "Loss on test= 0.006356110796332359\n",
      "acc for Lsat= 0.10919925829241676 \n",
      "acc for Psat= 0.17052478182941322 \n",
      "acc for optim= 0.18516201705623078\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.0059007564559578896\n",
      "Loss on test= 0.00617612898349762\n",
      "acc for Lsat= 0.1225814079958041 \n",
      "acc for Psat= 0.16675541387136233 \n",
      "acc for optim= 0.1865209421105376\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.0059668379835784435\n",
      "Loss on test= 0.0061417524702847\n",
      "acc for Lsat= 0.10652645514209005 \n",
      "acc for Psat= 0.1850605834801713 \n",
      "acc for optim= 0.18696092096836986\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.00569910928606987\n",
      "Loss on test= 0.00624121492728591\n",
      "acc for Lsat= 0.10578965613338467 \n",
      "acc for Psat= 0.17112893963720224 \n",
      "acc for optim= 0.1978533662437946\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.005813139490783215\n",
      "Loss on test= 0.00624050060287118\n",
      "acc for Lsat= 0.1158021565422894 \n",
      "acc for Psat= 0.16349985429858221 \n",
      "acc for optim= 0.18536581681857225\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.0058106048963963985\n",
      "Loss on test= 0.00622894149273634\n",
      "acc for Lsat= 0.130880564372362 \n",
      "acc for Psat= 0.15627054396326137 \n",
      "acc for optim= 0.18567836907213614\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.00600319541990757\n",
      "Loss on test= 0.006423246115446091\n",
      "acc for Lsat= 0.11121893118196739 \n",
      "acc for Psat= 0.18074239944050802 \n",
      "acc for optim= 0.1959210237677129\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.005626097787171602\n",
      "Loss on test= 0.005923647433519363\n",
      "acc for Lsat= 0.11455542915850733 \n",
      "acc for Psat= 0.15619944573385558 \n",
      "acc for optim= 0.192477784852255\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.005713301710784435\n",
      "Loss on test= 0.0061233388260006905\n",
      "acc for Lsat= 0.10258026724103901 \n",
      "acc for Psat= 0.16314240649257586 \n",
      "acc for optim= 0.18718844603250004\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.005784862674772739\n",
      "Loss on test= 0.00616655545309186\n",
      "acc for Lsat= 0.10540766085830762 \n",
      "acc for Psat= 0.1634819289479433 \n",
      "acc for optim= 0.19290828637703444\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.005792985670268536\n",
      "Loss on test= 0.005951841361820698\n",
      "acc for Lsat= 0.11064154403715834 \n",
      "acc for Psat= 0.15313361228261882 \n",
      "acc for optim= 0.18783773429183653\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.005904284305870533\n",
      "Loss on test= 0.005873079877346754\n",
      "acc for Lsat= 0.11206708695602641 \n",
      "acc for Psat= 0.15234668496536008 \n",
      "acc for optim= 0.186110985607401\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.0057450770400464535\n",
      "Loss on test= 0.00638154661282897\n",
      "acc for Lsat= 0.10606929336122325 \n",
      "acc for Psat= 0.17900082016205635 \n",
      "acc for optim= 0.18598187123024143\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.005948517005890608\n",
      "Loss on test= 0.0061337933875620365\n",
      "acc for Lsat= 0.10420613291402382 \n",
      "acc for Psat= 0.15823671877690168 \n",
      "acc for optim= 0.1846046236137595\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.005806154105812311\n",
      "Loss on test= 0.0060101342387497425\n",
      "acc for Lsat= 0.10069416646542409 \n",
      "acc for Psat= 0.16202828053477836 \n",
      "acc for optim= 0.18691539782417207\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.005548056215047836\n",
      "Loss on test= 0.006328993942588568\n",
      "acc for Lsat= 0.10880989935857714 \n",
      "acc for Psat= 0.1597357336549976 \n",
      "acc for optim= 0.18877077747959914\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.0056032901629805565\n",
      "Loss on test= 0.00589437410235405\n",
      "acc for Lsat= 0.10137767208977272 \n",
      "acc for Psat= 0.15065211874300716 \n",
      "acc for optim= 0.18463503102484047\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.0056482465006411076\n",
      "Loss on test= 0.005864533595740795\n",
      "acc for Lsat= 0.09263811428639668 \n",
      "acc for Psat= 0.15188150605536066 \n",
      "acc for optim= 0.18504054552239896\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.005586215760558844\n",
      "Loss on test= 0.006037954706698656\n",
      "acc for Lsat= 0.10651930453192059 \n",
      "acc for Psat= 0.1647529284763968 \n",
      "acc for optim= 0.18646826267964522\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005674300715327263\n",
      "Loss on test= 0.0063439616933465\n",
      "acc for Lsat= 0.12161871749786597 \n",
      "acc for Psat= 0.164168683198482 \n",
      "acc for optim= 0.18551304823100706\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.005855913273990154\n",
      "Loss on test= 0.0064721186645329\n",
      "acc for Lsat= 0.14183992888020175 \n",
      "acc for Psat= 0.16138539444369057 \n",
      "acc for optim= 0.1854240167791628\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005769427865743637\n",
      "Loss on test= 0.00591596495360136\n",
      "acc for Lsat= 0.10292074624949482 \n",
      "acc for Psat= 0.17026695529214497 \n",
      "acc for optim= 0.18573616685805333\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.0057109566405415535\n",
      "Loss on test= 0.0058181448839604855\n",
      "acc for Lsat= 0.09913097729853738 \n",
      "acc for Psat= 0.1488080555470849 \n",
      "acc for optim= 0.18675991003102674\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.0056835962459445\n",
      "Loss on test= 0.006129704415798187\n",
      "acc for Lsat= 0.11865165766234773 \n",
      "acc for Psat= 0.18319471949856764 \n",
      "acc for optim= 0.1887600125282424\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.005858339834958315\n",
      "Loss on test= 0.00603648042306304\n",
      "acc for Lsat= 0.1136334044410457 \n",
      "acc for Psat= 0.16354057272901873 \n",
      "acc for optim= 0.1840848723895269\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.005786367226392031\n",
      "Loss on test= 0.00631363969296217\n",
      "acc for Lsat= 0.10583888622548673 \n",
      "acc for Psat= 0.16241101617039955 \n",
      "acc for optim= 0.1994435912960939\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.005633939057588577\n",
      "Loss on test= 0.005907774902880192\n",
      "acc for Lsat= 0.10577624523835225 \n",
      "acc for Psat= 0.15340038505173897 \n",
      "acc for optim= 0.19122096039112924\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.0057175070978701115\n",
      "Loss on test= 0.006122434511780739\n",
      "acc for Lsat= 0.11389240778697894 \n",
      "acc for Psat= 0.15785405197144625 \n",
      "acc for optim= 0.18422178527485025\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005607176572084427\n",
      "Loss on test= 0.00616157753393054\n",
      "acc for Lsat= 0.12454377300762005 \n",
      "acc for Psat= 0.15448443872859619 \n",
      "acc for optim= 0.1863788565811479\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.005664716009050608\n",
      "Loss on test= 0.006080709397792816\n",
      "acc for Lsat= 0.1203174548217912 \n",
      "acc for Psat= 0.15272995712714604 \n",
      "acc for optim= 0.18459373552802907\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.005966877564787865\n",
      "Loss on test= 0.005995066370815039\n",
      "acc for Lsat= 0.10193875595585858 \n",
      "acc for Psat= 0.16186861188320156 \n",
      "acc for optim= 0.19102393795578423\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.00574875995516777\n",
      "Loss on test= 0.0058675287291407585\n",
      "acc for Lsat= 0.11478606860359955 \n",
      "acc for Psat= 0.15741958931982014 \n",
      "acc for optim= 0.18512202857370563\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.005601609591394663\n",
      "Loss on test= 0.0059258220717310905\n",
      "acc for Lsat= 0.10772264105720308 \n",
      "acc for Psat= 0.15285548724598294 \n",
      "acc for optim= 0.1833421501765229\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.005621005780994892\n",
      "Loss on test= 0.00621033925563097\n",
      "acc for Lsat= 0.10033411286319795 \n",
      "acc for Psat= 0.15929396942531615 \n",
      "acc for optim= 0.18491362561709704\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.005542001221328974\n",
      "Loss on test= 0.006044318433851004\n",
      "acc for Lsat= 0.09828823629367114 \n",
      "acc for Psat= 0.16075064037825024 \n",
      "acc for optim= 0.18361577012409405\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.005730077158659697\n",
      "Loss on test= 0.0057899379171431065\n",
      "acc for Lsat= 0.10303501307660898 \n",
      "acc for Psat= 0.14807590729105868 \n",
      "acc for optim= 0.18998898761158153\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.005590441636741161\n",
      "Loss on test= 0.006171156652271748\n",
      "acc for Lsat= 0.10644390316864136 \n",
      "acc for Psat= 0.16216131565739192 \n",
      "acc for optim= 0.18687459319630148\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005638055503368378\n",
      "Loss on test= 0.005959546659141779\n",
      "acc for Lsat= 0.12291916949706737 \n",
      "acc for Psat= 0.15433568809414674 \n",
      "acc for optim= 0.18536902910391045\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.0056757852435112\n",
      "Loss on test= 0.00576858501881361\n",
      "acc for Lsat= 0.11313695247470704 \n",
      "acc for Psat= 0.1685840327309789 \n",
      "acc for optim= 0.19147385241356804\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.005532461684197187\n",
      "Loss on test= 0.005921989679336548\n",
      "acc for Lsat= 0.10448513998995328 \n",
      "acc for Psat= 0.16752931734899412 \n",
      "acc for optim= 0.18721641128807254\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.005727788433432579\n",
      "Loss on test= 0.006168290041387081\n",
      "acc for Lsat= 0.10425345936931302 \n",
      "acc for Psat= 0.1579578052840441 \n",
      "acc for optim= 0.19283894734473653\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.0058445087634027\n",
      "Loss on test= 0.005992029327899218\n",
      "acc for Lsat= 0.10721257699628335 \n",
      "acc for Psat= 0.15120653757735822 \n",
      "acc for optim= 0.19135933402090766\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.005725780501961708\n",
      "Loss on test= 0.006551045458763838\n",
      "acc for Lsat= 0.11985637556652953 \n",
      "acc for Psat= 0.1680041816588208 \n",
      "acc for optim= 0.1855296155349729\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.005660012364387512\n",
      "Loss on test= 0.006067773327231407\n",
      "acc for Lsat= 0.11494928558513985 \n",
      "acc for Psat= 0.1624970449122122 \n",
      "acc for optim= 0.1815794914104658\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.005666828248649836\n",
      "Loss on test= 0.006318859290331602\n",
      "acc for Lsat= 0.10222334535304785 \n",
      "acc for Psat= 0.15375774043696164 \n",
      "acc for optim= 0.18435783295579902\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.005635859910398722\n",
      "Loss on test= 0.00591333769261837\n",
      "acc for Lsat= 0.12006935001404231 \n",
      "acc for Psat= 0.15284123365406255 \n",
      "acc for optim= 0.1885250911912629\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.005745202302932739\n",
      "Loss on test= 0.0059951916337013245\n",
      "acc for Lsat= 0.09793257163570111 \n",
      "acc for Psat= 0.14956820051706066 \n",
      "acc for optim= 0.19087125836223415\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.005458706524223089\n",
      "Loss on test= 0.006057477556169033\n",
      "acc for Lsat= 0.1072694858304031 \n",
      "acc for Psat= 0.1472140414963989 \n",
      "acc for optim= 0.1873976336752782\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.005689600482583046\n",
      "Loss on test= 0.005990668665617704\n",
      "acc for Lsat= 0.09990055462303399 \n",
      "acc for Psat= 0.16282721872502826 \n",
      "acc for optim= 0.18653003048274439\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.005465590860694647\n",
      "Loss on test= 0.005978597793728113\n",
      "acc for Lsat= 0.1115705058683808 \n",
      "acc for Psat= 0.15332576296940395 \n",
      "acc for optim= 0.18530906886312673\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.0056920358911156654\n",
      "Loss on test= 0.00599250290542841\n",
      "acc for Lsat= 0.1013561786786414 \n",
      "acc for Psat= 0.14320792403816232 \n",
      "acc for optim= 0.19309048165254156\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.00563773512840271\n",
      "Loss on test= 0.005981176160275936\n",
      "acc for Lsat= 0.1077258798228974 \n",
      "acc for Psat= 0.15121364567253417 \n",
      "acc for optim= 0.19040426935798432\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.00577656039968133\n",
      "Loss on test= 0.005973735358566046\n",
      "acc for Lsat= 0.11279877196913632 \n",
      "acc for Psat= 0.148005885543859 \n",
      "acc for optim= 0.19074283691234822\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.005592357832938433\n",
      "Loss on test= 0.0061147138476371765\n",
      "acc for Lsat= 0.10810685826613367 \n",
      "acc for Psat= 0.15340466155927013 \n",
      "acc for optim= 0.18564157483696536\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.005581734236329794\n",
      "Loss on test= 0.005852444563060999\n",
      "acc for Lsat= 0.10686549999543885 \n",
      "acc for Psat= 0.16870802106579405 \n",
      "acc for optim= 0.19026741974143865\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.005614962428808212\n",
      "Loss on test= 0.00597925903275609\n",
      "acc for Lsat= 0.10261099878639593 \n",
      "acc for Psat= 0.1530148557283831 \n",
      "acc for optim= 0.1909008140834418\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005703001748770475\n",
      "Loss on test= 0.006399346515536308\n",
      "acc for Lsat= 0.12245970429668543 \n",
      "acc for Psat= 0.15315781533914757 \n",
      "acc for optim= 0.18448990556820766\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.0057328613474965096\n",
      "Loss on test= 0.00583423487842083\n",
      "acc for Lsat= 0.10657672118562718 \n",
      "acc for Psat= 0.16548002889966656 \n",
      "acc for optim= 0.18305348645741548\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.00574187096208334\n",
      "Loss on test= 0.0063181654550135136\n",
      "acc for Lsat= 0.1308744688919703 \n",
      "acc for Psat= 0.14932762174174893 \n",
      "acc for optim= 0.18359464655581226\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.005795272998511791\n",
      "Loss on test= 0.0064500183798372746\n",
      "acc for Lsat= 0.11018878510632832 \n",
      "acc for Psat= 0.18667850254329293 \n",
      "acc for optim= 0.19015281703085182\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.005781594663858414\n",
      "Loss on test= 0.005985495168715715\n",
      "acc for Lsat= 0.12035377566627249 \n",
      "acc for Psat= 0.14437764522035895 \n",
      "acc for optim= 0.18677110544711076\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.005734746344387531\n",
      "Loss on test= 0.005814890377223492\n",
      "acc for Lsat= 0.10654728532001566 \n",
      "acc for Psat= 0.15180372813051077 \n",
      "acc for optim= 0.1843823876603425\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.0054968479089438915\n",
      "Loss on test= 0.006276863161474466\n",
      "acc for Lsat= 0.13028924221519422 \n",
      "acc for Psat= 0.1608088344928055 \n",
      "acc for optim= 0.18651322585473945\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.005590401589870453\n",
      "Loss on test= 0.006016926374286413\n",
      "acc for Lsat= 0.09535433723304451 \n",
      "acc for Psat= 0.15681526275836183 \n",
      "acc for optim= 0.18897177252920055\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.005571163259446621\n",
      "Loss on test= 0.005903019104152918\n",
      "acc for Lsat= 0.0958069618792325 \n",
      "acc for Psat= 0.1435381415708588 \n",
      "acc for optim= 0.18128526132696188\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.005382994189858437\n",
      "Loss on test= 0.005926339887082577\n",
      "acc for Lsat= 0.10220180530396229 \n",
      "acc for Psat= 0.14683137661607337 \n",
      "acc for optim= 0.18436553371842868\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.005475665908306837\n",
      "Loss on test= 0.005808097310364246\n",
      "acc for Lsat= 0.0994325351861138 \n",
      "acc for Psat= 0.15953391348355925 \n",
      "acc for optim= 0.18919693164659562\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.00564167182892561\n",
      "Loss on test= 0.00642711715772748\n",
      "acc for Lsat= 0.11736795073222704 \n",
      "acc for Psat= 0.18953111196389874 \n",
      "acc for optim= 0.187606862843028\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.005936896428465843\n",
      "Loss on test= 0.006179444026201963\n",
      "acc for Lsat= 0.12602196300517912 \n",
      "acc for Psat= 0.14929477998501514 \n",
      "acc for optim= 0.18828127523679664\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005795338656753302\n",
      "Loss on test= 0.005793415009975433\n",
      "acc for Lsat= 0.09825890897490033 \n",
      "acc for Psat= 0.16699742455730793 \n",
      "acc for optim= 0.18783614661741602\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.005605075508356094\n",
      "Loss on test= 0.005864595528692007\n",
      "acc for Lsat= 0.10475873223765882 \n",
      "acc for Psat= 0.14711345484239566 \n",
      "acc for optim= 0.18833295456579435\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.005787882953882217\n",
      "Loss on test= 0.006095580756664276\n",
      "acc for Lsat= 0.11040529693288614 \n",
      "acc for Psat= 0.15520954311894555 \n",
      "acc for optim= 0.18271154896541014\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.005746362265199423\n",
      "Loss on test= 0.006171075161546469\n",
      "acc for Lsat= 0.1098712941950637 \n",
      "acc for Psat= 0.15345212155473228 \n",
      "acc for optim= 0.1841283901309256\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.005559890531003475\n",
      "Loss on test= 0.006089953240007162\n",
      "acc for Lsat= 0.10250789670602456 \n",
      "acc for Psat= 0.15602944168467361 \n",
      "acc for optim= 0.19582948381434404\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.005640182178467512\n",
      "Loss on test= 0.006080791354179382\n",
      "acc for Lsat= 0.10177669693704858 \n",
      "acc for Psat= 0.15866204976486484 \n",
      "acc for optim= 0.18340756001526717\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.005774551536887884\n",
      "Loss on test= 0.006062834057956934\n",
      "acc for Lsat= 0.13678733165024087 \n",
      "acc for Psat= 0.1547967984416401 \n",
      "acc for optim= 0.18651572889506793\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.0058002592995762825\n",
      "Loss on test= 0.005790233612060547\n",
      "acc for Lsat= 0.10349350540412627 \n",
      "acc for Psat= 0.14815163135810164 \n",
      "acc for optim= 0.19222747459254017\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.005510182585567236\n",
      "Loss on test= 0.006149199791252613\n",
      "acc for Lsat= 0.10381410483996906 \n",
      "acc for Psat= 0.15964744845188908 \n",
      "acc for optim= 0.18625116708721476\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.005515206139534712\n",
      "Loss on test= 0.00583621533587575\n",
      "acc for Lsat= 0.11780455788283616 \n",
      "acc for Psat= 0.1553649510924761 \n",
      "acc for optim= 0.184228890177454\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.005610144231468439\n",
      "Loss on test= 0.006097097881138325\n",
      "acc for Lsat= 0.09634665208028997 \n",
      "acc for Psat= 0.15334941091267054 \n",
      "acc for optim= 0.18713451964435376\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.005574999842792749\n",
      "Loss on test= 0.0058724964037537575\n",
      "acc for Lsat= 0.09745809334905257 \n",
      "acc for Psat= 0.16291302773272429 \n",
      "acc for optim= 0.18830333665018034\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.0055714561603963375\n",
      "Loss on test= 0.005958933383226395\n",
      "acc for Lsat= 0.09395867843631636 \n",
      "acc for Psat= 0.15701272527041657 \n",
      "acc for optim= 0.18820340889647627\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.005544330924749374\n",
      "Loss on test= 0.005967178847640753\n",
      "acc for Lsat= 0.1145954763198608 \n",
      "acc for Psat= 0.15865237777745425 \n",
      "acc for optim= 0.1856167689378757\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005456933286041021\n",
      "Loss on test= 0.0056689721532166\n",
      "acc for Lsat= 0.10842211155205725 \n",
      "acc for Psat= 0.15490610490697027 \n",
      "acc for optim= 0.1862247215847035\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.005538435652852058\n",
      "Loss on test= 0.005729447118937969\n",
      "acc for Lsat= 0.09677296902717333 \n",
      "acc for Psat= 0.143035412968193 \n",
      "acc for optim= 0.1868367318911132\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.005286042578518391\n",
      "Loss on test= 0.006046931259334087\n",
      "acc for Lsat= 0.10098083818082011 \n",
      "acc for Psat= 0.15591640172636756 \n",
      "acc for optim= 0.18696256111158888\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005581807345151901\n",
      "Loss on test= 0.0058348411694169044\n",
      "acc for Lsat= 0.09418904689462923 \n",
      "acc for Psat= 0.1525778070237622 \n",
      "acc for optim= 0.1889188371239249\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005697465036064386\n",
      "Loss on test= 0.006108230445533991\n",
      "acc for Lsat= 0.11363089438197455 \n",
      "acc for Psat= 0.1811964559723234 \n",
      "acc for optim= 0.1881220536577874\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.005762061569839716\n",
      "Loss on test= 0.006254757754504681\n",
      "acc for Lsat= 0.1286379184029765 \n",
      "acc for Psat= 0.15121477679949258 \n",
      "acc for optim= 0.18503773361845635\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.005920207593590021\n",
      "Loss on test= 0.005830629728734493\n",
      "acc for Lsat= 0.10305339420203283 \n",
      "acc for Psat= 0.15155854019011147 \n",
      "acc for optim= 0.1853975824822162\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.005476354155689478\n",
      "Loss on test= 0.00577960442751646\n",
      "acc for Lsat= 0.10373518043933153 \n",
      "acc for Psat= 0.16137922667316948 \n",
      "acc for optim= 0.184596470922131\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.0055934651754796505\n",
      "Loss on test= 0.005871481262147427\n",
      "acc for Lsat= 0.10111826871277141 \n",
      "acc for Psat= 0.1332424698446974 \n",
      "acc for optim= 0.19497379060634853\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.005559887737035751\n",
      "Loss on test= 0.006326527334749699\n",
      "acc for Lsat= 0.1251934707240277 \n",
      "acc for Psat= 0.1692520893242594 \n",
      "acc for optim= 0.1857719461459547\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005591575056314468\n",
      "Loss on test= 0.0058481330052018166\n",
      "acc for Lsat= 0.09450568629826366 \n",
      "acc for Psat= 0.14804101445573709 \n",
      "acc for optim= 0.18286532962323493\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.005735965445637703\n",
      "Loss on test= 0.005989456549286842\n",
      "acc for Lsat= 0.09600395340365483 \n",
      "acc for Psat= 0.17023523490639195 \n",
      "acc for optim= 0.18929671444700058\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.005624700803309679\n",
      "Loss on test= 0.005969031248241663\n",
      "acc for Lsat= 0.10383431348895396 \n",
      "acc for Psat= 0.15085591990724867 \n",
      "acc for optim= 0.19042782329287966\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.005391941871494055\n",
      "Loss on test= 0.005732284393161535\n",
      "acc for Lsat= 0.09484386500650692 \n",
      "acc for Psat= 0.14443464704640052 \n",
      "acc for optim= 0.18699177975832829\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.005489608738571405\n",
      "Loss on test= 0.005578523501753807\n",
      "acc for Lsat= 0.09695270585487722 \n",
      "acc for Psat= 0.14817669880151674 \n",
      "acc for optim= 0.18466840976809082\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.005526237655431032\n",
      "Loss on test= 0.005927125923335552\n",
      "acc for Lsat= 0.11498916003187627 \n",
      "acc for Psat= 0.15148858416934083 \n",
      "acc for optim= 0.18515209595863927\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.005456479266285896\n",
      "Loss on test= 0.005862113554030657\n",
      "acc for Lsat= 0.10303113019255909 \n",
      "acc for Psat= 0.15103935236156513 \n",
      "acc for optim= 0.18936291087388904\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.005595969036221504\n",
      "Loss on test= 0.006075345911085606\n",
      "acc for Lsat= 0.10045844460064718 \n",
      "acc for Psat= 0.14289188704436595 \n",
      "acc for optim= 0.18587055142632233\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.005549203604459763\n",
      "Loss on test= 0.005723814480006695\n",
      "acc for Lsat= 0.09903290001465073 \n",
      "acc for Psat= 0.14757921115469308 \n",
      "acc for optim= 0.18691268803101863\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.0056655071675777435\n",
      "Loss on test= 0.006073006894439459\n",
      "acc for Lsat= 0.126324450675826 \n",
      "acc for Psat= 0.14211392426207298 \n",
      "acc for optim= 0.18831134233639474\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.005479242652654648\n",
      "Loss on test= 0.00606199074536562\n",
      "acc for Lsat= 0.09775957725909197 \n",
      "acc for Psat= 0.1666084577202029 \n",
      "acc for optim= 0.1870719532647903\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.005466619040817022\n",
      "Loss on test= 0.0059745353646576405\n",
      "acc for Lsat= 0.11869183758480593 \n",
      "acc for Psat= 0.13988687177324383 \n",
      "acc for optim= 0.18261293362986572\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.005618799477815628\n",
      "Loss on test= 0.006088661961257458\n",
      "acc for Lsat= 0.10403971909506032 \n",
      "acc for Psat= 0.15137329171891514 \n",
      "acc for optim= 0.18694335498293727\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.00568753108382225\n",
      "Loss on test= 0.005924766883254051\n",
      "acc for Lsat= 0.12059737925134155 \n",
      "acc for Psat= 0.14898528914754688 \n",
      "acc for optim= 0.1922098734952227\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.005599514581263065\n",
      "Loss on test= 0.006158881820738316\n",
      "acc for Lsat= 0.11093857927728488 \n",
      "acc for Psat= 0.19180884673846163 \n",
      "acc for optim= 0.1902274221884491\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.005532459821552038\n",
      "Loss on test= 0.005811888258904219\n",
      "acc for Lsat= 0.12341326548807588 \n",
      "acc for Psat= 0.15088844873062535 \n",
      "acc for optim= 0.18606712074786727\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005480752792209387\n",
      "Loss on test= 0.005769417155534029\n",
      "acc for Lsat= 0.10476060701625396 \n",
      "acc for Psat= 0.1423835377098766 \n",
      "acc for optim= 0.1898291408655422\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.00554609065875411\n",
      "Loss on test= 0.006005657836794853\n",
      "acc for Lsat= 0.10296677161366805 \n",
      "acc for Psat= 0.1357739857327967 \n",
      "acc for optim= 0.18487836052033368\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.005463022273033857\n",
      "Loss on test= 0.005830178502947092\n",
      "acc for Lsat= 0.09576285258041221 \n",
      "acc for Psat= 0.157847352366524 \n",
      "acc for optim= 0.18644538226087476\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.005475921090692282\n",
      "Loss on test= 0.005924304015934467\n",
      "acc for Lsat= 0.10271405569919562 \n",
      "acc for Psat= 0.15617232561910627 \n",
      "acc for optim= 0.18669449318219228\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.005451363045722246\n",
      "Loss on test= 0.0054250117391347885\n",
      "acc for Lsat= 0.09023196708605266 \n",
      "acc for Psat= 0.15093194344682603 \n",
      "acc for optim= 0.18960817795192958\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.005514024756848812\n",
      "Loss on test= 0.005787222646176815\n",
      "acc for Lsat= 0.10027184481834804 \n",
      "acc for Psat= 0.14874164485671507 \n",
      "acc for optim= 0.18387412403574893\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.0053382860496640205\n",
      "Loss on test= 0.006004427559673786\n",
      "acc for Lsat= 0.09404138850948436 \n",
      "acc for Psat= 0.14198517207055497 \n",
      "acc for optim= 0.1854876479725086\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.00538297276943922\n",
      "Loss on test= 0.006394388619810343\n",
      "acc for Lsat= 0.12178930773645973 \n",
      "acc for Psat= 0.14550982889227884 \n",
      "acc for optim= 0.18339390371064027\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.005659615620970726\n",
      "Loss on test= 0.00621522543951869\n",
      "acc for Lsat= 0.10966136276791175 \n",
      "acc for Psat= 0.20114165032675765 \n",
      "acc for optim= 0.18213823263028422\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.005584536585956812\n",
      "Loss on test= 0.005907601676881313\n",
      "acc for Lsat= 0.0933987742122357 \n",
      "acc for Psat= 0.13976350023340028 \n",
      "acc for optim= 0.184447900670568\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.005443855654448271\n",
      "Loss on test= 0.005577875766903162\n",
      "acc for Lsat= 0.10080867463895439 \n",
      "acc for Psat= 0.14748963578195134 \n",
      "acc for optim= 0.18356565491853258\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.005466136150062084\n",
      "Loss on test= 0.005884830374270678\n",
      "acc for Lsat= 0.10390007639747441 \n",
      "acc for Psat= 0.1489887219056097 \n",
      "acc for optim= 0.18317792178296824\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.005426851101219654\n",
      "Loss on test= 0.005842030514031649\n",
      "acc for Lsat= 0.10767411571998457 \n",
      "acc for Psat= 0.1552269804996212 \n",
      "acc for optim= 0.18400442512319312\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.005439253989607096\n",
      "Loss on test= 0.005529177375137806\n",
      "acc for Lsat= 0.09789821209631407 \n",
      "acc for Psat= 0.15181758100673481 \n",
      "acc for optim= 0.18081916866022102\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.00536393653601408\n",
      "Loss on test= 0.005996921565383673\n",
      "acc for Lsat= 0.09341257946782108 \n",
      "acc for Psat= 0.15612258293156236 \n",
      "acc for optim= 0.18656648282961436\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.005374421831220388\n",
      "Loss on test= 0.005605562124401331\n",
      "acc for Lsat= 0.09509358163867963 \n",
      "acc for Psat= 0.1480590906383539 \n",
      "acc for optim= 0.18898459200578588\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.005448598880320787\n",
      "Loss on test= 0.005948537029325962\n",
      "acc for Lsat= 0.09737506248269268 \n",
      "acc for Psat= 0.1453387049157361 \n",
      "acc for optim= 0.18599769581861264\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.005421431735157967\n",
      "Loss on test= 0.005930265877395868\n",
      "acc for Lsat= 0.11043446332257952 \n",
      "acc for Psat= 0.14234076021121173 \n",
      "acc for optim= 0.1853537322674399\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.0054784235544502735\n",
      "Loss on test= 0.0058210170827806\n",
      "acc for Lsat= 0.11745480958248859 \n",
      "acc for Psat= 0.1363119909258023 \n",
      "acc for optim= 0.18991171584521244\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.005776602774858475\n",
      "Loss on test= 0.005556806921958923\n",
      "acc for Lsat= 0.09025067605314788 \n",
      "acc for Psat= 0.15828735144679887 \n",
      "acc for optim= 0.18852969660145244\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.005374924745410681\n",
      "Loss on test= 0.005784748122096062\n",
      "acc for Lsat= 0.09727661751507234 \n",
      "acc for Psat= 0.1526614777298213 \n",
      "acc for optim= 0.18551509950211276\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.005300557240843773\n",
      "Loss on test= 0.0059079574421048164\n",
      "acc for Lsat= 0.10076719731542604 \n",
      "acc for Psat= 0.15490945831383263 \n",
      "acc for optim= 0.18525016140523115\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005621513817459345\n",
      "Loss on test= 0.006075018551200628\n",
      "acc for Lsat= 0.10351986287836602 \n",
      "acc for Psat= 0.1548882027139346 \n",
      "acc for optim= 0.1848511053439988\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.005455465521663427\n",
      "Loss on test= 0.005770660936832428\n",
      "acc for Lsat= 0.10116572434959085 \n",
      "acc for Psat= 0.1467864384105048 \n",
      "acc for optim= 0.18737434783307017\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.005570503883063793\n",
      "Loss on test= 0.006207256577908993\n",
      "acc for Lsat= 0.10660815327262115 \n",
      "acc for Psat= 0.14777576147458307 \n",
      "acc for optim= 0.1868933424253506\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.0055427514016628265\n",
      "Loss on test= 0.006118627730756998\n",
      "acc for Lsat= 0.09789778604121042 \n",
      "acc for Psat= 0.14471210498988904 \n",
      "acc for optim= 0.18596169342148444\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.005493760574609041\n",
      "Loss on test= 0.00593165960162878\n",
      "acc for Lsat= 0.09936068523352701 \n",
      "acc for Psat= 0.14619295558264098 \n",
      "acc for optim= 0.1848832250426632\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.005275818053632975\n",
      "Loss on test= 0.005768201779574156\n",
      "acc for Lsat= 0.10562637882075915 \n",
      "acc for Psat= 0.14188075736023462 \n",
      "acc for optim= 0.18338218126823572\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.0054536075331270695\n",
      "Loss on test= 0.005832360591739416\n",
      "acc for Lsat= 0.09378347188681506 \n",
      "acc for Psat= 0.13871682012246014 \n",
      "acc for optim= 0.18813271721474184\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.005353364162147045\n",
      "Loss on test= 0.0057630897499620914\n",
      "acc for Lsat= 0.09189420526987256 \n",
      "acc for Psat= 0.1358531583061228 \n",
      "acc for optim= 0.1858994517401329\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.005339734721928835\n",
      "Loss on test= 0.005817539989948273\n",
      "acc for Lsat= 0.10035506755230017 \n",
      "acc for Psat= 0.15647252094542538 \n",
      "acc for optim= 0.18893073999690288\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.005474141798913479\n",
      "Loss on test= 0.006006114184856415\n",
      "acc for Lsat= 0.1005477495873984 \n",
      "acc for Psat= 0.14479080533183641 \n",
      "acc for optim= 0.18515399598156265\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.0054053873755037785\n",
      "Loss on test= 0.0055879936553537846\n",
      "acc for Lsat= 0.09388027474700278 \n",
      "acc for Psat= 0.13665027807390387 \n",
      "acc for optim= 0.18709894486803663\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.005575163755565882\n",
      "Loss on test= 0.006102432496845722\n",
      "acc for Lsat= 0.10280046725720977 \n",
      "acc for Psat= 0.15888557034722417 \n",
      "acc for optim= 0.18827792192366752\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.005461525171995163\n",
      "Loss on test= 0.005738353356719017\n",
      "acc for Lsat= 0.09596292058808645 \n",
      "acc for Psat= 0.14380851674193124 \n",
      "acc for optim= 0.18371308479293696\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005550439469516277\n",
      "Loss on test= 0.00619541248306632\n",
      "acc for Lsat= 0.11310195124580688 \n",
      "acc for Psat= 0.17342404497518343 \n",
      "acc for optim= 0.18366210391222676\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005634721368551254\n",
      "Loss on test= 0.005578727461397648\n",
      "acc for Lsat= 0.09328416859175745 \n",
      "acc for Psat= 0.14451287330106227 \n",
      "acc for optim= 0.18874446089801103\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.00557450158521533\n",
      "Loss on test= 0.005795982200652361\n",
      "acc for Lsat= 0.0923614044857803 \n",
      "acc for Psat= 0.15477648367310837 \n",
      "acc for optim= 0.1862353144002751\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.0054361107759177685\n",
      "Loss on test= 0.005519865546375513\n",
      "acc for Lsat= 0.10692392481418997 \n",
      "acc for Psat= 0.14343522432475742 \n",
      "acc for optim= 0.18362722293704792\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.005504106171429157\n",
      "Loss on test= 0.005866297520697117\n",
      "acc for Lsat= 0.11824162759860367 \n",
      "acc for Psat= 0.13874716504692883 \n",
      "acc for optim= 0.18284739164764197\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.005332972388714552\n",
      "Loss on test= 0.005927161779254675\n",
      "acc for Lsat= 0.10227710817044017 \n",
      "acc for Psat= 0.14829834102331646 \n",
      "acc for optim= 0.1825995705276\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.00546577712520957\n",
      "Loss on test= 0.005752157419919968\n",
      "acc for Lsat= 0.09831619971339171 \n",
      "acc for Psat= 0.14656717040122966 \n",
      "acc for optim= 0.18490883998057708\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.005389004945755005\n",
      "Loss on test= 0.005814807023853064\n",
      "acc for Lsat= 0.10693565581223576 \n",
      "acc for Psat= 0.14039383722528992 \n",
      "acc for optim= 0.18477731082379792\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.005656811408698559\n",
      "Loss on test= 0.006195252761244774\n",
      "acc for Lsat= 0.10933531843113235 \n",
      "acc for Psat= 0.15661448196211447 \n",
      "acc for optim= 0.1818863595208559\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.005518138408660889\n",
      "Loss on test= 0.0057815611362457275\n",
      "acc for Lsat= 0.099579365169186 \n",
      "acc for Psat= 0.1437458565173615 \n",
      "acc for optim= 0.18403490357800242\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005421533714979887\n",
      "Loss on test= 0.005756934639066458\n",
      "acc for Lsat= 0.09658980762870252 \n",
      "acc for Psat= 0.1483684543436047 \n",
      "acc for optim= 0.18327455693341452\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.005531849805265665\n",
      "Loss on test= 0.0059744492173194885\n",
      "acc for Lsat= 0.09682585087304343 \n",
      "acc for Psat= 0.16006748530717968 \n",
      "acc for optim= 0.18446194745715852\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.005559367127716541\n",
      "Loss on test= 0.005800396203994751\n",
      "acc for Lsat= 0.10349056567252232 \n",
      "acc for Psat= 0.148458795869767 \n",
      "acc for optim= 0.18663512463206497\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.0055707599967718124\n",
      "Loss on test= 0.00572866341099143\n",
      "acc for Lsat= 0.11771456789377939 \n",
      "acc for Psat= 0.137709073495038 \n",
      "acc for optim= 0.18164009755295213\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.005405888892710209\n",
      "Loss on test= 0.005673439707607031\n",
      "acc for Lsat= 0.10159676543392109 \n",
      "acc for Psat= 0.14708051292945054 \n",
      "acc for optim= 0.18252484996313845\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.005462194327265024\n",
      "Loss on test= 0.005508395377546549\n",
      "acc for Lsat= 0.11002835405434853 \n",
      "acc for Psat= 0.14243196720464177 \n",
      "acc for optim= 0.18466422759185686\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.00538801122456789\n",
      "Loss on test= 0.0058302804827690125\n",
      "acc for Lsat= 0.09294953639186428 \n",
      "acc for Psat= 0.14697416492443252 \n",
      "acc for optim= 0.19356558991323156\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.005409083794802427\n",
      "Loss on test= 0.005745585076510906\n",
      "acc for Lsat= 0.08870035209032279 \n",
      "acc for Psat= 0.1489874489061672 \n",
      "acc for optim= 0.19020731717849942\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.005336243659257889\n",
      "Loss on test= 0.005809972994029522\n",
      "acc for Lsat= 0.09747932627765662 \n",
      "acc for Psat= 0.14319215812917713 \n",
      "acc for optim= 0.17896181923700513\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.005307949148118496\n",
      "Loss on test= 0.0056753032840788364\n",
      "acc for Lsat= 0.09327443219887288 \n",
      "acc for Psat= 0.13729498824702474 \n",
      "acc for optim= 0.18428189197603953\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.005441703367978334\n",
      "Loss on test= 0.0063706389628350735\n",
      "acc for Lsat= 0.11567462814238408 \n",
      "acc for Psat= 0.17294641859543108 \n",
      "acc for optim= 0.18361093481330867\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.005492181982845068\n",
      "Loss on test= 0.006361300125718117\n",
      "acc for Lsat= 0.12776041923624123 \n",
      "acc for Psat= 0.15965722197614848 \n",
      "acc for optim= 0.18655584275256842\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.00544788409024477\n",
      "Loss on test= 0.005614935420453548\n",
      "acc for Lsat= 0.09573781345209903 \n",
      "acc for Psat= 0.16342618291949024 \n",
      "acc for optim= 0.18067404754067348\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.005358824040740728\n",
      "Loss on test= 0.0056554293259978294\n",
      "acc for Lsat= 0.09740911300026267 \n",
      "acc for Psat= 0.15713145061139633 \n",
      "acc for optim= 0.19041768921994623\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.005355696193873882\n",
      "Loss on test= 0.00593504449352622\n",
      "acc for Lsat= 0.10323357136331725 \n",
      "acc for Psat= 0.1420611919854088 \n",
      "acc for optim= 0.18550667038928353\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.005357383284717798\n",
      "Loss on test= 0.005822432227432728\n",
      "acc for Lsat= 0.10677493198621764 \n",
      "acc for Psat= 0.16135237085114026 \n",
      "acc for optim= 0.18784136516006658\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.005420169793069363\n",
      "Loss on test= 0.00588928023353219\n",
      "acc for Lsat= 0.09935071260740704 \n",
      "acc for Psat= 0.14161797021645456 \n",
      "acc for optim= 0.1898657022213376\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.005405745003372431\n",
      "Loss on test= 0.005647735204547644\n",
      "acc for Lsat= 0.10097296951661937 \n",
      "acc for Psat= 0.13906900560903376 \n",
      "acc for optim= 0.18429104158988324\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.00547443563118577\n",
      "Loss on test= 0.005713649094104767\n",
      "acc for Lsat= 0.09519770000209778 \n",
      "acc for Psat= 0.14129890948990234 \n",
      "acc for optim= 0.18794701583534038\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.0054015303030610085\n",
      "Loss on test= 0.0055323089472949505\n",
      "acc for Lsat= 0.10034930919780005 \n",
      "acc for Psat= 0.1380487606133888 \n",
      "acc for optim= 0.1832342377767074\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.005581567995250225\n",
      "Loss on test= 0.005664678756147623\n",
      "acc for Lsat= 0.10652657377441584 \n",
      "acc for Psat= 0.1396813237346627 \n",
      "acc for optim= 0.18724967360169495\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.005440111737698317\n",
      "Loss on test= 0.006409772671759129\n",
      "acc for Lsat= 0.1239919294003394 \n",
      "acc for Psat= 0.1846405642136233 \n",
      "acc for optim= 0.1805498262293514\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.005559637676924467\n",
      "Loss on test= 0.005804617423564196\n",
      "acc for Lsat= 0.10090040577818621 \n",
      "acc for Psat= 0.14650559797283258 \n",
      "acc for optim= 0.18185473871097055\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.0053366622887551785\n",
      "Loss on test= 0.005508700385689735\n",
      "acc for Lsat= 0.08958324204319512 \n",
      "acc for Psat= 0.14833803910811627 \n",
      "acc for optim= 0.1856451101205469\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.005478327162563801\n",
      "Loss on test= 0.005617417395114899\n",
      "acc for Lsat= 0.1157953560233747 \n",
      "acc for Psat= 0.136551821266334 \n",
      "acc for optim= 0.18918798989007218\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005460724700242281\n",
      "Loss on test= 0.005840854719281197\n",
      "acc for Lsat= 0.1012766652321089 \n",
      "acc for Psat= 0.17089182291080784 \n",
      "acc for optim= 0.19041159478522762\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.0053489371202886105\n",
      "Loss on test= 0.005682576913386583\n",
      "acc for Lsat= 0.10639659686867346 \n",
      "acc for Psat= 0.13785803712655892 \n",
      "acc for optim= 0.18006728534945413\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.005592903587967157\n",
      "Loss on test= 0.005824712570756674\n",
      "acc for Lsat= 0.10306055756626774 \n",
      "acc for Psat= 0.1448486838899781 \n",
      "acc for optim= 0.1869741539984888\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.00539789441972971\n",
      "Loss on test= 0.005682520568370819\n",
      "acc for Lsat= 0.09310430160105564 \n",
      "acc for Psat= 0.15685869483599704 \n",
      "acc for optim= 0.18298848713820426\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.005391751881688833\n",
      "Loss on test= 0.005750506184995174\n",
      "acc for Lsat= 0.1328644170267531 \n",
      "acc for Psat= 0.15989149020508095 \n",
      "acc for optim= 0.1832149261158397\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.00550914416089654\n",
      "Loss on test= 0.005676716100424528\n",
      "acc for Lsat= 0.09417383606164917 \n",
      "acc for Psat= 0.13727939296547226 \n",
      "acc for optim= 0.18562813477350376\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.005299405660480261\n",
      "Loss on test= 0.005637006834149361\n",
      "acc for Lsat= 0.09514466641330482 \n",
      "acc for Psat= 0.14350209726595692 \n",
      "acc for optim= 0.18614321112997728\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.005314357578754425\n",
      "Loss on test= 0.005791105795651674\n",
      "acc for Lsat= 0.09943954388826741 \n",
      "acc for Psat= 0.1395256200607823 \n",
      "acc for optim= 0.18381462601846088\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.0053507075645029545\n",
      "Loss on test= 0.005605698563158512\n",
      "acc for Lsat= 0.10595548628613893 \n",
      "acc for Psat= 0.1571903617270338 \n",
      "acc for optim= 0.18253088784321508\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.005420527886599302\n",
      "Loss on test= 0.005520177073776722\n",
      "acc for Lsat= 0.09294248753173412 \n",
      "acc for Psat= 0.13922708448203716 \n",
      "acc for optim= 0.18757529224697195\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.005477086175233126\n",
      "Loss on test= 0.005668797064572573\n",
      "acc for Lsat= 0.09457315929476691 \n",
      "acc for Psat= 0.14586163799046786 \n",
      "acc for optim= 0.1889966750704106\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.005552053451538086\n",
      "Loss on test= 0.006037646904587746\n",
      "acc for Lsat= 0.09250131349934335 \n",
      "acc for Psat= 0.13071350755175493 \n",
      "acc for optim= 0.19504794054781185\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.005585339851677418\n",
      "Loss on test= 0.005610090214759111\n",
      "acc for Lsat= 0.09411435371952688 \n",
      "acc for Psat= 0.14867901891714586 \n",
      "acc for optim= 0.18758440906645232\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.005415249150246382\n",
      "Loss on test= 0.005554576870054007\n",
      "acc for Lsat= 0.08927636796304157 \n",
      "acc for Psat= 0.1512852505234273 \n",
      "acc for optim= 0.18514455181910897\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005573292262852192\n",
      "Loss on test= 0.0059072598814964294\n",
      "acc for Lsat= 0.12619021805585362 \n",
      "acc for Psat= 0.1488874782681779 \n",
      "acc for optim= 0.18193468397500534\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.0055261715315282345\n",
      "Loss on test= 0.005785208661109209\n",
      "acc for Lsat= 0.09814808716244541 \n",
      "acc for Psat= 0.14560520189887619 \n",
      "acc for optim= 0.18855626742649562\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.005407990887761116\n",
      "Loss on test= 0.005835691932588816\n",
      "acc for Lsat= 0.10544101956269503 \n",
      "acc for Psat= 0.15357587595733363 \n",
      "acc for optim= 0.18519838718399312\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.005398417357355356\n",
      "Loss on test= 0.005712205544114113\n",
      "acc for Lsat= 0.08985045494154219 \n",
      "acc for Psat= 0.14545794838458942 \n",
      "acc for optim= 0.1863282774866339\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.005199193488806486\n",
      "Loss on test= 0.005725282710045576\n",
      "acc for Lsat= 0.0852484092314675 \n",
      "acc for Psat= 0.13481823564693882 \n",
      "acc for optim= 0.18372917118973123\n",
      "Fold 5\n",
      "Epoch:1/1000\n",
      "Loss on train= 0.6145656704902649\n",
      "Loss on test= 0.3419512212276459\n",
      "acc for Lsat= 49.808933264804786 \n",
      "acc for Psat= 14.779072485933616 \n",
      "acc for optim= 2.2194734984551068\n",
      "Epoch:2/1000\n",
      "Loss on train= 0.3212907910346985\n",
      "Loss on test= 0.2777367830276489\n",
      "acc for Lsat= 20.089659340098752 \n",
      "acc for Psat= 10.536376172436748 \n",
      "acc for optim= 2.3745067050301674\n",
      "Epoch:3/1000\n",
      "Loss on train= 0.2562948167324066\n",
      "Loss on test= 0.27020758390426636\n",
      "acc for Lsat= 10.007444417881961 \n",
      "acc for Psat= 3.9746968760423487 \n",
      "acc for optim= 2.8120387541382748\n",
      "Epoch:4/1000\n",
      "Loss on train= 0.22956737875938416\n",
      "Loss on test= 0.2194819301366806\n",
      "acc for Lsat= 6.133254357878814 \n",
      "acc for Psat= 4.090723138308879 \n",
      "acc for optim= 3.2167690941969216\n",
      "Epoch:5/1000\n",
      "Loss on train= 0.18304826319217682\n",
      "Loss on test= 0.17440815269947052\n",
      "acc for Lsat= 3.5358409673354383 \n",
      "acc for Psat= 2.5319335309441313 \n",
      "acc for optim= 1.9873742680444177\n",
      "Epoch:6/1000\n",
      "Loss on train= 0.1675802767276764\n",
      "Loss on test= 0.15659689903259277\n",
      "acc for Lsat= 2.437411625321828 \n",
      "acc for Psat= 2.66577909848637 \n",
      "acc for optim= 3.732854607339822\n",
      "Epoch:7/1000\n",
      "Loss on train= 0.1396854966878891\n",
      "Loss on test= 0.13984209299087524\n",
      "acc for Lsat= 3.840762390865613 \n",
      "acc for Psat= 3.0001686420043048 \n",
      "acc for optim= 1.6759679299984442\n",
      "Epoch:8/1000\n",
      "Loss on train= 0.1197345033288002\n",
      "Loss on test= 0.1148223876953125\n",
      "acc for Lsat= 1.8794751300508061 \n",
      "acc for Psat= 1.1502311372056098 \n",
      "acc for optim= 1.8018582929656184\n",
      "Epoch:9/1000\n",
      "Loss on train= 0.10750412940979004\n",
      "Loss on test= 0.09992685914039612\n",
      "acc for Lsat= 1.6976352838495494 \n",
      "acc for Psat= 1.3268237427348601 \n",
      "acc for optim= 2.879342833986127\n",
      "Epoch:10/1000\n",
      "Loss on train= 0.0890452116727829\n",
      "Loss on test= 0.08539602160453796\n",
      "acc for Lsat= 1.7589992453944001 \n",
      "acc for Psat= 1.5475958246911354 \n",
      "acc for optim= 0.847792701114569\n",
      "Epoch:11/1000\n",
      "Loss on train= 0.07516055554151535\n",
      "Loss on test= 0.07146511226892471\n",
      "acc for Lsat= 1.1873485765246263 \n",
      "acc for Psat= 1.2710975304897085 \n",
      "acc for optim= 5.495925898657386\n",
      "Epoch:12/1000\n",
      "Loss on train= 0.06530263274908066\n",
      "Loss on test= 0.06393052637577057\n",
      "acc for Lsat= 1.4530638401507068 \n",
      "acc for Psat= 1.17764421136521 \n",
      "acc for optim= 1.0939697690963177\n",
      "Epoch:13/1000\n",
      "Loss on train= 0.05977152660489082\n",
      "Loss on test= 0.05583087354898453\n",
      "acc for Lsat= 1.4623990885800904 \n",
      "acc for Psat= 1.0171959072225174 \n",
      "acc for optim= 0.4677241871369237\n",
      "Epoch:14/1000\n",
      "Loss on train= 0.055557526648044586\n",
      "Loss on test= 0.05642305687069893\n",
      "acc for Lsat= 1.207606327057011 \n",
      "acc for Psat= 0.9499709575389654 \n",
      "acc for optim= 0.7953702637025992\n",
      "Epoch:15/1000\n",
      "Loss on train= 0.049297284334897995\n",
      "Loss on test= 0.04911494627594948\n",
      "acc for Lsat= 0.7535331845788632 \n",
      "acc for Psat= 0.930146943394221 \n",
      "acc for optim= 0.5309833495938604\n",
      "Epoch:16/1000\n",
      "Loss on train= 0.04776988923549652\n",
      "Loss on test= 0.044382352381944656\n",
      "acc for Lsat= 0.9902675316116567 \n",
      "acc for Psat= 1.0402372908068158 \n",
      "acc for optim= 0.4863741007615749\n",
      "Epoch:17/1000\n",
      "Loss on train= 0.043380334973335266\n",
      "Loss on test= 0.043679457157850266\n",
      "acc for Lsat= 0.7578800923704028 \n",
      "acc for Psat= 0.7135449220110678 \n",
      "acc for optim= 0.3247719691553295\n",
      "Epoch:18/1000\n",
      "Loss on train= 0.040064696222543716\n",
      "Loss on test= 0.039722003042697906\n",
      "acc for Lsat= 0.8058085349161509 \n",
      "acc for Psat= 0.673594162516075 \n",
      "acc for optim= 0.5301731186824203\n",
      "Epoch:19/1000\n",
      "Loss on train= 0.0371992252767086\n",
      "Loss on test= 0.038469139486551285\n",
      "acc for Lsat= 0.6444334809273734 \n",
      "acc for Psat= 0.6390706537251944 \n",
      "acc for optim= 0.586760871426372\n",
      "Epoch:20/1000\n",
      "Loss on train= 0.03858442232012749\n",
      "Loss on test= 0.039307765662670135\n",
      "acc for Lsat= 0.711793126218747 \n",
      "acc for Psat= 0.7889309089425636 \n",
      "acc for optim= 0.5477221219745164\n",
      "Epoch:21/1000\n",
      "Loss on train= 0.03469620645046234\n",
      "Loss on test= 0.03586452454328537\n",
      "acc for Lsat= 0.7257234576600209 \n",
      "acc for Psat= 0.6557033805114955 \n",
      "acc for optim= 0.3974267277363451\n",
      "Epoch:22/1000\n",
      "Loss on train= 0.03225196897983551\n",
      "Loss on test= 0.03262672945857048\n",
      "acc for Lsat= 0.7143855486254571 \n",
      "acc for Psat= 0.7086823755760787 \n",
      "acc for optim= 0.3459055069415688\n",
      "Epoch:23/1000\n",
      "Loss on train= 0.03123844973742962\n",
      "Loss on test= 0.03608965501189232\n",
      "acc for Lsat= 0.6314778206443762 \n",
      "acc for Psat= 0.6029949455778509 \n",
      "acc for optim= 0.3020063871649978\n",
      "Epoch:24/1000\n",
      "Loss on train= 0.030821755528450012\n",
      "Loss on test= 0.031175749376416206\n",
      "acc for Lsat= 0.6331781792687252 \n",
      "acc for Psat= 0.6493020468912387 \n",
      "acc for optim= 0.39387961620429407\n",
      "Epoch:25/1000\n",
      "Loss on train= 0.029515184462070465\n",
      "Loss on test= 0.03213194012641907\n",
      "acc for Lsat= 0.5653471869260657 \n",
      "acc for Psat= 0.8478486887005678 \n",
      "acc for optim= 0.3498117739074248\n",
      "Epoch:26/1000\n",
      "Loss on train= 0.028433391824364662\n",
      "Loss on test= 0.029021596536040306\n",
      "acc for Lsat= 0.6346903171485005 \n",
      "acc for Psat= 0.6206407666143219 \n",
      "acc for optim= 0.3385086023738071\n",
      "Epoch:27/1000\n",
      "Loss on train= 0.027485454455018044\n",
      "Loss on test= 0.029417218640446663\n",
      "acc for Lsat= 0.5853716707614771 \n",
      "acc for Psat= 0.5996404607410314 \n",
      "acc for optim= 0.2910510663661348\n",
      "Epoch:28/1000\n",
      "Loss on train= 0.02634824812412262\n",
      "Loss on test= 0.02796781435608864\n",
      "acc for Lsat= 0.54462421091305 \n",
      "acc for Psat= 0.6642154903178719 \n",
      "acc for optim= 0.3172844207729213\n",
      "Epoch:29/1000\n",
      "Loss on train= 0.02537686564028263\n",
      "Loss on test= 0.029126830399036407\n",
      "acc for Lsat= 0.5638982720988787 \n",
      "acc for Psat= 0.5449568752428295 \n",
      "acc for optim= 0.26274248151724244\n",
      "Epoch:30/1000\n",
      "Loss on train= 0.024633022025227547\n",
      "Loss on test= 0.026800164952874184\n",
      "acc for Lsat= 0.4723098634426498 \n",
      "acc for Psat= 0.5971476650504806 \n",
      "acc for optim= 0.25684178116873413\n",
      "Epoch:31/1000\n",
      "Loss on train= 0.02459137886762619\n",
      "Loss on test= 0.02802097238600254\n",
      "acc for Lsat= 0.46793757790099766 \n",
      "acc for Psat= 0.7511229944707415 \n",
      "acc for optim= 0.2746921292782398\n",
      "Epoch:32/1000\n",
      "Loss on train= 0.023721415549516678\n",
      "Loss on test= 0.024782827123999596\n",
      "acc for Lsat= 0.47186274999373795 \n",
      "acc for Psat= 0.5311838821511936 \n",
      "acc for optim= 0.265471040629545\n",
      "Epoch:33/1000\n",
      "Loss on train= 0.023216284811496735\n",
      "Loss on test= 0.02597644552588463\n",
      "acc for Lsat= 0.4623893811479921 \n",
      "acc for Psat= 0.5661638035684857 \n",
      "acc for optim= 0.2978396803261002\n",
      "Epoch:34/1000\n",
      "Loss on train= 0.021678920835256577\n",
      "Loss on test= 0.02387947402894497\n",
      "acc for Lsat= 0.47804649107836944 \n",
      "acc for Psat= 0.600075214373745 \n",
      "acc for optim= 0.24562177434129545\n",
      "Epoch:35/1000\n",
      "Loss on train= 0.024122178554534912\n",
      "Loss on test= 0.023841295391321182\n",
      "acc for Lsat= 0.4582699594135254 \n",
      "acc for Psat= 0.5883350170418715 \n",
      "acc for optim= 0.27748745736681807\n",
      "Epoch:36/1000\n",
      "Loss on train= 0.02203935571014881\n",
      "Loss on test= 0.024924147874116898\n",
      "acc for Lsat= 0.5217316664396233 \n",
      "acc for Psat= 0.5889473442193437 \n",
      "acc for optim= 0.27993389746821407\n",
      "Epoch:37/1000\n",
      "Loss on train= 0.021135380491614342\n",
      "Loss on test= 0.022991787642240524\n",
      "acc for Lsat= 0.46014037933437374 \n",
      "acc for Psat= 0.5545209067830248 \n",
      "acc for optim= 0.22811652128071666\n",
      "Epoch:38/1000\n",
      "Loss on train= 0.021275384351611137\n",
      "Loss on test= 0.023006677627563477\n",
      "acc for Lsat= 0.4223400434277857 \n",
      "acc for Psat= 0.5378925756314549 \n",
      "acc for optim= 0.22276815212187673\n",
      "Epoch:39/1000\n",
      "Loss on train= 0.020809805020689964\n",
      "Loss on test= 0.02260858193039894\n",
      "acc for Lsat= 0.4706671616693927 \n",
      "acc for Psat= 0.5078437110022405 \n",
      "acc for optim= 0.2298890536821692\n",
      "Epoch:40/1000\n",
      "Loss on train= 0.02068178914487362\n",
      "Loss on test= 0.02287541702389717\n",
      "acc for Lsat= 0.39990382899403953 \n",
      "acc for Psat= 0.5798360752194363 \n",
      "acc for optim= 0.2388605708887769\n",
      "Epoch:41/1000\n",
      "Loss on train= 0.02074895240366459\n",
      "Loss on test= 0.02362184412777424\n",
      "acc for Lsat= 0.49833585398776803 \n",
      "acc for Psat= 0.5113688337608729 \n",
      "acc for optim= 0.22611903654632426\n",
      "Epoch:42/1000\n",
      "Loss on train= 0.02069956250488758\n",
      "Loss on test= 0.021456899121403694\n",
      "acc for Lsat= 0.4759205224760512 \n",
      "acc for Psat= 0.5244739877038351 \n",
      "acc for optim= 0.29214875011969266\n",
      "Epoch:43/1000\n",
      "Loss on train= 0.01905805617570877\n",
      "Loss on test= 0.020488040521740913\n",
      "acc for Lsat= 0.4234824739041407 \n",
      "acc for Psat= 0.49006715319671873 \n",
      "acc for optim= 0.21543866634355086\n",
      "Epoch:44/1000\n",
      "Loss on train= 0.01897420361638069\n",
      "Loss on test= 0.022598711773753166\n",
      "acc for Lsat= 0.43407343863785836 \n",
      "acc for Psat= 0.5188453965557451 \n",
      "acc for optim= 0.2606198571472413\n",
      "Epoch:45/1000\n",
      "Loss on train= 0.019016453996300697\n",
      "Loss on test= 0.02034558728337288\n",
      "acc for Lsat= 0.4506154572208396 \n",
      "acc for Psat= 0.4921356517739665 \n",
      "acc for optim= 0.22926189860090282\n",
      "Epoch:46/1000\n",
      "Loss on train= 0.019317403435707092\n",
      "Loss on test= 0.02112532965838909\n",
      "acc for Lsat= 0.4487486767266893 \n",
      "acc for Psat= 0.44354897487057193 \n",
      "acc for optim= 0.22342175624424088\n",
      "Epoch:47/1000\n",
      "Loss on train= 0.018121348693966866\n",
      "Loss on test= 0.019952010363340378\n",
      "acc for Lsat= 0.4197857606481224 \n",
      "acc for Psat= 0.5115638476259754 \n",
      "acc for optim= 0.21862898173153014\n",
      "Epoch:48/1000\n",
      "Loss on train= 0.018397437408566475\n",
      "Loss on test= 0.01804310269653797\n",
      "acc for Lsat= 0.40735829661846196 \n",
      "acc for Psat= 0.5117899448761788 \n",
      "acc for optim= 0.22106168066396603\n",
      "Epoch:49/1000\n",
      "Loss on train= 0.017843574285507202\n",
      "Loss on test= 0.019168157130479813\n",
      "acc for Lsat= 0.40252482353678065 \n",
      "acc for Psat= 0.4240839166503589 \n",
      "acc for optim= 0.20825057830385296\n",
      "Epoch:50/1000\n",
      "Loss on train= 0.017887026071548462\n",
      "Loss on test= 0.019632142037153244\n",
      "acc for Lsat= 0.49280680806012983 \n",
      "acc for Psat= 0.46954295766259685 \n",
      "acc for optim= 0.2301014361732888\n",
      "Epoch:51/1000\n",
      "Loss on train= 0.01814793050289154\n",
      "Loss on test= 0.019381118938326836\n",
      "acc for Lsat= 0.34309589640568877 \n",
      "acc for Psat= 0.5519688193488992 \n",
      "acc for optim= 0.2304386347623037\n",
      "Epoch:52/1000\n",
      "Loss on train= 0.01722540892660618\n",
      "Loss on test= 0.019717982038855553\n",
      "acc for Lsat= 0.3784896561733873 \n",
      "acc for Psat= 0.48613943064553755 \n",
      "acc for optim= 0.22642702629012293\n",
      "Epoch:53/1000\n",
      "Loss on train= 0.01664387248456478\n",
      "Loss on test= 0.01941976137459278\n",
      "acc for Lsat= 0.35545634856068736 \n",
      "acc for Psat= 0.48833210159535123 \n",
      "acc for optim= 0.21187971387960222\n",
      "Epoch:54/1000\n",
      "Loss on train= 0.017036253586411476\n",
      "Loss on test= 0.01871068961918354\n",
      "acc for Lsat= 0.4222172842862211 \n",
      "acc for Psat= 0.4269419568105427 \n",
      "acc for optim= 0.20291152387774566\n",
      "Epoch:55/1000\n",
      "Loss on train= 0.017542093992233276\n",
      "Loss on test= 0.01889171078801155\n",
      "acc for Lsat= 0.33744273741031067 \n",
      "acc for Psat= 0.49098161185333916 \n",
      "acc for optim= 0.21334867840790647\n",
      "Epoch:56/1000\n",
      "Loss on train= 0.017068661749362946\n",
      "Loss on test= 0.02000555582344532\n",
      "acc for Lsat= 0.39711982894499426 \n",
      "acc for Psat= 0.42931109989077737 \n",
      "acc for optim= 0.20744353761793888\n",
      "Epoch:57/1000\n",
      "Loss on train= 0.017430730164051056\n",
      "Loss on test= 0.01944446936249733\n",
      "acc for Lsat= 0.41595814848729107 \n",
      "acc for Psat= 0.4393606637383543 \n",
      "acc for optim= 0.20901569806797018\n",
      "Epoch:58/1000\n",
      "Loss on train= 0.01679820381104946\n",
      "Loss on test= 0.01729670725762844\n",
      "acc for Lsat= 0.3745499857549429 \n",
      "acc for Psat= 0.43555163706542327 \n",
      "acc for optim= 0.21818410554442996\n",
      "Epoch:59/1000\n",
      "Loss on train= 0.016177935525774956\n",
      "Loss on test= 0.0188350360840559\n",
      "acc for Lsat= 0.36546809045455847 \n",
      "acc for Psat= 0.46884249766925506 \n",
      "acc for optim= 0.22236213678636163\n",
      "Epoch:60/1000\n",
      "Loss on train= 0.016054321080446243\n",
      "Loss on test= 0.018711281940340996\n",
      "acc for Lsat= 0.5023590444987719 \n",
      "acc for Psat= 0.4483941431563758 \n",
      "acc for optim= 0.2111663905146011\n",
      "Epoch:61/1000\n",
      "Loss on train= 0.015803169459104538\n",
      "Loss on test= 0.018667668104171753\n",
      "acc for Lsat= 0.4205994085189729 \n",
      "acc for Psat= 0.40827092225864375 \n",
      "acc for optim= 0.21515549818918078\n",
      "Epoch:62/1000\n",
      "Loss on train= 0.01567051373422146\n",
      "Loss on test= 0.018916504457592964\n",
      "acc for Lsat= 0.4325522474589426 \n",
      "acc for Psat= 0.3969534532664249 \n",
      "acc for optim= 0.21620522468307418\n",
      "Epoch:63/1000\n",
      "Loss on train= 0.016856694594025612\n",
      "Loss on test= 0.01830284111201763\n",
      "acc for Lsat= 0.47817869767373017 \n",
      "acc for Psat= 0.3820569462861108 \n",
      "acc for optim= 0.21815687470874054\n",
      "Epoch:64/1000\n",
      "Loss on train= 0.016185130923986435\n",
      "Loss on test= 0.016556724905967712\n",
      "acc for Lsat= 0.3500706640190555 \n",
      "acc for Psat= 0.40575318279818207 \n",
      "acc for optim= 0.19893295558295765\n",
      "Epoch:65/1000\n",
      "Loss on train= 0.016022270545363426\n",
      "Loss on test= 0.017421621829271317\n",
      "acc for Lsat= 0.30941287192310823 \n",
      "acc for Psat= 0.5099529155869416 \n",
      "acc for optim= 0.21721915379876933\n",
      "Epoch:66/1000\n",
      "Loss on train= 0.015481994487345219\n",
      "Loss on test= 0.016677405685186386\n",
      "acc for Lsat= 0.48881923530282356 \n",
      "acc for Psat= 0.374402914673161 \n",
      "acc for optim= 0.21214536651100774\n",
      "Epoch:67/1000\n",
      "Loss on train= 0.016210263594985008\n",
      "Loss on test= 0.01644083857536316\n",
      "acc for Lsat= 0.3120240263041046 \n",
      "acc for Psat= 0.41006033034300654 \n",
      "acc for optim= 0.20037014737174752\n",
      "Epoch:68/1000\n",
      "Loss on train= 0.015816064551472664\n",
      "Loss on test= 0.01802932098507881\n",
      "acc for Lsat= 0.44626025743308967 \n",
      "acc for Psat= 0.3700972647698186 \n",
      "acc for optim= 0.20688007016157164\n",
      "Epoch:69/1000\n",
      "Loss on train= 0.015162508934736252\n",
      "Loss on test= 0.015681754797697067\n",
      "acc for Lsat= 0.34097075451804737 \n",
      "acc for Psat= 0.4163237419531886 \n",
      "acc for optim= 0.21245767751686923\n",
      "Epoch:70/1000\n",
      "Loss on train= 0.01596112549304962\n",
      "Loss on test= 0.016545476391911507\n",
      "acc for Lsat= 0.343441651892647 \n",
      "acc for Psat= 0.43818614370104764 \n",
      "acc for optim= 0.2164471134827551\n",
      "Epoch:71/1000\n",
      "Loss on train= 0.015335126779973507\n",
      "Loss on test= 0.017272695899009705\n",
      "acc for Lsat= 0.3714105702881401 \n",
      "acc for Psat= 0.41774426111292934 \n",
      "acc for optim= 0.21216235140519082\n",
      "Epoch:72/1000\n",
      "Loss on train= 0.01506697665899992\n",
      "Loss on test= 0.015604278072714806\n",
      "acc for Lsat= 0.30949087385522295 \n",
      "acc for Psat= 0.4187172344049155 \n",
      "acc for optim= 0.20906574423464364\n",
      "Epoch:73/1000\n",
      "Loss on train= 0.01573714055120945\n",
      "Loss on test= 0.016051236540079117\n",
      "acc for Lsat= 0.38869774911357324 \n",
      "acc for Psat= 0.3781444281305115 \n",
      "acc for optim= 0.2166749495492017\n",
      "Epoch:74/1000\n",
      "Loss on train= 0.01512929517775774\n",
      "Loss on test= 0.016474368050694466\n",
      "acc for Lsat= 0.3672164723683559 \n",
      "acc for Psat= 0.3941893428454069 \n",
      "acc for optim= 0.21391760845337127\n",
      "Epoch:75/1000\n",
      "Loss on train= 0.015009029768407345\n",
      "Loss on test= 0.016567600890994072\n",
      "acc for Lsat= 0.35628004475986047 \n",
      "acc for Psat= 0.38034290614847677 \n",
      "acc for optim= 0.20604203935333734\n",
      "Epoch:76/1000\n",
      "Loss on train= 0.01490210834890604\n",
      "Loss on test= 0.01593538373708725\n",
      "acc for Lsat= 0.3143637345831494 \n",
      "acc for Psat= 0.449751299284438 \n",
      "acc for optim= 0.25825507263455666\n",
      "Epoch:77/1000\n",
      "Loss on train= 0.014533626846969128\n",
      "Loss on test= 0.015511277131736279\n",
      "acc for Lsat= 0.34790480855331457 \n",
      "acc for Psat= 0.38183441135077345 \n",
      "acc for optim= 0.21534533362393662\n",
      "Epoch:78/1000\n",
      "Loss on train= 0.014273756183683872\n",
      "Loss on test= 0.015800343826413155\n",
      "acc for Lsat= 0.37633592591510484 \n",
      "acc for Psat= 0.40261313735025983 \n",
      "acc for optim= 0.20674987570939296\n",
      "Epoch:79/1000\n",
      "Loss on train= 0.014601551927626133\n",
      "Loss on test= 0.016611212864518166\n",
      "acc for Lsat= 0.327201734353804 \n",
      "acc for Psat= 0.47286975184313446 \n",
      "acc for optim= 0.20571825357974838\n",
      "Epoch:80/1000\n",
      "Loss on train= 0.014816398732364178\n",
      "Loss on test= 0.014751078560948372\n",
      "acc for Lsat= 0.351791304113517 \n",
      "acc for Psat= 0.3658663362678993 \n",
      "acc for optim= 0.20016644996417277\n",
      "Epoch:81/1000\n",
      "Loss on train= 0.014419580809772015\n",
      "Loss on test= 0.015364754013717175\n",
      "acc for Lsat= 0.31042541619538233 \n",
      "acc for Psat= 0.3980386387608093 \n",
      "acc for optim= 0.21141508624620609\n",
      "Epoch:82/1000\n",
      "Loss on train= 0.015007677488029003\n",
      "Loss on test= 0.015658188611268997\n",
      "acc for Lsat= 0.3933002434292082 \n",
      "acc for Psat= 0.38828703923056185 \n",
      "acc for optim= 0.21714292422585166\n",
      "Epoch:83/1000\n",
      "Loss on train= 0.014741812832653522\n",
      "Loss on test= 0.015523809939622879\n",
      "acc for Lsat= 0.29583270765803515 \n",
      "acc for Psat= 0.38619330953727715 \n",
      "acc for optim= 0.21327737764252144\n",
      "Epoch:84/1000\n",
      "Loss on train= 0.014866289682686329\n",
      "Loss on test= 0.015106495469808578\n",
      "acc for Lsat= 0.3157539696116948 \n",
      "acc for Psat= 0.37294408413029073 \n",
      "acc for optim= 0.1910221359329456\n",
      "Epoch:85/1000\n",
      "Loss on train= 0.014378207735717297\n",
      "Loss on test= 0.015529383905231953\n",
      "acc for Lsat= 0.3216633491260019 \n",
      "acc for Psat= 0.4072894909498045 \n",
      "acc for optim= 0.21599963739616954\n",
      "Epoch:86/1000\n",
      "Loss on train= 0.014153150841593742\n",
      "Loss on test= 0.015027944929897785\n",
      "acc for Lsat= 0.29700794868724684 \n",
      "acc for Psat= 0.43120672046917224 \n",
      "acc for optim= 0.21606339767744953\n",
      "Epoch:87/1000\n",
      "Loss on train= 0.014971508644521236\n",
      "Loss on test= 0.01676981896162033\n",
      "acc for Lsat= 0.4388096441195141 \n",
      "acc for Psat= 0.38082035872848485 \n",
      "acc for optim= 0.18815333556593\n",
      "Epoch:88/1000\n",
      "Loss on train= 0.016440263018012047\n",
      "Loss on test= 0.016716821119189262\n",
      "acc for Lsat= 0.29504798060535625 \n",
      "acc for Psat= 0.41577448846448717 \n",
      "acc for optim= 0.21885955627480821\n",
      "Epoch:89/1000\n",
      "Loss on train= 0.015491905622184277\n",
      "Loss on test= 0.015393788926303387\n",
      "acc for Lsat= 0.3170887164045441 \n",
      "acc for Psat= 0.3420430011415886 \n",
      "acc for optim= 0.1854616371324775\n",
      "Epoch:90/1000\n",
      "Loss on train= 0.014536229893565178\n",
      "Loss on test= 0.014618420973420143\n",
      "acc for Lsat= 0.3694505325246255 \n",
      "acc for Psat= 0.34367244948072645 \n",
      "acc for optim= 0.22231820883442474\n",
      "Epoch:91/1000\n",
      "Loss on train= 0.01428777165710926\n",
      "Loss on test= 0.014646227471530437\n",
      "acc for Lsat= 0.2968703139958098 \n",
      "acc for Psat= 0.4182743139103276 \n",
      "acc for optim= 0.19983096658188476\n",
      "Epoch:92/1000\n",
      "Loss on train= 0.013415774330496788\n",
      "Loss on test= 0.014759199693799019\n",
      "acc for Lsat= 0.3076260141025976 \n",
      "acc for Psat= 0.40139010856077284 \n",
      "acc for optim= 0.20119318895878555\n",
      "Epoch:93/1000\n",
      "Loss on train= 0.014076328836381435\n",
      "Loss on test= 0.015681017190217972\n",
      "acc for Lsat= 0.43556106428820957 \n",
      "acc for Psat= 0.3547892827665684 \n",
      "acc for optim= 0.19942445570476733\n",
      "Epoch:94/1000\n",
      "Loss on train= 0.014550130814313889\n",
      "Loss on test= 0.01572507992386818\n",
      "acc for Lsat= 0.3020348863736371 \n",
      "acc for Psat= 0.3735135473378034 \n",
      "acc for optim= 0.19890501948341854\n",
      "Epoch:95/1000\n",
      "Loss on train= 0.014051934704184532\n",
      "Loss on test= 0.013227427378296852\n",
      "acc for Lsat= 0.3362078857923842 \n",
      "acc for Psat= 0.36595300155498434 \n",
      "acc for optim= 0.201191789347489\n",
      "Epoch:96/1000\n",
      "Loss on train= 0.013239585794508457\n",
      "Loss on test= 0.013625483959913254\n",
      "acc for Lsat= 0.31213166275085347 \n",
      "acc for Psat= 0.39293708008540384 \n",
      "acc for optim= 0.20671125272470448\n",
      "Epoch:97/1000\n",
      "Loss on train= 0.013623200356960297\n",
      "Loss on test= 0.014379103668034077\n",
      "acc for Lsat= 0.36558175894561995 \n",
      "acc for Psat= 0.37723027159118533 \n",
      "acc for optim= 0.21260523934911746\n",
      "Epoch:98/1000\n",
      "Loss on train= 0.013512802310287952\n",
      "Loss on test= 0.014041667804121971\n",
      "acc for Lsat= 0.3315650898612117 \n",
      "acc for Psat= 0.3475311951033013 \n",
      "acc for optim= 0.19597490263739759\n",
      "Epoch:99/1000\n",
      "Loss on train= 0.013504890725016594\n",
      "Loss on test= 0.013593880459666252\n",
      "acc for Lsat= 0.3237446439845124 \n",
      "acc for Psat= 0.38690587469727844 \n",
      "acc for optim= 0.20936159369717272\n",
      "Epoch:100/1000\n",
      "Loss on train= 0.013250215910375118\n",
      "Loss on test= 0.014893068000674248\n",
      "acc for Lsat= 0.3213603203934696 \n",
      "acc for Psat= 0.3661360861102151 \n",
      "acc for optim= 0.20248923975465252\n",
      "Epoch:101/1000\n",
      "Loss on train= 0.013553045690059662\n",
      "Loss on test= 0.014059774577617645\n",
      "acc for Lsat= 0.3345512991775048 \n",
      "acc for Psat= 0.3450808518266274 \n",
      "acc for optim= 0.20147900467780316\n",
      "Epoch:102/1000\n",
      "Loss on train= 0.013607406057417393\n",
      "Loss on test= 0.014281314797699451\n",
      "acc for Lsat= 0.35109226031986585 \n",
      "acc for Psat= 0.3786388823075883 \n",
      "acc for optim= 0.1934110516021758\n",
      "Epoch:103/1000\n",
      "Loss on train= 0.01399054005742073\n",
      "Loss on test= 0.013853681273758411\n",
      "acc for Lsat= 0.3024428509907813 \n",
      "acc for Psat= 0.34786427622203225 \n",
      "acc for optim= 0.2113559581350335\n",
      "Epoch:104/1000\n",
      "Loss on train= 0.013398789800703526\n",
      "Loss on test= 0.01412050798535347\n",
      "acc for Lsat= 0.3434026077539676 \n",
      "acc for Psat= 0.33220579626938423 \n",
      "acc for optim= 0.20599145249570167\n",
      "Epoch:105/1000\n",
      "Loss on train= 0.013969841413199902\n",
      "Loss on test= 0.01464920025318861\n",
      "acc for Lsat= 0.3461884812187498 \n",
      "acc for Psat= 0.35698226869216787 \n",
      "acc for optim= 0.21182680368873338\n",
      "Epoch:106/1000\n",
      "Loss on train= 0.013381849974393845\n",
      "Loss on test= 0.014333461411297321\n",
      "acc for Lsat= 0.29971356487510353 \n",
      "acc for Psat= 0.4079717991423746 \n",
      "acc for optim= 0.2123527152550612\n",
      "Epoch:107/1000\n",
      "Loss on train= 0.01301055308431387\n",
      "Loss on test= 0.014941532164812088\n",
      "acc for Lsat= 0.328273097100131 \n",
      "acc for Psat= 0.34654403388563354 \n",
      "acc for optim= 0.19127889571423343\n",
      "Epoch:108/1000\n",
      "Loss on train= 0.013014924712479115\n",
      "Loss on test= 0.014274063520133495\n",
      "acc for Lsat= 0.2844774500916759 \n",
      "acc for Psat= 0.39964787985663863 \n",
      "acc for optim= 0.21079719206298528\n",
      "Epoch:109/1000\n",
      "Loss on train= 0.013314747251570225\n",
      "Loss on test= 0.014660819433629513\n",
      "acc for Lsat= 0.32256552894763507 \n",
      "acc for Psat= 0.36408660840598267 \n",
      "acc for optim= 0.20089681291936945\n",
      "Epoch:110/1000\n",
      "Loss on train= 0.013747930526733398\n",
      "Loss on test= 0.014145390130579472\n",
      "acc for Lsat= 0.2853244641172242 \n",
      "acc for Psat= 0.39122194918839387 \n",
      "acc for optim= 0.21359148859352237\n",
      "Epoch:111/1000\n",
      "Loss on train= 0.013608022592961788\n",
      "Loss on test= 0.013750447891652584\n",
      "acc for Lsat= 0.2866833874119162 \n",
      "acc for Psat= 0.4149356128968559 \n",
      "acc for optim= 0.2169940434384428\n",
      "Epoch:112/1000\n",
      "Loss on train= 0.013014858588576317\n",
      "Loss on test= 0.014286142773926258\n",
      "acc for Lsat= 0.38585168528765185 \n",
      "acc for Psat= 0.3597066150725646 \n",
      "acc for optim= 0.19649247776547257\n",
      "Epoch:113/1000\n",
      "Loss on train= 0.013331289403140545\n",
      "Loss on test= 0.015036078169941902\n",
      "acc for Lsat= 0.30710169479913885 \n",
      "acc for Psat= 0.38535031415758875 \n",
      "acc for optim= 0.20802047538957796\n",
      "Epoch:114/1000\n",
      "Loss on train= 0.013546647503972054\n",
      "Loss on test= 0.013246789574623108\n",
      "acc for Lsat= 0.3076276630163193 \n",
      "acc for Psat= 0.3414740608772263 \n",
      "acc for optim= 0.2096991275859305\n",
      "Epoch:115/1000\n",
      "Loss on train= 0.013348402455449104\n",
      "Loss on test= 0.013478281907737255\n",
      "acc for Lsat= 0.2926864733643262 \n",
      "acc for Psat= 0.35111365375440506 \n",
      "acc for optim= 0.2245214200073506\n",
      "Epoch:116/1000\n",
      "Loss on train= 0.013317720033228397\n",
      "Loss on test= 0.013722890056669712\n",
      "acc for Lsat= 0.35914895773679806 \n",
      "acc for Psat= 0.3515069642696151 \n",
      "acc for optim= 0.19443013865591452\n",
      "Epoch:117/1000\n",
      "Loss on train= 0.013145443052053452\n",
      "Loss on test= 0.01399495080113411\n",
      "acc for Lsat= 0.3014394044221016 \n",
      "acc for Psat= 0.35596211923442195 \n",
      "acc for optim= 0.19068569279358707\n",
      "Epoch:118/1000\n",
      "Loss on train= 0.012552319094538689\n",
      "Loss on test= 0.013303028419613838\n",
      "acc for Lsat= 0.31671997849095485 \n",
      "acc for Psat= 0.3449308603978321 \n",
      "acc for optim= 0.20029334092919193\n",
      "Epoch:119/1000\n",
      "Loss on train= 0.013088204897940159\n",
      "Loss on test= 0.0134737528860569\n",
      "acc for Lsat= 0.29353745310583107 \n",
      "acc for Psat= 0.34311498897189624 \n",
      "acc for optim= 0.2119440902434921\n",
      "Epoch:120/1000\n",
      "Loss on train= 0.012776993215084076\n",
      "Loss on test= 0.01326072495430708\n",
      "acc for Lsat= 0.29416493949543493 \n",
      "acc for Psat= 0.3827723788046199 \n",
      "acc for optim= 0.21336240992107885\n",
      "Epoch:121/1000\n",
      "Loss on train= 0.012191525660455227\n",
      "Loss on test= 0.013269728049635887\n",
      "acc for Lsat= 0.27935987479088953 \n",
      "acc for Psat= 0.355612313843202 \n",
      "acc for optim= 0.20635468604642962\n",
      "Epoch:122/1000\n",
      "Loss on train= 0.012455513700842857\n",
      "Loss on test= 0.013057139702141285\n",
      "acc for Lsat= 0.2646608182522113 \n",
      "acc for Psat= 0.36745208497228243 \n",
      "acc for optim= 0.19089863775811017\n",
      "Epoch:123/1000\n",
      "Loss on train= 0.012862787581980228\n",
      "Loss on test= 0.014017364010214806\n",
      "acc for Lsat= 0.37649779389059895 \n",
      "acc for Psat= 0.31841802097564975 \n",
      "acc for optim= 0.20809684349145047\n",
      "Epoch:124/1000\n",
      "Loss on train= 0.013100097887217999\n",
      "Loss on test= 0.013387009501457214\n",
      "acc for Lsat= 0.26006967556284016 \n",
      "acc for Psat= 0.3704894233337146 \n",
      "acc for optim= 0.1827675527675468\n",
      "Epoch:125/1000\n",
      "Loss on train= 0.01294668484479189\n",
      "Loss on test= 0.013892579823732376\n",
      "acc for Lsat= 0.3506701987299879 \n",
      "acc for Psat= 0.32859973973807705 \n",
      "acc for optim= 0.19194479911524992\n",
      "Epoch:126/1000\n",
      "Loss on train= 0.01285589300096035\n",
      "Loss on test= 0.012912490405142307\n",
      "acc for Lsat= 0.27833293730117303 \n",
      "acc for Psat= 0.35449566275268096 \n",
      "acc for optim= 0.21180238106595825\n",
      "Epoch:127/1000\n",
      "Loss on train= 0.012870813719928265\n",
      "Loss on test= 0.012618034146726131\n",
      "acc for Lsat= 0.2782806577492442 \n",
      "acc for Psat= 0.3630708086428921 \n",
      "acc for optim= 0.1914041041629389\n",
      "Epoch:128/1000\n",
      "Loss on train= 0.012943039648234844\n",
      "Loss on test= 0.013582279905676842\n",
      "acc for Lsat= 0.36840459852582 \n",
      "acc for Psat= 0.3398216894081936 \n",
      "acc for optim= 0.21162620002326904\n",
      "Epoch:129/1000\n",
      "Loss on train= 0.013876604847609997\n",
      "Loss on test= 0.013662210665643215\n",
      "acc for Lsat= 0.2695791779133349 \n",
      "acc for Psat= 0.3876939505204495 \n",
      "acc for optim= 0.19543751339966794\n",
      "Epoch:130/1000\n",
      "Loss on train= 0.012962163425981998\n",
      "Loss on test= 0.012874863110482693\n",
      "acc for Lsat= 0.3286248030474457 \n",
      "acc for Psat= 0.3401272276562433 \n",
      "acc for optim= 0.2017302777578707\n",
      "Epoch:131/1000\n",
      "Loss on train= 0.012636987492442131\n",
      "Loss on test= 0.01264958456158638\n",
      "acc for Lsat= 0.3030639437062792 \n",
      "acc for Psat= 0.3437801870983649 \n",
      "acc for optim= 0.20112087733188241\n",
      "Epoch:132/1000\n",
      "Loss on train= 0.01228580716997385\n",
      "Loss on test= 0.013537539169192314\n",
      "acc for Lsat= 0.2718461517465569 \n",
      "acc for Psat= 0.4039461089736968 \n",
      "acc for optim= 0.18748014669932456\n",
      "Epoch:133/1000\n",
      "Loss on train= 0.012633439153432846\n",
      "Loss on test= 0.013148078694939613\n",
      "acc for Lsat= 0.29778398458877486 \n",
      "acc for Psat= 0.3362135699551584 \n",
      "acc for optim= 0.18311382987343122\n",
      "Epoch:134/1000\n",
      "Loss on train= 0.01176808774471283\n",
      "Loss on test= 0.01366011705249548\n",
      "acc for Lsat= 0.31791482337353894 \n",
      "acc for Psat= 0.32333191775290643 \n",
      "acc for optim= 0.20828755030781426\n",
      "Epoch:135/1000\n",
      "Loss on train= 0.012736636213958263\n",
      "Loss on test= 0.01338410098105669\n",
      "acc for Lsat= 0.3185858321035778 \n",
      "acc for Psat= 0.352287949471324 \n",
      "acc for optim= 0.2122681305603661\n",
      "Epoch:136/1000\n",
      "Loss on train= 0.01204435620456934\n",
      "Loss on test= 0.013253862969577312\n",
      "acc for Lsat= 0.2959436201829842 \n",
      "acc for Psat= 0.33379350007606384 \n",
      "acc for optim= 0.2026501960394375\n",
      "Epoch:137/1000\n",
      "Loss on train= 0.012272498570382595\n",
      "Loss on test= 0.013463112525641918\n",
      "acc for Lsat= 0.29410044857285034 \n",
      "acc for Psat= 0.3590233323215586 \n",
      "acc for optim= 0.19153676718980964\n",
      "Epoch:138/1000\n",
      "Loss on train= 0.012949030846357346\n",
      "Loss on test= 0.013791888952255249\n",
      "acc for Lsat= 0.2684764994653652 \n",
      "acc for Psat= 0.3924504615587451 \n",
      "acc for optim= 0.20147793998811553\n",
      "Epoch:139/1000\n",
      "Loss on train= 0.012280506081879139\n",
      "Loss on test= 0.013265765272080898\n",
      "acc for Lsat= 0.3373657378161886 \n",
      "acc for Psat= 0.3251719786390915 \n",
      "acc for optim= 0.18844233622510081\n",
      "Epoch:140/1000\n",
      "Loss on train= 0.012550595216453075\n",
      "Loss on test= 0.012602417729794979\n",
      "acc for Lsat= 0.2849487475251732 \n",
      "acc for Psat= 0.3345325216232657 \n",
      "acc for optim= 0.20702838609448904\n",
      "Epoch:141/1000\n",
      "Loss on train= 0.01232504565268755\n",
      "Loss on test= 0.012438214384019375\n",
      "acc for Lsat= 0.3012332469753732 \n",
      "acc for Psat= 0.33380968556764057 \n",
      "acc for optim= 0.1892201902108046\n",
      "Epoch:142/1000\n",
      "Loss on train= 0.012232445180416107\n",
      "Loss on test= 0.013702455908060074\n",
      "acc for Lsat= 0.31724285265880686 \n",
      "acc for Psat= 0.34429329005997406 \n",
      "acc for optim= 0.1859650088319263\n",
      "Epoch:143/1000\n",
      "Loss on train= 0.012083921581506729\n",
      "Loss on test= 0.013514579273760319\n",
      "acc for Lsat= 0.2788793728347489 \n",
      "acc for Psat= 0.38631605617228454 \n",
      "acc for optim= 0.2076850401494362\n",
      "Epoch:144/1000\n",
      "Loss on train= 0.0125548355281353\n",
      "Loss on test= 0.013506817631423473\n",
      "acc for Lsat= 0.3034758061154793 \n",
      "acc for Psat= 0.3416131863035104 \n",
      "acc for optim= 0.19233518054405963\n",
      "Epoch:145/1000\n",
      "Loss on train= 0.01310825627297163\n",
      "Loss on test= 0.012950367294251919\n",
      "acc for Lsat= 0.2964540623206353 \n",
      "acc for Psat= 0.3618275717366487 \n",
      "acc for optim= 0.20971056653218248\n",
      "Epoch:146/1000\n",
      "Loss on train= 0.012371211312711239\n",
      "Loss on test= 0.014460836537182331\n",
      "acc for Lsat= 0.41298151590103693 \n",
      "acc for Psat= 0.32899793707844566 \n",
      "acc for optim= 0.1903810205781572\n",
      "Epoch:147/1000\n",
      "Loss on train= 0.01285470835864544\n",
      "Loss on test= 0.013031797483563423\n",
      "acc for Lsat= 0.26286094177482744 \n",
      "acc for Psat= 0.38077813759446144 \n",
      "acc for optim= 0.20970080905296481\n",
      "Epoch:148/1000\n",
      "Loss on train= 0.011981513351202011\n",
      "Loss on test= 0.013092586770653725\n",
      "acc for Lsat= 0.307581763283026 \n",
      "acc for Psat= 0.34263630591182953 \n",
      "acc for optim= 0.19232718849365235\n",
      "Epoch:149/1000\n",
      "Loss on train= 0.01200073305517435\n",
      "Loss on test= 0.014104658737778664\n",
      "acc for Lsat= 0.2756724722446653 \n",
      "acc for Psat= 0.3880461331812065 \n",
      "acc for optim= 0.21805077226698336\n",
      "Epoch:150/1000\n",
      "Loss on train= 0.011829391121864319\n",
      "Loss on test= 0.012297678738832474\n",
      "acc for Lsat= 0.30858688744700563 \n",
      "acc for Psat= 0.3374072850909739 \n",
      "acc for optim= 0.19212233197275486\n",
      "Epoch:151/1000\n",
      "Loss on train= 0.012486166320741177\n",
      "Loss on test= 0.012637564912438393\n",
      "acc for Lsat= 0.3336677019500126 \n",
      "acc for Psat= 0.3096784140922571 \n",
      "acc for optim= 0.20711048623838982\n",
      "Epoch:152/1000\n",
      "Loss on train= 0.012488672509789467\n",
      "Loss on test= 0.01315831858664751\n",
      "acc for Lsat= 0.2770834307920314 \n",
      "acc for Psat= 0.336913474278635 \n",
      "acc for optim= 0.20571006742085063\n",
      "Epoch:153/1000\n",
      "Loss on train= 0.011856415309011936\n",
      "Loss on test= 0.012666849419474602\n",
      "acc for Lsat= 0.26821455736723493 \n",
      "acc for Psat= 0.34972840903437363 \n",
      "acc for optim= 0.1930270214576937\n",
      "Epoch:154/1000\n",
      "Loss on train= 0.012163828127086163\n",
      "Loss on test= 0.011927087791264057\n",
      "acc for Lsat= 0.2591423389765284 \n",
      "acc for Psat= 0.3215423832904011 \n",
      "acc for optim= 0.195204261812121\n",
      "Epoch:155/1000\n",
      "Loss on train= 0.011700431816279888\n",
      "Loss on test= 0.012312016449868679\n",
      "acc for Lsat= 0.26105170879173645 \n",
      "acc for Psat= 0.3424373610773897 \n",
      "acc for optim= 0.19948205667295318\n",
      "Epoch:156/1000\n",
      "Loss on train= 0.011724944226443768\n",
      "Loss on test= 0.012178592383861542\n",
      "acc for Lsat= 0.2773098071437266 \n",
      "acc for Psat= 0.30808616251155924 \n",
      "acc for optim= 0.19448453479710873\n",
      "Epoch:157/1000\n",
      "Loss on train= 0.011562403291463852\n",
      "Loss on test= 0.01284209918230772\n",
      "acc for Lsat= 0.28534796620419217 \n",
      "acc for Psat= 0.3870581673773921 \n",
      "acc for optim= 0.19549498032596974\n",
      "Epoch:158/1000\n",
      "Loss on train= 0.01183498464524746\n",
      "Loss on test= 0.012009882368147373\n",
      "acc for Lsat= 0.25916936035441646 \n",
      "acc for Psat= 0.34402195570745775 \n",
      "acc for optim= 0.194688171604885\n",
      "Epoch:159/1000\n",
      "Loss on train= 0.011714190244674683\n",
      "Loss on test= 0.012235242873430252\n",
      "acc for Lsat= 0.29101462909867704 \n",
      "acc for Psat= 0.31779811032268346 \n",
      "acc for optim= 0.19685277283463976\n",
      "Epoch:160/1000\n",
      "Loss on train= 0.011509295552968979\n",
      "Loss on test= 0.012360862456262112\n",
      "acc for Lsat= 0.2928251393762875 \n",
      "acc for Psat= 0.30873085115037335 \n",
      "acc for optim= 0.19690040141202003\n",
      "Epoch:161/1000\n",
      "Loss on train= 0.011377264745533466\n",
      "Loss on test= 0.012742490507662296\n",
      "acc for Lsat= 0.3043928272869256 \n",
      "acc for Psat= 0.3209712757401452 \n",
      "acc for optim= 0.1909333794090652\n",
      "Epoch:162/1000\n",
      "Loss on train= 0.011636977083981037\n",
      "Loss on test= 0.013347655534744263\n",
      "acc for Lsat= 0.25462163849654845 \n",
      "acc for Psat= 0.35919532059234077 \n",
      "acc for optim= 0.21741621307436756\n",
      "Epoch:163/1000\n",
      "Loss on train= 0.012216760776937008\n",
      "Loss on test= 0.013013414107263088\n",
      "acc for Lsat= 0.2958219016673264 \n",
      "acc for Psat= 0.3168850547527515 \n",
      "acc for optim= 0.19269738502374267\n",
      "Epoch:164/1000\n",
      "Loss on train= 0.011849773116409779\n",
      "Loss on test= 0.012579425238072872\n",
      "acc for Lsat= 0.30693768270361094 \n",
      "acc for Psat= 0.3380551141863334 \n",
      "acc for optim= 0.1917514893893247\n",
      "Epoch:165/1000\n",
      "Loss on train= 0.011830795556306839\n",
      "Loss on test= 0.01155235804617405\n",
      "acc for Lsat= 0.27836929351131834 \n",
      "acc for Psat= 0.2968497561780199 \n",
      "acc for optim= 0.1863604285777941\n",
      "Epoch:166/1000\n",
      "Loss on train= 0.01176244392991066\n",
      "Loss on test= 0.012405138462781906\n",
      "acc for Lsat= 0.27708868651919194 \n",
      "acc for Psat= 0.3551736891522246 \n",
      "acc for optim= 0.21311883088783362\n",
      "Epoch:167/1000\n",
      "Loss on train= 0.011949464678764343\n",
      "Loss on test= 0.011756868101656437\n",
      "acc for Lsat= 0.3036064583919666 \n",
      "acc for Psat= 0.3208991198445339 \n",
      "acc for optim= 0.19542204082935608\n",
      "Epoch:168/1000\n",
      "Loss on train= 0.012108808383345604\n",
      "Loss on test= 0.011882326565682888\n",
      "acc for Lsat= 0.2955579503336763 \n",
      "acc for Psat= 0.2898934601119451 \n",
      "acc for optim= 0.194040832003545\n",
      "Epoch:169/1000\n",
      "Loss on train= 0.01190449483692646\n",
      "Loss on test= 0.012437348254024982\n",
      "acc for Lsat= 0.25749478905207196 \n",
      "acc for Psat= 0.34661978195580234 \n",
      "acc for optim= 0.1880183595433926\n",
      "Epoch:170/1000\n",
      "Loss on train= 0.011585190892219543\n",
      "Loss on test= 0.011673499830067158\n",
      "acc for Lsat= 0.28252850308446054 \n",
      "acc for Psat= 0.304390338316986 \n",
      "acc for optim= 0.1898185916389023\n",
      "Epoch:171/1000\n",
      "Loss on train= 0.011282055638730526\n",
      "Loss on test= 0.012296122498810291\n",
      "acc for Lsat= 0.25652705669596443 \n",
      "acc for Psat= 0.3352900560057359 \n",
      "acc for optim= 0.20217688457993002\n",
      "Epoch:172/1000\n",
      "Loss on train= 0.011886641383171082\n",
      "Loss on test= 0.01269463263452053\n",
      "acc for Lsat= 0.29561938071915467 \n",
      "acc for Psat= 0.30549392265867503 \n",
      "acc for optim= 0.1989297096286032\n",
      "Epoch:173/1000\n",
      "Loss on train= 0.011460146866738796\n",
      "Loss on test= 0.011887186206877232\n",
      "acc for Lsat= 0.2658889658835922 \n",
      "acc for Psat= 0.3341895350287629 \n",
      "acc for optim= 0.19493516312369\n",
      "Epoch:174/1000\n",
      "Loss on train= 0.011639443226158619\n",
      "Loss on test= 0.01271713338792324\n",
      "acc for Lsat= 0.27097575616415087 \n",
      "acc for Psat= 0.36176265143805136 \n",
      "acc for optim= 0.22580299070223345\n",
      "Epoch:175/1000\n",
      "Loss on train= 0.011647773906588554\n",
      "Loss on test= 0.011499959975481033\n",
      "acc for Lsat= 0.2666298667604293 \n",
      "acc for Psat= 0.3227581457165859 \n",
      "acc for optim= 0.1863913359090891\n",
      "Epoch:176/1000\n",
      "Loss on train= 0.011216679587960243\n",
      "Loss on test= 0.011861803941428661\n",
      "acc for Lsat= 0.2781931075314849 \n",
      "acc for Psat= 0.30209019074909055 \n",
      "acc for optim= 0.19320014643214517\n",
      "Epoch:177/1000\n",
      "Loss on train= 0.011413153260946274\n",
      "Loss on test= 0.011682271026074886\n",
      "acc for Lsat= 0.28244079257760163 \n",
      "acc for Psat= 0.279326050302953 \n",
      "acc for optim= 0.19159324674598746\n",
      "Epoch:178/1000\n",
      "Loss on train= 0.011173714883625507\n",
      "Loss on test= 0.012310395948588848\n",
      "acc for Lsat= 0.27517253886415005 \n",
      "acc for Psat= 0.2934816270727285 \n",
      "acc for optim= 0.1989949505192117\n",
      "Epoch:179/1000\n",
      "Loss on train= 0.011041872203350067\n",
      "Loss on test= 0.01183676440268755\n",
      "acc for Lsat= 0.25162666866756084 \n",
      "acc for Psat= 0.3391894781711448 \n",
      "acc for optim= 0.19089823502482908\n",
      "Epoch:180/1000\n",
      "Loss on train= 0.011247610673308372\n",
      "Loss on test= 0.011633176356554031\n",
      "acc for Lsat= 0.26655832623660375 \n",
      "acc for Psat= 0.318374904961783 \n",
      "acc for optim= 0.18077263929545723\n",
      "Epoch:181/1000\n",
      "Loss on train= 0.011775377206504345\n",
      "Loss on test= 0.01179081853479147\n",
      "acc for Lsat= 0.2699664185212341 \n",
      "acc for Psat= 0.32281824572513007 \n",
      "acc for optim= 0.203616645014687\n",
      "Epoch:182/1000\n",
      "Loss on train= 0.011437461711466312\n",
      "Loss on test= 0.012067057192325592\n",
      "acc for Lsat= 0.24885664687341993 \n",
      "acc for Psat= 0.3432202100294042 \n",
      "acc for optim= 0.18189638194695146\n",
      "Epoch:183/1000\n",
      "Loss on train= 0.01180903147906065\n",
      "Loss on test= 0.01144140213727951\n",
      "acc for Lsat= 0.2867301147407457 \n",
      "acc for Psat= 0.31239208632219834 \n",
      "acc for optim= 0.19338519485880448\n",
      "Epoch:184/1000\n",
      "Loss on train= 0.011380488984286785\n",
      "Loss on test= 0.01182805560529232\n",
      "acc for Lsat= 0.30102124340325137 \n",
      "acc for Psat= 0.28212091812579815 \n",
      "acc for optim= 0.18818255379989396\n",
      "Epoch:185/1000\n",
      "Loss on train= 0.011428983882069588\n",
      "Loss on test= 0.013085400685667992\n",
      "acc for Lsat= 0.258146849927745 \n",
      "acc for Psat= 0.3949604170227234 \n",
      "acc for optim= 0.2196151574076177\n",
      "Epoch:186/1000\n",
      "Loss on train= 0.011932892724871635\n",
      "Loss on test= 0.012453373521566391\n",
      "acc for Lsat= 0.32701422571465055 \n",
      "acc for Psat= 0.29292490092911205 \n",
      "acc for optim= 0.18819434724578443\n",
      "Epoch:187/1000\n",
      "Loss on train= 0.011273992247879505\n",
      "Loss on test= 0.011456457898020744\n",
      "acc for Lsat= 0.26379083377403856 \n",
      "acc for Psat= 0.30239573314098317 \n",
      "acc for optim= 0.20650869662524693\n",
      "Epoch:188/1000\n",
      "Loss on train= 0.011219548992812634\n",
      "Loss on test= 0.010784963145852089\n",
      "acc for Lsat= 0.23759550189962453 \n",
      "acc for Psat= 0.2919269964674594 \n",
      "acc for optim= 0.191431141182212\n",
      "Epoch:189/1000\n",
      "Loss on train= 0.010972263291478157\n",
      "Loss on test= 0.011171257123351097\n",
      "acc for Lsat= 0.2558992952329375 \n",
      "acc for Psat= 0.28930585750721993 \n",
      "acc for optim= 0.18768862645828432\n",
      "Epoch:190/1000\n",
      "Loss on train= 0.010856479406356812\n",
      "Loss on test= 0.010970581322908401\n",
      "acc for Lsat= 0.2742704958236634 \n",
      "acc for Psat= 0.3037662533601209 \n",
      "acc for optim= 0.1946457525774426\n",
      "Epoch:191/1000\n",
      "Loss on train= 0.011063864454627037\n",
      "Loss on test= 0.012313717044889927\n",
      "acc for Lsat= 0.3265917353197869 \n",
      "acc for Psat= 0.3027451990823404 \n",
      "acc for optim= 0.18645175146126441\n",
      "Epoch:192/1000\n",
      "Loss on train= 0.011300483718514442\n",
      "Loss on test= 0.012470764108002186\n",
      "acc for Lsat= 0.25867702030513623 \n",
      "acc for Psat= 0.3314927472734934 \n",
      "acc for optim= 0.1929134608462445\n",
      "Epoch:193/1000\n",
      "Loss on train= 0.01095182541757822\n",
      "Loss on test= 0.011354057118296623\n",
      "acc for Lsat= 0.25521543439027805 \n",
      "acc for Psat= 0.29036303952620446 \n",
      "acc for optim= 0.1861356032442033\n",
      "Epoch:194/1000\n",
      "Loss on train= 0.011262446641921997\n",
      "Loss on test= 0.011091567575931549\n",
      "acc for Lsat= 0.24446099249811812 \n",
      "acc for Psat= 0.3076106701906518 \n",
      "acc for optim= 0.18682981234505552\n",
      "Epoch:195/1000\n",
      "Loss on train= 0.010905054397881031\n",
      "Loss on test= 0.010907857678830624\n",
      "acc for Lsat= 0.265355397617618 \n",
      "acc for Psat= 0.28787283570122707 \n",
      "acc for optim= 0.1917715160791778\n",
      "Epoch:196/1000\n",
      "Loss on train= 0.01037456002086401\n",
      "Loss on test= 0.011108646169304848\n",
      "acc for Lsat= 0.24393217924457453 \n",
      "acc for Psat= 0.31533468255331204 \n",
      "acc for optim= 0.18380697997448714\n",
      "Epoch:197/1000\n",
      "Loss on train= 0.011583956889808178\n",
      "Loss on test= 0.011402255855500698\n",
      "acc for Lsat= 0.2568203876398788 \n",
      "acc for Psat= 0.3125866209654043 \n",
      "acc for optim= 0.19954405883810547\n",
      "Epoch:198/1000\n",
      "Loss on train= 0.011395709589123726\n",
      "Loss on test= 0.012280079536139965\n",
      "acc for Lsat= 0.33281440117181343 \n",
      "acc for Psat= 0.29170820261509617 \n",
      "acc for optim= 0.19237627806274543\n",
      "Epoch:199/1000\n",
      "Loss on train= 0.01139615848660469\n",
      "Loss on test= 0.012248797342181206\n",
      "acc for Lsat= 0.25726083987020054 \n",
      "acc for Psat= 0.3533620241372373 \n",
      "acc for optim= 0.19308794749904645\n",
      "Epoch:200/1000\n",
      "Loss on train= 0.011400388553738594\n",
      "Loss on test= 0.010865059681236744\n",
      "acc for Lsat= 0.2547590109653834 \n",
      "acc for Psat= 0.29351422374252173 \n",
      "acc for optim= 0.2022485499159271\n",
      "Epoch:201/1000\n",
      "Loss on train= 0.010686560533940792\n",
      "Loss on test= 0.01158303115516901\n",
      "acc for Lsat= 0.29610369644010387 \n",
      "acc for Psat= 0.27876606509543295 \n",
      "acc for optim= 0.18553694738213258\n",
      "Epoch:202/1000\n",
      "Loss on train= 0.01155784446746111\n",
      "Loss on test= 0.01266320887953043\n",
      "acc for Lsat= 0.2468945141052985 \n",
      "acc for Psat= 0.3561412599821717 \n",
      "acc for optim= 0.1987726122468426\n",
      "Epoch:203/1000\n",
      "Loss on train= 0.011132908053696156\n",
      "Loss on test= 0.0111250514164567\n",
      "acc for Lsat= 0.2450207227635813 \n",
      "acc for Psat= 0.3316661238054729 \n",
      "acc for optim= 0.194194992626149\n",
      "Epoch:204/1000\n",
      "Loss on train= 0.010825511999428272\n",
      "Loss on test= 0.010711518116295338\n",
      "acc for Lsat= 0.22780004454445157 \n",
      "acc for Psat= 0.29685498883284756 \n",
      "acc for optim= 0.19633817465949244\n",
      "Epoch:205/1000\n",
      "Loss on train= 0.010766088962554932\n",
      "Loss on test= 0.010788332670927048\n",
      "acc for Lsat= 0.2657344010684213 \n",
      "acc for Psat= 0.271904948200257 \n",
      "acc for optim= 0.19038053911802816\n",
      "Epoch:206/1000\n",
      "Loss on train= 0.010817104950547218\n",
      "Loss on test= 0.011649184860289097\n",
      "acc for Lsat= 0.3268758830602549 \n",
      "acc for Psat= 0.288813823523369 \n",
      "acc for optim= 0.20100844349293828\n",
      "Epoch:207/1000\n",
      "Loss on train= 0.010906322859227657\n",
      "Loss on test= 0.011126259341835976\n",
      "acc for Lsat= 0.28596720967867995 \n",
      "acc for Psat= 0.2827205003060645 \n",
      "acc for optim= 0.18546882509747203\n",
      "Epoch:208/1000\n",
      "Loss on train= 0.010642250068485737\n",
      "Loss on test= 0.011278277263045311\n",
      "acc for Lsat= 0.249182032704525 \n",
      "acc for Psat= 0.25330358410108106 \n",
      "acc for optim= 0.20375977584350285\n",
      "Epoch:209/1000\n",
      "Loss on train= 0.010860849171876907\n",
      "Loss on test= 0.011267157271504402\n",
      "acc for Lsat= 0.2616780713589278 \n",
      "acc for Psat= 0.327691857516371 \n",
      "acc for optim= 0.18071117991960403\n",
      "Epoch:210/1000\n",
      "Loss on train= 0.010492179542779922\n",
      "Loss on test= 0.011471438221633434\n",
      "acc for Lsat= 0.2549699095559259 \n",
      "acc for Psat= 0.3218986034466317 \n",
      "acc for optim= 0.19777147518628735\n",
      "Epoch:211/1000\n",
      "Loss on train= 0.010499457828700542\n",
      "Loss on test= 0.010457360185682774\n",
      "acc for Lsat= 0.2325869016649233 \n",
      "acc for Psat= 0.30425845294994974 \n",
      "acc for optim= 0.1909147250371338\n",
      "Epoch:212/1000\n",
      "Loss on train= 0.010437012650072575\n",
      "Loss on test= 0.01074223592877388\n",
      "acc for Lsat= 0.2473917751501993 \n",
      "acc for Psat= 0.29316989806780624 \n",
      "acc for optim= 0.1883447030906825\n",
      "Epoch:213/1000\n",
      "Loss on train= 0.010507072322070599\n",
      "Loss on test= 0.010498478077352047\n",
      "acc for Lsat= 0.24350510639058606 \n",
      "acc for Psat= 0.2721803899743926 \n",
      "acc for optim= 0.18775777252740228\n",
      "Epoch:214/1000\n",
      "Loss on train= 0.010581332258880138\n",
      "Loss on test= 0.011085943318903446\n",
      "acc for Lsat= 0.22676206649659927 \n",
      "acc for Psat= 0.30648954121743216 \n",
      "acc for optim= 0.18452978200339357\n",
      "Epoch:215/1000\n",
      "Loss on train= 0.010704872198402882\n",
      "Loss on test= 0.010640564374625683\n",
      "acc for Lsat= 0.2570989790269947 \n",
      "acc for Psat= 0.2881067108207035 \n",
      "acc for optim= 0.184882490997108\n",
      "Epoch:216/1000\n",
      "Loss on train= 0.010826725512742996\n",
      "Loss on test= 0.010920921340584755\n",
      "acc for Lsat= 0.24012925681294045 \n",
      "acc for Psat= 0.2725663376940509 \n",
      "acc for optim= 0.18208841179237084\n",
      "Epoch:217/1000\n",
      "Loss on train= 0.01086881011724472\n",
      "Loss on test= 0.011241759173572063\n",
      "acc for Lsat= 0.2599859332549386 \n",
      "acc for Psat= 0.30846014656244886 \n",
      "acc for optim= 0.20457637736700096\n",
      "Epoch:218/1000\n",
      "Loss on train= 0.0105528449639678\n",
      "Loss on test= 0.011087573133409023\n",
      "acc for Lsat= 0.26159016951737074 \n",
      "acc for Psat= 0.2864858998404027 \n",
      "acc for optim= 0.18260347852680706\n",
      "Epoch:219/1000\n",
      "Loss on train= 0.010498029179871082\n",
      "Loss on test= 0.010349377058446407\n",
      "acc for Lsat= 0.23703353091348278 \n",
      "acc for Psat= 0.28877906204183595 \n",
      "acc for optim= 0.19435116205822234\n",
      "Epoch:220/1000\n",
      "Loss on train= 0.010321803390979767\n",
      "Loss on test= 0.01091716531664133\n",
      "acc for Lsat= 0.245348466774725 \n",
      "acc for Psat= 0.29845203920977853 \n",
      "acc for optim= 0.18094680547532704\n",
      "Epoch:221/1000\n",
      "Loss on train= 0.01095484383404255\n",
      "Loss on test= 0.011987259611487389\n",
      "acc for Lsat= 0.23935960305112777 \n",
      "acc for Psat= 0.36510009592432546 \n",
      "acc for optim= 0.23100522100941231\n",
      "Epoch:222/1000\n",
      "Loss on train= 0.011190514080226421\n",
      "Loss on test= 0.010687627829611301\n",
      "acc for Lsat= 0.25561925414032144 \n",
      "acc for Psat= 0.2571823929466102 \n",
      "acc for optim= 0.18849016480992342\n",
      "Epoch:223/1000\n",
      "Loss on train= 0.010062376968562603\n",
      "Loss on test= 0.010652040131390095\n",
      "acc for Lsat= 0.22688323259390633 \n",
      "acc for Psat= 0.2556729595289345 \n",
      "acc for optim= 0.19036571477851594\n",
      "Epoch:224/1000\n",
      "Loss on train= 0.0101205138489604\n",
      "Loss on test= 0.010387488640844822\n",
      "acc for Lsat= 0.24021156350687398 \n",
      "acc for Psat= 0.2648847178177182 \n",
      "acc for optim= 0.1833752563298222\n",
      "Epoch:225/1000\n",
      "Loss on train= 0.010086036287248135\n",
      "Loss on test= 0.012387532740831375\n",
      "acc for Lsat= 0.3325687892439033 \n",
      "acc for Psat= 0.2568217476472748 \n",
      "acc for optim= 0.199916741366511\n",
      "Epoch:226/1000\n",
      "Loss on train= 0.010815910995006561\n",
      "Loss on test= 0.011777402833104134\n",
      "acc for Lsat= 0.2402559508269621 \n",
      "acc for Psat= 0.31881570564740797 \n",
      "acc for optim= 0.19600812307464244\n",
      "Epoch:227/1000\n",
      "Loss on train= 0.010320070199668407\n",
      "Loss on test= 0.010685371235013008\n",
      "acc for Lsat= 0.2783146730016412 \n",
      "acc for Psat= 0.27738720276688966 \n",
      "acc for optim= 0.18804578912894288\n",
      "Epoch:228/1000\n",
      "Loss on train= 0.010929026640951633\n",
      "Loss on test= 0.011063188314437866\n",
      "acc for Lsat= 0.24056533976927622 \n",
      "acc for Psat= 0.3435486156880161 \n",
      "acc for optim= 0.1903971841039878\n",
      "Epoch:229/1000\n",
      "Loss on train= 0.010189213789999485\n",
      "Loss on test= 0.011327291838824749\n",
      "acc for Lsat= 0.2266944538711144 \n",
      "acc for Psat= 0.3374449369690965 \n",
      "acc for optim= 0.20124053037567538\n",
      "Epoch:230/1000\n",
      "Loss on train= 0.010397267527878284\n",
      "Loss on test= 0.010185755789279938\n",
      "acc for Lsat= 0.2449125424252381 \n",
      "acc for Psat= 0.27546664053511066 \n",
      "acc for optim= 0.18484603272636532\n",
      "Epoch:231/1000\n",
      "Loss on train= 0.010478340089321136\n",
      "Loss on test= 0.010735961608588696\n",
      "acc for Lsat= 0.2347862736704775 \n",
      "acc for Psat= 0.30441388928723473 \n",
      "acc for optim= 0.1911202279452266\n",
      "Epoch:232/1000\n",
      "Loss on train= 0.009810852818191051\n",
      "Loss on test= 0.010331481695175171\n",
      "acc for Lsat= 0.27172026484294587 \n",
      "acc for Psat= 0.2815237619743931 \n",
      "acc for optim= 0.19089903606938483\n",
      "Epoch:233/1000\n",
      "Loss on train= 0.009979325346648693\n",
      "Loss on test= 0.01103579718619585\n",
      "acc for Lsat= 0.24507729478172516 \n",
      "acc for Psat= 0.3447389174229071 \n",
      "acc for optim= 0.18137502163861705\n",
      "Epoch:234/1000\n",
      "Loss on train= 0.011203626170754433\n",
      "Loss on test= 0.012978780083358288\n",
      "acc for Lsat= 0.33558859830698534 \n",
      "acc for Psat= 0.30329199475976165 \n",
      "acc for optim= 0.1905289883114658\n",
      "Epoch:235/1000\n",
      "Loss on train= 0.010803930461406708\n",
      "Loss on test= 0.010843811556696892\n",
      "acc for Lsat= 0.20875757025141403 \n",
      "acc for Psat= 0.3203899614729966 \n",
      "acc for optim= 0.19181472368191108\n",
      "Epoch:236/1000\n",
      "Loss on train= 0.010976821184158325\n",
      "Loss on test= 0.01070408709347248\n",
      "acc for Lsat= 0.24725259319421347 \n",
      "acc for Psat= 0.2500584933450998 \n",
      "acc for optim= 0.19871368367803063\n",
      "Epoch:237/1000\n",
      "Loss on train= 0.01015698816627264\n",
      "Loss on test= 0.009967978112399578\n",
      "acc for Lsat= 0.242717898288205 \n",
      "acc for Psat= 0.2676620646636396 \n",
      "acc for optim= 0.18274354186477298\n",
      "Epoch:238/1000\n",
      "Loss on train= 0.010624634101986885\n",
      "Loss on test= 0.01104339025914669\n",
      "acc for Lsat= 0.21432151569495514 \n",
      "acc for Psat= 0.31862354408712834 \n",
      "acc for optim= 0.2014000171233142\n",
      "Epoch:239/1000\n",
      "Loss on train= 0.009985600598156452\n",
      "Loss on test= 0.01144874095916748\n",
      "acc for Lsat= 0.2617933872098624 \n",
      "acc for Psat= 0.26130069990295096 \n",
      "acc for optim= 0.1891391668249695\n",
      "Epoch:240/1000\n",
      "Loss on train= 0.010112653486430645\n",
      "Loss on test= 0.010301081463694572\n",
      "acc for Lsat= 0.2368315003559751 \n",
      "acc for Psat= 0.2728551531131616 \n",
      "acc for optim= 0.18662876978879636\n",
      "Epoch:241/1000\n",
      "Loss on train= 0.009908439591526985\n",
      "Loss on test= 0.010654968209564686\n",
      "acc for Lsat= 0.23157174410515513 \n",
      "acc for Psat= 0.30924485557657366 \n",
      "acc for optim= 0.18383521566727845\n",
      "Epoch:242/1000\n",
      "Loss on train= 0.010212224908173084\n",
      "Loss on test= 0.010632805526256561\n",
      "acc for Lsat= 0.27442841776646676 \n",
      "acc for Psat= 0.25480150809961416 \n",
      "acc for optim= 0.1950106792333457\n",
      "Epoch:243/1000\n",
      "Loss on train= 0.009915396571159363\n",
      "Loss on test= 0.009991991333663464\n",
      "acc for Lsat= 0.2263439804419157 \n",
      "acc for Psat= 0.24801699492776513 \n",
      "acc for optim= 0.18454954429288883\n",
      "Epoch:244/1000\n",
      "Loss on train= 0.009696525521576405\n",
      "Loss on test= 0.011468445882201195\n",
      "acc for Lsat= 0.23094531821039646 \n",
      "acc for Psat= 0.32815556587808054 \n",
      "acc for optim= 0.1907928905485324\n",
      "Epoch:245/1000\n",
      "Loss on train= 0.009819066151976585\n",
      "Loss on test= 0.010993419215083122\n",
      "acc for Lsat= 0.30911086678141886 \n",
      "acc for Psat= 0.2799178957141999 \n",
      "acc for optim= 0.18952850673458208\n",
      "Epoch:246/1000\n",
      "Loss on train= 0.00991775281727314\n",
      "Loss on test= 0.009680146351456642\n",
      "acc for Lsat= 0.22047643947900447 \n",
      "acc for Psat= 0.2510283665646211 \n",
      "acc for optim= 0.18860959983430803\n",
      "Epoch:247/1000\n",
      "Loss on train= 0.009896181523799896\n",
      "Loss on test= 0.01055097859352827\n",
      "acc for Lsat= 0.23866028029341407 \n",
      "acc for Psat= 0.2862230687883635 \n",
      "acc for optim= 0.1928983025907902\n",
      "Epoch:248/1000\n",
      "Loss on train= 0.010212164372205734\n",
      "Loss on test= 0.009805213660001755\n",
      "acc for Lsat= 0.23212669667495825 \n",
      "acc for Psat= 0.24617384258634017 \n",
      "acc for optim= 0.18052357175876782\n",
      "Epoch:249/1000\n",
      "Loss on train= 0.010409427806735039\n",
      "Loss on test= 0.010107637383043766\n",
      "acc for Lsat= 0.21487371212629192 \n",
      "acc for Psat= 0.2893107177881559 \n",
      "acc for optim= 0.1851544199471946\n",
      "Epoch:250/1000\n",
      "Loss on train= 0.009630825370550156\n",
      "Loss on test= 0.010213383473455906\n",
      "acc for Lsat= 0.2483277419005112 \n",
      "acc for Psat= 0.25374825973245235 \n",
      "acc for optim= 0.19102639985656547\n",
      "Epoch:251/1000\n",
      "Loss on train= 0.00997713953256607\n",
      "Loss on test= 0.010008761659264565\n",
      "acc for Lsat= 0.22458127889332313 \n",
      "acc for Psat= 0.27537039098935595 \n",
      "acc for optim= 0.18582025620912723\n",
      "Epoch:252/1000\n",
      "Loss on train= 0.009858720935881138\n",
      "Loss on test= 0.009926199913024902\n",
      "acc for Lsat= 0.22872458181355812 \n",
      "acc for Psat= 0.2524375713079126 \n",
      "acc for optim= 0.19700093739587118\n",
      "Epoch:253/1000\n",
      "Loss on train= 0.009370517916977406\n",
      "Loss on test= 0.009434204548597336\n",
      "acc for Lsat= 0.22617653069062696 \n",
      "acc for Psat= 0.23605497486502627 \n",
      "acc for optim= 0.18218381438222792\n",
      "Epoch:254/1000\n",
      "Loss on train= 0.00951717235147953\n",
      "Loss on test= 0.010452724993228912\n",
      "acc for Lsat= 0.21777457245053344 \n",
      "acc for Psat= 0.3008613590522022 \n",
      "acc for optim= 0.19688193671319237\n",
      "Epoch:255/1000\n",
      "Loss on train= 0.009742481634020805\n",
      "Loss on test= 0.009726496413350105\n",
      "acc for Lsat= 0.21312387258729945 \n",
      "acc for Psat= 0.24698600601404905 \n",
      "acc for optim= 0.1843406485918499\n",
      "Epoch:256/1000\n",
      "Loss on train= 0.00941549427807331\n",
      "Loss on test= 0.009575665928423405\n",
      "acc for Lsat= 0.22107387948820714 \n",
      "acc for Psat= 0.27401764950896534 \n",
      "acc for optim= 0.20264929335108578\n",
      "Epoch:257/1000\n",
      "Loss on train= 0.009441704489290714\n",
      "Loss on test= 0.009484724141657352\n",
      "acc for Lsat= 0.20433975278668232 \n",
      "acc for Psat= 0.26027545335079083 \n",
      "acc for optim= 0.1899029533084782\n",
      "Epoch:258/1000\n",
      "Loss on train= 0.00909917801618576\n",
      "Loss on test= 0.009589103981852531\n",
      "acc for Lsat= 0.22187930294430924 \n",
      "acc for Psat= 0.2580587938712057 \n",
      "acc for optim= 0.19007780704552593\n",
      "Epoch:259/1000\n",
      "Loss on train= 0.009353461675345898\n",
      "Loss on test= 0.010125880129635334\n",
      "acc for Lsat= 0.262941576230687 \n",
      "acc for Psat= 0.23731812864928742 \n",
      "acc for optim= 0.18187045173530103\n",
      "Epoch:260/1000\n",
      "Loss on train= 0.010183063335716724\n",
      "Loss on test= 0.010439918376505375\n",
      "acc for Lsat= 0.2080295103722473 \n",
      "acc for Psat= 0.321205012580001 \n",
      "acc for optim= 0.19787086868674447\n",
      "Epoch:261/1000\n",
      "Loss on train= 0.009653937071561813\n",
      "Loss on test= 0.009344968944787979\n",
      "acc for Lsat= 0.20083871197909148 \n",
      "acc for Psat= 0.25795688282548435 \n",
      "acc for optim= 0.18547105707920755\n",
      "Epoch:262/1000\n",
      "Loss on train= 0.009268069639801979\n",
      "Loss on test= 0.00970506016165018\n",
      "acc for Lsat= 0.2300208000813747 \n",
      "acc for Psat= 0.23673195190790852 \n",
      "acc for optim= 0.19133732888523994\n",
      "Epoch:263/1000\n",
      "Loss on train= 0.009682873263955116\n",
      "Loss on test= 0.009526620618999004\n",
      "acc for Lsat= 0.21509876004913506 \n",
      "acc for Psat= 0.29022715657444326 \n",
      "acc for optim= 0.19785752245797222\n",
      "Epoch:264/1000\n",
      "Loss on train= 0.010157467797398567\n",
      "Loss on test= 0.012358151376247406\n",
      "acc for Lsat= 0.3365273424708363 \n",
      "acc for Psat= 0.2668277565520099 \n",
      "acc for optim= 0.18265650487195118\n",
      "Epoch:265/1000\n",
      "Loss on train= 0.010110979899764061\n",
      "Loss on test= 0.010875768028199673\n",
      "acc for Lsat= 0.21575439360655718 \n",
      "acc for Psat= 0.33623915537461735 \n",
      "acc for optim= 0.18620752719688718\n",
      "Epoch:266/1000\n",
      "Loss on train= 0.009574290364980698\n",
      "Loss on test= 0.009986363351345062\n",
      "acc for Lsat= 0.23827081467301223 \n",
      "acc for Psat= 0.25436251280223554 \n",
      "acc for optim= 0.19693214430925593\n",
      "Epoch:267/1000\n",
      "Loss on train= 0.009401805698871613\n",
      "Loss on test= 0.009430806152522564\n",
      "acc for Lsat= 0.20844894092168928 \n",
      "acc for Psat= 0.28707197823895186 \n",
      "acc for optim= 0.18135179852222297\n",
      "Epoch:268/1000\n",
      "Loss on train= 0.009408573620021343\n",
      "Loss on test= 0.010122557170689106\n",
      "acc for Lsat= 0.23971969957258238 \n",
      "acc for Psat= 0.25484756936804565 \n",
      "acc for optim= 0.2119513437783314\n",
      "Epoch:269/1000\n",
      "Loss on train= 0.009544732980430126\n",
      "Loss on test= 0.00964195467531681\n",
      "acc for Lsat= 0.2124293866669917 \n",
      "acc for Psat= 0.2860653991005936 \n",
      "acc for optim= 0.1869215268876514\n",
      "Epoch:270/1000\n",
      "Loss on train= 0.009182224050164223\n",
      "Loss on test= 0.009066527709364891\n",
      "acc for Lsat= 0.21063624035647943 \n",
      "acc for Psat= 0.2382459624684258 \n",
      "acc for optim= 0.18312615709718696\n",
      "Epoch:271/1000\n",
      "Loss on train= 0.009077902883291245\n",
      "Loss on test= 0.009352974593639374\n",
      "acc for Lsat= 0.20237514786239738 \n",
      "acc for Psat= 0.2609196814755767 \n",
      "acc for optim= 0.1831857436462858\n",
      "Epoch:272/1000\n",
      "Loss on train= 0.008980769664049149\n",
      "Loss on test= 0.008924435824155807\n",
      "acc for Lsat= 0.21953111353672655 \n",
      "acc for Psat= 0.2300162116843039 \n",
      "acc for optim= 0.18969934012314651\n",
      "Epoch:273/1000\n",
      "Loss on train= 0.0090479152277112\n",
      "Loss on test= 0.00914356391876936\n",
      "acc for Lsat= 0.22034273833210058 \n",
      "acc for Psat= 0.245874823801914 \n",
      "acc for optim= 0.17884200516046356\n",
      "Epoch:274/1000\n",
      "Loss on train= 0.008814829401671886\n",
      "Loss on test= 0.009744955226778984\n",
      "acc for Lsat= 0.19260178132237835 \n",
      "acc for Psat= 0.26438292404952446 \n",
      "acc for optim= 0.20975658941305622\n",
      "Epoch:275/1000\n",
      "Loss on train= 0.009149480611085892\n",
      "Loss on test= 0.009711210615932941\n",
      "acc for Lsat= 0.21229538920067123 \n",
      "acc for Psat= 0.2317150790260126 \n",
      "acc for optim= 0.19670443452689482\n",
      "Epoch:276/1000\n",
      "Loss on train= 0.009212091565132141\n",
      "Loss on test= 0.009754616767168045\n",
      "acc for Lsat= 0.19714272515611503 \n",
      "acc for Psat= 0.25118982073697027 \n",
      "acc for optim= 0.18165226054172648\n",
      "Epoch:277/1000\n",
      "Loss on train= 0.009464533999562263\n",
      "Loss on test= 0.009646117687225342\n",
      "acc for Lsat= 0.20985261766260718 \n",
      "acc for Psat= 0.2589740709385882 \n",
      "acc for optim= 0.21105141479885048\n",
      "Epoch:278/1000\n",
      "Loss on train= 0.009089652448892593\n",
      "Loss on test= 0.009156930260360241\n",
      "acc for Lsat= 0.19570651963368943 \n",
      "acc for Psat= 0.24152519419995014 \n",
      "acc for optim= 0.19576972722020633\n",
      "Epoch:279/1000\n",
      "Loss on train= 0.009116212837398052\n",
      "Loss on test= 0.00890098512172699\n",
      "acc for Lsat= 0.1916977870972606 \n",
      "acc for Psat= 0.23573668057935596 \n",
      "acc for optim= 0.1833605182057215\n",
      "Epoch:280/1000\n",
      "Loss on train= 0.009194063022732735\n",
      "Loss on test= 0.009090669453144073\n",
      "acc for Lsat= 0.19393266094414421 \n",
      "acc for Psat= 0.23444179966603676 \n",
      "acc for optim= 0.1827014643064566\n",
      "Epoch:281/1000\n",
      "Loss on train= 0.008914944715797901\n",
      "Loss on test= 0.009860903955996037\n",
      "acc for Lsat= 0.21708782195109652 \n",
      "acc for Psat= 0.23483243625496625 \n",
      "acc for optim= 0.18210446556410514\n",
      "Epoch:282/1000\n",
      "Loss on train= 0.008889672346413136\n",
      "Loss on test= 0.009173968806862831\n",
      "acc for Lsat= 0.19707809186444847 \n",
      "acc for Psat= 0.24635133644984245 \n",
      "acc for optim= 0.18648043565562594\n",
      "Epoch:283/1000\n",
      "Loss on train= 0.008822325617074966\n",
      "Loss on test= 0.010348603129386902\n",
      "acc for Lsat= 0.20469956907169434 \n",
      "acc for Psat= 0.3372334200131186 \n",
      "acc for optim= 0.18678430225779066\n",
      "Epoch:284/1000\n",
      "Loss on train= 0.00894104689359665\n",
      "Loss on test= 0.009088019840419292\n",
      "acc for Lsat= 0.20360756903823654 \n",
      "acc for Psat= 0.23150557743748493 \n",
      "acc for optim= 0.18668970731402731\n",
      "Epoch:285/1000\n",
      "Loss on train= 0.008610752411186695\n",
      "Loss on test= 0.009098867885768414\n",
      "acc for Lsat= 0.2038102092118776 \n",
      "acc for Psat= 0.26196803925460266 \n",
      "acc for optim= 0.18601545848216766\n",
      "Epoch:286/1000\n",
      "Loss on train= 0.009061779826879501\n",
      "Loss on test= 0.009381722658872604\n",
      "acc for Lsat= 0.2402777947473608 \n",
      "acc for Psat= 0.24123838104199005 \n",
      "acc for optim= 0.1836782603435834\n",
      "Epoch:287/1000\n",
      "Loss on train= 0.008968740701675415\n",
      "Loss on test= 0.008814206346869469\n",
      "acc for Lsat= 0.22077591763848786 \n",
      "acc for Psat= 0.22420142408562982 \n",
      "acc for optim= 0.1867998895633934\n",
      "Epoch:288/1000\n",
      "Loss on train= 0.009006157517433167\n",
      "Loss on test= 0.00908966176211834\n",
      "acc for Lsat= 0.2006416923701921 \n",
      "acc for Psat= 0.2586968332390516 \n",
      "acc for optim= 0.18267175861776766\n",
      "Epoch:289/1000\n",
      "Loss on train= 0.009127824567258358\n",
      "Loss on test= 0.008934099227190018\n",
      "acc for Lsat= 0.20651376784968553 \n",
      "acc for Psat= 0.22388936298883566 \n",
      "acc for optim= 0.183109768088394\n",
      "Epoch:290/1000\n",
      "Loss on train= 0.008812646381556988\n",
      "Loss on test= 0.008459200151264668\n",
      "acc for Lsat= 0.2061354065535667 \n",
      "acc for Psat= 0.23246325879847093 \n",
      "acc for optim= 0.19012753555049994\n",
      "Epoch:291/1000\n",
      "Loss on train= 0.00891148578375578\n",
      "Loss on test= 0.01063451636582613\n",
      "acc for Lsat= 0.20192085423041134 \n",
      "acc for Psat= 0.32913857022008336 \n",
      "acc for optim= 0.20718344365862215\n",
      "Epoch:292/1000\n",
      "Loss on train= 0.009657738730311394\n",
      "Loss on test= 0.009690186008810997\n",
      "acc for Lsat= 0.2247295237651442 \n",
      "acc for Psat= 0.22307810096890998 \n",
      "acc for optim= 0.17845313307292507\n",
      "Epoch:293/1000\n",
      "Loss on train= 0.008626199327409267\n",
      "Loss on test= 0.008934436365962029\n",
      "acc for Lsat= 0.1859902662272423 \n",
      "acc for Psat= 0.23834111082596485 \n",
      "acc for optim= 0.19623403203477827\n",
      "Epoch:294/1000\n",
      "Loss on train= 0.00840547401458025\n",
      "Loss on test= 0.00892249308526516\n",
      "acc for Lsat= 0.19768201234726773 \n",
      "acc for Psat= 0.24902083199368633 \n",
      "acc for optim= 0.18593918468854162\n",
      "Epoch:295/1000\n",
      "Loss on train= 0.008506843820214272\n",
      "Loss on test= 0.008816782385110855\n",
      "acc for Lsat= 0.19440963367575886 \n",
      "acc for Psat= 0.24174251312279474 \n",
      "acc for optim= 0.18645340291362936\n",
      "Epoch:296/1000\n",
      "Loss on train= 0.008711746893823147\n",
      "Loss on test= 0.008343941532075405\n",
      "acc for Lsat= 0.19815145829629344 \n",
      "acc for Psat= 0.22451374759152481 \n",
      "acc for optim= 0.18618482477978757\n",
      "Epoch:297/1000\n",
      "Loss on train= 0.008399936370551586\n",
      "Loss on test= 0.008690680377185345\n",
      "acc for Lsat= 0.19486643289767355 \n",
      "acc for Psat= 0.22603348838086476 \n",
      "acc for optim= 0.18818796495096787\n",
      "Epoch:298/1000\n",
      "Loss on train= 0.008415285497903824\n",
      "Loss on test= 0.00889473408460617\n",
      "acc for Lsat= 0.18963383382632223 \n",
      "acc for Psat= 0.2233298242969194 \n",
      "acc for optim= 0.1844793633261885\n",
      "Epoch:299/1000\n",
      "Loss on train= 0.008135849609971046\n",
      "Loss on test= 0.008567326702177525\n",
      "acc for Lsat= 0.1809177660955495 \n",
      "acc for Psat= 0.23853118269126153 \n",
      "acc for optim= 0.18301455420205148\n",
      "Epoch:300/1000\n",
      "Loss on train= 0.008118832483887672\n",
      "Loss on test= 0.008317379280924797\n",
      "acc for Lsat= 0.17107001712222158 \n",
      "acc for Psat= 0.20222559224348516 \n",
      "acc for optim= 0.18548779626760703\n",
      "Epoch:301/1000\n",
      "Loss on train= 0.007901701144874096\n",
      "Loss on test= 0.00828690268099308\n",
      "acc for Lsat= 0.1961680945229985 \n",
      "acc for Psat= 0.23347396165146334 \n",
      "acc for optim= 0.19489476706919465\n",
      "Epoch:302/1000\n",
      "Loss on train= 0.008275034837424755\n",
      "Loss on test= 0.008493027649819851\n",
      "acc for Lsat= 0.17732631717650693 \n",
      "acc for Psat= 0.21077802463837159 \n",
      "acc for optim= 0.18249685255834297\n",
      "Epoch:303/1000\n",
      "Loss on train= 0.008713247254490852\n",
      "Loss on test= 0.00934862345457077\n",
      "acc for Lsat= 0.18841598696525255 \n",
      "acc for Psat= 0.23826856184079928 \n",
      "acc for optim= 0.19986385310037155\n",
      "Epoch:304/1000\n",
      "Loss on train= 0.00880577601492405\n",
      "Loss on test= 0.009772195480763912\n",
      "acc for Lsat= 0.2652937047341365 \n",
      "acc for Psat= 0.22566176065780474 \n",
      "acc for optim= 0.19109368673427093\n",
      "Epoch:305/1000\n",
      "Loss on train= 0.008767815306782722\n",
      "Loss on test= 0.00861313659697771\n",
      "acc for Lsat= 0.18813265833127613 \n",
      "acc for Psat= 0.22556774388531112 \n",
      "acc for optim= 0.1767598955526502\n",
      "Epoch:306/1000\n",
      "Loss on train= 0.00835415255278349\n",
      "Loss on test= 0.008883405476808548\n",
      "acc for Lsat= 0.2086599168611367 \n",
      "acc for Psat= 0.22305592541993297 \n",
      "acc for optim= 0.18861777588342302\n",
      "Epoch:307/1000\n",
      "Loss on train= 0.008327163755893707\n",
      "Loss on test= 0.008920526131987572\n",
      "acc for Lsat= 0.20298035133460346 \n",
      "acc for Psat= 0.22489965445172364 \n",
      "acc for optim= 0.18068906211351454\n",
      "Epoch:308/1000\n",
      "Loss on train= 0.008646915666759014\n",
      "Loss on test= 0.009335366077721119\n",
      "acc for Lsat= 0.22471453631316485 \n",
      "acc for Psat= 0.2303116779894789 \n",
      "acc for optim= 0.19187646869242475\n",
      "Epoch:309/1000\n",
      "Loss on train= 0.008033420890569687\n",
      "Loss on test= 0.008324556052684784\n",
      "acc for Lsat= 0.19249771405997987 \n",
      "acc for Psat= 0.21689010453361118 \n",
      "acc for optim= 0.1827018142669951\n",
      "Epoch:310/1000\n",
      "Loss on train= 0.007957163266837597\n",
      "Loss on test= 0.008133620023727417\n",
      "acc for Lsat= 0.17980645188600045 \n",
      "acc for Psat= 0.22382784107230383 \n",
      "acc for optim= 0.1841598325813489\n",
      "Epoch:311/1000\n",
      "Loss on train= 0.008015003055334091\n",
      "Loss on test= 0.00798631738871336\n",
      "acc for Lsat= 0.18709289841077653 \n",
      "acc for Psat= 0.20398173520333623 \n",
      "acc for optim= 0.1804886956160525\n",
      "Epoch:312/1000\n",
      "Loss on train= 0.0081035066395998\n",
      "Loss on test= 0.008592895232141018\n",
      "acc for Lsat= 0.21169375360570206 \n",
      "acc for Psat= 0.23834283762469383 \n",
      "acc for optim= 0.1863872383576147\n",
      "Epoch:313/1000\n",
      "Loss on train= 0.008204144425690174\n",
      "Loss on test= 0.008103434927761555\n",
      "acc for Lsat= 0.1813932093133128 \n",
      "acc for Psat= 0.2135583027786875 \n",
      "acc for optim= 0.18223836904419272\n",
      "Epoch:314/1000\n",
      "Loss on train= 0.007914233021438122\n",
      "Loss on test= 0.008575225248932838\n",
      "acc for Lsat= 0.19603781066558687 \n",
      "acc for Psat= 0.21449418431069006 \n",
      "acc for optim= 0.18983255587794454\n",
      "Epoch:315/1000\n",
      "Loss on train= 0.008047490380704403\n",
      "Loss on test= 0.008727746084332466\n",
      "acc for Lsat= 0.2007945620780416 \n",
      "acc for Psat= 0.21528365561044063 \n",
      "acc for optim= 0.18540750014925203\n",
      "Epoch:316/1000\n",
      "Loss on train= 0.008890294469892979\n",
      "Loss on test= 0.010897700674831867\n",
      "acc for Lsat= 0.2831941417614748 \n",
      "acc for Psat= 0.2537312357081199 \n",
      "acc for optim= 0.17459952900722875\n",
      "Epoch:317/1000\n",
      "Loss on train= 0.008808541111648083\n",
      "Loss on test= 0.008865026757121086\n",
      "acc for Lsat= 0.19766512644670556 \n",
      "acc for Psat= 0.22239600376273364 \n",
      "acc for optim= 0.19073133454421315\n",
      "Epoch:318/1000\n",
      "Loss on train= 0.007966838777065277\n",
      "Loss on test= 0.008219762705266476\n",
      "acc for Lsat= 0.16476452068634867 \n",
      "acc for Psat= 0.24291986372781585 \n",
      "acc for optim= 0.18798287530307325\n",
      "Epoch:319/1000\n",
      "Loss on train= 0.008253982290625572\n",
      "Loss on test= 0.008101099170744419\n",
      "acc for Lsat= 0.17165088921043453 \n",
      "acc for Psat= 0.22639858791914422 \n",
      "acc for optim= 0.19166504658622494\n",
      "Epoch:320/1000\n",
      "Loss on train= 0.007833353243768215\n",
      "Loss on test= 0.008771884255111217\n",
      "acc for Lsat= 0.16582543688147502 \n",
      "acc for Psat= 0.23117506626275194 \n",
      "acc for optim= 0.18002184132642854\n",
      "Epoch:321/1000\n",
      "Loss on train= 0.008484246209263802\n",
      "Loss on test= 0.008547780103981495\n",
      "acc for Lsat= 0.18573582894760737 \n",
      "acc for Psat= 0.19560785190344362 \n",
      "acc for optim= 0.20685549373353704\n",
      "Epoch:322/1000\n",
      "Loss on train= 0.008028140291571617\n",
      "Loss on test= 0.00811933446675539\n",
      "acc for Lsat= 0.17054820363957363 \n",
      "acc for Psat= 0.21715451654212517 \n",
      "acc for optim= 0.1824369037796159\n",
      "Epoch:323/1000\n",
      "Loss on train= 0.007999595254659653\n",
      "Loss on test= 0.009024109691381454\n",
      "acc for Lsat= 0.1720758009500707 \n",
      "acc for Psat= 0.2518644822283608 \n",
      "acc for optim= 0.1817643890242187\n",
      "Epoch:324/1000\n",
      "Loss on train= 0.00820897240191698\n",
      "Loss on test= 0.00838251318782568\n",
      "acc for Lsat= 0.169459454369163 \n",
      "acc for Psat= 0.21364721667210934 \n",
      "acc for optim= 0.18867054185908982\n",
      "Epoch:325/1000\n",
      "Loss on train= 0.007818683050572872\n",
      "Loss on test= 0.008153227157890797\n",
      "acc for Lsat= 0.15128447071459714 \n",
      "acc for Psat= 0.21986618518150586 \n",
      "acc for optim= 0.19332674115785728\n",
      "Epoch:326/1000\n",
      "Loss on train= 0.007752750068902969\n",
      "Loss on test= 0.008023402653634548\n",
      "acc for Lsat= 0.16137969917149117 \n",
      "acc for Psat= 0.21531337119113078 \n",
      "acc for optim= 0.1816098817995102\n",
      "Epoch:327/1000\n",
      "Loss on train= 0.007660629693418741\n",
      "Loss on test= 0.008382176049053669\n",
      "acc for Lsat= 0.16562139536569812 \n",
      "acc for Psat= 0.20315223422367126 \n",
      "acc for optim= 0.179850211449883\n",
      "Epoch:328/1000\n",
      "Loss on train= 0.0077225747518241405\n",
      "Loss on test= 0.007803546730428934\n",
      "acc for Lsat= 0.1669432435752982 \n",
      "acc for Psat= 0.2094028817710735 \n",
      "acc for optim= 0.18639993005613717\n",
      "Epoch:329/1000\n",
      "Loss on train= 0.007670615799725056\n",
      "Loss on test= 0.0083236675709486\n",
      "acc for Lsat= 0.16647639460506516 \n",
      "acc for Psat= 0.1960906670381457 \n",
      "acc for optim= 0.1791818210633148\n",
      "Epoch:330/1000\n",
      "Loss on train= 0.007868276908993721\n",
      "Loss on test= 0.008445053361356258\n",
      "acc for Lsat= 0.15964633343628828 \n",
      "acc for Psat= 0.22709934337861773 \n",
      "acc for optim= 0.19475911672353366\n",
      "Epoch:331/1000\n",
      "Loss on train= 0.0078109134919941425\n",
      "Loss on test= 0.008194640278816223\n",
      "acc for Lsat= 0.15929418813666107 \n",
      "acc for Psat= 0.21352612007196234 \n",
      "acc for optim= 0.1975900934085692\n",
      "Epoch:332/1000\n",
      "Loss on train= 0.007630449254065752\n",
      "Loss on test= 0.008596519008278847\n",
      "acc for Lsat= 0.15237723026065536 \n",
      "acc for Psat= 0.2446487530657254 \n",
      "acc for optim= 0.21611367028632786\n",
      "Epoch:333/1000\n",
      "Loss on train= 0.007739557418972254\n",
      "Loss on test= 0.008396623656153679\n",
      "acc for Lsat= 0.1796429997108782 \n",
      "acc for Psat= 0.19921011138168238 \n",
      "acc for optim= 0.17644293911210499\n",
      "Epoch:334/1000\n",
      "Loss on train= 0.007711227051913738\n",
      "Loss on test= 0.008123554289340973\n",
      "acc for Lsat= 0.1840009228713116 \n",
      "acc for Psat= 0.19895137979153749 \n",
      "acc for optim= 0.17534335684307487\n",
      "Epoch:335/1000\n",
      "Loss on train= 0.007730959914624691\n",
      "Loss on test= 0.008186421357095242\n",
      "acc for Lsat= 0.18231944979910375 \n",
      "acc for Psat= 0.19693775348645493 \n",
      "acc for optim= 0.19525476537676434\n",
      "Epoch:336/1000\n",
      "Loss on train= 0.007544321473687887\n",
      "Loss on test= 0.008767389692366123\n",
      "acc for Lsat= 0.16975200275724786 \n",
      "acc for Psat= 0.2114942106114448 \n",
      "acc for optim= 0.18837024885213982\n",
      "Epoch:337/1000\n",
      "Loss on train= 0.0074769798666238785\n",
      "Loss on test= 0.008316000923514366\n",
      "acc for Lsat= 0.1619569615088502 \n",
      "acc for Psat= 0.22207021245010733 \n",
      "acc for optim= 0.17607531780692734\n",
      "Epoch:338/1000\n",
      "Loss on train= 0.007430685218423605\n",
      "Loss on test= 0.008053887635469437\n",
      "acc for Lsat= 0.1732911957532436 \n",
      "acc for Psat= 0.1991084910064474 \n",
      "acc for optim= 0.1923535355990279\n",
      "Epoch:339/1000\n",
      "Loss on train= 0.007563944905996323\n",
      "Loss on test= 0.0076581258326768875\n",
      "acc for Lsat= 0.1487108635928253 \n",
      "acc for Psat= 0.2130123084776056 \n",
      "acc for optim= 0.19792621643210948\n",
      "Epoch:340/1000\n",
      "Loss on train= 0.007424302864819765\n",
      "Loss on test= 0.008480658754706383\n",
      "acc for Lsat= 0.16861549472886184 \n",
      "acc for Psat= 0.2509291811604487 \n",
      "acc for optim= 0.19136915450986727\n",
      "Epoch:341/1000\n",
      "Loss on train= 0.007472373079508543\n",
      "Loss on test= 0.007879628799855709\n",
      "acc for Lsat= 0.16065340389031918 \n",
      "acc for Psat= 0.18433313174883567 \n",
      "acc for optim= 0.18468941279245005\n",
      "Epoch:342/1000\n",
      "Loss on train= 0.0077453781850636005\n",
      "Loss on test= 0.008470291271805763\n",
      "acc for Lsat= 0.1566386262045668 \n",
      "acc for Psat= 0.24454751369164532 \n",
      "acc for optim= 0.20237453212918147\n",
      "Epoch:343/1000\n",
      "Loss on train= 0.007814020849764347\n",
      "Loss on test= 0.007536792661994696\n",
      "acc for Lsat= 0.15157429388432242 \n",
      "acc for Psat= 0.18767635285355136 \n",
      "acc for optim= 0.183537963878904\n",
      "Epoch:344/1000\n",
      "Loss on train= 0.007279036100953817\n",
      "Loss on test= 0.007784961257129908\n",
      "acc for Lsat= 0.1669657954074032 \n",
      "acc for Psat= 0.20133484457577558 \n",
      "acc for optim= 0.18512980785394498\n",
      "Epoch:345/1000\n",
      "Loss on train= 0.00748056173324585\n",
      "Loss on test= 0.007380878087133169\n",
      "acc for Lsat= 0.15496125997476265 \n",
      "acc for Psat= 0.20279311254715263 \n",
      "acc for optim= 0.17697569412274003\n",
      "Epoch:346/1000\n",
      "Loss on train= 0.007463580463081598\n",
      "Loss on test= 0.008077532984316349\n",
      "acc for Lsat= 0.1522016938304197 \n",
      "acc for Psat= 0.21120910413584956 \n",
      "acc for optim= 0.18388705755109402\n",
      "Epoch:347/1000\n",
      "Loss on train= 0.00722523732110858\n",
      "Loss on test= 0.007590093649923801\n",
      "acc for Lsat= 0.15708672855304892 \n",
      "acc for Psat= 0.19843481985834363 \n",
      "acc for optim= 0.1819885788753755\n",
      "Epoch:348/1000\n",
      "Loss on train= 0.007415550295263529\n",
      "Loss on test= 0.007487575989216566\n",
      "acc for Lsat= 0.17053426383156922 \n",
      "acc for Psat= 0.18919780095328845 \n",
      "acc for optim= 0.19046002114112726\n",
      "Epoch:349/1000\n",
      "Loss on train= 0.007915596477687359\n",
      "Loss on test= 0.009940140880644321\n",
      "acc for Lsat= 0.2357031062865922 \n",
      "acc for Psat= 0.21963783883631735 \n",
      "acc for optim= 0.18227559518921427\n",
      "Epoch:350/1000\n",
      "Loss on train= 0.008390123024582863\n",
      "Loss on test= 0.008220425806939602\n",
      "acc for Lsat= 0.19021202033618465 \n",
      "acc for Psat= 0.18351495463077483 \n",
      "acc for optim= 0.19009650213369148\n",
      "Epoch:351/1000\n",
      "Loss on train= 0.007359052076935768\n",
      "Loss on test= 0.008124182932078838\n",
      "acc for Lsat= 0.14133130147859801 \n",
      "acc for Psat= 0.20680961348234786 \n",
      "acc for optim= 0.19681693564595307\n",
      "Epoch:352/1000\n",
      "Loss on train= 0.007515655364841223\n",
      "Loss on test= 0.008183354511857033\n",
      "acc for Lsat= 0.1712262746087602 \n",
      "acc for Psat= 0.20742939052416676 \n",
      "acc for optim= 0.1836910119769558\n",
      "Epoch:353/1000\n",
      "Loss on train= 0.007319785188883543\n",
      "Loss on test= 0.007714856881648302\n",
      "acc for Lsat= 0.15749926423413238 \n",
      "acc for Psat= 0.19161146080374947 \n",
      "acc for optim= 0.17645803612609537\n",
      "Epoch:354/1000\n",
      "Loss on train= 0.0074163274839520454\n",
      "Loss on test= 0.008086934685707092\n",
      "acc for Lsat= 0.1534674188201079 \n",
      "acc for Psat= 0.18580980755633406 \n",
      "acc for optim= 0.1900032188366483\n",
      "Epoch:355/1000\n",
      "Loss on train= 0.007541192229837179\n",
      "Loss on test= 0.007473543751984835\n",
      "acc for Lsat= 0.1507460670109633 \n",
      "acc for Psat= 0.1873799752314788 \n",
      "acc for optim= 0.1763001764765388\n",
      "Epoch:356/1000\n",
      "Loss on train= 0.007183063309639692\n",
      "Loss on test= 0.007692440412938595\n",
      "acc for Lsat= 0.15668257417480888 \n",
      "acc for Psat= 0.2106625516228062 \n",
      "acc for optim= 0.19955284996259112\n",
      "Epoch:357/1000\n",
      "Loss on train= 0.007278362289071083\n",
      "Loss on test= 0.007695485837757587\n",
      "acc for Lsat= 0.1642506525078315 \n",
      "acc for Psat= 0.1903926324920129 \n",
      "acc for optim= 0.18893257903440272\n",
      "Epoch:358/1000\n",
      "Loss on train= 0.007711798883974552\n",
      "Loss on test= 0.008816616609692574\n",
      "acc for Lsat= 0.2325052673642334 \n",
      "acc for Psat= 0.217806937722874 \n",
      "acc for optim= 0.18210888107321313\n",
      "Epoch:359/1000\n",
      "Loss on train= 0.007672414183616638\n",
      "Loss on test= 0.007684745825827122\n",
      "acc for Lsat= 0.16656761582431748 \n",
      "acc for Psat= 0.19696264585787904 \n",
      "acc for optim= 0.1791937668699282\n",
      "Epoch:360/1000\n",
      "Loss on train= 0.007444536779075861\n",
      "Loss on test= 0.007336246315389872\n",
      "acc for Lsat= 0.15853007880614775 \n",
      "acc for Psat= 0.2099314192302083 \n",
      "acc for optim= 0.18919176469809548\n",
      "Epoch:361/1000\n",
      "Loss on train= 0.007354537025094032\n",
      "Loss on test= 0.007281413301825523\n",
      "acc for Lsat= 0.1596094606353475 \n",
      "acc for Psat= 0.18938054432835966 \n",
      "acc for optim= 0.18792138586698348\n",
      "Epoch:362/1000\n",
      "Loss on train= 0.007277647964656353\n",
      "Loss on test= 0.00765956798568368\n",
      "acc for Lsat= 0.15850935834992708 \n",
      "acc for Psat= 0.19248706160539414 \n",
      "acc for optim= 0.17685485031353151\n",
      "Epoch:363/1000\n",
      "Loss on train= 0.007445766590535641\n",
      "Loss on test= 0.007772176526486874\n",
      "acc for Lsat= 0.15704194220627452 \n",
      "acc for Psat= 0.22113882625397588 \n",
      "acc for optim= 0.20910733115022717\n",
      "Epoch:364/1000\n",
      "Loss on train= 0.007364724762737751\n",
      "Loss on test= 0.00785153266042471\n",
      "acc for Lsat= 0.14902331356109136 \n",
      "acc for Psat= 0.19200420210540484 \n",
      "acc for optim= 0.18542537005338028\n",
      "Epoch:365/1000\n",
      "Loss on train= 0.0073238336481153965\n",
      "Loss on test= 0.007842084392905235\n",
      "acc for Lsat= 0.1593966992222704 \n",
      "acc for Psat= 0.17945434469098256 \n",
      "acc for optim= 0.18971972165992326\n",
      "Epoch:366/1000\n",
      "Loss on train= 0.007291417568922043\n",
      "Loss on test= 0.008206612430512905\n",
      "acc for Lsat= 0.17504208399529442 \n",
      "acc for Psat= 0.1904812075758069 \n",
      "acc for optim= 0.19007765527310735\n",
      "Epoch:367/1000\n",
      "Loss on train= 0.007485550362616777\n",
      "Loss on test= 0.0077530075795948505\n",
      "acc for Lsat= 0.1560328952441292 \n",
      "acc for Psat= 0.18853333553968202 \n",
      "acc for optim= 0.17997445376487292\n",
      "Epoch:368/1000\n",
      "Loss on train= 0.007635453715920448\n",
      "Loss on test= 0.009280560538172722\n",
      "acc for Lsat= 0.2332139225005788 \n",
      "acc for Psat= 0.23233970096818235 \n",
      "acc for optim= 0.18126659102642206\n",
      "Epoch:369/1000\n",
      "Loss on train= 0.007843776606023312\n",
      "Loss on test= 0.008085903711616993\n",
      "acc for Lsat= 0.16754652619227703 \n",
      "acc for Psat= 0.20637444614559033 \n",
      "acc for optim= 0.19698403910171414\n",
      "Epoch:370/1000\n",
      "Loss on train= 0.007831490598618984\n",
      "Loss on test= 0.009645340964198112\n",
      "acc for Lsat= 0.18655058841489383 \n",
      "acc for Psat= 0.33474570197621517 \n",
      "acc for optim= 0.18484667440120653\n",
      "Epoch:371/1000\n",
      "Loss on train= 0.008072294294834137\n",
      "Loss on test= 0.008631772361695766\n",
      "acc for Lsat= 0.21785693836903547 \n",
      "acc for Psat= 0.21620058114956117 \n",
      "acc for optim= 0.17728492645877295\n",
      "Epoch:372/1000\n",
      "Loss on train= 0.007651651278138161\n",
      "Loss on test= 0.008027302101254463\n",
      "acc for Lsat= 0.15525213970834295 \n",
      "acc for Psat= 0.24333868108658216 \n",
      "acc for optim= 0.17866133261911998\n",
      "Epoch:373/1000\n",
      "Loss on train= 0.007219185121357441\n",
      "Loss on test= 0.007511598989367485\n",
      "acc for Lsat= 0.16869259295011851 \n",
      "acc for Psat= 0.17549615350899175 \n",
      "acc for optim= 0.17805877473053397\n",
      "Epoch:374/1000\n",
      "Loss on train= 0.006970539689064026\n",
      "Loss on test= 0.007457326631993055\n",
      "acc for Lsat= 0.1432765863616793 \n",
      "acc for Psat= 0.20644917466709295 \n",
      "acc for optim= 0.18578692642218134\n",
      "Epoch:375/1000\n",
      "Loss on train= 0.007369325961917639\n",
      "Loss on test= 0.007434464991092682\n",
      "acc for Lsat= 0.1793434782087866 \n",
      "acc for Psat= 0.18917509538424399 \n",
      "acc for optim= 0.1847283684882144\n",
      "Epoch:376/1000\n",
      "Loss on train= 0.007396035362035036\n",
      "Loss on test= 0.008294808678328991\n",
      "acc for Lsat= 0.1510326316902045 \n",
      "acc for Psat= 0.2631822969027503 \n",
      "acc for optim= 0.19749077773944995\n",
      "Epoch:377/1000\n",
      "Loss on train= 0.007392076309770346\n",
      "Loss on test= 0.007664993871003389\n",
      "acc for Lsat= 0.14507434965501997 \n",
      "acc for Psat= 0.18438879635887442 \n",
      "acc for optim= 0.18814749602078937\n",
      "Epoch:378/1000\n",
      "Loss on train= 0.007518866565078497\n",
      "Loss on test= 0.009966140612959862\n",
      "acc for Lsat= 0.17910134532327085 \n",
      "acc for Psat= 0.30554498271953506 \n",
      "acc for optim= 0.20402893427536445\n",
      "Epoch:379/1000\n",
      "Loss on train= 0.007826569490134716\n",
      "Loss on test= 0.00792934000492096\n",
      "acc for Lsat= 0.1840798808502907 \n",
      "acc for Psat= 0.19433130075231636 \n",
      "acc for optim= 0.17794509476018178\n",
      "Epoch:380/1000\n",
      "Loss on train= 0.00755218043923378\n",
      "Loss on test= 0.007445529568940401\n",
      "acc for Lsat= 0.14369264485559158 \n",
      "acc for Psat= 0.1864441969479292 \n",
      "acc for optim= 0.17928344758653667\n",
      "Epoch:381/1000\n",
      "Loss on train= 0.007186749950051308\n",
      "Loss on test= 0.007596142124384642\n",
      "acc for Lsat= 0.17320093178363927 \n",
      "acc for Psat= 0.18969995621473418 \n",
      "acc for optim= 0.18023653886659796\n",
      "Epoch:382/1000\n",
      "Loss on train= 0.007046353071928024\n",
      "Loss on test= 0.00771909486502409\n",
      "acc for Lsat= 0.15902470552492728 \n",
      "acc for Psat= 0.17557556608818092 \n",
      "acc for optim= 0.1933780260921147\n",
      "Epoch:383/1000\n",
      "Loss on train= 0.006936097517609596\n",
      "Loss on test= 0.007425406947731972\n",
      "acc for Lsat= 0.13950976576849472 \n",
      "acc for Psat= 0.1787593795415764 \n",
      "acc for optim= 0.18262579511551155\n",
      "Epoch:384/1000\n",
      "Loss on train= 0.00701358774676919\n",
      "Loss on test= 0.0076778847724199295\n",
      "acc for Lsat= 0.14694765362869322 \n",
      "acc for Psat= 0.18803616885364183 \n",
      "acc for optim= 0.19629515029324252\n",
      "Epoch:385/1000\n",
      "Loss on train= 0.007105530705302954\n",
      "Loss on test= 0.007556559517979622\n",
      "acc for Lsat= 0.13344759059067562 \n",
      "acc for Psat= 0.1761661520046261 \n",
      "acc for optim= 0.1738335061628693\n",
      "Epoch:386/1000\n",
      "Loss on train= 0.006919218692928553\n",
      "Loss on test= 0.007554569281637669\n",
      "acc for Lsat= 0.14238514142915987 \n",
      "acc for Psat= 0.18856552542045207 \n",
      "acc for optim= 0.18037342944096624\n",
      "Epoch:387/1000\n",
      "Loss on train= 0.007117866072803736\n",
      "Loss on test= 0.007519914302974939\n",
      "acc for Lsat= 0.1419232309846971 \n",
      "acc for Psat= 0.182265646297532 \n",
      "acc for optim= 0.17627652978052985\n",
      "Epoch:388/1000\n",
      "Loss on train= 0.007184998597949743\n",
      "Loss on test= 0.007602060679346323\n",
      "acc for Lsat= 0.1455630344612735 \n",
      "acc for Psat= 0.18386764974506983 \n",
      "acc for optim= 0.17843446474624955\n",
      "Epoch:389/1000\n",
      "Loss on train= 0.0071035875007510185\n",
      "Loss on test= 0.00795585848391056\n",
      "acc for Lsat= 0.1702987138548929 \n",
      "acc for Psat= 0.1870836069215468 \n",
      "acc for optim= 0.18318913049396066\n",
      "Epoch:390/1000\n",
      "Loss on train= 0.007472383324056864\n",
      "Loss on test= 0.008002670481801033\n",
      "acc for Lsat= 0.14501511818330767 \n",
      "acc for Psat= 0.21534349332855604 \n",
      "acc for optim= 0.19895821205553424\n",
      "Epoch:391/1000\n",
      "Loss on train= 0.007541353814303875\n",
      "Loss on test= 0.007986096665263176\n",
      "acc for Lsat= 0.1441253381808904 \n",
      "acc for Psat= 0.22895152765541768 \n",
      "acc for optim= 0.18312565769262265\n",
      "Epoch:392/1000\n",
      "Loss on train= 0.007049999665468931\n",
      "Loss on test= 0.007351050153374672\n",
      "acc for Lsat= 0.18398214885802205 \n",
      "acc for Psat= 0.17811907589064627 \n",
      "acc for optim= 0.18141678765226724\n",
      "Epoch:393/1000\n",
      "Loss on train= 0.0070590367540717125\n",
      "Loss on test= 0.00732532748952508\n",
      "acc for Lsat= 0.14445878671920243 \n",
      "acc for Psat= 0.19458200703310916 \n",
      "acc for optim= 0.1791084958398241\n",
      "Epoch:394/1000\n",
      "Loss on train= 0.00719929113984108\n",
      "Loss on test= 0.00738481106236577\n",
      "acc for Lsat= 0.1393193751266986 \n",
      "acc for Psat= 0.199288130407303 \n",
      "acc for optim= 0.19496923068348887\n",
      "Epoch:395/1000\n",
      "Loss on train= 0.006884497124701738\n",
      "Loss on test= 0.0074570500291883945\n",
      "acc for Lsat= 0.14968779350194875 \n",
      "acc for Psat= 0.1694887725275278 \n",
      "acc for optim= 0.1761643834998121\n",
      "Epoch:396/1000\n",
      "Loss on train= 0.006831118371337652\n",
      "Loss on test= 0.007496214937418699\n",
      "acc for Lsat= 0.13938598904325342 \n",
      "acc for Psat= 0.17264606978174402 \n",
      "acc for optim= 0.18321830783003815\n",
      "Epoch:397/1000\n",
      "Loss on train= 0.006936463061720133\n",
      "Loss on test= 0.008216993883252144\n",
      "acc for Lsat= 0.15301854548654203 \n",
      "acc for Psat= 0.19984039517565458 \n",
      "acc for optim= 0.1932013496501032\n",
      "Epoch:398/1000\n",
      "Loss on train= 0.007124337833374739\n",
      "Loss on test= 0.007340696174651384\n",
      "acc for Lsat= 0.1380769415132571 \n",
      "acc for Psat= 0.18067268194853708 \n",
      "acc for optim= 0.19020474546143026\n",
      "Epoch:399/1000\n",
      "Loss on train= 0.007147978059947491\n",
      "Loss on test= 0.007260949816554785\n",
      "acc for Lsat= 0.16160469454144902 \n",
      "acc for Psat= 0.18135089076171487 \n",
      "acc for optim= 0.17913368195611037\n",
      "Epoch:400/1000\n",
      "Loss on train= 0.0069798962213099\n",
      "Loss on test= 0.007890919223427773\n",
      "acc for Lsat= 0.13985710327268847 \n",
      "acc for Psat= 0.21820892517975832 \n",
      "acc for optim= 0.19307809585697508\n",
      "Epoch:401/1000\n",
      "Loss on train= 0.0069787767715752125\n",
      "Loss on test= 0.0069753630086779594\n",
      "acc for Lsat= 0.13225458766239048 \n",
      "acc for Psat= 0.18277727563715523 \n",
      "acc for optim= 0.18352344486846636\n",
      "Epoch:402/1000\n",
      "Loss on train= 0.006962466984987259\n",
      "Loss on test= 0.0074167512357234955\n",
      "acc for Lsat= 0.155011709529504 \n",
      "acc for Psat= 0.16640480212103653 \n",
      "acc for optim= 0.18920078015475833\n",
      "Epoch:403/1000\n",
      "Loss on train= 0.006822791416198015\n",
      "Loss on test= 0.007681563030928373\n",
      "acc for Lsat= 0.1538678053387646 \n",
      "acc for Psat= 0.1942210062403011 \n",
      "acc for optim= 0.1974602791816154\n",
      "Epoch:404/1000\n",
      "Loss on train= 0.006809493992477655\n",
      "Loss on test= 0.007224014960229397\n",
      "acc for Lsat= 0.142126677568481 \n",
      "acc for Psat= 0.18068613300762945 \n",
      "acc for optim= 0.17686236299163963\n",
      "Epoch:405/1000\n",
      "Loss on train= 0.006924741435796022\n",
      "Loss on test= 0.007508371025323868\n",
      "acc for Lsat= 0.14494743742703822 \n",
      "acc for Psat= 0.1781427981955457 \n",
      "acc for optim= 0.18134985911675683\n",
      "Epoch:406/1000\n",
      "Loss on train= 0.006851299665868282\n",
      "Loss on test= 0.007523758802562952\n",
      "acc for Lsat= 0.14755951700459818 \n",
      "acc for Psat= 0.17054560202611926 \n",
      "acc for optim= 0.18548420718989445\n",
      "Epoch:407/1000\n",
      "Loss on train= 0.006832929793745279\n",
      "Loss on test= 0.007506716530770063\n",
      "acc for Lsat= 0.15269801699708344 \n",
      "acc for Psat= 0.1758466859677633 \n",
      "acc for optim= 0.1805663558021109\n",
      "Epoch:408/1000\n",
      "Loss on train= 0.006661309860646725\n",
      "Loss on test= 0.0070379339158535\n",
      "acc for Lsat= 0.1351266927753725 \n",
      "acc for Psat= 0.1790256974899005 \n",
      "acc for optim= 0.1790799930522029\n",
      "Epoch:409/1000\n",
      "Loss on train= 0.0066169751808047295\n",
      "Loss on test= 0.007864737883210182\n",
      "acc for Lsat= 0.13125738418459798 \n",
      "acc for Psat= 0.2053798406716373 \n",
      "acc for optim= 0.18784561367346353\n",
      "Epoch:410/1000\n",
      "Loss on train= 0.006799150258302689\n",
      "Loss on test= 0.0071578300558030605\n",
      "acc for Lsat= 0.12490368934754692 \n",
      "acc for Psat= 0.17461991527638698 \n",
      "acc for optim= 0.18658136146585064\n",
      "Epoch:411/1000\n",
      "Loss on train= 0.006774122826755047\n",
      "Loss on test= 0.007417603861540556\n",
      "acc for Lsat= 0.14979194106178464 \n",
      "acc for Psat= 0.19969847868196666 \n",
      "acc for optim= 0.18598679684593847\n",
      "Epoch:412/1000\n",
      "Loss on train= 0.006748196203261614\n",
      "Loss on test= 0.007625354453921318\n",
      "acc for Lsat= 0.14090738425710064 \n",
      "acc for Psat= 0.19265568320426332 \n",
      "acc for optim= 0.18664737571389967\n",
      "Epoch:413/1000\n",
      "Loss on train= 0.006954974960535765\n",
      "Loss on test= 0.008787504397332668\n",
      "acc for Lsat= 0.2126588227657475 \n",
      "acc for Psat= 0.20417926828256094 \n",
      "acc for optim= 0.17841324798557592\n",
      "Epoch:414/1000\n",
      "Loss on train= 0.00705569377169013\n",
      "Loss on test= 0.007320295553654432\n",
      "acc for Lsat= 0.14196705770801152 \n",
      "acc for Psat= 0.21404917045887087 \n",
      "acc for optim= 0.17734441085781713\n",
      "Epoch:415/1000\n",
      "Loss on train= 0.00700422516092658\n",
      "Loss on test= 0.007395236752927303\n",
      "acc for Lsat= 0.12776975644243313 \n",
      "acc for Psat= 0.1923277122536832 \n",
      "acc for optim= 0.18833048122272023\n",
      "Epoch:416/1000\n",
      "Loss on train= 0.006869634613394737\n",
      "Loss on test= 0.007500950712710619\n",
      "acc for Lsat= 0.16374638086121718 \n",
      "acc for Psat= 0.1777505128699655 \n",
      "acc for optim= 0.18623988321346974\n",
      "Epoch:417/1000\n",
      "Loss on train= 0.006757800467312336\n",
      "Loss on test= 0.007474160753190517\n",
      "acc for Lsat= 0.14616862930351537 \n",
      "acc for Psat= 0.17486266061245323 \n",
      "acc for optim= 0.17494421896289925\n",
      "Epoch:418/1000\n",
      "Loss on train= 0.006706027779728174\n",
      "Loss on test= 0.0075441813096404076\n",
      "acc for Lsat= 0.12725519152295034 \n",
      "acc for Psat= 0.18630812855084267 \n",
      "acc for optim= 0.1852991160830104\n",
      "Epoch:419/1000\n",
      "Loss on train= 0.006580001208931208\n",
      "Loss on test= 0.007184124086052179\n",
      "acc for Lsat= 0.13115372576541662 \n",
      "acc for Psat= 0.17297355522938326 \n",
      "acc for optim= 0.1839432418890992\n",
      "Epoch:420/1000\n",
      "Loss on train= 0.006759531330317259\n",
      "Loss on test= 0.006933608092367649\n",
      "acc for Lsat= 0.13143479529673519 \n",
      "acc for Psat= 0.17384052458021917 \n",
      "acc for optim= 0.1835918795231703\n",
      "Epoch:421/1000\n",
      "Loss on train= 0.006887605879455805\n",
      "Loss on test= 0.007292876951396465\n",
      "acc for Lsat= 0.13324340910905325 \n",
      "acc for Psat= 0.21213448387517267 \n",
      "acc for optim= 0.1779864160414051\n",
      "Epoch:422/1000\n",
      "Loss on train= 0.006694437470287085\n",
      "Loss on test= 0.006899920292198658\n",
      "acc for Lsat= 0.13168726742209155 \n",
      "acc for Psat= 0.18847396280813836 \n",
      "acc for optim= 0.19114107160998697\n",
      "Epoch:423/1000\n",
      "Loss on train= 0.006396023090928793\n",
      "Loss on test= 0.007324571255594492\n",
      "acc for Lsat= 0.14091413504448008 \n",
      "acc for Psat= 0.17799638990802152 \n",
      "acc for optim= 0.18228829628926055\n",
      "Epoch:424/1000\n",
      "Loss on train= 0.006632816046476364\n",
      "Loss on test= 0.007367273326963186\n",
      "acc for Lsat= 0.1227339133310479 \n",
      "acc for Psat= 0.22015939505249893 \n",
      "acc for optim= 0.1763581665493232\n",
      "Epoch:425/1000\n",
      "Loss on train= 0.006830880418419838\n",
      "Loss on test= 0.007070319727063179\n",
      "acc for Lsat= 0.13817366292765285 \n",
      "acc for Psat= 0.1850971270899162 \n",
      "acc for optim= 0.1920595689735896\n",
      "Epoch:426/1000\n",
      "Loss on train= 0.006567215081304312\n",
      "Loss on test= 0.007162580732256174\n",
      "acc for Lsat= 0.1458505764775278 \n",
      "acc for Psat= 0.1781759860459715 \n",
      "acc for optim= 0.18185134525548952\n",
      "Epoch:427/1000\n",
      "Loss on train= 0.006810896564275026\n",
      "Loss on test= 0.007514160126447678\n",
      "acc for Lsat= 0.13230072385513114 \n",
      "acc for Psat= 0.18574012316885735 \n",
      "acc for optim= 0.1915150492073242\n",
      "Epoch:428/1000\n",
      "Loss on train= 0.006865540519356728\n",
      "Loss on test= 0.00736490823328495\n",
      "acc for Lsat= 0.12966693325017054 \n",
      "acc for Psat= 0.17937375514282672 \n",
      "acc for optim= 0.18397949794415874\n",
      "Epoch:429/1000\n",
      "Loss on train= 0.00689794821664691\n",
      "Loss on test= 0.007177129853516817\n",
      "acc for Lsat= 0.13564911599785742 \n",
      "acc for Psat= 0.18313967504072934 \n",
      "acc for optim= 0.18282568133021784\n",
      "Epoch:430/1000\n",
      "Loss on train= 0.0065704635344445705\n",
      "Loss on test= 0.007428484503179789\n",
      "acc for Lsat= 0.1364813566843237 \n",
      "acc for Psat= 0.18002175218534214 \n",
      "acc for optim= 0.20015301762870907\n",
      "Epoch:431/1000\n",
      "Loss on train= 0.006492061540484428\n",
      "Loss on test= 0.006972355768084526\n",
      "acc for Lsat= 0.13788311379977455 \n",
      "acc for Psat= 0.17422447310350203 \n",
      "acc for optim= 0.17781752648450616\n",
      "Epoch:432/1000\n",
      "Loss on train= 0.006676576565951109\n",
      "Loss on test= 0.0069284518249332905\n",
      "acc for Lsat= 0.12404249151399106 \n",
      "acc for Psat= 0.17050872874733305 \n",
      "acc for optim= 0.1810531158465892\n",
      "Epoch:433/1000\n",
      "Loss on train= 0.00663845706731081\n",
      "Loss on test= 0.007172017823904753\n",
      "acc for Lsat= 0.1308124874213363 \n",
      "acc for Psat= 0.18989917811211515 \n",
      "acc for optim= 0.18504202125378946\n",
      "Epoch:434/1000\n",
      "Loss on train= 0.0064815557561814785\n",
      "Loss on test= 0.007708738557994366\n",
      "acc for Lsat= 0.17356404458188404 \n",
      "acc for Psat= 0.178468942507841 \n",
      "acc for optim= 0.19233729957318785\n",
      "Epoch:435/1000\n",
      "Loss on train= 0.006719160825014114\n",
      "Loss on test= 0.006974900607019663\n",
      "acc for Lsat= 0.13189874814618063 \n",
      "acc for Psat= 0.1738727237334696 \n",
      "acc for optim= 0.18231950887839973\n",
      "Epoch:436/1000\n",
      "Loss on train= 0.006489059422165155\n",
      "Loss on test= 0.007038512267172337\n",
      "acc for Lsat= 0.14362651095962373 \n",
      "acc for Psat= 0.16872937653367398 \n",
      "acc for optim= 0.17812772432472398\n",
      "Epoch:437/1000\n",
      "Loss on train= 0.006472572684288025\n",
      "Loss on test= 0.007263515144586563\n",
      "acc for Lsat= 0.14105338923617314 \n",
      "acc for Psat= 0.17885386126764094 \n",
      "acc for optim= 0.1911760761075006\n",
      "Epoch:438/1000\n",
      "Loss on train= 0.006702460814267397\n",
      "Loss on test= 0.0071992455050349236\n",
      "acc for Lsat= 0.16671217592981627 \n",
      "acc for Psat= 0.18336760680925226 \n",
      "acc for optim= 0.1864962369574518\n",
      "Epoch:439/1000\n",
      "Loss on train= 0.006688370369374752\n",
      "Loss on test= 0.007830417715013027\n",
      "acc for Lsat= 0.13022712884792442 \n",
      "acc for Psat= 0.23245104544547435 \n",
      "acc for optim= 0.18080747642238557\n",
      "Epoch:440/1000\n",
      "Loss on train= 0.00688795605674386\n",
      "Loss on test= 0.007696972694247961\n",
      "acc for Lsat= 0.13770113511492452 \n",
      "acc for Psat= 0.22317096009826826 \n",
      "acc for optim= 0.1972756853672455\n",
      "Epoch:441/1000\n",
      "Loss on train= 0.006877346895635128\n",
      "Loss on test= 0.006931825540959835\n",
      "acc for Lsat= 0.13170764949902797 \n",
      "acc for Psat= 0.17276183544516058 \n",
      "acc for optim= 0.1820992780630319\n",
      "Epoch:442/1000\n",
      "Loss on train= 0.006459119729697704\n",
      "Loss on test= 0.007161826826632023\n",
      "acc for Lsat= 0.12428860041683824 \n",
      "acc for Psat= 0.17162283353104998 \n",
      "acc for optim= 0.1770410169406066\n",
      "Epoch:443/1000\n",
      "Loss on train= 0.006520944647490978\n",
      "Loss on test= 0.007198459003120661\n",
      "acc for Lsat= 0.1259960123724171 \n",
      "acc for Psat= 0.17161772146592139 \n",
      "acc for optim= 0.17626047799841232\n",
      "Epoch:444/1000\n",
      "Loss on train= 0.006932276766747236\n",
      "Loss on test= 0.006955673918128014\n",
      "acc for Lsat= 0.11991709682772772 \n",
      "acc for Psat= 0.17124898101289962 \n",
      "acc for optim= 0.18423074652062002\n",
      "Epoch:445/1000\n",
      "Loss on train= 0.006478792522102594\n",
      "Loss on test= 0.007077197078615427\n",
      "acc for Lsat= 0.14096928348200458 \n",
      "acc for Psat= 0.1618650974309214 \n",
      "acc for optim= 0.1774258014195504\n",
      "Epoch:446/1000\n",
      "Loss on train= 0.006588190793991089\n",
      "Loss on test= 0.007778502535074949\n",
      "acc for Lsat= 0.1814293935564465 \n",
      "acc for Psat= 0.18887321604652552 \n",
      "acc for optim= 0.1881506539757908\n",
      "Epoch:447/1000\n",
      "Loss on train= 0.00669625960290432\n",
      "Loss on test= 0.007459585554897785\n",
      "acc for Lsat= 0.13769909466642213 \n",
      "acc for Psat= 0.20017998509426696 \n",
      "acc for optim= 0.18135777852000765\n",
      "Epoch:448/1000\n",
      "Loss on train= 0.006529468111693859\n",
      "Loss on test= 0.006588246673345566\n",
      "acc for Lsat= 0.1124810840774444 \n",
      "acc for Psat= 0.16669837603596102 \n",
      "acc for optim= 0.1803525100888337\n",
      "Epoch:449/1000\n",
      "Loss on train= 0.006684031803160906\n",
      "Loss on test= 0.0068206400610506535\n",
      "acc for Lsat= 0.11959301850026458 \n",
      "acc for Psat= 0.18486743580463136 \n",
      "acc for optim= 0.1870819475220603\n",
      "Epoch:450/1000\n",
      "Loss on train= 0.006615480873733759\n",
      "Loss on test= 0.007110531907528639\n",
      "acc for Lsat= 0.1116492997890002 \n",
      "acc for Psat= 0.18202688079761437 \n",
      "acc for optim= 0.19057796047743947\n",
      "Epoch:451/1000\n",
      "Loss on train= 0.0064505934715271\n",
      "Loss on test= 0.0073349387384951115\n",
      "acc for Lsat= 0.14195703170455892 \n",
      "acc for Psat= 0.17171953720932479 \n",
      "acc for optim= 0.18503539554766868\n",
      "Epoch:452/1000\n",
      "Loss on train= 0.0063795605674386024\n",
      "Loss on test= 0.006996906362473965\n",
      "acc for Lsat= 0.14862372934289467 \n",
      "acc for Psat= 0.16872711139553526 \n",
      "acc for optim= 0.18557696128579773\n",
      "Epoch:453/1000\n",
      "Loss on train= 0.006315747741609812\n",
      "Loss on test= 0.006927789188921452\n",
      "acc for Lsat= 0.12028850217169038 \n",
      "acc for Psat= 0.1700925554878915 \n",
      "acc for optim= 0.177973659653848\n",
      "Epoch:454/1000\n",
      "Loss on train= 0.006326968315988779\n",
      "Loss on test= 0.0069933440536260605\n",
      "acc for Lsat= 0.13748395062264812 \n",
      "acc for Psat= 0.17294284913617866 \n",
      "acc for optim= 0.18168113326211854\n",
      "Epoch:455/1000\n",
      "Loss on train= 0.006506592500954866\n",
      "Loss on test= 0.00686193723231554\n",
      "acc for Lsat= 0.11741353520650961 \n",
      "acc for Psat= 0.1673051825777817 \n",
      "acc for optim= 0.18381854524378174\n",
      "Epoch:456/1000\n",
      "Loss on train= 0.00669793551787734\n",
      "Loss on test= 0.007135417312383652\n",
      "acc for Lsat= 0.12935417070077196 \n",
      "acc for Psat= 0.18577378942252343 \n",
      "acc for optim= 0.1825406985288344\n",
      "Epoch:457/1000\n",
      "Loss on train= 0.006586208939552307\n",
      "Loss on test= 0.0072305588982999325\n",
      "acc for Lsat= 0.12407111792758076 \n",
      "acc for Psat= 0.17461625035473352 \n",
      "acc for optim= 0.2015221608386775\n",
      "Epoch:458/1000\n",
      "Loss on train= 0.006509789731353521\n",
      "Loss on test= 0.0070160930044949055\n",
      "acc for Lsat= 0.13175017450644114 \n",
      "acc for Psat= 0.1675776710461478 \n",
      "acc for optim= 0.18805616387122673\n",
      "Epoch:459/1000\n",
      "Loss on train= 0.006220494396984577\n",
      "Loss on test= 0.006856628227978945\n",
      "acc for Lsat= 0.11251661260347168 \n",
      "acc for Psat= 0.16089464850305438 \n",
      "acc for optim= 0.17832848160819673\n",
      "Epoch:460/1000\n",
      "Loss on train= 0.006630985997617245\n",
      "Loss on test= 0.007187230046838522\n",
      "acc for Lsat= 0.12778439515736942 \n",
      "acc for Psat= 0.18262636878550392 \n",
      "acc for optim= 0.18007332333994996\n",
      "Epoch:461/1000\n",
      "Loss on train= 0.006382098887115717\n",
      "Loss on test= 0.006783325225114822\n",
      "acc for Lsat= 0.1297031045467119 \n",
      "acc for Psat= 0.16687267389744362 \n",
      "acc for optim= 0.18332902140384125\n",
      "Epoch:462/1000\n",
      "Loss on train= 0.006405689753592014\n",
      "Loss on test= 0.006737875752151012\n",
      "acc for Lsat= 0.12735774209407175 \n",
      "acc for Psat= 0.16397649869332642 \n",
      "acc for optim= 0.18068891946853818\n",
      "Epoch:463/1000\n",
      "Loss on train= 0.006460265256464481\n",
      "Loss on test= 0.006604723632335663\n",
      "acc for Lsat= 0.1221738252648689 \n",
      "acc for Psat= 0.16431124794584998 \n",
      "acc for optim= 0.19139112628862198\n",
      "Epoch:464/1000\n",
      "Loss on train= 0.006439769174903631\n",
      "Loss on test= 0.007041383069008589\n",
      "acc for Lsat= 0.12803765480106666 \n",
      "acc for Psat= 0.1908365698081394 \n",
      "acc for optim= 0.18470465133432298\n",
      "Epoch:465/1000\n",
      "Loss on train= 0.006562434136867523\n",
      "Loss on test= 0.00707488926127553\n",
      "acc for Lsat= 0.14549700345141592 \n",
      "acc for Psat= 0.17965940317159748 \n",
      "acc for optim= 0.1762298698777775\n",
      "Epoch:466/1000\n",
      "Loss on train= 0.006462942808866501\n",
      "Loss on test= 0.007456307299435139\n",
      "acc for Lsat= 0.18139443704227018 \n",
      "acc for Psat= 0.16214118147272838 \n",
      "acc for optim= 0.18393694500535554\n",
      "Epoch:467/1000\n",
      "Loss on train= 0.006589664611965418\n",
      "Loss on test= 0.006787586957216263\n",
      "acc for Lsat= 0.12130415121597037 \n",
      "acc for Psat= 0.1619785915049961 \n",
      "acc for optim= 0.18680518731431467\n",
      "Epoch:468/1000\n",
      "Loss on train= 0.006497730500996113\n",
      "Loss on test= 0.006768485065549612\n",
      "acc for Lsat= 0.1251607706905461 \n",
      "acc for Psat= 0.16188124601267498 \n",
      "acc for optim= 0.1786125966292506\n",
      "Epoch:469/1000\n",
      "Loss on train= 0.0065110474824905396\n",
      "Loss on test= 0.006857693195343018\n",
      "acc for Lsat= 0.13675666777417064 \n",
      "acc for Psat= 0.16652275591701965 \n",
      "acc for optim= 0.1838077344833005\n",
      "Epoch:470/1000\n",
      "Loss on train= 0.006322301458567381\n",
      "Loss on test= 0.006691416259855032\n",
      "acc for Lsat= 0.1256189302308485 \n",
      "acc for Psat= 0.16840373434301986 \n",
      "acc for optim= 0.18665189443006164\n",
      "Epoch:471/1000\n",
      "Loss on train= 0.006164642050862312\n",
      "Loss on test= 0.007036119233816862\n",
      "acc for Lsat= 0.11951908812062989 \n",
      "acc for Psat= 0.17865359649798138 \n",
      "acc for optim= 0.1796156161188511\n",
      "Epoch:472/1000\n",
      "Loss on train= 0.006395714823156595\n",
      "Loss on test= 0.007059021387249231\n",
      "acc for Lsat= 0.1308419819570036 \n",
      "acc for Psat= 0.18713688903993342 \n",
      "acc for optim= 0.1847969277225182\n",
      "Epoch:473/1000\n",
      "Loss on train= 0.006342191249132156\n",
      "Loss on test= 0.006750171072781086\n",
      "acc for Lsat= 0.14370968837934248 \n",
      "acc for Psat= 0.17819247719697592 \n",
      "acc for optim= 0.17965515854253467\n",
      "Epoch:474/1000\n",
      "Loss on train= 0.006516532506793737\n",
      "Loss on test= 0.008131114766001701\n",
      "acc for Lsat= 0.2237313028267127 \n",
      "acc for Psat= 0.18538400205799332 \n",
      "acc for optim= 0.18164614778311955\n",
      "Epoch:475/1000\n",
      "Loss on train= 0.007010870147496462\n",
      "Loss on test= 0.0072854310274124146\n",
      "acc for Lsat= 0.13306215859760168 \n",
      "acc for Psat= 0.20658238835620962 \n",
      "acc for optim= 0.1867675324951267\n",
      "Epoch:476/1000\n",
      "Loss on train= 0.006492817774415016\n",
      "Loss on test= 0.00678993808105588\n",
      "acc for Lsat= 0.11685639501083642 \n",
      "acc for Psat= 0.15770944753756463 \n",
      "acc for optim= 0.17727179857468137\n",
      "Epoch:477/1000\n",
      "Loss on train= 0.0067614237777888775\n",
      "Loss on test= 0.007247415836900473\n",
      "acc for Lsat= 0.14161312840780307 \n",
      "acc for Psat= 0.1734529659124407 \n",
      "acc for optim= 0.18264294906481865\n",
      "Epoch:478/1000\n",
      "Loss on train= 0.0065687899477779865\n",
      "Loss on test= 0.006861494388431311\n",
      "acc for Lsat= 0.11524302890643644 \n",
      "acc for Psat= 0.16119848188590968 \n",
      "acc for optim= 0.17996809317540946\n",
      "Epoch:479/1000\n",
      "Loss on train= 0.0066243433393538\n",
      "Loss on test= 0.0069310711696743965\n",
      "acc for Lsat= 0.12049246846848183 \n",
      "acc for Psat= 0.1708243468468042 \n",
      "acc for optim= 0.18229428871151976\n",
      "Epoch:480/1000\n",
      "Loss on train= 0.0063543012365698814\n",
      "Loss on test= 0.006842104252427816\n",
      "acc for Lsat= 0.12348283854066182 \n",
      "acc for Psat= 0.18620217050469118 \n",
      "acc for optim= 0.19016359129612792\n",
      "Epoch:481/1000\n",
      "Loss on train= 0.006505307741463184\n",
      "Loss on test= 0.006887192837893963\n",
      "acc for Lsat= 0.13085915297842032 \n",
      "acc for Psat= 0.16165903552910865 \n",
      "acc for optim= 0.1813493149386624\n",
      "Epoch:482/1000\n",
      "Loss on train= 0.006363105494529009\n",
      "Loss on test= 0.006700713653117418\n",
      "acc for Lsat= 0.11895814881762648 \n",
      "acc for Psat= 0.15887726372240063 \n",
      "acc for optim= 0.1745823247254613\n",
      "Epoch:483/1000\n",
      "Loss on train= 0.006334667559713125\n",
      "Loss on test= 0.007204268127679825\n",
      "acc for Lsat= 0.13061095444580256 \n",
      "acc for Psat= 0.1919010145179296 \n",
      "acc for optim= 0.18681226266366507\n",
      "Epoch:484/1000\n",
      "Loss on train= 0.006571554113179445\n",
      "Loss on test= 0.007120952010154724\n",
      "acc for Lsat= 0.1369637379845036 \n",
      "acc for Psat= 0.1612667700392194 \n",
      "acc for optim= 0.18040482703057686\n",
      "Epoch:485/1000\n",
      "Loss on train= 0.006536622531712055\n",
      "Loss on test= 0.006688219960778952\n",
      "acc for Lsat= 0.11690813187148197 \n",
      "acc for Psat= 0.16837894586403263 \n",
      "acc for optim= 0.1780398343567405\n",
      "Epoch:486/1000\n",
      "Loss on train= 0.006492281798273325\n",
      "Loss on test= 0.007542000617831945\n",
      "acc for Lsat= 0.12211326902180822 \n",
      "acc for Psat= 0.19740083787237073 \n",
      "acc for optim= 0.1907633846875288\n",
      "Epoch:487/1000\n",
      "Loss on train= 0.00636874558404088\n",
      "Loss on test= 0.00669452641159296\n",
      "acc for Lsat= 0.1213103376624423 \n",
      "acc for Psat= 0.16848550406245166 \n",
      "acc for optim= 0.18229606390795183\n",
      "Epoch:488/1000\n",
      "Loss on train= 0.006459118332713842\n",
      "Loss on test= 0.007644998375326395\n",
      "acc for Lsat= 0.1810184082995027 \n",
      "acc for Psat= 0.1915372348812772 \n",
      "acc for optim= 0.1845293249311399\n",
      "Epoch:489/1000\n",
      "Loss on train= 0.0062979841604828835\n",
      "Loss on test= 0.0068612792529165745\n",
      "acc for Lsat= 0.1458364695286915 \n",
      "acc for Psat= 0.17535809306743538 \n",
      "acc for optim= 0.18161337382250892\n",
      "Epoch:490/1000\n",
      "Loss on train= 0.006312157493084669\n",
      "Loss on test= 0.0070243398658931255\n",
      "acc for Lsat= 0.1275744380064356 \n",
      "acc for Psat= 0.1705074987064463 \n",
      "acc for optim= 0.19049625634215772\n",
      "Epoch:491/1000\n",
      "Loss on train= 0.006253567058593035\n",
      "Loss on test= 0.0068323370069265366\n",
      "acc for Lsat= 0.11781145022882117 \n",
      "acc for Psat= 0.17011456321530297 \n",
      "acc for optim= 0.1774834499428033\n",
      "Epoch:492/1000\n",
      "Loss on train= 0.006328410003334284\n",
      "Loss on test= 0.006969859357923269\n",
      "acc for Lsat= 0.14364155501292986 \n",
      "acc for Psat= 0.16888106851868126 \n",
      "acc for optim= 0.19004676355210812\n",
      "Epoch:493/1000\n",
      "Loss on train= 0.006380434613674879\n",
      "Loss on test= 0.006556099746376276\n",
      "acc for Lsat= 0.12393242792400011 \n",
      "acc for Psat= 0.16579133266804078 \n",
      "acc for optim= 0.18555795966481822\n",
      "Epoch:494/1000\n",
      "Loss on train= 0.006349163595587015\n",
      "Loss on test= 0.007464457303285599\n",
      "acc for Lsat= 0.15492765362472155 \n",
      "acc for Psat= 0.16928949550394032 \n",
      "acc for optim= 0.18738362048091603\n",
      "Epoch:495/1000\n",
      "Loss on train= 0.006567084230482578\n",
      "Loss on test= 0.0070615410804748535\n",
      "acc for Lsat= 0.11000594406001965 \n",
      "acc for Psat= 0.15522481321533046 \n",
      "acc for optim= 0.17798738847861573\n",
      "Epoch:496/1000\n",
      "Loss on train= 0.006507948040962219\n",
      "Loss on test= 0.007396479602903128\n",
      "acc for Lsat= 0.1225622375401021 \n",
      "acc for Psat= 0.1809248897199661 \n",
      "acc for optim= 0.17556787818311162\n",
      "Epoch:497/1000\n",
      "Loss on train= 0.006517438683658838\n",
      "Loss on test= 0.007124715019017458\n",
      "acc for Lsat= 0.11785301486113092 \n",
      "acc for Psat= 0.19174672557925015 \n",
      "acc for optim= 0.18461628102350158\n",
      "Epoch:498/1000\n",
      "Loss on train= 0.0064412071369588375\n",
      "Loss on test= 0.006955583114176989\n",
      "acc for Lsat= 0.11023927400913681 \n",
      "acc for Psat= 0.18191914035646656 \n",
      "acc for optim= 0.184639593832179\n",
      "Epoch:499/1000\n",
      "Loss on train= 0.006242966745048761\n",
      "Loss on test= 0.00652683712542057\n",
      "acc for Lsat= 0.12170860188277202 \n",
      "acc for Psat= 0.16516346659569783 \n",
      "acc for optim= 0.1748444527569148\n",
      "Epoch:500/1000\n",
      "Loss on train= 0.006350772455334663\n",
      "Loss on test= 0.007120971567928791\n",
      "acc for Lsat= 0.1458427370779445 \n",
      "acc for Psat= 0.1579349678617476 \n",
      "acc for optim= 0.19538710943218005\n",
      "Epoch:501/1000\n",
      "Loss on train= 0.0062891170382499695\n",
      "Loss on test= 0.006919425912201405\n",
      "acc for Lsat= 0.13946220798149578 \n",
      "acc for Psat= 0.17486365301084658 \n",
      "acc for optim= 0.19156580279202406\n",
      "Epoch:502/1000\n",
      "Loss on train= 0.006304361391812563\n",
      "Loss on test= 0.006708098109811544\n",
      "acc for Lsat= 0.11891382693064446 \n",
      "acc for Psat= 0.17781216000439598 \n",
      "acc for optim= 0.19202364330057656\n",
      "Epoch:503/1000\n",
      "Loss on train= 0.0064837452955543995\n",
      "Loss on test= 0.007613781839609146\n",
      "acc for Lsat= 0.14332166467043492 \n",
      "acc for Psat= 0.20951728054689306 \n",
      "acc for optim= 0.18528598776211472\n",
      "Epoch:504/1000\n",
      "Loss on train= 0.006463772151619196\n",
      "Loss on test= 0.006552181206643581\n",
      "acc for Lsat= 0.11911921069845988 \n",
      "acc for Psat= 0.15689791161325262 \n",
      "acc for optim= 0.17822105063979368\n",
      "Epoch:505/1000\n",
      "Loss on train= 0.006245788652449846\n",
      "Loss on test= 0.006609548814594746\n",
      "acc for Lsat= 0.12414210414869203 \n",
      "acc for Psat= 0.16713662330530804 \n",
      "acc for optim= 0.17469338605701293\n",
      "Epoch:506/1000\n",
      "Loss on train= 0.006336285267025232\n",
      "Loss on test= 0.006635204888880253\n",
      "acc for Lsat= 0.12715622358008336 \n",
      "acc for Psat= 0.1647154736589597 \n",
      "acc for optim= 0.18362501135581347\n",
      "Epoch:507/1000\n",
      "Loss on train= 0.006104998290538788\n",
      "Loss on test= 0.006609427742660046\n",
      "acc for Lsat= 0.10859187549045231 \n",
      "acc for Psat= 0.17787463475863244 \n",
      "acc for optim= 0.18415712604330758\n",
      "Epoch:508/1000\n",
      "Loss on train= 0.006124552804976702\n",
      "Loss on test= 0.006552062928676605\n",
      "acc for Lsat= 0.1172817949568695 \n",
      "acc for Psat= 0.1552175935215743 \n",
      "acc for optim= 0.17373419796665182\n",
      "Epoch:509/1000\n",
      "Loss on train= 0.0061453706584870815\n",
      "Loss on test= 0.007167513947933912\n",
      "acc for Lsat= 0.15064146611139068 \n",
      "acc for Psat= 0.1642447583752258 \n",
      "acc for optim= 0.18044735367115886\n",
      "Epoch:510/1000\n",
      "Loss on train= 0.006456592585891485\n",
      "Loss on test= 0.006854289211332798\n",
      "acc for Lsat= 0.11229017310996808 \n",
      "acc for Psat= 0.16158969938534043 \n",
      "acc for optim= 0.19449886719585727\n",
      "Epoch:511/1000\n",
      "Loss on train= 0.006360921543091536\n",
      "Loss on test= 0.006515206303447485\n",
      "acc for Lsat= 0.11728536137458631 \n",
      "acc for Psat= 0.16205622502168546 \n",
      "acc for optim= 0.17973159977163805\n",
      "Epoch:512/1000\n",
      "Loss on train= 0.006273665931075811\n",
      "Loss on test= 0.00676103588193655\n",
      "acc for Lsat= 0.10329430934152234 \n",
      "acc for Psat= 0.18440049116941706 \n",
      "acc for optim= 0.18506506413815274\n",
      "Epoch:513/1000\n",
      "Loss on train= 0.0061959740705788136\n",
      "Loss on test= 0.006794873159378767\n",
      "acc for Lsat= 0.11101808615193616 \n",
      "acc for Psat= 0.18115108027695126 \n",
      "acc for optim= 0.17955335001007386\n",
      "Epoch:514/1000\n",
      "Loss on train= 0.006240534596145153\n",
      "Loss on test= 0.007121331058442593\n",
      "acc for Lsat= 0.1407885631852215 \n",
      "acc for Psat= 0.17283247128174387 \n",
      "acc for optim= 0.17926786476982978\n",
      "Epoch:515/1000\n",
      "Loss on train= 0.0064687361009418964\n",
      "Loss on test= 0.0066989632323384285\n",
      "acc for Lsat= 0.1287286545995473 \n",
      "acc for Psat= 0.16413598006543845 \n",
      "acc for optim= 0.18162728232880107\n",
      "Epoch:516/1000\n",
      "Loss on train= 0.006232722196727991\n",
      "Loss on test= 0.007248633541166782\n",
      "acc for Lsat= 0.17015231300255884 \n",
      "acc for Psat= 0.1619748406771223 \n",
      "acc for optim= 0.1898833502717395\n",
      "Epoch:517/1000\n",
      "Loss on train= 0.006438856013119221\n",
      "Loss on test= 0.006387673784047365\n",
      "acc for Lsat= 0.11778752051345151 \n",
      "acc for Psat= 0.14837636394525872 \n",
      "acc for optim= 0.18033113607592186\n",
      "Epoch:518/1000\n",
      "Loss on train= 0.006181969307363033\n",
      "Loss on test= 0.00660962238907814\n",
      "acc for Lsat= 0.11099312266461173 \n",
      "acc for Psat= 0.16634348219919604 \n",
      "acc for optim= 0.17679962817183892\n",
      "Epoch:519/1000\n",
      "Loss on train= 0.006123112980276346\n",
      "Loss on test= 0.006415625102818012\n",
      "acc for Lsat= 0.11426346306866667 \n",
      "acc for Psat= 0.16900712883571495 \n",
      "acc for optim= 0.18766699789557606\n",
      "Epoch:520/1000\n",
      "Loss on train= 0.006118402816355228\n",
      "Loss on test= 0.006727835163474083\n",
      "acc for Lsat= 0.11464111196446075 \n",
      "acc for Psat= 0.15695666342291004 \n",
      "acc for optim= 0.1800714381268027\n",
      "Epoch:521/1000\n",
      "Loss on train= 0.006080945022404194\n",
      "Loss on test= 0.006710606161504984\n",
      "acc for Lsat= 0.11409394656943347 \n",
      "acc for Psat= 0.16425476418965954 \n",
      "acc for optim= 0.1812119336982289\n",
      "Epoch:522/1000\n",
      "Loss on train= 0.006236837711185217\n",
      "Loss on test= 0.006908741779625416\n",
      "acc for Lsat= 0.12071489545820534 \n",
      "acc for Psat= 0.14601726870903928 \n",
      "acc for optim= 0.17639868984204102\n",
      "Epoch:523/1000\n",
      "Loss on train= 0.00609807251021266\n",
      "Loss on test= 0.00659524230286479\n",
      "acc for Lsat= 0.11308785983424444 \n",
      "acc for Psat= 0.16430795559900324 \n",
      "acc for optim= 0.1858833844369964\n",
      "Epoch:524/1000\n",
      "Loss on train= 0.006270868703722954\n",
      "Loss on test= 0.006679960060864687\n",
      "acc for Lsat= 0.12431530675286491 \n",
      "acc for Psat= 0.170990463209384 \n",
      "acc for optim= 0.17835961931179894\n",
      "Epoch:525/1000\n",
      "Loss on train= 0.006148421671241522\n",
      "Loss on test= 0.006353746633976698\n",
      "acc for Lsat= 0.10659318578792579 \n",
      "acc for Psat= 0.14945539554277182 \n",
      "acc for optim= 0.1801644966900112\n",
      "Epoch:526/1000\n",
      "Loss on train= 0.006099389865994453\n",
      "Loss on test= 0.006604607682675123\n",
      "acc for Lsat= 0.1152986084678313 \n",
      "acc for Psat= 0.16044472203949087 \n",
      "acc for optim= 0.1838161650064433\n",
      "Epoch:527/1000\n",
      "Loss on train= 0.006130722817033529\n",
      "Loss on test= 0.006526656914502382\n",
      "acc for Lsat= 0.12514182985128866 \n",
      "acc for Psat= 0.1626570812016094 \n",
      "acc for optim= 0.17958800296409655\n",
      "Epoch:528/1000\n",
      "Loss on train= 0.006149010267108679\n",
      "Loss on test= 0.006917659193277359\n",
      "acc for Lsat= 0.13536800700546262 \n",
      "acc for Psat= 0.15987389591597495 \n",
      "acc for optim= 0.17852832075421524\n",
      "Epoch:529/1000\n",
      "Loss on train= 0.006078803446143866\n",
      "Loss on test= 0.006858654320240021\n",
      "acc for Lsat= 0.11443411682306205 \n",
      "acc for Psat= 0.15310848835832044 \n",
      "acc for optim= 0.1820165895826333\n",
      "Epoch:530/1000\n",
      "Loss on train= 0.006266792304813862\n",
      "Loss on test= 0.00684303417801857\n",
      "acc for Lsat= 0.1167663362170461 \n",
      "acc for Psat= 0.15452159074425176 \n",
      "acc for optim= 0.1807270472341955\n",
      "Epoch:531/1000\n",
      "Loss on train= 0.006068271119147539\n",
      "Loss on test= 0.006598758045583963\n",
      "acc for Lsat= 0.11775485749368288 \n",
      "acc for Psat= 0.15569841162453532 \n",
      "acc for optim= 0.17964652008179702\n",
      "Epoch:532/1000\n",
      "Loss on train= 0.0058563933707773685\n",
      "Loss on test= 0.00691252714022994\n",
      "acc for Lsat= 0.14941678796341135 \n",
      "acc for Psat= 0.16471366528717613 \n",
      "acc for optim= 0.1798650114366911\n",
      "Epoch:533/1000\n",
      "Loss on train= 0.006405785214155912\n",
      "Loss on test= 0.006887503899633884\n",
      "acc for Lsat= 0.11794248717842955 \n",
      "acc for Psat= 0.17084278137604628 \n",
      "acc for optim= 0.19433699209002336\n",
      "Epoch:534/1000\n",
      "Loss on train= 0.00649811327457428\n",
      "Loss on test= 0.006936002057045698\n",
      "acc for Lsat= 0.11084522380911888 \n",
      "acc for Psat= 0.17660761559243962 \n",
      "acc for optim= 0.19364033337175388\n",
      "Epoch:535/1000\n",
      "Loss on train= 0.00634100753813982\n",
      "Loss on test= 0.006491344887763262\n",
      "acc for Lsat= 0.11160279791728175 \n",
      "acc for Psat= 0.15831793500835636 \n",
      "acc for optim= 0.18941542851320325\n",
      "Epoch:536/1000\n",
      "Loss on train= 0.006201212294399738\n",
      "Loss on test= 0.0068541234359145164\n",
      "acc for Lsat= 0.1231087913890606 \n",
      "acc for Psat= 0.15708796855819931 \n",
      "acc for optim= 0.1852326886085162\n",
      "Epoch:537/1000\n",
      "Loss on train= 0.00602445425465703\n",
      "Loss on test= 0.00668595265597105\n",
      "acc for Lsat= 0.10893914009053733 \n",
      "acc for Psat= 0.16782906514481974 \n",
      "acc for optim= 0.1887954810642148\n",
      "Epoch:538/1000\n",
      "Loss on train= 0.006094246171414852\n",
      "Loss on test= 0.006273268721997738\n",
      "acc for Lsat= 0.12293364317256265 \n",
      "acc for Psat= 0.16136456512968386 \n",
      "acc for optim= 0.1830051051073913\n",
      "Epoch:539/1000\n",
      "Loss on train= 0.005936045665293932\n",
      "Loss on test= 0.006593689322471619\n",
      "acc for Lsat= 0.10642558554546529 \n",
      "acc for Psat= 0.1610736652332658 \n",
      "acc for optim= 0.18083711730639876\n",
      "Epoch:540/1000\n",
      "Loss on train= 0.006026766262948513\n",
      "Loss on test= 0.006412019953131676\n",
      "acc for Lsat= 0.11926662901582165 \n",
      "acc for Psat= 0.16940501235441258 \n",
      "acc for optim= 0.1828594567875725\n",
      "Epoch:541/1000\n",
      "Loss on train= 0.005950648337602615\n",
      "Loss on test= 0.006573543883860111\n",
      "acc for Lsat= 0.1348953862725836 \n",
      "acc for Psat= 0.14919043123066994 \n",
      "acc for optim= 0.18868225854535398\n",
      "Epoch:542/1000\n",
      "Loss on train= 0.005940685514360666\n",
      "Loss on test= 0.006589746568351984\n",
      "acc for Lsat= 0.1134627478329664 \n",
      "acc for Psat= 0.15278924415509565 \n",
      "acc for optim= 0.17837358705139073\n",
      "Epoch:543/1000\n",
      "Loss on train= 0.005969735328108072\n",
      "Loss on test= 0.006470437161624432\n",
      "acc for Lsat= 0.10406407408329453 \n",
      "acc for Psat= 0.1468667045699322 \n",
      "acc for optim= 0.1867717859548343\n",
      "Epoch:544/1000\n",
      "Loss on train= 0.005915882997214794\n",
      "Loss on test= 0.0063989670015871525\n",
      "acc for Lsat= 0.10846426654306153 \n",
      "acc for Psat= 0.15403040236392912 \n",
      "acc for optim= 0.1781305476395666\n",
      "Epoch:545/1000\n",
      "Loss on train= 0.006062020547688007\n",
      "Loss on test= 0.006814027205109596\n",
      "acc for Lsat= 0.11796372751419243 \n",
      "acc for Psat= 0.18411185507982245 \n",
      "acc for optim= 0.17929370722228313\n",
      "Epoch:546/1000\n",
      "Loss on train= 0.006134322844445705\n",
      "Loss on test= 0.006846267729997635\n",
      "acc for Lsat= 0.116188404873858 \n",
      "acc for Psat= 0.1962782076641846 \n",
      "acc for optim= 0.19264343382195784\n",
      "Epoch:547/1000\n",
      "Loss on train= 0.006077265832573175\n",
      "Loss on test= 0.00647716922685504\n",
      "acc for Lsat= 0.11024010158469506 \n",
      "acc for Psat= 0.1519634974068741 \n",
      "acc for optim= 0.18091345200151346\n",
      "Epoch:548/1000\n",
      "Loss on train= 0.0059853121638298035\n",
      "Loss on test= 0.007155699655413628\n",
      "acc for Lsat= 0.11985728639627855 \n",
      "acc for Psat= 0.2054239977018955 \n",
      "acc for optim= 0.18241840104288343\n",
      "Epoch:549/1000\n",
      "Loss on train= 0.006348520517349243\n",
      "Loss on test= 0.006836544256657362\n",
      "acc for Lsat= 0.11678349789235962 \n",
      "acc for Psat= 0.14948433831202654 \n",
      "acc for optim= 0.18862727220837122\n",
      "Epoch:550/1000\n",
      "Loss on train= 0.00610694196075201\n",
      "Loss on test= 0.006598389241844416\n",
      "acc for Lsat= 0.11884054687166176 \n",
      "acc for Psat= 0.16901214245619978 \n",
      "acc for optim= 0.1778218955055108\n",
      "Epoch:551/1000\n",
      "Loss on train= 0.006048217881470919\n",
      "Loss on test= 0.0064069596119225025\n",
      "acc for Lsat= 0.10739886175700014 \n",
      "acc for Psat= 0.1421351205380002 \n",
      "acc for optim= 0.18142885555911778\n",
      "Epoch:552/1000\n",
      "Loss on train= 0.0058799684047698975\n",
      "Loss on test= 0.006519420072436333\n",
      "acc for Lsat= 0.11667337969569015 \n",
      "acc for Psat= 0.14556729044563974 \n",
      "acc for optim= 0.1841050460697862\n",
      "Epoch:553/1000\n",
      "Loss on train= 0.006010399665683508\n",
      "Loss on test= 0.006524938158690929\n",
      "acc for Lsat= 0.1161672921793563 \n",
      "acc for Psat= 0.15350893902872548 \n",
      "acc for optim= 0.18541362864474403\n",
      "Epoch:554/1000\n",
      "Loss on train= 0.006146393250674009\n",
      "Loss on test= 0.006660886574536562\n",
      "acc for Lsat= 0.1264191298039188 \n",
      "acc for Psat= 0.17468397212939898 \n",
      "acc for optim= 0.18786583342628901\n",
      "Epoch:555/1000\n",
      "Loss on train= 0.005953713320195675\n",
      "Loss on test= 0.006437747739255428\n",
      "acc for Lsat= 0.10409422224516768 \n",
      "acc for Psat= 0.14980121653041628 \n",
      "acc for optim= 0.1931247948754482\n",
      "Epoch:556/1000\n",
      "Loss on train= 0.006072624586522579\n",
      "Loss on test= 0.006382841616868973\n",
      "acc for Lsat= 0.11050015471784903 \n",
      "acc for Psat= 0.14427181611397952 \n",
      "acc for optim= 0.1831169060391958\n",
      "Epoch:557/1000\n",
      "Loss on train= 0.0060829659923911095\n",
      "Loss on test= 0.006638590712100267\n",
      "acc for Lsat= 0.10987781243886151 \n",
      "acc for Psat= 0.1739817114170025 \n",
      "acc for optim= 0.1775365782457688\n",
      "Epoch:558/1000\n",
      "Loss on train= 0.006047223228961229\n",
      "Loss on test= 0.006496695335954428\n",
      "acc for Lsat= 0.11564013669822243 \n",
      "acc for Psat= 0.14695937968021006 \n",
      "acc for optim= 0.18349493208136095\n",
      "Epoch:559/1000\n",
      "Loss on train= 0.005899455863982439\n",
      "Loss on test= 0.00647325674071908\n",
      "acc for Lsat= 0.11645269942256796 \n",
      "acc for Psat= 0.14313486499210692 \n",
      "acc for optim= 0.1868973266017639\n",
      "Epoch:560/1000\n",
      "Loss on train= 0.006149322260171175\n",
      "Loss on test= 0.006504678633064032\n",
      "acc for Lsat= 0.11218634181669755 \n",
      "acc for Psat= 0.14379733786897259 \n",
      "acc for optim= 0.182233160420774\n",
      "Epoch:561/1000\n",
      "Loss on train= 0.005854638293385506\n",
      "Loss on test= 0.006478253286331892\n",
      "acc for Lsat= 0.11199645688086432 \n",
      "acc for Psat= 0.1445784879887824 \n",
      "acc for optim= 0.18023677146759268\n",
      "Epoch:562/1000\n",
      "Loss on train= 0.0059621757827699184\n",
      "Loss on test= 0.007015065755695105\n",
      "acc for Lsat= 0.118956050919211 \n",
      "acc for Psat= 0.15590845682733234 \n",
      "acc for optim= 0.19089788130989646\n",
      "Epoch:563/1000\n",
      "Loss on train= 0.0058814603835344315\n",
      "Loss on test= 0.006623419467359781\n",
      "acc for Lsat= 0.11597716206362008 \n",
      "acc for Psat= 0.14270610714210907 \n",
      "acc for optim= 0.18506609430473486\n",
      "Epoch:564/1000\n",
      "Loss on train= 0.006214379798620939\n",
      "Loss on test= 0.006532659754157066\n",
      "acc for Lsat= 0.11912558016237029 \n",
      "acc for Psat= 0.15095501136556622 \n",
      "acc for optim= 0.17983227797894408\n",
      "Epoch:565/1000\n",
      "Loss on train= 0.006163112819194794\n",
      "Loss on test= 0.006725895684212446\n",
      "acc for Lsat= 0.10282984633971463 \n",
      "acc for Psat= 0.15249986431356205 \n",
      "acc for optim= 0.18272370215884204\n",
      "Epoch:566/1000\n",
      "Loss on train= 0.005914468318223953\n",
      "Loss on test= 0.006748632062226534\n",
      "acc for Lsat= 0.10646338564773772 \n",
      "acc for Psat= 0.17776902682755646 \n",
      "acc for optim= 0.18412835312162731\n",
      "Epoch:567/1000\n",
      "Loss on train= 0.005996834486722946\n",
      "Loss on test= 0.00657717976719141\n",
      "acc for Lsat= 0.10503822414606999 \n",
      "acc for Psat= 0.16665909288932523 \n",
      "acc for optim= 0.1790202047774505\n",
      "Epoch:568/1000\n",
      "Loss on train= 0.006096409168094397\n",
      "Loss on test= 0.006668624468147755\n",
      "acc for Lsat= 0.11840058729009134 \n",
      "acc for Psat= 0.17799155585965046 \n",
      "acc for optim= 0.1799554372692463\n",
      "Epoch:569/1000\n",
      "Loss on train= 0.006106340326368809\n",
      "Loss on test= 0.006500187795609236\n",
      "acc for Lsat= 0.10583985457628456 \n",
      "acc for Psat= 0.14064852874513945 \n",
      "acc for optim= 0.19087770982730298\n",
      "Epoch:570/1000\n",
      "Loss on train= 0.0060556246899068356\n",
      "Loss on test= 0.006654293276369572\n",
      "acc for Lsat= 0.10098406843050833 \n",
      "acc for Psat= 0.14170576995554365 \n",
      "acc for optim= 0.1844687168914588\n",
      "Epoch:571/1000\n",
      "Loss on train= 0.006088629364967346\n",
      "Loss on test= 0.006382439285516739\n",
      "acc for Lsat= 0.10599239812571934 \n",
      "acc for Psat= 0.15100809101181073 \n",
      "acc for optim= 0.1837814419443514\n",
      "Epoch:572/1000\n",
      "Loss on train= 0.005995574407279491\n",
      "Loss on test= 0.0064011369831860065\n",
      "acc for Lsat= 0.11278166682905837 \n",
      "acc for Psat= 0.16466679228252684 \n",
      "acc for optim= 0.17954972677822698\n",
      "Epoch:573/1000\n",
      "Loss on train= 0.005868438631296158\n",
      "Loss on test= 0.00649215467274189\n",
      "acc for Lsat= 0.1043595069719447 \n",
      "acc for Psat= 0.15713493364736816 \n",
      "acc for optim= 0.17482991747625204\n",
      "Epoch:574/1000\n",
      "Loss on train= 0.006172505673021078\n",
      "Loss on test= 0.006474415771663189\n",
      "acc for Lsat= 0.10724502575575863 \n",
      "acc for Psat= 0.14539430787376428 \n",
      "acc for optim= 0.1829955336428642\n",
      "Epoch:575/1000\n",
      "Loss on train= 0.005854587536305189\n",
      "Loss on test= 0.0063741253688931465\n",
      "acc for Lsat= 0.12482053988304391 \n",
      "acc for Psat= 0.1494413250214736 \n",
      "acc for optim= 0.18566021685591125\n",
      "Epoch:576/1000\n",
      "Loss on train= 0.005885597784072161\n",
      "Loss on test= 0.006560022477060556\n",
      "acc for Lsat= 0.10539844232271978 \n",
      "acc for Psat= 0.14129733225504346 \n",
      "acc for optim= 0.17681954449429413\n",
      "Epoch:577/1000\n",
      "Loss on train= 0.005826551467180252\n",
      "Loss on test= 0.006707069464027882\n",
      "acc for Lsat= 0.12388849361262963 \n",
      "acc for Psat= 0.1878315680879326 \n",
      "acc for optim= 0.18779012151575505\n",
      "Epoch:578/1000\n",
      "Loss on train= 0.006169336382299662\n",
      "Loss on test= 0.006767357233911753\n",
      "acc for Lsat= 0.11177344636767668 \n",
      "acc for Psat= 0.16354430545894902 \n",
      "acc for optim= 0.19279064297486417\n",
      "Epoch:579/1000\n",
      "Loss on train= 0.00606519216671586\n",
      "Loss on test= 0.006387590896338224\n",
      "acc for Lsat= 0.1277564436346253 \n",
      "acc for Psat= 0.15434414211194963 \n",
      "acc for optim= 0.18092683958692746\n",
      "Epoch:580/1000\n",
      "Loss on train= 0.005812437739223242\n",
      "Loss on test= 0.0064177741296589375\n",
      "acc for Lsat= 0.11460047838839474 \n",
      "acc for Psat= 0.14955550589577998 \n",
      "acc for optim= 0.1800714955286328\n",
      "Epoch:581/1000\n",
      "Loss on train= 0.005939733237028122\n",
      "Loss on test= 0.006405604537576437\n",
      "acc for Lsat= 0.11621548873880459 \n",
      "acc for Psat= 0.1515174044710505 \n",
      "acc for optim= 0.17981171480743058\n",
      "Epoch:582/1000\n",
      "Loss on train= 0.005895689595490694\n",
      "Loss on test= 0.006306665949523449\n",
      "acc for Lsat= 0.11437423658582888 \n",
      "acc for Psat= 0.14655938523237483 \n",
      "acc for optim= 0.17785207247716706\n",
      "Epoch:583/1000\n",
      "Loss on train= 0.005938960704952478\n",
      "Loss on test= 0.006475952919572592\n",
      "acc for Lsat= 0.10568637904075716 \n",
      "acc for Psat= 0.16046851543271598 \n",
      "acc for optim= 0.18359554180543933\n",
      "Epoch:584/1000\n",
      "Loss on train= 0.006049425806850195\n",
      "Loss on test= 0.006314034573733807\n",
      "acc for Lsat= 0.10060952002956074 \n",
      "acc for Psat= 0.15048910379000363 \n",
      "acc for optim= 0.17766683360712057\n",
      "Epoch:585/1000\n",
      "Loss on train= 0.006133735179901123\n",
      "Loss on test= 0.0069009894505143166\n",
      "acc for Lsat= 0.1533911901999707 \n",
      "acc for Psat= 0.15437814231085892 \n",
      "acc for optim= 0.18973524146831705\n",
      "Epoch:586/1000\n",
      "Loss on train= 0.005967009346932173\n",
      "Loss on test= 0.006359557621181011\n",
      "acc for Lsat= 0.11059557453322745 \n",
      "acc for Psat= 0.14852434394245284 \n",
      "acc for optim= 0.1782439050525851\n",
      "Epoch:587/1000\n",
      "Loss on train= 0.005889337509870529\n",
      "Loss on test= 0.006400702521204948\n",
      "acc for Lsat= 0.10591792183359927 \n",
      "acc for Psat= 0.1597557343503113 \n",
      "acc for optim= 0.1799869435827516\n",
      "Epoch:588/1000\n",
      "Loss on train= 0.006024064030498266\n",
      "Loss on test= 0.006938866339623928\n",
      "acc for Lsat= 0.1297665894701406 \n",
      "acc for Psat= 0.1863257527976603 \n",
      "acc for optim= 0.18075237314688372\n",
      "Epoch:589/1000\n",
      "Loss on train= 0.005926476325839758\n",
      "Loss on test= 0.006821203976869583\n",
      "acc for Lsat= 0.14674039341793474 \n",
      "acc for Psat= 0.15934211283229624 \n",
      "acc for optim= 0.18221421642337485\n",
      "Epoch:590/1000\n",
      "Loss on train= 0.00616796500980854\n",
      "Loss on test= 0.006776982918381691\n",
      "acc for Lsat= 0.14447941207543993 \n",
      "acc for Psat= 0.1559215353789761 \n",
      "acc for optim= 0.18706589934447684\n",
      "Epoch:591/1000\n",
      "Loss on train= 0.005924553144723177\n",
      "Loss on test= 0.006509376224130392\n",
      "acc for Lsat= 0.10308751136328931 \n",
      "acc for Psat= 0.15877009657422728 \n",
      "acc for optim= 0.176160837423305\n",
      "Epoch:592/1000\n",
      "Loss on train= 0.0059832497499883175\n",
      "Loss on test= 0.006551086436957121\n",
      "acc for Lsat= 0.1156580709276121 \n",
      "acc for Psat= 0.15830883382803806 \n",
      "acc for optim= 0.17241907475967064\n",
      "Epoch:593/1000\n",
      "Loss on train= 0.0057487329468131065\n",
      "Loss on test= 0.006322223227471113\n",
      "acc for Lsat= 0.10487943106425641 \n",
      "acc for Psat= 0.16075831105640567 \n",
      "acc for optim= 0.17887086891648124\n",
      "Epoch:594/1000\n",
      "Loss on train= 0.005948033183813095\n",
      "Loss on test= 0.006708541419357061\n",
      "acc for Lsat= 0.1352377790420995 \n",
      "acc for Psat= 0.14342320838082834 \n",
      "acc for optim= 0.18632328071438123\n",
      "Epoch:595/1000\n",
      "Loss on train= 0.006052195560187101\n",
      "Loss on test= 0.0063631534576416016\n",
      "acc for Lsat= 0.11778521318288551 \n",
      "acc for Psat= 0.14480986404883817 \n",
      "acc for optim= 0.18080610161473565\n",
      "Epoch:596/1000\n",
      "Loss on train= 0.005859739147126675\n",
      "Loss on test= 0.006281579378992319\n",
      "acc for Lsat= 0.10540395084318657 \n",
      "acc for Psat= 0.14776084122161176 \n",
      "acc for optim= 0.18148399591090758\n",
      "Epoch:597/1000\n",
      "Loss on train= 0.00590307405218482\n",
      "Loss on test= 0.006115656346082687\n",
      "acc for Lsat= 0.10261169796734575 \n",
      "acc for Psat= 0.1528152194450278 \n",
      "acc for optim= 0.17828731163231246\n",
      "Epoch:598/1000\n",
      "Loss on train= 0.006035932805389166\n",
      "Loss on test= 0.006828442215919495\n",
      "acc for Lsat= 0.1208733059808225 \n",
      "acc for Psat= 0.1614755857984488 \n",
      "acc for optim= 0.20080558175018345\n",
      "Epoch:599/1000\n",
      "Loss on train= 0.005979814566671848\n",
      "Loss on test= 0.006944373715668917\n",
      "acc for Lsat= 0.1191366011975333 \n",
      "acc for Psat= 0.14300964200707406 \n",
      "acc for optim= 0.1842693775842929\n",
      "Epoch:600/1000\n",
      "Loss on train= 0.006045450456440449\n",
      "Loss on test= 0.006377069745212793\n",
      "acc for Lsat= 0.127044067177152 \n",
      "acc for Psat= 0.15851340362875155 \n",
      "acc for optim= 0.17403293283186633\n",
      "Epoch:601/1000\n",
      "Loss on train= 0.005906963255256414\n",
      "Loss on test= 0.00666135223582387\n",
      "acc for Lsat= 0.11446056363352385 \n",
      "acc for Psat= 0.16357643573497563 \n",
      "acc for optim= 0.18374991119933962\n",
      "Epoch:602/1000\n",
      "Loss on train= 0.005894351284950972\n",
      "Loss on test= 0.006760796532034874\n",
      "acc for Lsat= 0.11808913660361985 \n",
      "acc for Psat= 0.18254765702600953 \n",
      "acc for optim= 0.18369552053203334\n",
      "Epoch:603/1000\n",
      "Loss on train= 0.006032331380993128\n",
      "Loss on test= 0.006326266098767519\n",
      "acc for Lsat= 0.11253128242950555 \n",
      "acc for Psat= 0.1565526002749736 \n",
      "acc for optim= 0.18522313052504244\n",
      "Epoch:604/1000\n",
      "Loss on train= 0.006004790775477886\n",
      "Loss on test= 0.006425313651561737\n",
      "acc for Lsat= 0.11988872302838174 \n",
      "acc for Psat= 0.14764900597984412 \n",
      "acc for optim= 0.1801697859544528\n",
      "Epoch:605/1000\n",
      "Loss on train= 0.00588742271065712\n",
      "Loss on test= 0.006727778818458319\n",
      "acc for Lsat= 0.11960841751666305 \n",
      "acc for Psat= 0.15126982692360752 \n",
      "acc for optim= 0.17871096735204553\n",
      "Epoch:606/1000\n",
      "Loss on train= 0.005933093372732401\n",
      "Loss on test= 0.006612218916416168\n",
      "acc for Lsat= 0.12395744884185152 \n",
      "acc for Psat= 0.15269852535980674 \n",
      "acc for optim= 0.1827295784422165\n",
      "Epoch:607/1000\n",
      "Loss on train= 0.0060184854082763195\n",
      "Loss on test= 0.006538824178278446\n",
      "acc for Lsat= 0.1104526472777144 \n",
      "acc for Psat= 0.14799366404935796 \n",
      "acc for optim= 0.1760635962394082\n",
      "Epoch:608/1000\n",
      "Loss on train= 0.00592064717784524\n",
      "Loss on test= 0.006477490533143282\n",
      "acc for Lsat= 0.1052305014515927 \n",
      "acc for Psat= 0.1652927098530384 \n",
      "acc for optim= 0.17558507177094787\n",
      "Epoch:609/1000\n",
      "Loss on train= 0.005947243422269821\n",
      "Loss on test= 0.006736334878951311\n",
      "acc for Lsat= 0.104171874215708 \n",
      "acc for Psat= 0.175100948200936 \n",
      "acc for optim= 0.18974158122969823\n",
      "Epoch:610/1000\n",
      "Loss on train= 0.005956628825515509\n",
      "Loss on test= 0.0065662674605846405\n",
      "acc for Lsat= 0.11599416375950461 \n",
      "acc for Psat= 0.14266251049091314 \n",
      "acc for optim= 0.17801577450462885\n",
      "Epoch:611/1000\n",
      "Loss on train= 0.00593841215595603\n",
      "Loss on test= 0.006452766712754965\n",
      "acc for Lsat= 0.12197889620379024 \n",
      "acc for Psat= 0.1484019515187957 \n",
      "acc for optim= 0.17993737567014897\n",
      "Epoch:612/1000\n",
      "Loss on train= 0.006189961452037096\n",
      "Loss on test= 0.006384300999343395\n",
      "acc for Lsat= 0.11067336871766217 \n",
      "acc for Psat= 0.1564523195315121 \n",
      "acc for optim= 0.1818648707168966\n",
      "Epoch:613/1000\n",
      "Loss on train= 0.0058202254585921764\n",
      "Loss on test= 0.006571988109499216\n",
      "acc for Lsat= 0.1288163783478598 \n",
      "acc for Psat= 0.14671927943401927 \n",
      "acc for optim= 0.1845534823276497\n",
      "Epoch:614/1000\n",
      "Loss on train= 0.00600009597837925\n",
      "Loss on test= 0.006581341382116079\n",
      "acc for Lsat= 0.12719205496082936 \n",
      "acc for Psat= 0.16117008592709373 \n",
      "acc for optim= 0.18572742430793154\n",
      "Epoch:615/1000\n",
      "Loss on train= 0.005841989070177078\n",
      "Loss on test= 0.006790261249989271\n",
      "acc for Lsat= 0.13039545150123727 \n",
      "acc for Psat= 0.1506932335518995 \n",
      "acc for optim= 0.1875295168878037\n",
      "Epoch:616/1000\n",
      "Loss on train= 0.0057236310094594955\n",
      "Loss on test= 0.006486944854259491\n",
      "acc for Lsat= 0.11247832290216554 \n",
      "acc for Psat= 0.1483936821256559 \n",
      "acc for optim= 0.17576727150047544\n",
      "Epoch:617/1000\n",
      "Loss on train= 0.0058740838430821896\n",
      "Loss on test= 0.006405096501111984\n",
      "acc for Lsat= 0.12115009372098907 \n",
      "acc for Psat= 0.15064412809748565 \n",
      "acc for optim= 0.1786451458189068\n",
      "Epoch:618/1000\n",
      "Loss on train= 0.005739962682127953\n",
      "Loss on test= 0.006794538348913193\n",
      "acc for Lsat= 0.10930000287401727 \n",
      "acc for Psat= 0.17566003390643115 \n",
      "acc for optim= 0.18892268864201162\n",
      "Epoch:619/1000\n",
      "Loss on train= 0.005961953662335873\n",
      "Loss on test= 0.006320760119706392\n",
      "acc for Lsat= 0.11864316397804325 \n",
      "acc for Psat= 0.14631264014080783 \n",
      "acc for optim= 0.18010696100418344\n",
      "Epoch:620/1000\n",
      "Loss on train= 0.005757245700806379\n",
      "Loss on test= 0.006559034809470177\n",
      "acc for Lsat= 0.11676075073251091 \n",
      "acc for Psat= 0.15752552291536231 \n",
      "acc for optim= 0.17889462001799306\n",
      "Epoch:621/1000\n",
      "Loss on train= 0.0057808696292340755\n",
      "Loss on test= 0.006487119477242231\n",
      "acc for Lsat= 0.11739992294125101 \n",
      "acc for Psat= 0.15273882744091927 \n",
      "acc for optim= 0.1826426903551476\n",
      "Epoch:622/1000\n",
      "Loss on train= 0.005812617484480143\n",
      "Loss on test= 0.006309031043201685\n",
      "acc for Lsat= 0.11667520558240554 \n",
      "acc for Psat= 0.15274261996323654 \n",
      "acc for optim= 0.18046417588060248\n",
      "Epoch:623/1000\n",
      "Loss on train= 0.00590185821056366\n",
      "Loss on test= 0.006884356494992971\n",
      "acc for Lsat= 0.11567777310206034 \n",
      "acc for Psat= 0.14958009590765745 \n",
      "acc for optim= 0.1755487395720793\n",
      "Epoch:624/1000\n",
      "Loss on train= 0.0057893358170986176\n",
      "Loss on test= 0.006207125261425972\n",
      "acc for Lsat= 0.10685928578175787 \n",
      "acc for Psat= 0.15132271872233535 \n",
      "acc for optim= 0.1786906770130588\n",
      "Epoch:625/1000\n",
      "Loss on train= 0.005935207474976778\n",
      "Loss on test= 0.006470691412687302\n",
      "acc for Lsat= 0.11598447314327132 \n",
      "acc for Psat= 0.15021129710623457 \n",
      "acc for optim= 0.18043651428624644\n",
      "Epoch:626/1000\n",
      "Loss on train= 0.00579414376989007\n",
      "Loss on test= 0.006874385755509138\n",
      "acc for Lsat= 0.14066615156450515 \n",
      "acc for Psat= 0.15434654514439466 \n",
      "acc for optim= 0.18827305303845096\n",
      "Epoch:627/1000\n",
      "Loss on train= 0.005960681941360235\n",
      "Loss on test= 0.006837241817265749\n",
      "acc for Lsat= 0.12674907583356598 \n",
      "acc for Psat= 0.15555096739238145 \n",
      "acc for optim= 0.1751743190685066\n",
      "Epoch:628/1000\n",
      "Loss on train= 0.006042312830686569\n",
      "Loss on test= 0.006583251990377903\n",
      "acc for Lsat= 0.10375979556364177 \n",
      "acc for Psat= 0.16442138704794884 \n",
      "acc for optim= 0.19153998488268295\n",
      "Epoch:629/1000\n",
      "Loss on train= 0.005845054518431425\n",
      "Loss on test= 0.0065186768770217896\n",
      "acc for Lsat= 0.11634371287359115 \n",
      "acc for Psat= 0.14389989125794905 \n",
      "acc for optim= 0.18566573327417107\n",
      "Epoch:630/1000\n",
      "Loss on train= 0.005746728274971247\n",
      "Loss on test= 0.006407988257706165\n",
      "acc for Lsat= 0.11228415825667148 \n",
      "acc for Psat= 0.15483791330213642 \n",
      "acc for optim= 0.18712130365945656\n",
      "Epoch:631/1000\n",
      "Loss on train= 0.005666166078299284\n",
      "Loss on test= 0.006762102246284485\n",
      "acc for Lsat= 0.10357586069563171 \n",
      "acc for Psat= 0.15771248604080212 \n",
      "acc for optim= 0.1960108036688387\n",
      "Epoch:632/1000\n",
      "Loss on train= 0.00589573010802269\n",
      "Loss on test= 0.006242999341338873\n",
      "acc for Lsat= 0.10529031535794059 \n",
      "acc for Psat= 0.14853066893351674 \n",
      "acc for optim= 0.1759162727767065\n",
      "Epoch:633/1000\n",
      "Loss on train= 0.005787237547338009\n",
      "Loss on test= 0.006312279962003231\n",
      "acc for Lsat= 0.10245583784525772 \n",
      "acc for Psat= 0.147057718106435 \n",
      "acc for optim= 0.17787454762590765\n",
      "Epoch:634/1000\n",
      "Loss on train= 0.005813268478959799\n",
      "Loss on test= 0.006567557342350483\n",
      "acc for Lsat= 0.11403326107311394 \n",
      "acc for Psat= 0.14203450165736348 \n",
      "acc for optim= 0.17714390337400107\n",
      "Epoch:635/1000\n",
      "Loss on train= 0.00600998243317008\n",
      "Loss on test= 0.007032081484794617\n",
      "acc for Lsat= 0.16593979231271325 \n",
      "acc for Psat= 0.14601478402313414 \n",
      "acc for optim= 0.1857480950906115\n",
      "Epoch:636/1000\n",
      "Loss on train= 0.0058724721893668175\n",
      "Loss on test= 0.0067294081673026085\n",
      "acc for Lsat= 0.10583634003765005 \n",
      "acc for Psat= 0.14315985139337037 \n",
      "acc for optim= 0.1871627001328615\n",
      "Epoch:637/1000\n",
      "Loss on train= 0.005977404769510031\n",
      "Loss on test= 0.006702797953039408\n",
      "acc for Lsat= 0.1009837508025003 \n",
      "acc for Psat= 0.15699034225996247 \n",
      "acc for optim= 0.19457057987722584\n",
      "Epoch:638/1000\n",
      "Loss on train= 0.00603808369487524\n",
      "Loss on test= 0.0066859908401966095\n",
      "acc for Lsat= 0.10608144423754697 \n",
      "acc for Psat= 0.17458908221944852 \n",
      "acc for optim= 0.18659156617882142\n",
      "Epoch:639/1000\n",
      "Loss on train= 0.005706080701202154\n",
      "Loss on test= 0.006488936021924019\n",
      "acc for Lsat= 0.10040987783971922 \n",
      "acc for Psat= 0.14504183666934495 \n",
      "acc for optim= 0.18479681720915725\n",
      "Epoch:640/1000\n",
      "Loss on train= 0.005624860990792513\n",
      "Loss on test= 0.0061888801865279675\n",
      "acc for Lsat= 0.1051341194312322 \n",
      "acc for Psat= 0.14543566929294344 \n",
      "acc for optim= 0.18058681339499053\n",
      "Epoch:641/1000\n",
      "Loss on train= 0.0056917015463113785\n",
      "Loss on test= 0.006611229386180639\n",
      "acc for Lsat= 0.11920236041019591 \n",
      "acc for Psat= 0.15147639142006036 \n",
      "acc for optim= 0.19676470520878525\n",
      "Epoch:642/1000\n",
      "Loss on train= 0.006139658857136965\n",
      "Loss on test= 0.006120616104453802\n",
      "acc for Lsat= 0.10397836250721396 \n",
      "acc for Psat= 0.14766811110016148 \n",
      "acc for optim= 0.18436159795412588\n",
      "Epoch:643/1000\n",
      "Loss on train= 0.005905505735427141\n",
      "Loss on test= 0.006110259797424078\n",
      "acc for Lsat= 0.0990954669956039 \n",
      "acc for Psat= 0.1435845061266495 \n",
      "acc for optim= 0.17626149231800808\n",
      "Epoch:644/1000\n",
      "Loss on train= 0.0055817305110394955\n",
      "Loss on test= 0.0068196505308151245\n",
      "acc for Lsat= 0.13205012321803655 \n",
      "acc for Psat= 0.1475370655870223 \n",
      "acc for optim= 0.17879463483701422\n",
      "Epoch:645/1000\n",
      "Loss on train= 0.005768477451056242\n",
      "Loss on test= 0.006759340409189463\n",
      "acc for Lsat= 0.11859981527244198 \n",
      "acc for Psat= 0.1887854276763145 \n",
      "acc for optim= 0.18247693743106863\n",
      "Epoch:646/1000\n",
      "Loss on train= 0.005825337953865528\n",
      "Loss on test= 0.006418292410671711\n",
      "acc for Lsat= 0.11036013678356046 \n",
      "acc for Psat= 0.1446288108067011 \n",
      "acc for optim= 0.1745171371638238\n",
      "Epoch:647/1000\n",
      "Loss on train= 0.005687963683158159\n",
      "Loss on test= 0.006292102392762899\n",
      "acc for Lsat= 0.11696640681613521 \n",
      "acc for Psat= 0.15497688124700196 \n",
      "acc for optim= 0.17655222218432384\n",
      "Epoch:648/1000\n",
      "Loss on train= 0.005792013835161924\n",
      "Loss on test= 0.0065839639864861965\n",
      "acc for Lsat= 0.13411271253860185 \n",
      "acc for Psat= 0.1486642465453893 \n",
      "acc for optim= 0.17895571532880225\n",
      "Epoch:649/1000\n",
      "Loss on train= 0.005912910681217909\n",
      "Loss on test= 0.00655687041580677\n",
      "acc for Lsat= 0.10392101669301262 \n",
      "acc for Psat= 0.1637070941110339 \n",
      "acc for optim= 0.18665919305551482\n",
      "Epoch:650/1000\n",
      "Loss on train= 0.005702029913663864\n",
      "Loss on test= 0.006341669708490372\n",
      "acc for Lsat= 0.11318320617506057 \n",
      "acc for Psat= 0.14038168042424623 \n",
      "acc for optim= 0.17980045357845345\n",
      "Epoch:651/1000\n",
      "Loss on train= 0.005823022220283747\n",
      "Loss on test= 0.0063086142763495445\n",
      "acc for Lsat= 0.10111910794798475 \n",
      "acc for Psat= 0.14627396449707133 \n",
      "acc for optim= 0.18127012177512555\n",
      "Epoch:652/1000\n",
      "Loss on train= 0.005899215582758188\n",
      "Loss on test= 0.0064070262014865875\n",
      "acc for Lsat= 0.09931076626259817 \n",
      "acc for Psat= 0.14405316224460335 \n",
      "acc for optim= 0.1758740570313313\n",
      "Epoch:653/1000\n",
      "Loss on train= 0.005799729377031326\n",
      "Loss on test= 0.006310699041932821\n",
      "acc for Lsat= 0.10686987907294247 \n",
      "acc for Psat= 0.13874698552111622 \n",
      "acc for optim= 0.18187314778826816\n",
      "Epoch:654/1000\n",
      "Loss on train= 0.005721560679376125\n",
      "Loss on test= 0.006313270423561335\n",
      "acc for Lsat= 0.10704418105562612 \n",
      "acc for Psat= 0.14539730570671716 \n",
      "acc for optim= 0.18600651986691785\n",
      "Epoch:655/1000\n",
      "Loss on train= 0.005604814738035202\n",
      "Loss on test= 0.006442091427743435\n",
      "acc for Lsat= 0.09960602678938658 \n",
      "acc for Psat= 0.14666210222571016 \n",
      "acc for optim= 0.18393431402500166\n",
      "Epoch:656/1000\n",
      "Loss on train= 0.005686430726200342\n",
      "Loss on test= 0.006292745005339384\n",
      "acc for Lsat= 0.09426432597930386 \n",
      "acc for Psat= 0.13724431493477424 \n",
      "acc for optim= 0.18132491971413464\n",
      "Epoch:657/1000\n",
      "Loss on train= 0.0055914283730089664\n",
      "Loss on test= 0.005915983580052853\n",
      "acc for Lsat= 0.1031158514341815 \n",
      "acc for Psat= 0.1348618206221036 \n",
      "acc for optim= 0.18054506397427264\n",
      "Epoch:658/1000\n",
      "Loss on train= 0.005762282758951187\n",
      "Loss on test= 0.006299554370343685\n",
      "acc for Lsat= 0.10543913447250754 \n",
      "acc for Psat= 0.15072286564470033 \n",
      "acc for optim= 0.19340657098943928\n",
      "Epoch:659/1000\n",
      "Loss on train= 0.005756467115134001\n",
      "Loss on test= 0.006407980807125568\n",
      "acc for Lsat= 0.12965191398723588 \n",
      "acc for Psat= 0.14622292123775402 \n",
      "acc for optim= 0.18050435943690807\n",
      "Epoch:660/1000\n",
      "Loss on train= 0.005903901997953653\n",
      "Loss on test= 0.006402826402336359\n",
      "acc for Lsat= 0.10616982797958881 \n",
      "acc for Psat= 0.15943549351674954 \n",
      "acc for optim= 0.176558634912461\n",
      "Epoch:661/1000\n",
      "Loss on train= 0.005952303297817707\n",
      "Loss on test= 0.006250645965337753\n",
      "acc for Lsat= 0.0979969625615799 \n",
      "acc for Psat= 0.1621055818312817 \n",
      "acc for optim= 0.18316347717260154\n",
      "Epoch:662/1000\n",
      "Loss on train= 0.005787544883787632\n",
      "Loss on test= 0.0065099685452878475\n",
      "acc for Lsat= 0.11057344668621781 \n",
      "acc for Psat= 0.14870063851536172 \n",
      "acc for optim= 0.19378866914396325\n",
      "Epoch:663/1000\n",
      "Loss on train= 0.005621107295155525\n",
      "Loss on test= 0.006370680406689644\n",
      "acc for Lsat= 0.10393851046268907 \n",
      "acc for Psat= 0.13728811574815694 \n",
      "acc for optim= 0.1749833883743307\n",
      "Epoch:664/1000\n",
      "Loss on train= 0.005789229180663824\n",
      "Loss on test= 0.0061635831370949745\n",
      "acc for Lsat= 0.11329626943067632 \n",
      "acc for Psat= 0.13523914042664928 \n",
      "acc for optim= 0.18019945342961888\n",
      "Epoch:665/1000\n",
      "Loss on train= 0.005774885416030884\n",
      "Loss on test= 0.007573454175144434\n",
      "acc for Lsat= 0.14857908623594931 \n",
      "acc for Psat= 0.17775718378518723 \n",
      "acc for optim= 0.18041409246566295\n",
      "Epoch:666/1000\n",
      "Loss on train= 0.006152397952973843\n",
      "Loss on test= 0.006785087287425995\n",
      "acc for Lsat= 0.13584124470105932 \n",
      "acc for Psat= 0.1602387912681926 \n",
      "acc for optim= 0.17980285143258712\n",
      "Epoch:667/1000\n",
      "Loss on train= 0.005805719643831253\n",
      "Loss on test= 0.006307942792773247\n",
      "acc for Lsat= 0.11520665376743112 \n",
      "acc for Psat= 0.15054066542543912 \n",
      "acc for optim= 0.18381412652835658\n",
      "Epoch:668/1000\n",
      "Loss on train= 0.005933757405728102\n",
      "Loss on test= 0.007175125647336245\n",
      "acc for Lsat= 0.14628604361416858 \n",
      "acc for Psat= 0.17931034795434797 \n",
      "acc for optim= 0.17461383725413895\n",
      "Epoch:669/1000\n",
      "Loss on train= 0.006121359299868345\n",
      "Loss on test= 0.0065812477841973305\n",
      "acc for Lsat= 0.11116391757090766 \n",
      "acc for Psat= 0.16228027942440457 \n",
      "acc for optim= 0.18494795620672294\n",
      "Epoch:670/1000\n",
      "Loss on train= 0.005742812063544989\n",
      "Loss on test= 0.00651167705655098\n",
      "acc for Lsat= 0.11367470954559147 \n",
      "acc for Psat= 0.13753500640021352 \n",
      "acc for optim= 0.18962347676456606\n",
      "Epoch:671/1000\n",
      "Loss on train= 0.005742192268371582\n",
      "Loss on test= 0.006392084527760744\n",
      "acc for Lsat= 0.12144556902001229 \n",
      "acc for Psat= 0.15204358379459165 \n",
      "acc for optim= 0.18013094742821878\n",
      "Epoch:672/1000\n",
      "Loss on train= 0.005582253914326429\n",
      "Loss on test= 0.0066442773677408695\n",
      "acc for Lsat= 0.12426306198871995 \n",
      "acc for Psat= 0.14801844123850075 \n",
      "acc for optim= 0.18711151665202894\n",
      "Epoch:673/1000\n",
      "Loss on train= 0.005732199642807245\n",
      "Loss on test= 0.006335070356726646\n",
      "acc for Lsat= 0.11779867311864618 \n",
      "acc for Psat= 0.1472641780221431 \n",
      "acc for optim= 0.18078534005720848\n",
      "Epoch:674/1000\n",
      "Loss on train= 0.005676413886249065\n",
      "Loss on test= 0.006539639085531235\n",
      "acc for Lsat= 0.13805542575743965 \n",
      "acc for Psat= 0.15697286522126425 \n",
      "acc for optim= 0.18211563165867858\n",
      "Epoch:675/1000\n",
      "Loss on train= 0.005744958762079477\n",
      "Loss on test= 0.0062638199888169765\n",
      "acc for Lsat= 0.10324295712279756 \n",
      "acc for Psat= 0.15628044241486844 \n",
      "acc for optim= 0.17903758089168598\n",
      "Epoch:676/1000\n",
      "Loss on train= 0.005633531603962183\n",
      "Loss on test= 0.006016572471708059\n",
      "acc for Lsat= 0.10137653345325015 \n",
      "acc for Psat= 0.14841759122189893 \n",
      "acc for optim= 0.18262325292295317\n",
      "Epoch:677/1000\n",
      "Loss on train= 0.005597760435193777\n",
      "Loss on test= 0.0061637237668037415\n",
      "acc for Lsat= 0.10259195740188677 \n",
      "acc for Psat= 0.1408463815580343 \n",
      "acc for optim= 0.17851351109783212\n",
      "Epoch:678/1000\n",
      "Loss on train= 0.00570894917473197\n",
      "Loss on test= 0.006270475685596466\n",
      "acc for Lsat= 0.10036614723464127 \n",
      "acc for Psat= 0.15344770004966896 \n",
      "acc for optim= 0.185258865974726\n",
      "Epoch:679/1000\n",
      "Loss on train= 0.005581487435847521\n",
      "Loss on test= 0.006087746471166611\n",
      "acc for Lsat= 0.09984856594185858 \n",
      "acc for Psat= 0.1309845477305116 \n",
      "acc for optim= 0.18335334789757696\n",
      "Epoch:680/1000\n",
      "Loss on train= 0.005687965080142021\n",
      "Loss on test= 0.006543475668877363\n",
      "acc for Lsat= 0.11424364074551642 \n",
      "acc for Psat= 0.13692188473887962 \n",
      "acc for optim= 0.17417363757257728\n",
      "Epoch:681/1000\n",
      "Loss on train= 0.0058316937647759914\n",
      "Loss on test= 0.006536518689244986\n",
      "acc for Lsat= 0.13173652551989307 \n",
      "acc for Psat= 0.14972946716736907 \n",
      "acc for optim= 0.17963323682246699\n",
      "Epoch:682/1000\n",
      "Loss on train= 0.005652707535773516\n",
      "Loss on test= 0.0062024351209402084\n",
      "acc for Lsat= 0.10167692099268483 \n",
      "acc for Psat= 0.1431709571841165 \n",
      "acc for optim= 0.1751212064727304\n",
      "Epoch:683/1000\n",
      "Loss on train= 0.0056933085434138775\n",
      "Loss on test= 0.006388895213603973\n",
      "acc for Lsat= 0.1052606717637006 \n",
      "acc for Psat= 0.15481219098990057 \n",
      "acc for optim= 0.1872335870923885\n",
      "Epoch:684/1000\n",
      "Loss on train= 0.005642382428050041\n",
      "Loss on test= 0.006223123986274004\n",
      "acc for Lsat= 0.10614966235747088 \n",
      "acc for Psat= 0.13416623736384437 \n",
      "acc for optim= 0.18270321009814802\n",
      "Epoch:685/1000\n",
      "Loss on train= 0.0055689383298158646\n",
      "Loss on test= 0.0065300073474645615\n",
      "acc for Lsat= 0.11279715408227738 \n",
      "acc for Psat= 0.14256160628885203 \n",
      "acc for optim= 0.1748099268035237\n",
      "Epoch:686/1000\n",
      "Loss on train= 0.005643019452691078\n",
      "Loss on test= 0.006287158466875553\n",
      "acc for Lsat= 0.11992270178420536 \n",
      "acc for Psat= 0.1401080118342657 \n",
      "acc for optim= 0.19119649710751757\n",
      "Epoch:687/1000\n",
      "Loss on train= 0.0056825014762580395\n",
      "Loss on test= 0.0060281590558588505\n",
      "acc for Lsat= 0.09543905755508912 \n",
      "acc for Psat= 0.14062230750914442 \n",
      "acc for optim= 0.1818451411291065\n",
      "Epoch:688/1000\n",
      "Loss on train= 0.005688713863492012\n",
      "Loss on test= 0.006224636919796467\n",
      "acc for Lsat= 0.11620513076866361 \n",
      "acc for Psat= 0.13693095033246455 \n",
      "acc for optim= 0.17614560469746257\n",
      "Epoch:689/1000\n",
      "Loss on train= 0.0057710618712008\n",
      "Loss on test= 0.006343152839690447\n",
      "acc for Lsat= 0.1189466171762171 \n",
      "acc for Psat= 0.13822940105919615 \n",
      "acc for optim= 0.18525980379258802\n",
      "Epoch:690/1000\n",
      "Loss on train= 0.005859751254320145\n",
      "Loss on test= 0.006353343371301889\n",
      "acc for Lsat= 0.10322218332321273 \n",
      "acc for Psat= 0.15611576211285558 \n",
      "acc for optim= 0.19454708025648684\n",
      "Epoch:691/1000\n",
      "Loss on train= 0.005709988996386528\n",
      "Loss on test= 0.006235036067664623\n",
      "acc for Lsat= 0.12207514620011167 \n",
      "acc for Psat= 0.15052403406510367 \n",
      "acc for optim= 0.18012720275950475\n",
      "Epoch:692/1000\n",
      "Loss on train= 0.0055892132222652435\n",
      "Loss on test= 0.00630709994584322\n",
      "acc for Lsat= 0.09446944355534516 \n",
      "acc for Psat= 0.139502080381548 \n",
      "acc for optim= 0.18022015872727132\n",
      "Epoch:693/1000\n",
      "Loss on train= 0.005739121697843075\n",
      "Loss on test= 0.006312530487775803\n",
      "acc for Lsat= 0.09680522466591417 \n",
      "acc for Psat= 0.12644781192302926 \n",
      "acc for optim= 0.18428627320504115\n",
      "Epoch:694/1000\n",
      "Loss on train= 0.005663531366735697\n",
      "Loss on test= 0.006370513699948788\n",
      "acc for Lsat= 0.11255009595908509 \n",
      "acc for Psat= 0.1422733599152337 \n",
      "acc for optim= 0.18033075698343565\n",
      "Epoch:695/1000\n",
      "Loss on train= 0.005599426105618477\n",
      "Loss on test= 0.006386932451277971\n",
      "acc for Lsat= 0.1003646175245857 \n",
      "acc for Psat= 0.16065001457740188 \n",
      "acc for optim= 0.18176584721511324\n",
      "Epoch:696/1000\n",
      "Loss on train= 0.005688788834959269\n",
      "Loss on test= 0.00640996266156435\n",
      "acc for Lsat= 0.10052597617091201 \n",
      "acc for Psat= 0.15994405805022788 \n",
      "acc for optim= 0.18934673329487728\n",
      "Epoch:697/1000\n",
      "Loss on train= 0.005790664814412594\n",
      "Loss on test= 0.006428985390812159\n",
      "acc for Lsat= 0.11893024666676834 \n",
      "acc for Psat= 0.1483410842479917 \n",
      "acc for optim= 0.18440627340080368\n",
      "Epoch:698/1000\n",
      "Loss on train= 0.005741585046052933\n",
      "Loss on test= 0.0062217810191214085\n",
      "acc for Lsat= 0.10814178941149355 \n",
      "acc for Psat= 0.15602537104524514 \n",
      "acc for optim= 0.17870734319627538\n",
      "Epoch:699/1000\n",
      "Loss on train= 0.005781431682407856\n",
      "Loss on test= 0.006716346833854914\n",
      "acc for Lsat= 0.11754657479587122 \n",
      "acc for Psat= 0.16655237691346714 \n",
      "acc for optim= 0.1739912423484276\n",
      "Epoch:700/1000\n",
      "Loss on train= 0.005633103661239147\n",
      "Loss on test= 0.006288453470915556\n",
      "acc for Lsat= 0.10605701597316695 \n",
      "acc for Psat= 0.14417853972103084 \n",
      "acc for optim= 0.18606938525947536\n",
      "Epoch:701/1000\n",
      "Loss on train= 0.005703706294298172\n",
      "Loss on test= 0.006547496188431978\n",
      "acc for Lsat= 0.1458061797528575 \n",
      "acc for Psat= 0.15955440175159188 \n",
      "acc for optim= 0.18087733812132945\n",
      "Epoch:702/1000\n",
      "Loss on train= 0.005749490112066269\n",
      "Loss on test= 0.006190184503793716\n",
      "acc for Lsat= 0.10971866898037398 \n",
      "acc for Psat= 0.14325317154772643 \n",
      "acc for optim= 0.18312149903444983\n",
      "Epoch:703/1000\n",
      "Loss on train= 0.005826575215905905\n",
      "Loss on test= 0.00612400658428669\n",
      "acc for Lsat= 0.10406099025473804 \n",
      "acc for Psat= 0.14665492519339687 \n",
      "acc for optim= 0.17657511620071986\n",
      "Epoch:704/1000\n",
      "Loss on train= 0.006143767386674881\n",
      "Loss on test= 0.006311082746833563\n",
      "acc for Lsat= 0.10471013308338963 \n",
      "acc for Psat= 0.14258406939346568 \n",
      "acc for optim= 0.17948860195465385\n",
      "Epoch:705/1000\n",
      "Loss on train= 0.005606589838862419\n",
      "Loss on test= 0.0062095001339912415\n",
      "acc for Lsat= 0.09610149935923785 \n",
      "acc for Psat= 0.14668168333177534 \n",
      "acc for optim= 0.18500267436305629\n",
      "Epoch:706/1000\n",
      "Loss on train= 0.005765164736658335\n",
      "Loss on test= 0.006429232191294432\n",
      "acc for Lsat= 0.10447573346693574 \n",
      "acc for Psat= 0.1389227915174176 \n",
      "acc for optim= 0.17450655247732233\n",
      "Epoch:707/1000\n",
      "Loss on train= 0.005890313070267439\n",
      "Loss on test= 0.006240478716790676\n",
      "acc for Lsat= 0.1025174661344154 \n",
      "acc for Psat= 0.13983791825693037 \n",
      "acc for optim= 0.1792932093299588\n",
      "Epoch:708/1000\n",
      "Loss on train= 0.005545868072658777\n",
      "Loss on test= 0.006363734137266874\n",
      "acc for Lsat= 0.09754929403156354 \n",
      "acc for Psat= 0.13331150903911093 \n",
      "acc for optim= 0.17570693430222445\n",
      "Epoch:709/1000\n",
      "Loss on train= 0.00562673294916749\n",
      "Loss on test= 0.006536942441016436\n",
      "acc for Lsat= 0.1308582207457344 \n",
      "acc for Psat= 0.1439079164075353 \n",
      "acc for optim= 0.18266193445562778\n",
      "Epoch:710/1000\n",
      "Loss on train= 0.005770353600382805\n",
      "Loss on test= 0.006215355824679136\n",
      "acc for Lsat= 0.10613768856767249 \n",
      "acc for Psat= 0.1603664697970459 \n",
      "acc for optim= 0.1811436335360375\n",
      "Epoch:711/1000\n",
      "Loss on train= 0.005744767840951681\n",
      "Loss on test= 0.005938773043453693\n",
      "acc for Lsat= 0.10431871284115113 \n",
      "acc for Psat= 0.14502967473794867 \n",
      "acc for optim= 0.18176349011403745\n",
      "Epoch:712/1000\n",
      "Loss on train= 0.005701135843992233\n",
      "Loss on test= 0.0063689048402011395\n",
      "acc for Lsat= 0.1300171920583757 \n",
      "acc for Psat= 0.14118085944969838 \n",
      "acc for optim= 0.18228659231562988\n",
      "Epoch:713/1000\n",
      "Loss on train= 0.005567426793277264\n",
      "Loss on test= 0.006112434435635805\n",
      "acc for Lsat= 0.09730002042734838 \n",
      "acc for Psat= 0.13478597200989142 \n",
      "acc for optim= 0.18126730324278223\n",
      "Epoch:714/1000\n",
      "Loss on train= 0.005637014750391245\n",
      "Loss on test= 0.006225848104804754\n",
      "acc for Lsat= 0.1126119203142372 \n",
      "acc for Psat= 0.13374569447576937 \n",
      "acc for optim= 0.17846512582283308\n",
      "Epoch:715/1000\n",
      "Loss on train= 0.005548778455704451\n",
      "Loss on test= 0.006387489847838879\n",
      "acc for Lsat= 0.09958115872163405 \n",
      "acc for Psat= 0.1672923338317344 \n",
      "acc for optim= 0.17962650390720722\n",
      "Epoch:716/1000\n",
      "Loss on train= 0.005462749861180782\n",
      "Loss on test= 0.006341253407299519\n",
      "acc for Lsat= 0.1153891664594254 \n",
      "acc for Psat= 0.13248293707384018 \n",
      "acc for optim= 0.1752695394022848\n",
      "Epoch:717/1000\n",
      "Loss on train= 0.005566287785768509\n",
      "Loss on test= 0.006315761245787144\n",
      "acc for Lsat= 0.0968412218889186 \n",
      "acc for Psat= 0.14518735166658822 \n",
      "acc for optim= 0.17698119352354622\n",
      "Epoch:718/1000\n",
      "Loss on train= 0.005589353386312723\n",
      "Loss on test= 0.006282370071858168\n",
      "acc for Lsat= 0.10886282245707461 \n",
      "acc for Psat= 0.14536742707832828 \n",
      "acc for optim= 0.18684542635692505\n",
      "Epoch:719/1000\n",
      "Loss on train= 0.005570694338530302\n",
      "Loss on test= 0.0061859446577727795\n",
      "acc for Lsat= 0.10433809077661925 \n",
      "acc for Psat= 0.13670414366198988 \n",
      "acc for optim= 0.17990208849058312\n",
      "Epoch:720/1000\n",
      "Loss on train= 0.005550350993871689\n",
      "Loss on test= 0.006288059055805206\n",
      "acc for Lsat= 0.1261611268275528 \n",
      "acc for Psat= 0.1568028340947822 \n",
      "acc for optim= 0.18055529758369676\n",
      "Epoch:721/1000\n",
      "Loss on train= 0.005830939393490553\n",
      "Loss on test= 0.006417656783014536\n",
      "acc for Lsat= 0.13482858289064745 \n",
      "acc for Psat= 0.14060736955326028 \n",
      "acc for optim= 0.18062061748893585\n",
      "Epoch:722/1000\n",
      "Loss on train= 0.005719634238630533\n",
      "Loss on test= 0.006311110220849514\n",
      "acc for Lsat= 0.1044585384704741 \n",
      "acc for Psat= 0.15270499783850244 \n",
      "acc for optim= 0.17485921329816692\n",
      "Epoch:723/1000\n",
      "Loss on train= 0.00568834925070405\n",
      "Loss on test= 0.006416188552975655\n",
      "acc for Lsat= 0.10580876422401023 \n",
      "acc for Psat= 0.1418455882855766 \n",
      "acc for optim= 0.18485331764657809\n",
      "Epoch:724/1000\n",
      "Loss on train= 0.00548699451610446\n",
      "Loss on test= 0.006056814454495907\n",
      "acc for Lsat= 0.10061654527503919 \n",
      "acc for Psat= 0.14770087460845205 \n",
      "acc for optim= 0.1756341087979154\n",
      "Epoch:725/1000\n",
      "Loss on train= 0.005581001751124859\n",
      "Loss on test= 0.006387611385434866\n",
      "acc for Lsat= 0.09520548967224293 \n",
      "acc for Psat= 0.1597647266237507 \n",
      "acc for optim= 0.1898908522631184\n",
      "Epoch:726/1000\n",
      "Loss on train= 0.005717616993933916\n",
      "Loss on test= 0.006096044089645147\n",
      "acc for Lsat= 0.10765580860976824 \n",
      "acc for Psat= 0.14847276255022734 \n",
      "acc for optim= 0.17873567638818127\n",
      "Epoch:727/1000\n",
      "Loss on train= 0.005896599963307381\n",
      "Loss on test= 0.006569873075932264\n",
      "acc for Lsat= 0.11127784075827132 \n",
      "acc for Psat= 0.15492758456601807 \n",
      "acc for optim= 0.20204318152835307\n",
      "Epoch:728/1000\n",
      "Loss on train= 0.005830541253089905\n",
      "Loss on test= 0.006266143172979355\n",
      "acc for Lsat= 0.1015479603202871 \n",
      "acc for Psat= 0.14806159232975916 \n",
      "acc for optim= 0.1891119538640635\n",
      "Epoch:729/1000\n",
      "Loss on train= 0.005776628386229277\n",
      "Loss on test= 0.006411182228475809\n",
      "acc for Lsat= 0.1135917811946533 \n",
      "acc for Psat= 0.18077428115263455 \n",
      "acc for optim= 0.18317301006241843\n",
      "Epoch:730/1000\n",
      "Loss on train= 0.005734185688197613\n",
      "Loss on test= 0.006077870726585388\n",
      "acc for Lsat= 0.10665576571324382 \n",
      "acc for Psat= 0.14475525633226766 \n",
      "acc for optim= 0.17706134812393368\n",
      "Epoch:731/1000\n",
      "Loss on train= 0.005756204482167959\n",
      "Loss on test= 0.006232460029423237\n",
      "acc for Lsat= 0.10749865458692202 \n",
      "acc for Psat= 0.14842307673672497 \n",
      "acc for optim= 0.18406747083803165\n",
      "Epoch:732/1000\n",
      "Loss on train= 0.005417696665972471\n",
      "Loss on test= 0.006177948322147131\n",
      "acc for Lsat= 0.110145469816299 \n",
      "acc for Psat= 0.14299211243445734 \n",
      "acc for optim= 0.18550133853164202\n",
      "Epoch:733/1000\n",
      "Loss on train= 0.00574488053098321\n",
      "Loss on test= 0.006193476263433695\n",
      "acc for Lsat= 0.10754005401040095 \n",
      "acc for Psat= 0.1354173528551424 \n",
      "acc for optim= 0.18156861732102206\n",
      "Epoch:734/1000\n",
      "Loss on train= 0.005839608144015074\n",
      "Loss on test= 0.006176240276545286\n",
      "acc for Lsat= 0.09867571098078831 \n",
      "acc for Psat= 0.14127252038126276 \n",
      "acc for optim= 0.1802805019909579\n",
      "Epoch:735/1000\n",
      "Loss on train= 0.005824456922709942\n",
      "Loss on test= 0.0065727815963327885\n",
      "acc for Lsat= 0.11353497315766448 \n",
      "acc for Psat= 0.17282711959925434 \n",
      "acc for optim= 0.18136688412045784\n",
      "Epoch:736/1000\n",
      "Loss on train= 0.005633616354316473\n",
      "Loss on test= 0.006335217971354723\n",
      "acc for Lsat= 0.09541236559339498 \n",
      "acc for Psat= 0.14787135212208632 \n",
      "acc for optim= 0.18143646089296978\n",
      "Epoch:737/1000\n",
      "Loss on train= 0.005563384387642145\n",
      "Loss on test= 0.006448701955378056\n",
      "acc for Lsat= 0.11249126382976163 \n",
      "acc for Psat= 0.13892853404760314 \n",
      "acc for optim= 0.18284849114972562\n",
      "Epoch:738/1000\n",
      "Loss on train= 0.005632538814097643\n",
      "Loss on test= 0.005970169324427843\n",
      "acc for Lsat= 0.09783141108079797 \n",
      "acc for Psat= 0.13676292866200082 \n",
      "acc for optim= 0.18293858005239044\n",
      "Epoch:739/1000\n",
      "Loss on train= 0.005657207686454058\n",
      "Loss on test= 0.00712054455652833\n",
      "acc for Lsat= 0.12762731496803068 \n",
      "acc for Psat= 0.15724482712399024 \n",
      "acc for optim= 0.1717109781843107\n",
      "Epoch:740/1000\n",
      "Loss on train= 0.0058191921561956406\n",
      "Loss on test= 0.006366404239088297\n",
      "acc for Lsat= 0.09871981232648731 \n",
      "acc for Psat= 0.15365184428351852 \n",
      "acc for optim= 0.17996112149193\n",
      "Epoch:741/1000\n",
      "Loss on train= 0.005776044446974993\n",
      "Loss on test= 0.006527115125209093\n",
      "acc for Lsat= 0.12817428578914664 \n",
      "acc for Psat= 0.13310634826144235 \n",
      "acc for optim= 0.18827326902054187\n",
      "Epoch:742/1000\n",
      "Loss on train= 0.005838376469910145\n",
      "Loss on test= 0.006600754801183939\n",
      "acc for Lsat= 0.11850899079187094 \n",
      "acc for Psat= 0.155041309392427 \n",
      "acc for optim= 0.1936097005975109\n",
      "Epoch:743/1000\n",
      "Loss on train= 0.005653988104313612\n",
      "Loss on test= 0.006497133988887072\n",
      "acc for Lsat= 0.12359062670651129 \n",
      "acc for Psat= 0.1502870552074085 \n",
      "acc for optim= 0.18833908083201464\n",
      "Epoch:744/1000\n",
      "Loss on train= 0.005472044926136732\n",
      "Loss on test= 0.006115691736340523\n",
      "acc for Lsat= 0.10033340513828543 \n",
      "acc for Psat= 0.1358542843529919 \n",
      "acc for optim= 0.18047335366225187\n",
      "Epoch:745/1000\n",
      "Loss on train= 0.005638951435685158\n",
      "Loss on test= 0.006272729951888323\n",
      "acc for Lsat= 0.1084838597056598 \n",
      "acc for Psat= 0.14551230393018635 \n",
      "acc for optim= 0.1817655541004477\n",
      "Epoch:746/1000\n",
      "Loss on train= 0.0055821845307946205\n",
      "Loss on test= 0.006370380986481905\n",
      "acc for Lsat= 0.11210538548776501 \n",
      "acc for Psat= 0.13716511213865873 \n",
      "acc for optim= 0.18213738063823873\n",
      "Epoch:747/1000\n",
      "Loss on train= 0.005597081501036882\n",
      "Loss on test= 0.0063199508003890514\n",
      "acc for Lsat= 0.09531218981739308 \n",
      "acc for Psat= 0.160923379092424 \n",
      "acc for optim= 0.20078940834007541\n",
      "Epoch:748/1000\n",
      "Loss on train= 0.0054781027138233185\n",
      "Loss on test= 0.006689634174108505\n",
      "acc for Lsat= 0.14132871023000423 \n",
      "acc for Psat= 0.1549733897789492 \n",
      "acc for optim= 0.1877752724695572\n",
      "Epoch:749/1000\n",
      "Loss on train= 0.005711689591407776\n",
      "Loss on test= 0.006263477727770805\n",
      "acc for Lsat= 0.08963285805795626 \n",
      "acc for Psat= 0.13775587767753278 \n",
      "acc for optim= 0.18360505382909234\n",
      "Epoch:750/1000\n",
      "Loss on train= 0.005413874052464962\n",
      "Loss on test= 0.006341920234262943\n",
      "acc for Lsat= 0.11233598973525104 \n",
      "acc for Psat= 0.13962603594429032 \n",
      "acc for optim= 0.19191804971640644\n",
      "Epoch:751/1000\n",
      "Loss on train= 0.00558033213019371\n",
      "Loss on test= 0.006194939836859703\n",
      "acc for Lsat= 0.11152497653748793 \n",
      "acc for Psat= 0.1536552705979606 \n",
      "acc for optim= 0.18289723189308907\n",
      "Epoch:752/1000\n",
      "Loss on train= 0.005691204685717821\n",
      "Loss on test= 0.006533229723572731\n",
      "acc for Lsat= 0.130970609179398 \n",
      "acc for Psat= 0.13834013779710788 \n",
      "acc for optim= 0.17887551147837025\n",
      "Epoch:753/1000\n",
      "Loss on train= 0.005648904014378786\n",
      "Loss on test= 0.006080292630940676\n",
      "acc for Lsat= 0.09652018401287378 \n",
      "acc for Psat= 0.1342809645234118 \n",
      "acc for optim= 0.18935153019437923\n",
      "Epoch:754/1000\n",
      "Loss on train= 0.005748555529862642\n",
      "Loss on test= 0.0060980734415352345\n",
      "acc for Lsat= 0.09617816258431018 \n",
      "acc for Psat= 0.14266416257438724 \n",
      "acc for optim= 0.18322680441374592\n",
      "Epoch:755/1000\n",
      "Loss on train= 0.005640920251607895\n",
      "Loss on test= 0.006104703526943922\n",
      "acc for Lsat= 0.10951928233390405 \n",
      "acc for Psat= 0.14160295292563438 \n",
      "acc for optim= 0.18430722538308808\n",
      "Epoch:756/1000\n",
      "Loss on train= 0.00558242853730917\n",
      "Loss on test= 0.006489959079772234\n",
      "acc for Lsat= 0.09678511168453566 \n",
      "acc for Psat= 0.151976650647456 \n",
      "acc for optim= 0.19538247765681185\n",
      "Epoch:757/1000\n",
      "Loss on train= 0.005540791898965836\n",
      "Loss on test= 0.006168188527226448\n",
      "acc for Lsat= 0.0943098175669902 \n",
      "acc for Psat= 0.14445432453037446 \n",
      "acc for optim= 0.17626578597257198\n",
      "Epoch:758/1000\n",
      "Loss on train= 0.00550488568842411\n",
      "Loss on test= 0.006491818930953741\n",
      "acc for Lsat= 0.11037404213309825 \n",
      "acc for Psat= 0.13236467748193734 \n",
      "acc for optim= 0.18721418752003524\n",
      "Epoch:759/1000\n",
      "Loss on train= 0.005517734680324793\n",
      "Loss on test= 0.006236953195184469\n",
      "acc for Lsat= 0.10903781158718877 \n",
      "acc for Psat= 0.14557136290517272 \n",
      "acc for optim= 0.17996533484872967\n",
      "Epoch:760/1000\n",
      "Loss on train= 0.005398536566644907\n",
      "Loss on test= 0.006176754366606474\n",
      "acc for Lsat= 0.10744877193422527 \n",
      "acc for Psat= 0.14377725167886624 \n",
      "acc for optim= 0.18665906855347172\n",
      "Epoch:761/1000\n",
      "Loss on train= 0.005567010026425123\n",
      "Loss on test= 0.006129316054284573\n",
      "acc for Lsat= 0.11635557284632449 \n",
      "acc for Psat= 0.13736617196986642 \n",
      "acc for optim= 0.17888614936717945\n",
      "Epoch:762/1000\n",
      "Loss on train= 0.005455546081066132\n",
      "Loss on test= 0.00648347195237875\n",
      "acc for Lsat= 0.1259225799717893 \n",
      "acc for Psat= 0.14617109826758062 \n",
      "acc for optim= 0.1863801210582497\n",
      "Epoch:763/1000\n",
      "Loss on train= 0.005736015737056732\n",
      "Loss on test= 0.0064734830521047115\n",
      "acc for Lsat= 0.10828510430420481 \n",
      "acc for Psat= 0.1516185323032945 \n",
      "acc for optim= 0.17994442925871335\n",
      "Epoch:764/1000\n",
      "Loss on train= 0.005415782798081636\n",
      "Loss on test= 0.006174362264573574\n",
      "acc for Lsat= 0.10915058072571548 \n",
      "acc for Psat= 0.1349034018260111 \n",
      "acc for optim= 0.17737606413567722\n",
      "Epoch:765/1000\n",
      "Loss on train= 0.0055552031844854355\n",
      "Loss on test= 0.006059674080461264\n",
      "acc for Lsat= 0.1075853280178508 \n",
      "acc for Psat= 0.1344960808388936 \n",
      "acc for optim= 0.1820894115687332\n",
      "Epoch:766/1000\n",
      "Loss on train= 0.005495649296790361\n",
      "Loss on test= 0.005974501371383667\n",
      "acc for Lsat= 0.09744257330016423 \n",
      "acc for Psat= 0.14421415164932547 \n",
      "acc for optim= 0.17895250583178032\n",
      "Epoch:767/1000\n",
      "Loss on train= 0.005356517154723406\n",
      "Loss on test= 0.006461175158619881\n",
      "acc for Lsat= 0.11901466989134028 \n",
      "acc for Psat= 0.12374978290192025 \n",
      "acc for optim= 0.1975290683571537\n",
      "Epoch:768/1000\n",
      "Loss on train= 0.005709270015358925\n",
      "Loss on test= 0.006182760465890169\n",
      "acc for Lsat= 0.09800021207360629 \n",
      "acc for Psat= 0.13169124212443545 \n",
      "acc for optim= 0.18729814044199883\n",
      "Epoch:769/1000\n",
      "Loss on train= 0.005326336715370417\n",
      "Loss on test= 0.006239649374037981\n",
      "acc for Lsat= 0.0934426192507213 \n",
      "acc for Psat= 0.13034349020237057 \n",
      "acc for optim= 0.1770174628697825\n",
      "Epoch:770/1000\n",
      "Loss on train= 0.005568808875977993\n",
      "Loss on test= 0.006304070353507996\n",
      "acc for Lsat= 0.10648675563871482 \n",
      "acc for Psat= 0.14781683249521402 \n",
      "acc for optim= 0.17944376738741993\n",
      "Epoch:771/1000\n",
      "Loss on train= 0.005437626037746668\n",
      "Loss on test= 0.006083112675696611\n",
      "acc for Lsat= 0.09934417736377188 \n",
      "acc for Psat= 0.13325782128495275 \n",
      "acc for optim= 0.1805124574868695\n",
      "Epoch:772/1000\n",
      "Loss on train= 0.005405306816101074\n",
      "Loss on test= 0.006412696558982134\n",
      "acc for Lsat= 0.10676747533987016 \n",
      "acc for Psat= 0.1318023740496463 \n",
      "acc for optim= 0.1942378780879554\n",
      "Epoch:773/1000\n",
      "Loss on train= 0.005454414989799261\n",
      "Loss on test= 0.006108846515417099\n",
      "acc for Lsat= 0.10129679162025657 \n",
      "acc for Psat= 0.15037605003532717 \n",
      "acc for optim= 0.1776841198538146\n",
      "Epoch:774/1000\n",
      "Loss on train= 0.005411786958575249\n",
      "Loss on test= 0.006219153292477131\n",
      "acc for Lsat= 0.10316812065311597 \n",
      "acc for Psat= 0.13509251283071302 \n",
      "acc for optim= 0.17462392114092976\n",
      "Epoch:775/1000\n",
      "Loss on train= 0.005551590118557215\n",
      "Loss on test= 0.006467577535659075\n",
      "acc for Lsat= 0.1060467624489289 \n",
      "acc for Psat= 0.13870693248286212 \n",
      "acc for optim= 0.178288056517525\n",
      "Epoch:776/1000\n",
      "Loss on train= 0.005545387044548988\n",
      "Loss on test= 0.0062361895106732845\n",
      "acc for Lsat= 0.10013578319409074 \n",
      "acc for Psat= 0.1619271754074084 \n",
      "acc for optim= 0.1775743261855727\n",
      "Epoch:777/1000\n",
      "Loss on train= 0.005670758895576\n",
      "Loss on test= 0.006115353666245937\n",
      "acc for Lsat= 0.11234003766518781 \n",
      "acc for Psat= 0.13304748313800654 \n",
      "acc for optim= 0.1754794302093599\n",
      "Epoch:778/1000\n",
      "Loss on train= 0.005444671958684921\n",
      "Loss on test= 0.006077172234654427\n",
      "acc for Lsat= 0.10608255813404882 \n",
      "acc for Psat= 0.13537809815242002 \n",
      "acc for optim= 0.18318401268896473\n",
      "Epoch:779/1000\n",
      "Loss on train= 0.005303414538502693\n",
      "Loss on test= 0.006263700779527426\n",
      "acc for Lsat= 0.10433145603342613 \n",
      "acc for Psat= 0.15190070400653818 \n",
      "acc for optim= 0.18587242190457753\n",
      "Epoch:780/1000\n",
      "Loss on train= 0.005517324898391962\n",
      "Loss on test= 0.006538597401231527\n",
      "acc for Lsat= 0.11177583325615299 \n",
      "acc for Psat= 0.14435458115491448 \n",
      "acc for optim= 0.17141407462097388\n",
      "Epoch:781/1000\n",
      "Loss on train= 0.005500529892742634\n",
      "Loss on test= 0.006560089066624641\n",
      "acc for Lsat= 0.1230971486642128 \n",
      "acc for Psat= 0.14770249278487843 \n",
      "acc for optim= 0.18761887127588803\n",
      "Epoch:782/1000\n",
      "Loss on train= 0.005623175762593746\n",
      "Loss on test= 0.006252449005842209\n",
      "acc for Lsat= 0.0924383690221614 \n",
      "acc for Psat= 0.1402594935563314 \n",
      "acc for optim= 0.17761151661524294\n",
      "Epoch:783/1000\n",
      "Loss on train= 0.005403116345405579\n",
      "Loss on test= 0.006100648082792759\n",
      "acc for Lsat= 0.09824428032951477 \n",
      "acc for Psat= 0.12769284285337962 \n",
      "acc for optim= 0.1830608593162605\n",
      "Epoch:784/1000\n",
      "Loss on train= 0.005435358267277479\n",
      "Loss on test= 0.006412464659661055\n",
      "acc for Lsat= 0.13335013914166682 \n",
      "acc for Psat= 0.14822536316341167 \n",
      "acc for optim= 0.18130361199037615\n",
      "Epoch:785/1000\n",
      "Loss on train= 0.0053803869523108006\n",
      "Loss on test= 0.006591918878257275\n",
      "acc for Lsat= 0.10533665779315061 \n",
      "acc for Psat= 0.1629520249639843 \n",
      "acc for optim= 0.18917498467551738\n",
      "Epoch:786/1000\n",
      "Loss on train= 0.005432556848973036\n",
      "Loss on test= 0.006128120701760054\n",
      "acc for Lsat= 0.09847392647465991 \n",
      "acc for Psat= 0.13663297963185114 \n",
      "acc for optim= 0.1754621677328556\n",
      "Epoch:787/1000\n",
      "Loss on train= 0.005454607307910919\n",
      "Loss on test= 0.006198635790497065\n",
      "acc for Lsat= 0.09855318052212755 \n",
      "acc for Psat= 0.12587921727777723 \n",
      "acc for optim= 0.18150325878325976\n",
      "Epoch:788/1000\n",
      "Loss on train= 0.005528946407139301\n",
      "Loss on test= 0.0060888901352882385\n",
      "acc for Lsat= 0.11147320917827251 \n",
      "acc for Psat= 0.13450087128232738 \n",
      "acc for optim= 0.17589275049266673\n",
      "Epoch:789/1000\n",
      "Loss on train= 0.00551097234711051\n",
      "Loss on test= 0.006738726515322924\n",
      "acc for Lsat= 0.10356304723556327 \n",
      "acc for Psat= 0.1420840111988058 \n",
      "acc for optim= 0.1734079722450973\n",
      "Epoch:790/1000\n",
      "Loss on train= 0.005747709423303604\n",
      "Loss on test= 0.006124321836978197\n",
      "acc for Lsat= 0.09703434761445891 \n",
      "acc for Psat= 0.14894115495630164 \n",
      "acc for optim= 0.17456059974176272\n",
      "Epoch:791/1000\n",
      "Loss on train= 0.005559721030294895\n",
      "Loss on test= 0.006074646953493357\n",
      "acc for Lsat= 0.10778157779161614 \n",
      "acc for Psat= 0.13733755494871175 \n",
      "acc for optim= 0.17932241492632428\n",
      "Epoch:792/1000\n",
      "Loss on train= 0.005661699455231428\n",
      "Loss on test= 0.006593265570700169\n",
      "acc for Lsat= 0.11931762098989812 \n",
      "acc for Psat= 0.14117165526288356 \n",
      "acc for optim= 0.18382670695822434\n",
      "Epoch:793/1000\n",
      "Loss on train= 0.005348181817680597\n",
      "Loss on test= 0.006174744106829166\n",
      "acc for Lsat= 0.12334925417562155 \n",
      "acc for Psat= 0.14585646937830152 \n",
      "acc for optim= 0.18841486333018972\n",
      "Epoch:794/1000\n",
      "Loss on train= 0.00558742368593812\n",
      "Loss on test= 0.006046109367161989\n",
      "acc for Lsat= 0.10610255635130393 \n",
      "acc for Psat= 0.13589430396283297 \n",
      "acc for optim= 0.18165295101451626\n",
      "Epoch:795/1000\n",
      "Loss on train= 0.005396764725446701\n",
      "Loss on test= 0.0061836084350943565\n",
      "acc for Lsat= 0.10214410378889702 \n",
      "acc for Psat= 0.13841482580469733 \n",
      "acc for optim= 0.17730600739537217\n",
      "Epoch:796/1000\n",
      "Loss on train= 0.005577062722295523\n",
      "Loss on test= 0.006387933157384396\n",
      "acc for Lsat= 0.12735961469647997 \n",
      "acc for Psat= 0.1283374156581901 \n",
      "acc for optim= 0.18869043289352272\n",
      "Epoch:797/1000\n",
      "Loss on train= 0.005319391377270222\n",
      "Loss on test= 0.006200606469064951\n",
      "acc for Lsat= 0.09970530107049114 \n",
      "acc for Psat= 0.15343472118108628 \n",
      "acc for optim= 0.18346249843430626\n",
      "Epoch:798/1000\n",
      "Loss on train= 0.005575291346758604\n",
      "Loss on test= 0.006437143310904503\n",
      "acc for Lsat= 0.10767909131295016 \n",
      "acc for Psat= 0.15677233483118594 \n",
      "acc for optim= 0.17758789529266247\n",
      "Epoch:799/1000\n",
      "Loss on train= 0.005586722400039434\n",
      "Loss on test= 0.006124794948846102\n",
      "acc for Lsat= 0.11119265477745241 \n",
      "acc for Psat= 0.13917623233322401 \n",
      "acc for optim= 0.18195848342009535\n",
      "Epoch:800/1000\n",
      "Loss on train= 0.005427543539553881\n",
      "Loss on test= 0.006052752025425434\n",
      "acc for Lsat= 0.10184914263111335 \n",
      "acc for Psat= 0.1268969590710555 \n",
      "acc for optim= 0.18489855142788503\n",
      "Epoch:801/1000\n",
      "Loss on train= 0.0055995844304561615\n",
      "Loss on test= 0.006211832631379366\n",
      "acc for Lsat= 0.10626030341905573 \n",
      "acc for Psat= 0.1516685213208972 \n",
      "acc for optim= 0.18532216771332136\n",
      "Epoch:802/1000\n",
      "Loss on train= 0.005576573312282562\n",
      "Loss on test= 0.006077275611460209\n",
      "acc for Lsat= 0.09955401463763121 \n",
      "acc for Psat= 0.1444176016006445 \n",
      "acc for optim= 0.1902614919224091\n",
      "Epoch:803/1000\n",
      "Loss on train= 0.005534697789698839\n",
      "Loss on test= 0.006136187817901373\n",
      "acc for Lsat= 0.10146384931453582 \n",
      "acc for Psat= 0.13171449631661714 \n",
      "acc for optim= 0.18265744354265104\n",
      "Epoch:804/1000\n",
      "Loss on train= 0.005691017955541611\n",
      "Loss on test= 0.006140545476227999\n",
      "acc for Lsat= 0.11329224849163191 \n",
      "acc for Psat= 0.14329408742926456 \n",
      "acc for optim= 0.1772755202190098\n",
      "Epoch:805/1000\n",
      "Loss on train= 0.005458302330225706\n",
      "Loss on test= 0.006009015254676342\n",
      "acc for Lsat= 0.09699851190661458 \n",
      "acc for Psat= 0.1390248013565601 \n",
      "acc for optim= 0.17789452483303356\n",
      "Epoch:806/1000\n",
      "Loss on train= 0.0054077343083918095\n",
      "Loss on test= 0.006720851641148329\n",
      "acc for Lsat= 0.12588262249916887 \n",
      "acc for Psat= 0.14963545823880173 \n",
      "acc for optim= 0.17885982267069236\n",
      "Epoch:807/1000\n",
      "Loss on train= 0.0056776427663862705\n",
      "Loss on test= 0.006223037838935852\n",
      "acc for Lsat= 0.09765318421988799 \n",
      "acc for Psat= 0.14501928814738135 \n",
      "acc for optim= 0.177344500986066\n",
      "Epoch:808/1000\n",
      "Loss on train= 0.005507061257958412\n",
      "Loss on test= 0.006225083023309708\n",
      "acc for Lsat= 0.11728960363256254 \n",
      "acc for Psat= 0.14110164997815075 \n",
      "acc for optim= 0.18501334584010293\n",
      "Epoch:809/1000\n",
      "Loss on train= 0.005533731076866388\n",
      "Loss on test= 0.006037021521478891\n",
      "acc for Lsat= 0.10599722199168062 \n",
      "acc for Psat= 0.13702268689294678 \n",
      "acc for optim= 0.17623721323631136\n",
      "Epoch:810/1000\n",
      "Loss on train= 0.005383256357163191\n",
      "Loss on test= 0.006149730645120144\n",
      "acc for Lsat= 0.10362180891698715 \n",
      "acc for Psat= 0.13715226886363827 \n",
      "acc for optim= 0.1740344023000512\n",
      "Epoch:811/1000\n",
      "Loss on train= 0.005667120683938265\n",
      "Loss on test= 0.006085538771003485\n",
      "acc for Lsat= 0.11001467958726067 \n",
      "acc for Psat= 0.1513576508255999 \n",
      "acc for optim= 0.17650431786793072\n",
      "Epoch:812/1000\n",
      "Loss on train= 0.005451696924865246\n",
      "Loss on test= 0.006174844689667225\n",
      "acc for Lsat= 0.08995881621332216 \n",
      "acc for Psat= 0.1331635363352627 \n",
      "acc for optim= 0.18256721201281742\n",
      "Epoch:813/1000\n",
      "Loss on train= 0.0053953081369400024\n",
      "Loss on test= 0.006249196827411652\n",
      "acc for Lsat= 0.11288491433123285 \n",
      "acc for Psat= 0.1399052017684863 \n",
      "acc for optim= 0.18307476539092762\n",
      "Epoch:814/1000\n",
      "Loss on train= 0.005489626433700323\n",
      "Loss on test= 0.006067727692425251\n",
      "acc for Lsat= 0.10648046867138611 \n",
      "acc for Psat= 0.15482176476586373 \n",
      "acc for optim= 0.1766772066961216\n",
      "Epoch:815/1000\n",
      "Loss on train= 0.005589009262621403\n",
      "Loss on test= 0.006196916103363037\n",
      "acc for Lsat= 0.12618616623829254 \n",
      "acc for Psat= 0.13997525593613164 \n",
      "acc for optim= 0.18551024842644268\n",
      "Epoch:816/1000\n",
      "Loss on train= 0.0057486556470394135\n",
      "Loss on test= 0.006556241307407618\n",
      "acc for Lsat= 0.12051899504011213 \n",
      "acc for Psat= 0.1339398243415201 \n",
      "acc for optim= 0.19225755328868943\n",
      "Epoch:817/1000\n",
      "Loss on train= 0.0055051990784704685\n",
      "Loss on test= 0.006092976778745651\n",
      "acc for Lsat= 0.10230124782952402 \n",
      "acc for Psat= 0.12938287419353817 \n",
      "acc for optim= 0.18378785753058333\n",
      "Epoch:818/1000\n",
      "Loss on train= 0.00542966416105628\n",
      "Loss on test= 0.005988128483295441\n",
      "acc for Lsat= 0.0975140740230711 \n",
      "acc for Psat= 0.13585329928762926 \n",
      "acc for optim= 0.17810973884908768\n",
      "Epoch:819/1000\n",
      "Loss on train= 0.005569627974182367\n",
      "Loss on test= 0.006099925376474857\n",
      "acc for Lsat= 0.09742775350963002 \n",
      "acc for Psat= 0.13028338310867155 \n",
      "acc for optim= 0.17280111885471744\n",
      "Epoch:820/1000\n",
      "Loss on train= 0.005281532183289528\n",
      "Loss on test= 0.006239431444555521\n",
      "acc for Lsat= 0.09561005617473156 \n",
      "acc for Psat= 0.13098999372864994 \n",
      "acc for optim= 0.17789640820790398\n",
      "Epoch:821/1000\n",
      "Loss on train= 0.0054012201726436615\n",
      "Loss on test= 0.006108875386416912\n",
      "acc for Lsat= 0.10371117237087149 \n",
      "acc for Psat= 0.13830380378906632 \n",
      "acc for optim= 0.18017703177391597\n",
      "Epoch:822/1000\n",
      "Loss on train= 0.005469305906444788\n",
      "Loss on test= 0.00596616230905056\n",
      "acc for Lsat= 0.10333087374337839 \n",
      "acc for Psat= 0.1381183259287786 \n",
      "acc for optim= 0.17914790942361264\n",
      "Epoch:823/1000\n",
      "Loss on train= 0.0054657673463225365\n",
      "Loss on test= 0.006462511140853167\n",
      "acc for Lsat= 0.10835757906828865 \n",
      "acc for Psat= 0.14902842766881558 \n",
      "acc for optim= 0.18273823139299905\n",
      "Epoch:824/1000\n",
      "Loss on train= 0.005466246511787176\n",
      "Loss on test= 0.006510807201266289\n",
      "acc for Lsat= 0.11767880961819852 \n",
      "acc for Psat= 0.1321037710804129 \n",
      "acc for optim= 0.17546103915073358\n",
      "Epoch:825/1000\n",
      "Loss on train= 0.005453088786453009\n",
      "Loss on test= 0.0062247877940535545\n",
      "acc for Lsat= 0.10142241874571606 \n",
      "acc for Psat= 0.1454891869581257 \n",
      "acc for optim= 0.18697530225085063\n",
      "Epoch:826/1000\n",
      "Loss on train= 0.0053665428422391415\n",
      "Loss on test= 0.005946151912212372\n",
      "acc for Lsat= 0.11043170240976043 \n",
      "acc for Psat= 0.14758620632465108 \n",
      "acc for optim= 0.17482297550733952\n",
      "Epoch:827/1000\n",
      "Loss on train= 0.005570493638515472\n",
      "Loss on test= 0.00663795368745923\n",
      "acc for Lsat= 0.14495070892094114 \n",
      "acc for Psat= 0.15962460637862116 \n",
      "acc for optim= 0.17545362284675367\n",
      "Epoch:828/1000\n",
      "Loss on train= 0.005464504007250071\n",
      "Loss on test= 0.006051054690033197\n",
      "acc for Lsat= 0.09123325709873116 \n",
      "acc for Psat= 0.14014773438842493 \n",
      "acc for optim= 0.19272907967127956\n",
      "Epoch:829/1000\n",
      "Loss on train= 0.005365337710827589\n",
      "Loss on test= 0.00622424716129899\n",
      "acc for Lsat= 0.10382811185702587 \n",
      "acc for Psat= 0.13353126993586834 \n",
      "acc for optim= 0.19337488094150382\n",
      "Epoch:830/1000\n",
      "Loss on train= 0.005468050017952919\n",
      "Loss on test= 0.006248690187931061\n",
      "acc for Lsat= 0.09973406809472411 \n",
      "acc for Psat= 0.14174710472441926 \n",
      "acc for optim= 0.1924693791669304\n",
      "Epoch:831/1000\n",
      "Loss on train= 0.005375660955905914\n",
      "Loss on test= 0.006010591518133879\n",
      "acc for Lsat= 0.1016243424479676 \n",
      "acc for Psat= 0.14049880683808824 \n",
      "acc for optim= 0.17722949580115788\n",
      "Epoch:832/1000\n",
      "Loss on train= 0.005250281188637018\n",
      "Loss on test= 0.006082598119974136\n",
      "acc for Lsat= 0.10232085486285988 \n",
      "acc for Psat= 0.13297999401624172 \n",
      "acc for optim= 0.17572806156886608\n",
      "Epoch:833/1000\n",
      "Loss on train= 0.005355122033506632\n",
      "Loss on test= 0.00610919576138258\n",
      "acc for Lsat= 0.10488757789144845 \n",
      "acc for Psat= 0.13307374270585506 \n",
      "acc for optim= 0.17947086923478478\n",
      "Epoch:834/1000\n",
      "Loss on train= 0.00544601958245039\n",
      "Loss on test= 0.006017445586621761\n",
      "acc for Lsat= 0.11224580295295139 \n",
      "acc for Psat= 0.13091609300216817 \n",
      "acc for optim= 0.18637505871839663\n",
      "Epoch:835/1000\n",
      "Loss on train= 0.0055402908474206924\n",
      "Loss on test= 0.00627183448523283\n",
      "acc for Lsat= 0.10883666151176084 \n",
      "acc for Psat= 0.1368785557660207 \n",
      "acc for optim= 0.19192015338014273\n",
      "Epoch:836/1000\n",
      "Loss on train= 0.00543005857616663\n",
      "Loss on test= 0.005991404410451651\n",
      "acc for Lsat= 0.09623583273022925 \n",
      "acc for Psat= 0.13940023345403152 \n",
      "acc for optim= 0.18721855095571885\n",
      "Epoch:837/1000\n",
      "Loss on train= 0.005465024150907993\n",
      "Loss on test= 0.006222143769264221\n",
      "acc for Lsat= 0.11995806976268857 \n",
      "acc for Psat= 0.13508810267963256 \n",
      "acc for optim= 0.17872325877966833\n",
      "Epoch:838/1000\n",
      "Loss on train= 0.005383501760661602\n",
      "Loss on test= 0.0061261579394340515\n",
      "acc for Lsat= 0.09471272147039614 \n",
      "acc for Psat= 0.13123170607387863 \n",
      "acc for optim= 0.18184481063636682\n",
      "Epoch:839/1000\n",
      "Loss on train= 0.0054129199124872684\n",
      "Loss on test= 0.00601969426497817\n",
      "acc for Lsat= 0.0963357824133709 \n",
      "acc for Psat= 0.1401141173543307 \n",
      "acc for optim= 0.18026564026653957\n",
      "Epoch:840/1000\n",
      "Loss on train= 0.005460726097226143\n",
      "Loss on test= 0.0061423564329743385\n",
      "acc for Lsat= 0.09747986887414917 \n",
      "acc for Psat= 0.1343447503970896 \n",
      "acc for optim= 0.17323699613985746\n",
      "Epoch:841/1000\n",
      "Loss on train= 0.005391585174947977\n",
      "Loss on test= 0.00619524996727705\n",
      "acc for Lsat= 0.10357109880183628 \n",
      "acc for Psat= 0.12719338452724654 \n",
      "acc for optim= 0.17966365792701747\n",
      "Epoch:842/1000\n",
      "Loss on train= 0.005428334232419729\n",
      "Loss on test= 0.0060895467177033424\n",
      "acc for Lsat= 0.0991487281452233 \n",
      "acc for Psat= 0.12725297002056693 \n",
      "acc for optim= 0.18107879736307333\n",
      "Epoch:843/1000\n",
      "Loss on train= 0.0054329149425029755\n",
      "Loss on test= 0.006302685011178255\n",
      "acc for Lsat= 0.10002204607999528 \n",
      "acc for Psat= 0.14741385837353893 \n",
      "acc for optim= 0.19319097557345846\n",
      "Epoch:844/1000\n",
      "Loss on train= 0.005725181195884943\n",
      "Loss on test= 0.006493992172181606\n",
      "acc for Lsat= 0.13212801727996074 \n",
      "acc for Psat= 0.1480924154983999 \n",
      "acc for optim= 0.18399653101450433\n",
      "Epoch:845/1000\n",
      "Loss on train= 0.005320227239280939\n",
      "Loss on test= 0.006065458059310913\n",
      "acc for Lsat= 0.09464048717123598 \n",
      "acc for Psat= 0.1353178920513374 \n",
      "acc for optim= 0.17762991477496343\n",
      "Epoch:846/1000\n",
      "Loss on train= 0.005394828971475363\n",
      "Loss on test= 0.006289342883974314\n",
      "acc for Lsat= 0.0880964509488707 \n",
      "acc for Psat= 0.13905945506899656 \n",
      "acc for optim= 0.1734601244353498\n",
      "Epoch:847/1000\n",
      "Loss on train= 0.005359142553061247\n",
      "Loss on test= 0.006278686225414276\n",
      "acc for Lsat= 0.10266969171372416 \n",
      "acc for Psat= 0.13273137237994304 \n",
      "acc for optim= 0.18497117732541035\n",
      "Epoch:848/1000\n",
      "Loss on train= 0.005443587899208069\n",
      "Loss on test= 0.0060971565544605255\n",
      "acc for Lsat= 0.0945337847139345 \n",
      "acc for Psat= 0.13195624322348307 \n",
      "acc for optim= 0.1821757653474332\n",
      "Epoch:849/1000\n",
      "Loss on train= 0.0055359844118356705\n",
      "Loss on test= 0.006530992221087217\n",
      "acc for Lsat= 0.1113751720621298 \n",
      "acc for Psat= 0.16395312502104156 \n",
      "acc for optim= 0.17582922290292394\n",
      "Epoch:850/1000\n",
      "Loss on train= 0.005529844667762518\n",
      "Loss on test= 0.0060386196710169315\n",
      "acc for Lsat= 0.1042591191046887 \n",
      "acc for Psat= 0.1387881340608948 \n",
      "acc for optim= 0.1854697256948862\n",
      "Epoch:851/1000\n",
      "Loss on train= 0.005385908763855696\n",
      "Loss on test= 0.006097718607634306\n",
      "acc for Lsat= 0.0999541174188272 \n",
      "acc for Psat= 0.12730631022240524 \n",
      "acc for optim= 0.18548198560710555\n",
      "Epoch:852/1000\n",
      "Loss on train= 0.005314972251653671\n",
      "Loss on test= 0.006156612187623978\n",
      "acc for Lsat= 0.10333479657410091 \n",
      "acc for Psat= 0.14224789856614395 \n",
      "acc for optim= 0.18055591069749394\n",
      "Epoch:853/1000\n",
      "Loss on train= 0.0053871069103479385\n",
      "Loss on test= 0.006210120860487223\n",
      "acc for Lsat= 0.09874890737227654 \n",
      "acc for Psat= 0.13671277015720557 \n",
      "acc for optim= 0.17161264998475248\n",
      "Epoch:854/1000\n",
      "Loss on train= 0.005429662298411131\n",
      "Loss on test= 0.0062452880665659904\n",
      "acc for Lsat= 0.11239557821635093 \n",
      "acc for Psat= 0.15194879011172108 \n",
      "acc for optim= 0.17795582730402001\n",
      "Epoch:855/1000\n",
      "Loss on train= 0.005333422217518091\n",
      "Loss on test= 0.0061143250204622746\n",
      "acc for Lsat= 0.09058381056943829 \n",
      "acc for Psat= 0.1319093602118023 \n",
      "acc for optim= 0.18477802771238325\n",
      "Epoch:856/1000\n",
      "Loss on train= 0.00530523294582963\n",
      "Loss on test= 0.0058605726808309555\n",
      "acc for Lsat= 0.10212183516943418 \n",
      "acc for Psat= 0.13720104317772755 \n",
      "acc for optim= 0.1726393925146174\n",
      "Epoch:857/1000\n",
      "Loss on train= 0.005457780789583921\n",
      "Loss on test= 0.006044086534529924\n",
      "acc for Lsat= 0.10268330687345735 \n",
      "acc for Psat= 0.14730879015149154 \n",
      "acc for optim= 0.18211187365458947\n",
      "Epoch:858/1000\n",
      "Loss on train= 0.005252260249108076\n",
      "Loss on test= 0.00604100851342082\n",
      "acc for Lsat= 0.10100022004515237 \n",
      "acc for Psat= 0.1349310078742022 \n",
      "acc for optim= 0.1716523623855595\n",
      "Epoch:859/1000\n",
      "Loss on train= 0.005433673970401287\n",
      "Loss on test= 0.005879669915884733\n",
      "acc for Lsat= 0.09869500506290439 \n",
      "acc for Psat= 0.13497624466801456 \n",
      "acc for optim= 0.18017477691647107\n",
      "Epoch:860/1000\n",
      "Loss on train= 0.0053856694139540195\n",
      "Loss on test= 0.0065076714381575584\n",
      "acc for Lsat= 0.09263162515165632 \n",
      "acc for Psat= 0.14700990846196596 \n",
      "acc for optim= 0.1938148540847193\n",
      "Epoch:861/1000\n",
      "Loss on train= 0.005398406181484461\n",
      "Loss on test= 0.005952584557235241\n",
      "acc for Lsat= 0.10266521687489161 \n",
      "acc for Psat= 0.137375912388542 \n",
      "acc for optim= 0.18134951546089723\n",
      "Epoch:862/1000\n",
      "Loss on train= 0.005315191578119993\n",
      "Loss on test= 0.006299503147602081\n",
      "acc for Lsat= 0.10515652544109813 \n",
      "acc for Psat= 0.1500336489027516 \n",
      "acc for optim= 0.19153270878398918\n",
      "Epoch:863/1000\n",
      "Loss on train= 0.005297570023685694\n",
      "Loss on test= 0.00610656151548028\n",
      "acc for Lsat= 0.10146310233069047 \n",
      "acc for Psat= 0.1332515965785113 \n",
      "acc for optim= 0.17904875811773463\n",
      "Epoch:864/1000\n",
      "Loss on train= 0.005284690763801336\n",
      "Loss on test= 0.006139867473393679\n",
      "acc for Lsat= 0.09431191044386034 \n",
      "acc for Psat= 0.1293502305875043 \n",
      "acc for optim= 0.17859568052364796\n",
      "Epoch:865/1000\n",
      "Loss on train= 0.0053575471974909306\n",
      "Loss on test= 0.006176012568175793\n",
      "acc for Lsat= 0.10835769054099081 \n",
      "acc for Psat= 0.13665641894646904 \n",
      "acc for optim= 0.18015422639200243\n",
      "Epoch:866/1000\n",
      "Loss on train= 0.005442236550152302\n",
      "Loss on test= 0.006136502139270306\n",
      "acc for Lsat= 0.1012216727902434 \n",
      "acc for Psat= 0.13971664863367272 \n",
      "acc for optim= 0.18475470051319354\n",
      "Epoch:867/1000\n",
      "Loss on train= 0.0052482993341982365\n",
      "Loss on test= 0.006056560203433037\n",
      "acc for Lsat= 0.11417710391471116 \n",
      "acc for Psat= 0.14092361538501266 \n",
      "acc for optim= 0.1766092439633952\n",
      "Epoch:868/1000\n",
      "Loss on train= 0.005506924819201231\n",
      "Loss on test= 0.0061577726155519485\n",
      "acc for Lsat= 0.0935414406297318 \n",
      "acc for Psat= 0.13201081654189106 \n",
      "acc for optim= 0.18303742222971345\n",
      "Epoch:869/1000\n",
      "Loss on train= 0.0053612603805959225\n",
      "Loss on test= 0.0060907467268407345\n",
      "acc for Lsat= 0.10370523883414877 \n",
      "acc for Psat= 0.13019030839194923 \n",
      "acc for optim= 0.17644394382250383\n",
      "Epoch:870/1000\n",
      "Loss on train= 0.005459729582071304\n",
      "Loss on test= 0.005966272205114365\n",
      "acc for Lsat= 0.0987785045764413 \n",
      "acc for Psat= 0.13621968762550535 \n",
      "acc for optim= 0.17391135118044893\n",
      "Epoch:871/1000\n",
      "Loss on train= 0.005308420863002539\n",
      "Loss on test= 0.006052936427295208\n",
      "acc for Lsat= 0.09649909046948177 \n",
      "acc for Psat= 0.1297842206969123 \n",
      "acc for optim= 0.18512549463351716\n",
      "Epoch:872/1000\n",
      "Loss on train= 0.005305805709213018\n",
      "Loss on test= 0.0062112328596413136\n",
      "acc for Lsat= 0.12328423708203738 \n",
      "acc for Psat= 0.1396687211314911 \n",
      "acc for optim= 0.17651960935633063\n",
      "Epoch:873/1000\n",
      "Loss on train= 0.005466597620397806\n",
      "Loss on test= 0.006179917603731155\n",
      "acc for Lsat= 0.10800160201566325 \n",
      "acc for Psat= 0.14667308339691262 \n",
      "acc for optim= 0.17571718462316666\n",
      "Epoch:874/1000\n",
      "Loss on train= 0.005399346351623535\n",
      "Loss on test= 0.005966488271951675\n",
      "acc for Lsat= 0.10268716050836779 \n",
      "acc for Psat= 0.13763703970689675 \n",
      "acc for optim= 0.17856946158833542\n",
      "Epoch:875/1000\n",
      "Loss on train= 0.005261626094579697\n",
      "Loss on test= 0.006195956375449896\n",
      "acc for Lsat= 0.10958888706103978 \n",
      "acc for Psat= 0.12610438622226466 \n",
      "acc for optim= 0.17998793185175538\n",
      "Epoch:876/1000\n",
      "Loss on train= 0.005336002912372351\n",
      "Loss on test= 0.006282246205955744\n",
      "acc for Lsat= 0.10283785524336085 \n",
      "acc for Psat= 0.13327417603197658 \n",
      "acc for optim= 0.1823020816196577\n",
      "Epoch:877/1000\n",
      "Loss on train= 0.005147071555256844\n",
      "Loss on test= 0.005912217311561108\n",
      "acc for Lsat= 0.0926967024620646 \n",
      "acc for Psat= 0.13366531137805196 \n",
      "acc for optim= 0.17818476381147838\n",
      "Epoch:878/1000\n",
      "Loss on train= 0.005300627555698156\n",
      "Loss on test= 0.006472745910286903\n",
      "acc for Lsat= 0.10082448664639622 \n",
      "acc for Psat= 0.1713461250177253 \n",
      "acc for optim= 0.1838182154316771\n",
      "Epoch:879/1000\n",
      "Loss on train= 0.005360882729291916\n",
      "Loss on test= 0.006305216811597347\n",
      "acc for Lsat= 0.1252860900978025 \n",
      "acc for Psat= 0.13827511887899718 \n",
      "acc for optim= 0.17665681475378825\n",
      "Epoch:880/1000\n",
      "Loss on train= 0.0054357824847102165\n",
      "Loss on test= 0.006025015842169523\n",
      "acc for Lsat= 0.10247057569134285 \n",
      "acc for Psat= 0.13599919245294217 \n",
      "acc for optim= 0.17288187817054784\n",
      "Epoch:881/1000\n",
      "Loss on train= 0.005268339067697525\n",
      "Loss on test= 0.0063650477677583694\n",
      "acc for Lsat= 0.09873634871680331 \n",
      "acc for Psat= 0.15696272853982904 \n",
      "acc for optim= 0.19274252861525107\n",
      "Epoch:882/1000\n",
      "Loss on train= 0.005392896942794323\n",
      "Loss on test= 0.006213020998984575\n",
      "acc for Lsat= 0.10442993313279318 \n",
      "acc for Psat= 0.12790874567344565 \n",
      "acc for optim= 0.1820127675629426\n",
      "Epoch:883/1000\n",
      "Loss on train= 0.005317955277860165\n",
      "Loss on test= 0.006187439896166325\n",
      "acc for Lsat= 0.10332117995794299 \n",
      "acc for Psat= 0.13191894904189444 \n",
      "acc for optim= 0.17687205373135917\n",
      "Epoch:884/1000\n",
      "Loss on train= 0.005178771913051605\n",
      "Loss on test= 0.006257739383727312\n",
      "acc for Lsat= 0.11247144074897455 \n",
      "acc for Psat= 0.13512243160551762 \n",
      "acc for optim= 0.1797549566340838\n",
      "Epoch:885/1000\n",
      "Loss on train= 0.0053492141887545586\n",
      "Loss on test= 0.0058905864134430885\n",
      "acc for Lsat= 0.08935282050821362 \n",
      "acc for Psat= 0.13727892526579327 \n",
      "acc for optim= 0.17545938450740492\n",
      "Epoch:886/1000\n",
      "Loss on train= 0.005209901835769415\n",
      "Loss on test= 0.006403871346265078\n",
      "acc for Lsat= 0.09643975464011527 \n",
      "acc for Psat= 0.13936071491206334 \n",
      "acc for optim= 0.20008736750134662\n",
      "Epoch:887/1000\n",
      "Loss on train= 0.005279493518173695\n",
      "Loss on test= 0.006029809359461069\n",
      "acc for Lsat= 0.09929377160871686 \n",
      "acc for Psat= 0.1447252464648415 \n",
      "acc for optim= 0.1734927774695048\n",
      "Epoch:888/1000\n",
      "Loss on train= 0.005334462504833937\n",
      "Loss on test= 0.005886129569262266\n",
      "acc for Lsat= 0.09981832495531447 \n",
      "acc for Psat= 0.12500155034210628 \n",
      "acc for optim= 0.18518480924611724\n",
      "Epoch:889/1000\n",
      "Loss on train= 0.005229749716818333\n",
      "Loss on test= 0.006244023330509663\n",
      "acc for Lsat= 0.10227615132935787 \n",
      "acc for Psat= 0.14250932425740018 \n",
      "acc for optim= 0.17961196911765925\n",
      "Epoch:890/1000\n",
      "Loss on train= 0.005661768838763237\n",
      "Loss on test= 0.006243032868951559\n",
      "acc for Lsat= 0.11574671489948217 \n",
      "acc for Psat= 0.13535044762884046 \n",
      "acc for optim= 0.1750070986912144\n",
      "Epoch:891/1000\n",
      "Loss on train= 0.005265210755169392\n",
      "Loss on test= 0.005927548743784428\n",
      "acc for Lsat= 0.09233910889301639 \n",
      "acc for Psat= 0.1383450315389151 \n",
      "acc for optim= 0.17555212931948225\n",
      "Epoch:892/1000\n",
      "Loss on train= 0.005327566992491484\n",
      "Loss on test= 0.006245996803045273\n",
      "acc for Lsat= 0.12248523914732702 \n",
      "acc for Psat= 0.14407066803413712 \n",
      "acc for optim= 0.1779222698435799\n",
      "Epoch:893/1000\n",
      "Loss on train= 0.005421195179224014\n",
      "Loss on test= 0.006015952210873365\n",
      "acc for Lsat= 0.10228644190632376 \n",
      "acc for Psat= 0.13576126942989195 \n",
      "acc for optim= 0.1779427316057451\n",
      "Epoch:894/1000\n",
      "Loss on train= 0.005358826834708452\n",
      "Loss on test= 0.006105268839746714\n",
      "acc for Lsat= 0.09296974684999687 \n",
      "acc for Psat= 0.15440785917364677 \n",
      "acc for optim= 0.17892501054655255\n",
      "Epoch:895/1000\n",
      "Loss on train= 0.00534412357956171\n",
      "Loss on test= 0.005999188404530287\n",
      "acc for Lsat= 0.09311380562262997 \n",
      "acc for Psat= 0.13938867128986898 \n",
      "acc for optim= 0.18322620786947466\n",
      "Epoch:896/1000\n",
      "Loss on train= 0.005197118502110243\n",
      "Loss on test= 0.005862140096724033\n",
      "acc for Lsat= 0.1008849715042003 \n",
      "acc for Psat= 0.1394634304881901 \n",
      "acc for optim= 0.1784632987287527\n",
      "Epoch:897/1000\n",
      "Loss on train= 0.005130426492542028\n",
      "Loss on test= 0.006069045979529619\n",
      "acc for Lsat= 0.09512397458054662 \n",
      "acc for Psat= 0.13722433080270016 \n",
      "acc for optim= 0.17429142871820288\n",
      "Epoch:898/1000\n",
      "Loss on train= 0.0053253513760864735\n",
      "Loss on test= 0.006080521736294031\n",
      "acc for Lsat= 0.09294960725420132 \n",
      "acc for Psat= 0.14050133940921622 \n",
      "acc for optim= 0.1843242887405568\n",
      "Epoch:899/1000\n",
      "Loss on train= 0.005306031554937363\n",
      "Loss on test= 0.006203311961144209\n",
      "acc for Lsat= 0.08468064435025661 \n",
      "acc for Psat= 0.12585802133889648 \n",
      "acc for optim= 0.1880744159255686\n",
      "Epoch:900/1000\n",
      "Loss on train= 0.005418967921286821\n",
      "Loss on test= 0.0062674847431480885\n",
      "acc for Lsat= 0.11853464771480442 \n",
      "acc for Psat= 0.14178796299295185 \n",
      "acc for optim= 0.18405985222328788\n",
      "Epoch:901/1000\n",
      "Loss on train= 0.005396401975303888\n",
      "Loss on test= 0.006158068310469389\n",
      "acc for Lsat= 0.10245877867505365 \n",
      "acc for Psat= 0.13768741757316924 \n",
      "acc for optim= 0.17681968908419565\n",
      "Epoch:902/1000\n",
      "Loss on train= 0.005363559816032648\n",
      "Loss on test= 0.00597580149769783\n",
      "acc for Lsat= 0.09844359954480196 \n",
      "acc for Psat= 0.1292136771257146 \n",
      "acc for optim= 0.1843299638036978\n",
      "Epoch:903/1000\n",
      "Loss on train= 0.005139293614774942\n",
      "Loss on test= 0.006187156308442354\n",
      "acc for Lsat= 0.10683618140687093 \n",
      "acc for Psat= 0.12920047675093668 \n",
      "acc for optim= 0.17260265458233148\n",
      "Epoch:904/1000\n",
      "Loss on train= 0.005402407608926296\n",
      "Loss on test= 0.006160044111311436\n",
      "acc for Lsat= 0.09117446626493139 \n",
      "acc for Psat= 0.14193880355716396 \n",
      "acc for optim= 0.1840085117067447\n",
      "Epoch:905/1000\n",
      "Loss on train= 0.005408700555562973\n",
      "Loss on test= 0.006132976152002811\n",
      "acc for Lsat= 0.0992798144913326 \n",
      "acc for Psat= 0.12754732101319075 \n",
      "acc for optim= 0.18228868415946203\n",
      "Epoch:906/1000\n",
      "Loss on train= 0.005329558160156012\n",
      "Loss on test= 0.006043576169759035\n",
      "acc for Lsat= 0.09432458778721442 \n",
      "acc for Psat= 0.12101396745873884 \n",
      "acc for optim= 0.17704517825711835\n",
      "Epoch:907/1000\n",
      "Loss on train= 0.005111268255859613\n",
      "Loss on test= 0.006215421017259359\n",
      "acc for Lsat= 0.09960921115273515 \n",
      "acc for Psat= 0.12879431301755515 \n",
      "acc for optim= 0.17331626621031565\n",
      "Epoch:908/1000\n",
      "Loss on train= 0.005321100819855928\n",
      "Loss on test= 0.006098462268710136\n",
      "acc for Lsat= 0.11225714178941355 \n",
      "acc for Psat= 0.1527821652249875 \n",
      "acc for optim= 0.1821592700507855\n",
      "Epoch:909/1000\n",
      "Loss on train= 0.005373796913772821\n",
      "Loss on test= 0.006337911356240511\n",
      "acc for Lsat= 0.1105926650464811 \n",
      "acc for Psat= 0.13449200027567035 \n",
      "acc for optim= 0.17404515880625696\n",
      "Epoch:910/1000\n",
      "Loss on train= 0.005367461591959\n",
      "Loss on test= 0.005785011220723391\n",
      "acc for Lsat= 0.0944856583162495 \n",
      "acc for Psat= 0.12336890928652454 \n",
      "acc for optim= 0.17652123913117607\n",
      "Epoch:911/1000\n",
      "Loss on train= 0.005435967817902565\n",
      "Loss on test= 0.006377846468240023\n",
      "acc for Lsat= 0.09861117079666563 \n",
      "acc for Psat= 0.17050201279945845 \n",
      "acc for optim= 0.18394369947945036\n",
      "Epoch:912/1000\n",
      "Loss on train= 0.005360272713005543\n",
      "Loss on test= 0.00599351990967989\n",
      "acc for Lsat= 0.10077085948600513 \n",
      "acc for Psat= 0.14689772789020258 \n",
      "acc for optim= 0.17980515513193232\n",
      "Epoch:913/1000\n",
      "Loss on train= 0.005302872508764267\n",
      "Loss on test= 0.006303013302385807\n",
      "acc for Lsat= 0.104288889148462 \n",
      "acc for Psat= 0.12973214379488096 \n",
      "acc for optim= 0.18489431112524224\n",
      "Epoch:914/1000\n",
      "Loss on train= 0.00532077020034194\n",
      "Loss on test= 0.006228907033801079\n",
      "acc for Lsat= 0.11129514343187635 \n",
      "acc for Psat= 0.13880433652548008 \n",
      "acc for optim= 0.18043978268643684\n",
      "Epoch:915/1000\n",
      "Loss on train= 0.005202471278607845\n",
      "Loss on test= 0.005978640168905258\n",
      "acc for Lsat= 0.09695963409326781 \n",
      "acc for Psat= 0.1263403505101759 \n",
      "acc for optim= 0.18704983924113025\n",
      "Epoch:916/1000\n",
      "Loss on train= 0.005198479164391756\n",
      "Loss on test= 0.006554233841598034\n",
      "acc for Lsat= 0.12196744328297643 \n",
      "acc for Psat= 0.1413286452738063 \n",
      "acc for optim= 0.17169751938848293\n",
      "Epoch:917/1000\n",
      "Loss on train= 0.0053014294244349\n",
      "Loss on test= 0.006345522589981556\n",
      "acc for Lsat= 0.09636338126729242 \n",
      "acc for Psat= 0.11990851783755993 \n",
      "acc for optim= 0.17927688548147286\n",
      "Epoch:918/1000\n",
      "Loss on train= 0.005324447061866522\n",
      "Loss on test= 0.006182695738971233\n",
      "acc for Lsat= 0.10303027888462027 \n",
      "acc for Psat= 0.12738453598517405 \n",
      "acc for optim= 0.1838360678633454\n",
      "Epoch:919/1000\n",
      "Loss on train= 0.005180360283702612\n",
      "Loss on test= 0.006411584094166756\n",
      "acc for Lsat= 0.11633437467794235 \n",
      "acc for Psat= 0.1403959537948895 \n",
      "acc for optim= 0.17943899434023355\n",
      "Epoch:920/1000\n",
      "Loss on train= 0.0052971066907048225\n",
      "Loss on test= 0.006229639984667301\n",
      "acc for Lsat= 0.09901996164610294 \n",
      "acc for Psat= 0.1352303094621274 \n",
      "acc for optim= 0.1820472706105339\n",
      "Epoch:921/1000\n",
      "Loss on train= 0.0051558976992964745\n",
      "Loss on test= 0.0059902663342654705\n",
      "acc for Lsat= 0.09317495682586568 \n",
      "acc for Psat= 0.1331653114516284 \n",
      "acc for optim= 0.17275269181325525\n",
      "Epoch:922/1000\n",
      "Loss on train= 0.005224592052400112\n",
      "Loss on test= 0.006557619199156761\n",
      "acc for Lsat= 0.12560662742476256 \n",
      "acc for Psat= 0.12676379700029522 \n",
      "acc for optim= 0.1870323282147445\n",
      "Epoch:923/1000\n",
      "Loss on train= 0.0053449636325240135\n",
      "Loss on test= 0.006142984144389629\n",
      "acc for Lsat= 0.1017489732027555 \n",
      "acc for Psat= 0.13888861565471833 \n",
      "acc for optim= 0.18296808321837935\n",
      "Epoch:924/1000\n",
      "Loss on train= 0.005480567459017038\n",
      "Loss on test= 0.0062707653269171715\n",
      "acc for Lsat= 0.1161323669542148 \n",
      "acc for Psat= 0.15108442279012968 \n",
      "acc for optim= 0.16872690231134815\n",
      "Epoch:925/1000\n",
      "Loss on train= 0.00542319705709815\n",
      "Loss on test= 0.006048501469194889\n",
      "acc for Lsat= 0.1062785390667791 \n",
      "acc for Psat= 0.14167108826508934 \n",
      "acc for optim= 0.17772179615286265\n",
      "Epoch:926/1000\n",
      "Loss on train= 0.005204118322581053\n",
      "Loss on test= 0.006156336981803179\n",
      "acc for Lsat= 0.12025485011315865 \n",
      "acc for Psat= 0.13475939981472654 \n",
      "acc for optim= 0.1761344024849369\n",
      "Epoch:927/1000\n",
      "Loss on train= 0.005250910297036171\n",
      "Loss on test= 0.006264384835958481\n",
      "acc for Lsat= 0.11894578619749617 \n",
      "acc for Psat= 0.14061072127710064 \n",
      "acc for optim= 0.18014153105747427\n",
      "Epoch:928/1000\n",
      "Loss on train= 0.005310464650392532\n",
      "Loss on test= 0.0060717761516571045\n",
      "acc for Lsat= 0.09439095334708296 \n",
      "acc for Psat= 0.13034360852423993 \n",
      "acc for optim= 0.1717923468353732\n",
      "Epoch:929/1000\n",
      "Loss on train= 0.005277044139802456\n",
      "Loss on test= 0.00613638898357749\n",
      "acc for Lsat= 0.09484422857956014 \n",
      "acc for Psat= 0.13259547436392818 \n",
      "acc for optim= 0.1815476715343736\n",
      "Epoch:930/1000\n",
      "Loss on train= 0.0052794599905610085\n",
      "Loss on test= 0.005899613257497549\n",
      "acc for Lsat= 0.09496825971804417 \n",
      "acc for Psat= 0.13904560022263282 \n",
      "acc for optim= 0.18083429574410004\n",
      "Epoch:931/1000\n",
      "Loss on train= 0.005090552382171154\n",
      "Loss on test= 0.006139648612588644\n",
      "acc for Lsat= 0.0933238704408661 \n",
      "acc for Psat= 0.13050389984381874 \n",
      "acc for optim= 0.1827151346788939\n",
      "Epoch:932/1000\n",
      "Loss on train= 0.005183998961001635\n",
      "Loss on test= 0.006120204925537109\n",
      "acc for Lsat= 0.09356379631938318 \n",
      "acc for Psat= 0.13202857386677969 \n",
      "acc for optim= 0.1804843023598936\n",
      "Epoch:933/1000\n",
      "Loss on train= 0.005413662642240524\n",
      "Loss on test= 0.006321331020444632\n",
      "acc for Lsat= 0.10887109839438334 \n",
      "acc for Psat= 0.12570743482555974 \n",
      "acc for optim= 0.19114826901251514\n",
      "Epoch:934/1000\n",
      "Loss on train= 0.005398907698690891\n",
      "Loss on test= 0.005977333057671785\n",
      "acc for Lsat= 0.09418344293820664 \n",
      "acc for Psat= 0.13448875274245778 \n",
      "acc for optim= 0.17974141719119655\n",
      "Epoch:935/1000\n",
      "Loss on train= 0.005475095007568598\n",
      "Loss on test= 0.006124878767877817\n",
      "acc for Lsat= 0.10615353050199731 \n",
      "acc for Psat= 0.12979602272927138 \n",
      "acc for optim= 0.1775947491685718\n",
      "Epoch:936/1000\n",
      "Loss on train= 0.00531463697552681\n",
      "Loss on test= 0.00607461528852582\n",
      "acc for Lsat= 0.10534002364739396 \n",
      "acc for Psat= 0.1364369580163068 \n",
      "acc for optim= 0.18280789169909084\n",
      "Epoch:937/1000\n",
      "Loss on train= 0.00517210504040122\n",
      "Loss on test= 0.0058554732240736485\n",
      "acc for Lsat= 0.09773367955665088 \n",
      "acc for Psat= 0.11856782199480469 \n",
      "acc for optim= 0.16972949251333266\n",
      "Epoch:938/1000\n",
      "Loss on train= 0.005406287033110857\n",
      "Loss on test= 0.006160750985145569\n",
      "acc for Lsat= 0.10186188152075698 \n",
      "acc for Psat= 0.13389343390403063 \n",
      "acc for optim= 0.18479932321026385\n",
      "Epoch:939/1000\n",
      "Loss on train= 0.00513115432113409\n",
      "Loss on test= 0.006008927244693041\n",
      "acc for Lsat= 0.10496434908324727 \n",
      "acc for Psat= 0.1485544429796006 \n",
      "acc for optim= 0.17331163016842457\n",
      "Epoch:940/1000\n",
      "Loss on train= 0.005156861152499914\n",
      "Loss on test= 0.006138471886515617\n",
      "acc for Lsat= 0.11061452450802929 \n",
      "acc for Psat= 0.133970395177879 \n",
      "acc for optim= 0.18294983362084474\n",
      "Epoch:941/1000\n",
      "Loss on train= 0.0051828972063958645\n",
      "Loss on test= 0.005801228806376457\n",
      "acc for Lsat= 0.1030828648388891 \n",
      "acc for Psat= 0.12784547665929896 \n",
      "acc for optim= 0.18428813189670634\n",
      "Epoch:942/1000\n",
      "Loss on train= 0.0051824599504470825\n",
      "Loss on test= 0.006098131183534861\n",
      "acc for Lsat= 0.10739625618996304 \n",
      "acc for Psat= 0.13175529439793504 \n",
      "acc for optim= 0.18311616851596982\n",
      "Epoch:943/1000\n",
      "Loss on train= 0.005246372427791357\n",
      "Loss on test= 0.005978447385132313\n",
      "acc for Lsat= 0.09174437514831602 \n",
      "acc for Psat= 0.12509020146631666 \n",
      "acc for optim= 0.17658350427942823\n",
      "Epoch:944/1000\n",
      "Loss on train= 0.0052617499604821205\n",
      "Loss on test= 0.006228769663721323\n",
      "acc for Lsat= 0.10308484129017709 \n",
      "acc for Psat= 0.12213749387340968 \n",
      "acc for optim= 0.16945606667200158\n",
      "Epoch:945/1000\n",
      "Loss on train= 0.005335440393537283\n",
      "Loss on test= 0.006013994105160236\n",
      "acc for Lsat= 0.09246121087842582 \n",
      "acc for Psat= 0.13379428010341174 \n",
      "acc for optim= 0.1762611315404144\n",
      "Epoch:946/1000\n",
      "Loss on train= 0.005319184623658657\n",
      "Loss on test= 0.006011576391756535\n",
      "acc for Lsat= 0.09986749168332978 \n",
      "acc for Psat= 0.1316136427399292 \n",
      "acc for optim= 0.18406152953156982\n",
      "Epoch:947/1000\n",
      "Loss on train= 0.005214225500822067\n",
      "Loss on test= 0.0059859114699065685\n",
      "acc for Lsat= 0.09470609423755746 \n",
      "acc for Psat= 0.1332745225512091 \n",
      "acc for optim= 0.19172185776603282\n",
      "Epoch:948/1000\n",
      "Loss on train= 0.005010056309401989\n",
      "Loss on test= 0.0059942686930298805\n",
      "acc for Lsat= 0.09349293850670111 \n",
      "acc for Psat= 0.12779305160215315 \n",
      "acc for optim= 0.1811394165378553\n",
      "Epoch:949/1000\n",
      "Loss on train= 0.005030404310673475\n",
      "Loss on test= 0.005946788005530834\n",
      "acc for Lsat= 0.12462005551620307 \n",
      "acc for Psat= 0.12999299114039248 \n",
      "acc for optim= 0.18271199633797505\n",
      "Epoch:950/1000\n",
      "Loss on train= 0.005209755152463913\n",
      "Loss on test= 0.0058799139223992825\n",
      "acc for Lsat= 0.10113821631209664 \n",
      "acc for Psat= 0.12661867787739878 \n",
      "acc for optim= 0.17258176376482756\n",
      "Epoch:951/1000\n",
      "Loss on train= 0.005220575258135796\n",
      "Loss on test= 0.006155938841402531\n",
      "acc for Lsat= 0.09465196744905847 \n",
      "acc for Psat= 0.12319519820288159 \n",
      "acc for optim= 0.18454528836261133\n",
      "Epoch:952/1000\n",
      "Loss on train= 0.0051681906916201115\n",
      "Loss on test= 0.006276159547269344\n",
      "acc for Lsat= 0.10828190534750505 \n",
      "acc for Psat= 0.133842571295198 \n",
      "acc for optim= 0.1850409607989003\n",
      "Epoch:953/1000\n",
      "Loss on train= 0.005135989747941494\n",
      "Loss on test= 0.006251044105738401\n",
      "acc for Lsat= 0.10009176088152437 \n",
      "acc for Psat= 0.12207443005567165 \n",
      "acc for optim= 0.18726127826237768\n",
      "Epoch:954/1000\n",
      "Loss on train= 0.005311502609401941\n",
      "Loss on test= 0.006262312643229961\n",
      "acc for Lsat= 0.09418638412716357 \n",
      "acc for Psat= 0.13197342837989032 \n",
      "acc for optim= 0.16959567639416367\n",
      "Epoch:955/1000\n",
      "Loss on train= 0.005434579681605101\n",
      "Loss on test= 0.006261717062443495\n",
      "acc for Lsat= 0.1082383792427116 \n",
      "acc for Psat= 0.1551232791758316 \n",
      "acc for optim= 0.1860385826894899\n",
      "Epoch:956/1000\n",
      "Loss on train= 0.005132666788995266\n",
      "Loss on test= 0.005851578898727894\n",
      "acc for Lsat= 0.10324353135932805 \n",
      "acc for Psat= 0.12873546001856548 \n",
      "acc for optim= 0.17742163008325576\n",
      "Epoch:957/1000\n",
      "Loss on train= 0.005191447678953409\n",
      "Loss on test= 0.005975551903247833\n",
      "acc for Lsat= 0.09909469955975694 \n",
      "acc for Psat= 0.12627073252115842 \n",
      "acc for optim= 0.17517596649369066\n",
      "Epoch:958/1000\n",
      "Loss on train= 0.0050696441903710365\n",
      "Loss on test= 0.005961122456938028\n",
      "acc for Lsat= 0.0970083222795037 \n",
      "acc for Psat= 0.13084591470927126 \n",
      "acc for optim= 0.17976294719841987\n",
      "Epoch:959/1000\n",
      "Loss on train= 0.005068756639957428\n",
      "Loss on test= 0.005886285565793514\n",
      "acc for Lsat= 0.09901782116829023 \n",
      "acc for Psat= 0.14128429546460936 \n",
      "acc for optim= 0.1730760900212957\n",
      "Epoch:960/1000\n",
      "Loss on train= 0.005123812239617109\n",
      "Loss on test= 0.006065309513360262\n",
      "acc for Lsat= 0.11197945022347809 \n",
      "acc for Psat= 0.13603446500719193 \n",
      "acc for optim= 0.17627920605048886\n",
      "Epoch:961/1000\n",
      "Loss on train= 0.005205038469284773\n",
      "Loss on test= 0.005935111083090305\n",
      "acc for Lsat= 0.08801197354648246 \n",
      "acc for Psat= 0.12292789495924993 \n",
      "acc for optim= 0.1835144161246717\n",
      "Epoch:962/1000\n",
      "Loss on train= 0.005145225673913956\n",
      "Loss on test= 0.006012000143527985\n",
      "acc for Lsat= 0.09658171742798374 \n",
      "acc for Psat= 0.13241738019988603 \n",
      "acc for optim= 0.1862009957977827\n",
      "Epoch:963/1000\n",
      "Loss on train= 0.005004439037293196\n",
      "Loss on test= 0.005820926744490862\n",
      "acc for Lsat= 0.09235699654880405 \n",
      "acc for Psat= 0.13446029497846226 \n",
      "acc for optim= 0.18145373188416963\n",
      "Epoch:964/1000\n",
      "Loss on train= 0.005061930511146784\n",
      "Loss on test= 0.006222181487828493\n",
      "acc for Lsat= 0.10473555491623564 \n",
      "acc for Psat= 0.1446590413284188 \n",
      "acc for optim= 0.17689869475108966\n",
      "Epoch:965/1000\n",
      "Loss on train= 0.005259938538074493\n",
      "Loss on test= 0.006220705807209015\n",
      "acc for Lsat= 0.10966312746540545 \n",
      "acc for Psat= 0.1344998626734951 \n",
      "acc for optim= 0.18124846032647005\n",
      "Epoch:966/1000\n",
      "Loss on train= 0.005165774375200272\n",
      "Loss on test= 0.006039978936314583\n",
      "acc for Lsat= 0.10224518951628421 \n",
      "acc for Psat= 0.1400871017584735 \n",
      "acc for optim= 0.1870619597221267\n",
      "Epoch:967/1000\n",
      "Loss on train= 0.005161899607628584\n",
      "Loss on test= 0.0058492072857916355\n",
      "acc for Lsat= 0.09890550140832093 \n",
      "acc for Psat= 0.13605989199388235 \n",
      "acc for optim= 0.18075893479063948\n",
      "Epoch:968/1000\n",
      "Loss on train= 0.0051878588274121284\n",
      "Loss on test= 0.006196961272507906\n",
      "acc for Lsat= 0.09729571180922271 \n",
      "acc for Psat= 0.14188409259570448 \n",
      "acc for optim= 0.18282387604980366\n",
      "Epoch:969/1000\n",
      "Loss on train= 0.005175053607672453\n",
      "Loss on test= 0.006474624387919903\n",
      "acc for Lsat= 0.10530098267580319 \n",
      "acc for Psat= 0.15868773537651454 \n",
      "acc for optim= 0.18376708247469958\n",
      "Epoch:970/1000\n",
      "Loss on train= 0.005208419170230627\n",
      "Loss on test= 0.006357237230986357\n",
      "acc for Lsat= 0.13215313480868027 \n",
      "acc for Psat= 0.13907443990583643 \n",
      "acc for optim= 0.18099548480457672\n",
      "Epoch:971/1000\n",
      "Loss on train= 0.00520628085359931\n",
      "Loss on test= 0.006024432834237814\n",
      "acc for Lsat= 0.104359904294873 \n",
      "acc for Psat= 0.1285117203219778 \n",
      "acc for optim= 0.1801852167836564\n",
      "Epoch:972/1000\n",
      "Loss on train= 0.005059459712356329\n",
      "Loss on test= 0.006095123011618853\n",
      "acc for Lsat= 0.10148339687000124 \n",
      "acc for Psat= 0.13421597744977512 \n",
      "acc for optim= 0.18986743687221908\n",
      "Epoch:973/1000\n",
      "Loss on train= 0.005184279754757881\n",
      "Loss on test= 0.006178945768624544\n",
      "acc for Lsat= 0.10624528946330321 \n",
      "acc for Psat= 0.14444105193034698 \n",
      "acc for optim= 0.177721904620323\n",
      "Epoch:974/1000\n",
      "Loss on train= 0.005140833090990782\n",
      "Loss on test= 0.006167103070765734\n",
      "acc for Lsat= 0.08879362899194455 \n",
      "acc for Psat= 0.13510645178805936 \n",
      "acc for optim= 0.17818714103481922\n",
      "Epoch:975/1000\n",
      "Loss on train= 0.005117135122418404\n",
      "Loss on test= 0.006336753722280264\n",
      "acc for Lsat= 0.12033736528537702 \n",
      "acc for Psat= 0.13560009344270793 \n",
      "acc for optim= 0.17719130480634365\n",
      "Epoch:976/1000\n",
      "Loss on train= 0.005159858614206314\n",
      "Loss on test= 0.006064760033041239\n",
      "acc for Lsat= 0.10166197215222707 \n",
      "acc for Psat= 0.1363532617102156 \n",
      "acc for optim= 0.1743680323304419\n",
      "Epoch:977/1000\n",
      "Loss on train= 0.005148605909198523\n",
      "Loss on test= 0.005805075168609619\n",
      "acc for Lsat= 0.09884593319522722 \n",
      "acc for Psat= 0.1289451553786205 \n",
      "acc for optim= 0.17227020624549508\n",
      "Epoch:978/1000\n",
      "Loss on train= 0.004963744431734085\n",
      "Loss on test= 0.006282438058406115\n",
      "acc for Lsat= 0.08588268777544973 \n",
      "acc for Psat= 0.14582847377514246 \n",
      "acc for optim= 0.18553084731299305\n",
      "Epoch:979/1000\n",
      "Loss on train= 0.0050918934866786\n",
      "Loss on test= 0.005940251052379608\n",
      "acc for Lsat= 0.12059869439404268 \n",
      "acc for Psat= 0.12880432028086636 \n",
      "acc for optim= 0.18133936350912613\n",
      "Epoch:980/1000\n",
      "Loss on train= 0.005140179302543402\n",
      "Loss on test= 0.005698142573237419\n",
      "acc for Lsat= 0.09901772245460869 \n",
      "acc for Psat= 0.12807502827737322 \n",
      "acc for optim= 0.1697386067281714\n",
      "Epoch:981/1000\n",
      "Loss on train= 0.0052687800489366055\n",
      "Loss on test= 0.005946984980255365\n",
      "acc for Lsat= 0.08735060461212771 \n",
      "acc for Psat= 0.1397707118554104 \n",
      "acc for optim= 0.1765373284683831\n",
      "Epoch:982/1000\n",
      "Loss on train= 0.005187259521335363\n",
      "Loss on test= 0.006171699147671461\n",
      "acc for Lsat= 0.10653133441484929 \n",
      "acc for Psat= 0.13150427935100398 \n",
      "acc for optim= 0.17252254759403482\n",
      "Epoch:983/1000\n",
      "Loss on train= 0.0051749940030276775\n",
      "Loss on test= 0.00574094895273447\n",
      "acc for Lsat= 0.09747404100618057 \n",
      "acc for Psat= 0.13582894459013606 \n",
      "acc for optim= 0.1706197553377409\n",
      "Epoch:984/1000\n",
      "Loss on train= 0.005293950904160738\n",
      "Loss on test= 0.0058651454746723175\n",
      "acc for Lsat= 0.09856495189265319 \n",
      "acc for Psat= 0.12145003575626445 \n",
      "acc for optim= 0.18363216087711437\n",
      "Epoch:985/1000\n",
      "Loss on train= 0.005227515008300543\n",
      "Loss on test= 0.006169354077428579\n",
      "acc for Lsat= 0.09889725558331505 \n",
      "acc for Psat= 0.148116442160306 \n",
      "acc for optim= 0.19804753829602753\n",
      "Epoch:986/1000\n",
      "Loss on train= 0.0053404285572469234\n",
      "Loss on test= 0.005852286238223314\n",
      "acc for Lsat= 0.1031571773191622 \n",
      "acc for Psat= 0.12276474353403516 \n",
      "acc for optim= 0.18585190520527126\n",
      "Epoch:987/1000\n",
      "Loss on train= 0.005207738373428583\n",
      "Loss on test= 0.006089003756642342\n",
      "acc for Lsat= 0.09625920418497487 \n",
      "acc for Psat= 0.12924413517999495 \n",
      "acc for optim= 0.19111251771820995\n",
      "Epoch:988/1000\n",
      "Loss on train= 0.005296978633850813\n",
      "Loss on test= 0.005941267125308514\n",
      "acc for Lsat= 0.09043486889666814 \n",
      "acc for Psat= 0.1292404425222184 \n",
      "acc for optim= 0.18229597388900878\n",
      "Epoch:989/1000\n",
      "Loss on train= 0.0053326720371842384\n",
      "Loss on test= 0.006165649741888046\n",
      "acc for Lsat= 0.10348573200541777 \n",
      "acc for Psat= 0.14368078528619294 \n",
      "acc for optim= 0.18077567713495474\n",
      "Epoch:990/1000\n",
      "Loss on train= 0.005363995674997568\n",
      "Loss on test= 0.005903387442231178\n",
      "acc for Lsat= 0.11559495448462381 \n",
      "acc for Psat= 0.12285317906713256 \n",
      "acc for optim= 0.1733119297816055\n",
      "Epoch:991/1000\n",
      "Loss on train= 0.005178181454539299\n",
      "Loss on test= 0.0057917507365345955\n",
      "acc for Lsat= 0.0945645784456046 \n",
      "acc for Psat= 0.1317130215864597 \n",
      "acc for optim= 0.17719248288046663\n",
      "Epoch:992/1000\n",
      "Loss on train= 0.005097417160868645\n",
      "Loss on test= 0.006132221315056086\n",
      "acc for Lsat= 0.09806741792018037 \n",
      "acc for Psat= 0.1506661766848006 \n",
      "acc for optim= 0.18369127425633497\n",
      "Epoch:993/1000\n",
      "Loss on train= 0.005075299646705389\n",
      "Loss on test= 0.00585174560546875\n",
      "acc for Lsat= 0.11013697177167761 \n",
      "acc for Psat= 0.1305240268720377 \n",
      "acc for optim= 0.17435837283566366\n",
      "Epoch:994/1000\n",
      "Loss on train= 0.005163914058357477\n",
      "Loss on test= 0.006043584086000919\n",
      "acc for Lsat= 0.09998331984561291 \n",
      "acc for Psat= 0.13266587711661518 \n",
      "acc for optim= 0.17184086507738774\n",
      "Epoch:995/1000\n",
      "Loss on train= 0.005147536285221577\n",
      "Loss on test= 0.005970541853457689\n",
      "acc for Lsat= 0.10503884269658602 \n",
      "acc for Psat= 0.12626906709066765 \n",
      "acc for optim= 0.17635932317145675\n",
      "Epoch:996/1000\n",
      "Loss on train= 0.005081620998680592\n",
      "Loss on test= 0.005896721500903368\n",
      "acc for Lsat= 0.10436058104417081 \n",
      "acc for Psat= 0.1274031828302167 \n",
      "acc for optim= 0.17888847084270032\n",
      "Epoch:997/1000\n",
      "Loss on train= 0.004937693476676941\n",
      "Loss on test= 0.0062093413434922695\n",
      "acc for Lsat= 0.12282561018371903 \n",
      "acc for Psat= 0.12831846421537133 \n",
      "acc for optim= 0.1796109194784441\n",
      "Epoch:998/1000\n",
      "Loss on train= 0.005234507843852043\n",
      "Loss on test= 0.005798222962766886\n",
      "acc for Lsat= 0.09370581879027945 \n",
      "acc for Psat= 0.1307407704119815 \n",
      "acc for optim= 0.18148079556965474\n",
      "Epoch:999/1000\n",
      "Loss on train= 0.005055502522736788\n",
      "Loss on test= 0.005887312814593315\n",
      "acc for Lsat= 0.08930668822130568 \n",
      "acc for Psat= 0.13104290841028915 \n",
      "acc for optim= 0.171970225387979\n",
      "Epoch:1000/1000\n",
      "Loss on train= 0.005070059560239315\n",
      "Loss on test= 0.006266147829592228\n",
      "acc for Lsat= 0.09962620185688138 \n",
      "acc for Psat= 0.12970766376928916 \n",
      "acc for optim= 0.17040094541804077\n"
     ]
    }
   ],
   "source": [
    "history = {'train_loss': [], 'test_loss': [],'train_acc':[],'test_acc1':[], 'test_acc2':[], \n",
    "          'test_acc3':[]}\n",
    "\n",
    "for fold, (train_idx,val_idx) in enumerate(splits.split(np.arange(len(dataset)))):\n",
    "\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "\n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = DataLoader(dataset, batch_size=64, sampler=train_sampler)\n",
    "    test_loader = DataLoader(dataset, batch_size=1, sampler=test_sampler)\n",
    "    \n",
    "    model = Network(input_size,output_size).to(device) \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        loss_on_train = train_epoch(model, optimizer, criterion, train_loader)\n",
    "        train_loss = float(np.mean(loss_on_train))\n",
    "        _, loss_on_test = validate(model, criterion, test_loader)\n",
    "        test_loss = float(np.mean(loss_on_test))\n",
    "        train_acc = test(model, train_loader)\n",
    "        test_acc = test(model, test_loader)\n",
    "        \n",
    "        print(\"Epoch:{}/{}\".format(epoch + 1, num_epochs))\n",
    "        print('Loss on train=', train_loss)\n",
    "        print('Loss on test=', test_loss)\n",
    "        print('acc for Lsat=', test_acc[0],'\\n' 'acc for Psat=', test_acc[1], '\\n' 'acc for optim=', test_acc[2])\n",
    "        \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    #history['train_acc'].append(train_acc)\n",
    "    history['test_acc1'].append(test_acc[0])  \n",
    "    history['test_acc2'].append(test_acc[1])  \n",
    "    history['test_acc3'].append(test_acc[2])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1cd2aea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of 5 fold cross validation\n",
      "Average Training Loss: 0.0053 \t Average Test Loss: 0.0058 \t Average Lsat Acc: 0.104 \t Average Psat Acc: 0.140 \t Average Loptim Acc: 0.175\n"
     ]
    }
   ],
   "source": [
    "avg_train_loss = np.mean(history['train_loss'])\n",
    "avg_test_loss = np.mean(history['test_loss'])\n",
    "avg_test_acc1 = np.mean(history['test_acc1'])\n",
    "avg_test_acc2 = np.mean(history['test_acc2'])\n",
    "avg_test_acc3 = np.mean(history['test_acc3'])\n",
    "\n",
    "print('Performance of {} fold cross validation'.format(k))\n",
    "print(\"Average Training Loss: {:.4f} \\t Average Test Loss: {:.4f} \\t Average Lsat Acc: {:.3f} \\t Average Psat Acc: {:.3f} \\t Average Loptim Acc: {:.3f}\".format(avg_train_loss,avg_test_loss,avg_test_acc1,avg_test_acc2,\n",
    "avg_test_acc3))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed580319",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
